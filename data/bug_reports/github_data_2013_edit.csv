repo,issue_link,issue_id,post,question,answer
elastic/kibana,https://github.com/elastic/kibana/issues/21204,elastic_kibana_issues_21204,"[Infra UI] Reconstruct log message from parsed data

This issues outlines the way in which the log messages displayed in the logging 
ui part of the Infra UI are derived from the documents stored in Elasticsearch.

# Task Breakdown

* [x] Implement graphql query to request log entries from a source (with a naive, static rule list) (PR #21306)
* [x] Update logging ui to consume the new graphql query (PR #21706)
* [ ] Add formatting rules for filebeat modules
* [ ] Add generic, robust fallback formatting rules
* [ ] Add configuration options to allow the user to specify custom rules

# Rationale

Simply displaying ""the log message"" as-is from a specific field in the 
documents retrieved from Elasticsearch is not practical for several reasons:

* **lack of a message**: Documents produced by some beats modules (and other
  sources) do not always have a single ""message"" field. Reasons might be that
  the message has been forwarded in a parsed format by a third party or that
  the message representation is highly use-case-dependent.
* **normalization**: When aggregating logs from different sources in a
  centralized store and UI the disparities between the log formats become
  apparent. In order to improve the user experience when viewing log messages
  from multiple sources we want to benefit from the extraction and
  normalization that has in many cases already been performed as part of the
  ingest pipeline. (e.g. timestamps, IP addresses)
* **enrichment**: The document might already have been enriched with details 
  from additional sources during ingestion, that were not part of the original 
  message.
* **interactivity**: Knowing the substructure of a synthesized log message 
  enables the UI components to improve the rendering and provide deeper 
  interactivity with parts of the message (e.g. add a filter by clicking on a 
  hostname).

# Specification

The message reconstruction process is paramtereized by a set of predefined 
rules as well as rules provided by the user in the configuration (see 
""Formatting Rules"" below).

The retrieval, transformation and rendering can be broken down into the 
following steps:

1. Querying
   1. Load list of formatting rules
   2. Extract set of required fields from formatting conditions and instructions
   3. Fetch documents including the required fields
2. Extraction
   1. Apply the formatting rules to each document with the first match winning
   2. Transmit the response to the browser including a sequence of tokens for 
      each entry which were resolved as described in the formatting instructions
3. Rendering
   1. Render the tokens as specified in the response for each log entry

## Formatting Rules

The rules are kept in an ordered list that encodes the relative priority of 
each rule. A rule is composed of a formatting condition and formatting 
instructions in a declarative manner. The declarative characteristic allows for 
derivation of the set of required document fields, which is useful for 
validation and optimization.

```typescript
interface FormattingRule {
  condition: FormattingCondition;
  format: FormattingInstructions;
}
```

The **formatting condition** is used to decide whether to use the corresponding 
formatting instruction to format the log event. It is either a list of 
field-value-pairs that the event document needs to contain in order to match or 
a list of fields that need to be present in order to match.

```typescript
type FormattingCondition =
  | FormattingFieldValueCondition
  | FormattingFieldExistsCondition;

interface FormattingFieldValueCondition {
  values: {
    [fieldName: string]: any;
  };
}

interface FormattingFieldExistsCondition {
  exists: string[];
}
```

The **formatting instructions** declare how the log message can be derived from 
the document fields. This is done by defining a list of tokens that either 
represent a field from the documents or a string constant. The tokens will be 
concatenated to produce the message.

```typescript
type FormattingInstructions = FormattingInstruction[];

type FormattingInstruction =
  | FormattingFieldReference
  | FormattingConstant

interface FormattingFieldReference {
  field: string;
}

interface FormattingConstant {
  constant: string;
}
```

# Considerations

## Where should the synthesis happen?

The synthesis could be performed in three different locations of the data 
retrieval pipeline:

* **In the query**: A painless scripted field could construct the message from 
  various document fields. While that would minimize the amount of data that 
  needs to be transferred from Elasticsearch to Kibana, it would deny knowledge 
  about the message substructe to the client. Additionally, programmatically 
  generating the painless scripts increases the complexity while reducing 
  testability.
* **In the Kibana server**: The Kibana server could retrieve the documents and 
  synthesize the message for delivery to the client. That would keep all the 
  processing logic in TypeScript and minimize the amount of data transferred to 
  the browser. The UI components would still lack deeper knowledge about the 
  message substructure.
* **In the browser**: Performing the reconstruction in the browser would yield 
  ultimate rendering flexibility at the cost of an increased data transfer 
  volume.

Flexibility and ease of implementation suggests the third option would be preferable.",What would be the benefit of the `in the browser` option that you would have different rendering options? Do you expect the way it's rendered to change often?,Flexibility and ease of implementation suggests the third option would be preferable.
elastic/kibana,https://github.com/elastic/kibana/issues/23885,elastic_kibana_issues_23885,"Screenreader doesn't announce that user is in a new space

**Kibana version:** 6.x latest snapshot

**Browser version:** chrome latest

**Browser OS version:** OS X

**Original install method (e.g. download page, yum, from source, etc.):** from snapshots

**Describe the bug:**  When a non-sighted user navigates to a space - User doesn't know that he is in that space. 

**Steps to reproduce:**
1. Use voiceover
2. Have more than one space
3. Try to navigate to a space using keyboard
4. Screenreader doesn't let the user know that she is in that space.

**Screenshots (if relevant):**
<img width=""1440"" alt=""screen shot 2018-10-05 at 12 26 28 pm"" src=""https://user-images.githubusercontent.com/7074629/46547397-c2e2e000-c899-11e8-8bb8-de3ce4bc53db.png"">

## Steps to fix that:

- [ ] 1. Make notifications showing while switching to another space: https://github.com/elastic/kibana/pull/36746
- [x] 2. Make notification announced by a ScreenReader: needs wait until https://github.com/elastic/eui/pull/2055 is merged into Kibana (Eui version next after 12.0.0)
- [ ] 3. Make showable notification hidden from a visual layout (ScreenReaderOnly)","Can you make it say ""Switching to space ____"" when the user clicks to select one? i.e. right  _before_ it transitions","Steps to fix that:

- [ ] 1. Make notifications showing while switching to another space
- [ ] 2. Make notification announced by a ScreenReader: needs wait until https://github.com/elastic/eui/pull/2055 is merged into Kibana.
- [ ] 3. Make showable notification hidden from a visual layout (ScreenReaderOnly)"
elastic/kibana,https://github.com/elastic/kibana/issues/33671,elastic_kibana_issues_33671,"[Meta] Prepare stack monitoring for new platform

Stack Monitoring migration will be a little untraditional since it will still keep angularjs in the first phase.  With `configureAppAngularModule` we are able to create an angular shim until we are ready to refactor to React.

Helpful links:
https://github.com/elastic/kibana/issues/31968
https://github.com/elastic/kibana/tree/master/rfcs/text

Legends: 
:hourglass_flowing_sand: Currently in-progress by @igoristic

## Client Side [docs](https://github.com/elastic/kibana/blob/master/src/core/MIGRATION.md#browser-side-plan-of-action): 

### 7.6
 **Phase 1:** (Part of the NP progress and is required before 8.0)
- [ ]  :hourglass_flowing_sand: Create shim wrapper for legacy dependencies `legacy.ts`, CoreSetup `plugin.ts`, and start `np_ready` directory process.
- [ ] :hourglass_flowing_sand: Change angular instance to `configureAppAngularModule`. Test original functionality still works: routing, breadcrumbs, globalState, timefilter, etc...
- [ ] Isolate main legacy angular components:
	- `ui/timefilter`(or possible leverage: https://github.com/elastic/kibana/pull/44783)
	- `ui/kbn_top_nav` (using https://github.com/elastic/kibana/pull/48542)
- [ ] Change any deprecated import aliases like: `plugins/monitoring/*` to their direct paths
- [ ] Move app entry/injection to `legacy.ts`

### 7.7
 **Phase 2:** (This phase will not be part of the NP 8.0 progress, but will follow shortly after Phase 1)
- [ ] Start angularjs to React/Typescript refactor:
	- Create React alternatives to `ui/timefilter` and `ui/kbn_top_nav`
	- Replace ui/router with react `BrowserRouter` router
	- Create global context states (in lieu of `globalState`, `timefilter`)
	- Move rest of the app to the `np_ready` directory

## Server Side [docs](https://github.com/elastic/kibana/blob/master/src/core/MIGRATION.md#server-side-plan-of-action): 

### 7.5
 **Phase 1:**
- [ ] Phase 1 of server-side migration (create appropriate shims and migrate usage to shims, create new plugin definition file) -> https://github.com/elastic/kibana/pull/46507
- [ ] Move all server.plugins.* calls to the backend Legacy shim


*NOTE*: Please note this list/ETAs is still work in progress and will be updated over time",Do you know when we want to have this done by? It might be good to find a home for this in the Stack Monitoring project board.,"## Angular Deprecation
The following modules need to be refactored away from angular:"
elastic/kibana,https://github.com/elastic/kibana/issues/46329,elastic_kibana_issues_46329,"[APM] Stack trace Local variables panel is not aligned with EUI vars

# Summary

The local variables section on the stack trace component does not have the appropriate styling to make it consistent with Kibana. There's primarily a problem with the styled component container and its style parameters which are setting the `font-family` to `Open Sans`.

<img width=""1599"" alt=""Screenshot 2019-09-23 at 12 39 55"" src=""https://user-images.githubusercontent.com/4104278/65419747-a1a73680-ddff-11e9-9528-3e44b8d7c155.png"">

It should be updated to not use the styled component container and instead use the `EuiTable` component and its inherited styles. As an example take a look at the implementation of the Metadata `EuiTable`.

<img width=""1628"" alt=""Screenshot 2019-09-23 at 13 39 57"" src=""https://user-images.githubusercontent.com/4104278/65422760-a839ac00-de07-11e9-87b4-e4c9b4c601a0.png"">","What font is wrong, and what should it be changed to? If there is a particular EUI component that should be used, please link that as well.","It should be updated to not use the styled component container and instead use the `EuiTable` component and its inherited styles. As an example take a look at the implementation of the Metadata `EuiTable`.

<img width=""1628"" alt=""Screenshot 2019-09-23 at 13 39 57"" src=""https://user-images.githubusercontent.com/4104278/65422760-a839ac00-de07-11e9-87b4-e4c9b4c601a0.png"">"
elastic/kibana,https://github.com/elastic/kibana/issues/24408,elastic_kibana_issues_24408,"[APM] Service overview: Adapt duration unit based on the median response time in the list

### Problem
The the Service list and Transactions list, we  durations are always displayed in `ms`. If the median duration in the list is in seconds, we should display duration for all services in seconds.

Requirements:
 - Display duration in appropriate unit (micro-sec, ms, sec, min, hour)
 - All services should display duration in the same unit (don't show one service in ms and another in minutes - make it harder to compare)

### Potential solution
To keep all units consistent for comparison, we could calculate the median duration, and convert the units based on this.

Get median service by duration:
```js
function median(numbers) {
  const middle = (numbers.length + 1) / 2;
  const sorted = [...numbers].sort(); // avoid mutating when sorting
  return sorted.length % 2 === 0
    ? (sorted[middle - 1.5] + sorted[middle - 0.5]) / 2
    : sorted[middle - 1];
}


median(services.map(service => service.responseTime))
```",why median? It would require you to sort them and find the middle one,"ms, sec, min, hour)
 - All services should display duration in the same unit (don't shoth + 1) / 2;
  const sorted = [...numbers].sort(); // avoid mutatin"
elastic/kibana,https://github.com/elastic/kibana/issues/26574,elastic_kibana_issues_26574,"[APM] Linking to Infra and Logging UIs

This is a new implementation issue for https://github.com/elastic/kibana/issues/26326 and what we discussed around 6.5.
Handy: 6.5 implementation issue https://github.com/elastic/kibana/issues/23315 and the removal issue https://github.com/elastic/kibana/issues/24562

### Motivation
We're bringing back the integration links in 6.6. 

>For the links to be useful, the logs, metrics and APM data needs to have the appropriate fields in their documents, for example container.id or kubernetes.pod.id.

>We're working to make it easier to set things up such that fields are added and the links are useful.
For example, with elastic/apm#22 container ID will automatically be added if the agent runs in a container. With elastic/apm#21 APM agent data will have kubernetes fields as well.

For when these links result in jumping to another solution with no results (due to the above complications) we'll update the no page-message to include a troubleshooting guide.

Update: We've decided to deactivate any links that links to a null value. We need some way of letting the user know why some links are greyed out. (e.g. tooltip with link to docs)

### Cross-solution links

- [ ] Bring back links in the transaction sample header
- [ ] Implement links in the error occurrence header (not required in this iteration)
- Don't implement these links for RUM services

Link | Description
-- | --
""[icon] Show trace logs"" | link to logs UI filtered for time and `trace.id`
""[icon] Show pod logs"" | link to logs UI filtered for time and `kubeternetes.pod.uid`
""[icon] Show container logs"" | link to logs UI filtered for time and `container.id`
""[icon] Show host logs"" | link to logs UI filtered for time and `host.name`
""[icon] Show pod metrics"" | links to infra UI filtered for time and `kubeternetes.pod.uid`
""[icon] Show container metrics"" | links to infra UI filtered for time and `container.id`
""[icon] Show host metrics"" | link to infra UI filtered for time and `host.name`

[icon]: Solution icon of app that we're linking to.
Deep-linking URLs: https://github.com/elastic/kibana/issues/23315#issuecomment-432305017



### Troubleshooting link

Links from Infra and Logging will drop into `/app/apm#/services/` with a `trace.id : ` query, so we should add our troubleshooting link here. 

- [ ] Add troubleshooting docs link to Services list ""no result"" message ([Example](https://cloudup.com/i89J8zHUKJ4))","don't show the host logs link if kubernetes.pod.uid is found, or things of that nature)?",Update: We've decided to deactivate any links that links to a null value. We need some way of letting the user know why some links are greyed out. (e.g. tooltip with link to docs)
elastic/kibana,https://github.com/elastic/kibana/issues/40704,elastic_kibana_issues_40704,"APM Sample Data

In order to improve the getting started experience, we'd like to add sample data to Kibana to power APM ~+ Infra + Logs~ so users can get hands on with them.  Edit: leave infra/logs/uptime for a follow on effort.

elastic/kibana#17807 originally added sample data into Kibana, so could help as a reference for implementation.

~Logs UI already supports the sample data index (`kibana_sample_data_logs`) by default, so populating that index should just work.~

~Infra UI also includes the logging sample index by default but not one for metrics.~

~APM UI does not include a sample data index by default.  elastic/kibana#39741 could fit in nicely to enable that.~ edit: use an index name that matches the exist pattern

See https://github.com/elastic/kibana/issues/40704#issuecomment-547198210 for more implementation details

cc @tbragin @nehaduggal","Can sample data have dynamic dates applied?

Another reason to consider building a simple data generator to use for dev that could export this kind of data... space time someday!","~~~~ edit: use an index name that matches the exist pattern

See https://github.com/elastic/kibana/issues/40704#issuecomment-547198210 for more implementation details"
elastic/kibana,https://github.com/elastic/kibana/issues/21128,elastic_kibana_issues_21128,"Monitoring and alerts for Elasticsearch CCR

**Describe the feature:**
Overview
The CCR feature provides the ability for ES users to have their indices data replicated to other clusters in order to achieve DR copy or mirroring data for geo proximity queries (data served closer to the clients)
The ES mechanism follows the CCS implementation of trusted clusters as the basis for getting access to data. The remote index is called “follower” and the data source index is called “leader”. 
The follower is aware of its leader but not vice versa. The follower fetches data from the leader. The fetching is done by each of the follower shards that copies operations form the leader ops-log. The followers are created and removed by the new CCR API. 
The main use case is “Auto follow” - the follower is defined by an index template and it creates an follower index for each leader index matching the template

The monitoring of this feature is critical for understanding the ongoing replication:
Does my cluster trust other clusters? And are they really accessible?
How many indices in my cluster are followers? 
Does replication really happen for my index? And If not why?
Is any follower index / shard in index lagging behind its leader? And be what number of operations?
Does the follower lacks resources (Storage / CPU / RAM) to cope with writing the data?


Monitoring of cross cluster replication (CCR):
Metrics and their visualisations should allow the user to see:
- If the follower index is indeed connected to the leader remote index
- If there is an lag of operations between follower and leader (how many operations behind)
- Consider networking information (num of bytes received and, num of packages dropped / errors) to get an indication about quality of network and the replication load 
Exact list of metrics to be added depends on ES CCR monitoring API [will link issue when read]

The following tasks need to be planned and phased:
* Add CCR metrics collections to ES Metricbeat module
* Add CCR metrics graphs to ES monitoring screen to summarize all indices replication per cluster
* Add CCR metrics per index in index details screen
* Add Cluster alert in case of leader not reachable more than 5 minutes
* Add Cluster alert in case of lag between follower and leader (need to check based on last successful fetch)

**Suggest first phase**
For 6.5 we suggest to add a way to find out the if:
All followers can access leaders (We have requested API for access problems)
If there are any followers lagging behind leaders

**Describe a specific use case for the feature:**
Cross cluster replication is about Active - Passive replication from one index to another (dabbed leader and follower) [Read here for more details](https://github.com/elastic/elasticsearch/issues/30086)
In order to ensure, index is indeed following leader without significant lag user should be able to get indications on the monitoring and management relevant screens.","Will the point of the graph(s) be to understand, visually, if the follower is lagging too far behind the leader? Or something else?","** Suggest firs phase**
For 6.5 we suggest to add a way to find out the if:
All followers can access leaders (We have requested API for access problems)
If there are any followers lagging behind leaders"
elastic/kibana,https://github.com/elastic/kibana/issues/19641,elastic_kibana_issues_19641,"Reduce of empty array with no initial value

:information_source: **See [comment below](#issuecomment-394599463) for actual solution/workaround.**

**Kibana version:**
6.3
**Elasticsearch version:**
6.3
**Server OS version:**
darwin x64
**Describe the bug:**
An unexpected error occurred: ""Reduce of empty array with no initial value"".
**Steps to reproduce:**
1. git clone https://github.com/elastic/kibana
2. git checkout  6.3
3. yarn kbn bootstrap",Can you verify you are on Node 8.11.0?,:information_source: **See [comment below](#issuecomment-394599463) for actual solution/workaround.**
elastic/kibana,https://github.com/elastic/kibana/issues/35489,elastic_kibana_issues_35489,"[Canvas] Raw documents - limit of 100 docvalue_fields

**Describe the feature:**
I suspect this is an imposed limitation, but it may be a bug. When you select an element and change to the **Raw documents** source, depending upon the Index and Sort Field you choose, you can hit this message upon clicking the Preview button:

<img width=""611"" alt=""Screenshot 2019-04-23 11 41 15"" src=""https://user-images.githubusercontent.com/446285/56601967-098ff180-65c2-11e9-8270-0d197882a4e8.png"">

**Describe a specific use case for the feature:**
I'm not sure what the message means, but it feels like I'm returning too many results. Either way, some more information and/or the ability to override this here would likely be helpful to users.

@dschneiter noted that a customer asked about this limitation and whether or not it is configurable.
They didn't get back any error, but wanted Canvas to be able to render information about large result sets. What they got back was not limited to exactly 100, but they didn't manage to get back larger numbers than around 500 (the student is not 100% clear about the queries his colleague executed).",Where is the setting to change this if there isn't a 1000 document limit?,"@dschneiter noted that a customer asked about this limitation and whether or not it is configurable.
They didn't get back any error, but wanted Canvas to be able to render information about large result sets. What they got back was not limited to exactly 100, but they didn't manage to get back larger numbers than around 500 (the student is not 100% clear about the queries his colleague executed)."
elastic/kibana,https://github.com/elastic/kibana/issues/26259,elastic_kibana_issues_26259,"APM bundle optimization

Related to elastic/kibana#26258 and #26255, the `apm.bundle.js` file is 1.5 MB / 175 KB gzipped. We should probably address the following things as quick-ish wins:

* react-vis (526 KB / 48 KB gzipped) and d3-geo (84 KB / 14 KB gzipped) both show up in the APM bundle _and also_ in `vendors.bundle.js` -- the webpack configuration setup in Kibana is not easy to follow but we should engage Kibana operations if necessary and find out why this duplication exists
  - [x] Why is react-vis duplicated? **Answer**: Because EUI ships its own copy so we have to keep those version ranges in sync
  - [ ] Why is d3-geo duplicated?
* [ ] react-syntax-highlighter (188 KB / 14 KB gzipped) is big and contains a ton of unnecessary CSS that we could probably remove (this gzips very well)
  * Note: there is already a highlightJS package that is huge and loaded in the Kibana bundle, we could consider using that and remove this dep, etc.
* [ ] react-redux-request (138 KB / 12 KB gzipped) -- we should look at this and see if we can trim the build down a bit (although it also gzips quite nicely already)
* [ ] create-react-class (28 KB / 2.3 KB gzipped) why do we load this? It's not in any bundle but ours ... 

To be perfectly honest, if we could knock out the top item on this list and de-dupe our bundle from the vendors bundle, our gzipped bundle size would be about 100-110 KB, with about half of that being our actual APM code. Not great, but not horrible.",Do you know if APM or one of its dependencies is using a different version than what's in the vendor bundle?,"- [x] Why is react-vis duplicated? **Answer**: Because EUI ships its own copy so we have to keep those version ranges in sync
  - [ ] Why is d3-geo duplicated?"
elastic/kibana,https://github.com/elastic/kibana/issues/38167,elastic_kibana_issues_38167,"[Logs UI] Link Trace ID to APM

In our ongoing efforts to cross-link between observability solutions, we should be able to link some log field values to their related solution pages. For this ticket, we'll start with linking any log detail flyout that contains a ""trace ID"" to the APM trace page for that trace.

AC:
* logs with a trace ID should contain a new link in their log detail flyout's action menu for ""View in APM"", similar to the view monitor link that exists now

<img width=""2239"" alt=""Screen Shot 2019-06-24 at 3 29 10 PM"" src=""https://user-images.githubusercontent.com/159370/60046820-477ac600-9696-11e9-8d96-821065d6b8d9.png"">","How do you see the UI? Action button in the popover that will link / show action popover (if multiple actions)?
![Screenshot_2019-06-06_at_14_23_20](https://user-images.githubusercontent.com/841813/59032557-e023e000-8866-11e9-9968-246685991590.png)","For this ticket, we'll start with linking any log detail flyout that contains a ""trace ID"" to the APM trace page for that trace. logs with a have that trace ID appear as a"
elastic/kibana,https://github.com/elastic/kibana/issues/60937,elastic_kibana_issues_60937,"Migrate Logstash plugin

We need to migrate the Logstash plugin in `x-pack/legacy/plugins/logstash` to the New Platform.

Subtasks:
- [x] Migrate client-side - **this should be prioritized first to help unblock management's migration**
  - [ ] Refactor all services in public/services to use NP services
  - [ ] Move services to plugin class + shim
  - [ ] Move logic out of Angular routes & directives into React app
  - [ ] Handle dependency between monitoring and logstash ([here](https://github.com/elastic/kibana/blob/master/x-pack/legacy/plugins/logstash/public/services/monitoring/monitoring_service.factory.js#L15) and [here](https://github.com/elastic/kibana/blob/master/x-pack/legacy/plugins/logstash/public/services/monitoring/monitoring_service.js#L33))
  - [ ] Migrate to New Platform
    -  this could be done as a single step or with a shimming phase. App seems small enough to do in a single step.
- [x] Migrate server-side https://github.com/elastic/kibana/pull/63135

Things we are not doing:
- Converting everything to TypeScript
  - May make sense to use TS in certain places (eg. plugin class), but we are not converting all the existing code to TS as part of this migration.

Resources:
- [Mapping for `.logstash` index](https://github.com/elastic/elasticsearch/blob/master/x-pack/plugin/core/src/main/resources/logstash-management.json)
- [Logstash centralized pipeline management docs](https://www.elastic.co/guide/en/logstash/current/logstash-centralized-pipeline-management.html)",Should the `Migrate client-side` part be prioritized for 7.8?,"- [ ] Remove all dependencies on Angular  - [ ] Migrate to New Platform
    -  this could be done as a single step or with a shimming phase. App seems small enough to do in a single step."
elastic/kibana,https://github.com/elastic/kibana/issues/23985,elastic_kibana_issues_23985,"Allow to export all dashboards via dashboard export API

**Updated by Tim**: Feature request to make the `dashboard` parameter in the dashboard export API optional, to allow exporting all dashboards.

**Kibana version:**
6.4.2
**Elasticsearch version:**
6.4.2
**Server OS version:**
Linux 3.16.0-7-amd64 #1 SMP Debian 3.16.59-1 (2018-10-03) x86_64 GNU/Linux
**Browser version:**
Firefox 60.2.2esr (64-bit)
**Browser OS version:**
Linux 4.9.0-8-amd64 #1 SMP Debian 4.9.110-3+deb9u5 (2018-09-30) x86_64 GNU/Linux

**Original install method (e.g. download page, yum, from source, etc.):**
Debian package

**Describe the bug:**
https://www.elastic.co/guide/en/kibana/6.4/dashboard-import-api-export.html describes the query parameter dashboard as optional. But it is required.

**Steps to reproduce:**
1. run curl as described without the optional parameter
```
curl -X GET ""http://localhost:5601/api/kibana/dashboards/export"" -H 'kbn-xsrf: true
```
2. you will receive this error
```
{""statusCode"":400,""error"":""Bad Request"",""message"":""child \""dashboard\"" fails because [\""dashboard\"" is required]"",""validation"":{""source"":""query"",""keys"":[""dashboard""]}}
```

**Expected behavior:**
It should return all dashboards like documented.

**Screenshots (if relevant):**

**Errors in browser console (if relevant):**

**Provide logs and/or server output (if relevant):**

**Any additional context:**",Does anyone know what our intended behavior here is?,"**Updated by Tim**: Feature request to make the `dashboard` parameter in the dashboard export API optional, to allow exporting all dashboards."
elastic/kibana,https://github.com/elastic/kibana/issues/25715,elastic_kibana_issues_25715,"Filter data that has not been migrated to 7.0

From Kibana 7.0 all ES queries in APM ui should only retrieve 7.0 data, and this filter out 6.x data since this can cause issues in the UI.

Field to filter on `observer.version_major` and checking it is `>= 7`",Should we also migrate v1 fields to v2?,"tion assitant, the APM UI should filte out ol data by using the field `observerversion_major` and checking it is `== 7`"
elastic/kibana,https://github.com/elastic/kibana/issues/35898,elastic_kibana_issues_35898,"Allow index pattern with no matching data

**Describe the feature:**
Allow index patterns to be created without matching indices, so that the messaging doesn't appear to be an error.

**Describe a specific use case for the feature:**
Right now APM automatically creates the apm index pattern on server startup if it doesn't already exist. The goal is to make the [query bar](https://www.elastic.co/guide/en/kibana/7.0/query-bar.html) in the APM UI, which relies on the index pattern, work automatically.  

If that happens on a fresh instance without any data, the user sees this messaging:
![image](https://user-images.githubusercontent.com/1967266/57042363-4dfe3b80-6c19-11e9-88fd-f30a57c5fdfb.png)
It indicates that something is wrong, when there's really no error.

To reproduce: start kibana 7.2 snapshot or newer with a fresh elasticsearch and navigate to discover.",What do you think the best course of action is?,"The goal is to make the [query bar](https://www.elastic.co/guide/en/kibana/7.0/query-bar.html) in the APM UI, which relies on the index pattern, work automatically.  



To reproduce: start kibana 7.2 snapshot or newer with a fresh elasticsearch and navigate to discover."
elastic/kibana,https://github.com/elastic/kibana/issues/37914,elastic_kibana_issues_37914,"[Code]: Script error occurs on query submit

**Kibana version:** master

**Elasticsearch version:** master

**Server OS version:**

**Browser version:** Chrome 74

**Browser OS version:** MacOS 10.14.5

**Original install method (e.g. download page, yum, from source, etc.):** master

**Describe the bug:** Error occurs on query submit

**Steps to reproduce:**
I can reproduce it while running [from source view page to search page can go back and forward](https://github.com/elastic/kibana/blob/master/x-pack/test/functional/apps/code/history.ts#L103) functional test locally.
```
         └- ✖ fail: ""Code History browser history can go back while exploring code app from source view page to search page can go back and forward""
         │      Error: retry.try timeout: TimeoutError: Waiting for element to be located By(css selector, [data-test-subj~=""queryInput""])
         │ Wait timed out after 10059ms
         │     at /Users/dzmitrylemechko/github/kibana/node_modules/selenium-webdriver/lib/webdriver.js:834:17
         │     at process._tickCallback (internal/process/next_tick.js:68:7)
         │       at lastError (/Users/dzmitrylemechko/github/kibana/test/common/services/retry/retry_for_success.ts:28:9)
         │       at onFailure (/Users/dzmitrylemechko/github/kibana/test/common/services/retry/retry_for_success.ts:68:13)
```

**Expected behavior:** Results are displayed

**Screenshots (if relevant):**
<img width=""1712"" alt=""Kibana 2019-06-03 19-08-47"" src=""https://user-images.githubusercontent.com/10977896/58822151-19760900-8637-11e9-912d-69b583dea626.png"">


**Errors in browser console (if relevant):**

```
         │      http://localhost:5620/api/code/repo/config/github.com/Microsoft/TypeScript-Node-Starter - Failed to load resource: the server responded with a status of 404 (Not Found)
         │      http://localhost:5620/bundles/commons.bundle.js 24909:20 Error: Script error. (:0)
         │          at push../src/legacy/ui/public/notify/notify.js.window.onerror (http://localhost:5620/bundles/commons.bundle.js:143475:32)
         │      javascript 0:190 Uncaught DOMException: Failed to execute 'removeChild' on 'Node': The node to be removed is not a child of this node.
         │      http://localhost:5620/bundles/commons.bundle.js 143474:31 Uncaught Error: Script error. (:0)
```

**Provide logs and/or server output (if relevant):**

**Any additional context:**",Can you elaborate on the steps?,"```
         └- ✖ fail: ""Code History browser history can go back while exploring code app from source view page to search page can go back and forward""
         │      Error: retry.try timeout: TimeoutError: Waiting for element to be located By(css selector, [data-test-subj~=""queryInput""])
         │ Wait timed out after 10059ms
         │     at /Users/dzmitrylemechko/github/kibana/node_modules/selenium-webdriver/lib/webdriver.js:834:17
         │     at process._tickCallback (internal/process/next_tick.js:68:7)
         │       at lastError (/Users/dzmitrylemechko/github/kibana/test/common/services/retry/retry_for_success.ts:28:9)
         │       at onFailure (/Users/dzmitrylemechko/github/kibana/test/common/services/retry/retry_for_success.ts:68:13)
```"
elastic/kibana,https://github.com/elastic/kibana/issues/53117,elastic_kibana_issues_53117,"[Automation] Improve testing experience with FTR

### Summary

The purpose is to collect the pain points we face today in the test automation process and FTR as a solution specifically, discuss possible solutions and work on it.

### Areas to improve/ issues

- [x] Hard to use Page Objects files
Some POs are way too large (vizualize_page.js, dashboard_page.js) and are not in TS yet, that slows down the process of adding/updating tests and keeping track of available functions.
    - proposal: split functions between several POs and services (visualize, visualize_editor, etc.) and convert current ones into TS.
- [ ] Current E2E tests are slow and repetitive in preconditions
Most of the tests have similar preconditions that we do via UI (e.g. date picker setup). It does not only take time but also may introduce additional flakiness though it is not the main functionality to be tested in particular tests.
    - proposal: launch Kibana with custom state and avoid doing UI pre-conditions",Should we document them and make reusable?,[ ] [ ]
elastic/kibana,https://github.com/elastic/kibana/issues/61738,elastic_kibana_issues_61738,"[Meta] Background Search Roadmap

### Background searches

A background search refers to running one or more ES searches in the background, in the context of a dashboard, or another application, allowing a user to come back and view the results later.

### Proof of Concept

The [POC PR](https://github.com/elastic/kibana/pull/64641) includes a partial implementation of the Background Search feature, used for demo purposes. It also contains a sample plugin.

It should be reviewed and serve as a basis for the full implementation.

### Tasks

(*) Means that the capability was implemented in the POC.

#### Improve search API
  - [x] [Refactor `fetchSoon` and `callClient` to isolate `msearch`](https://github.com/elastic/kibana/issues/61739)
  - [ ] Improve typing around requests / responses
  - [ ] Improve providing context to strategies - [Client](https://github.com/elastic/kibana/pull/60342) and [Server](https://github.com/elastic/kibana/pull/68452). [Logs example](https://github.com/elastic/kibana/pull/67533#pullrequestreview-419944992).
  - [ ] Allow reusing strategies on server side
  - [ ] Expose search API on server. 

#### Client side `BackgroundSession`
  - [ ] (*) Add a `session` sub service to the existing `search` service with get \ start \ set \ clear APIs.
  - [ ] (*) Add a `subscribe` method to the existing `search` service. Trigger an update when a session is sent to background by a user. (Notification comes from `search_interceptor`)
  - [ ] (*) Use the application state to set \ start a session ID to track \ reload a session.
  - [ ] (*) In `SearchSource` add methods: `setSessionId` and `getSessionId`. Integrate with the searchService.
  - [ ] (*)  When a user chooses to send a search to background, send a request to the server to create a `BackgroundSession` object.
  - [ ] URL service - store and reconstruct urls
  - [ ] Allow disabling background search per app

#### Server side Background Session Service
  - [ ] (*) Implement server side background session service API (trackId / store / getId) https://github.com/elastic/kibana/issues/61743
  - [ ] (*) Implement server side background session service monitoring loop that syncs tracked IDs to a saved objcet if a user decides to store the session.
  - [ ] Handle edge case of extending expiration of requests not generated by async search
  - [ ] Implement versioned updates (concurrency)
  - [ ] Don't allow adding new requests to a complete / error session

#### `Embeddables` integration
   - [ ] implement observable in base class and opt out by default
   - [ ] opt in in visualize embeddable
   - [ ] opt out for terms agg with other bucket, tsvb, timelion and so on.
   - [ ] Render opt out message when reloading

#### Monitoring service
  - [ ] [ES to allow monitoring server to get Background Search metadata](https://github.com/elastic/elasticsearch/issues/57537)
  - [ ] Create a task manager task to track session progress

#### Management
   - [ ] (*) Clear a session upon navigating away from each application \ canceling an ongoing refresh. (Automatically, using the application service).
   - [ ] List current user's sessions
   - [ ] Cancel running session
   - [ ] Delete session (and expire)
   - [ ] Extend session

#### UI
  - [ ] (*) [Dashboard background search UI](https://github.com/elastic/kibana/issues/61740)
  - [ ] [Background search management UI](https://github.com/elastic/kibana/issues/61741)
  - [ ] Kibana global notifications 

#### Misc
  - [ ] [Telemetry](https://github.com/elastic/kibana/issues/62964)
  - [ ] [Use search service in TSVB (Server side)](https://github.com/elastic/kibana/issues/67587)
  - [x] [Use search service in Vega](https://github.com/elastic/kibana/issues/67584) 
  - [ ] [Use search service in Timelion](https://github.com/elastic/kibana/issues/67585)

### `keep_alive` time

The ElasticSearch `_async_search` endpoint stores results of queries that ran longer than `wait_for_completion_timeout` by default.

The default `keep_alive` time is **5 days**, and this includes both **the query run time and store time**. So if `keep_alive` is 5 days and the query ran for 4 days, it will be stored by default for another **1 day**. If a query did not complete until the `keep_alive` time is reached - it will be canceled.

So while implementing this feature, it is important that **Kibana doesn't store all queries for that time period**. Storing queries for a long time is expensive in terms of both resources and cost. Instead, we should store the data for an initially short time, and then **extend** it, by sending a GET request to the same search ID, with a longer `keep_alive`.

### Known limitations

- **Follow up searches** - Some visualizations send additional searches based on the results of an initial search. For example, known examples are a pie chart with an Other bucket or a histogram based on the non default timefield. 
If we rely on the browser to track and store outgoing requests for a given background search, navigating away from the visualization before the secondary request was sent, will result in a **partial background search** that triggers an additional background search when opened. 
The solution to this seems to be supporting _server side execution_, but this maybe complex and time consuming.   
  - **ES support**: When can we expect ES atomic handling of the two examples mentioned (pie charts, histogram)
  - Do **Maps** and **TSVB**  have similar limitations?
- **TSVB does not use the existing search service**. More over, it sends multiple requests from the server side. This might be resolved by making the search service available on the server side and using it from TSVB, or having TSVB use the `_async_search` API and return the search IDs somehow to the client.
- **Timelion** won't be supported.
- **Completion notifications** should be available to the user, regardless which application he's using ATM. This requires implementing a generic push notifications service (With [Web Workers?](https://caniuse.com/#feat=webworkers)).  Maybe implemented in Phase 2.
- **Web Sockets** - can we use them on cloud somehow?",Can we store it for the timeout time configured?,"- [ ] [Background Search Service](https://github.com/elastic/kibana/issues/61743)
- [ ] Search Service
  - [ ] [Refactor `fetchSoon` and `callClient` to isolate `msearch`](https://github.com/elastic/kibana/issues/61739)
  - [ ] `data_enhanced/search` changes
     - [ ] [Pass down `backgroundRequestID` to ES in `async_search`](https://github.com/elastic/kibana/issues/61744)
     - [ ] [Return `backgroundRequestID` from `async_search`](https://github.com/elastic/kibana/issues/61745)
     - [ ] Pass down `keep_results_timeout` to `async_search` (See https://github.com/elastic/kibana/issues/61498 and https://github.com/elastic/elasticsearch/issues/54069 for naming)
     - [ ] [Use `search_interceptor` to save a `backgroundSeach`](https://github.com/elastic/kibana/issues/61746)
- [ ] App integration
  - [ ] [Applications should set the background search ID, if available, onto the `SearchSource`.](https://github.com/elastic/kibana/issues/61742)"
elastic/kibana,https://github.com/elastic/kibana/issues/56762,elastic_kibana_issues_56762,"Collect non-sensitive platform-specific config stats

We would like to understand what platform features are used and how they configured by the users. That would help us make decisions about API completeness. 
The main problem with this that the platform doesn't have access to the Telemetry plugin. Nor telemetry plugin has access to the platform config.

One item we'd like to include this as well is which 3rd party plugins are installed + enabled.

Questions we'd like to answer for config things:
- How many SavedObjects do we have?
- Which plugins were disabled by the user?
- Are any 3rd party plugins installed? Which ones?

Data to collect, all keys should be opt-in:
- Disabled plugins + installed 3rd party plugins
- HTTP config (?)
- Elasticsearch config (?)
- Logging config (?)",Which part of the config would the plugin actually need access to? Everything?,One item we'd like to include this as well is which 3rd party plugins are installed + enabled.
elastic/kibana,https://github.com/elastic/kibana/issues/52494,elastic_kibana_issues_52494,"Refactor kibana-react context

- [ ] Refactor `kibana-react` global context
  - [ ] Remove `.notifications` and `.overlays` objects from context.
  - [ ] Lift `.services` object up.
  - [ ] Possibly add `useNotifications` and `useOverlays` hooks instead of `.overlays` and `.notifications` objects.
- [ ] Update docs to remove examples of passing all of `core` to the provider
  - As discussed in #53029, passing all of `core` to the provider encourages tight coupling to the UI, which can be problematic, and we want to avoid recommending this to devs.
  - Examples using this approach should be removed from the docs; instead we should only show examples where pieces of core are explicitly passed to the provider.","Should we include those in the scope of this issue, or track separately?","- [ ] Update docs to remove examples of passing all of `core` to the provider
  - As discussed in #53029, passing all of `core` to the provider encourages tight coupling to the UI, which can be problematic, and we want to avoid recommending this to devs.
  - Examples using this approach should be removed from the docs; instead we should only show examples where pieces of core are explicitly passed to the provider."
elastic/kibana,https://github.com/elastic/kibana/issues/61063,elastic_kibana_issues_61063,"[APM] ""For the last"" expression component jumps around when editing values 

![Kapture 2020-03-24 at 14 02 18](https://user-images.githubusercontent.com/352732/77429079-6b139e00-6dd9-11ea-9922-6e1b8ace2c87.gif)","Would it be possible to put the ""for the last"" statement on its own row?",2020-03-24 at 14 02 18622-6e1b8ace2cif
elastic/kibana,https://github.com/elastic/kibana/issues/59697,elastic_kibana_issues_59697,"[Canvas] Telemetry Notification Shows in Full Screen

![image](https://user-images.githubusercontent.com/515272/76248730-47b4f480-6218-11ea-890b-a12d53dfa543.png)


To get the Notification to show up, you just need to fire up a clean install of ES and Kibana and it should be there.",may i work on this issue ?,"To get the Notification to show up, you just need to fire up a clean install of ES and Kibana and it should be there."
elastic/kibana,https://github.com/elastic/kibana/issues/43980,elastic_kibana_issues_43980,"[APM] Implementation of browser breakdown for errors

As a user, I want to see the error distribution for each browser vendor. We have a very similar chart to visualize page load by browser (screenshots: https://github.com/elastic/kibana/issues/35571). 

The new chart should
- show the error occurrences for top 3 browser vendors (+ others aggregated) over the selected timeframe as a stacked bar chart
- the tooltip should show the occurrences and the error rate (%).
- please use eui viz colors

![Frame-1](https://user-images.githubusercontent.com/20965076/63867157-ae796b80-c9b4-11e9-9aa2-3824e47d2317.png)


Related design issue: https://github.com/elastic/kibana/issues/37869",Does it makes sense to have a stacked bar chart for this?,"occurrences for top 3 browser vendors (+ others aggregated) over the selected timeframe as a stacked bar chart
- the tooltip should show the occurrences and the error"
elastic/kibana,https://github.com/elastic/kibana/issues/48616,elastic_kibana_issues_48616,"[Logs UI] customization: smart presets vs. of user choices

In my most recent review, I stumbled across the `customize` actions. Thinking this through again, I'm not sure if we need them and would like to discuss this here.

Currently, the customize menu looks like this:
<img width=""257"" alt=""Screenshot 2019-10-18 at 10 10 17"" src=""https://user-images.githubusercontent.com/20965076/67078516-be7e2200-f191-11e9-89b2-6e33754f8d5f.png"">

- Minimap
In my opinion, the minimap should scale according to the selected timeframe. This timeframe is selected on purpose and there should not be a need to select an additional timeframe/scale for the minimap.

_Minimap controls will be removed during the work being done to switch us to the datetime picker, see: #37217_

- Wrap long lines
I think we could always wrap long lines. Investigating logs is rarely something one would do on a smartphone.

_Line length controls will be taken care of as we investigate column selection and line wrapping more holistically for the logs stream view, see: elastic/kibana#52490 _

- Text size
The text size is chosen to fit our product and our users' needs. Additionally, the text size can always be adjusted via the browser zoom.

_Text size controls are moved to #53130_


What would dropping the menu mean?

Benefits
- dropping actions/choices can reduce cognitive load
- focus on the main use cases
- (I think in the future we will have more features which could need some space)

Cons
- fewer user choices/customization",Maybe there's something I'm missing?,"*This will be removed during the work being done to switch us to the datetime picker, see: #37217



*This will be taken care of as we investigate column selection and line wrapping more holistically for the logs stream view, see: [proof of conept ticket creation TBD]*This should be done when we have time."
elastic/kibana,https://github.com/elastic/kibana/issues/65426,elastic_kibana_issues_65426,"[APM] Remove link from active page in the breadcrumb

The last item in the breadcrumb shouldn't be clickable because it's the active page.

![May-06-2020 10-26-42](https://user-images.githubusercontent.com/55978943/81154526-4556e880-8f84-11ea-99d5-af355544f20e.gif)",Which request is failing? (eg `GET /api/apm/foo?bar=baz`),"The link generated to use in the transaction overview breadcrumb, contains only these items:
```
// public/components/shared/Links/apm/APMLink.tsx
export const PERShen a user clicks on it, the links doesn't have all necessary queryrams to be able to"
elastic/kibana,https://github.com/elastic/kibana/issues/61074,elastic_kibana_issues_61074,"[EPM] setup end point installing old package version

When the user goes to the ingest manager for the first time the /setup endpoint is called which installed `base` and `system` packages.  The latest system package should be installed.  

https://epr-staging.elastic.co/search?package=system   returns the latest package last instead of first.  /setup was installing an old package.  currently how things work is we fetch packages from the registry to search saved objects for and return the installed packages. but we always get the latest packages via https://epr-staging.elastic.co/search?category .  if the user has an old package installed, it wont be searched for.  so that's something to sort out with the package versions.  we should probably only present users with the version they are using in the UI and https://epr-staging.elastic.co/search?category should perhaps return all the versions to filter through",What version is installed at the moment?,"https://epr-staging.elastic.co/search?package=system   returns the latest package last instead of first.  /setup was installing an old package.  currently how things work is we fetch packages from the registry to search saved objects for and return the installed packages. but we always get the latest packages via https://epr-staging.elastic.co/search?category .  if the user has an old package installed, it wont be searched for.  so that's something to sort out with the package versions.  we should probably only present users with the version they are using in the UI and https://epr-staging.elastic.co/search?category should perhaps return all the versions to filter through"
elastic/kibana,https://github.com/elastic/kibana/issues/56375,elastic_kibana_issues_56375,"Discover crashes when the primary index pattern is empty (Case: APM)

**Temporary workaround:**
Changing the default index pattern from `apm-*` to something else fixes the issue

**Kibana version:**
7.5.2
**Elasticsearch version:**
7.5.2
**Server OS version:**
Ubuntu 18.04.03
**Browser version:**
Chrome 79.0.3945.130 / FireFox 72.0.2 (64-bit)
**Browser OS version:**
Windows 10
**Original install method (e.g. download page, yum, from source, etc.):**
Installed from offical repository with APT
**Describe the bug:**
When clicking ""Discover"" button in left hand toolbar i get the following error 
""Error fetching fields"", Error: Not Found at https://elk.xxxx..no/bundles/commons.bundle.js:3:1371537 
**Steps to reproduce:**
1. Install ELK statck
2. Install OpenJDK 11
3.

**Expected behavior:**
To get discover page
**Screenshots (if relevant):**
![kibana3](https://user-images.githubusercontent.com/8417277/73450681-300b6600-4366-11ea-8e0f-4828a8e6821e.jpg)

**Errors in browser console (if relevant):**
`VM6:1 GET https://xxxxxxxxx.no/api/index_patterns/_fields_for_wildcard?pattern=apm-*&meta_fields=_source&meta_fields=_id&meta_fields=_type&meta_fields=_index&meta_fields=_score 404 (Not Found)
(anonymous) @ VM6:1
_callee6$ @ commons.bundle.js:3
tryCatch @ vendors.bundle.dll.js:489
invoke @ vendors.bundle.dll.js:489
forEach.prototype.<computed> @ vendors.bundle.dll.js:489
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
fetcher @ commons.bundle.js:3
Promise.then (async)
_callee7$ @ commons.bundle.js:3
tryCatch @ vendors.bundle.dll.js:489
invoke @ vendors.bundle.dll.js:489
forEach.prototype.<computed> @ vendors.bundle.dll.js:489
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
_callee8$ @ commons.bundle.js:3
tryCatch @ vendors.bundle.dll.js:489
invoke @ vendors.bundle.dll.js:489
forEach.prototype.<computed> @ vendors.bundle.dll.js:489
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
fetch @ commons.bundle.js:3
_request @ commons.bundle.js:3
getFieldsForWildcard @ commons.bundle.js:3
fetchForWildcard @ commons.bundle.js:3
fetch @ commons.bundle.js:3
_callee9$ @ commons.bundle.js:3
tryCatch @ vendors.bundle.dll.js:489
invoke @ vendors.bundle.dll.js:489
forEach.prototype.<computed> @ vendors.bundle.dll.js:489
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
_fetchFields @ commons.bundle.js:3
refreshFields @ commons.bundle.js:3
_callee$ @ commons.bundle.js:3
tryCatch @ vendors.bundle.dll.js:489
invoke @ vendors.bundle.dll.js:489
forEach.prototype.<computed> @ vendors.bundle.dll.js:489
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
indexFields @ commons.bundle.js:3
_callee2$ @ commons.bundle.js:3
tryCatch @ vendors.bundle.dll.js:489
invoke @ vendors.bundle.dll.js:489
forEach.prototype.<computed> @ vendors.bundle.dll.js:489
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
updateFromElasticSearch @ commons.bundle.js:3
_callee3$ @ commons.bundle.js:3
tryCatch @ vendors.bundle.dll.js:489
invoke @ vendors.bundle.dll.js:489
forEach.prototype.<computed> @ vendors.bundle.dll.js:489
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
Promise.then (async)
asyncGeneratorStep @ commons.bundle.js:3
_next @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
init @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
(anonymous) @ kibana.bundle.js:3
Promise.then (async)
ip @ kibana.bundle.js:3
invoke @ vendors.bundle.dll.js:435
(anonymous) @ commons.bundle.js:3
processQueue @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:435
$digest @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:435
completeTask @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:435
setTimeout (async)
Browser.self.defer @ vendors.bundle.dll.js:435
$evalAsync @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:435
scheduleProcessQueue @ vendors.bundle.dll.js:435
$$resolve @ vendors.bundle.dll.js:435
doResolve @ vendors.bundle.dll.js:435
Promise.then (async)
$$resolve @ vendors.bundle.dll.js:435
resolvePromise @ vendors.bundle.dll.js:435
Deferred.resolve @ vendors.bundle.dll.js:435
_module.service.Promise.resolve @ commons.bundle.js:3
_module.service.Promise.try @ commons.bundle.js:3
(anonymous) @ commons.bundle.js:3
_module.service.Promise.map @ commons.bundle.js:3
invokeEach @ commons.bundle.js:3
doWork @ commons.bundle.js:3
invoke @ vendors.bundle.dll.js:435
__prep__ @ commons.bundle.js:3
invoke @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:257
forEach @ vendors.bundle.dll.js:435
resolveLocals @ vendors.bundle.dll.js:257
processQueue @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:435
$digest @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:435
(anonymous) @ vendors.bundle.dll.js:435
forEach @ vendors.bundle.dll.js:435
fireStateOrUrlChange @ vendors.bundle.dll.js:435
cacheStateAndFireUrlChange @ vendors.bundle.dll.js:435
dispatch @ vendors.bundle.dll.js:429
elemData.handle @ vendors.bundle.dll.js:429
Show 36 more frames`
**Provide logs and/or server output (if relevant):**

**Any additional context:**
Using nginx as proxy_pass",Can you share the proxy pass configuration?  Is kibana configured route under a subfolder?,"**Temporary workaround:**
Changing the default index pattern from `apm-*` to something else fixes the issue"
elastic/kibana,https://github.com/elastic/kibana/issues/60390,elastic_kibana_issues_60390,"[Logs UI] Allow users to specify datasets in ML job configuration

:information_source: *This has been split out of #59005.*

## Summary
Today at ML job configuration, we allow users to specify index to choose from. With this feature, we will allow them to choose a specific dataset as well. This helps users to have granular control on running ML jobs which can be useful when users are trying to reserve ML capacity on the datasets that matter the most as well as filter out datasets not suitable for categorization.

## Mockup

![grafik](https://user-images.githubusercontent.com/973741/79851289-61278f80-83c5-11ea-8947-5ac5ef1f828d.png)

Please note that showing the warning indicator is not part of this issue and will be handled in #61900.","Could you please expand on what constitutes a ""dataset"" in this situation?
Is this something that could be achieved by overriding the query used by the job's datafeed?",Please note that showing the warning indicator is not part of this issue and will be handled in a [this](https://github.com/elastic/kibana/issues/61900) issue
moby/moby,https://github.com/moby/moby/issues/39773,moby_moby_issues_39773,"Remove old PR checks that have migrated to the Jenkinsfile

The moby PR checks are currently migrating from an old way of running Jenkins jobs with manual configuration on the Jenkins master to a `Jenkinsfile`-driven way that was added with PR #38565. Docker will still provide the compute resources and administration of the Jenkins infrastructure, but having the `Jenkinsfile` define the PR checks will allow the moby maintainers more control over optimizing the build jobs (#39651) and keeping code changes that affect build process in the same PR.

This also brings a migration from an old Jenkins master https://jenkins.dockerproject.org to the new Jenkins master https://ci.docker.com/public/job/moby/. The new Jenkins master is configured with a UI to help visualize the PR check steps:

![Screen Shot 2019-08-19 at 3 34 57 PM](https://user-images.githubusercontent.com/57640/63304208-1c2be600-c297-11e9-82c6-f83063397183.png)

And reporting of test results (#39675):
![Screen Shot 2019-08-19 at 3 37 38 PM](https://user-images.githubusercontent.com/57640/63304300-5bf2cd80-c297-11e9-9e05-42bf2dbb1af3.png)

As the new PR checks come online, driven by the new `Jenkinsfile`, the old PR checks will be removed:
 - [x] dco-signed
   - [x] enable alternative DCO bot: https://github.com/moby/moby/issues/39538
 - [x] experimental
 - [x] janky
 - [x] powerpc
 - [x] vendor
 - [x] windowsRS1
 - [x] windowsRS5-process
 - [x] z

![Screen Shot 2019-08-19 at 3 26 54 PM](https://user-images.githubusercontent.com/57640/63304063-96a83600-c296-11e9-9d3c-6b2d57390ba2.png)",can we keep the dco-signed for now? it also adds a label and a comment to help contributors,"vendor
 - [ ]"
moby/moby,https://github.com/moby/moby/issues/38650,moby_moby_issues_38650,"docker Midnight machine

```
[root@localhost ~]# uname -a
Linux localhost.localdomain 4.20.5-1.el7.elrepo.x86_64 #1 SMP Sat Jan 26 10:55:51 EST 2019 x86_64 x86_64 x86_64 GNU/Linux
```
```
[root@localhost ~]# docker version
Client:
 Version:           18.09.1
 API version:       1.39
 Go version:        go1.10.6
 Git commit:        4c52b90
 Built:             Wed Jan  9 19:35:01 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          18.09.1
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.6
  Git commit:       4c52b90
  Built:            Wed Jan  9 19:06:30 2019
  OS/Arch:          linux/amd64
  Experimental:     false
```
```
[root@localhost ~]# journalctl -u docker.service
Then prompt，Detailed log
[test.txt](https://github.com/moby/moby/files/2810574/test.txt)
```
```
cat /etc/sysctl.conf
vm.max_map_count=655360
vm.overcommit_memory=1
net.core.somaxconn= 1024
fs.file-max=3836960
net.ipv4.tcp_rmem=8192 8198308 88888888
net.ipv4.tcp_wmem=8192 8198308 88888888
net.core.somaxconn = 2048
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.neigh.default.gc_thresh1=4096
net.ipv4.neigh.default.gc_thresh2=6144
net.ipv4.neigh.default.gc_thresh3=8192
net.ipv4.ip_forward=1
```
```
cat /etc/security/limits.d/90-nproc.conf
# Default limit for number of user's processes to prevent
# accidental fork bombs.
# See rhbz #432903 for reasoning.

*          soft    nproc     unlimited
root       soft    nproc     unlimited
```
```
cat /etc/security/limits.conf 
# /etc/security/limits.conf
#
#This file sets the resource limits for the users logged in via PAM.
#It does not affect resource limits of the system services.
#Also note that configuration files in /etc/security/limits.d directory,
#which are read in alphabetical order, override the settings in this
#file in case the domain is the same or more specific.
#That means for example that setting a limit for wildcard domain here
#can be overriden with a wildcard setting in a config file in the
#subdirectory, but a user specific setting here can be overriden only
#with a user specific setting in the subdirectory.
#
#Each line describes a limit for a user in the form:
#
#<domain>        <type>  <item>  <value>
#
#Where:
#<domain> can be:
#        - a user name
#        - a group name, with @group syntax
#        - the wildcard *, for default entry
#        - the wildcard %, can be also used with %group syntax,
#                 for maxlogin limit
#
#<type> can have the two values:
#        - ""soft"" for enforcing the soft limits
#        - ""hard"" for enforcing hard limits
#
#<item> can be one of the following:
#        - core - limits the core file size (KB)
#        - data - max data size (KB)
#        - fsize - maximum filesize (KB)
#        - memlock - max locked-in-memory address space (KB)
#        - nofile - max number of open file descriptors
#        - rss - max resident set size (KB)
#        - stack - max stack size (KB)
#        - cpu - max CPU time (MIN)
#        - nproc - max number of processes
#        - as - address space limit (KB)
#        - maxlogins - max number of logins for this user
#        - maxsyslogins - max number of logins on the system
#        - priority - the priority to run user process with
#        - locks - max number of file locks the user can hold
#        - sigpending - max number of pending signals
#        - msgqueue - max memory used by POSIX message queues (bytes)
#        - nice - max nice priority allowed to raise to values: [-20, 19]
#        - rtprio - max realtime priority
#
#<domain>      <type>  <item>         <value>
#

#*               soft    core            0
#*               hard    rss             10000
#@student        hard    nproc           20
#@faculty        soft    nproc           20
#@faculty        hard    nproc           50
#ftp             hard    nproc           0
#@student        -       maxlogins       4

*                soft    nofile          196605
*                hard    nofile          196605
*                soft    nproc           196605
*                hard    nproc           196605
```
[root@localhost home]# free -m
total used free shared buff/cache available
Mem: 64383 6006 53796 150 4580 57160
Swap: 98299 0 98299",What's the issue?,"[root@localhost home]# free -m
total used free shared buff/cache available
Mem: 64383 6006 53796 150 4580 57160
Swap: 98299 0 98299"
moby/moby,https://github.com/moby/moby/issues/40399,moby_moby_issues_40399,"OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused ""process_linux.go:101: executing setns process caused \""exit status 1\"""": unknown

---------------------------------------------------
BUG REPORT INFORMATION
---------------------------------------------------
**Description**

Service worked OK and suddenly turned Unhealthy 

```
FailingStreak 3
2
End 2020-01-21T15:06:18.1439409Z
ExitCode -1
Output OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused ""process_linux.go:101: executing setns process caused \""exit status 1\"""": unknown
Start 2020-01-21T15:06:18.007996483Z
3
End 2020-01-21T15:06:28.33604261Z
ExitCode -1
Output OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused ""process_linux.go:101: executing setns process caused \""exit status 1\"""": unknown
Start 2020-01-21T15:06:28.157518263Z
4
End 2020-01-21T15:06:38.703726179Z
ExitCode -1
Output OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused ""read init-p: connection reset by peer"": unknown
Start 2020-01-21T15:06:38.350317727Z
```

**Steps to reproduce the issue:**
don't know yet what causes: 

```
Output OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused ""read init-p: connection reset by peer"": unknown
``` 

**Additional information you deem important (e.g. issue happens only occasionally):**

**Output of `docker version`:**

```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea838
 Built:             Wed Nov 13 07:29:52 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.1
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.5
  Git commit:       74b1e89
  Built:            Thu Jul 25 21:19:41 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker info`:**

```
Client:
 Debug Mode: false

Server:
 Containers: 33
  Running: 21
  Paused: 0
  Stopped: 12
 Images: 16
 Server Version: 19.03.1
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: awslogs
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: active
  NodeID: zuvtge6vhow5s6fdi84m52bgh
  Is Manager: true
  ClusterID: f8x0rci4oq57u8elufoqnsv9m
  Managers: 1
  Nodes: 1
  Default Address Pool: 10.0.0.0/8  
  SubnetSize: 24
  Data Path Port: 4789
  Orchestration:
   Task History Retention Limit: 5
  Raft:
   Snapshot Interval: 10000
   Number of Old Snapshots to Retain: 0
   Heartbeat Tick: 1
   Election Tick: 10
  Dispatcher:
   Heartbeat Period: 5 seconds
  CA Configuration:
   Expiry Duration: 3 months
   Force Rotate: 0
  Autolock Managers: false
  Root Rotation In Progress: false
  Node Address: 172.0.11.33
  Manager Addresses:
   172.0.11.33:2377
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339
 runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657
 init version: fec3683
 Security Options:
  apparmor
  seccomp
   Profile: default
 Kernel Version: 4.15.0-1057-aws
 Operating System: Ubuntu 18.04.2 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: 4
 Total Memory: 15.66GiB
 Name: devnode1
 ID: JQGY:G3FF:GLYN:23JZ:5GEI:76GY:HULG:YH4I:ZOG2:LVXD:7AWM:P2NM
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Live Restore Enabled: false

WARNING: API is accessible on http://0.0.0.0:2376 without encryption.
         Access to the remote API is equivalent to root access on the host. Refer
         to the 'Docker daemon attack surface' section in the documentation for
         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface
WARNING: No swap limit support
```

**Additional environment details (AWS, VirtualBox, physical, etc.):**
Hosted on AWS, EC2 instance
Docker Swarm 1-node cluster, overlay network
Distributor ID:	Ubuntu
Description:	Ubuntu 18.04.2 LTS
Release:	18.04
Codename:	bionic

CPU and RAM, Disk were not overloaded
inodes OK
![image](https://user-images.githubusercontent.com/4895059/72891545-227a2e80-3d1d-11ea-872d-2b879dcb2aa6.png)


looking forward to your suggestions about what may cause an issue!
Thanks in advance",Do you have a memory limit applied to the container?,"```
```


``

``"
moby/moby,https://github.com/moby/moby/issues/40515,moby_moby_issues_40515,"iptables --uid-owner | --gid-owner filtering not working with embedded DNS

**Edit:**  
**<TL;DR>**
DNS requests are traversed directly to the embedded DNS 127.0.0.11 and bypass iptables.  
The embedded DNS then forwards the DNS requests through the containers iptables as uid/gid 0, ignoring uid and gid from the initial request.

**Implications:**
Can't filter DNS requests, which can lead to DNS bleeding or resolving-problems in lots of vpn-client projects.

**Suggested fix:**
Filter DNS requests to `127.0.0.11` through iptables and let the embedded dns bypass iptables

**Workaround:**
Manually change the `/etc/resolv.conf` to use custom dns servers. Unfortunately the --dns option only changes the DNS servers used by the embedded DNS. Not very good practice to change the resolv.conf inside the container and won't work with read-only containers.
When using custom networks, docker does not set hostnames of other network containers in the _/etc/hosts_ file anymore. So when the embedded DNS is overwritten in the _resolv.conf_, resolving hostnames of other containers in the network is broken!

</BR></BR></BR>
**Original Post:**
I created a small docker-compose project to reproduce this behavior.
The container with `network_mode: bridge` is able to resolve the domain, but the other one with the custom network will result in a ***bad address*** error.
Is this by design or a bug?<br />
Additional Info: The packets are accepted and flagged as --gid-owner root in the custom network.

**docker-compose.yml**

```yaml
version: ""3.4""

x-iptables:
  &default-iptables
  image: vimagick/iptables
  cap_add:
    - NET_ADMIN
  command: >
      sh -c '
        adduser -D admin
        iptables -P OUTPUT DROP &&
        iptables -A OUTPUT -p udp -m owner --gid-owner admin -j ACCEPT &&
        iptables -A OUTPUT -p udp -m owner --uid-owner admin -j ACCEPT &&
        echo options timeout:1>>/etc/resolv.conf &&
        su -c ""ping google.com"" - admin
      '

services:
  iptables_bridge: 
    << : *default-iptables
    network_mode: bridge
    
  iptables_custom:
    << : *default-iptables
    networks:
      - custom

networks:
  custom:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_ip_masquerade: ""true""
      com.docker.network.bridge.enable_icc: ""true""
```
**docker network inspect bridge**

```json
[
    {
        ""Name"": ""bridge"",
        ""Id"": ""487d2b1d5e1e514aded43adee8678125b1b9fb340fcf6f4e643198d0ea94f45d"",
        ""Created"": ""2020-02-13T13:05:41.695016429+01:00"",
        ""Scope"": ""local"",
        ""Driver"": ""bridge"",
        ""EnableIPv6"": false,
        ""IPAM"": {
            ""Driver"": ""default"",
            ""Options"": null,
            ""Config"": [
                {
                    ""Subnet"": ""172.25.0.0/16"",
                    ""Gateway"": ""172.25.0.1""
                }
            ]
        },
        ""Internal"": false,
        ""Attachable"": false,
        ""Ingress"": false,
        ""ConfigFrom"": {
            ""Network"": """"
        },
        ""ConfigOnly"": false,
        ""Containers"": {},
        ""Options"": {
            ""com.docker.network.bridge.default_bridge"": ""true"",
            ""com.docker.network.bridge.enable_icc"": ""true"",
            ""com.docker.network.bridge.enable_ip_masquerade"": ""true"",
            ""com.docker.network.bridge.host_binding_ipv4"": ""0.0.0.0"",
            ""com.docker.network.bridge.name"": ""docker0"",
            ""com.docker.network.driver.mtu"": ""1500""
        },
        ""Labels"": {}
    }
]
```
**docker network inspect net_custom**

```json
[
    {
        ""Name"": ""net_custom"",
        ""Id"": ""d898866753a16e360d440e4fcacdf8c92eb12f1a443bcc86a3f2be240b853400"",
        ""Created"": ""2020-02-13T14:43:17.744258173+01:00"",
        ""Scope"": ""local"",
        ""Driver"": ""bridge"",
        ""EnableIPv6"": false,
        ""IPAM"": {
            ""Driver"": ""default"",
            ""Options"": null,
            ""Config"": [
                {
                    ""Subnet"": ""172.19.0.0/16"",
                    ""Gateway"": ""172.19.0.1""
                }
            ]
        },
        ""Internal"": false,
        ""Attachable"": true,
        ""Ingress"": false,
        ""ConfigFrom"": {
            ""Network"": """"
        },
        ""ConfigOnly"": false,
        ""Containers"": {},
        ""Options"": {
            ""com.docker.network.bridge.enable_icc"": ""true"",
            ""com.docker.network.bridge.enable_ip_masquerade"": ""true""
        },
        ""Labels"": {
            ""com.docker.compose.network"": ""custom"",
            ""com.docker.compose.project"": ""net"",
            ""com.docker.compose.version"": ""1.25.4""
        }
    }
]
```

**System Info:**
```
docker --version
Docker version 19.03.5, build 633a0ea838

docker-compose --version
docker-compose version 1.25.4, build 8d51620a

uname -a
Linux v22019058359789001 4.19.0-6-amd64 #1 SMP Debian 4.19.67-2+deb10u2 (2019-11-11) x86_64 GNU/Linux

docker info
Client:
 Debug Mode: false

Server:
 Containers: 30
  Running: 3
  Paused: 0
  Stopped: 27
 Images: 100
 Server Version: 19.03.5
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339
 runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657
 init version: fec3683
 Security Options:
  apparmor
  seccomp
   Profile: default
 Kernel Version: 4.19.0-6-amd64
 Operating System: Debian GNU/Linux 10 (buster)
 OSType: linux
 Architecture: x86_64
 CPUs: 1
 Total Memory: 1.948GiB
 Name: v22019058359789001
 ID: QWPC:PGAF:5G72:QJGW:IIW7:3RV3:ESMO:ZYLX:UHZP:U372:RIGW:XG5Q
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Live Restore Enabled: false

WARNING: No swap limit support
```",Can you post output of `docker version` and `docker info` as well?,"**System Info:**
```
docker --version
Docker version 19.03.5, build 633a0ea838

docker-compose --version
docker-compose version 1.25.4, build 8d51620a

uname -a
Linux v22019058359789001 4.19.0-6-amd64 #1 SMP Debian 4.19.67-2+deb10u2 (2019-11-11) x86_64 GNU/Linux

docker info
Client:
 Debug Mode: false

Server:
 Containers: 30
  Running: 3
  Paused: 0
  Stopped: 27
 Images: 100
 Server Version: 19.03.5
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339
 runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657
 init version: fec3683
 Security Options:
  apparmor
  seccomp
   Profile: default
 Kernel Version: 4.19.0-6-amd64
 Operating System: Debian GNU/Linux 10 (buster)
 OSType: linux
 Architecture: x86_64
 CPUs: 1
 Total Memory: 1.948GiB
 Name: v22019058359789001
 ID: QWPC:PGAF:5G72:QJGW:IIW7:3RV3:ESMO:ZYLX:UHZP:U372:RIGW:XG5Q
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Registry: https://index.docker.io/v1/
 Labels:
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Live Restore Enabled: false

WARNING: No swap limit support
```"
Perl/perl5,https://github.com/Perl/perl5/issues/17535,Perl_perl5_issues_17535,"NetBSD and ""warning: cast between incompatible function types""

**Description**
I'm building Perl 5.30.1 from the release tarball on NetBSD 8.1. The prototype for the signal handler on NetBSD is different than what Perl expects. Compiling after configuration results in:

```
gcc -c -DPERL_CORE -g2 -O2 -march=native -fPIC -pthread -fwrapv -fno-strict-aliasing -pipe -fstack-protector-strong -I/usr/local/include -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64 -O2 -Wall -Werror=declaration-after-statement -Werror=pointer-arith -Wextra -Wc++-compat -Wwrite-strings util.c
util.c: In function 'Perl_rsignal':
util.c:2698:22: warning: cast between incompatible function types from 'Sighandler_t' {aka 'void (*)(int,  struct <anonymous> *, void *)'} to 'void (*)(int)' [-Wcast-function-type]
     act.sa_handler = (void(*)(int))handler;
                      ^
util.c:2706:40: warning: cast between incompatible function types from 'void (*)(int)' to 'void (*)(int,  siginfo_t *, void *)' {aka 'void (*)(int,  struct <anonymous> *, void *)'} [-Wcast-function-type]
     if (signo == SIGCHLD && handler == (Sighandler_t) SIG_IGN)
...
```

**Steps to Reproduce**
Test a build on NetBSD 8.1.

**Expected behavior**
A clean compile is expected. Typically you do something like this on Apple or the BSDs:

```
#if defined(__APPLE__) || defined(__FreeBSD__) || defined(__NetBSD__) || \
      defined(__OpenBSD__) || defined(__DragonFly__)
# define SIGFUNCTION sig_t
#else
# define SIGFUNCTION sighandler_t
#endif

static SIGFUNCTION s_sigint;
static SIGFUNCTION s_sighup;
static SIGFUNCTION s_sigquit;
...

void install_signall_handlers()
{
    s_sigint = signal(SIGINT, signal_callback);
    s_sighup = signal(SIGHUP, signal_callback);
    s_sigquit = signal(SIGQUIT, signal_callback);
}
```

**Perl configuration**
```
$ PERL5LIB=./lib ./perl -V
Summary of my perl5 (revision 5 version 30 subversion 1) configuration:
   
  Platform:
    osname=netbsd
    osvers=8.1
    archname=amd64-netbsd
    uname='netbsd localhost 8.1 netbsd 8.1 (generic) #0: fri may 31 08:43:59 utc 2019 mkrepro@mkrepro.netbsd.org:usrsrcsysarchamd64compilegeneric amd64 '
    config_args='-des -Dprefix=/usr/local -Dlibdir=/usr/local/lib -Dpkgconfig=/usr/local/lib/pkgconfig -Dcc=gcc -Dcxx=g++ -Acppflags=-I/usr/local/include -DNDEBUG -Accflags=-g2 -O2 -fPIC -pthread -Acxxflags=-g2 -O2 -fPIC -pthread -Aldflags=-L/usr/local/lib -Wl,-R,'XXORIGIN/../lib' -Wl,-R,/usr/local/lib -Wl,--enable-new-dtags -Dextras=Text::Template Test::More'
    hint=recommended
    useposix=true
    d_sigaction=define
    useithreads=undef
    usemultiplicity=undef
    use64bitint=define
    use64bitall=define
    uselongdouble=undef
    usemymalloc=n
    default_inc_excludes_dot=define
    bincompat5005=undef
  Compiler:
    cc='gcc'
    ccflags ='-g2 -O2 -fPIC -pthread -fwrapv -fno-strict-aliasing -pipe -fstack-protector-strong -I/usr/pkg/include -I/usr/local/include -D_FORTIFY_SOURCE=2'
    optimize='-O'
    cppflags='-I/usr/local/include -DNDEBUG -g2 -O2 -fPIC -pthread -fwrapv -fno-strict-aliasing -pipe -fstack-protector-strong -I/usr/pkg/include -I/usr/local/include'
    ccversion=''
    gccversion='5.5.0'
    gccosandvers=''
    intsize=4
    longsize=8
    ptrsize=8
    doublesize=8
    byteorder=12345678
    doublekind=3
    d_longlong=define
    longlongsize=8
    d_longdbl=define
    longdblsize=16
    longdblkind=3
    ivtype='long'
    ivsize=8
    nvtype='double'
    nvsize=8
    Off_t='off_t'
    lseeksize=8
    alignbytes=8
    prototype=define
  Linker and Libraries:
    ld='gcc'
    ldflags =' -Wl,-rpath,/usr/pkg/lib -Wl,-rpath,/usr/local/lib -L/usr/local/lib -Wl,-R,XXORIGIN/../lib -Wl,-R,/usr/local/lib -Wl,--enable-new-dtags -fstack-protector-strong -L/usr/pkg/lib'
    libpth=/usr/local/lib /usr/include/gcc-5 /usr/lib /usr/pkg/lib /lib
    libs=-lpthread -ldb -lm -lcrypt -lutil -lc -lposix
    perllibs=-lpthread -lm -lcrypt -lutil -lc -lposix
    libc=/lib/libc.so
    so=so
    useshrplib=false
    libperl=libperl.a
    gnulibc_version=''
  Dynamic Linking:
    dlsrc=dl_dlopen.xs
    dlext=so
    d_dlsymun=undef
    ccdlflags='-Wl,-E '
    cccdlflags='-DPIC -fPIC '
    lddlflags='-shared  -L/usr/local/lib -Wl,-R,XXORIGIN/../lib -Wl,-R,/usr/local/lib -L/usr/pkg/lib -fstack-protector-strong'

Characteristics of this binary (from libperl): 
  Compile-time options:
    HAS_TIMES
    PERLIO_LAYERS
    PERL_COPY_ON_WRITE
    PERL_DONT_CREATE_GVSV
    PERL_MALLOC_WRAP
    PERL_OP_PARENT
    PERL_PRESERVE_IVUV
    USE_64_BIT_ALL
    USE_64_BIT_INT
    USE_LARGE_FILES
    USE_LOCALE
    USE_LOCALE_COLLATE
    USE_LOCALE_CTYPE
    USE_LOCALE_NUMERIC
    USE_LOCALE_TIME
    USE_PERLIO
    USE_PERL_ATOF
  Built under netbsd
  Compiled at Feb  7 2020 01:18:37
  %ENV:
    PERL5LIB=""./lib""
  @INC:
    ./lib
    /usr/local/lib/perl5/site_perl/5.30.1/amd64-netbsd
    /usr/local/lib/perl5/site_perl/5.30.1
    /usr/local/lib/perl5/5.30.1/amd64-netbsd
    /usr/local/lib/perl5/5.30.1
```","Can you supply the `perl -V` information that you used on NetBSD?

Thank you very much.
Jim Keenan","1 (generic) #0: fri may 31 0pkg/include -I/usr/Wl,-rpath,/usr/pkg/lib -Wl,-rpath,/usr/local/lib - -L/usr/pkg/lib0./"
laravel/framework,https://github.com/laravel/framework/issues/28202,laravel_framework_issues_28202,"[5.8] Can't resolve instance from service container

- Laravel Version: 5.8.11
- PHP Version: 7.1.26 (Homestead) - but also tested with 7.2 with same result

Since updating from 5.7 to 5.8, I can't resolve an instance anymore. It returns a string and I get `Trying to get property of non-object`.


### Steps To Reproduce:

I bind the instance in a Middleware with:

```
        $globals = new Globals();
        app()->instance('App\Helpers\Globals', $globals);
        $globals->brows_browser = Agent::browser();
```

when trying to resolve it later (for example in web.php) with:

```
$browser = resolve('App\Helpers\Globals')->brows_browser;
```

I get an error exception `Trying to get property of non-object`. $browser is a string ""Helpers\Globals"" and not an object. Was working fine in all Laravel versions before.

```
namespace App\Helpers;

class Globals
{
    public $brows_browser;
    public $brows_device;
    public $brows_platform;
    public $brows_version;

}
```",Can you link to the laracasts issue?,.26 (Homestead) - but also tested with 7.2 with same result
laravel/framework,https://github.com/laravel/framework/issues/27477,laravel_framework_issues_27477,"Routing: Root Level Property Inside Domain Group Ignored (thrown to bottom of the list)

- Laravel Version: 5.7.25 (also affects 5.5)
- PHP Version: Anything ^7.1
- Database Driver & Version: Not Applicable

### Description:

When working with Laravel Routing, I am trying to do the following route (which seems perfectly valid). I am trying to throw a SPA on a subdomain, hence why I need a catch-all on that domain.

```php
Auth::routes();
Route::group(['domain' => 'console.graphictrak.test'], function() {
    Route::get('/{any}', 'SpaController@index')->where('any', '.*');
});
Route::get('/', function () {
    return view('welcome');
});
```

In practice, the Laravel Routes are shown as this

```
+--------------------------+----------+-----------------------------------------+-----------------------------------+---------------------------------------------------------------------------+--------------+
| Domain                   | Method   | URI                                     | Name                              | Action                                                                    | Middleware   |
+--------------------------+----------+-----------------------------------------+-----------------------------------+---------------------------------------------------------------------------+--------------+
|                          | GET|HEAD | /                                       |                                   | Closure                                                                   | web          |
|                          | GET|HEAD | api/shows/12345/datasources             |                                   | Closure                                                                   | api          |
|                          | GET|HEAD | api/user                                |                                   | Closure                                                                   | api,auth:api |
|                          | POST     | login                                   |                                   | App\Http\Controllers\Auth\LoginController@login                           | web,guest    |
|                          | GET|HEAD | login                                   | login                             | App\Http\Controllers\Auth\LoginController@showLoginForm                   | web,guest    |
|                          | POST     | logout                                  | logout                            | App\Http\Controllers\Auth\LoginController@logout                          | web          |
|                          | POST     | oauth/authorize                         | passport.authorizations.approve   | Laravel\Passport\Http\Controllers\ApproveAuthorizationController@approve  | web,auth     |
|                          | GET|HEAD | oauth/authorize                         | passport.authorizations.authorize | Laravel\Passport\Http\Controllers\AuthorizationController@authorize       | web,auth     |
|                          | DELETE   | oauth/authorize                         | passport.authorizations.deny      | Laravel\Passport\Http\Controllers\DenyAuthorizationController@deny        | web,auth     |
|                          | POST     | oauth/clients                           | passport.clients.store            | Laravel\Passport\Http\Controllers\ClientController@store                  | web,auth     |
|                          | GET|HEAD | oauth/clients                           | passport.clients.index            | Laravel\Passport\Http\Controllers\ClientController@forUser                | web,auth     |
|                          | PUT      | oauth/clients/{client_id}               | passport.clients.update           | Laravel\Passport\Http\Controllers\ClientController@update                 | web,auth     |
|                          | DELETE   | oauth/clients/{client_id}               | passport.clients.destroy          | Laravel\Passport\Http\Controllers\ClientController@destroy                | web,auth     |
|                          | GET|HEAD | oauth/personal-access-tokens            | passport.personal.tokens.index    | Laravel\Passport\Http\Controllers\PersonalAccessTokenController@forUser   | web,auth     |
|                          | POST     | oauth/personal-access-tokens            | passport.personal.tokens.store    | Laravel\Passport\Http\Controllers\PersonalAccessTokenController@store     | web,auth     |
|                          | DELETE   | oauth/personal-access-tokens/{token_id} | passport.personal.tokens.destroy  | Laravel\Passport\Http\Controllers\PersonalAccessTokenController@destroy   | web,auth     |
|                          | GET|HEAD | oauth/scopes                            | passport.scopes.index             | Laravel\Passport\Http\Controllers\ScopeController@all                     | web,auth     |
|                          | POST     | oauth/token                             | passport.token                    | Laravel\Passport\Http\Controllers\AccessTokenController@issueToken        | throttle     |
|                          | POST     | oauth/token/refresh                     | passport.token.refresh            | Laravel\Passport\Http\Controllers\TransientTokenController@refresh        | web,auth     |
|                          | GET|HEAD | oauth/tokens                            | passport.tokens.index             | Laravel\Passport\Http\Controllers\AuthorizedAccessTokenController@forUser | web,auth     |
|                          | DELETE   | oauth/tokens/{token_id}                 | passport.tokens.destroy           | Laravel\Passport\Http\Controllers\AuthorizedAccessTokenController@destroy | web,auth     |
|                          | POST     | password/email                          | password.email                    | App\Http\Controllers\Auth\ForgotPasswordController@sendResetLinkEmail     | web,guest    |
|                          | GET|HEAD | password/reset                          | password.request                  | App\Http\Controllers\Auth\ForgotPasswordController@showLinkRequestForm    | web,guest    |
|                          | POST     | password/reset                          | password.update                   | App\Http\Controllers\Auth\ResetPasswordController@reset                   | web,guest    |
|                          | GET|HEAD | password/reset/{token}                  | password.reset                    | App\Http\Controllers\Auth\ResetPasswordController@showResetForm           | web,guest    |
|                          | GET|HEAD | register                                | register                          | App\Http\Controllers\Auth\RegisterController@showRegistrationForm         | web,guest    |
|                          | POST     | register                                |                                   | App\Http\Controllers\Auth\RegisterController@register                     | web,guest    |
| console.graphictrak.test | GET|HEAD | {any}                                   |                                   | App\Http\Controllers\SpaController@index                                  | web,auth     |
+--------------------------+----------+-----------------------------------------+-----------------------------------+---------------------------------------------------------------------------+--------------+
```
Notice that the domain route with the property is at the bottom and therefore is being overridden/ignored thanks to a non-propertied nor domain specified index route.

The end result is `/` without a domain is being called when I am trying to call the index of the subdomain.

EDIT: Updated with better example of production code.",Can you post your entire routes file?,"Auth::routes();
 --------------------------------                                --------------------------------          |
|                          | POST     | login                                   |                                   | App\Http\Controllers\Auth\LoginController@login                           | web,guest   Auth\LoginController@logout                          | web          |
|                          | POST     | oauth/authorize                         | passport.authorizations.approve   | Laravel\Passport\s\ApproveAuthorizationControllerlientCPersonals\ScopeControllerLink    | web,guest    |
|                          | POST     | password/reset                          | password.update                   | App\Http\Controllers\Auth\ResetPasswordController@reset           setForm           | web,uest    |
|                          | GET|HEAD | register                                | register                          | App\Http\Controllers\Auth\RegisterController@showReg         --------------------------------

EDIT: Updated with better example of production code."
laravel/framework,https://github.com/laravel/framework/issues/28569,laravel_framework_issues_28569,"[5.8] Query builder Increment/Decrement method when using table alias throws unknown column error for timestamps

- Laravel Version: 5.8.14
- PHP Version: 7.1.18
- Database Driver & Version: MySQL 5.7.17 

### Description:

When using the query builder increment or decrement method, if you use table aliases then the updated_at timestamp is prefixed with the fully qualified table name and not the alias and as such throws unknown column error. 

### Steps To Reproduce:

Define a query using table alias  e.g.

    return  $this->model->from('order_item_product as t1')
            ->join(DB::Raw('(
               select t1.product_id as product_id
	                , MIN(t1.created_at) as created_at
		            , MIN(t1.order_item_id) as order_item_id
		         FROM order_item_product t1
          INNER JOIN order_items t2 on t1.order_item_id = t2.id
          INNER JOIN orders t3 on t2.order_id = t3.id
          INNER JOIN recruiters t4 on t3.recruiter_id = t4.id
               WHERE t1.product_id = ?
                 AND t1.available > 0
                 AND TIMESTAMPADD(DAY,t1.valid_days,t1.created_at) > now()
	             AND t4.company_id = ?
            GROUP BY t1.product_id) AS t2'), function($join)
            {
                $join->on('t1.order_item_id', '=', 't2.order_item_id');
                $join->on('t1.created_at', '=', 't2.created_at');

            })
            ->setBindings([$productId, $companyId])
            ->decrement('t1.available', 1, ['updated_at' => DB::Raw('now()')]);

Run and execute query, check query log to see what the query was executed as and you will note the `updated_at` column has ended up being prefixed with the table name (in the above example it's ended up as `order_item_product.updated_at` and as such throws unknown column error because the table was aliased in the query as `t1`.

If you omit the updated_at column from the query e.g. `->decrement('t1.available', 1);` it still gets added to the query as `order_item_product.updated_at` and messes up the order of bindings.

If you change the above example query by prefixing the updated_at column with the table alias e.g. ` ['t1.updated_at' => DB::Raw('now()')]` ,  the same thing happens i.e. an additional  `order_item_product.updated_at` timestamp gets added to the query and with the bindings messed up and unknown column error.

A similar effect occurs when using queryscopes where multiple tables are joined. In this scenario no table prefix is applied and if there's a column that has the same name in different tables you get the same ambiguous column error.  

For example if I have the following query scope in my Article model and use it with a query join to another table that also has a `status_id` field I get the ambiguous column error for status_id:

     public function scopePublished($query)
     {
         return $query->where('start_at', '<=', Carbon::now())
              ->where('end_at', '>=', Carbon::now())
              ->where('status_id', '=', 4);
     }

     Article::join('authors', 'authors.id', '=', 'articles.author_id')
                ->Published()->select('articles.*', 'authors.phone')->get();",What's the query and the error?,"- Laravel Version: 5.8.14
- PRun and execute query, check query log to see what the query was executed as and you will note the `updated_at` column has ended up being prefixed with the table name (in the above example it's ended up as `order_item_product.updated_at` and as such throws unknown column error.

you omit the updated_at column from the query e.g. `->decrement('t1.available', 1);` it still gets added to the query as `order_item_product.updated_at` and messes up the order of bindings.

updated_at column with the  the same thing happens i.e. an additional  `order_item_product.updated_at` timestamp gets added to the query and with"
laravel/framework,https://github.com/laravel/framework/issues/25041,laravel_framework_issues_25041,"""app()->makeWith(..."" does not work with ""app()->instance(...""

- Laravel Version: 5.6
- PHP Version: 7.1

### Description:

function `app()->makeWith(... `
does not work with `app()->instance(...`

It should return prepared instance, but it creates a new object all the time.

It makes `Mocking` impossible. `Unit-testing` concept is not working.",How would Laravel know that the instance you've provided earlier is built using those same parameters?,`````` `Unit-testing` concept is not working.
laravel/framework,https://github.com/laravel/framework/issues/25592,laravel_framework_issues_25592,"Can't comment a script tag in blade

- Laravel Version: 5.5
- PHP Version: 7.1
- Database Driver & Version: MariaDB  

### Description:

I added a partial in my <head> tag in app.blade.php 
That partial has a simple <script> tag with some silly code in it

I decide to comment it with the blade comment {{--<script>  </script--}}

It does not only hide the code , it adds the full script code with blade comment in the <body> tag

### Steps To Reproduce:

1. Create a partial with a <script> tag in it and its </script> end tag and code in it 
2. add an include in the <head> tag
3. blade {{-- comment the entire script code with tags in your partial and see what happens , the code is still read

### EDIT

Try to add that script in your partial 

```
{{-- <script>
window.trans = <?php

// copy all translations from /resources/lang/CURRENT_LOCALE/* to global JS variable

$lang_files = File::files(resource_path() . '/lang/' . LaravelLocalization::getCurrentLocale());
$trans = [];
foreach ($lang_files as $f) {
    $filename = pathinfo($f)['filename'];
    $trans[$filename] = trans($filename);
}
echo json_encode($trans);
?>;
</script> --}}
```


Thanks for your help, I am perhaps making a huge mistake, I'm a Laravel amateur and kind of beginner",Could you share the partial?,"### EDIT

Try to add that script in your partial 

```
{{-- <script>
window.trans = <?php

// copy all translations from /resources/lang/CURRENT_LOCALE/* to global JS variable

$lang_files = File::files(resource_path() . '/lang/' . LaravelLocalization::getCurrentLocale());
$trans = [];
foreach ($lang_files as $f) {
    $filename = pathinfo($f)['filename'];
    $trans[$filename] = trans($filename);
}
echo json_encode($trans);
?>;
</script> --}}
```"
laravel/framework,https://github.com/laravel/framework/issues/31172,laravel_framework_issues_31172,"Use Model query make memory  overflow

- Laravel Version: v6.9.0
- PHP Version: 7.4.0
- Database Driver & Version:8.0

- TELESCOPE_ENABLED=false （try close this）

### Description:
```
Artisan::command('test:test', function () {
    for ($i = 0; $i < 10000; $i++) {
            $user =  \App\Models\User::query()->first();
            unset($user);
            if ($i % 1000 == 0) {
                var_dump(memory_get_usage() / 1024 / 1024);
            }
        }
});
```
use this code in routes/console.php
### Steps To Reproduce:
run : php artisan test:test

result:
![image](https://user-images.githubusercontent.com/8857514/72707011-6abd1380-3b9a-11ea-9224-72dbe0806c94.png)


###  The following code is ok.
```
Artisan::command('test:test', function () {
    for ($i = 0; $i < 10000; $i++) {
       $user =  \App\Models\User::query();
        if ($i % 1000 == 0) {
            var_dump(memory_get_usage() / 1024 / 1024);
        }
    }
});
```

### Result
![image](https://user-images.githubusercontent.com/8857514/72706615-6ba17580-3b99-11ea-8d20-0ed3ba76a64e.png)

### Expect the result
keep memory no growth

### Description
so  , why GC not work when i query anything？

memory Sustained growth in production , 

similar code make php memory exceed expectation.

my expectation is that memory stays constant.","What is the expected behavior?

Less than half a MB doesn't seem excessive for 1000 queries.","in production ,similar code make php memory exceed expectation。

My expectation is that memory stays constant。"
laravel/framework,https://github.com/laravel/framework/issues/26297,laravel_framework_issues_26297,"request->expectsJson() does not work correctly in old browser

- Laravel Version: 5.7.*
- PHP Version: 7.2.*
- Database Driver & Version:

### Description:
Ajax request to server (axios with header 'X-Requested-With': 'XMLHttpRequest')

$request->expectsJson() does not work correctly in Firefox 38 browser whereas $request->ajax() works correctly.

$request->expectsJson() return false
but $request->ajax() return true

whereas in more modern browsers both return true","What is correctly/not correctly?
What is the error message?","Ajax request to server (axios with header 'X-Requested-With': 'XMLHttpRequest')



$request->expectsJson() return false
but $request->ajax() return true

whereas in more modern browsers both return true"
laravel/framework,https://github.com/laravel/framework/issues/26309,laravel_framework_issues_26309,"BadMethodCallException: Method Illuminate\Validation\Validator::validateText does not exist.

Laravel Version: 5.7.*
PHP Version: 7.1.6
Database Driver & Version:

**Description:**

Hi ! I'm not sure if this is my mistake or an issue with laravel. I followed the tutorial on site to validate a simple form and I get `BadMethodCallException: Method Illuminate\Validation\Validator::validateText does not exist.` instead.

This is my controller. By default I start by invoking the `index()` method. Error occurs inside `_validate()`, at `if($ret -> fails())`
```
<?php

namespace App\Http\Controllers\Students\Auth;

use Illuminate\Http\Request;
use Illuminate\Support\Facades\Auth;
use Illuminate\Support\Facades\Hash;
use App\Http\Controllers\Controller;
use App\Students;
use Validator;

class Register extends Controller
{
	/*
	* Vars
	*/
	protected $guard = 'students';
	protected $provider = 'students';
	protected $success = '/students/dashboard';
	protected $fail = '/register#students';

	/*
	*	Some construct
	*/
	public function __construct()
	{
		if(Auth::guard($this -> guard) -> check())
			return redirect($this -> success);
	}

	/*
	*	Bind all methods
	*/
	public function index(Request $request)
	{
		$this -> _validate($request);

		$user = $this -> register($request -> input());

		Auth::guard($this -> guard) -> login($user);

		return redirect($this -> success);
	}

	/*
	*	Validate the form
	*/
	protected function _validate(Request $request)
	{
		$ret = Validator::make($request -> input(), [
			'name' => 'required|text|max:255',
			'email' => 'required|email|unique:' . $this -> provider,
			'password' => 'required|min:6',
		]);

		if($ret -> fails())
		 	return redirect() -> to($this -> fail)
								-> withInput()
								-> withErrors($ret);
	}

	/*
	*	Register the user
	*/
	protected function register(array $data)
	{
		return Students::create([
			'name' => $data['name'],
			'email' => $data['email'],
			'password' => Hash::make($data['password']),
		]);
	}

}
```","Where did you read about it?

I assume you want to use `'name' => 'required|string|max:255'`.","Laravel Version: 5.7.*
PHP Version: 7.1.6
Database Driver & Version:

**Description:**"
laravel/framework,https://github.com/laravel/framework/issues/27201,laravel_framework_issues_27201,"[5.7] Model Has breaking change

- Laravel Version: 5.7.19
- PHP Version: PHP 7.2.10-0ubuntu0.18.04.1 (cli) (built: Sep 13 2018 13:45:02) ( NTS )
- Database Driver & Version: MySQL 5.7 using PDO

### Description:

Breaking change in has functionality for related models. 

In short, `has()` no longer respects joins but it does for wheres in `newQuery`. This results in query errors for anything more complex.

```
 SQLSTATE[42P01]: Undefined table: 7 ERROR:  missing FROM-clause entry for table ""stustathist""
```

### Steps To Reproduce:

```php
     Student::with(['schedule'])->has('schedule')->get();
```

```php
<?php

// Student Model
class Student extends Model
{
    protected $primaryKey = 'studentid';

    public function schedule()
    {
            return $this->hasOne(Schedule::class, 'ssstupk', 'stupk');
    }
}
```

```php
<?php

// Schedule Model
class Schedule extends Model
{
    public $timestamps = false;

    protected $table = 'stuschedules';
    protected $primaryKey = 'sspk';

    public function newQuery()
    {
        return parent::newQuery()
            ->join('stustathist', 'stuschedules.sssthpk', '=', 'stustathist.sthpk')
            ->join('programs', 'stuschedules.sspgcode', '=', 'programs.pgcode')
            ->where('stustathist.sthdel', 0)
            ->select([
                'sspk',
                'ssstdate as schedule_start_date',
                'ssendate as schedule_end_date',
                'stuschedules.ssstupk',
                'stuschedules.sscertpk',
                'stuschedules.ssglvcode as grade_level',
                'stustathist.sthsscode',
                'stuschedules.ssrgcode as charter',
                'programs.program as location',
                'programs.pgcode',
                'sscertpk as teacher_id',
            ]);
    }
}
```

### Expected 

Truncated SQL query what is included is what is generated by the has.

5.6.x SQL generated:

```sql
where exists(
  select *
  from ""stuschedules""
    inner join ""stustathist"" on ""stuschedules"".""sssthpk"" = ""stustathist"".""sthpk""
    inner join ""programs"" on ""stuschedules"".""sspgcode"" = ""programs"".""pgcode""
  where ""sthdel"" = ? and ""students"".""stupk"" = ""stuschedules"".""ssstupk"" and ""sthdel"" = ? and ""ssendate"" :: date >= ?
)
```

### Actual

Truncated SQL query what is included is what is generated by the has.

5.7.x SQL generated:
```sql
where exists(
  select *
  from ""stuschedules""
  where ""sthdel"" = ? and ""students"".""stupk"" = ""stuschedules"".""ssstupk"" and ""sthdel"" = ? and ""ssendate"" :: date >= ?
)
```

### Solution

We hot patched a file just to see if this would solve the issue and it does. Changing `src/Illuminate/Database/Eloquent/Concerns/QueriesRelationships.php` in `has()`

Broken
```
$relation->getRelated()->newQueryWithoutRelationships(), $this        
```

Fixed
```
$relation->getRelated()->newQuery(), $this
```",Where does `students` come from?,"query what is included is what is  by the has.

5.6.x SQL generatedwhere
...and query what is included is what is  by the has.

5.7.x SQL generatedwhere
...and"
laravel/framework,https://github.com/laravel/framework/issues/27241,laravel_framework_issues_27241,"artisan queue:work timeouts however artisan queue:listen process job

- Laravel Version: 5.7.21
- PHP Version: 7.1.23
- Database Driver & Version: sqlanywhere 17.0.0
- OS: Ubuntu 18.04, Debian 9

Output of: `$pdo = \DB::connection('sasql_001')->getPdo();`
```
PDOConnection {#1213
  inTransaction: false
  attributes: {
    CASE: NATURAL
    ERRMODE: EXCEPTION
    PERSISTENT: false
    DRIVER_NAME: ""sqlanywhere""
    ORACLE_NULLS: NATURAL
    CLIENT_VERSION: ""17.0.0.""
    SERVER_VERSION: ""17.0.9.4838""
    STATEMENT_CLASS: array:2 [
      0 => ""Doctrine\DBAL\Driver\PDOStatement""
      1 => []
    ]
    DEFAULT_FETCH_MODE: BOTH
  }
}
```

### Description:
I made a connection where laravel connects to sqlanywhere database using https://github.com/josueneo/laravel5-sqlanywhere package. 

In config/database.php connections array i add:
```
'sasql_001' => [
    'driver' => 'sqlanywhere',
    'dsn' => 'sqlanywhere:',
    'username' => env('SA_USERNAME', 'root'),
    'password' => env('SA_PASSWORD', 'yourpassword'),
    'database' => env('SA_DB_NAME_001', 'sqladb'),
    'databasefile' => env('SA_DB_FILE_001', ''),
    'host' => env('SA_HOST', 'localhost'),
    'port' => env('SA_PORT', '2638'),
    'options' => 'ASTOP=no;CharSet=utf8',
],
```

For example when i go to uri `/delayed` app do some queries in sqlanywhere model and return data. Then i make Queueable Job to get the same data from model and if there is some data send email.

For development i make get uri `/dispatch` to execute: 
```
Route::get('dispatch', function () {
    dispatch(new App\Jobs\RemindMaintenance())
        ->onConnection('maintenance')
        ->onQueue('maintenance');
});
```

In .env file i change
```
CACHE_DRIVER=redis
SESSION_DRIVER=redis
QUEUE_CONNECTION=redis
BROADCAST_DRIVER=redis
```

In config/queue.php connections array i add
```
'maintenance' => [
    'driver' => 'redis',
    'connection' => 'default',
    'queue' => 'maintenance',
    'retry_after' => 14400,
],
```

### Steps To Reproduce:

I start:
`php artisan queue:listen maintenance --tries=1 --queue=maintenance --timeout=30`

And hit `http://myapp.test/dispatch`

I see in terminal that job is processed (everything works like should work)
```
[2019-01-20 23:31:12][107] Processing: App\Jobs\RemindMaintenance
[2019-01-20 23:35:07][107] Processed: App\Jobs\RemindMaintenance
```

Then i stop queue:listen and start 
`php artisan queue:work maintenance --tries=1 --queue=maintenance --timeout=30`

Hit one more time `http://myapp.test/dispatch`

And in terminal see that job is processing and failed
```
[2019-01-20 23:37:04][109] Processing: App\Jobs\RemindMaintenance
[2019-01-20 24:05:08][109] Failed: App\Jobs\RemindMaintenance
```

And whatever i set as job --timeout 30 sec or 12400 sec at the end it always timeouts
```
Illuminate\Queue\MaxAttemptsExceededException: App\Jobs\RemindMaintenance has been attempted too many times or run too long. The job may have previously timed out. in /var/www/vendor/laravel/framework/src/Illuminate/Queue/Worker.php:401
```

Strange is that, if I call only one simple query in the model, then `queue:work ...` finish succesfully Job.
```
[2019-01-20 23:54:12][111] Processing: App\Jobs\RemindMaintenance
[2019-01-20 23:55:47][111] Processed: App\Jobs\RemindMaintenance
```

Thanks for your help.",What does the error log say for the failed job?,"- OS: Ubuntu 18.04, Debian 9"
laravel/framework,https://github.com/laravel/framework/issues/29302,laravel_framework_issues_29302,"UrlGenerator error during installation

- Laravel Version: 5.8.29
- PHP Version: 7.2.19
- Database Driver & Version: mysql

### Description:
While installing a fresh new version on my testing environment ""composer install"" ends with a UrlGenerator error message. Any attempt to call cli commads ends with a UrlGenerator error message.

![laravel](https://user-images.githubusercontent.com/42065357/61912298-02b6a900-af3a-11e9-8f01-f0cee165b44f.png)


### Steps To Reproduce:
My composer.json is

```
{
    ""name"": ""laravel/laravel"",
    ""type"": ""project"",
    ""description"": ""The Laravel Framework."",
    ""keywords"": [
        ""framework"",
        ""laravel""
    ],
    ""license"": ""MIT"",
    ""require"": {
        ""php"": ""^7.1.3"",
        ""fideloper/proxy"": ""^4.0"",
        ""laravel/framework"": ""5.8.*"",
        ""laravel/tinker"": ""^1.0"",
        ""moontoast/math"": ""^1.0"",
        ""league/flysystem-aws-s3-v3"": ""~1.0"",
        ""league/flysystem-cached-adapter"": ""~1.0"",
        ""laravel/cashier"": ""^9.3.0""
    },
    ""require-dev"": {
        ""beyondcode/laravel-dump-server"": ""^1.0"",
        ""filp/whoops"": ""^2.0"",
        ""fzaninotto/faker"": ""^1.4"",
        ""mockery/mockery"": ""^1.0"",
        ""nunomaduro/collision"": ""^3.0"",
        ""phpunit/phpunit"": ""^7.5""
    },
    ""config"": {
        ""optimize-autoloader"": true,
        ""preferred-install"": ""dist"",
        ""sort-packages"": true
    },
    ""extra"": {
        ""laravel"": {
            ""dont-discover"": []
        }
    },
    ""autoload"": {
        ""psr-4"": {
            ""App\\"": ""app/""
        },
        ""classmap"": [
            ""database/seeds"",
            ""database/factories""
        ]
    },
    ""autoload-dev"": {
        ""psr-4"": {
            ""Tests\\"": ""tests/""
        }
    },
    ""minimum-stability"": ""dev"",
    ""prefer-stable"": true,
    ""scripts"": {
        ""post-autoload-dump"": [
            ""Illuminate\\Foundation\\ComposerScripts::postAutoloadDump"",
            ""@php artisan package:discover --ansi""
        ],
        ""post-root-package-install"": [
            ""@php -r \""file_exists('.env') || copy('.env.example', '.env');\""""
        ],
        ""post-create-project-cmd"": [
            ""@php artisan key:generate --ansi""
        ]
    }
}


```
Run cli command ""composer install""",What's in your composer.json file? The package.json file relates to your JavaScript side of things. The composer.json file will have the info about your PHP dependencies? :),"4"",
        ""mockery/mockery"": ""^psr-4"": {
            ""App\\"": ""app/""
        },
        ""classmap"": [
            ""database/seeds"",
            ""database/factories""
        ]
    },
    ""autoload-de"
laravel/framework,https://github.com/laravel/framework/issues/27904,laravel_framework_issues_27904,"ResourceCollection should not have collection static method.

- Laravel Version: 5.8.4
- PHP Version: 7.2.10
- Database Driver & Version: MySQL 5.7.23

### Description:

`\Illuminate\Http\Resources\Json\JsonResource::collection` static method should not be inherited to `\Illuminate\Http\Resources\Json\ResourceCollection`.

Because it is trying to create a new instance of `\Illuminate\Http\Resources\Json\AnonymousResourceCollection`, with `$resource` (that is the collection) and `static::class` (that is the class extended from`\Illuminate\Http\Resources\Json\ResourceCollection`) arguments. `$resource->mapInto()` is being called for each resource item, and throws an error.

> Call to undefined method App\User::mapInto()


### Steps To Reproduce:

1. Create a new class extended from ResourceCollection.
2. Call collection static method with a user collection.

> UserCollection::collection(User::all());

```php
<?php
declare(strict_types=1);

namespace App;

use Illuminate\Notifications\Notifiable;
use Illuminate\Foundation\Auth\User as Authenticatable;
use Laravel\Passport\HasApiTokens;

/**
 * Class User
 *
 * @package App
 */
class User extends Authenticatable
{
    use HasApiTokens, Notifiable;

    /**
     * The attributes that are mass assignable.
     *
     * @var array
     */
    protected $fillable = [
        'name', 'email', 'password',
    ];

    /**
     * The attributes that should be hidden for arrays.
     *
     * @var array
     */
    protected $hidden = [
        'password', 'remember_token',
    ];

    /**
     * The attributes that should be cast to native types.
     *
     * @var array
     */
    protected $casts = [
        'email_verified_at' => 'datetime',
    ];
}
```

```php
<?php
declare(strict_types=1);

namespace App\Http\Resources;

use Illuminate\Http\Resources\Json\JsonResource;

/**
 * Class User
 *
 * @package App\Http\Resources
 */
class User extends JsonResource
{
    /**
     * Transform the resource into an array.
     *
     * @param  \Illuminate\Http\Request  $request
     * @return array
     */
    public function toArray($request): array
    {
        return [
            'name' => $this->name,
        ];
    }
}
```

```php
<?php
declare(strict_types=1);

namespace App\Http\Resources;

use Illuminate\Http\Resources\Json\ResourceCollection;

/**
 * Class UserCollection
 *
 * @package App\Http\Resources
 */
class UserCollection extends ResourceCollection
{
    /**
     * Transform the resource collection into an array.
     *
     * @param  \Illuminate\Http\Request  $request
     * @return array
     */
    public function toArray($request)
    {
        return [
            'data' => $this->collection,
            'links' => [
                'self' => 'link-value',
            ],
        ];
    }
}
```

```php
Route::get('/test', function () {
    return App\Http\Resources\UserCollection::collection(App\User::all());
});
```",Can you copy/paste the minimum amount of code that's needed to reproduce this?,"```php
<?php
declare(strict_types=1);

namespace App;

use Illuminate\Notifications\Notifiable;
use Illuminate\Foundation\Auth\User as Authenticatable;
use Laravel\Passport\HasApiTokens;

/**
 * Class User
 *
 * @package App
 */
class User extends Authenticatable
{
    use HasApiTokens, Notifiable;

    /**
     * The attributes that are mass assignable.
     *
     * @var array
     */
    protected $fillable = [
        'name', 'email', 'password',
    ];

    /**
     * The attributes that should be hidden for arrays.
     *
     * @var array
     */
    protected $hidden = [
        'password', 'remember_token',
    ];

    /**
     * The attributes that should be cast to native types.
     *
     * @var array
     */
    protected $casts = [
        'email_verified_at' => 'datetime',
    ];
}
```

```php
<?php
declare(strict_types=1);

namespace App\Http\Resources;

use Illuminate\Http\Resources\Json\JsonResource;

/**
 * Class User
 *
 * @package App\Http\Resources
 */
class User extends JsonResource
{
    /**
     * Transform the resource into an array.
     *
     * @param  \Illuminate\Http\Request  $request
     * @return array
     */
    public function toArray($request): array
    {
        return [
            'name' => $this->name,
        ];
    }
}
```

```php
<?php
declare(strict_types=1);

namespace App\Http\Resources;

use Illuminate\Http\Resources\Json\ResourceCollection;

/**
 * Class UserCollection
 *
 * @package App\Http\Resources
 */
class UserCollection extends ResourceCollection
{
    /**
     * Transform the resource collection into an array.
     *
     * @param  \Illuminate\Http\Request  $request
     * @return array
     */
    public function toArray($request)
    {
        return [
            'data' => $this->collection,
            'links' => [
                'self' => 'link-value',
            ],
        ];
    }
}
```

```php
Route::get('/test', function () {
    return App\Http\Resources\UserCollection::collection(App\User::all());
});
```"
laravel/framework,https://github.com/laravel/framework/issues/28022,laravel_framework_issues_28022,"SoftDelete::runSoftDelete does not take into account overridden Model::setKeysForSaveQuery 

- Laravel Version: 5.8.4
- PHP Version: 7.2.4
- Database Driver & Version: MySql

### Description:
SoftDelete::runSoftDelete does not take into account overridden Model::setKeysForSaveQuery method.
I use this for multi-tenancy purposes. Or for use composite primary keys.

Model:
```
<?php

namespace App;

use Illuminate\Database\Eloquent\Model;
use Illuminate\Database\Eloquent\SoftDeletes;

class Shop extends Model
{
    use SoftDeletes;

    public $primaryKey= 'shop_id';

    protected function setKeysForSaveQuery(Builder $query) {
        $query
            ->where('user_id', '=', $this->getAttribute('user_id'))
            ->where('shop_id', '=', $this->getAttribute('shop_id'));

        return $query;
    }
}
```
When running below code:

```
$shop = Shop::find(1);
$shop->delete();
```

Expected query:
`UPDATE shop SET deleted_at = ?, Shop.updated_at = ? WHERE  shop_id = ? AND user_id = ?`

Actual query:
`UPDATE shop SET deleted_at = ?, SHOP.updated_at = ? WHERE shop_id = ?`

Solution is to replace below line

```
<?php

namespace Illuminate\Database\Eloquent;

trait SoftDeletes
{
     ...
     protected function runSoftDelete()
    {
        $query = $this->newModelQuery()->where($this->getKeyName(), $this->getKey());
        ...
     }
     ...
}
```
To

`$query = $this->setKeysForSaveQuery($this->newModelQuery());`",Why would `update Shop` be expected here?,"I use this for multi-tenancy purposes.
;

    public $primaryKey= 'shop_id'When running below code:

```
$shop = Shop::find(1);
$shop->delete();
```"
laravel/framework,https://github.com/laravel/framework/issues/28832,laravel_framework_issues_28832,"Carbon throws error when PostgreSQL has removed trailing milliseconds

- Laravel Version: 5.8.8
- PHP Version: 7.3.6
- Database Driver & Version: (PostgreSQL) 9.6.11
- Carbon Version: 2.19.2

### Description:
**TLDR;** When trying to get `created_at` field from the model, Carbon throws `InvalidArgumentException`, because milliseconds are missing from the timestamp field. Carbon waits for the `Y-m-d H:i:s.u` format, but PostgreSQL has stripped milliseconds.

If PostgreSQL timestamp value is saved in DB as follows: `2019-01-12 09:00:00.000000`, then when querying data PostgreSQL removes those (`.000000`) milliseconds and returns value as follows `2019-01-12 09:00:00` (this doesn't happen in standard cases, where milliseconds isn't `.000000`. 

Date format for Carbon is set to `Y-m-d H:i:s.u`, but Carbon receives value without milliseconds and throws following error `at Carbon::rawCreateFromFormat('Y-m-d H:i:s.u', '2019-01-12 09:00:00', null)`.

How to resolve this case? Is there an option to set a fallback date format? It would be cool if Carbon could handle this case on his own.

### Steps To Reproduce:
1) Create a PostgreSQL table with timestamp precision 6
2) Save data with zero milliseconds (`2019-01-12 09:00:00.000000`)
3) Set models date format to `Y-m-d H:i:s.u`
4) Query the model
5) Try to get value from model `$myCoolModel->created_at`
6) See the error
7) cry",Which version of Carbon are you using? Does upgrading to the latest version of Laravel and Carbon fixes your problem?,- Carbon Version: 2.19.2
laravel/framework,https://github.com/laravel/framework/issues/29230,laravel_framework_issues_29230,"onOneServer not respected using elastic beanstalk and redis

- Laravel Version: 5.8.26
- PHP Version: 7.2
- Database Driver & Version: postgresSQL

### Description:

When using onOneServer for cron tasks, the task is executed on all instances when deployed on aws beanstalk. Works fine on localhost.

relevant versions:
```
    ""laravel/framework"": ""5.8.*"",
    ""predis/predis"": ""~1.0"",
```
redis version on localhost, using managed redis on AWS (version 3)
```
Redis server v=3.2.12 sha=00000000:0 malloc=jemalloc-4.0.3 bits=64 build=9537aa82cd76e6f2
```

Our setup on AWS:
4 beanstalk environments (web, worker1, worker2, preprod-web)
instance count is normally as follows:
web: 2 (can scale to 8)
worker1: 1 (can scale to 8)
worker2: 1 (can scale to 8)
preprod-web: 1

cron scheduled jobs are only triggered on the worker environments but the tasks are processed twice from what we observe.
Based on beanstalk conf it will only trigger cron on one instance in the environment.

we use the onOneServer command and have redis as a cache server to keep track of the command locking.

Yet we still see the issue.

If we use withoutOverlapping it works as expected. But this isn't really clean.

Any ideas? Happy for  any inputs.

Redis db conf:
```
    'redis' => [

        'client' => 'predis',

        'default' => [
            'host'     => env('REDIS_HOST', 'redis'),
            'password' => env('REDIS_PASSWORD', null),
            'port'     => env('REDIS_PORT', 6379),
            'database' => 0,
        ],

        'cache' => [
            'host'     => env('REDIS_HOST', 'redis'),
            'password' => env('REDIS_PASSWORD', null),
            'port'     => env('REDIS_PORT', 6379),
            'database' => 1,
        ],

    ],
```

Redis cache store:
```
...
    'default' => env('CACHE_DRIVER', 'redis'),
...
    'stores' => [
...
        'redis' => [
            'driver' => 'redis',
            'connection' => 'cache',
        ],
    ],
...
```

What is interesting is that the cron trigger from elastic beanstalk will only execute on one instance within an environment, but since we have two environments they both execute (which is fine) but the joob should't be triggered twice.

Sample job:
```
        $schedule->command('score:calculate')
            ->dailyAt('0:00')
            ->onOneServer()
            ->runInBackground();
```
What we use as a workaround for now is:
```
            ->withoutOverlapping(5)
```
Should this be an acceptable solution?
I still think it's worth reporting, so I'm open to provide additional information and try get this working.

### Steps To Reproduce:
Running a scheduled task with `onOneServer` on elastic Beanstalk (I know very specific) with more than one worker environment.

Thanks!",Can you please fill out the issue template?,"- Laravel Version: 5.8.26
- PHP Version: 7.2
- Database Driver & Version: postgresSQL

### Description:

### Steps  with `onOneServer` on elastic Beanstalk (I know very specific) with more than one worker environment.

Thank"
vgstation-coders/vgstation13,https://github.com/vgstation-coders/vgstation13/issues/23608,vgstation-coders_vgstation13_issues_23608,"dwarf swords should break open crates and do damage to airlocks

the dwarf swords don't break open doors or crates but ~~the swords made from kitchen knifes and a welder break open airlocks~~ well i guess they don't anyways so i think the swords made with a forge and and anvil should be strong enough to break open airlocks (and locked crates too so cargo gets a good reason to build the crew swords)",why do the kitchen knife swords open airlocks?,~~~~ well i guess they don't anyways
vgstation-coders/vgstation13,https://github.com/vgstation-coders/vgstation13/issues/20844,vgstation-coders_vgstation13_issues_20844,"How could we make the Robust Softdrinks vending machine more fun/useful?

One thing I love about this game is that almost everything has some super secret, super niche use, and almost all the vendors have some form of junk that you can use effectively or just have fun fucking around with.
The soda vendor seems to be the exception. I just can't find anything to do with it. The only thing it does is give you cans, but Groan's Soda also gives you cans and even cheaper.
I'm not saying REE REMOVE IT, but maybe we can work at least a little fun into it?

Some ideas (looking for more):

 - An expensive large soda bottle that, when emptied, doubles as a large beaker? MetaStation already has this in the form of the soviet soda vendor, which actually sells large beakers for 15$
 - Give more uses to basic soda, even super situational ones? Maybe soda makes gremlins hyperactive? Maybe roaches love a certain type of soda? Maybe it makes gas masks yucky and sticky so the Clown can prank shitters?
 - Contraband/coin sodas that have powergay applications? Maybe a drink that has a bit of hyperzine in it? Maybe it sells bleach?
 - Sodas (but not Groan's) have a 1/10 chance of coming with a SURPRISE COUPON!!! inside? Or a novelty soda that has a glowstick inside?",While giving everything function is nice does it really need it? Its a fluff machine for fluff drinks.,Or a novelty soda that has a glowstick inside?
vgstation-coders/vgstation13,https://github.com/vgstation-coders/vgstation13/issues/21615,vgstation-coders_vgstation13_issues_21615,"There are some good points to be made for un-mapping sidewindow-grille-sidewindow combos and replacing them with fullwindows+grille

It's not an intuitive idea, but let me elaborate.

Pros of un-mapping side windows:

 - Side windows are relatively annoying and time-consuming to rebuild, for no good reason. Rebuilding a single full-tile would be much easier if we add an option to make a full-tile when slapping a grille with glass.
 - By simplifying down to full-tiles we could also add a ""grille+window"" function to the RCD
 - Would mostly fix probably the worst ZAS bug of them all, #19258
 - Side-windows also have tons of other weird bugs, like pressure and fires only breaking them from one side, adjacency issues like bees stinging through them and biomass spreading inside them, etc. These bugs would still exist, but show much less often.
 - Side windows also have collision issues like mobs stopping to break them needlessly and stopping thrown items midair
 - Assuming #21595 is merged, this would add consistency to the values. Same for any other PR that does something with windows.
 - You can silicate spray both sides of a window at once!

Cons:
 - Players really like the rotate-window trick to break into areas. However if there's only one full-tile in the way they'd surely come up with a similar trick like unscrew-and-pull-away, and it would probably take even less time.
 - Players also like to break one window and the grille to ""expand"" their offices sometimes. Granted you could still build your own side window if you wanted the end result, but it wouldn't really be the same thing.
 - Full-tile window HP would have to be doubled to compensate",What about the aesthetics ?,"Side windows also have collision issues like mobs stopping to break them needlessly and stopping thrown items midair
 -"
vgstation-coders/vgstation13,https://github.com/vgstation-coders/vgstation13/issues/24117,vgstation-coders_vgstation13_issues_24117,"Snow Taxi is pretty shit (and 10 reasons you wont beleive why!!!!1)

#### Description of issue
Feedback on snow taxi map, sonix was all bein a bitch like ""waaaaaaa u b mean and say u dont like so write feedback"" well I am so there.


#### Difference between expected and actual behavior
Expected: good map
Got: Snaxi


#### Steps to reproduce
Have adspergs force badmap



Okay shit memes aside,  Sonix said to give some feedback about new snaxi map so here goes:

~~Shit needs population minimum. It beyond sucks ass with only a few people. On top of that, everything is so fuckin far apart its going to be isolating and therefore boring as fuck. Like, how many people go to the extra mining base on the mining asteroid? None, yeah cause no one is there and its too far away to be useful. This whole map is that. Why would I walk the distance of all the way accross box 3-4 times over to go to the bar? I wouldn't and probably no one else will either so we'll all crowd north east station or central.~~

~~Needs a fuckin map on the website. ""Waaa powergaming"" its a new map, we gotta figure out where shit is. The feeling of exploration is great but at the same time so is knowing where my office is.~~

~~The movement lag is shit.~~

The central/security substation feels incomplete. Possibly because its the size of box and all it has is sec and bridge (and a shitty half done R&D). Either make nice big dedicated substations for a dept or focus them in one place, spreading them out just means you either don't have access to what you need or everything is coppied 10 times. Also the location of mining in r&d is weird and both the shuttles are next to each other. Move mining out to the big ol space dock you got or something. Or with cargo since its part of cargo anyway.

~~The permabrig is cool. The rest of the brig is average at best. Armoury shutters leading into the medbay is whack, that should be a seperate switch.~~

The ""EVA"" by bridge is weird and empty, there are coats everywhere already.

The shuttle bay was cool but good fuckin luck finding it. Should really be connected to the engineering substation or have a special office there, and a dedicated airlock from main station.

The whole ""on a planet"" thing is average as well, basically tators are gonna be longshotting everyone or doing stupid shit and running into the trees never to be seen until they blow shit up again. So either sec will ignore them (ya forced shitcurity) or all disperse into the bush and leave station sec-less. On top of that, there were what like 3 ID/Coms consoles that are accessible from outside? Sure thats fine on space station where its hard to get to without being thrown into space and theres carp and breaking through the windows to bridge is gonna be very quickly noticed, less cool when people can walk up in a coat. So outside needs to be dangerous in some way aparrt from ""you get cold unless you're wearing one of the many hardsuits around or a warm coat that are everywhere""

Speaking of dangerous outside, no one is gonna go between substations even if its not dangerous. Glass tubes are a possible idea, that way you can have snowmen or some shit out there and still quickly get between stations. Or make a reskinned trashbin that uses disposal pipes to get folks from place to place. Shit, make a portal system, put it in mechanic's office and now mechanic can do something apart from either being a shitty engineer or building 2 of every machine because shits and giggles. Also, just put things close together I guess.

Having more destination taggers/wrapping paper would be cool because then everyone could send shit to each other via the trash. Send food to bridge, send corpses to med, send guns to engineering or get no power. You know, normal shit.

Also, the cold air could rapidly lower temperatures until inside also gets fucked so now instead of supplying air, atmos can supply warm air by using a thermo chamber like teg (that you can add to atmos). This works because now the tators in the great outdoors can sabotage air lines and sec+atmos teams will have to be dispersed to deal with it.

Blah blah blah I'm a whiny faggot and this isn't a professional bug report, ok, but as proffanity filled as this is I feel I raised some good points and ideas.
Its a cool map, but its gonna be a free for all shitshow because everyone is so isolated they can do whatever the fuck they want, at which point they'll get bored and dab. Just suffers from being TOO FUCKING BIG",Why? Who knows.,"~~.~~

~~Needs a fuckin map on the website. ""Waaa powergaming"" its a new map, we gotta figure out where shit is. The feeling of exploration is great but at the same time so is knowing where my office is.~~

~~The movement lag is shit.~~

The central/security substation feels incomplete. Possibly because its the size of box and all it has is sec and bridge (and a shitty half done R&D). Either make nice big dedicated substations for a dept or focus them in one place, spreading them out just means you either don't have access to what you need or everything is coppied 10 times. Also the location of mining in r&d is weird and both the shuttles are next to each other. Move mining out to the big ol space dock you got or something. Or with cargo since its part of cargo anyway~~"
electron/electron,https://github.com/electron/electron/issues/13628,electron_electron_issues_13628,"Electron crash during open DevTools on MacOS (v3.0.0-beta.2) 

* Electron Version: v3.0.0-beta.2
* Operating System (Platform and Version): macOS 10.13.5
* Last known working Electron version: v3.0.0-beta.1

**Expected Behavior**
Launching DevTools

**Actual behavior**
Electron crash with current dump:
```
Crashing on exception: *** -[__NSArrayM objectAtIndex:]: index 1 beyond bounds [0 .. 0]

Application Specific Backtrace 1:
0   CoreFoundation                      0x00007fff489d332b __exceptionPreprocess + 171
1   libobjc.A.dylib                     0x00007fff6fb41c76 objc_exception_throw + 48
2   CoreFoundation                      0x00007fff48a14634 _CFThrowFormattedException + 202
3   CoreFoundation                      0x00007fff488f2290 __CFStringDecodeByteStream3 + 0
4   Electron Framework                  0x000000010e7554c2 _ZN9brightray8IOThread7CleanUpEv + 2210
...
```

**Additional info** 
`BrowserWindow` should contain `titleBarStyle` with `hiddenInset` value.

Full dump attached to [link](https://github.com/electron/electron/files/2185677/dump.txt)",Do you see it everytime you launch the renderer devtools?,"**Additional info** 
`BrowserWindow` should contain `titleBarStyle` with `hiddenInset` value."
electron/electron,https://github.com/electron/electron/issues/14462,electron_electron_issues_14462,"Doesn’t highlight file in file manager when using showItemInFolder() under Linux

* Output of `node_modules/.bin/electron --version`: v2.0.8
* Operating System (Platform and Version): Arch Linux

**Expected Behavior**
Should highlight file when opening file manager with `showItemInFolder()`.

**Actual behavior**
It opens the correct directory but doesn’t highlight the file.

**To reproduce**
```
❯ electron -i
> const {shell} = require('electron')
> shell.showItemInFolder('/home/user/folder')
true
```

It opens the file manager in `/home/user` but `folder` is not highlighted.

**Additional Information**
See how they fixed this problem in Firefox:
https://hg.mozilla.org/mozilla-central/rev/5fc52820456d",Can you provide us with steps to reproduce this?,".

**To reproduce**
```
❯ electron -i
> const {shell} = require('electron')
> shell.showItemInFolder('/home/user/folder')
true
```

It opens the file manager in `/home/user` but `folder` is not highlighted"
electron/electron,https://github.com/electron/electron/issues/14697,electron_electron_issues_14697,"v3.0.0 fails to create a working renderer on Linux

* Output of `node_modules/.bin/electron --version`: `v3.0.0`
* Operating System (Platform and Version): `Debian GNU/Linux 9.5 x86_64`
* Output of `node_modules/.bin/electron --version` on last known working Electron version (if applicable): `v2.0.10`

**Expected Behavior**
My previously working application, not concerned by any of the [breaking changes](https://github.com/electron/electron/blob/master/docs/api/breaking-changes.md#breaking-api-changes-30), still works fine after upgrading Electron to v3.

**Actual behavior**
The renderer window shows a frozen view of what was underneath it when it opened. Hitting the usual keyboard shortcut to open the devtools doesn't work. Rolling back to the latest v2.x and everything works fine again.

**To Reproduce**
Simply launch electron v3.0 without any arguments (or `-d`), even the default bundled app doesn't work.

**Screenshots**
![electron_bug](https://user-images.githubusercontent.com/24496417/45767911-c2acd880-bc3b-11e8-8f71-911c7edcc319.png)
On the left is the working default app on v2. On the right is v3. I blurred the window for privacy reasons, the point is it's showing a frozen view of my desktop.

---
**Additional Information**
Debian 9.5 x86_64.
Kernel is `4.9.0-8-amd64`.

Integrated GPU is `Intel HD Graphics 4600` on an `i5-4200H` Haswell chip.
2nd GPU is `Nvidia GeForce 850M`.

Intel driver: [`xserver-xorg-video-intel`](https://packages.debian.org/stretch/xserver-xorg-video-intel) `2:2.99.917+git20161206-1 amd64` (latest in stretch) aka default xorg handler for integrated GPUs
Nvidia driver: [`nvidia-driver`](https://packages.debian.org/stretch/nvidia-driver) `384.130-1 amd64` (also latest in stretch) aka latest closed source driver from nvidia

*Side note: I'm using [`bumblebee`](https://packages.debian.org/stretch/bumblebee) to handle the Optimus logic and switching between GPUs.*",What graphics card/drivers are you using? Do you see the behaviour still when running with `--disable-gpu`?,"---Debian 9.5 x86_64.
Kernel is `4.9.0-8-amd64`.

Integrated GPU is `Intel HD Graphics 4600` on an `i5-4200H` Haswell chip.
2nd GPU is `"
electron/electron,https://github.com/electron/electron/issues/23148,electron_electron_issues_23148,"After upgrading from electron version 6.x to the new version of electron (7.x, 8.x, 9.x), the page rendering performance drops significantly

<!--  As an open source project with a dedicated but small maintainer team, it can sometimes take a long time for issues to be addressed so please be patient and we will get back to you as soon as we can.
-->

### Preflight Checklist
<!-- Please ensure you've completed the following steps by replacing [ ] with [x]-->

* [x] I have read the [Contributing Guidelines](https://github.com/electron/electron/blob/master/CONTRIBUTING.md) for this project.
* [x] I agree to follow the [Code of Conduct](https://github.com/electron/electron/blob/master/CODE_OF_CONDUCT.md) that this project adheres to.
* [x] I have searched the issue tracker for an issue that matches the one I want to file, without success.

### Issue Details

* **Electron Version:**
  * 7.x,8.x,9.x
* **Operating System:**
  * macOS 10.14.6 
* **Last Known Working Electron version:**
  * v6.1.10

### Expected Behavior
There should be no noticeable performance degradation

### Actual Behavior
After upgrading from electron version 6.x to the new version of electron (7.x, 8.x, 9.x), the page rendering performance drops significantly
### To Reproduce
The only change I made was to try to upgrade different electron versions (from 6.x to 7.x 8.x 9.x)

<!--
For bugs that can be encapsulated in a small experiment, you can use Electron Fiddle (https://github.com/electron/fiddle) to publish your example to a GitHub Gist and link it your bug report.
-->

<!--
If Fiddle is insufficient to produce an example, please provide an example REPOSITORY that can be cloned and run. You can fork electron-quick-start (https://github.com/electron/electron-quick-start) and include a link to the branch with your changes.
-->

<!--
If you provide a URL, please list the commands required to clone/setup/run your repo e.g.
```sh
$ git clone $YOUR_URL -b $BRANCH
$ npm install
$ npm start || electron .
```
-->

### Screenshots
<!-- If applicable, add screenshots to help explain your problem. -->
electron 6.x  https://moon.fm/dist/6.x.mov
electron 8.x  https://moon.fm/dist/8.x.mov
Take a look at these two screen recordings (6.x vs 8.x), the problem in the video is not as obvious as it actually is, but please observe the expansion animation of the menu, you can still find obvious differences

### Additional Information
<!-- Add any other context about the problem here. -->
here is the demo repository based on  electron quick start
https://github.com/gaodeng/electron-render-issue
click the **toggle expand** button
You will see a lot of unnecessary renderings on the right column (electron v7.x 8.x 9.x)",Does this affect all page rendering or are you experiencing the slow down in a specific scenario? Can you post a html page that demonstrates the degradation?,"here is demo the repository
https://github.com/gaodeng/electron-render-issue
click this toggle expand button
You will see a lot of unnecessary renderings on the right column (electron v7.x 8.x 9.x)"
electron/electron,https://github.com/electron/electron/issues/16558,electron_electron_issues_16558,"Electron 4.0.2 remote.getCurrentWindow() returns null inside webview preload script

* Operating System (Platform and Version):
Ubuntu 16.04

**Expected Behavior**
require('electron').remote.getCurrentWindow() returns BrowserWindow object

**Actual behavior**
require('electron').remote.getCurrentWindow() returns null

**To Reproduce**
https://github.com/kaniseo/electron-getCurrentWindow-bug
Instructions on reproduction in the readme file.",can I work on this issue ?,"getCurrentWindow() returns BrowserWindow object

**Actual behavior**
require("
electron/electron,https://github.com/electron/electron/issues/19269,electron_electron_issues_19269,"Electron >= 3.0.8 freezes amdgpu system

### Preflight Checklist
<!-- Please ensure you've completed the following steps by replacing [ ] with [x]-->

* [x] I have read the [Contributing Guidelines](https://github.com/electron/electron/blob/master/CONTRIBUTING.md) for this project.
* [x] I agree to follow the [Code of Conduct](https://github.com/electron/electron/blob/master/CODE_OF_CONDUCT.md) that this project adheres to.
* [x] I have searched the issue tracker for an issue that matches the one I want to file, without success.

### Issue

__update:__ 

Electron <= 3.0.3 is slow and laggy on amdgpu.
Electron >= 3.0.8 is fast and smooth at first, but then freezes system.

With amdgpu I specifically mean AMD Picasso Core APU (Zen+ CPU Vega GPU).

Original issue description below.

---

I'm unsure if I'm allowed to post this vague issue here, because I'm not sure what's to blame. But here goes:

As a developer, I'm a big fan of Atom (IDE) and Boostnote (notes). They are both Electron apps. Usually I'm working on 2 Intel machines. One with nVidia graphics, and one with onboard Intel HD graphics.

I recently bought an **AMD Ryzen 5 3400G** with onboard **Radeon Vega Graphics** (APU) on an ASRock A300 Mini-STX board to replace an outdated desktop computer. I'm really pleased with this small machine. Everything is going snappy. Everything seems faster than my old machine at a fraction of the power usage.

However, Electron apps seem to go way slower. Everything moves with a lag or latency of 100ms, from scrolling to selecting text. And the Window seems to update at ~10 FPS while the rest of my machine updates at 60 FPS. In stead of tabs with code being visible instantly, I see them being constructed. First the panel, then grey text appears, then a syntax highlighting pass. This only takes a couple of frames, but it's annoying enough, especially since it works fluently on older machines.

### Issue Details

* **Electron Version:**
  * 2.x and 3.x
* **Operating System:**
  * Linux Mint 19.1 Cinnamon 4.0.10 x64
* **Graphics Hardware:**
  * Advanced Micro Devices, Inc. [AMD/ATI] Picasso
* **APU:**
  * [Ryzen 5 3400G](https://www.amd.com/en/products/apu/amd-ryzen-5-3400g#product-specs)

### Expected Behavior
Snappy and fluent interface

### Actual Behavior
Laggy and stuttering interface

### Additional Information
Google Chrome itself is going super fluent.","Can you please try https://electronjs.org/fiddle, which is based on Electron 5 if it still reproduces?","__update:__ 

Electron <= 3.0.3 is slow and laggy on amdgpu.
Electron >= 3.0.8 is fast and smooth at first, but then crashes amdgpu.

With amdgpu I specifically mean AMD Picasso Core APU (Zen+ CPU Vega GPU).

Original issue description below.

---"
electron/electron,https://github.com/electron/electron/issues/22500,electron_electron_issues_22500,"Temporary .ico files created by NativeImage should be cleaned

<!--  As an open source project with a dedicated but small maintainer team, it can sometimes take a long time for issues to be addressed so please be patient and we will get back to you as soon as we can.
-->

### Preflight Checklist
<!-- Please ensure you've completed the following steps by replacing [ ] with [x]-->

* [x] I have read the [Contributing Guidelines](https://github.com/electron/electron/blob/master/CONTRIBUTING.md) for this project.
* [x] I agree to follow the [Code of Conduct](https://github.com/electron/electron/blob/master/CODE_OF_CONDUCT.md) that this project adheres to.
* [x] I have searched the issue tracker for an issue that matches the one I want to file, without success.

### Issue Details

* **Electron Version:**
  * 7.1.10
* **Operating System:**
  * Windows 10 (1909)

### Expected Behavior
<!-- A clear and concise description of what you expected to happen. -->
Temporary .tmp.ico files created by NativeImage in \Users\\\<user>\AppData\Local\Temp\ should be cleaned after NativeImage is destroyed or when application exits.

### Actual Behavior
<!-- A clear and concise description of what actually happened. -->
The .tmp.ico file is left in \Users\\\<user>\AppData\Local\Temp\. If the application is opened multiple times there are multiple temporary icons.

### To Reproduce
<!--
Your best chance of getting this bug looked at quickly is to provide an example.
-->
1. Create a NativeImage with an .ico file archived in an asar-archive
2. Start the application
  2a. Check that a .tmp.ico file was created in \Users\\\<user>\AppData\Local\Temp\
3. Quit the application
  3a. Notice that the file wasn't deleted

<!--
For bugs that can be encapsulated in a small experiment, you can use Electron Fiddle (https://github.com/electron/fiddle) to publish your example to a GitHub Gist and link it your bug report.
-->

<!--
If Fiddle is insufficient to produce an example, please provide an example REPOSITORY that can be cloned and run. You can fork electron-quick-start (https://github.com/electron/electron-quick-start) and include a link to the branch with your changes.
-->

<!--
If you provide a URL, please list the commands required to clone/setup/run your repo e.g.
```sh
$ git clone $YOUR_URL -b $BRANCH
$ npm install
$ npm start || electron .
```
-->

### Additional Information
<!-- Add any other context about the problem here. -->
This is related to https://github.com/electron/electron/issues/10796 with the difference that #10796 answered whether or not the files could be deleted and didn't address that they should be deleted automatically.

The code doing the copying:
https://github.com/electron/electron/blob/v1.8.1/atom/common/api/atom_api_native_image.cc#L168-L184",Would it be possible to load icon directly from ASAR instead of dumping it to disk first?,"The code doing the copying:
https://github.com/electron/electron/blob/v1.8.1/atom/common/api/atom_api_native_image.cc#L168-L184"
apache/incubator-echarts,https://github.com/apache/incubator-echarts/issues/11249,apache_incubator-echarts_issues_11249,"bug with quantityExponent

### Version
4.3.0

### Reproduction link
[https://github.com/apache/incubator-echarts/blob/7041103fb91cf5aeacf934bc990a023dfd3c5dfa/src/util/number.js#L390](https://github.com/apache/incubator-echarts/blob/7041103fb91cf5aeacf934bc990a023dfd3c5dfa/src/util/number.js#L390)

### Steps to reproduce
quantityExponent has bug with `quantityExponent(1000)`

### What is expected?
`quantityExponent(1000)` is expected to be 3 

### What is actually happening?
`quantityExponent(1000) = 2`

I recommend using Math.log10(val) instead.

<!-- This issue is generated by echarts-issue-helper. DO NOT REMOVE -->",Do you mind making a pull request to fix it?,I recommend using Math.log10(val) instead.
apache/incubator-echarts,https://github.com/apache/incubator-echarts/issues/12099,apache_incubator-echarts_issues_12099,"Let yAxis. type support custom function.

### What problem does this feature solve?

I found that [`yAxis. type` only supports : `value`, `category`, `time`, `log` ](https://www.echartsjs.com/en/option.html#yAxis.type).

I have many lines (different level) to show, Hope it supports custom function.

### What does the proposed API look like?
For example, I want to draw 3 line(**They have different zoom level: 5 times, 20 time and log** )

            yAxis: [
                {
                    type:(value)=>(value*5), //5 level
                },
                {
                    type:(value)=>(value*20), //20 level
                },
                {
                    type:""log"", //log level
                },
            ],

<!-- This issue is generated by echarts-issue-helper. DO NOT REMOVE -->
<!-- This issue is in English. DO NOT REMOVE -->","What kind of custom function do you need? In your given example, the type should probably be `log`.","[For example, I want to draw 3 line(**They have different zoom level: 5 times, 20 time and log** )

[
                    ,
                {
                    type:""log"", //log level
                },
            ]"
appium/appium,https://github.com/appium/appium/issues/11271,appium_appium_issues_11271,"Session ID is null  in Appium 1.9.0

## The problem

Trying to obtain the device Performance as mentioned in the [link](http://appium.io/docs/en/commands/device/performance-data/get-performance-data/) , we need to get the session ID as one of the inputs for the API which I am trying to retrieve from _/wd/hub/status_ but response obtained is 

_{""status"":0,""value"":{""build"":{""version"":""1.9.0""}},""sessionId"":null}_


## Environment

* Appium version (or git revision) that exhibits the issue:1.9
* Node.js version (unless using Appium.app|exe):
* Mobile platform/version under test:10.9.0
* Real device or emulator/simulator:Real Device
* Appium CLI or Appium.app|exe:

## Details

If necessary, describe the problem you have been experiencing in more detail.

## Link to Appium logs

Gist to Appium [Logs](https://gist.github.com/pavanbachu0604/3bd8bdf622b11c902c510d30485e60e1)",Can you please properly describe the actual and the expected result and fix the link to logs?,"but response obtained is 

_{""status"":0"
appium/appium,https://github.com/appium/appium/issues/10848,appium_appium_issues_10848,"setGeoLocation iOS Real device problem

## The problem

Execution of the command `idevicelocation -d -u REAL_DEVICE_UUID 30 23` changes my coordinates on the real device, but when executing the test with 

`driver.setLocation(new Location(30.0001, 21.0002, 1));`

returns 

` Responding to client with driver.setGeoLocation() result: null`  
and the coordinates aren't changed 

## Environment

* Appium version (or git revision) that exhibits the issue: 1.8.1 
* Last Appium version that did not exhibit the issue (if applicable):
* Desktop OS/version used to run Appium: macOS 10.13.4
* Node.js version (unless using Appium.app|exe): v8.11.2
* Mobile platform/version under test: 11.4
* Real device or emulator/simulator: real device 
* Appium CLI or Appium.app|exe: node Appium cli 

## Details

## Link to Appium logs

https://gist.github.com/ktanev/f51605bfd7cf4606f8df8e841f1983d2


## Code To Reproduce Issue [ Good To Have ]

`driver.setLocation(new Location(30.0001, 21.0002, 1));`",What do you expect it to return instead?,and the coordinates aren't changed
appium/appium,https://github.com/appium/appium/issues/11539,appium_appium_issues_11539,"Appium with UiAutomator2 returns a different DOM than UiAutomatorViewer

## The problem

Inspecting a Activity via UiAutomator2 returns all available elements. Inspecting it with appium desktop using UiAutomator2 as automationName does not return all the elements

## Environment

* Appium version (or git revision) that exhibits the issue: 1.9.1, 1.9.2.beta.2
* Last Appium version that did not exhibit the issue (if applicable): none
* Desktop OS/version used to run Appium: MacOS Sierra
* Node.js version (unless using Appium.app|exe): v8.9.3
* Mobile platform/version under test: Android
* Real device or emulator/simulator: both
* Appium CLI or Appium.app|exe: both

## Link to Appium logs

Not needed

## Note
ignoreUninmportantViews is set to false

## Please see the attached screenshots
![screen shot 2018-10-17 at 12 43 55 pm](https://user-images.githubusercontent.com/31648187/47078523-28c15700-d20c-11e8-8f51-9aa1532da42c.png)
<img width=""914"" alt=""screen shot 2018-10-17 at 12 56 10 pm"" src=""https://user-images.githubusercontent.com/31648187/47078542-2fe86500-d20c-11e8-8b73-7a43fad011be.png"">",What is in getPageSource output there?,"## Note
ignoreUninmportantViews is set to false"
appium/appium,https://github.com/appium/appium/issues/12104,appium_appium_issues_12104,"iOS-HybridApp-WebView: WebView is returned very abnormally

## The problem

So we have an Hybrid App being tested on iOS which is using Cordova and has UIWEBView enabled. We wanted to work with the WebView instead of Native context, so we tried to switch the context. Now the real fun begins here.

On Local iOS Device, WebView is not returned but following the steps from https://github.com/appium/appium/issues/9599 mentioned by @MaxDomash, ""If I manually start device's Safari then webviews are visible."", we were able to get the WebView.

On BrowserStack, cloud service which uses factory reset real devices, WebView is returned on first execution and then on subsequent executions WebView is not returned.

## Environment
* Appium version (or git revision) that exhibits the issue: Local - 1.70.,1.8.0,19.1,1.11.0-beta.3 ... BrowserStack - 1.6.5, 1.7.0 (default), 1.7.1, 1.7.2, 1.8.0, 1.9.1 
* Desktop OS/version used to run Appium: MAcBook Pro, Mojave/High Sierra
* Node.js version (unless using Appium.app|exe): v10.12.0
* Mobile platform/version under test: iPhone 6, 6s Plus, 7/ iOS 11,11.3,12.1
* Real device or emulator/simulator: Real Device
* Appium CLI or Appium.app|exe: Appium CLI
* Xcode version: 9.4.1 and 10.1

## Link to Appium logs

Complete Appium (Local Device + BrowserStack) Logs - https://gist.github.com/MarvelCoder/ce332c97084802a47b960e4ffbffb421",Did you try to detect the webview by just using IWDP tool from the terminal? Did it work?,"[ Local - 1.70.,1.8.0,19.1,1.11.0-beta.3 ... BrowserStack - 1.6.5, 1.7.0 (default), 1.7.1, 1.7.2, 1.8.0, 1.9.1  v10.12.0 Appium CLI
* Xcode version: 9.4.1 and 10.1Link to Appium logs

Complete Appium (Local"
appium/appium,https://github.com/appium/appium/issues/12205,appium_appium_issues_12205,"simctl getDevices is failing the regexp with versionMatchRe.match is not a function

## The problem

When Appium is preparing to launch the simulator and my app ... I see the following in the debug log:

[debug] [simctl] Unable to get JSON device list: versionMatchRe.match is not a function
[debug] [simctl] Falling back to manual parsing

## Environment

* Appium version: 1.11.1
* Desktop OS/version used to run Appium: macOS 10.14.3
* Xcode version: 10.1 (10B61)
* Node.js version: 11.9.0
* Mobile platform/version under test: iOS 12
* Real device or emulator/simulator: sim
* Appium CLI or Appium.app|exe: cli

## Link to Appium logs

https://gist.github.com/ChrisEdgington/520d7a13aa4cee7cbc721898224bd7a7",What version of Xcode are you on?,* Xcode version: 10.1 (10B61)
appium/appium,https://github.com/appium/appium/issues/12368,appium_appium_issues_12368,"appium 1.12 started with ANDROID_UIAUTOMATOR2 deletes appium-uiautomator2-server-v3.4.0.apk file

## The problem

after a fresh install of appium 1.12 (issue also on 1.11) and starting an appium android test from java :
with ANDROID_UIAUTOMATOR2 deletes appium-uiautomator2-server-v3.4.0.apk,
which in turns throws an blocking error the ""appium-uiautomator2-server-v3.4.0.apk' is not writeable. Please grant write permissions to this file or to its parent folder "" message.

## Environment

* Appium version (or git revision) that exhibits the issue:1.12, 1.11
* Last Appium version that did not exhibit the issue (if applicable):unknown
* Desktop OS/version used to run Appium:Windows 10
* Node.js version (unless using Appium.app|exe): 8.11.3
* Npm or Yarn package manager:5.6.0
* Mobile platform/version under test:
* Real device or emulator/simulator:both
* Appium CLI or Appium.app|exe:Yes

## Details

N/A

## Link to Appium logs

N/A

## Code To Reproduce Issue [ Good To Have ]

start an appium server with a java client where:
caps.setCapability(MobileCapabilityType.AUTOMATION_NAME, AutomationName.ANDROID_UIAUTOMATOR2);
and in debug mode and stop just before the instruction
this.driver = new AppiumDriver<WebElement>( url_ , caps );
after it is executed, the file is deleted.",Maybe these are deleted by some antivirus software running on your computer?,"start an appium server with a java client where:
caps.setCapability(MobileCapabilityType.AUTOMATIO"
appium/appium,https://github.com/appium/appium/issues/12946,appium_appium_issues_12946,"Issue with UiAutomator2 - AutomationName Capabilities.

## The problem

I was trying to run the below line of code and it works fine when i use AutomationName as UiAutomator1. But when i use UiAutomator2 (latest one
), it is giving below error. 

**FAILED: manin1
org.openqa.selenium.WebDriverException: Connection refused
Build info: version: '3.141.59', revision: 'e82be7d358', time: '2018-11-14T08:17:03'
System info: host: 'USCHAMNMOG0JK78', ip: '2606:a000:1215:c3b2:e5f0:1980:6db2:8d57', os.name: 'Mac OS X', os.arch: 'x86_64', os.version: '10.14.5', java.version: '1.8.0_91'
Driver info: driver.version: AndroidDriver**

## Code To Reproduce Issue [ Good To Have ]

Note: (here, i am manually opening Appium Desktop Client)

**My Script
```java
public void manin1 () throws InterruptedException, IOException
		{	
			
			oCaps = new DesiredCapabilities();
			oCaps.setCapability(""noReset"", ""true"");
			oCaps.setCapability(""deviceName"", ""Pixel_3_XL_API_28"");   //Pixel_3_API_28   Nexus_6P_API_27 Pixel 3 API 28
			oCaps.setCapability(""platformName"", ""Android"");
			oCaps.setCapability(""automationName"", ""UiAutomator2"");  // works fine only when i use UiAutomator1
			oCaps.setCapability(""appPackage"", ""com.android.chrome"");
			oCaps.setCapability(""appActivity"", ""com.google.android.apps.chrome.Main"");
			
			URL url = new URL(""http://127.0.0.1:4723/wd/hub"");
			driver = new AndroidDriver<MobileElement> (url,oCaps);
			driver.get(""https://www.google.come"");

		}
```



## Environment

* Appium version (or git revision) that exhibits the issue:
* Last Appium version that did not exhibit the issue (if applicable):
* Desktop OS/version used to run Appium:
* Node.js version (unless using Appium.app|exe):
* Npm or Yarn package manager:
* Mobile platform/version under test:
* Real device or emulator/simulator:
* Appium CLI or Appium.app|exe:

## Details
nfo AppiumDoctor Appium Doctor v.1.11.1
info AppiumDoctor ### Diagnostic for necessary dependencies starting ###
info AppiumDoctor  ✔ The Node.js binary was found at: /usr/local/bin/node
info AppiumDoctor  ✔ Node version is 12.6.0
info AppiumDoctor  ✔ Xcode is installed at: /Applications/Xcode.app/Contents/Developer
info AppiumDoctor  ✔ Xcode Command Line Tools are installed in: /Applications/Xcode.app/Contents/Developer
info AppiumDoctor  ✔ DevToolsSecurity is enabled.
info AppiumDoctor  ✔ The Authorization DB is set up properly.
info AppiumDoctor  ✔ Carthage was found at: /usr/local/bin/carthage. Installed version is: 0.33.0
info AppiumDoctor  ✔ HOME is set to: /Users/vz8zw5
info AppiumDoctor  ✔ ANDROID_HOME is set to: /Users/vz8zw5/Library/Android/sdk
info AppiumDoctor  ✔ JAVA_HOME is set to: /Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home
info AppiumDoctor  ✔ adb exists at: /Users/vz8zw5/Library/Android/sdk/platform-tools/adb
info AppiumDoctor  ✔ android exists at: /Users/vz8zw5/Library/Android/sdk/tools/android
info AppiumDoctor  ✔ emulator exists at: /Users/vz8zw5/Library/Android/sdk/tools/emulator
info AppiumDoctor  ✔ Bin directory of $JAVA_HOME is set
info AppiumDoctor ### Diagnostic for necessary dependencies completed, no fix needed. ###
info AppiumDoctor 
info AppiumDoctor ### Diagnostic for optional dependencies starting ###
WARN AppiumDoctor  ✖ opencv4nodejs cannot be found.
WARN AppiumDoctor  ✖ ffmpeg cannot be found
WARN AppiumDoctor  ✖ mjpeg-consumer cannot be found.
WARN AppiumDoctor  ✖ idb and idb_companion are not installed
WARN AppiumDoctor  ✖ applesimutils cannot be found
WARN AppiumDoctor  ✖ idevicelocation cannot be found
WARN AppiumDoctor  ✖ ios-deploy cannot be found
WARN AppiumDoctor  ✖ ios_webkit_debug_proxy cannot be found
WARN AppiumDoctor  ✖ ifuse cannot be found
WARN AppiumDoctor  ✖ bundletool.jar cannot be found
info AppiumDoctor ### Diagnostic for optional dependencies completed, 10 fixes possible. ###
info AppiumDoctor 
info AppiumDoctor ### Optional Manual Fixes ###
info AppiumDoctor The configuration can install optionally. Please do the following manually:
WARN AppiumDoctor  ➜ Why opencv4nodejs is needed and how to install it: https://github.com/appium/appium/blob/master/docs/en/writing-running-appium/image-comparison.md
WARN AppiumDoctor  ➜ ffmpeg is needed to record screen features. Please read https://www.ffmpeg.org/ to install it
WARN AppiumDoctor  ➜ mjpeg-consumer module is required to use MJPEG-over-HTTP features. Please install it with 'npm i -g mjpeg-consumer'.
WARN AppiumDoctor  ➜ Why idb is needed and how to install it: https://github.com/appium/appium-idb
WARN AppiumDoctor  ➜ Why applesimutils is needed and how to install it: http://appium.io/docs/en/drivers/ios-xcuitest/
WARN AppiumDoctor  ➜ idevicelocation is used to set geolocation for real device. Please read https://github.com/JonGabilondoAngulo/idevicelocation to install it
WARN AppiumDoctor  ➜ ios-deploy is used to install iOS applications to real device. Please read http://appium.io/docs/en/drivers/ios-xcuitest-real-devices/ to install it
WARN AppiumDoctor  ➜ ios_webkit_debug_proxy is used to proxy requests from Appium to MobileSafari running on real device. Please read https://github.com/google/ios-webkit-debug-proxy to install it
WARN AppiumDoctor  ➜ ifuse is used to manage files/folders against a real device. Please read https://github.com/appium/appium/blob/master/docs/en/writing-running-appium/ios/ios-xctest-file-movement.md to install it
WARN AppiumDoctor  ➜ bundletool.jar is used to handle Android App Bundle. Please read http://appium.io/docs/en/writing-running-appium/android/android-appbundle/ to install it
info AppiumDoctor 
info AppiumDoctor ###
info AppiumDoctor 
info AppiumDoctor Bye! Run appium-doctor again when all manual fixes have been applied!
info AppiumDoctor 


Error from Desktop Appium SErver:
=========================

```
[Appium] Welcome to Appium v1.14.0
[Appium] Non-default server args:
[Appium]   address: 127.0.0.1
[Appium]   allowInsecure: {
[Appium]   }
[Appium]   denyInsecure: {
[Appium]   }
[Appium] Appium REST http interface listener started on 127.0.0.1:4723
[HTTP] --> POST /wd/hub/session
[HTTP] {""desiredCapabilities"":{""appActivity"":""com.google.android.apps.chrome.Main"",""appPackage"":""com.android.chrome"",""noReset"":""true"",""automationName"":""UiAutomator2"",""platformName"":""Android"",""deviceName"":""Pixel_3_XL_API_28""},""capabilities"":{""firstMatch"":[{""appium:appActivity"":""com.google.android.apps.chrome.Main"",""appium:appPackage"":""com.android.chrome"",""appium:automationName"":""UiAutomator2"",""appium:deviceName"":""Pixel_3_XL_API_28"",""appium:noReset"":""true"",""platformName"":""android""}]}}
[W3C] Calling AppiumDriver.createSession() with args: [{""appActivity"":""com.google.android.apps.chrome.Main"",""appPackage"":""com.android.chrome"",""noReset"":""true"",""automationName"":""UiAutomator2"",""platformName"":""Android"",""deviceName"":""Pixel_3_XL_API_28""},null,{""firstMatch"":[{""appium:appActivity"":""com.google.android.apps.chrome.Main"",""appium:appPackage"":""com.android.chrome"",""appium:automationName"":""UiAutomator2"",""appium:deviceName"":""Pixel_3_XL_API_28"",""appium:noReset"":""true"",""platformName"":""android""}]}]
[BaseDriver] Event 'newSessionRequested' logged at 1563811534630 (12:05:34 GMT-0400 (EDT))
[Appium] Appium v1.14.0 creating new AndroidUiautomator2Driver (v1.33.1) session
[Appium] Capabilities:
[Appium]   platformName: android
[Appium]   appActivity: com.google.android.apps.chrome.Main
[Appium]   appPackage: com.android.chrome
[Appium]   automationName: UiAutomator2
[Appium]   deviceName: Pixel_3_XL_API_28
[Appium]   noReset: true
[BaseDriver] W3C capabilities {""alwaysMatch"":{""platformNa... and MJSONWP desired capabilities {""appActivity"":""com.google.... were provided
[BaseDriver] Creating session with W3C capabilities: {""alwaysMatch"":{""platformNa...
[BaseDriver] Capability 'noReset' changed from string to boolean. This may cause unexpected behavior
[BaseDriver] Session created with session id: ab1a31f3-8d23-4bdc-a6f4-f7215e9fc2e9
[ADB] Using 'adb' from '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb'
[AndroidDriver] Retrieving device list
[ADB] Trying to find a connected android device
[ADB] Getting connected devices...
[ADB] 1 device(s) connected
[AndroidDriver] Using device: emulator-5554
[ADB] Using 'adb' from '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb'
[ADB] Setting device id to emulator-5554
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell getprop ro.build.version.sdk'
[ADB] Current device property 'ro.build.version.sdk': 28
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell getprop ro.build.version.release'
[ADB] Current device property 'ro.build.version.release': 9
[ADB] Device API level: 28
[UiAutomator2] Relaxing hidden api policy
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings put global hidden_api_policy_pre_p_apps 1'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings put global hidden_api_policy_p_apps 1'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings put global hidden_api_policy 1'
[AndroidDriver] No app sent in, not parsing package/activity
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 wait-for-device'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell echo ping'
[AndroidDriver] Pushing settings apk to device...
[ADB] Getting install status for io.appium.settings
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell dumpsys package io.appium.settings'
[ADB] 'io.appium.settings' is installed
[ADB] Getting package info for 'io.appium.settings'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell dumpsys package io.appium.settings'
[ADB] Using 'aapt' from '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/aapt'
[ADB] The version name of the installed 'io.appium.settings' is greater or equal to the application version name ('2.14.1' >= '2.14.1')
[ADB] There is no need to install/upgrade '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/io.appium.settings/apks/settings_apk-debug.apk'
[ADB] Getting IDs of all 'io.appium.settings' processes
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell 'pgrep --help; echo $?''
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell pgrep -f io\\.appium\\.settings'
[AndroidDriver] io.appium.settings is already running. There is no need to reset its permissions.
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell appops set io.appium.settings android\:mock_location allow'
[Logcat] Starting logcat capture
[ADB] Getting install status for io.appium.uiautomator2.server
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell dumpsys package io.appium.uiautomator2.server'
[ADB] 'io.appium.uiautomator2.server' is not installed
[ADB] App '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' is not installed
[UiAutomator2] io.appium.uiautomator2.server installation state: notInstalled
[ADB] Checking app cert for /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk
[ADB] Using 'apksigner' from '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner'
[ADB] Starting '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner' with args '[""verify"",""--print-certs"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk""]'
[ADB] Got an error during apksigner execution: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner verify --print-certs /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2
[ADB] apksigner stderr: Unable to locate an executable at ""/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java"" (-1)
[ADB] 
[ADB] Cannot use apksigner tool for signature verification. Original error: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner verify --print-certs /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2
[ADB] Defaulting to verify.jar
[ADB] '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' is not signed with debug cert
[ADB] Using 'zipalign' from '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/zipalign'
[ADB] /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' is already zip-aligned. Doing nothing
[ADB] Signing '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' with default cert
[ADB] Starting '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner' with args '[""sign"",""--key"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.pk8"",""--cert"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.x509.pem"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk""]'
[ADB] Got an error during apksigner execution: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner sign --key /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.pk8 --cert /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.x509.pem /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2
[ADB] apksigner stderr: Unable to locate an executable at ""/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java"" (-1)
[ADB] 
[ADB] Cannot use apksigner tool for signing. Defaulting to sign.jar. Original error: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner sign --key /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.pk8 --cert /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.x509.pem /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2; StdErr: Unable to locate an executable at ""/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java"" (-1)
[ADB] 
[ADB] Resigning apk.
[UiAutomator2] Deleting UiAutomator2 session
[UiAutomator2] Deleting UiAutomator2 server session
[WD Proxy] Matched '/' to command name 'deleteSession'
[UiAutomator2] Did not get confirmation UiAutomator2 deleteSession worked; Error was: UnknownError: An unknown server-side error occurred while processing the command. Original error: Trying to proxy a session command without session id
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell am force-stop com.android.chrome'
[Logcat] Stopping logcat capture
[ADB] Removing forwarded port socket connection: 8200 
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 forward --remove tcp\:8200'
[UiAutomator2] Unable to remove port forward 'Error executing adbExec. Original error: 'Command '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 forward --remove tcp\:8200' exited with code 1'; Stderr: 'adb: error: listener 'tcp:8200' not found'; Code: '1''
[UiAutomator2] Restoring hidden api policy to the device default configuration
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings delete global hidden_api_policy_pre_p_apps'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings delete global hidden_api_policy_p_apps'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings delete global hidden_api_policy'
[BaseDriver] Event 'newSessionStarted' logged at 1563811536075 (12:05:36 GMT-0400 (EDT))
[W3C] Encountered internal error running command: Error: Could not sign with default certificate. Original error Command '/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java' not found. Is it installed?
[W3C]     at ADB.signWithDefaultCert (/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/lib/tools/apk-signing.js:125:13)
[HTTP] <-- POST /wd/hub/session 500 1447 ms - 970
[HTTP] 
```",What is the error happening on the _server_ side?,"Error from Desktop Appium SErver:
=========================

**[Appium] Welcome to Appium v1.14.0
[Appium] Non-default server args:
[Appium]   address: 127.0.0.1
[Appium]   allowInsecure: {
[Appium]   }
[Appium]   denyInsecure: {
[Appium]   }
[Appium] Appium REST http interface listener started on 127.0.0.1:4723
[HTTP] --> POST /wd/hub/session
[HTTP] {""desiredCapabilities"":{""appActivity"":""com.google.android.apps.chrome.Main"",""appPackage"":""com.android.chrome"",""noReset"":""true"",""automationName"":""UiAutomator2"",""platformName"":""Android"",""deviceName"":""Pixel_3_XL_API_28""},""capabilities"":{""firstMatch"":[{""appium:appActivity"":""com.google.android.apps.chrome.Main"",""appium:appPackage"":""com.android.chrome"",""appium:automationName"":""UiAutomator2"",""appium:deviceName"":""Pixel_3_XL_API_28"",""appium:noReset"":""true"",""platformName"":""android""}]}}
[W3C] Calling AppiumDriver.createSession() with args: [{""appActivity"":""com.google.android.apps.chrome.Main"",""appPackage"":""com.android.chrome"",""noReset"":""true"",""automationName"":""UiAutomator2"",""platformName"":""Android"",""deviceName"":""Pixel_3_XL_API_28""},null,{""firstMatch"":[{""appium:appActivity"":""com.google.android.apps.chrome.Main"",""appium:appPackage"":""com.android.chrome"",""appium:automationName"":""UiAutomator2"",""appium:deviceName"":""Pixel_3_XL_API_28"",""appium:noReset"":""true"",""platformName"":""android""}]}]
[BaseDriver] Event 'newSessionRequested' logged at 1563811534630 (12:05:34 GMT-0400 (EDT))
[Appium] Appium v1.14.0 creating new AndroidUiautomator2Driver (v1.33.1) session
[Appium] Capabilities:
[Appium]   platformName: android
[Appium]   appActivity: com.google.android.apps.chrome.Main
[Appium]   appPackage: com.android.chrome
[Appium]   automationName: UiAutomator2
[Appium]   deviceName: Pixel_3_XL_API_28
[Appium]   noReset: true
[BaseDriver] W3C capabilities {""alwaysMatch"":{""platformNa... and MJSONWP desired capabilities {""appActivity"":""com.google.... were provided
[BaseDriver] Creating session with W3C capabilities: {""alwaysMatch"":{""platformNa...
[BaseDriver] Capability 'noReset' changed from string to boolean. This may cause unexpected behavior
[BaseDriver] Session created with session id: ab1a31f3-8d23-4bdc-a6f4-f7215e9fc2e9
[ADB] Using 'adb' from '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb'
[AndroidDriver] Retrieving device list
[ADB] Trying to find a connected android device
[ADB] Getting connected devices...
[ADB] 1 device(s) connected
[AndroidDriver] Using device: emulator-5554
[ADB] Using 'adb' from '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb'
[ADB] Setting device id to emulator-5554
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell getprop ro.build.version.sdk'
[ADB] Current device property 'ro.build.version.sdk': 28
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell getprop ro.build.version.release'
[ADB] Current device property 'ro.build.version.release': 9
[ADB] Device API level: 28
[UiAutomator2] Relaxing hidden api policy
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings put global hidden_api_policy_pre_p_apps 1'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings put global hidden_api_policy_p_apps 1'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings put global hidden_api_policy 1'
[AndroidDriver] No app sent in, not parsing package/activity
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 wait-for-device'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell echo ping'
[AndroidDriver] Pushing settings apk to device...
[ADB] Getting install status for io.appium.settings
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell dumpsys package io.appium.settings'
[ADB] 'io.appium.settings' is installed
[ADB] Getting package info for 'io.appium.settings'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell dumpsys package io.appium.settings'
[ADB] Using 'aapt' from '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/aapt'
[ADB] The version name of the installed 'io.appium.settings' is greater or equal to the application version name ('2.14.1' >= '2.14.1')
[ADB] There is no need to install/upgrade '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/io.appium.settings/apks/settings_apk-debug.apk'
[ADB] Getting IDs of all 'io.appium.settings' processes
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell 'pgrep --help; echo $?''
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell pgrep -f io\\.appium\\.settings'
[AndroidDriver] io.appium.settings is already running. There is no need to reset its permissions.
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell appops set io.appium.settings android\:mock_location allow'
[Logcat] Starting logcat capture
[ADB] Getting install status for io.appium.uiautomator2.server
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell dumpsys package io.appium.uiautomator2.server'
[ADB] 'io.appium.uiautomator2.server' is not installed
[ADB] App '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' is not installed
[UiAutomator2] io.appium.uiautomator2.server installation state: notInstalled
[ADB] Checking app cert for /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk
[ADB] Using 'apksigner' from '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner'
[ADB] Starting '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner' with args '[""verify"",""--print-certs"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk""]'
[ADB] Got an error during apksigner execution: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner verify --print-certs /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2
[ADB] apksigner stderr: Unable to locate an executable at ""/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java"" (-1)
[ADB] 
[ADB] Cannot use apksigner tool for signature verification. Original error: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner verify --print-certs /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2
[ADB] Defaulting to verify.jar
[ADB] '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' is not signed with debug cert
[ADB] Using 'zipalign' from '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/zipalign'
[ADB] /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' is already zip-aligned. Doing nothing
[ADB] Signing '/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' with default cert
[ADB] Starting '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner' with args '[""sign"",""--key"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.pk8"",""--cert"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.x509.pem"",""/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk""]'
[ADB] Got an error during apksigner execution: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner sign --key /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.pk8 --cert /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.x509.pem /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2
[ADB] apksigner stderr: Unable to locate an executable at ""/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java"" (-1)
[ADB] 
[ADB] Cannot use apksigner tool for signing. Defaulting to sign.jar. Original error: Command '/Users/vz8zw5/Library/Android/sdk/build-tools/29.0.1/apksigner sign --key /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.pk8 --cert /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/keys/testkey.x509.pem /Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-uiautomator2-server/apks/appium-uiautomator2-server-v3.7.0.apk' exited with code 2; StdErr: Unable to locate an executable at ""/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java"" (-1)
[ADB] 
[ADB] Resigning apk.
[UiAutomator2] Deleting UiAutomator2 session
[UiAutomator2] Deleting UiAutomator2 server session
[WD Proxy] Matched '/' to command name 'deleteSession'
[UiAutomator2] Did not get confirmation UiAutomator2 deleteSession worked; Error was: UnknownError: An unknown server-side error occurred while processing the command. Original error: Trying to proxy a session command without session id
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell am force-stop com.android.chrome'
[Logcat] Stopping logcat capture
[ADB] Removing forwarded port socket connection: 8200 
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 forward --remove tcp\:8200'
[UiAutomator2] Unable to remove port forward 'Error executing adbExec. Original error: 'Command '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 forward --remove tcp\:8200' exited with code 1'; Stderr: 'adb: error: listener 'tcp:8200' not found'; Code: '1''
[UiAutomator2] Restoring hidden api policy to the device default configuration
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings delete global hidden_api_policy_pre_p_apps'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings delete global hidden_api_policy_p_apps'
[ADB] Running '/Users/vz8zw5/Library/Android/sdk/platform-tools/adb -P 5037 -s emulator-5554 shell settings delete global hidden_api_policy'
[BaseDriver] Event 'newSessionStarted' logged at 1563811536075 (12:05:36 GMT-0400 (EDT))
[W3C] Encountered internal error running command: Error: Could not sign with default certificate. Original error Command '/Library/Java/JavaVirtualMachines/jdk1.8.0_91.jdk/Contents/Home/bin/bin/java' not found. Is it installed?
[W3C]     at ADB.signWithDefaultCert (/Applications/Appium.app/Contents/Resources/app/node_modules/appium/node_modules/appium-adb/lib/tools/apk-signing.js:125:13)
[HTTP] <-- POST /wd/hub/session 500 1447 ms - 970
[HTTP] **"
appium/appium,https://github.com/appium/appium/issues/13093,appium_appium_issues_13093,"Unable To Find the PID in Web View on real devices but working fine With Emulator

## The problem

I'm trying to perform the actions on webview in android Hybrid app which is built on React native. The same thing working with an emulator but when I'm running it on a real device. Appium is unable to find out the PID.

 Getting Below Error:

**An unknown server-side error occurred while processing the command. Original error: Failed to start Chromedriver session: An unknown server-side error occurred while processing the command. Original error: unknown error: Failed to get PID for the following process: com.traveltriangle.traveller
  (process name must be specified if not equal to package name)**

## Environment

* Appium version that exhibits the issue:  Appium v1.14.0, Appium v1.13.0 and Appium v1.12.1.
* Last Appium version that did not exhibit the issue (if applicable): Appium v1.14.0
* Desktop OS/version used to run Appium: Windows 10
* Node.js version (unless using Appium.app|exe): 10.6
* Npm or Yarn package manager: 6.9
* Mobile platform/version under test: 9
* Real device or emulator/simulator: Real Device
* Appium CLI or Appium.app|exe: Both
* APPIUM CHROME DRIVER: LATEST
## Details

On Emulator Its working.On real device giving an Error.
An unknown server-side error occurred while processing the command. Original error: Failed to start Chromedriver session: An unknown server-side error occurred while processing the command. Original error: unknown error: Failed to get PID for the following process: com.traveltriangle.traveller
  (process name must be specified if not equal to package name)

## Link to Appium logs

[https://gist.github.com/tahirakhlaaq/53de659cb5fe89889ab9dec7432c135c](url)

## APK Link
[https://drive.google.com/open?id=1q1UmVID_m89R8B04Pbk03WeaFBO_UXSV](url)
## Code To Reproduce Issue [ Good To Have ]

```
@BeforeMethod
	public void androidCapabilities() throws MalformedURLException {
		File f = new File(""src"");
		File fs = new File(f, ""app-locators.apk"");
		DesiredCapabilities cap = new DesiredCapabilities();
		cap.setCapability(""automationName"", ""uiAutomator2"");
		cap.setCapability(""platformName"", ""Android"");
		cap.setCapability(""platformVersion"", ""9"");
		cap.setCapability(""deviceName"", ""OPPO F11 Pro"");
		cap.setCapability(""appPackage"", ""com.traveltriangle.traveller"");
		cap.setCapability(""appActivity"", ""com.traveltriangle.traveller.MainActivity"");
		cap.setCapability(""noReset"", true);
		String baseURL = ""http://0.0.0.0:"";
		String minorURL = ""/wd/hub"";
		String port = ""4723"";
		driver = new AndroidDriver<AndroidElement>(new URL(baseURL + port + minorURL), cap);
		
	@Test
	public void launch() throws InterruptedException, MalformedURLException {
		WebDriverWait wait = new WebDriverWait(driver, 10);

		Thread.sleep(4000);
	  waitForElementPresent((MobileBy.
		  AccessibilityId(""ChatBotView_5343_5_FormButton_903_2, "")), 30);
		  driver.findElement((MobileBy.
		  AccessibilityId(""ChatBotView_5343_5_FormButton_903_2, ""))).click();
            //    driver.findElement(MobileBy.AccessibilityId(""CustomFAB_470_2"")).click();
		Thread.sleep(4000);
		Set<String> contextNames = driver.getContextHandles();
		for (String contextName : contextNames) {
			System.out.println(contextName);
			driver.context(contextName);
			if (contextName.contains(""WEBVIEW"")) {
				driver.context(contextName);
			}
		}
		// System.out.println(driver.getPageSource());
		waitForElementPresent(By.xpath(""(//a[@class='rsc-os-option-element sc-bxivhb PUXvG'])[1]""), 30);
		driver.findElement(By.xpath(""(//a[@class='rsc-os-option-element sc-bxivhb PUXvG'])[1]"")).click();
		waitForElementPresent(By.xpath(""(//a[@class='rsc-os-option-element sc-bxivhb PUXvG'])[1]""), 30);
		driver.findElement(By.xpath(""(//a[@class='rsc-os-option-element sc-bxivhb PUXvG'])[1]"")).click();
		waitForElementPresent(By.xpath(""//input[@placeholder='Type your destination...']""), 30);
		driver.findElement(By.xpath(""//input[@placeholder='Type your destination...']"")).sendKeys(""cool"");

	}

	public static void waitForElementPresent(final By by, int timeOutInSeconds) {
		WebDriverWait wait = new WebDriverWait(driver, timeOutInSeconds);

		wait.until(new ExpectedCondition<Boolean>() {

			public Boolean apply(WebDriver d) {
				// TODO Auto-generated method stub
				return d.findElement(by).isDisplayed();
			}
		});
	}
	}
```

@mykola-mokhnach",Can you list the web view using IWDP console and/or list it using Safari remote debugger?,* APPIUM CHROME DRIVER: LATEST59cb5evx6JcQmca
appium/appium,https://github.com/appium/appium/issues/13158,appium_appium_issues_13158,"useXctestrunFile: true is expecting .xcodeproj project in the folder and WebDriverAgent.xcodeproj -showBuildSettings' exited with code 66

## The problem

Hello,

Requirement: We want a re usable WDA .xctestrun file to run tests on real device without building and would like to use that in couple of appium installed machines so test cases should run without building.

**Issue:** Previously(appium 1.7), we had created .xctestrun file and placed in separate folder(WDA) and ran it, it worked but in Appium 1.14, if i do same thing appium expecting .xcodeproj project file in WDA folder, giving WebDriverAgent.xcodeproj -showBuildSettings' exited with code 66.

## Environment
* Appium version (or git revision) that exhibits the issue: 1.14
xcode 10.3 
Node latest
Mac OS latest

## Link to Appium logs
LOGS: https://gist.github.com/govindu84/33c23b4e5d51c45684da8762b1225fb0

Things i research:
I see in appium 1.12, fixed following issue, i feel this is causing this issue. 
https://github.com/appium/appium-xcuitest-driver/pull/903

Note: If i tried to copy .xcodeproj to  Custom WDA folder and run the appium, it is working.",What is the output of `xcodebuild -project /Applications/Olympus/bin/WDA/WebDriverAgent.xcodeproj -showBuildSettings` when executed from the command line?,"Requirement: to run tests on real device without building (appium 1.7), it"
appium/appium,https://github.com/appium/appium/issues/13320,appium_appium_issues_13320,"[IOS][WD Proxy] Got an unexpected response with status undefined: {""code"":""ECONNRESET""}  Original error: Could not proxy command to remote server.Error: socket hang up

## The problem
I'm working on an IOS App with MacOSCatalina 10.15. The WebAgent project is built successfully and WebAgentRunner-Runner.App is reachable by Appium Server.
There are similar issues related to this error however I'm not working on Android so it is no use uninstalling io.appium.uiautomator2 which is not listed in my package.

## Environment

* Appium version (or git revision) that exhibits the issue: 1.15.0
* Last Appium version that did not exhibit the issue (if applicable):
* Desktop OS/version used to run Appium: macOS Catalina 10.15 
* Node.js version (unless using Appium.app|exe): v.9.3.0
* Npm or Yarn package manager: nom version 5.6.0
* Mobile platform/version under test: iOS 12.1
* Real device or emulator/simulator: iPhone 6
* Appium CLI or Appium.app|exe: CLI

## Details

Xcode 10.2 is used. The Xcode project is inside my workspace and the bundle id created in .xcodeproject is pasted to the app in .properties
I changed the WebDriverAgent.app to WebDriverAgentRunner-Runner.App as Appium couldn't find the App in my build folder.

## Link to Appium logs

https://gist.github.com/AymarN/b1e7abc7587c43d6422e046666a6e7e4

## Code To Reproduce Issue [ Good To Have ]

Below the desired capabilities:

caps.setCapability(""deviceName"", PARAMETERS.getProperty(""deviceName_IPhone""));
caps.setCapability(""udid"", PARAMETERS.getProperty(""udid""));
caps.setCapability(""automationName"",PARAMETERS.getProperty(""automationName_IPhone""));
caps.setCapability(""platformVersion"", PARAMETERS.getProperty(""platformVersion_IPhone""));
caps.setCapability(""platformName"", PARAMETERS.getProperty(""platformName_IPhone""));
caps.setCapability(""xcodeOrgId"", PARAMETERS.getProperty(""xcodeOrgId""));
caps.setCapability(""realDeviceLogger"",PARAMETERS.getProperty(""realDeviceLogger_IPhone""));
caps.setCapability(""noReset"", PARAMETERS.getProperty(""noReset_IPhone""));
caps.setCapability(""bundleId"", PARAMETERS.getProperty(""bundleId""));
caps.setCapability(""app"",Path + ""//App//B.tv_"" + PARAMETERS.getProperty(""version_App_Btv_IPhone"") + ""_pprod.ipa"");
caps.setCapability(""xcodeSigningId"", PARAMETERS.getProperty(""xcodeSigningId""));
driver = new IOSDriver<MobileElement>(new URL(PARAMETERS.getProperty(""url_Driver_IPhone"")), caps);","Could you enable `showXcodeLog` to be able to track xcodebuild process?
@AymarN","Xcode 10.2 is used. The Xcode project is inside my workspace and the bundle id created in .xcodeproject is pasted to the app in .properties
 changed the WebDriverAgent.app to WebDriverAgentRunner-Runner.App as Appium couldn't"
appium/appium,https://github.com/appium/appium/issues/13707,appium_appium_issues_13707,"UiAutomator2 can find element; Espresso can't.

## The problem
With UiAutomator2, I am able to find an element by xpath. Once I switch to using Espresso, however, it gets stuck trying to find the same element. 

## Environment

* Appium version (or git revision) that exhibits the issue: 1.15.1
* Last Appium version that did not exhibit the issue (if applicable):
* Desktop OS/version used to run Appium: macOS Mojave - 10.14.6
* Node.js version (unless using Appium.app|exe): 12.13.1
* Npm or Yarn package manager: yarn 1.16.0
* Mobile platform/version under test: Android 9
* Real device or emulator/simulator: emulator
* Appium CLI or Appium.app|exe: Appium CLI

## Details

When spying on elements via Appium Studio, I can get xpaths just fine. UiAutomator2 can then detect elements using those xpaths, but Espresso can't. When I use an xpath as a selector such as `const environment = await driver.$(""//*[@tag='Primary_Button_Login']"");`, it just hangs there, waiting to find it. It also hangs when I use this selector strategy:  `driver.$(""~Primary_Button_Login"")`. Espresso can't seem to see anything.

Here are my capabilities:
```
capabilities: {
    platformName: ""Android"",
    platformVersion: ""9"",
    deviceName: ""Android Phone"",
    app: ""/Users/blane/Documents/Development/appium/[AppNameRedacted].apk"",
    appPackage: ""com.[AppNameRedacted].mobile.enterprise"",
    appActivity: ""com.[AppNameRedacted].mobile.MainActivity"",
    automationName: ""Espresso"",
    forceEspressoRebuild: ""true"",
    newCommandTimeout: 10,
    appWaitDuration: 60000,
    autoGrantPermissions: ""true""
  }
```
## Link to Appium logs

[Appium log](https://gist.github.com/blane1988/e4cdba3e51be13c67c688269dafe4179)

## Source code of test

```
""use strict""
const wdio = require(""webdriverio"");
jest.setTimeout(100000);

// Android testing for emulator and device.
const opts = {
  port: 4723,
  capabilities: {
    platformName: ""Android"",
    platformVersion: ""9"",
    deviceName: ""Android Phone"",
    app: ""/Users/blane/Documents/Development/appium/[AppNameRedacted].apk"",
    appPackage: ""com.[AppNameRedacted].mobile.enterprise"",
    appActivity: ""com.[AppNameRedacted].mobile.MainActivity"",
    // automationName: ""UiAutomator2"",
    automationName: ""Espresso"",
    forceEspressoRebuild: ""true"",
    newCommandTimeout: 10,
    appWaitDuration: 60000,
    autoGrantPermissions: ""true"",
    clearDeviceLogsOnStart: ""true""
  }
};

it('should show login screen using Espresso driver', async () => {
  const driver = await wdio.remote(opts);
  await driver.setImplicitTimeout(30000);

  // const environment = await driver.$(""//*[@tag='Midway (Local Proxy)']"");
  // const environment = await driver.$(""//*[@text='Midway (Local Proxy)']"");

  // Test flow hangs at next line.
  const environment = await driver.$(""~Midway (Local Proxy)"");
  await environment.touchAction('tap');

  const logIn = await driver.$(""//*[@text='LOG IN']"");
  // const logIn = await driver.$(""//*[@tag='PrimaryButton_Login']"");
  await logIn.touchAction('tap');

  const username = await driver.$(""//*[@text='Card User ID']"");
  await username.addValue(""ASYS12345"");

  const password = await driver.$(""//*[@text='Password']"");
  await password.addValue(""Discover01"");

  const loginButton = await driver.$(""//*[@text='LOG IN']"");
  await loginButton.touchAction('tap');
});
```","Can you get the source, in your test script, right before you are trying to find the element?","## Source code of test

```
""use strict""
const wdio = require(""webdriverio"");
jest.setTimeout(100000);

// Android testing for emulator and device.
const opts = {
  port: 4723,
  capabilities: {
    platformName: ""Android"",
    platformVersion: ""9"",
    deviceName: ""Android Phone"",
    app: ""/Users/blane/Documents/Development/appium/[AppNameRedacted].apk"",
    appPackage: ""com.[AppNameRedacted].mobile.enterprise"",
    appActivity: ""com.[AppNameRedacted].mobile.MainActivity"",
    // automationName: ""UiAutomator2"",
    automationName: ""Espresso"",
    forceEspressoRebuild: ""true"",
    newCommandTimeout: 10,
    appWaitDuration: 60000,
    autoGrantPermissions: ""true"",
    clearDeviceLogsOnStart: ""true""
  }
};

it('should show login screen using Espresso driver', async () => {
  const driver = await wdio.remote(opts);
  await driver.setImplicitTimeout(30000);

  // const environment = await driver.$(""//*[@tag='Midway (Local Proxy)']"");
  // const environment = await driver.$(""//*[@text='Midway (Local Proxy)']"");

  // Test flow hangs at next line.
  const environment = await driver.$(""~Midway (Local Proxy)"");
  await environment.touchAction('tap');

  const logIn = await driver.$(""//*[@text='LOG IN']"");
  // const logIn = await driver.$(""//*[@tag='PrimaryButton_Login']"");
  await logIn.touchAction('tap');

  const username = await driver.$(""//*[@text='Card User ID']"");
  await username.addValue(""ASYS12345"");

  const password = await driver.$(""//*[@text='Password']"");
  await password.addValue(""Discover01"");

  const loginButton = await driver.$(""//*[@text='LOG IN']"");
  await loginButton.touchAction('tap');
});
```"
facebook/react,https://github.com/facebook/react/issues/15548,facebook_react_issues_15548,"Feedback on useEffect depndencies change error

Some feedback on `useEffect`

**What is the current behavior?**

I am using `useEffect` to load details on a set of users that are kept in props.

I want to minimize loading and there are situations where the array of users (and the actual user objects) are recreated but really they refer to the same identities.

So I do

```
const userIds = users.map(u => id)
useEffect(() => {
  if(!userIds.length)
    return
  ...load more stuff by querying endpoints about these ids and set state..
}, userIds)
```

aand I run into a warning

> The final argument passed to useEffect changed size between renders. The order and size of this array must remain constant

which to me is...kinda the point, is it not? I understand if we don't want to do a deep comparison in the dependencies, but if the dependencies themselves change...well that seems straightforward, run the effect. 

I know that I can do `[userIds.join(' '])` in this case, but that seems like just extra work for no reason and really anti-intuitive. And ends up doing the same exact thing but with extra steps! 

To be clear, what I'm proposing is removing [this whole block here](https://github.com/facebook/react/blob/master/packages/react-reconciler/src/ReactFiberHooks.js#L308) and replacing it with

```
if (nextDeps.length !== prevDeps.length)
  return false
```

As far as I can tell, this warning serves no real purpose and makes the use case outlined above awkward to deal with",Why not just passing `non zero-length userIds` as params to `useEffect` instead ?,"pt in props.

I want to minimize loading and there are situations where the array of users (and the actual user objects) are recreated but really they refer to the same identities.

So I do"
facebook/react,https://github.com/facebook/react/issues/11538,facebook_react_issues_11538,"Make React resilient to DOM mutations from Google Translate

## Coming from search? See workaround here: https://github.com/facebook/react/issues/11538#issuecomment-417504600. And star this issue: https://bugs.chromium.org/p/chromium/issues/detail?id=872770.

**Do you want to request a *feature* or report a *bug*?**

Bug, though there's a decent chance it's a Chrome/Google Translate one

**What is the current behavior?**

When using Google Translate on a page using React 16, a certain code pattern produces a Javascript error (`Failed to execute 'removeChild' on 'Node': The node to be removed is not a child of this node.`) when the rendered content changes.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem via https://jsfiddle.net or similar (template for React 16: https://jsfiddle.net/Luktwrdm/, template for React 15: https://jsfiddle.net/hmbg7e9w/).**

(This has only been checked on macOS 10.13.1)
1. Navigate to https://qq49kwjynj.codesandbox.io/ in a Chrome browser set to some language other than Japanese.
2. Right click the page and select ""Translate to English""
3. Click the checkbox, and the error will show.

The source of the example can be found at https://codesandbox.io/s/qq49kwjynj
The part of the code that seems to cause it is the following two lines:
```js
{this.state.checked && ""選択済み""}
{!this.state.checked && ""無選択""}
```
Changing this to the following fixes the behavior with Google Translate:
```js
{this.state.checked ? ""選択済み"" : ""無選択""}
```

**What is the expected behavior?**

It should not produce an error.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

I created an identical example with React 15 at the following pages:
https://p93xxmr0rq.codesandbox.io/
https://codesandbox.io/s/p93xxmr0rq
When repeating the same steps outlined above, no error was produced.
It only seems to affect React 16.
As this is a Chrome-only feature, it only affects Chrome.",Could be related? https://github.com/facebook/react/issues/9836,## Coming from search? See workaround here: https://github.com/facebook/react/issues/11538#issuecomment-417504600. And star this issue: https://bugs.chromium.org/p/chromium/issues/detail?id=872770.
facebook/react,https://github.com/facebook/react/issues/12981,facebook_react_issues_12981,"Get state's error message when using getDerivedStateFromProps lifecycle even when initializing the state in the constructor. 

<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
Bug
**What is the current behavior?**
I have a component and I'm using the life cycle `componentWillReceiveProps()`:

```
import { connect } from 'react-redux';
import { Component } from 'react';

class MyApp extends Component {
  constructor(props) {
    super(props);
    this.state = {
      currentTab: 0,
    };
  }
  UNSAFE_componentWillReceiveProps(nextProps) {
    if (this.state.currentTab !== nextProps.tabNumber) {
      this.setState({ currentTab: nextProps.tabNumber });
    }
  }
}


connect(state => ({
  tabNumber: state.common.editMyAppTabs.tabNumber,
}))(MyApp);
```
I tried to change the `componetWillReceiveProps` by `getDerivedStateFromProps` : 
```
import { connect } from 'react-redux';
import { Component } from 'react';
class MyApp extends Component {
  constructor(props) {
    super(props);
    this.state = {
      currentTab: 0,
    };
  }
  static getDerivedStateFromProps(props, state) {
    if (state.currentTab !== props.tabNumber) {
      return { currentTab: props.tabNumber };
    }
    return null;
  }
}

connect(state => ({
  tabNumber: state.common.editMyAppTabs.tabNumber,
}))(MyApp);
```
I got this error: 
```
Did not properly initialize state during construction. Expected state to be an object, but it was undefined.

The above error occurred in the <Translate(ReduxForm)> component:
    in Translate(ReduxForm) (created by WithStyles(Translate(ReduxForm)))
    in WithStyles(Translate(ReduxForm)) (created by Connect(WithStyles(Translate(ReduxForm))))
    in Connect(WithStyles(Translate(ReduxForm))) (created by Route)
    in Route (created by withRouter(Connect(WithStyles(Translate(ReduxForm)))))
    in withRouter(Connect(WithStyles(Translate(ReduxForm)))) (created by MyAppWrapper)
    in MyAppWrapper (created by Route)
    in Route (created by ProtectedRoute)
    in ProtectedRoute (created by Main)
    in Switch (created by Main)
    in main (created by Main)
    in Main (created by AppRoutes)
    in div (created by AppRoutes)
    in AppRoutes (created by App)
    in Router (created by BrowserRouter)
    in BrowserRouter (created by App)
    in Provider (created by App)
    in I18nextProvider (created by App)
    in MuiThemeProvider (created by App)
    in App

```
and the `state = null`
**What is the expected behavior?**
No warning and error problem. Does this due to the `connect` function ?
**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
**react**: 16.4.0
**OS**: ubtunu 17.10 (64bit)",Can your try to create a simplified version of the app that still exhibits the problem?,"The above error occurred in the <Translate(ReduxForm)> component:
    in Translate(ReduxForm) (created by WithStyles(Translate(ReduxForm)))
    in WithStyles(Translate(ReduxForm)) (created by Connect(WithStyles(Translate(ReduxForm))))
    in Connect(WithStyles(Translate(ReduxForm))) (created by Route)
    in Route (created by withRouter(Connect(WithStyles(Translate(ReduxForm)))))
    in withRouter(Connect(WithStyles(Translate(ReduxForm)))) (created by MyAppWrapper)
    in MyAppWrapper (created by Route)
    in Route (created by ProtectedRoute)
    in ProtectedRoute (created by Main)
    in Switch (created by Main)
    in main (created by Main)
    in Main (created by AppRoutes)
    in div (created by AppRoutes)
    in AppRoutes (created by App)
    in Router (created by BrowserRouter)
    in BrowserRouter (created by App)
    in Provider (created by App)
    in I18nextProvider (created by App)
    in MuiThemeProvider (created by App)
    in App"
facebook/react,https://github.com/facebook/react/issues/18178,facebook_react_issues_18178,"Bug: too hard to fix ""Cannot update a component from inside the function body of a different component.""

#  Note: React 16.13.1 fixed some cases where this was overfiring. If upgrading React and ReactDOM to 16.13.1 doesn't fix the warning, read this: https://github.com/facebook/react/issues/18178#issuecomment-595846312
----

React version:

16.13.0

## Steps To Reproduce

1. Build a time machine.
2. Go to the year 2017.
3. Build a huge application of 10K lines of code.
4. Get 80 (!) dependencies at package.json file including ones that become no longer maintained.
5. Update React to the latest version at February 27, 2020.
6. Get tons of errors that you don't know how to fix.
7. Tell your client that fixes are going to take unknown time and it's going to cost $$$ + days or weeks of investigation or we're going to get stuck with the outdated version of React and related libraries forever which will cost more $$$ but later.

Being serious, the business I work for isn't interested on that at all. Obviously I'd never made it happen to get such warnings to appear if I'd get them earlier. Currently that's impossibly hard to make the errors to be fixed because I get them at many different cases and with a huge stack trace. I tried to fix at least one of the appearing errors and it already took a lot of time. I tried to debug some of used libraries but got no luck. 

Just one example:

![image](https://user-images.githubusercontent.com/1082083/75559100-8fcf5c80-5a4b-11ea-8173-4f0a62cc5de3.png)

There we can notice the use of an outdated react-router, an outdated redux-connect (which I had to put to the project source to fix errors of outdated `componentWillReceiveProps` method), some HOCs created by recompose etc. It isn't just a simple virtual DOM tree where I can walk thru components developed by me and search by `setState` string to fix the bug, that's way more complicated than that.

Please make an ""UNSAFE"" option to disable this error or provide a simpler way to find where the error is thrown 🙏",Can you post that too? That should show you the exact callsite that is causing a side-effect in render.,"#  Coming from search for the warning message? See this update: https://github.com/facebook/react/issues/18178#issuecomment-600369392.
----"
facebook/react,https://github.com/facebook/react/issues/14102,facebook_react_issues_14102,"Synthetic KeyboardEvent should support KeyboardEvent.code

**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
The current synthetic keyboard event does not support the [`KeyboardEvent.code`](https://www.w3.org/TR/uievents/#dom-keyboardevent-code) property.

**What is the expected behavior?**
The synthetic keyboard event should pass along the [`KeyboardEvent.code`](https://www.w3.org/TR/uievents/#dom-keyboardevent-code) property. This is currently in the WD of DOM Events but is part of replacing `keyCode` and `charCode` and is much more consistent and easy to use. This is currently only supported by FF and Chrome ([CanIUse](https://caniuse.com/#feat=keyboardevent-code)) so it may be a bit premature to fully integrate. However `keyCode`, `charCode` and `which` are being deprecated so this will eventually need to be added.

Edit: I spoke too quickly, CanIUse shows that FF, Chrome, Safari and Opera support it. IE, Edge and most mobile browsers do not.",Do you want to send a PR? 🙂,"Edit: I spoke too quickly, CanIUse shows that FF, Chrome, Safari and Opera support it. IE, Edge and most mobile browsers do not."
facebook/react,https://github.com/facebook/react/issues/18594,facebook_react_issues_18594,"feat: allow multiple opaque identifiers in HTML attributes

react version: #17322
Original: https://github.com/facebook/react/pull/17322#issuecomment-613104823

Currently only a single value from `useOpaqueIdentifier` (unreleased) can be passed to HTML attributes. However, there are HTML attributes which support multiple ids (IDREFS) like `aria-labelledby`. This can be used to implement various patterns such as: 
```jsx
export default function App() {
  const taxpayerId = React.unstable_useOpaqueIdentifier();
  const spouseId = React.unstable_useOpaqueIdentifier();
  const w2GrossId = React.unstable_useOpaqueIdentifier();
  const dividendsId = React.unstable_useOpaqueIdentifier();
  return (
    <table>
      <tbody>
        <tr>
          <td />
          <th id={taxpayerId}>Taxpayer</th>
          <th id={spouseId}>Spouse</th>
        </tr>

        <tr>
          <th id={w2GrossId}>W2 Gross</th>
          <td>
            <input type=""text"" aria-labelledby={[taxpayerId, w2GrossId]} />
          </td>
          <td>
            <input type=""text"" aria-labelledby={[spouseId, w2GrossId]} />
          </td>
        </tr>

        <tr>
          <th id={dividendsId}>Dividends</th>
          <td>
            <input type=""text"" aria-labelledby={[taxpayerId, dividendsId]} />
          </td>
          <td>
            <input type=""text"" aria-labelledby={[spouseId, dividendsId]} />
          </td>
        </tr>
      </tbody>
    </table>
  );
}
````
-- https://codesandbox.io/s/useopaqueidentifier-for-idrefs-ocnm4

This example is from https://www.w3.org/WAI/GL/wiki/Using_aria-labelledby_to_concatenate_a_label_from_several_text_nodes

This currently almost works but it concatenates the ids with `"",""` (default toString of arrays) instead of `"" ""`.

`<button aria-labelledby={[opaqueIdentifier1, opaqueIdentifier1]} />` is to me the most intuitive one since we're passing a list of ids. 

Edit:
Removed the collapsible listbox example since that pattern has some a11y issue.",Maybe a special value like `React.createIdentifierList` that React could check for and serialize differently?,"Edit:
Removed the collapsible listbox example since that pattern has some a11y issue."
facebook/react,https://github.com/facebook/react/issues/15014,facebook_react_issues_15014,"DOM tree normalization causes React to enter an irrecoverable error state

Reproduction:
1) Open any React site that has a variable adjacent to other text
2) Type document.body.normalize() into javascript console
3) React enters an irrecoverable error state",How can we fix this in the DOM in a way that React can work properly with translations and other extensions in general?,"Reprouction:
1) Opn any React site that has a variab adjacent to other xt
2) Type ocument.body.normalize() into javascript console
3) React enters an irrecoverable error state"
facebook/react,https://github.com/facebook/react/issues/15333,facebook_react_issues_15333,"Support HTML5 Video Attribute disablePictureInPicture

Bug Report: `disablePictureInPicture` for html5 video elements are not supported

Eg:

```
    <video
    src=""https://www.w3schools.com/tags/movie.mp4""
    disablePictureInPicture
    loop
    controls
    controlsList=""nodownload""  
    ></video>
```

**What is the current behavior?**

Should remove the 3 dots (more button) on videos on Chrome:

![image](https://user-images.githubusercontent.com/2953026/55615012-0231b100-5797-11e9-9020-3552a1b8401e.png)

**What is the expected behavior?**

Instead, the attribute is not taken into consideration so the more menu stays:

![image](https://user-images.githubusercontent.com/2953026/55615032-107fcd00-5797-11e9-8d3a-4c25c8ed6e99.png)

Example:

https://jsfiddle.net/r1w4x7m0/2/

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

All / Latest, Chrome Browsers, All OSes.

Pull request for this issue has also been submitted: #15334",Do you know which browsers support `disablePictureInPicture`?,Pull request for this issue has also been submitted: #15334
facebook/react,https://github.com/facebook/react/issues/15814,facebook_react_issues_15814,"Feature request: useEffect add support for async await functions

Feature request for adding to the  API for the **useEffect** hook:

currently if I want to use a class component **componentDidMount** to fetch things from my server I could use **async** method like so:

```
async componentDidMount() {
     try {
        const response = await fetch('...');
        const json = await response.json();
        this.setState({...});
    catch(err) {
        this.setState(...)
    }
}
```

The **useEffect** should optionally return a cleanup function so applying this kind of syntax in a **useEffect** is wrong.
So this is wrong:

```
useEffect(async () => {
    try {
        const response = await fetch('...');
        const json = await response.json();
        setSomeStateCreatedWithUseStatet(...)
    catch(err) {
        setSomeStateCreatedWithUseStatet(...)
    }
})
```

Of course I could wrap the above code in another async function like so:

```
useEffect(() => {
    (async function() {
        try {
            const response = await fetch('...');
            const json = await response.json();
            setSomeStateCreatedWithUseStatet(...)
        catch(err) {
            setSomeStateCreatedWithUseStatet(...)
        }    
    })()
})
```

But this extra nesting kind of contradict the nice readable syntax that async await is giving us. 
Since the cleanup function is running in an async way already, it seems to me that the **useEffect**
should support a return value of a cleanup function or a promise wrapped cleanup function so we can use the async await syntax in the useEffect hook. 
So my suggestion is to not change the useEffect rather add an extra option to use async await functions inside the useEffect.

In this way we can use the regular useEffect but also these usages of useEffect will be valid as well:

```
useEffect(async () => {
    try {
        const response = await fetch('...');
        const json = await response.json();
        setSomeStateCreatedWithUseStatet(...)
    catch(err) {
        setSomeStateCreatedWithUseStatet(...)
    }
    return function cleanup() {...}
})
```

or if you prefer the hard way:

```
useEffect(() => {
    ...
    return new Promise((resolve) => {
        resolve(function cleanup() { ...})   
    })
})
```

What do you think?",What happens if the effect needs to clean up before the promise resolves?,"So my suggestion is to not change the useEffect rather add an extra option to use async await functions.
 we can use the regular useEffect but also"
facebook/react,https://github.com/facebook/react/issues/16255,facebook_react_issues_16255,"UseEffect infinity reload if value props is undefined

<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
Bug

**What is the current behavior?**
If the props received undefined value, useEffect understand the value props change, and reload infinity times.
Obviously the data must be handled, but when it gets undefined the infinite reload should not happen.

In the codesandbox example, I force the props checkedItems with undefined, but if I don't pass any props, the default value is undefined, the useEffect understand the value change, and start que infinity loop.

**Example below:**
https://codesandbox.io/s/aged-river-ypn7y

**What is the expected behavior?**
Load only one time, because the value undefined not change.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

React Typescript
My react version: `16.8.1`
My react dom version: `16.8.1`
My chrome version: `75.0.3770.142`
""@types/react"": ""16.7.22"",
""@types/react-dom"": ""16.0.11"",

Thanks.",Could you please make a codesandbox repro?,"I force the props checkedItems with undefined, but if e don't pass any props, the useEffect understand the value change, and start que infinity loop.

React Typescript
 version: `16.8.1`
My react dom""@types/react"": ""16.7.22"",
""@types/react-dom"": ""16.0.11"","
facebook/react,https://github.com/facebook/react/issues/17404,facebook_react_issues_17404,"ESLint exhaustive-deps rule should be more consistent about 'Ref' values

**Do you want to request a *feature* or report a *bug*?**

*BUG* - or possibly a misunderstanding about `Ref`s and dependencies

**What is the current behavior?**

Edit: Sandbox here, my pseudo below wasn't exactly accurate: https://codesandbox.io/s/patient-shadow-eswc6

```
export const MyReactFunction = (props) => {
    ...
    const myRef= useRef(null);
    ...
    const myCallback = useCallback((args) => {
        //...
        if (myVal.current === 0) { .... }
        if (props.otherRef.current == null) { ... }
    }, []);
    ...
    myCallback(1);
}
```
Gives ESLint warning:
> React Hook useCallback has missing dependencies: 'myRef' and 'props.otherRef'. Either include them or remove the dependency array.eslint(react-hooks/exhaustive-deps)

**What is the expected behavior?**

Unless I am misunderstanding, there is no reason to include a `Ref` value in the dependency list. If I include a `Ref.current`, I get the message `Mutable values like 'myRef.current' aren't valid dependencies because mutating them doesn't re-render the component.`

Since passing in `myRef` as a dependency is meaningless, and passing in `myRef.current` also provides a warning, I would expect the exhaustive-deps warning to know to not care about `myRef` or any other `Ref` value in the scope in regards to missing dependencies.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

N/A",what `eslint-plugin-react-hooks` version is this? I don't see the same warning. Take a look at this example: https://codesandbox.io/s/admiring-ardinghelli-4uolf,"Edit: Sandbox here, my pseudo below wasn't exactly accurate: https://codesandbox.io/s/patient-shadow-eswc6"
facebook/react,https://github.com/facebook/react/issues/17571,facebook_react_issues_17571,"useEffect, componentWillReceiveProps usage

my script;

When my goal is to change the line,
Clear the selection and update the state lines.
![41617FEA-D822-4C74-B422-A06B10DF20A8](https://user-images.githubusercontent.com/13018803/70597482-888d7500-1bf9-11ea-8860-c4f9396e63e8.jpeg)

Since it enters the console.log (a) at first boot, I need to clear the selection.

**(First Render Console)**
![1645F842-A81A-40B6-AF1F-8FECF9F3C6EE](https://user-images.githubusercontent.com/13018803/70597565-b672b980-1bf9-11ea-8395-64197c21b138.jpeg)

but when I update props.rows,
both lines should be updated, as well as clear the selection.

**(Set Props Render Console)**
![6F215AF6-8E86-4789-B403-8E95FF149D43](https://user-images.githubusercontent.com/13018803/70597621-d73b0f00-1bf9-11ea-9ec7-52384fdd567e.jpeg)

but when I do with callback, the current props.rows are not coming. When the first opening works on.

will not work on first boot. It will only work on line changes. it also needs to arrive up to date line information.

callback does not show the current line information :(

how do i do it like componentWillReceiveProps?

@gaearon 
Why does useEffect work on first boot even though props.rows is connected and props.rows is unchanged? Shouldn't it expect props.rows to change?",can anyone else can explain it? i just wanna the state can be update in time when i setXXX,Why does useEffect work on first boot even though props.rows is connected and props.rows is unchanged? Shouldn't it expect props.rows to change?
facebook/react,https://github.com/facebook/react/issues/18116,facebook_react_issues_18116,"React retains component references to old renders causing browser memory to increase

<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version: 16.12.0
Link to deployed demo app - https://tsjohns9.github.io/react-memory-leak/
Link to demo repo - https://github.com/tsjohns9/react-memory-leak

## The current behavior
React appears to retain references to old renders of components which prevents the browser from running the garbage collector on unused memory.

## The expected behavior
React should release the memory of components from previous renders

## Description
I have a web app that imports an OAS 3/Swagger 2.0 json spec file, and renders the file using the swagger-ui component, https://github.com/swagger-api/swagger-ui.

These json files can be very large. If I upload a file that is 500kb and pass it into the swagger-ui component the heap snapshot in chrome will show about 32.6 MB being used to render the app.

At some point during the lifecycle of this component the spec file may be updated by a user. When this happens the swagger-ui component will re-render. Between re-renders I can see from my heap snapshot that about 15 more mb are added to the heap.

Even if this component is completely unmounted, the memory is still retained and cannot be garbage collected.

I would expect that after a re-render the heap size would be about the same, and the old references would be released for garbage collection.

I have come here with this issue and not swagger-ui because based on the heap snapshots the detached DOM elements are being retained by React directly.

The spec file that I have used is about 500kb. Unfortunately it is a proprietary file and I cannot share it here. Instead, I have provided a spec file from swagger-ui. This file is much smaller, but it will serve the purpose of showing how react is retaining references to old component renders. In my situation since the file is so large this becomes much more apparent to the user that there is a problem than with a much smaller json file.

![Screen Shot 2020-02-24 at 1 17 42 PM](https://user-images.githubusercontent.com/24981281/75188107-c97d2c00-5708-11ea-95dd-7320d75cbf99.png)
![Screen Shot 2020-02-24 at 1 21 30 PM](https://user-images.githubusercontent.com/24981281/75188095-c2eeb480-5708-11ea-9ede-c6f29452dde5.png)

## Steps To Reproduce
1. View the app [here](https://tsjohns9.github.io/react-memory-leak/)
2. Open the console, and take a heap snapshot
3. Press the Update Spec button in the top left of the app, or the Unmount button
4. Take another heap snapshot.
5. You will see that the heap size has increased
6. Compare the two heap sizes and check to see how many new detached objects there are. Here is a screenshot as an example
![Screen Shot 2020-02-24 at 1 26 19 PM](https://user-images.githubusercontent.com/24981281/75188470-6c35aa80-5709-11ea-956b-61022e80fa4b.png)

Link to code example: https://tsjohns9.github.io/react-memory-leak",Does https://github.com/facebook/react/issues/18066 help?,"Link to deployed demo app - https://tsjohns9.github.io/react-memory-leak/
Link to demo repo - https://github.com/tsjohns9/react-memory-leak.github.io.github.io"
eslint/eslint,https://github.com/eslint/eslint/issues/10741,eslint_eslint_issues_10741,"one-var with --fix is adding multiple empty lines between var declarations on keeping on the same line

**Tell us about your environment**

* **ESLint Version:**
v5.2.0

* **Node Version:**
8.11.3

* **npm Version:**
5.6.0

**What parser (default, Babel-ESLint, etc.) are you using?**
default

**Please show your full configuration:**

<details>
<summary>Configuration</summary>

<!-- Paste your configuration below: -->
```json
{
  ""env"": {
    ""browser"": true
  },
  ""extends"": ""eslint:recommended"",
  ""parserOptions"": {
    ""ecmaVersion"": 5
  },
  ""rules"": {
    ""indent"": [""error"", 2],
    ""linebreak-style"": [""error"", ""unix""],
    ""quotes"": [""error"", ""single""],
    ""semi"": [""error"", ""always""],
    ""one-var"": [""error"", ""never""]
  }
}
```

</details>

**What did you do? Please include the actual source code causing the issue, as well as the command that you used to run ESLint.**

<!-- Paste the source code below: -->
**Input A** 
```js
var a = 1, b = 2, c = 3;
```
**Output A** 
```js
var a = 1; var b = 2; var c = 3;
```

**Input B** 
```js
var a = 1, 
  b = 2, 
  c = 3;
```
**Output B** 
```js
var a = 1;
 
    
var b = 2;
 
    
var c = 3;
```

<!-- Paste the command you used to run ESLint: -->
```bash
eslint --quiet --fix src/
```

**What did you expect to happen?**
Do not include multiple lines between variables declaration

**Expected output on both cases** 
```js
var a = 1; 
var b = 2;
var c = 3;
```",Could you clarify which one is the actual output after running `eslint --fix`? Are the other two samples also related to the issue?,"**Input A** 
 A**Input B** 
 B"
eslint/eslint,https://github.com/eslint/eslint/issues/11005,eslint_eslint_issues_11005,"add --list-target-files option

**The version of ESLint you are using.**

5.7.0

**The problem you want to solve.**

I'm working on https://awesomecode.io, our users may not use `eslint` directly on their shell, we have a requirement to list target files so that our users can add ignore patterns properly.

**Your take on the correct solution to problem.**

We can add prefix `DEBUG=eslint:linter` to get target files, but it's very slow and its output contains too many verbose text.

My solution is to add `--list-target-files` option, then it gets all target files without parsing files, so it's super fast. Its output is straightforward, only lists the target filenames.",Does the ability above satisfy your use case?,"our users may not use `eslint` directly on their shell, we have a requirement to list target files so that our users can add ignore patterns properly.

**Your take on the correct solution to problem.**

We can add prefix `DEBUG=eslint:linter` to get target files, but"
eslint/eslint,https://github.com/eslint/eslint/issues/11271,eslint_eslint_issues_11271,"no-magic-numbers ignore default argument

**What rule do you want to change?**
no-magic-numbers

**Does this change cause the rule to produce more or fewer warnings?**
fewer

**How will the change be implemented? (New option, new default behavior, etc.)?**
New Option + added as new default behavior.

**Please provide some example code that this change will affect:**
```
getItemById (id = 0) {
//...
}
```

**What does the rule currently do for this code?**
Show a warning

**What will the rule do after it's changed?**
Not show a warning

**Are you willing to submit a pull request to implement this change?**
Only if I have time. I have no experience with eslint plugin development.

---
Further information:

There should be an option for ignoring default argument values.

The reasoning for this is that id could be thought of as an alias for a constant called DEFAULT_ID.

I have found a duplicate that has been closed for lack of interest.
However, I feel there is no appropriate way of working around this issue. The only alternative would be to stop using default argument values which is not appropriate. Please reconsider.

https://github.com/eslint/eslint/issues/10751","Can you please update your original description using the following template?
https://github.com/eslint/eslint/blob/master/.github/ISSUE_TEMPLATE/RULE_CHANGE.md","What does the rule currently do for this code?
Show a warning

What will the rule do after it's changed?
Not show a warning

Are you willing to submit a pull request to implement this change?
Only if I have time. I have no experience with eslint plugin development.

Further information:

There should be an option for ignoring default argument values."
eslint/eslint,https://github.com/eslint/eslint/issues/11964,eslint_eslint_issues_11964,"CLIEngine addPlugin function not working

<!--
    ESLint adheres to the [JS Foundation Code of Conduct](https://js.foundation/community/code-of-conduct).

    This template is for bug reports. If you are here for another reason, please see below:

    1. To propose a new rule: https://eslint.org/docs/developer-guide/contributing/new-rules
    2. To request a rule change: https://eslint.org/docs/developer-guide/contributing/rule-changes
    3. To request a change that is not a bug fix, rule change, or new rule: https://eslint.org/docs/developer-guide/contributing/changes
    4. If you have any questions, please stop by our chatroom: https://gitter.im/eslint/eslint

    Note that leaving sections blank will make it difficult for us to troubleshoot and we may have to close the issue.
-->

**Tell us about your environment**

* **ESLint Version:** 6.0.1
* **Node Version:** 12.4.0
* **npm Version:** 6.9.0

**What parser (default, Babel-ESLint, etc.) are you using?**
Default

**Please show your full configuration:**

<details>
<summary>Configuration</summary>

<!-- Paste your configuration below: -->
```js
{
    ""parserOptions"": {
        ""ecmaFeatures"": {
            ""jsx"": true
        }
    },
    ""globals"": {
        ""createReactClass"": true
    },
    ""plugins"": [""react""],
    ""extends"": [""plugin:react/recommended""],
    ""rules"": {
        ""react/jsx-wrap-multilines"": [
            ""error"", {
                ""declaration"": ""parens-new-line"",
                ""assignment"": ""parens-new-line"",
                ""return"": ""parens-new-line"",
                ""arrow"": ""parens-new-line"",
                ""condition"": ""parens-new-line"",
                ""logical"": ""parens-new-line"",
                ""prop"": ""parens-new-line""
            }
        ]
    }
}
```

</details>

**What did you do? Please include the actual source code causing the issue, as well as the command that you used to run ESLint.**

I'm trying to merge a PR that updates our ESLint dependency from 5.x to 6.x.  However, a test that adds react-eslint-plugin and formats React does not pass.  If I add it via the `plugins` string array in the CLIEngine options it runs.  PR I'm referring to is:  https://github.com/Unibeautify/beautifier-eslint/pull/142.

I tried debugging, and the best I can tell `additionalPluginPool` isn't used in the relevant functions (mainly executeOnText()).

<!-- Paste the source code below: -->
```js
      const cliOptions: CLIOptions = {
        baseConfig: {
          extends: extendsToAdd,
          globals: globals,
        },
        fix: true,
        parserOptions: parseOpts,
        rules: finalOptions,
        useEslintrc: false,
      };
      const cli: CLIEngine = new CLIEngine(cliOptions);
      cli.addPlugin(""react"", reactPlugin.package);
      const report: LintReport = cli.executeOnText(text);
      const result: LintResult = report.results[0];
```

<!-- Paste the command you used to run ESLint: -->
```bash

```

**What did you expect to happen?**
The plugin be used when added via addPlugin

**What actually happened? Please include the actual, raw output from ESLint.**
I don't see it using the plugin.

**Are you willing to submit a pull request to fix this bug?**
If I need to","What do you use the config?
If your config doesn't have `plugins: [""react""]`, the config cannot use `react/*` rules.","{
    ""parserOptions"": {
        ""ecmaFeatures"": {
            ""jsx"": true
        }
    },
    ""globals"": {
        ""createReactClass"": true
    },
    ""plugins"": [""react""],
    ""extends"": [""plugin:react/recommended""],
    ""rules"": {
        ""react/jsx-wrap-multilines"": [
            ""error"", {
                ""declaration"": ""parens-new-line"",
                ""assignment"": ""parens-new-line"",
                ""return"": ""parens-new-line"",
                ""arrow"": ""parens-new-line"",
                ""condition"": ""parens-new-line"",
                ""logical"": ""parens-new-line"",
                ""prop"": ""parens-new-line""
            }
        ]
    }
}"
eslint/eslint,https://github.com/eslint/eslint/issues/12160,eslint_eslint_issues_12160,"require-atomic-updates bug

**Tell us about your environment**

* **ESLint Version:** 6.2.2
* **Node Version:** 10.16.0
* **npm Version:** 6.9.0

**What parser (default, Babel-ESLint, etc.) are you using?**
typescript-eslint-parser but it doesn't work with the default parser as well

**Please show your full configuration:**

[ESLint Playground Link](https://eslint.org/demo#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)

**What did you do? Please include the actual source code causing the issue, as well as the command that you used to run ESLint.**

<!-- Paste the source code below: -->
```js
const { readFile } = require('fs')

async function getValue() {
  return 3
}

async function foo(filePath, lastModifiedTime) {
  if (lastModifiedTime === undefined) {
    const value = await getValue()
    lastModifiedTime = value
  }

  readFile(filePath, () => {
    const modifiedTime = lastModifiedTime || 3

    // ...do something with modifiedTime

    return modifiedTime
  })

  return lastModifiedTime
}

foo('/Users/current/.gitconfig')

```

**What did you expect to happen?**

Not to show an error


**What actually happened? Please include the actual, raw output from ESLint.**

Shows an error that I don't think is valid.


**Are you willing to submit a pull request to fix this bug?**

I am not familiar with ESLint codebase, so no.",Do you have a minimal repro case that you might be able to share?,"// ...do something with modifiedTime

    '/Users/current/.gitconfig'"
HaxeFoundation/haxe,https://github.com/HaxeFoundation/haxe/issues/9083,HaxeFoundation_haxe_issues_9083,"[jvm] Crash when printing an enum

Minimal example of the bug:

```haxe
enum Foo {
    Bar;
}

class Main {
    static public function main () {
        trace(Bar.getName()); // works
        trace(Bar); // crash
    }
}
```

Running `haxe -main Main -java bin/java -D jvm && java -jar ./bin/java/Main.jar` results in the following output:

```
Main.hx:8: Bar
Exception in thread ""main"" java.lang.NullPointerException
	at haxe.root.Type.getEnumConstructs(/Users/nissen/haxe/versions/4.0.0/std/jvm/_std/Type.hx)
	at haxe.jvm.Enum.toString(/Users/nissen/haxe/versions/4.0.0/std/jvm/Enum.hx)
	at haxe.jvm.Jvm.toString(/Users/nissen/haxe/versions/4.0.0/std/jvm/Jvm.hx)
	at haxe.root.Std.string(/Users/nissen/haxe/versions/4.0.0/std/jvm/_std/Std.hx)
	at haxe.Log.formatOutput(/Users/nissen/haxe/versions/4.0.0/std/haxe/Log.hx)
	at haxe.Log.hx_closure$0(/Users/nissen/haxe/versions/4.0.0/std/haxe/Log.hx)
	at java.lang.invoke.MethodHandle.invokeWithArguments(MethodHandle.java:627)
	at haxe.jvm.Jvm.call(/Users/nissen/haxe/versions/4.0.0/std/jvm/Jvm.hx)
	at haxe.root.Main.main(Main.hx)
	at haxe.root.Main.main(Main.hx)
```

`haxe -main Main --interp` produces the expected output:
```
Main.hx:8: Bar
Main.hx:9: Bar
```

I'm using Haxe 4.0.5 through `lix`. Why the path points to `haxe/versions/4.0.0/std/...` I don't know.",Could you try upgrading? :),I'm using Haxe 4.0.5 through `lix`. Why the path points to `haxe/versions/4.0.0/std/...` I don't know.
doxygen/doxygen,https://github.com/doxygen/doxygen/issues/7761,doxygen_doxygen_issues_7761,"Two java files in same name are merged into a same class_XXX.xml

**Describe the bug**
<!--
Describe what you see that (you think) is wrong.
-->
When I parsed a java project , I got a file named classorg_1_1mozilla_1_1focus_1_1web_1_1_web_view_provider.xml , there are two functions whose name is ""preload"" and their id is same.  The java project zip file is attached in this issue.
[refs-tags-v6.0-RC1-error.zip](https://github.com/doxygen/doxygen/files/4593259/refs-tags-v6.0-RC1-error.zip)

**Expected behavior**
<!--
Describe what you would have expected or think is correct.
-->
The two function belong to two different classes with same name, and two different class_XX.xml files should be generated. But only one class_xx.xml is generated and two class are merged.
<!--
**Screenshots**
If useful, add screenshots to help explain your problem.

**To Reproduce**
Attach a self contained example that allows us to reproduce the problem.
Such an example typically exist of some source code (can be dummy code) and a doxygen configuration file used (you can strip it using `doxygen -s -u`). After you verified the example demonstrates the problem, put it in a zip (or tarball) and attach it to the bug report. Try to avoid linking to external sources, since they might disappear in the future.
-->
**Version**
<!--
Mention the version of doxygen used (output of `doxygen --version`) and the platform on which you run doxygen (e.g. Windows 10, 64 bit). If you run doxygen under Linux please also mention the name and version of the distribution used (output of `lsb_release -a`) and mention if you compiled doxygen yourself or that you use a binary that comes with the distribution or from the doxygen website.  
-->
1.8.16

<!--
**Stack trace**
If you encounter a crash and can build doxygen from sources yourself with debug info (`-DCMAKE_BUILD_TYPE=Debug`), a stack trace can be very helpful (especially if it is not possible to capture the problem in a small example that can be shared).

**Additional context**
Add any other context about the problem here.
-->","Can you please provide the doxygen configuration file as well?
(currently there are only 2 java files in a directory structure)","<!--
--><!--
--><!--
-->
<!---->
<!---->"
doxygen/doxygen,https://github.com/doxygen/doxygen/issues/7714,doxygen_doxygen_issues_7714,"Parsing C++ string default arguments fails

e.g.
```cpp
/** @addtogroup Test
*  @{
*/

/**
@param str
@param delims
@param maxSplits
*/
void tokenise(const char* str, const char* delims = ""\"""", int maxSplits = 0);

/**
@param buf
@param maxCount
@param delim
*/
void readLine(char* buf, int maxCount, const char* delim = ""\n"");

/** @} */
```
->
```
test.cpp:5: warning: argument 'delims' of command @param is not found in the argument list of tokenise(const char *str)
test.cpp:5: warning: argument 'maxSplits' of command @param is not found in the argument list of tokenise(const char *str)
test.cpp:12: warning: argument 'delim' of command @param is not found in the argument list of readLine(char *buf, int maxCount)
```
and neither shows up in the HTML docs.",Could you please attach a complete example (source+config file in a tar or zip) and mention the version of doxygen you are using?,"/** @addtogroup Test
*  @{
*/

/** @} */
test.cpp:5: warning: argument 'delims' of command @param is not found in the argument list of tokenise(const char *str)
test.cpp:5: (const char *str)"
wordpress-mobile/WordPress-iOS,https://github.com/wordpress-mobile/WordPress-iOS/issues/11650,wordpress-mobile_WordPress-iOS_issues_11650,"Open a post with a remote auto-save, app must show a dialog asking to restore it

When a user opens a published post with a remote auto-save, we must show a dialog “A more recent revision of this post exists. Restore?”. Like in Calypso:

<img width=""422"" alt=""screenshot-2019-05-03-at-09 25 19"" src=""https://user-images.githubusercontent.com/40213/57301854-3a9c1600-70da-11e9-8b51-caace0fe6d33.png"">

## Decision
we are splitting this from the discussion on [conflict resolution](https://github.com/wordpress-mobile/WordPress-Android/issues/10008).

**Implementation logic:**
hasLocalChanges == true -> ignore autosave and just open the post
hasLocalChanges == false && post.autosave == null -> just open the post
hasLocalChanges == false && post.autosave != null -> open the post and show the dialog. If the user clicks on restore, load the autosave revision and set hasLocalChanges to true.

```
The service to query the latest autosave for a post is:
GET https://public-api.wordpress.com/rest/v1.1/sites/$site_id/posts/$post_id/autosave
```

## Corresponding Android Ticket

https://github.com/wordpress-mobile/WordPress-Android/issues/9812","Maybe the message could be something like: ""There's an autosave, want to restore it?""?","Decision
we are splitting this from the discussion on [conflict resolution](https://github.com/wordpress-mobile/WordPress-Android/issues/10008).

**Implementation logic:**
hasLocalChanges == true -> ignore autosave and just open the post
hasLocalChanges == false && post.autosave == null -> just open the post
hasLocalChanges == false && post.autosave != null -> open the post and show the dialog. If the user clicks on restore, load the autosave revision and set hasLocalChanges to true.

```
The service to query the latest autosave for a post is:
GET https://public-api.wordpress.com/rest/v1.1/sites/$site_id/posts/$post_id/autosave
```

##"
centreon/centreon,https://github.com/centreon/centreon/issues/7310,centreon_centreon_issues_7310,"Graphs: strange char & missing dates in exports

Hi,

There are 2 issues with exported graphs, see the example below :
- a strange `\l` character is visible in the last line of the legend ;
- From / to dates are missing / empty.

![tools-sys-cpu](https://user-images.githubusercontent.com/40244829/54745988-4fc0f200-4bcb-11e9-8f56-d0ebd31d170d.png)

Thank you 👍 

Edit : please see #7316 for a fix.

Edit : issue still present in 19.04.3.","Do you have this issue on all the graphs, or only this one ?

Regards,","please see #7316 for a fix.

Edit :"
SeleniumHQ/selenium,https://github.com/SeleniumHQ/selenium/issues/6835,SeleniumHQ_selenium_issues_6835,"firefox.Options. setPreference() not a function

## 🐛 Bug Report
Hi, I've been referencing  [this](https://seleniumhq.github.io/selenium/docs/api/javascript/module/selenium-webdriver/firefox.html) docs, wich seams incorrect.

I've been trying to set the firefox driver path, but when testing  i've come across this:

It says in the [`firefox.Options`](https://seleniumhq.github.io/selenium/docs/api/javascript/module/selenium-webdriver/firefox_exports_Options.html) docs that a method called  `.setPreference(key, value)` exists but when called it says it is not defined. 

Are they intended to exist? Or is that docs outdated?

If so where could I find info in how to set the driver path?

_PD: I can attach more info if needed!_

## Environment
OS:  Windows 8
Browser: Firefox
Browser version: 63.0.1 (32-bit)
Browser Driver version: 0.23.0

EDIT:
I'm using version: `3.6.0` of selenium-webdriver",Which command are you after?,"EDIT:
I'm using version: `3.6.0` of selenium-webdriver"
SeleniumHQ/selenium,https://github.com/SeleniumHQ/selenium/issues/7023,SeleniumHQ_selenium_issues_7023,"Unable to install selenium server standalone 3.8.0

## 🐛 Bug Report

I started having problem when installing selenium-server-standalone-3.8.0.jar from npm this afternoon. Can someone help, please?

## To Reproduce
We are pulling selenium-server-standalone from npm and install to local and aws instance with a clean build, which mean no node_modules folder. Below is the error
> selenium-standalone installation starting
> 
> selenium install:
> from: https://selenium-release.storage.googleapis.com/3.8/selenium-server-standalone-3.8.0.jar
> to: /Users/weiming.chen/Projects/AD-PracticeOnline-Automation-Tests/node_modules/selenium-standalone/.selenium/selenium-server/3.8.0-server.jar
> 
> chrome install:
> from: https://chromedriver.storage.googleapis.com/2.37/chromedriver_mac64.zip
> to: /Users/weiming.chen/Projects/AD-PracticeOnline-Automation-Tests/node_modules/selenium-standalone/.selenium/chromedriver/2.37-x64-chromedriver
> 
> firefox install:
> from: https://github.com/mozilla/geckodriver/releases/download/v0.23.0/geckodriver-v0.23.0-macos.tar.gz
> to: /Users/weiming.chen/Projects/AD-PracticeOnline-Automation-Tests/node_modules/selenium-standalone/.selenium/geckodriver/0.23.0-x64-geckodriver
> /Users/weiming.chen/Projects/AD-PracticeOnline-Automation-Tests/node_modules/selenium-standalone/bin/selenium-standalone:111
>         throw err;
>         ^
> 
> Error: Could not download https://selenium-release.storage.googleapis.com/3.8/selenium-server-standalone-3.8.0.jar
>     at Request.<anonymous> (/Users/weiming.chen/Projects/AD-PracticeOnline-Automation-Tests/node_modules/selenium-standalone/lib/install.js:373:21)
>     at emitOne (events.js:116:13)
>     at Request.emit (events.js:211:7)
>     at Request.onRequestResponse (/Users/weiming.chen/Projects/AD-PracticeOnline-Automation-Tests/node_modules/request/request.js:1066:10)
>     at emitOne (events.js:116:13)
>     at ClientRequest.emit (events.js:211:7)
>     at HTTPParser.parserOnIncomingClient [as onIncoming] (_http_client.js:551:21)
>     at HTTPParser.parserOnHeadersComplete (_http_common.js:117:23)
>     at TLSSocket.socketOnData (_http_client.js:440:20)
>     at emitOne (events.js:116:13)

## Environment

OS: <!-- Windows 10, OSX, Linux -->
Browser Driver version: <!-- e.g.: ChromeDriver 2.43, GeckoDriver 0.23 -->","Can you download it on your machine from your browser?
https://selenium-release.storage.googleapis.com/3.8/selenium-server-standalone-3.8.0.jar","with a clean build, which mean no node_modules folder"
Semantic-Org/Semantic-UI,https://github.com/Semantic-Org/Semantic-UI/issues/6575,Semantic-Org_Semantic-UI_issues_6575,"Dropdown on iOS's focus cursor should remain situated in the focused input, but is moving out of the focused input.

### Dropdown on iOs 's focus cursor should remain situated in the focused input.

### Steps
1. use the dropdown as normally you would do in iOs
2. Its broken.

### Expected Result
1. the cursor does not 'fly out' of the input vertically

### Actual Result
2. the cursor really does 'fly out' of the input vertically
![image](https://user-images.githubusercontent.com/954596/45454337-20c04580-b6a9-11e8-9aa7-231f6402c9ce.png)
### Version
2.3.1

### Testing
The semantic ui dropdown is confirmed as working as expected on the following

- the IOS simulator inside of Xcode (all versions of ios in the simulator)
- an Ipad running safari
- All browsers I tested (even IE)
- Android (Tested on an edge 6 plus as well as a Note 9, actual hardware not simulator)

it DOES NOT CORRECTLY work on

- Iphone 7and  Iphone 7 plus",Can you create a [JSFiddle ](https://jsfiddle.net/ca0rovs3/) to replicate the issue?,"(all versions of ios in the simulator))
- Android (Tested on an edge 6 plus as well as a Note 9, actual hardware not simulator"
Semantic-Org/Semantic-UI,https://github.com/Semantic-Org/Semantic-UI/issues/6726,Semantic-Org_Semantic-UI_issues_6726,"Specify working version of gulp in peerDependencies

### Steps
1. npm install gulp@4.0.0
2. npm install semantic-ui@2.4.2

### Expected Result
Setup runs without errors

### Actual Result
Setup quits with error message `TypeError: gulp.hasTask is not a function`

### Version
gulp@4.0.0
semantic-ui@2.4.2

Currently the version of gulp specified in Semantic's peerDependencies is '*'. I suggest we fix it to a version that is tested and works with semantic-ui (e.g. 3.9.1), since newer versions of gulp can introduce breaking changes, like 4.0.0 did. This would provide a friendly warning/indication about which version of gulp should be installed as a peer dep when installing semantic-ui.","Does SUI even support Gulp 4? I remember having trouble using it with FUI some time ago, but I believe it's been added by now.",This would provide a friendly warning/indication about which version of gulp should be installed as a peer dep when installing semantic-ui.
TryGhost/Ghost,https://github.com/TryGhost/Ghost/issues/10230,TryGhost_Ghost_issues_10230,"[route] collection filters do not apply correctly on /:

Hello folks!

I'm following [from this conversation in the forum](https://forum.ghost.org/t/collection-filters-works-well-on-the-homepage-but-breaks-under-tags-section/4273/3?u=pascalandy). My goal is to filter out some tags from the Ghost’s homepage.

### EDIT: Little hack

[For now, this works](https://github.com/TryGhost/Ghost/issues/10230#issuecomment-444264911)

### Issue
I’m applying this yaml but no filtering occurs on https://mysite.com/en/
**EDIT**: The result in my case, is that those tags ([how-to, about, under-the-hood]) do still appears in Ghost’s homepage.

To be clear about my domains:
- https://mysite.com/ is served by Caddy (static pages)
- https://mysite.com/en/ is served by Ghost

```
# filters out few tags from Ghost's homepage
routes:
  /:
    controller: channel
    filter: tag:-[how-to,about,under-the-hood]

# redefine the collections as I we can't define /: twice
collections:
  /archive/:
    permalink: /{slug}/
    template:
      - index

# default values
taxonomies:
  tag: /tag/{slug}/
  author: /author/{slug}/
```

### Technical details:

* Ghost Version: 2.1.1
* CLI version: 1.9.4
* Node Version: 10.14.10
* Browser/OS: chrome 66, osx 10.13.4
* Server-side: Alpine:3.8 in Docker [using this image](https://travis-ci.org/firepress-org/ghostfire/branches)
* Database: sqlite","Could you please describe the behaviour you see?

Thanks :)","**EDIT**: I mean the posts with those tag ([how-to, about, under-the-hood]) still appears in Ghost’s homepage."
TryGhost/Ghost,https://github.com/TryGhost/Ghost/issues/9956,TryGhost_Ghost_issues_9956,"Duplicated entries in /sitemap-pages.xml after uploading routes.yaml

### Issue Summary [EDITED]

**NOTE:** After a couple tests, @kirrg001 figured out this only happens when you upload your `routes.yaml` file through the admin. There is a way to fix it, if you restart your ghost server after uploading the routes file.

Using the multi-language feature (dynamic routing), it creates duplicated records on the `/sitemap-pages.xml` file (see image)

![Imgur](https://i.imgur.com/Rb4O7ay.png)

### To Reproduce

Using this `routes.yaml` file:
```
routes:

collections:
  /:
    permalink: /{slug}/
    filter: 'tag:-[en,es]'
    template:
      - index
  /en/:
    permalink: /en/{slug}/
    filter: 'tag:en'
  /es/:
    permalink: /es/{slug}/
    filter: 'tag:es'

taxonomies:
  tag: /tag/{slug}/
  author: /author/{slug}/
```

### Technical details:

* Ghost Version: 2.2.0 
* Node Version: v8.12.0
* Browser/OS: Chrome 69.0.3497.100 / MacOS High Sierra
* Database: MySQL",Could you please update your filters and report back? Thanks!,"[EDITED]

**NOTE:** After a couple tests, @kirrg001 figured out this only happens when you upload your `routes.yaml` file through the admin. There is a way to fix it, if you restart your ghost server after uploading the routes file."
mapbox/mapbox-gl-js,https://github.com/mapbox/mapbox-gl-js/issues/7893,mapbox_mapbox-gl-js_issues_7893,"Synchronous redraw API

## Motivation

In react-map-gl, when the viewport updates, we call `Map.jumpTo()` inside `componentDidUpdate()`, which schedules a Mapbox rerender in the next animation frame. This causes the canvas rerender to always occur one step behind the React updates.

You can see this issue in https://github.com/uber/react-map-gl/pull/720 and https://github.com/uber/deck.gl/issues/2458.

## Design

Provide a synchronous API e.g. `redraw()` that immediately flushes the dirty state.

### Implementation

Here's how we are currently forcing rerender:

```js
// map render will throw error if style is not loaded
if (map.style) {
  // cancel the scheduled update
  if (map._frame) {
    map._frame.cancel();
    map._frame = null;
  }
  map._render();
}
```

Private methods and properties are manipulated here, which is not a reliable solution.","does `triggerRepaint()` address this need? 

https://docs.mapbox.com/mapbox-gl-js/api/#map#triggerrepaint","// cancel the scheduled update
  if ("
mapbox/mapbox-gl-js,https://github.com/mapbox/mapbox-gl-js/issues/8041,mapbox_mapbox-gl-js_issues_8041,"Numbers and symbols mixed with CJK text are misaligned

<!--
Hello! Thanks for contributing.

The answers to many ""how do I...?"" questions can be found in our [help documentation](https://mapbox.com/help). If you can't find the answer there, the best place to ask is either [Stack Overflow](https://stackoverflow.com/questions/tagged/mapbox-gl-js) or [Mapbox support](https://mapbox.com/contact/).

However, if you have a question that isn't addressed in the documentation but should be, please do let us know by filling out the template below!  As a general rule, if a question is about _how Mapbox GL JS works_ rather than your specific use case, we will try to address it here or by improving the documentation.  Otherwise, we might close the issue here and instead recommend asking on Stack Overflow or contacting support.

-->

**mapbox-gl-js version**:
master branch

### Question
I upgraded mapbox-gl-js version to master from 0.50.0. Texts including unicode, number were displaying alright but with master.

with v0.50.0 (also okay with v0.53.1)
![image](https://user-images.githubusercontent.com/7428017/54415171-cdee4600-473e-11e9-8d93-a76700ccad2a.png)

with master
![image](https://user-images.githubusercontent.com/7428017/54415203-e9595100-473e-11e9-81de-eb70c63acc0b.png)

Texts' font looks a bit different and the vertical positions are different between special characters/numbers and unicode string.

I have checked its style from layer info, it sets the same properties.
Any changes made on the text-fields since v0.53.1? so I can modify the part of causing this issue.

p.s. the reason why I tried to upgrade was https://github.com/mapbox/mapbox-gl-js/issues/7614


Thanks.",Can you provide us with a minimal reproducible live test case for this? We'll bisect to the offending commit.,"master from 0.50.0. Texts including unicode, number were displaying alright but with master.

with v0.50.0 (also okay with v"
mapbox/mapbox-gl-js,https://github.com/mapbox/mapbox-gl-js/issues/8635,mapbox_mapbox-gl-js_issues_8635,"Prevent small GeoJSON line features from disappearing at low zoom levels

## Motivation

<!--
What problem are we trying to solve?  Please link any relevant issues.
What use cases are we trying to accommodate?

Focus on the problem and save design ideas for the next section.
-->
For features in a line layer, when zoomed out past a certain point (guessing when lines reach ~1 px or less in length), the lines disappear entirely, even if they have a width and rounded endcaps.

For many use cases, such as showing a highlight for particular features, we would still like to be able to see that these features are present, as it's misleading otherwise.

## Design Alternatives

<!--
How could we accommodate the use cases above?
Is ""do nothing"" an option?
-->
Rendering the endcaps of the line would solve the visibility problem, showing a circle or a square instead of nothing.
For compatibility with the existing behavior (which is desired behavior for other use cases),
an opt-in layout property could be used to enable this. 

Not sure about naming or implementation as I'm not an expert on the codebase, although I could certainly look into it :)",Can you make a test case showing what you're describing? a 1px line _should_ still be visible.,"Edit: The real issue was GeoJSON simplification leading to short line features being simplified to 0 size at low zoom level.

This can be effectively disabled by setting the `tolerance` property on the source to a very small number (like 0.000001).  

(A tolerance of 0 results in no features being rendered)"
wordpress-mobile/WordPress-Android,https://github.com/wordpress-mobile/WordPress-Android/issues/9568,wordpress-mobile_WordPress-Android_issues_9568,"Offline Support: Local drafts aren't synched when going back online.

## Description

Local drafts with changes aren’t uploaded to the server after a connection is re-established

Opening and closing the post or pulling to refresh the post list don't force the post to sync either.

There's also no ""Update"" action when going into posts that were created while offline.

## Matching iOS issue

https://github.com/wordpress-mobile/WordPress-iOS/issues/11449

## Tracking

| Description | Status | 
|--------|-------|
| <p>**Syncing after leaving Editor.** <p>After creating a new post while offline. When you come back online and open the post, then back out of the post, the local changes are not synced.</p><p><img src=""https://user-images.githubusercontent.com/161697/56057592-0b30fe00-5d14-11e9-90d5-2192e6688b0e.gif"" width=""240"">   | ❓Could not reproduce anymore. |
| <p>**Swipe to refresh.**<p>In this gif, local changes were saved while offline and I expected pull to refresh to start syncing the changes: <p><img src=""https://user-images.githubusercontent.com/161697/56057132-f0aa5500-5d12-11e9-9deb-1beca98de612.gif"" width=""240""> | ✔️ Done in #9774 | 
| <p>**Different Editor actions.**<p>And this gif might be a new issue. Notice how both of these posts are drafts, but they have different actions in the editor (Publish vs Update).<p><img src=""https://user-images.githubusercontent.com/161697/56057705-59de9800-5d14-11e9-825b-a47cfb099f17.gif"" width=""240""> | ✔️Will be handled in #9612  |
| **Auto-upload for Pages**. | ✔️ Will be handled in #9851 |
| <p>**Media in draft posts do not get automatically uploaded**.<p>Tapping the _Retry_ button after works though.<p><img width=""240"" src=""https://user-images.githubusercontent.com/198826/57093331-cb35b900-6cca-11e9-93a1-b0c9e07729a9.gif""> | ✔️Will be handled in #9804 | 
| <p>**Auto-upload of Local Changes**.<p>| ✔️ Will be handled in #9846  |","Do we have an issue created for iOS? Can't seem to find it. 

<img src=""https://user-images.githubusercontent.com/198826/55907467-13fac600-5b94-11e9-83fd-2019b2c147ca.gif"" width=""320"" />",aren’t uploaded to the server after a connection is re
netdata/netdata,https://github.com/netdata/netdata/issues/3844,netdata_netdata_issues_3844,"Ubuntu Minimal 18.04 - Netdata Will Not Start

NETDATA isn't correctly starting. I read down and it seems not to bind correctly to localhost. 

Can someone with more experience please help me out? Many thanks! This is a clean OS and it's not working, strange. 

<details>
<summary>click for log</summary>

```
2018-06-18 21:25:20: netdata INFO  : MAIN : resources control: allowed file descriptors: soft = 1024, max = 1048576
2018-06-18 21:25:20: netdata INFO  : MAIN : Adjusted my Out-Of-Memory (OOM) score from 0 to 1000.
2018-06-18 21:25:20: netdata INFO  : MAIN : Adjusted netdata scheduling policy to idle (5), with priority 0.
2018-06-18 21:25:20: netdata INFO  : MAIN : netdata started on pid 1726.
2018-06-18 21:25:20: netdata ERROR : MAIN : HEALTH [VM-Hosting]: cannot open health file: /var/lib/netdata/health/health-log.db.old (errno 2, No such file or directory)
2018-06-18 21:25:20: netdata INFO  : MAIN : Host 'VM-Hosting' (at registry as 'VM-Hosting') with guid '7f631292-7334-11e8-9143-000c29881913' initialized, os 'linux', timezone 'Europe/London', tags '', program_name 'netdata', program_version '1.10.1_rolling', update every 1, memory mode save, history entries 3996, streaming disabled (to '' with api key ''), health enabled, cache_dir '/var/cache/netdata', varlib_dir '/var/lib/netdata', health_log '/var/lib/netdata/health/health-log.db', alarms default handler '/usr/libexec/netdata/plugins.d/alarm-notify.sh', alarms default recipient 'root'
2018-06-18 21:25:20: netdata INFO  : PLUGIN[proc] : thread created with task id 1731
2018-06-18 21:25:20: netdata INFO  : PLUGIN[tc] : thread created with task id 1734
2018-06-18 21:25:20: netdata INFO  : PLUGINSD : thread created with task id 1738
2018-06-18 21:25:20: netdata INFO  : PLUGIN[cgroup] : thread created with task id 1733
2018-06-18 21:25:20: netdata INFO  : PLUGIN[idlejitter] : thread created with task id 1735
2018-06-18 21:25:20: netdata INFO  : BACKENDS : thread created with task id 1736
2018-06-18 21:25:20: netdata INFO  : STATSD : thread created with task id 1742
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : thread created with task id 1732
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : thread created with task id 1739
2018-06-18 21:25:20: netdata INFO  : MAIN : netdata initialization completed. Enjoy real-time performance monitoring!
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : starting worker 2
2018-06-18 21:25:20: netdata INFO  : HEALTH : thread created with task id 1737
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[node.d] : thread created with task id 1744
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : starting worker 3
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static2] : thread created with task id 1745
2018-06-18 21:25:20: netdata INFO  : BACKENDS : cleaning up...
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static2] : POLLFD: LISTENER: listening on 'tcp:127.0.0.1:19999'
2018-06-18 21:25:20: netdata INFO  : BACKENDS : thread with task id 1736 finished
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[charts.d] : thread created with task id 1743
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : starting worker 4
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[fping] : thread created with task id 1749
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static3] : thread created with task id 1748
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : starting worker 5
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[node.d] : connected to '/usr/libexec/netdata/plugins.d/node.d.plugin' running on pid 1747
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[fping] : connected to '/usr/libexec/netdata/plugins.d/fping.plugin' running on pid 1752
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static4] : thread created with task id 1751
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[charts.d] : connected to '/usr/libexec/netdata/plugins.d/charts.d.plugin' running on pid 1750
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static4] : POLLFD: LISTENER: listening on 'tcp:127.0.0.1:19999'
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[python.d] : thread created with task id 1754
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static3] : POLLFD: LISTENER: listening on 'tcp:127.0.0.1:19999'
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[python.d] : connected to '/usr/libexec/netdata/plugins.d/python.d.plugin' running on pid 1755
2018-06-18 21:25:20: netdata ERROR : PLUGINSD : cannot open plugins directory '/etc/netdata/custom-plugins.d' (errno 2, No such file or directory)
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : thread created with task id 1757
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : starting worker 6
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : connected to '/usr/libexec/netdata/plugins.d/apps.plugin' running on pid 1758
2018-06-18 21:25:20: netdata INFO  : STATSD_COLLECTOR[1] : thread created with task id 1767
2018-06-18 21:25:20: netdata INFO  : STATSD_COLLECTOR[1] : STATSD collector thread started with taskid 1767
2018-06-18 21:25:20: netdata INFO  : STATSD_COLLECTOR[1] : POLLFD: LISTENER: listening on 'udp:[::1]:8125'
2018-06-18 21:25:20: netdata INFO  : STATSD_COLLECTOR[1] : POLLFD: LISTENER: listening on 'udp:127.0.0.1:8125'
2018-06-18 21:25:20: netdata INFO  : STATSD_COLLECTOR[1] : POLLFD: LISTENER: listening on 'tcp:[::1]:8125'
2018-06-18 21:25:20: netdata INFO  : STATSD_COLLECTOR[1] : POLLFD: LISTENER: listening on 'tcp:127.0.0.1:8125'
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : POLLFD: LISTENER: listening on 'tcp:127.0.0.1:19999'
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.statsd_useful_metrics/main.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.statsd_useful_metrics/gauges.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static6] : thread created with task id 1768
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static6] : POLLFD: LISTENER: listening on 'tcp:127.0.0.1:19999'
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.statsd_useful_metrics/counters.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.statsd_useful_metrics/timers.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.statsd_useful_metrics/meters.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.statsd_useful_metrics/histograms.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static5] : thread created with task id 1756
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static5] : POLLFD: LISTENER: listening on 'tcp:127.0.0.1:19999'
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.statsd_useful_metrics/sets.db.
2018-06-18 21:25:20: apps.plugin INFO  : MAIN : started on pid 1758
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.tcp_connects/main.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.tcp_connects/connects.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.tcp_connects/disconnects.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.tcp_connected/main.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.tcp_connected/connected.db.
2018-06-18 21:25:20: tc-qos-helper.sh: WARNING: FireQoS is not installed on this system. Use FireQoS to apply traffic QoS and expose the class names to netdata. Check https://github.com/firehol/netdata/wiki/You-should-install-QoS-on-all-your-servers
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.plugin_statsd_charting_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.plugin_statsd_charting_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.plugin_statsd_charting_cpu/system.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.plugin_statsd_collector1_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.plugin_statsd_collector1_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : STATSD : Initializing file /var/cache/netdata/netdata.plugin_statsd_collector1_cpu/system.db.
2018-06-18 21:25:20: fping.plugin: FATAL: no hosts configured in '/etc/netdata/fping.conf' - nothing to do.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[fping] : called DISABLE. Disabling it.
2018-06-18 21:25:20: netdata ERROR : PLUGINSD[fping] : '/usr/libexec/netdata/plugins.d/fping.plugin' (pid 1752) disconnected after 0 successful data collections (ENDs).
2018-06-18 21:25:20: netdata ERROR : PLUGINSD[fping] : child pid 1752 exited with code 1.
2018-06-18 21:25:20: netdata ERROR : PLUGINSD[fping] : '/usr/libexec/netdata/plugins.d/fping.plugin' (pid 1752) exited with error code 1. Disabling it.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[fping] : thread with task id 1749 finished
2018-06-18 21:25:20: charts.d: INFO: main: started from '/usr/libexec/netdata/plugins.d/charts.d.plugin' with options: 1
2018-06-18 21:25:20: charts.d: INFO: apache: is disabled. Add a line with apache=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: cpu_apps: is disabled. Add a line with cpu_apps=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: cpufreq: is disabled. Add a line with cpufreq=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: example: is disabled. Add a line with example=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: exim: is disabled. Add a line with exim=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: hddtemp: is disabled. Add a line with hddtemp=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: load_average: is disabled. Add a line with load_average=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: mem_apps: is disabled. Add a line with mem_apps=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: mysql: is disabled. Add a line with mysql=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: nginx: is disabled. Add a line with nginx=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: phpfpm: is disabled. Add a line with phpfpm=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: postfix: is disabled. Add a line with postfix=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: sensors: is disabled. Add a line with sensors=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: squid: is disabled. Add a line with squid=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: INFO: tomcat: is disabled. Add a line with tomcat=force in /etc/netdata/charts.d.conf to enable it (or remove the line that disables it).
2018-06-18 21:25:20: charts.d: ERROR: ap: no devices found in AP mode, with 'iw dev'
2018-06-18 21:25:20: charts.d: ERROR: ap: module's 'ap' check() function reports failure.
2018-06-18 21:25:20: charts.d: WARNING: apcupsd: command 'apcaccess' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2018-06-18 21:25:20: charts.d: ERROR: apcupsd: module's 'apcupsd' check() function reports failure.
2018-06-18 21:25:20: charts.d: WARNING: libreswan: command 'ipsec' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2018-06-18 21:25:20: charts.d: ERROR: libreswan: module's 'libreswan' check() function reports failure.
2018-06-18 21:25:20: charts.d: WARNING: nut: command 'upsc' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2018-06-18 21:25:20: charts.d: ERROR: nut: module's 'nut' check() function reports failure.
2018-06-18 21:25:20: charts.d: WARNING: opensips: command 'opensipsctl' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2018-06-18 21:25:20: python.d INFO: plugin: main: Using python 2
2018-06-18 21:25:20: charts.d: ERROR: opensips: module's 'opensips' check() function reports failure.
2018-06-18 21:25:20: charts.d: FATAL: main: No charts to collect data from.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[charts.d] : called DISABLE. Disabling it.
2018-06-18 21:25:20: netdata ERROR : PLUGINSD[charts.d] : '/usr/libexec/netdata/plugins.d/charts.d.plugin' (pid 1750) disconnected after 0 successful data collections (ENDs).
2018-06-18 21:25:20: netdata ERROR : PLUGINSD[charts.d] : '/usr/libexec/netdata/plugins.d/charts.d.plugin' (pid 1750) does not generate useful output but it reports success (exits with 0). Will not start it again - it is now disabled..
2018-06-18 21:25:20: python.d ERROR: plugin: main: module load config: 'cpuidle' => [FAILED]
2018-06-18 21:25:20: python.d ERROR: plugin: main: load config error : [Errno 2] No such file or directory: '/etc/netdata/python.d/cpuidle.conf'
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static2] : Initializing file /var/cache/netdata/netdata.web_thread2_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static2] : Initializing file /var/cache/netdata/netdata.web_thread2_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static3] : Initializing file /var/cache/netdata/netdata.web_thread3_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static2] : Initializing file /var/cache/netdata/netdata.web_thread2_cpu/system.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static3] : Initializing file /var/cache/netdata/netdata.web_thread3_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static3] : Initializing file /var/cache/netdata/netdata.web_thread3_cpu/system.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static6] : Initializing file /var/cache/netdata/netdata.web_thread6_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static6] : Initializing file /var/cache/netdata/netdata.web_thread6_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static6] : Initializing file /var/cache/netdata/netdata.web_thread6_cpu/system.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static4] : Initializing file /var/cache/netdata/netdata.web_thread4_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static4] : Initializing file /var/cache/netdata/netdata.web_thread4_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev/main.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static4] : Initializing file /var/cache/netdata/netdata.web_thread4_cpu/system.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev/avail.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static5] : Initializing file /var/cache/netdata/netdata.web_thread5_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev/used.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static5] : Initializing file /var/cache/netdata/netdata.web_thread5_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : Initializing file /var/cache/netdata/netdata.web_thread1_cpu/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : Initializing file /var/cache/netdata/netdata.web_thread1_cpu/user.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static5] : Initializing file /var/cache/netdata/netdata.web_thread5_cpu/system.db.
2018-06-18 21:25:20: netdata INFO  : WEB_SERVER[static1] : Initializing file /var/cache/netdata/netdata.web_thread1_cpu/system.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev_shm/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev_shm/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev_shm/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._dev_shm/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev_shm/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev_shm/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev_shm/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._dev_shm/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run_lock/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run_lock/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run_lock/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_space._run_lock/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run_lock/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run_lock/avail.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run_lock/used.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[diskspace] : Initializing file /var/cache/netdata/disk_inodes._run_lock/reserved_for_root.db.
2018-06-18 21:25:20: netdata INFO  : PLUGIN[proc] : Using now_boottime_usec() for uptime (dt is 0 ms)
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/netdata.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/netdata.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/apps.plugin.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/apps.plugin.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/node.d.plugin.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/node.d.plugin.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.mem/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/tc_qos_helper.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/tc_qos_helper.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/logs.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/logs.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/ssh.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/ssh.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/cron.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/cron.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/ksmd.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/ksmd.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/system.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/system.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/kernel.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/kernel.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/other.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.mem/other.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/netdata.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/netdata.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/apps.plugin.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/apps.plugin.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/node.d.plugin.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/node.d.plugin.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.vmem/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/tc_qos_helper.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/tc_qos_helper.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/logs.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/logs.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/ssh.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/ssh.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/cron.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/cron.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/ksmd.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/ksmd.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/system.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/system.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/kernel.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/kernel.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/other.db does not have the expected multiplier (expected 1, found 4096). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : File /var/cache/netdata/apps.vmem/other.db does not have the expected divisor (expected 1024, found 1048576). Previous values may be wrong.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.threads/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.processes/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_user/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_system/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/main.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/netdata.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/apps.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/node.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/tc_qos_helper.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/logs.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/ssh.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/cron.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/ksmd.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/system.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/kernel.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/other.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.major_faults/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.minor_faults/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.preads/python.d.plugin.db.
2018-06-18 21:25:20: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.pwrites/python.d.plugin.db.
2018-06-18 21:25:20: netdata Too many logs (201 logs in 1 seconds, threshold is set to 200 logs in 1200 seconds). Preventing more logs from process 'netdata' for 1199 seconds.
2018-06-18 21:25:21: node.d.plugin: ERROR: Cannot load module's stiebeleltron config from /etc/netdata/node.d/stiebeleltron.conf exception: Error: ENOENT: no such file or directory, open '/etc/netdata/node.d/stiebeleltron.conf', using internal defaults.
2018-06-18 21:25:21: node.d.plugin: ERROR: Cannot load module's snmp config from /etc/netdata/node.d/snmp.conf exception: Error: ENOENT: no such file or directory, open '/etc/netdata/node.d/snmp.conf', using internal defaults.
2018-06-18 21:25:21: node.d.plugin: ERROR: Cannot load module's sma_webbox config from /etc/netdata/node.d/sma_webbox.conf exception: Error: ENOENT: no such file or directory, open '/etc/netdata/node.d/sma_webbox.conf', using internal defaults.
2018-06-18 21:25:21: node.d.plugin: ERROR: Cannot load module's named config from /etc/netdata/node.d/named.conf exception: Error: ENOENT: no such file or directory, open '/etc/netdata/node.d/named.conf', using internal defaults.
2018-06-18 21:25:21: node.d.plugin: ERROR: Cannot load module's fronius config from /etc/netdata/node.d/fronius.conf exception: Error: ENOENT: no such file or directory, open '/etc/netdata/node.d/fronius.conf', using internal defaults.
2018-06-18 21:25:21: node.d.plugin: ERROR: named: local: Failed to make request, message: connect ECONNREFUSED 127.0.0.1:8888
2018-06-18 21:25:21: python.d ERROR: apache: localhost: Url: http://localhost/server-status?auto. Error: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /server-status?auto (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab182eeb10>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d INFO: apache: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: apache: localipv4: Url: http://127.0.0.1/server-status?auto. Error: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: /server-status?auto (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab182eed50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d INFO: apache: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: apache: localipv6: Url: http://::1/server-status?auto. Error: Failed to parse: ::1
2018-06-18 21:25:21: python.d INFO: apache: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: beanstalk: beanstalk: 'beanstalkc' module is needed to use beanstalk.chart.py
2018-06-18 21:25:21: python.d INFO: beanstalk: beanstalk: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: bind_rndc: bind_rndc: Can't locate ""rndc"" binary or binary is not executable by netdata
2018-06-18 21:25:21: python.d INFO: bind_rndc: bind_rndc: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: boinc: boinc: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: ceph: ceph: rados module is needed to use ceph.chart.py
2018-06-18 21:25:21: python.d INFO: ceph: ceph: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: couchdb: localhost: Url: http://127.0.0.1:5984/_node/couchdb@127.0.0.1/_stats. Error: HTTPConnectionPool(host='127.0.0.1', port=5984): Max retries exceeded with url: /_node/couchdb@127.0.0.1/_stats (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab183036d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: couchdb: localhost: Url: http://127.0.0.1:5984/_active_tasks. Error: HTTPConnectionPool(host='127.0.0.1', port=5984): Max retries exceeded with url: /_active_tasks (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab183035d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: couchdb: localhost: Url: http://127.0.0.1:5984/_node/couchdb@127.0.0.1/_system. Error: HTTPConnectionPool(host='127.0.0.1', port=5984): Max retries exceeded with url: /_node/couchdb@127.0.0.1/_system (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18303410>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: couchdb: localhost: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: couchdb: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: cpufreq: cpufreq: couldn't find a method to read cpufreq statistics
2018-06-18 21:25:21: python.d INFO: cpufreq: cpufreq: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: cpuidle: cpuidle: couldn't find cstate stats
2018-06-18 21:25:21: python.d INFO: cpuidle: cpuidle: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: dns_query_time: dns_query_time: 'python-dnspython' package is needed to use dns_query_time.chart.py
2018-06-18 21:25:21: python.d INFO: dns_query_time: dns_query_time: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: dnsdist: dnsdist: URL is not defined or type is not <str>
2018-06-18 21:25:21: python.d INFO: dnsdist: dnsdist: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: dovecot: localhost: Failed to connect to ""::1"", port 24242, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: dovecot: localhost: Failed to connect to ""127.0.0.1"", port 24242, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: dovecot: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: dovecot: localipv4: Failed to connect to ""127.0.0.1"", port 24242, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: dovecot: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: dovecot: localipv6: Failed to connect to ""::1"", port 24242, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: dovecot: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: dovecot: localsocket: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: elasticsearch: local: Url: http://127.0.0.1:9200/_nodes/_local/stats. Error: HTTPConnectionPool(host='127.0.0.1', port=9200): Max retries exceeded with url: /_nodes/_local/stats (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab183036d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: elasticsearch: local: Url: http://127.0.0.1:9200/_cluster/health. Error: HTTPConnectionPool(host='127.0.0.1', port=9200): Max retries exceeded with url: /_cluster/health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18303650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: elasticsearch: local: Url: http://127.0.0.1:9200/_cluster/stats. Error: HTTPConnectionPool(host='127.0.0.1', port=9200): Max retries exceeded with url: /_cluster/stats (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18303690>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: elasticsearch: local: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: elasticsearch: local: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: exim: local: ""/usr/sbin/exim4"" is not executable
2018-06-18 21:25:21: python.d INFO: exim: local: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: fail2ban: fail2ban: /var/log/fail2ban.log is not readable or empty
2018-06-18 21:25:21: python.d INFO: fail2ban: fail2ban: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: freeradius: freeradius: Can't locate ""radclient"" binary or binary is not executable by netdata
2018-06-18 21:25:21: python.d INFO: freeradius: freeradius: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: haproxy: haproxy: URL is not defined or type is not <str>
2018-06-18 21:25:21: python.d INFO: haproxy: haproxy: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: hddtemp: localhost: Autodetecting disks
2018-06-18 21:25:21: python.d ERROR: hddtemp: localhost: Failed to connect to ""::1"", port 7634, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: hddtemp: localhost: Failed to connect to ""127.0.0.1"", port 7634, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: hddtemp: localhost: no data received
2018-06-18 21:25:21: python.d INFO: hddtemp: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: hddtemp: localipv4: Autodetecting disks
2018-06-18 21:25:21: python.d ERROR: hddtemp: localipv4: Failed to connect to ""127.0.0.1"", port 7634, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: hddtemp: localipv4: no data received
2018-06-18 21:25:21: python.d INFO: hddtemp: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: hddtemp: localipv6: Autodetecting disks
2018-06-18 21:25:21: python.d ERROR: hddtemp: localipv6: Failed to connect to ""::1"", port 7634, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: hddtemp: localipv6: no data received
2018-06-18 21:25:21: python.d INFO: hddtemp: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: httpcheck: httpcheck: URL is not defined or type is not <str>
2018-06-18 21:25:21: python.d INFO: httpcheck: httpcheck: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: icecast: localhost: Url: http://localhost:8443/status-json.xsl. Error: HTTPConnectionPool(host='localhost', port=8443): Max retries exceeded with url: /status-json.xsl (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1ecb7150>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d INFO: icecast: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: icecast: localipv4: Url: http://127.0.0.1:8443/status-json.xsl. Error: HTTPConnectionPool(host='127.0.0.1', port=8443): Max retries exceeded with url: /status-json.xsl (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab182eed90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d INFO: icecast: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: ipfs: localhost: Url: http://localhost:5001/api/v0/pin/ls. Error: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/pin/ls (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18303410>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: ipfs: localhost: Url: http://localhost:5001/api/v0/stats/repo. Error: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/stats/repo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18303190>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: ipfs: localhost: Url: http://localhost:5001/api/v0/stats/bw. Error: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/stats/bw (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18303410>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: ipfs: localhost: Url: http://localhost:5001/api/v0/swarm/peers. Error: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /api/v0/swarm/peers (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18303190>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: ipfs: localhost: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: ipfs: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: isc_dhcpd: isc_dhcpd: 'python-ipaddress' module is needed
2018-06-18 21:25:21: python.d INFO: isc_dhcpd: isc_dhcpd: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: litespeed: localhost: ""/tmp/lshttpd/"" has no ""rtreport"" files or dir is not readable
2018-06-18 21:25:21: python.d INFO: litespeed: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mdstat: mdstat: Failed to read data from /proc/mdstat or there is no active arrays
2018-06-18 21:25:21: python.d INFO: mdstat: mdstat: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: memcached: localhost: Failed to connect to ""::1"", port 11211, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: memcached: localhost: Failed to connect to ""127.0.0.1"", port 11211, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: memcached: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: memcached: localipv4: Failed to connect to ""127.0.0.1"", port 11211, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: memcached: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: memcached: localipv6: Failed to connect to ""::1"", port 11211, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: memcached: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mongodb: local: 127.0.0.1:27017: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: mongodb: local: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: mycnf1: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: mycnf1: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: mycnf2: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: mycnf2: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: debiancnf: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: debiancnf: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket1: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket1: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket2: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket2: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket3: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket3: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket4: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcp: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcp: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcpipv4: Can't establish connection to MySQL: (2003, ""Can't connect to MySQL server on '127.0.0.1' (111)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcpipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcpipv6: Can't establish connection to MySQL: (2003, ""Can't connect to MySQL server on '::1' (111)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcpipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: mycnf1_root: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: mycnf1_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: mycnf2_root: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: mycnf2_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket1_root: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket1_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket2_root: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket2_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket3_root: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket3_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket4_root: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket4_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcp_root: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcp_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcpipv4_root: Can't establish connection to MySQL: (2003, ""Can't connect to MySQL server on '127.0.0.1' (111)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcpipv4_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcpipv6_root: Can't establish connection to MySQL: (2003, ""Can't connect to MySQL server on '::1' (111)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcpipv6_root: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: mycnf1_netdata: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: mycnf1_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: mycnf2_netdata: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: mycnf2_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket1_netdata: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket1_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket2_netdata: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket2_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket3_netdata: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket3_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: socket4_netdata: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: socket4_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcp_netdata: Can't establish connection to MySQL: (2002, ""Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcp_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcpipv4_netdata: Can't establish connection to MySQL: (2003, ""Can't connect to MySQL server on '127.0.0.1' (111)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcpipv4_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: mysql: tcpipv6_netdata: Can't establish connection to MySQL: (2003, ""Can't connect to MySQL server on '::1' (111)"")
2018-06-18 21:25:21: python.d INFO: mysql: tcpipv6_netdata: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: nginx: localhost: Url: http://localhost/stub_status. Error: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /stub_status (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1e0f4110>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: nginx: localhost: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: nginx: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: nginx: localipv4: Url: http://127.0.0.1/stub_status. Error: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: /stub_status (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1e0f4e90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: nginx: localipv4: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: nginx: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: nginx: localipv6: Url: http://[::1]/stub_status. Error: HTTPConnectionPool(host='::1', port=80): Max retries exceeded with url: /stub_status (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1812dd50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: nginx: localipv6: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: nginx: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: nginx_plus: localhost: Url: http://localhost/status. Error: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /status (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1812ded0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d INFO: nginx_plus: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: nginx_plus: localipv4: Url: http://127.0.0.1/status. Error: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: /status (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18138150>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d INFO: nginx_plus: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: nginx_plus: localipv6: Url: http://[::1]/status. Error: HTTPConnectionPool(host='::1', port=80): Max retries exceeded with url: /status (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18138390>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d INFO: nginx_plus: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: nsd: local: Can't locate ""nsd-control stats_noreset"" binary
2018-06-18 21:25:21: python.d INFO: nsd: local: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: ntpd: localhost: socket to ""::1"" port 123: failed to receive response: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: ntpd: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: ntpd: localhost_ipv4: socket to ""127.0.0.1"" port 123: failed to receive response: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: ntpd: localhost_ipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: ntpd: localhost_ipv6: socket to ""::1"" port 123: failed to receive response: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: ntpd: localhost_ipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: ovpn_status_log: ovpn_status_log: 'log_path' is not defined
2018-06-18 21:25:21: python.d INFO: ovpn_status_log: ovpn_status_log: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: phpfpm: localhost: Url: http://localhost/status?full&json. Error: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /status?full&json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab181383d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: phpfpm: localhost: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: phpfpm: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: phpfpm: localipv4: Url: http://127.0.0.1/status?full&json. Error: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: /status?full&json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18138650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: phpfpm: localipv4: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: phpfpm: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: phpfpm: localipv6: Url: http://::1/status?full&json. Error: Failed to parse: ::1
2018-06-18 21:25:21: python.d ERROR: phpfpm: localipv6: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: phpfpm: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: portcheck: portcheck: Host or port missing
2018-06-18 21:25:21: python.d INFO: portcheck: portcheck: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: postfix: local: Can't locate ""postqueue -p"" binary
2018-06-18 21:25:21: python.d INFO: postfix: local: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: postgres: socket: Failed to connect to {'user': 'postgres', 'database': 'postgres'}. Error: could not connect to server: No such file or directory
	Is the server running locally and accepting
	connections on Unix domain socket ""/var/run/postgresql/.s.PGSQL.5432""?

2018-06-18 21:25:21: python.d INFO: postgres: socket: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: postgres: tcp: Failed to connect to {'port': 5432, 'host': 'localhost', 'user': 'postgres', 'database': 'postgres'}. Error: could not connect to server: Connection refused
	Is the server running on host ""localhost"" (::1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Connection refused
	Is the server running on host ""localhost"" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?

2018-06-18 21:25:21: python.d INFO: postgres: tcp: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: postgres: tcpipv4: Failed to connect to {'port': 5432, 'host': '127.0.0.1', 'user': 'postgres', 'database': 'postgres'}. Error: could not connect to server: Connection refused
	Is the server running on host ""127.0.0.1"" and accepting
	TCP/IP connections on port 5432?

2018-06-18 21:25:21: python.d INFO: postgres: tcpipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: postgres: tcpipv6: Failed to connect to {'port': 5432, 'host': '::1', 'user': 'postgres', 'database': 'postgres'}. Error: could not connect to server: Connection refused
	Is the server running on host ""::1"" and accepting
	TCP/IP connections on port 5432?

2018-06-18 21:25:21: python.d INFO: postgres: tcpipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: powerdns: powerdns: URL is not defined or type is not <str>
2018-06-18 21:25:21: python.d INFO: powerdns: powerdns: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: puppet: puppet: Url: https://VM-Hosting:8140/status/v1/services?level=debug. Error: HTTPSConnectionPool(host='vm-hosting', port=8140): Max retries exceeded with url: /status/v1/services?level=debug (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fab18138690>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: puppet: puppet: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: puppet: puppet: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: rabbitmq: local: Url: http://127.0.0.1:15672/api/nodes. Error: HTTPConnectionPool(host='127.0.0.1', port=15672): Max retries exceeded with url: /api/nodes (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18138d50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: rabbitmq: local: Url: http://127.0.0.1:15672/api/overview. Error: HTTPConnectionPool(host='127.0.0.1', port=15672): Max retries exceeded with url: /api/overview (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18138e50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: rabbitmq: local: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: rabbitmq: local: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: redis: socket1: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: redis: socket2: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: redis: socket3: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: redis: localhost: Failed to connect to ""::1"", port 6379, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: redis: localhost: Failed to connect to ""127.0.0.1"", port 6379, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: redis: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: redis: localipv4: Failed to connect to ""127.0.0.1"", port 6379, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: redis: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: redis: localipv6: Failed to connect to ""::1"", port 6379, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d INFO: redis: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: retroshare: localhost: Url: http://localhost:9090/api/v2/stats. Error: HTTPConnectionPool(host='localhost', port=9090): Max retries exceeded with url: /api/v2/stats (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1d2aaf90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: retroshare: localhost: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: retroshare: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: samba: samba: Can't locate 'sudo' or 'smbstatus' binary
2018-06-18 21:25:21: python.d INFO: samba: samba: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: sensors: sensors: check() => [OK]
2018-06-18 21:25:21: python.d ERROR: smartd_log: smartd_log: check() unhandled exception: [Errno 2] No such file or directory: '/var/log/smartd'
2018-06-18 21:25:21: python.d INFO: smartd_log: smartd_log: check() => [FAILED]
2018-06-18 21:25:21: python.d INFO: spigotmc: spigotmc: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: springboot: local: Url: http://localhost:8080/metrics. Error: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /metrics (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1d2ca150>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: springboot: local: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: springboot: local: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: springboot: local_ip: Url: http://127.0.0.1:8080/metrics. Error: HTTPConnectionPool(host='127.0.0.1', port=8080): Max retries exceeded with url: /metrics (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1d2ca610>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: springboot: local_ip: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: springboot: local_ip: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128old: Failed to connect to ""::1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128old: Failed to connect to ""127.0.0.1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128old: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp3128old: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080old: Failed to connect to ""::1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080old: Failed to connect to ""127.0.0.1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080old: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp8080old: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128new: Failed to connect to ""::1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128new: Failed to connect to ""127.0.0.1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128new: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp3128new: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080new: Failed to connect to ""::1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080new: Failed to connect to ""127.0.0.1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080new: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp8080new: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128oldipv4: Failed to connect to ""127.0.0.1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128oldipv4: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp3128oldipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080oldipv4: Failed to connect to ""127.0.0.1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080oldipv4: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp8080oldipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128newipv4: Failed to connect to ""127.0.0.1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128newipv4: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp3128newipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080newipv4: Failed to connect to ""127.0.0.1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080newipv4: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp8080newipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128oldipv6: Failed to connect to ""::1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128oldipv6: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp3128oldipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080oldipv6: Failed to connect to ""::1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080oldipv6: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp8080oldipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128newipv6: Failed to connect to ""::1"", port 3128, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp3128newipv6: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp3128newipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080newipv6: Failed to connect to ""::1"", port 8080, error: [Errno 111] Connection refused
2018-06-18 21:25:21: python.d ERROR: squid: tcp8080newipv6: invalid data received
2018-06-18 21:25:21: python.d INFO: squid: tcp8080newipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: tomcat: localhost: Url: http://localhost:8080/manager/status?XML=true. Error: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /manager/status?XML=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1d2ca610>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: tomcat: localhost: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: tomcat: localhost: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: tomcat: localipv4: Url: http://127.0.0.1:8080/manager/status?XML=true. Error: HTTPConnectionPool(host='127.0.0.1', port=8080): Max retries exceeded with url: /manager/status?XML=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1d2ca050>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: tomcat: localipv4: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: tomcat: localipv4: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: tomcat: localipv6: Url: http://[::1]:8080/manager/status?XML=true. Error: HTTPConnectionPool(host='::1', port=8080): Max retries exceeded with url: /manager/status?XML=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab1d2ca250>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: tomcat: localipv6: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: tomcat: localipv6: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: traefik: local: Url: http://localhost:8080/health. Error: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fab18138b90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-06-18 21:25:21: python.d ERROR: traefik: local: _get_data() returned no data or type is not <dict>
2018-06-18 21:25:21: python.d INFO: traefik: local: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: varnish: varnish: Can't locate 'varnishstat' binary or binary is not executable by user netdata
2018-06-18 21:25:21: python.d INFO: varnish: varnish: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: w1sensor: w1sensor: [Errno 2] No such file or directory: '/sys/bus/w1/devices/'
2018-06-18 21:25:21: python.d INFO: w1sensor: w1sensor: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: nginx_log: /var/log/nginx/access.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: nginx_log: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: nginx_log2: /var/log/nginx/localhost.access_log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: nginx_log2: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: apache_log: /var/log/apache2/access.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: apache_log: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: apache_log2: /var/log/apache2/access_log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: apache_log2: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: apache_log3: /var/log/httpd/access_log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: apache_log3: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: apache_vhosts_log: /var/log/apache2/other_vhosts_access.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: apache_vhosts_log: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: gunicorn_log: /var/log/gunicorn/access.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: gunicorn_log: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: gunicorn_log2: /var/log/gunicorn/gunicorn-access.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: gunicorn_log2: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: apache_cache: /var/log/apache/cache.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: apache_cache: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: apache2_cache: /var/log/apache2/cache.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: apache2_cache: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: httpd_cache: /var/log/httpd/cache.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: httpd_cache: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: squid_log1: /var/log/squid3/access.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: squid_log1: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: web_log: squid_log2: /var/log/squid/access.log not readable or not exist
2018-06-18 21:25:21: python.d INFO: web_log: squid_log2: check() => [FAILED]
2018-06-18 21:25:21: python.d ERROR: sensors: sensors: create() => [FAILED] (charts: 0)
2018-06-18 21:25:21: python.d INFO: plugin: main: FINISHED
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: netdata prepares to exit with code 0...
2018-06-18 21:26:03: netdata ERROR : PLUGINSD[apps] : read failed
2018-06-18 21:26:03: netdata ERROR : PLUGINSD[apps] : '/usr/libexec/netdata/plugins.d/apps.plugin' (pid 1758) disconnected after 2365 successful data collections (ENDs).
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: cleaning up the database...
2018-06-18 21:26:03: netdata INFO  : MAIN : Cleaning up database [1 hosts(s)]...
2018-06-18 21:26:03: netdata INFO  : MAIN : Cleaning up database of host 'VM-Hosting'...
2018-06-18 21:26:03: netdata ERROR : PLUGINSD[apps] : child pid 1758 killed by signal 15.
2018-06-18 21:26:03: netdata ERROR : PLUGINSD[apps] : '/usr/libexec/netdata/plugins.d/apps.plugin' (pid 1758) exited with error code -1, but has given useful output in the past (2365 times). Waiting a bit before starting it again.
2018-06-18 21:26:03: netdata ERROR : PLUGIN[tc] : child pid 1740 killed by signal 15.
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: stopping master threads...
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: PLUGIN[proc]
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: PLUGIN[diskspace]
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: PLUGIN[cgroup]
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: PLUGIN[tc]
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: PLUGIN[idlejitter]
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: HEALTH
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: PLUGINSD
2018-06-18 21:26:03: netdata INFO  : PLUGIN[tc] : cleaning up...
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: WEB_SERVER[static1]
2018-06-18 21:26:03: netdata INFO  : PLUGIN[idlejitter] : cleaning up...
2018-06-18 21:26:03: netdata INFO  : HEALTH : cleaning up...
2018-06-18 21:26:03: netdata INFO  : PLUGINSD : cleaning up...
2018-06-18 21:26:03: netdata INFO  : PLUGINSD : stopping plugin thread: plugin:apps
2018-06-18 21:26:03: netdata INFO  : PLUGIN[diskspace] : cleaning up...
2018-06-18 21:26:03: netdata INFO  : PLUGINSD[apps] : data collection thread exiting
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: Stopping master thread: STATSD
2018-06-18 21:26:03: netdata INFO  : PLUGIN[cgroup] : cleaning up...
2018-06-18 21:26:03: netdata INFO  : MAIN : Waiting 9 threads to finish...
2018-06-18 21:26:03: netdata INFO  : PLUGIN[cgroup] : thread with task id 1733 finished
2018-06-18 21:26:03: netdata INFO  : PLUGIN[proc] : cleaning up...
2018-06-18 21:26:03: netdata INFO  : PLUGIN[proc] : thread with task id 1731 finished
2018-06-18 21:26:03: netdata INFO  : HEALTH : thread with task id 1737 finished
2018-06-18 21:26:03: netdata INFO  : PLUGIN[tc] : thread with task id 1734 finished
2018-06-18 21:26:03: netdata INFO  : PLUGINSD : cleanup completed.
2018-06-18 21:26:03: netdata INFO  : PLUGIN[diskspace] : thread with task id 1732 finished
2018-06-18 21:26:03: netdata INFO  : PLUGINSD[apps] : killing child process pid 1758
2018-06-18 21:26:03: netdata ERROR : PLUGINSD[apps] : Request to kill pid 1758, but it is not running. (errno 3, No such process)
2018-06-18 21:26:03: netdata INFO  : PLUGINSD[apps] : thread with task id 1757 finished
2018-06-18 21:26:03: netdata INFO  : STATSD : cleaning up...
2018-06-18 21:26:03: netdata INFO  : PLUGINSD : thread with task id 1738 finished
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : freeing local web clients cache...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : stopped after 0 connects, 0 disconnects (max concurrent 0), 0 receptions and 0 sends
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : stopping worker 2
2018-06-18 21:26:03: netdata INFO  : PLUGIN[idlejitter] : thread with task id 1735 finished
2018-06-18 21:26:03: netdata INFO  : STATSD : STATSD: stopping data collection thread 1...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : stopping worker 3
2018-06-18 21:26:03: netdata INFO  : STATSD_COLLECTOR[1] : cleaning up...
2018-06-18 21:26:03: netdata INFO  : STATSD : STATSD: closing sockets...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static3] : freeing local web clients cache...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static3] : stopped after 0 connects, 0 disconnects (max concurrent 0), 0 receptions and 0 sends
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : stopping worker 4
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static2] : freeing local web clients cache...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static2] : stopped after 0 connects, 0 disconnects (max concurrent 0), 0 receptions and 0 sends
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static2] : thread with task id 1745 finished
2018-06-18 21:26:03: netdata INFO  : STATSD_COLLECTOR[1] : thread with task id 1767 finished
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : stopping worker 5
2018-06-18 21:26:03: netdata INFO  : STATSD : STATSD: cleanup completed.
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static4] : freeing local web clients cache...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static5] : freeing local web clients cache...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static5] : stopped after 0 connects, 0 disconnects (max concurrent 0), 0 receptions and 0 sends
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static5] : thread with task id 1756 finished
2018-06-18 21:26:03: netdata INFO  : STATSD : thread with task id 1742 finished
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static3] : thread with task id 1748 finished
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : stopping worker 6
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static4] : stopped after 0 connects, 0 disconnects (max concurrent 0), 0 receptions and 0 sends
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : Waiting 5 static web threads to finish...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static4] : thread with task id 1751 finished
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static6] : freeing local web clients cache...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static6] : stopped after 0 connects, 0 disconnects (max concurrent 0), 0 receptions and 0 sends
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static6] : thread with task id 1768 finished
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : closing all web server sockets...
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : all static web threads stopped.
2018-06-18 21:26:03: netdata INFO  : WEB_SERVER[static1] : thread with task id 1739 finished
2018-06-18 21:26:03: netdata INFO  : MAIN : All threads finished.
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: freeing database memory...
2018-06-18 21:26:03: netdata INFO  : MAIN : Freeing all memory for host 'VM-Hosting'...
2018-06-18 21:26:03: netdata INFO  : MAIN : EXIT: all done - netdata is now exiting - bye bye...
```

</details>",Which ISO image you use?,"<details>
<summary>click for log</summary>

</details>"
netdata/netdata,https://github.com/netdata/netdata/issues/6037,netdata_netdata_issues_6037,"Question for the Netdata-Dashboard

On Ubuntu 16.04 LTS 
Hi I'm at a loss......My /etc/netdata/netdata.conf just don't include the part ""#Per chart configuration""......how can I order my sections on dashboard?

Further more,On my dashboard,I can't see suboptions by click mainoptions?It's really inconvenient ,how can I fix it?
Waiting for any reply. Thank you very much~",How did you install netdata?,On Ubuntu 16.04 LTS
netdata/netdata,https://github.com/netdata/netdata/issues/6467,netdata_netdata_issues_6467,"CentOS 6.8 Unable to Load PostgreSQL Chart

### Bug report summary

 - `PostgreSQL 8.4`
 - `python 2.6`
 - `python-psycopg2 2.0.14 (dt dec ext pq3)`

___

When attempting to configure the PostgreSQL chart in NetData, I receive the following error using a Socket or TCP connection:
```
`WARNING: plugin[checker] : postgres[socket] : unhandled exception on check : argument 3 must be string, not None, skipping the job`
`plugin[checker] : postgres[tcp] : unhandled exception on check : argument 6 must be string, not None, skipping the job`
```

No matter what my configuration, it won't load.  I've tried to follow the plugin with the debug and trace switches, but those don't seem to work:


> su -s /bin/bash netdata

```
/usr/libexec/netdata/plugins.d/python.d.plugin 1 debug trace postgres
2019-07-15 18:03:31: python.d INFO: plugin[main] : using python v2
2019-07-15 18:03:31: python.d INFO: plugin[main] : starting setup
2019-07-15 18:03:31: python.d INFO: plugin[main] : checking for config in ['/etc/netdata', '/usr/lib/netdata/conf.d']
2019-07-15 18:03:31: python.d INFO: plugin[main] : config found, loading config '/usr/lib/netdata/conf.d/python.d.conf'
2019-07-15 18:03:31: python.d INFO: plugin[main] : config successfully loaded
2019-07-15 18:03:31: python.d INFO: plugin[main] : starting checker process (1 module(s) to check)
2019-07-15 18:03:31: python.d INFO: plugin[checker] : starting...
2019-07-15 18:03:31: python.d INFO: plugin[checker] : postgres : checking
2019-07-15 18:03:31: python.d INFO: plugin[checker] : postgres : source successfully loaded
2019-07-15 18:03:31: python.d INFO: plugin[checker] : postgres : found config file '/etc/netdata/python.d/postgres.conf'
2019-07-15 18:03:31: python.d INFO: plugin[checker] : postgres : created 1 job(s) from the config
2019-07-15 18:03:31: python.d WARNING: plugin[checker] : postgres[tcp] : unhandled exception on check : argument 6 must be string, not None, skipping the job
2019-07-15 18:03:31: python.d INFO: plugin[checker] : postgres : all jobs failed, skipping module
2019-07-15 18:03:31: python.d INFO: plugin[checker] : terminating...
2019-07-15 18:03:31: python.d INFO: plugin[main] : stopping checker process
2019-07-15 18:03:31: python.d INFO: plugin[main] : no modules to run
DISABLE`
```

##### OS / Environment
CentOS release 6.8 (Final)
python-psycopg2-2.0.14-2.el6.x86_64

##### Netdata version (ouput of `netdata -V`)
netdata v1.16.0-43-nightly

##### Component Name
PostgreSQL module

##### Steps To Reproduce
- Configure /etc/netdata/postgres.conf with data to connect to PostgreSQL database
- Start netdata

##### Expected behavior
PostgreSQL chart to load in dashboard",Could you add some debug statements to the module `check()`	method and see where exactly this exception raises?,"- `PostgreSQL 8.4`
 - `python 2.6`
 - `python-psycopg2 2.0.14 (dt dec ext pq3)`

___"
netdata/netdata,https://github.com/netdata/netdata/issues/6640,netdata_netdata_issues_6640,"failed to start netdata, process quit silently

##### Question summary
we use netdata to monitor  container's app, got one case that netdata did not start successfully ( using same start cmd for failure/succeess case), looks did trigger netdata start, but there is no more log hint after following line. And there is no netdata process with ""ps -ef"" command, so looks netdata was exit silently.

anyone can give us some hints, i attach the success/error log for reference.

thanks for help.

`2019-08-12 08:39:56: netdata INFO  : WEB_SERVER[static1] : starting worker 2``

##### OS / Environment
CentOS7.6

##### Component Name
version: netdata v1.15.0
##### Expected results

netdata was started successfully.


see the error log as below:

<details>
<summary>===failure log====
</summary>

```
2019-08-12 08:39:53: netdata INFO  : MAIN : Executing /usr/libexec/netdata/plugins.d/system-info.sh
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_NAME=""CentOS Linux""
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_ID=centos
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_ID_LIKE=rhel fedora
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_VERSION=7 (Core)
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_VERSION_ID=7
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_DETECTION=/etc/os-release
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_KERNEL_NAME=Linux
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_KERNEL_VERSION=3.10.0-957.el7.x86_64
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_ARCHITECTURE=x86_64
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_VIRTUALIZATION=none
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_VIRT_DETECTION=systemd-detect-virt
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_CONTAINER=none
2019-08-12 08:39:55: netdata INFO  : MAIN : NETDATA_SYSTEM_CONTAINER_DETECTION=systemd-detect-virt
2019-08-12 08:39:55: netdata INFO  : MAIN : /usr/libexec/netdata/plugins.d/anonymous-statistics.sh 'START' '-' '-'
2019-08-12 08:39:56: netdata INFO  : MAIN : resources control: allowed file descriptors: soft = 655360, max = 655360
2019-08-12 08:39:56: netdata INFO  : MAIN : Out-Of-Memory (OOM) score is already set to the wanted value 936
2019-08-12 08:39:56: netdata INFO  : MAIN : Adjusted netdata scheduling policy to idle (5), with priority 0.
2019-08-12 08:39:56: netdata INFO  : MAIN : Running with process scheduling policy 'idle'
2019-08-12 08:39:56: netdata ERROR : MAIN : User 888 is not present.
2019-08-12 08:39:56: netdata ERROR : MAIN : Cannot become user '888'. Continuing as we are.
2019-08-12 08:39:56: netdata INFO  : MAIN : netdata started on pid 95.
2019-08-12 08:39:56: netdata ERROR : MAIN : User 'ssdepg' is not present. Ignoring option.
2019-08-12 08:39:56: netdata INFO  : MAIN : CONFIG: cannot load user config '/etc/netdata/stream.conf'. Will try stock config.
2019-08-12 08:39:56: netdata INFO  : MAIN : Host 'hivip-unifyapi-svc-1540938827-6p7jk' (at registry as 'hivip-unifyapi-svc-1540938827-6p7jk') with guid 'c324465c-bcdc-11e9-96b0-3a66960e462a' initialized, os 'li
nux', timezone 'UTC', tags '', program_name 'netdata', program_version 'v1.15.0', update every 5, memory mode save, history entries 924, streaming disabled (to '' with api key ''), health disabled, cache_dir '/
var/cache/netdata', varlib_dir '/var/lib/netdata', health_log '/var/lib/netdata/health/health-log.db', alarms default handler '/usr/libexec/netdata/plugins.d/alarm-notify.sh', alarms default recipient 'root'
2019-08-12 08:39:56: netdata INFO  : MAIN : SYSTEM_INFO: free 0x1913e30
2019-08-12 08:39:56: netdata INFO  : PLUGIN[proc] : thread created with task id 96
2019-08-12 08:39:56: netdata INFO  : BACKENDS : thread created with task id 98
2019-08-12 08:39:56: netdata INFO  : STATSD : thread created with task id 97
2019-08-12 08:39:56: netdata INFO  : WEB_SERVER[static1] : thread created with task id 99
2019-08-12 08:39:56: netdata INFO  : PLUGINSD : thread created with task id 100
2019-08-12 08:39:56: netdata INFO  : WEB_SERVER[static1] : starting worker 2`
```

</details>

<details>
<summary>===normally start log====</summary>

```
2019-08-12 10:50:24: netdata INFO  : MAIN : Executing /usr/libexec/netdata/plugins.d/system-info.sh
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_NAME=""CentOS Linux""
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_ID=centos
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_ID_LIKE=rhel fedora
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_VERSION=7 (Core)
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_VERSION_ID=7
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_OS_DETECTION=/etc/os-release
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_KERNEL_NAME=Linux
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_KERNEL_VERSION=3.10.0-957.el7.x86_64
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_ARCHITECTURE=x86_64
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_VIRTUALIZATION=none
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_VIRT_DETECTION=systemd-detect-virt
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_CONTAINER=none
2019-08-12 10:50:25: netdata INFO  : MAIN : NETDATA_SYSTEM_CONTAINER_DETECTION=systemd-detect-virt
2019-08-12 10:50:25: netdata INFO  : MAIN : /usr/libexec/netdata/plugins.d/anonymous-statistics.sh 'START' '-' '-'
2019-08-12 10:50:25: netdata INFO  : MAIN : resources control: allowed file descriptors: soft = 655360, max = 655360
2019-08-12 10:50:25: netdata INFO  : MAIN : Out-Of-Memory (OOM) score is already set to the wanted value 936
2019-08-12 10:50:25: netdata INFO  : MAIN : Adjusted netdata scheduling policy to idle (5), with priority 0.
2019-08-12 10:50:25: netdata INFO  : MAIN : Running with process scheduling policy 'idle'
2019-08-12 10:50:25: netdata ERROR : MAIN : User 888 is not present.
2019-08-12 10:50:25: netdata ERROR : MAIN : Cannot become user '888'. Continuing as we are.
2019-08-12 10:50:25: netdata INFO  : MAIN : netdata started on pid 347.
2019-08-12 10:50:25: netdata ERROR : MAIN : User 'ssdepg' is not present. Ignoring option.
2019-08-12 10:50:25: netdata INFO  : MAIN : CONFIG: cannot load user config '/etc/netdata/stream.conf'. Will try stock config.
2019-08-12 10:50:25: netdata INFO  : MAIN : Host 'hivip-unifyapi-svc-1540938827-6p7jk' (at registry as 'hivip-unifyapi-svc-1540938827-6p7jk') with guid 'c324465c-bcdc-11e9-96b0-3a66960e462a' initialized, os 'linux', timezone 'UTC', tags '', program_name 'netdata', program_version 'v1.15.0', update every 5, memory mode save, history entries 924, streaming disabled (to '' with api key ''), health disabled, cache_dir '/var/cache/netdata', varlib_dir '/var/lib/netdata', health_log '/var/lib/netdata/health/health-log.db', alarms default handler '/usr/libexec/netdata/plugins.d/alarm-notify.sh', alarms default recipient 'root'
2019-08-12 10:50:25: netdata INFO  : MAIN : SYSTEM_INFO: free 0xd8de80
2019-08-12 10:50:25: netdata INFO  : PLUGIN[proc] : thread created with task id 348
2019-08-12 10:50:25: netdata INFO  : STATSD : thread created with task id 349
2019-08-12 10:50:25: netdata INFO  : BACKENDS : thread created with task id 350
2019-08-12 10:50:25: netdata INFO  : WEB_SERVER[static1] : thread created with task id 351
2019-08-12 10:50:25: netdata INFO  : BACKENDS : cleaning up...
2019-08-12 10:50:25: netdata INFO  : BACKENDS : thread with task id 350 finished
2019-08-12 10:50:25: netdata INFO  : MAIN : netdata initialization completed. Enjoy real-time performance monitoring!
2019-08-12 10:50:25: netdata INFO  : HEALTH : thread created with task id 353
2019-08-12 10:50:25: netdata INFO  : WEB_SERVER[static1] : starting worker 2
2019-08-12 10:50:25: netdata INFO  : PLUGINSD : thread created with task id 352
2019-08-12 10:50:25: netdata INFO  : WEB_SERVER[static1] : POLLFD: LISTENER: listening on 'tcp:0.0.0.0:19999'
2019-08-12 10:50:25: netdata INFO  : WEB_SERVER[static1] : POLLFD: LISTENER: listening on 'tcp:[::]:19999'
2019-08-12 10:50:25: netdata INFO  : STATSD : thread with task id 349 finished
2019-08-12 10:50:25: netdata INFO  : WEB_SERVER[static2] : thread created with task id 354
2019-08-12 10:50:25: netdata INFO  : WEB_SERVER[static2] : POLLFD: LISTENER: listening on 'tcp:0.0.0.0:19999'
2019-08-12 10:50:25: netdata INFO  : WEB_SERVER[static2] : POLLFD: LISTENER: listening on 'tcp:[::]:19999'
2019-08-12 10:50:25: netdata INFO  : PLUGINSD[apps] : thread created with task id 355
2019-08-12 10:50:25: netdata INFO  : PLUGINSD[charts.d] : thread created with task id 356
2019-08-12 10:50:25: netdata INFO  : PLUGINSD[apps] : connected to '/usr/libexec/netdata/plugins.d/apps.plugin' running on pid 357
2019-08-12 10:50:25: netdata INFO  : PLUGINSD[charts.d] : connected to '/usr/libexec/netdata/plugins.d/charts.d.plugin' running on pid 358
2019-08-12 10:50:25: netdata ERROR : PLUGINSD : cannot open plugins directory '/etc/netdata/custom-plugins.d' (errno 2, No such file or directory)
2019-08-12 10:50:26: apps.plugin ERROR : MAIN : PROCFILE: Cannot open file '/etc/netdata/apps_groups.conf' (errno 2, No such file or directory)
2019-08-12 10:50:26: apps.plugin INFO  : MAIN : Cannot read process groups configuration file '/etc/netdata/apps_groups.conf'. Will try '/usr/lib/netdata/conf.d/apps_groups.conf'
2019-08-12 10:50:26: apps.plugin INFO  : MAIN : Loaded config file '/usr/lib/netdata/conf.d/apps_groups.conf'
2019-08-12 10:50:26: apps.plugin INFO  : MAIN : started on pid 357
2019-08-12 10:50:26: charts.d: INFO: main: started from '/usr/libexec/netdata/plugins.d/charts.d.plugin' with options: 5
2019-08-12 10:50:26: charts.d: INFO: main: Configuration file '/usr/lib/netdata/conf.d/charts.d.conf' loaded.
2019-08-12 10:50:26: charts.d: WARNING: main: Configuration file '/etc/netdata/charts.d.conf' not found.
2019-08-12 10:50:26: charts.d: INFO: apache: is disabled. Add a line with apache=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: cpu_apps: is disabled. Add a line with cpu_apps=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: cpufreq: is disabled. Add a line with cpufreq=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: example: is disabled. Add a line with example=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: exim: is disabled. Add a line with exim=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: hddtemp: is disabled. Add a line with hddtemp=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: load_average: is disabled. Add a line with load_average=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: mem_apps: is disabled. Add a line with mem_apps=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: mysql: is disabled. Add a line with mysql=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: nginx: is disabled. Add a line with nginx=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: phpfpm: is disabled. Add a line with phpfpm=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: postfix: is disabled. Add a line with postfix=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: sensors: is disabled. Add a line with sensors=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: squid: is disabled. Add a line with squid=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: INFO: tomcat: is disabled. Add a line with tomcat=force in '/etc/netdata/charts.d.conf' to enable it (or remove the line that disables it).
2019-08-12 10:50:26: charts.d: WARNING: ap: command 'iw' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/src/jdk1.8.0_151/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2019-08-12 10:50:26: charts.d: ERROR: ap: module's 'ap' check() function reports failure.
2019-08-12 10:50:26: charts.d: WARNING: apcupsd: command 'apcaccess' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/src/jdk1.8.0_151/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2019-08-12 10:50:26: charts.d: ERROR: apcupsd: module's 'apcupsd' check() function reports failure.
2019-08-12 10:50:26: charts.d: WARNING: libreswan: command 'ipsec' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/src/jdk1.8.0_151/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2019-08-12 10:50:26: charts.d: ERROR: libreswan: module's 'libreswan' check() function reports failure.
2019-08-12 10:50:26: charts.d: WARNING: nut: command 'upsc' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/src/jdk1.8.0_151/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2019-08-12 10:50:26: charts.d: ERROR: nut: module's 'nut' check() function reports failure.
2019-08-12 10:50:26: charts.d: WARNING: opensips: command 'opensipsctl' is not found in /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/src/jdk1.8.0_151/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin.
2019-08-12 10:50:26: charts.d: ERROR: opensips: module's 'opensips' check() function reports failure.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[charts.d] : Initializing file /var/cache/netdata/cpu.limit/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[charts.d] : Initializing file /var/cache/netdata/cpu.limit/cpu.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[charts.d] : Initializing file /var/cache/netdata/cpu.limit/memory.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[charts.d] : Initializing file /var/cache/netdata/netdata.plugin_chartsd_cpu_limit/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[charts.d] : Initializing file /var/cache/netdata/netdata.plugin_chartsd_cpu_limit/run_time.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net.eth0/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net.eth0/received.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net.eth0/sent.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_cpu/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_cpu/user.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_cpu/system.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net_packets.eth0/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net_packets.eth0/received.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net_packets.eth0/sent.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net_packets.eth0/multicast.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/calls.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/files.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/filenames.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/inode_changes.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/link_changes.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/pids.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/fds.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/targets.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_sizes/new_pids.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net_drops.eth0/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net_drops.eth0/inbound.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/net_drops.eth0/outbound.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_fix/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_fix/utime.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_fix/stime.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_fix/gtime.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_fix/minflt.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_fix/majflt.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_sockets/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_sockets/used.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_children_fix/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_children_fix/cutime.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_children_fix/cstime.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_children_fix/cgtime.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_children_fix/cminflt.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/netdata.apps_children_fix/cmajflt.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_tcp_sockets/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_tcp_sockets/alloc.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_tcp_sockets/orphan.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_tcp_sockets/inuse.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_tcp_sockets/timewait.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_tcp_mem/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_tcp_mem/mem.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.mem/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.mem/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_udp_mem/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.sockstat_udp_mem/mem.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.mem/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.mem/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpconnaborts/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpconnaborts/TCPAbortOnData.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.mem/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpconnaborts/TCPAbortOnClose.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpconnaborts/TCPAbortOnMemory.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpconnaborts/TCPAbortOnTimeout.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpconnaborts/TCPAbortOnLinger.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpconnaborts/TCPAbortFailed.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.vmem/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.vmem/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpreorders/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpreorders/TCPTSReorder.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpreorders/TCPSACKReorder.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpreorders/TCPFACKReorder.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpreorders/TCPRenoReorder.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.vmem/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpofo/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpofo/TCPOFOQueue.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.vmem/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpofo/TCPOFODrop.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpofo/TCPOFOMerge.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.tcpofo/OfoPruned.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.vmem/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/system.ip/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/system.ip/InOctets.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/system.ip/OutOctets.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.threads/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.threads/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.ecnpkts/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.ecnpkts/InCEPkts.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.ecnpkts/InNoECTPkts.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.ecnpkts/InECT0Pkts.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ip.ecnpkts/InECT1Pkts.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.threads/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.packets/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.packets/InReceives.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.threads/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.packets/OutRequests.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.packets/ForwDatagrams.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.packets/InDelivers.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.threads/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcpsock/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcpsock/CurrEstab.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.processes/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.processes/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcppackets/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcppackets/InSegs.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcppackets/OutSegs.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.processes/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcperrors/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcperrors/InErrs.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.processes/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcperrors/InCsumErrors.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcperrors/RetransSegs.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.processes/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcpopens/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcpopens/ActiveOpens.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcpopens/PassiveOpens.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_user/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_user/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcphandshake/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcphandshake/EstabResets.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcphandshake/OutRsts.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcphandshake/AttemptFails.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.tcphandshake/TCPSynRetrans.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_user/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.udppackets/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.udppackets/InDatagrams.db.
2019-08-12 10:50:26: netdata INFO  : PLUGIN[proc] : Initializing file /var/cache/netdata/ipv4.udppackets/OutDatagrams.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_user/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_user/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_system/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_system/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_system/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_system/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.cpu_system/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.swap/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.major_faults/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.major_faults/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.major_faults/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.major_faults/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.major_faults/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.minor_faults/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.minor_faults/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.minor_faults/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.minor_faults/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.minor_faults/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.preads/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.preads/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.preads/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.preads/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.preads/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.pwrites/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.pwrites/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.pwrites/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.pwrites/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.pwrites/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lreads/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lreads/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lreads/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lreads/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lreads/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lwrites/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lwrites/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lwrites/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lwrites/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.lwrites/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.files/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.files/netdata.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.files/apps.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.files/charts.d.plugin.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.files/other.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.sockets/main.db.
2019-08-12 10:50:26: netdata INFO  : PLUGINSD[apps] : Initializing file /var/cache/netdata/apps.sockets/netdata.db.
2019-08-12 10:50:26: netdata LOG FLOOD PROTECTION too many logs (201 logs in 1 seconds, threshold is set to 200 logs in 1200 seconds). Preventing more logs from process 'netdata' for 1199 seconds.
```

</details>",What does it show when Netdata doesn't start?,"<details>
<summary></summary>
``
```</details>

<details>
<summary></summary>
``
``</details>"
netdata/netdata,https://github.com/netdata/netdata/issues/6527,netdata_netdata_issues_6527,"host needs attention / is critical - 1m ipv4 udp receive buffer errors - ipv4.udperrors

Hi guys,

I get emails like this:

![host needs attention](https://user-images.githubusercontent.com/991344/61771959-671a2100-adf1-11e9-8bdd-e0c7dbed3c9a.PNG)

![host is critical](https://user-images.githubusercontent.com/991344/61771986-7600d380-adf1-11e9-876d-9dc0274592f4.PNG)

I am using netdata in a docker container on an openmediavault 4 machine with debian stretch os. Everything is up-to-date.

```
root@omv4:~# uname -a
Linux omv4 4.19.0-0.bpo.5-amd64 #1 SMP Debian 4.19.37-4~bpo9+1 (2019-06-19) x86_64 GNU/Linux
```

I found some issue reports here on github from other guys reporting the same issue, but there are no answers to fix the issue:

https://github.com/netdata/netdata/issues/4086
https://github.com/netdata/netdata/issues/1754
https://github.com/netdata/netdata/issues/2102

At the netdata WebInterface I see the following:

![udp errors](https://user-images.githubusercontent.com/991344/61772371-60d87480-adf2-11e9-9df5-b7081c723631.PNG)

![udp some errors](https://user-images.githubusercontent.com/991344/61772378-646bfb80-adf2-11e9-9af1-e7a580398431.PNG)

I tried to configure my receive and write buffers, but nothing helped. I started with the following configuration:

https://github.com/netdata/netdata/issues/1076#issuecomment-509214247

But for my udp errors this didn't work and I tried to combine the informations of the following internet sites:

https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/UDPSocketBuffers.html
http://www.nateware.com/linux-network-tuning-for-2013.html#.XTgD2lwzZhF
https://opensourceforu.com/2016/10/network-performance-monitoring/
https://wiki.archlinux.org/index.php/Sysctl

My current ""/etc/sysctl.d/99-network-tuning.conf"" looks as follows:

```
### KERNEL TUNING ###

# Increase size of file handles and inode cache
fs.file-max = 2097152

# Do less swapping / Virtual memory
vm.swappiness = 10
vm.dirty_ratio = 60
vm.dirty_background_ratio = 2

# Sets the time before the kernel considers migrating a proccess to another core
kernel.sched_migration_cost_ns = 5000000

# Group tasks by TTY
#kernel.sched_autogroup_enabled = 0

### GENERAL NETWORK SECURITY OPTIONS ###

# Number of times SYNACKs for passive TCP connection.
net.ipv4.tcp_synack_retries = 2

# Allowed local port range
net.ipv4.ip_local_port_range = 2000 65535

# Protect against tcp time-wait assassination hazards, drop RST packets for sockets in the time-wait state
net.ipv4.tcp_rfc1337 = 1

# Helps protect against SYN flood attacks. Only kicks in when net.ipv4.tcp_max_syn_backlog is reached
net.ipv4.tcp_syncookies = 1

# Specify how many seconds to wait for a final FIN packet before the socket is forcibly closed
net.ipv4.tcp_fin_timeout = 10

# With the following settings, your application will detect dead TCP connections after 120 seconds (60s + 10s + 10s + 10s + 10s + 10s + 10s)
net.ipv4.tcp_keepalive_time = 60
net.ipv4.tcp_keepalive_intvl = 10
net.ipv4.tcp_keepalive_probes = 6

### TUNING NETWORK PERFORMANCE ###

# https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/UDPSocketBuffers.html
# On the Linux platform Tx ring buffer overruns can occur when transmission rates approach 1Gbps and the default send socket buffer is greater than 65536.
# It is recommended to set the net.core.wmem_default kernel parameter to no larger than 65536 bytes.
# Transmitting applications can configure the send socket buffer size for InfiniBand, UDP, or TCP protocols independently in a transmit instance.

# Default and Maximum Socket Receive Buffer
net.core.rmem_default = 8388608
net.core.rmem_max = 16777216

# Default and Maximum Socket Send Buffer
net.core.wmem_default = 65536
net.core.wmem_max = 16777216

# Increase the maximum amount of option memory buffers
net.core.optmem_max = 65536

# Increase number of incoming connections
#net.core.somaxconn = 65535

# Increase number of incoming connections backlog
net.core.netdev_max_backlog = 100000

# Maximum number of microseconds in one NAPI polling cycle.
# Polling will exit when either netdev_budget_usecs have elapsed during the poll cycle or the number of packets processed reaches netdev_budget.
net.core.netdev_budget = 60000
net.core.netdev_budget_usecs = 6000

# Increase the tcp read and write-buffer-space allocatable
net.ipv4.tcp_rmem = 4096 1048576 2097152
net.ipv4.tcp_wmem = 4096 65536 16777216

# Increase the tcp read and write-buffer-space allocatable (default = 4096)
net.ipv4.udp_rmem_min = 8192
net.ipv4.udp_wmem_min = 8192

# Increase the maximum total buffer-space allocatable
# This is measured in units of pages (4096 bytes)
#net.ipv4.tcp_mem = 786432 1048576 26777216
#net.ipv4.udp_mem = 65536 131072 262144

# Make room for more TIME_WAIT sockets due to more clients,
# and allow them to be reused if we run out of sockets
net.ipv4.tcp_max_syn_backlog = 30000
net.ipv4.tcp_max_tw_buckets = 2000000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_slow_start_after_idle = 0
```

What else information do you need to help me to solve my issue?

How is it possible to analyze my network regarding udp traffic to find the cause?

Best regards Hoppel",Does it affect number of RcvbufErrors?,"```
root@omv4:~# uname -a
Linux omv4 4.19.0-0.bpo.5-amd64 #1 SMP Debian 4.19.37-4~bpo9+1 (2019-06-19) x86_64 GNU/Linux
```"
netdata/netdata,https://github.com/netdata/netdata/issues/7551,netdata_netdata_issues_7551,"CentOS 6.10 build failed

##### Bug report summary

When I used a clean VPS on DigitalOcean using CentOS 6 x86_64 the following steps worked perfectly:

- yum update
- yum install -y httpd httpd-tools
- yum install -y epel-release
- yum install -y http://repo.okay.com.mx/centos/6/x86_64/release/okay-release-1-1.noarch.rpm
- yum install -y okay-release
- bash <(curl -Ss https://my-netdata.io/kickstart.sh)

but now I am doing it on the production server I want netdata to be at. The VPS was pure for testing purposes. The error I get is the following (scroll further for whole info):

```
configure: error: libuv required but not found. Try installing 'libuv1-dev' or 'libuv-devel'.
 FAILED


  ^
  |.-.   .-.   .-.   .-.   .-.   .  netdata                          .-.   .-
  |   '-'   '-'   '-'   '-'   '-'   sorry, it failed to build...  '-'   '-'
  +----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+--->


^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Sorry! netdata failed to build...

You may need to check these:

1. The package uuid-dev (or libuuid-devel) has to be installed.

   If your system cannot find libuuid, although it is installed
   run me with the option:  --libs-are-really-here

2. The package zlib1g-dev (or zlib-devel) has to be installed.

   If your system cannot find zlib, although it is installed
   run me with the option:  --libs-are-really-here

3. You need basic build tools installed, like:

   gcc make autoconf automake pkg-config

   Autoconf version 2.60 or higher is required.

If you still cannot get it to build, ask for help at github:

   https://github.com/netdata/netdata/issues


 FAILED

 ABORTED  netdata-installer.sh exited with error
```

Everything package that is required by netdata is installed, I did `yum update`, I tried possible solutions from 296, 979, 2056 and 1537 but none of them fix the problem I have. Here is the full output:

<details>
<summary>log</summary>
<p>

```
[~]# bash <(curl -Ss https://my-netdata.io/kickstart.sh)
System            : Linux
Operating System  : GNU/Linux
Machine           : x86_64
BASH major version:
 --- Fetching script to detect required packages... ---
[/tmp/netdata-kickstart-oIIUSg]# curl -sSL --connect-timeout 10 --retry 3 https://raw.githubusercontent.com/netdata/netdata-demo-site/master/install-required-packages.sh
 OK

 --- Running downloaded script to detect required packages... ---
[/tmp/netdata-kickstart-oIIUSg]# /bin/bash /tmp/netdata-kickstart-oIIUSg/install-required-packages.sh netdata
Cannot find /etc/os-release
Cannot find valid distribution with lsb-release
Loading /etc/centos-release ...
You should have EPEL enabled to install all the prerequisites.
Check: http://www.tecmint.com/how-to-enable-epel-repository-for-rhel-centos-6-5/

We detected these:
Distribution    : CentOS
Version         : 6.10
Codename        : Final
Package Manager : install_yum
Packages Tree   : centos
Detection Method: /etc/centos-release
Default Python v: 2

WARNING
package autoconf-archive is not available in this system.
You may try to install without it.

WARNING
package autogen is not available in this system.
You may try to install without it.

 > Checking if package 'zlib-devel' is installed...
 > Checking if package 'libuuid-devel' is installed...
 > Checking if package 'libmnl-devel' is installed...
 > Checking if package 'libuv-devel' is installed...
 > Checking if package 'lz4-devel' is installed...
 > Checking if package 'openssl-devel' is installed...
 > Checking if package 'Judy-devel' is installed...

All required packages are already installed. Now proceed to the next step.

 OK

[/tmp/netdata-kickstart-oIIUSg]# curl -sSL --connect-timeout 10 --retry 3 https://storage.googleapis.com/netdata-nightlies/sha256sums.txt
 OK

[/tmp/netdata-kickstart-oIIUSg]# curl -sSL --connect-timeout 10 --retry 3 https://storage.googleapis.com/netdata-nightlies/netdata-latest.tar.gz
 OK

[/tmp/netdata-kickstart-oIIUSg]# tar -xf netdata-latest.tar.gz
 OK

 --- Installing netdata... ---
[/tmp/netdata-kickstart-oIIUSg/netdata-v1.19.0-129-gc4c9624e]# ./netdata-installer.sh --auto-update

  ^
  |.-.   .-.   .-.   .-.   .  netdata
  |   '-'   '-'   '-'   '-'   real-time performance monitoring, done right!
  +----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+--->


  You are about to build and install netdata to your system.

  It will be installed at these locations:

   - the daemon     at /usr/sbin/netdata
   - config files   in /etc/netdata
   - web files      in /usr/share/netdata
   - plugins        in /usr/libexec/netdata
   - cache files    in /var/cache/netdata
   - db files       in /var/lib/netdata
   - log files      in /var/log/netdata
   - pid file       at /var/run/netdata.pid
   - logrotate file at /etc/logrotate.d/netdata

  This installer allows you to change the installation path.
  Press Control-C and run the same command with --help for help.

Press ENTER to build and install netdata to your system >

 --- Run autotools to configure the build environment ---
[/tmp/netdata-kickstart-oIIUSg/netdata-v1.19.0-129-gc4c9624e]# autoreconf -ivf
autoreconf: Entering directory `.'
autoreconf: configure.ac: not using Gettext
autoreconf: running: aclocal --force -I build/m4
autoreconf: configure.ac: tracing
autoreconf: configure.ac: not using Libtool
autoreconf: running: /usr/bin/autoconf --force
autoreconf: running: /usr/bin/autoheader --force
autoreconf: running: automake --add-missing --copy --force-missing
autoreconf: Leaving directory `.'
 OK

[/tmp/netdata-kickstart-oIIUSg/netdata-v1.19.0-129-gc4c9624e]# ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var --libexecdir=/usr/libexec --libdir=/usr/lib --with-zlib --with-math --with-user=netdata CFLAGS=-O2
checking whether to enable maintainer-specific portions of Makefiles... no
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking how to create a pax tar archive... gnutar
checking whether make supports nested variables... (cached) yes
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking whether gcc understands -c and -o together... yes
checking for style of include used by make... GNU
checking dependency style of gcc... gcc3
checking for gcc option to accept ISO C99... -std=gnu99
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking dependency style of g++... gcc3
checking for pkg-config... /usr/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking minix/config.h usability... no
checking minix/config.h presence... no
checking for minix/config.h... no
checking whether it is safe to define __EXTENSIONS__... yes
checking for __attribute__((returns_nonnull))... no
checking for __attribute__((malloc))... yes
checking for __attribute__((noreturn))... yes
checking for __attribute__((noinline))... yes
checking for __attribute__((format))... yes
checking for __attribute__((warn_unused_result))... yes
checking for struct timespec... yes
checking for clockid_t... yes
checking for library containing clock_gettime... -lrt
checking for clock_gettime... yes
checking for sched_setscheduler... yes
checking for sched_getscheduler... yes
checking for sched_getparam... yes
checking for sched_get_priority_min... yes
checking for sched_get_priority_max... yes
checking for getpriority... yes
checking for setpriority... yes
checking for nice... yes
checking for recvmmsg... yes
checking for int8_t... yes
checking for int16_t... yes
checking for int32_t... yes
checking for int64_t... yes
checking for uint8_t... yes
checking for uint16_t... yes
checking for uint32_t... yes
checking for uint64_t... yes
checking for inline... inline
checking whether strerror_r is declared... yes
checking for strerror_r... yes
checking whether strerror_r returns char *... yes
checking for _Generic... no
checking for __atomic... no
checking size of void *... 8
checking whether sys/types.h defines makedev... yes
checking for sys/types.h... (cached) yes
checking for netinet/in.h... yes
checking for arpa/nameser.h... yes
checking for netdb.h... yes
checking for resolv.h... yes
checking for sys/prctl.h... yes
checking for sys/vfs.h... yes
checking for sys/statfs.h... yes
checking for sys/statvfs.h... yes
checking for sys/mount.h... yes
checking for accept4... yes
checking operating system... linux with id 1
checking if compiler needs -Werror to reject unknown flags... no
checking for the pthreads library -lpthreads... no
checking whether pthreads work without any flags... yes
checking for joinable pthread attribute... PTHREAD_CREATE_JOINABLE
checking if more special flags are required for pthreads... no
checking for PTHREAD_PRIO_INHERIT... yes
checking for sin in -lm... yes
checking if libm should be used... yes
checking for uv_fs_scandir_next in -luv... no
configure: error: libuv required but not found. Try installing 'libuv1-dev' or 'libuv-devel'.
 FAILED


  ^
  |.-.   .-.   .-.   .-.   .-.   .  netdata                          .-.   .-
  |   '-'   '-'   '-'   '-'   '-'   sorry, it failed to build...  '-'   '-'
  +----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+--->


^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Sorry! netdata failed to build...

You may need to check these:

1. The package uuid-dev (or libuuid-devel) has to be installed.

   If your system cannot find libuuid, although it is installed
   run me with the option:  --libs-are-really-here

2. The package zlib1g-dev (or zlib-devel) has to be installed.

   If your system cannot find zlib, although it is installed
   run me with the option:  --libs-are-really-here

3. You need basic build tools installed, like:

   gcc make autoconf automake pkg-config

   Autoconf version 2.60 or higher is required.

If you still cannot get it to build, ask for help at github:

   https://github.com/netdata/netdata/issues


 FAILED

 ABORTED  netdata-installer.sh exited with error

```

</p>
</details>

##### OS / Environment

CentOS release 6.10 (Final)

##### Steps To Reproduce

Simply run: `bash <(curl -Ss https://my-netdata.io/kickstart.sh)`",maybe the lib‘s path is wrong? or missing libuv.pc？,"<details>
<summary>log</summary>
<p></p>
</details>"
hashicorp/packer,https://github.com/hashicorp/packer/issues/7228,hashicorp_packer_issues_7228,"Packer is stuck at ""Preparing build: qemu"" stage

- Packer version: `Packer v1.3.3`
- Host platform: `Fedora 29`
- [Debug log output, template, and var files](https://gist.github.com/Wenzel/50c0e853d900432d948a3221d34017ea)
- example to reproduce the bug; in the gist
  
Packer is stuck, and don't want to start downloading the file.

I tried with another template (var-file), `ubuntu-16.04.json`, and it works fine.
In fact i just copy pasted this var file, and replaced the urls to download `ubuntu-14.10`, so really weird.

I also checked that my QEMU or KVM installation was not buggy, my VMs are starting without any problems.

Can you help ?
Thanks !",Could you provide the values for the variables that you used?,", template, and var files"
hashicorp/packer,https://github.com/hashicorp/packer/issues/6589,hashicorp_packer_issues_6589,"amazon: Impossible to associate public IP in default subnet w/o auto-assign public IP

`Packer v1.2.5`

Builder type `amazon-ebs`

Assuming default networking setup.

Steps to reproduce:
1. Find default VPC and disable `Auto-assign public IPv4 address` in its default subnets
2. Leave `vpc_id` and `subnet_id` in default values(unset)
3. Set `associate_public_ip` to true
3. Start packer build
4. EC2 instance will be created without public IP address

More information
[associate_public_ip_address](https://www.packer.io/docs/builders/amazon-ebs.html#associate_public_ip_address) `: true` does not work here, because based on source code it only takes effect if `subnet_id`(or `vpc_id`) is specified.
https://github.com/hashicorp/packer/blob/v1.2.5/builder/amazon/common/step_run_source_instance.go#L157-L167

```
	if s.SubnetId != """" && s.AssociatePublicIpAddress {
		runOpts.NetworkInterfaces = []*ec2.InstanceNetworkInterfaceSpecification{
			{
				DeviceIndex:              aws.Int64(0),
				AssociatePublicIpAddress: &s.AssociatePublicIpAddress,
				SubnetId:                 &s.SubnetId,
				Groups:                   securityGroupIds,
				DeleteOnTermination:      aws.Bool(true),
			},
		}
	} else {
```

`associate_public_ip_address` must work for default VPC in spite of disabled `Auto-assign public IPv4 address`.",Do you think this is a bug? To me what you describe is the intended behaviour.,"et `associate_public_ip` to true
3. S"
ArduPilot/ardupilot,https://github.com/ArduPilot/ardupilot/issues/13593,ArduPilot_ardupilot_issues_13593,"Plane: Add RCx_OPTION for Preflight Calibration

Having ""Preflight Calibration"" be an option for RCx_Option would be awesome, we could then trigger this from the radio when ready rather than being required to invoke it from the GCS.

**Describe the solution you'd like**
Provide as one of the options available in RCx_Option; primary use-case for me would be to zero out the airspeed sensor on a Plane, but having this available for all systems so that you can re-init Gyro, Accel, and Baro would be a good idea too.. Thanks @Pedals2Paddles for the question on that!

**Describe alternatives you've considered**
Mavlink command from Yaapu would be one alternative but isn't realistic as a solution for all applications, as not all RF links will support two-way telemetry through FrSky.

**Platform**
[X] All
[  ] AntennaTracker
[  ] Copter
[X] Plane
[  ] Rover
[  ] Submarine

**Additional context**",Which preflight calibration?,"; primary use-case for me would be to zero out the airspeed sensor on a Plane, but having this available for all systems so that you can re-init Gyro, Accel, and Baro would be a good idea too.. Thanks @Pedals2Paddles for the question on that!Mavlink command from Yaapu would be one alternative but isn't realistic as a solution for all applications, as not all RF links will support two-way telemetry through FrSky.All
[  ] AntennaTracker
[  ] Copter
[X]"
ArduPilot/ardupilot,https://github.com/ArduPilot/ardupilot/issues/11642,ArduPilot_ardupilot_issues_11642,"Copter locks up in flight, motors stop, crashes vehicle w/ Pixhawk 2

### Bug report

There are now at least three different people with 4 different Solos running 3.7-dev that have had ArduCopter crash and stop in flight. 

- The dataflash and telemetry end abruptly with seemingly no problem logged.
- The motors stop. The copter falls to the ground (obviously).
- There are no sounds, beeps, or indications. It just stops and drops.
- Upon repowering, everything starts up like normal.
- I have an incident that took place before the watchdog even existed.  And three more post watchdog.
- In the all cases, the version of Copter master (3.7-dev) was about a month or more old from now, so probably just before and just after watchdog was implemented (for time reference). 

Thus Far, it has not happened to anyone using the Green Cube.  And to my knowledge it hasn't happened to anyone else running any other hardware.  _It appears to be isolated to the old 3DR manufactured Pixhawk 2 for the Solo_.

I've put the latest master from yesterday up for users to install since I think it has some better logging.  And hoping some users will be willing to test it knowing their Solo could still crash at anytime.

This appears to be what happened back in this issue that at the time seemed like a watchdog issue.  As it turns out, it was the watchdog doing its job. (https://github.com/ArduPilot/ardupilot/issues/11296)

This is a video from a tablet that was screen recording at the time of the incident. It shows that the video stream, wifi link, and companion computer were still powered up and running, despite the autopilot failing. https://www.youtube.com/watch?v=a96sfrEvaWY&feature=youtu.be&t=141.  This corresponds to log # 4 in the pre enhanced logging zip file.

**Version**
ArduCopter master 3.7-dev

**Platform**
[  ] All
[  ] AntennaTracker
[X] Copter
[  ] Plane
[  ] Rover
[  ] Submarine

**Airframe type**
3DR Solo

**Hardware type**
Pixhawk 2 cube that is OEM on the Solo.  But this is really no different than any other pixhawk 2 hardware on any other vehicle.  Vehicles with this failure as far as we know all were equipped with the Solo gimbal.

**Logs**
This first zip is 4 different logs from _before the new enhanced logging._  One of these incidents happened with Watchdog enabled.  The others were either before the watchdog or with it disabled.
[Solo.Shutdown.Logs.Before.New.Logging.zip](https://github.com/ArduPilot/ardupilot/files/3323334/Solo.Shutdown.Logs.Before.New.Logging.zip)


Once we get logs using the new logs, I'll put them below.",Did you update the firmware source that Solex uses ?,".  But this is really no different than any other pixhawk 2 hardware on any other vehicle.  Vehicles with this failure as far as we know all were equipped with the Solo gimbal.Shutdown  (Before New Logging)Shutdown.Before.New.Logging.Once we get logs using the new logs, I'll put them below."
ArduPilot/ardupilot,https://github.com/ArduPilot/ardupilot/issues/12035,ArduPilot_ardupilot_issues_12035,"VTOL-Plane: TakeOff can be triggered whilst in forward flight

### Bug report

Quadplane only

**Issue details**

If a ""TakeOff"" command is sent during active flight of a VTOL plane, the aircraft will attempt to takeoff again to a new altitude =  (current altitude) + (takeoff altitude).  This is particularly dramatic as the quadplane will try to hover up to that new altitude.

After you have made this mistake once, ArduPlane will throw a ""Already flying - no takeoff"" error if you try and repeat it. (Edit: Playing around a bit more in SITL and it seems it is possible to make this happen repeatedly, but I haven't managed to pin down the requirements yet).

There is an associated UX issue in MissionPlanner where the takeoff set altitude modal is identical to the ""Fly to Here Alt"" modal, meaning you can accidentally select TakeOff in the MissionPlanner right click context menu, but think you are just setting a guided mode altitude.  More concerning is that if you press ""cancel"" on this modal, the aircraft will still try to TakeOff to the default altitude in the modal (i.e. the last guided mode altitude you set).  

To emphasise, if you accidentally click TakeOff in the context menu, there is no way that I have found to escape the following modal that doesn't cause a TakeOff instruction to be sent, leading to a potentially catastrophic outcome.

**Version**
3.9.8 in real life
3.10.0-dev in SITL

**Platform**
[  ] All
[  ] AntennaTracker
[  ] Copter
[X] Plane (VTOL only)
[  ] Rover
[  ] Submarine

**Airframe type**
Quadplane (conventional FW layout)

**Hardware type**
Pixhawk 2.1 (Cube)

**Logs**
I can provide logs later if required (I need to trim them, and change my trousers after this flight), but it is easily repeatable using the quadplane SITL model in MissionPlanner.",Can you confirm this is a vtol-only thing or not?,"Quadplane only

 of a VTOL plane (VTOL only)"
ArduPilot/ardupilot,https://github.com/ArduPilot/ardupilot/issues/12044,ArduPilot_ardupilot_issues_12044,"QGC can not detecting the pixhawk board , B/E in red color?

Hi. I met a problem after uploading the firmware built from the master branch. The codes can be compiled and uploaded. But after it is uploaded, the B/E light is always in orange color. The qgroundcontrol can not detect the pixhawk board now. Has anyone met this problem before?

-  Pixhawk 2.4.8  
-  ArduRover 3.5.1  
-  Master

$ ./waf configure --board fmuv2
The screen is like this after running the code.
I have run the './waf distclean'
before this.
Then I input '' ./waf --target bin/ardurover --upload ''
![图片](https://user-images.githubusercontent.com/9352717/63078506-45363900-bf6e-11e9-870b-bacc4c818477.png)

![图片](https://user-images.githubusercontent.com/9352717/63078489-3c456780-bf6e-11e9-897d-c245488ab0c5.png)

![图片](https://user-images.githubusercontent.com/9352717/63078516-4bc4b080-bf6e-11e9-96a0-30bf13c84f25.png)","Which board?

Which git hash?","-  Pixhawk 2.4.8  
-  ArduRover 3.5.1  
-  Master

$ ./waf configure --board fmuv2
The screen is like this after running the code.
I have run the './waf distclean'
before this.
Then I input '' ./waf --target bin/ardurover --upload ''
![图片](https://user-images.githubusercontent.com/9352717/63078506-45363900-bf6e-11e9-870b-bacc4c818477.png)

![图片](https://user-images.githubusercontent.com/9352717/63078489-3c456780-bf6e-11e9-897d-c245488ab0c5.png)

![图片](https://user-images.githubusercontent.com/9352717/63078516-4bc4b080-bf6e-11e9-96a0-30bf13c84f25.png)"
ArduPilot/ardupilot,https://github.com/ArduPilot/ardupilot/issues/12338,ArduPilot_ardupilot_issues_12338,"SmartPort telemetry doesn't work with serial option 4 on Matek F405 Wing

**Hey googlers! Using F.Port on your FrSky receiver would probably be a better option if it supports it. Solder to the Uninverted SmartPort pad and then flash it to F.Port through your radio. It should just work when you plug it into a UART with RCIN set.**


### Bug report

**Issue details**
I have an FrSky R-XSR's SmartPort (pre-inverted) wire hooked up to TX1 on my Matek F405-Wing. I have the following options set:
![image](https://user-images.githubusercontent.com/6174343/65101728-f299d380-d996-11e9-9ea8-bc17d6e0d206.png)
As I understand it, SERIAL1_OPTIONS 4 should enable half-duplex mode and it should ""just work"" since it's already been pre-inverted by the R-XSR itself, however it does not. A similar setup (softserial & halfduplex) works as expected in iNav, so I know it's not a hardware flaw.
I've also tried setting options to 7 and running with uninverted signal, which doesn't work at all either.

I am running the Yaapu telemetry script on my radio and I've also tried regular S.Port protocol 4 to no avail.

**Version**
3.10.0-FIRMWARE_VERSION_TYPE_DEV
Nightly from 9/17/19

**Platform**
[  ] All
[  ] AntennaTracker
[  ] Copter
[X] Plane
[  ] Rover
[  ] Submarine

**Airframe type**
Sonicmodell AR Wing

**Hardware type**
Matek F405-Wing

**Logs**
N/A",How have you got it wired up exactly?,Hey googlers! Using F.Port on your FrSky receiver would probably be a better option if it supports it. Solder to the Uninverted SmartPort pad and then flash it to F.Port through your radio. It should just work when you plug it into a UART with RCIN set.
Facepunch/garrysmod-issues,https://github.com/Facepunch/garrysmod-issues/issues/3520,Facepunch_garrysmod-issues_issues_3520,"ManipulateBoneScale breaks render boxes

Snipped.

Real cause posted at the bottom.",Does multiplying the render bounds manually fix it?,"Even after you revert the model's scale, the render box doesn't return to it's normal size."
w3c/csswg-drafts,https://github.com/w3c/csswg-drafts/issues/3520,w3c_csswg-drafts_issues_3520,"[css-page] [css-gcpm] Page-based counters not quite working as expected

We've just redone our counter implementation to match the current draft in css-page, and we've hit a few inconsistencies.

The language in question is [this bit](https://drafts.csswg.org/css-page-3/#page-based-counters) from css-page:

> A counter-increment within either a page or margin context causes the counter to increment with the generation of each page box.
> 
> If a counter is reset or incremented within the page context, it is in scope for all page-margin boxes and obscures all counters of the same name within the document.
> 
> If a counter is reset or incremented within a margin context, it is in scope for that page-margin box and obscures any counters of the same name in both the page context and the document.
> 
> If a counter that has not been reset or incremented within the margin context or the page context is used by counter() or counters() in the margin context, then the resultant value is exactly as if the page-margin box were an element within the document at the start of the page, inside the deepest element in the normal flow that spans the page break. Use of the counter in this way does not affect the calculation of the counter’s value.
> 

I have three issues with this.

### 1. Scoping problem

_""If a counter is reset or incremented within the page context, it is in scope for all page-margin boxes and obscures all counters of the same name within the document.""_

I don't believe this accurately conveys the intention from the original discussions, as (to me) it implies that the scope ends when the page-margin ends. The counter incremented in `@page { counter-increment: page 2 }` (from [example 20](https://drafts.csswg.org/css-page-3/#example-13051aa4)) is changing a different ""page"" counter to the the one used in the body of the document.

A qualifier was suggested when this was [first raised](https://lists.w3.org/Archives/Public/www-style/2009Apr/0368.html) but it seems to have eroded over time.

I think the intended meaning is if a counter is incremented **for the first time** - incrementing any counter without a previous reset will create a new counter. Should this instead read ""_if a counter is created within the page context_""? Created is the term used in css-lists for when a counter is reset **or** set/incremented without a previous reset. With an implied rule of `:root { counter-reset: page 0 }` this solves the scope issue.

### 2. Unnecessary qualifier in last paragraph

The last paragraph starts by telling me it only applies _if the counter has not been reset or incremented in the page context_, but it is relevant if the counter is incremented too - how else would we know what value we're incrementing? It's really just telling us where in the document to take the initial counter values from.

To illustrate with an example, lets say I have the following HTML. I've used ""section"" as a counter to illustrate this could apply to any counter, not just the obvious choice of ""page"".
```html
<html>
 <style>
  @page {
   counter-increment: section 1;
   @top-center { content: counter(section); }
  }
  :root { counter-reset: section 5 }
  div::before { content: counter(section) }
  #div2 { break-before: page }
</style>
 <body>
  <div id=""div1""></div>
  <div id=""div2""></div>
</body>
</html>
``` 
so there is a page break between div1 and div2.

![output-001](https://user-images.githubusercontent.com/989243/51131545-f5e92800-1827-11e9-94bc-f962742d047a.png)

The page-content rules are effectively inserting some boxes into the tree at the position described above: _inside the deepest element in the normal flow that spans the page break_:

![output-002](https://user-images.githubusercontent.com/989243/51131978-06e66900-1829-11e9-87ef-359e334e082b.png)

and the counter values are as shown in the boxes: 5 before the page break, 6 after.

### 3. Counter-reset in body not acting as expected.

All of which leads me up to my final concern. If I modify the style to add `#div2 { counter-reset: section 10}`, then the expectation is that div2 will be on page 10, but it's not.

![output-003](https://user-images.githubusercontent.com/989243/51132497-45305800-182a-11e9-9bd3-cb077d33f132.png)

This expectation seems pretty widespread - some examples:
* https://github.com/web-platform-tests/wpt/blob/master/css/css-page/page-counters-000.xht
* http://css4.pub/2015/malthus/essay.html (Prince)
* https://www.oxygenxml.com/events/2015/DITA_OT_Day_2015/Slides/dita-css.pdf (Oxygen XML)
* https://github.com/Kozea/WeasyPrint/issues/93 - discussion.
and I'm pretty sure it's how AH works as well.

This was also suggested in @fantasai's [original text on this](https://lists.w3.org/Archives/Public/www-style/2009Apr/0227.html):
> Copy counters in scope at all break points, in document order, into the @page counter scope, obscuring any counters of the same name there. (In CSS3, this step is not required.)

Although this somewhat depends on whether ""break points"" is the point between elements, or includes the break-causing element. Either way, as it is now this step has disappeared, and ""In CSS3 this step is not required"" has me wondering if this was intentional.

I think this step is necessary. Why? Because otherwise, the process of resetting a page counter at the start of a chapter becomes very complex. 

```html
<style>
@page :nth(1 of chapter) {
    counter-set: page 1; /* Edited, original had counter-reset by mistake */
    counter-increment: 0;
}
.chapter {
    break-before: page;
    page: chapter;
}
</style>
<section class=""chapter"">
```

You can't reset in @page:first as this [refers](https://lists.w3.org/Archives/Public/www-style/2013Oct/0567.html) to the first page in the document. The [:nth selector](https://drafts.csswg.org/css-gcpm/#document-sequence-selector) is very new and I don't think is supported by anyone, yet.

To sum up:
* Prince and AH both propagate a `counter-reset: page` on a break-causing element to the page margin.
* There is a long-held presumption that this is how it should work, and a clear requirement that it's possible.
* The alternative is complex and relies on a very new selector.

I've come to this very late and I'm sure there's a backstory to this I'm unaware of, and no doubt other implementations too. But to my mind this could be addressed by adding a paragraph:

> Copy all counters from any elements on the page that have a forced page break, in document order, to the @page counter scope, obscuring any counters of the same name.

Limiting it to break-causing elements will cover the case where an element has `break-before: page; counter-reset: page 99` while removing a lot of the complexity over determining which element on the page has precedence. <strike>This approach is similar to the one used in [css-gcpm](
https://drafts.csswg.org/css-gcpm/#document-sequence-selectors) to determine when to start a new page group.</strike> _edit: not accurate, removed_",Would that solve some of these use cases?,"/* Edited, original had counter-reset by mistake */"
Unitech/pm2,https://github.com/Unitech/pm2/issues/4206,Unitech_pm2_issues_4206,"Bug in application streaming data after update from 3.2.9 to 3.4.0

My application uses SFTP (via ssh2-promises) to copy data.

It opens a readStream (sftp.createreadstream) and a writeStream (sftp2.createwritestream) and copies data with readStream.pipe(writeStream).

After I upgraded pm2 to 3.4.0 I get strange copy errors (exception log contains ""cannot access method slice of undefined""). Error codes appear to come from my application, but breakpoints are not hit (from where the codes are sent).

As soon as I go back to 3.2.9 everything works again.",which node version are you using ?,"codes are sent).

As soon as I go back to 3.2.9 ever"
Unitech/pm2,https://github.com/Unitech/pm2/issues/4379,Unitech_pm2_issues_4379,"Environment variables in cluster mode - please reopen

This is a request to re-open issue 3062.  This issue is affecting me, and the resolution is not sufficient. https://github.com/Unitech/pm2/issues/3062

When working in fork mode, everything is fine: environment variables declared in the ecosystem are properly applied to the executable, and all is well.

However, when working in cluster mode, it looks like this is NOT the case. Rather, it seems that there is a master Node script that is running the cluster instances, and instead of running them with an environment as defined, instead environment variables are being injected with process.ENV or similar.

The problem here is that (at least on Linux systems) the LD_LIBRARY_PATH variable cannot be injected this way in order for libraries to be resolved. They must be set in the calling process. 

(In principle, the problem could be solved by setting up library RPATHs so all the external libraries point to each other, but in practice I cannot do that: my executable library chain is about 10 libraries deep, all using the environment method and I'm not even able to modify the binaries in any easy way.)


## How could we reproduce this issue?

I've created a small proof-of-principle repository here:
https://github.com/nathanieltagg/pm2-environment-test

Follow the instructions in the README on a Linux machine to see the problem. Similar problems can be shown for OSX running with DYLD_LIBRARY_PATH (in insecure mode).",Could this issue be related to #4331? I'm having an issue where pm2 is throwing an error because `process.env.pm2_env` is null.,"(In principle, the problem could be solved by setting up library RPATHs so all the external libraries point to each other, but in practice I cannot do that: my executable library chain is about 10 libraries deep, all using the environment method and I'm not even able to modify the binaries in any easy way.)


## How could we reproduce this issue?"
ankidroid/Anki-Android,https://github.com/ankidroid/Anki-Android/issues/5753,ankidroid_Anki-Android_issues_5753,"Can't use ""<"" and "">"" symbols in flashcards

###### Reproduction Steps

1. Add a new flashcard in an existing deck with ""<"" and/or "">"" symbols in it (whether it's on the front or the back doesn't matter). For instance, let's say we create a flashcard with ""Hello \<name\> on it.
2. Save the flashcard


###### Expected Result

While studying or simply browsing decks, the flashcard should show the whole content (""Hello \<name\>"" in our example from above).

###### Actual Result

The text between the ""<"" and "">"" symbols and the symbols themselves are ignored. Only ""Hello"" is displayed in our example.

Additional information : if I create the flashcard in the Anki desktop app or Ankiweb and just sync it, it displays just fine on Ankidroid.

###### Debug info

AnkiDroid Version = 2.9.1

Android Version = 7.0

ACRA UUID = 23c6ee72-7f20-4b10-a38c-8b73aa6f275a

###### Research
*Enter an [ x ] character to confirm the points below:*

[ x ] I have read the [support page](https://ankidroid.org/docs/help.html) and am reporting a bug or enhancement request specific to AnkiDroid

[ x ] I have checked the [manual](https://ankidroid.org/docs/manual.html) and the [FAQ](https://github.com/ankidroid/Anki-Android/wiki/FAQ) and could not find a solution to my issue

[ x ] I have searched for similar existing issues here and on the user forum",Can you please enter the debug info as requested? It helps us know what version you are on,"AnkiDroid Version = 2.9.1

Android Version = 7.0

AC"
openssl/openssl,https://github.com/openssl/openssl/issues/10291,openssl_openssl_issues_10291,"Some strange errors with using lybcrypto-3.dll externally 

<!--
NOTE:

    If you're asking about how to use OpenSSL, this isn't the right 
    forum.  Please see our User Support resources:
    https://github.com/openssl/openssl/blob/master/.github/SUPPORT.md

If relevant, please remember to tell us in what OpenSSL version you
found the issue.

Please remember to put ``` lines before and after any commands plus
output and code, like this:

    ```
    $ echo output output output
    output output output
    ```

    ```
    #include <stdio.h>
    
    int main() {
        int foo = 1;
        printf(""%d\n"", foo);
    }
    ```
-->

Hello! I am a Lua programmer and i need to use some of openssl cryptographic functions in Lua, such as HMAC SHA-512, so i decide to use it by the writing Dynamic Link Library in C with exported function that communicates with OpenSSL modules - they computing hash and returning it to the DLL and the DLL return this hash to the Lua code, So there is my code of DLL
in C on the MS Visual Studio 2017:

 ``` C
#define LUA_LIB
#define LUA_BUILD_AS_DLL

#include ""lua.h""
#include ""lualib.h""
#include ""lauxlib.h""
#include ""luaconf.h""
#include <openssl/hmac.h>
#include ""hmac_lcl.h""
#include ""stdafx.h""

static int forLua_Hmacsha512(lua_State *L) {

	size_t lSecret, lMsg;
	const char* secret = luaL_checklstring(L, 1, &lSecret);
	const unsigned char* msg = (const unsigned char*)luaL_checklstring(L, 2, &lMsg);

	HMAC_CTX ctx;
	HMAC_CTX_reset(&ctx);
	HMAC_Init_ex(&ctx, secret, lSecret, EVP_sha512(), NULL);

	HMAC_Update(&ctx, msg, lMsg);

	unsigned char result[129];
	unsigned int result_len = 129;
	HMAC_Final(&ctx, result, &result_len);

	lua_pushlstring(L, (const char*)result, result_len);

	return 1; 
}



LUALIB_API int __declspec(dllexport) luaopen_Hm512(lua_State* L) {
	lua_newtable(L);
	lua_pushstring(L, ""Hm512"");
	lua_pushcfunction(L, forLua_Hmacsha512);
	lua_rawset(L, -3);

	return 1;
}

```

this code need to include in Additional Dependency of Linker of properties of the project
the previously compiled into static library the Hmac sources from `\openssl-master\crypto\hmac`
and Lua51.lib ( or Lua53.lib or othe version of Lua)

After i compiled my project into DLL naming it for example Hm512 - Hm512.dll i  tried to use it in lua script to get Hmac Sha-512  hash, for this it needs to put libcrypto-3.dll  and compiled Hmac512.dll in the folder of Lua interpreter binaries
Lua script looks like this:
```
hm = require (""Hm512"")

x=hm.Hm512(""sfgds"",""drgsd"")
```
after trying to execute this script it always gives me error and Windows suggest me an option - stops the program Lua.exe or debug it, if i choose to debug it with Visual Studio i see this:
https://cloud.mail.ru/public/EudE%2FSr82auPUz
https://cloud.mail.ru/public/G9MM%2FLxkm1Jbq3
So the C code stops on the error in string -  
```
if (!EVP_MD_CTX_test_flags(ctx, EVP_MD_CTX_FLAG_KEEP_PKEY_CTX))      
```
Unhandled exception thrown: read acces violation. ctx was 0xCCCCCCCC 
![Ashampoo_Snap_29 октября 2019 г _20h44m47s_026_](https://user-images.githubusercontent.com/21098903/67794144-14957400-fa74-11e9-916d-e9e4748b7c18.jpg)

![Ashampoo_Snap_29 октября 2019 г _20h06m00s_025_](https://user-images.githubusercontent.com/21098903/67793827-7b665d80-fa73-11e9-9019-c938bccd0a58.jpg)


by calling function   EVP_MD_CTX_test_flags
from the \openssl-master\crypto\evp\digest.c  line 910:
```
int EVP_MD_CTX_test_flags(const EVP_MD_CTX *ctx, int flags)
```

So i tried to build my Hm512.dll library with previous versions of OpenSSL and its libcrypto.dll, of openssl  - 1.1.1d,  1.1.0l and others, and to execute my Lua script with newly builded Hm512.dll library on its sources and with libcrypto.dll  of its version openssl, and libcrypto.dll of all version of OpenSSL gives me the same error:
```
if (!EVP_MD_CTX_test_flags(ctx, EVP_MD_CTX_FLAG_KEEP_PKEY_CTX))      
```
Unhandled exception thrown: read acces violation. ctx was 0xCCCCCCCC  

by calling function   EVP_MD_CTX_test_flags
from the \openssl-master\crypto\evp\digest.c  line :
```
int EVP_MD_CTX_test_flags(const EVP_MD_CTX *ctx, int flags)
```
How it may be that your library throwns error if try to use it externally?","Do I understand correctly, that Hm512.dll is a compilation of the source from OpenSSL's `crypto/hmac` into a separate library? If that is the case... Why?","![Ashampoo_Snap_29 октября 2019 г _20h05m31s_024_](https://user-images.githubusercontent.com/21098903/67793818-76091300-fa73-11e9-9272-7f86fe2352ec.jpg)
![Ashampoo_Snap_29 октября 2019 г _20h06m00s_025_](https://user-images.githubusercontent.com/21098903/67793827-7b665d80-fa73-11e9-9019-c938bccd0a58.jpg)"
openssl/openssl,https://github.com/openssl/openssl/issues/11567,openssl_openssl_issues_11567,"semantic bug when verifying certificate file

<!--
Thank you for your bug report. If this is your first one,
please take the time to read the following lines before posting it.

NOTE:

    If you're asking about how to use OpenSSL, this isn't the right 
    forum.  Please see our User Support resources:
    https://github.com/openssl/openssl/blob/master/.github/SUPPORT.md

Please remember to tell us in what OpenSSL version you found the issue.

For build issues:

    If this is a build issue, please include the configuration output
    as well as a log of all errors.  Don't forget to include the exact
    commands you typed.

    With OpenSSL before 1.1.1, the configuration output comes from the
    configuration command.  With OpenSSL 1.1.1 and on, it's the output
    of `perl configdata.pm --dump`

For other issues:

    If it isn't a build issue, example code or commands to reproduce
    the issue is highly appreciated.
    Also, please remember to tell us if you worked with your own
    OpenSSL build or if it is system provided.

Please remember to put ``` lines before and after any commands plus
output and code, like this:

    ```
    $ echo output output output
    output output output
    ```

    ```
    #include <stdio.h>
    
    int main() {
        int foo = 1;
        printf(""%d\n"", foo);
    }
    ```
-->
I found a potential semantic bug when verifying certificate file.
The results (exit status & output) are different between Libressl (3.1.0)  and openssl (commit 031c9bd3f3e9a02fa126c7dbc47f3d934678a195)

How to reproduce :
`openssl x509 -in $PoC -text -noout`

Here's the certificate.
```
-----BEGIN CERTIFICATE-----
MIICUTCCAfugAwIBAgKBADANBgkqhkiG9w0BAQQFADBXMQswCQYDVQQGEwJDTjEL
MAkGA1UECBMCUE4xCzAJBgNVBAcTAkNOMQswCQYDVQQKEwJPTjELMAkGA1UECxMC
VU4xFDASBgNVBAMTC0hlcm9uZyBZYW5nMB4XDTA1MDcxNTIxMTk0N1oXDTA1MDgx
NDIxMTk0N1owVzELMAkGA1UEBhMCQ04xCzAJBgNVBAgTAlBOMQswCQYDVQQHEwJD
TjELMAkGA1UEChMCT04xCzAJBgNVBAsTAlVOMRQwEgYDVQQDEwtIZXJvbmcgWWFu
ZzBcMA0GCSqGSIb3fQEBAQUAA0sAMEgCQJCp5hnG7ogBhtlynpOS21cBewKE/B7j
V14qey3lnr26xZUsSVko36ZnhiaO/zbMOoRcKK9vEcgMtcLFuQTWDN3RAgMBAAGj
gbEwga4wHQYDVR0OBBYEFFXI70krXeQDxZgbaCQoR4jUDncEMH8GA1UdIwR4MHaA
FFXI70krXeQDxZgbaCQoR4jUDncEoVukWTBXMQswCQYDVQQGEwJDTjELMAkGA1UE
CBMCUE4xCzAJBgNVBAcTAkNOMQswCQYDVQQKEwJPTjELMAkGA1UECxMCVU4xFDAF
BgNVBAMTC0hlcm9uZyBZYW5nggEAMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEE
BQADQQA/ugzBrjjK9jcWnDVfGHlk3icNRq0oV7Ri32z/+HQX67aRfgZu7KWdI+Ju
Wm7DCfrPNGVwFWUQOmsPue9rZBgO
-----END CERTIFICATE-----
```
[PoC](https://github.com/SuhwanSong/PoC/blob/master/ssl/issue%2311567)

Here's log.

program : Libressl
```
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 0 (0x0)
    Signature Algorithm: md5WithRSAEncryption
        Issuer: C=CN, ST=PN, L=CN, O=ON, OU=UN, CN=Herong Yang
        Validity
            Not Before: Jul 15 21:19:47 2005 GMT
            Not After : Aug 14 21:19:47 2005 GMT
        Subject: C=CN, ST=PN, L=CN, O=ON, OU=UN, CN=Herong Yang
        Subject Public Key Info:
            Public Key Algorithm: 1.2.840.113661.1.1.1
            Unable to load Public Key
140462724956608:error:06FFF09C:digital envelope routines:CRYPTO_internal:unsupported algorithm:evp/p_lib.c:245:
140462724956608:error:0BFFF06F:x509 certificate routines:CRYPTO_internal:unsupported algorithm:asn1/x_pubkey.c:197:
        X509v3 extensions:
            X509v3 Subject Key Identifier: 
                55:C8:EF:49:2B:5D:E4:03:C5:98:1B:68:24:28:47:88:D4:0E:77:04
            X509v3 Authority Key Identifier: 
                0v..U..I+].....h$(G...w..[.Y0W1.0...U....CN1.0...U....PN1.0...U....CN1.0...U.
..ON1.0...U....UN1.0...U....Herong Yang...
            X509v3 Basic Constraints: 
                CA:TRUE
    Signature Algorithm: md5WithRSAEncryption
         3f:ba:0c:c1:ae:38:ca:f6:37:16:9c:35:5f:18:79:64:de:27:
         0d:46:ad:28:57:b4:62:df:6c:ff:f8:74:17:eb:b6:91:7e:06:
         6e:ec:a5:9d:23:e2:6e:5a:6e:c3:09:fa:cf:34:65:70:15:65:
         10:3a:6b:0f:b9:ef:6b:64:18:0e

exit status : 0
```

program : openssl (commit 031c9bd3f3e9a02fa126c7dbc47f3d934678a195)
```
unable to load certificate
40:B7:E2:82:0C:7F:00:00:error:asn1 encoding routines:c2i_ibuf:illegal zero content:crypto/asn1/a_int.c:154:
40:B7:E2:82:0C:7F:00:00:error:asn1 encoding routines:asn1_template_noexp_d2i:nested asn1 error:crypto/asn1/tasn_dec.c:629:Field=serialNumber, Type=X509_CINF
40:B7:E2:82:0C:7F:00:00:error:asn1 encoding routines:asn1_template_noexp_d2i:nested asn1 error:crypto/asn1/tasn_dec.c:629:Field=cert_info, Type=X509
40:B7:E2:82:0C:7F:00:00:error:PEM routines:PEM_ASN1_read_bio:ASN1 lib:crypto/pem/pem_oth.c:33:

exit status : 1
```

Environment :
  Description: Ubuntu 18.04.1 LTS
  Release: 18.04",Could you please add the certificate in question as a PEM format?,"Here's the certificate.
```
-----BEGIN CERTIFICATE-----
MIICUTCCAfugAwIBAgKBADANBgkqhkiG9w0BAQQFADBXMQswCQYDVQQGEwJDTjEL
MAkGA1UECBMCUE4xCzAJBgNVBAcTAkNOMQswCQYDVQQKEwJPTjELMAkGA1UECxMC
VU4xFDASBgNVBAMTC0hlcm9uZyBZYW5nMB4XDTA1MDcxNTIxMTk0N1oXDTA1MDgx
NDIxMTk0N1owVzELMAkGA1UEBhMCQ04xCzAJBgNVBAgTAlBOMQswCQYDVQQHEwJD
TjELMAkGA1UEChMCT04xCzAJBgNVBAsTAlVOMRQwEgYDVQQDEwtIZXJvbmcgWWFu
ZzBcMA0GCSqGSIb3fQEBAQUAA0sAMEgCQJCp5hnG7ogBhtlynpOS21cBewKE/B7j
V14qey3lnr26xZUsSVko36ZnhiaO/zbMOoRcKK9vEcgMtcLFuQTWDN3RAgMBAAGj
gbEwga4wHQYDVR0OBBYEFFXI70krXeQDxZgbaCQoR4jUDncEMH8GA1UdIwR4MHaA
FFXI70krXeQDxZgbaCQoR4jUDncEoVukWTBXMQswCQYDVQQGEwJDTjELMAkGA1UE
CBMCUE4xCzAJBgNVBAcTAkNOMQswCQYDVQQKEwJPTjELMAkGA1UECxMCVU4xFDAF
BgNVBAMTC0hlcm9uZyBZYW5nggEAMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEE
BQADQQA/ugzBrjjK9jcWnDVfGHlk3icNRq0oV7Ri32z/+HQX67aRfgZu7KWdI+Ju
Wm7DCfrPNGVwFWUQOmsPue9rZBgO
-----END CERTIFICATE-----
```"
pixijs/pixi.js,https://github.com/pixijs/pixi.js/issues/5470,pixijs_pixi.js_issues_5470,"[Performance] Speed of playing animation is sometimes strangely fast in ios

Edit:

I find that I am wrong.
The problem doesn't happen in iOS, but in machines with poor hardware.

--
I run dragonbones skeleton animation with PIXI.
(Sorry I am not sure is it appropriate to ask here)

> this.factory = dragonBones.PixiFactory.factory;
> this.armatureDisplay = this.factory.buildArmatureDisplay('Bone', name);
> this.addChild(this.armatureDisplay);
> this.armatureDisplay.animation.play(actionName);

It's good in Chrome running in windows / android.
But the speed of playing animation is sometimes strangely fast in ios.
If I play the animation continuously, it works fine.
But if I wait for few seconds and then play it, the animation speed will be strangely fast!

### Environment

- **`pixi.js` version**: 4.8.5
- **Browser & Version**: Chrome 72
- **OS & Version**: ios12.1",Could you please provide more information @chilin99999 or an example that we can test? It’s hard to know what you mean by strangely fast. Thanks.,"Edit:

I find that I am wrong.
The problem doesn't happen in iOS, but in machines with poor hardware.

--"
pixijs/pixi.js,https://github.com/pixijs/pixi.js/issues/5654,pixijs_pixi.js_issues_5654,"Setting resolution to 2 flips canvas V5

### Expected Behavior
Resolution to be 2 for retina devices
PIXI.settings.RESOLUTION = 2;

***Edit***
This is happening while exporting to base64 image.

### Current Behavior

Setting resolution to 2 flips and skews the canvas


- **`pixi.js` version**: 5
- **Browser & Version**: chrome latest
- **OS & Version**: mojave","Did you put `resolution` param into renderer options?

```js
let app = new PIXI.Application({ width, height, resolution:2 } );
//or
let renderer= new PIXI.Renderer({ width, height, resolution:2 } );
```","***Edit***
This is happening while exporting to base64 image."
pixijs/pixi.js,https://github.com/pixijs/pixi.js/issues/6303,pixijs_pixi.js_issues_6303,"Filter padding should be additive

<!--
Thank you for reporting an issue!

Before opening an issue _please_ check if a similar issue exists by
searching existing issues (https://github.com/pixijs/pixi.js/issues).

If possible, please provide code that demonstrates the problem.
Links to a running example of the problem are best!

Before submitting please read:

Contributors guide: https://github.com/pixijs/pixi.js/blob/dev/.github/CONTRIBUTING.md
Code of Conduct: https://github.com/pixijs/pixi.js/blob/dev/.github/CODE_OF_CONDUCT.md
-->

<!-- Bug Report (delete if not applicable) -->
### Expected Behavior

Since each filter sees the result of calculations of the previous one, filter padding should be calculated additively. 

### Current Behavior

Right now the maximum padding is used. If you had 2 outline filters for instance, the second filter would get cut off.

https://github.com/pixijs/pixi.js/blob/873b65041bd3a5d173b0e0e10fa93be68bc033d9/packages/core/src/filters/FilterSystem.js#L194

### Possible Solution

I'd be all for including filter padding in the bounds calculation. Then other code wouldn't have to worry about filter padding anymore. For instance ``cacheAsBitmap = true`` will cut filters off if they're on a child element, because it doesn't take filter padding into account properly at all (there are multiple issues with how it calculates those).

### Environment

* **`pixi.js` version**:  5.20",Do you happen to know if that was the case for Adobe Flash? I can test it in a week when I go back to my work after holidays :),**Edit:** Actually not. This misses filters on parent containers.
pixijs/pixi.js,https://github.com/pixijs/pixi.js/issues/6299,pixijs_pixi.js_issues_6299,"After destroying an object

I found out when I was using tween

```
var Container = new PIXI.Container();
.....
.....
Container.destroy({children:true});
.....
if(Container._destroyed){
  stopTween()
}

```
-------------------------------------
**These values will give an error message {width，height，..} [TypeError: ..]**
```
{
   width:[TypeError: Cannot read property 'scale' of null
    at Container.prototypeAccessors.scale.get (webpack-internal:///./node_modules/@pixi/display/lib/display.es.js:1040:31)
    at Container.prototypeAccessors.width.get (webpack-internal:///./node_modules/@pixi/display/lib/display.es.js:1851:21)
    at Container.invokeGetter (<anonymous>:1:142)],

height:[TypeError: .......]
.....
 _destroyed: true,  //  OK
}
```
Does this affect performance？",What exactly?,**// These values will give an error message**{width，height，..}
pixijs/pixi.js,https://github.com/pixijs/pixi.js/issues/6321,pixijs_pixi.js_issues_6321,"Bounds Problem In Case Of Negative Width Passed To DrawRect

<!--
Thank you for reporting an issue!

Before opening an issue _please_ check if a similar issue exists by
searching existing issues (https://github.com/pixijs/pixi.js/issues).

If possible, please provide code that demonstrates the problem.
Links to a running example of the problem are best!

Before submitting please read:

Contributors guide: https://github.com/pixijs/pixi.js/blob/dev/.github/CONTRIBUTING.md
Code of Conduct: https://github.com/pixijs/pixi.js/blob/dev/.github/CODE_OF_CONDUCT.md
-->

<!-- Bug Report (delete if not applicable) -->
### Expected Behavior
Graphics return positive width and height instead of 0s
### Current Behavior
Graphics returned 0 value for both width and height
Please also have a look at the console output for bounds, we got INFINITY, which is also a problem.

![BoundsProblemInCaseOfNegativeWidthPassedToDrawRect](https://user-images.githubusercontent.com/17470555/72149372-f1753200-33dd-11ea-935f-8a92ed5343dc.png)

### Possible Solution

### Steps to Reproduce
https://github.com/andyc365/for-pixi/blob/master/src/views/Home.vue

### Environment

- **`pixi.js` version**: 5.2.0
- **Browser & Version**: _e.g. Chrome 67_
- **OS & Version**: _e.g. Ubuntu 18.04_
- **Running Example**: _url_","Do you know if any other 2D renderer supports negative width and height there?

I think that's undefined behaviour.","Please also have a look at the console output for bounds, we got INFINITY, which is also a problem."
exercism/exercism,https://github.com/exercism/exercism/issues/4240,exercism_exercism_issues_4240,"[Markdown] Comment box rendered / removed html markup that was part of a code snippet

As part of a conversation with a student, I posted some code in the comment field that included html markup, something like this:

```html
<h1>This is an h1 header</h1>
<p>This is a paragraph</p>
<strong>Some strong text</strong>
<ul><li>List item 1</li><li>List item 2</li></ul>
```

When viewing it in the ""Preview"" tab, or after clicking the ""Comment"" button, it seems to render the html markup (as can be seen with ""List item 1"" and ""List item 2"" below) but then not show any of the other effects (such as the H1 header and strong text that isn't actually in bold).

```text
This is an h1 header
This is a paragraph
Some strong text

List item 1
List item 2

```",Which one do we use?,"code in the comment field that included html markup, something like this:

```html
<h1>This is an h1 header</h1>
<p>This is a paragraph</p>
<strong>Some strong text</strong>
<ul><li>List item 1</li><li>List item 2</li></ul>
```

When viewing it in the ""Preview"" tab, or after clicking the """
exercism/exercism,https://github.com/exercism/exercism/issues/4321,exercism_exercism_issues_4321,"Can't download exercises

I recently upgraded to the latest version of exercism (3.0.9) and now I can't download exercises while at work.  I have the http_proxy and https_proxy environment variables set and everything worked on a previous version (2.2.6) but now it doesn't.  

Any suggestions?

Here is a dump of exercism troubleshoot
> exercism.exe troubleshoot

<details>
<summary> Troubleshooting Information</summary>

```
Troubleshooting Information
===========================

Version
----------------
Current: 3.0.9
Latest:  <unknown>

Error: Get https://api.github.com/repos/exercism/cli/releases/latest: proxyconnect tcp: EOF

Call 'exercism upgrade' to get the latest version.
See the release notes at https://github.com/exercism/cli/releases/tag/ for details.


Operating System
----------------
OS:           windows
Architecture: amd64


Configuration
----------------
Home:      C:\Users\crchapma
Workspace: C:\Users\crchapma\Exercism (default)
Config:    C:\Users\crchapma\AppData\Roaming\exercism
API key:   <not configured>
Find your API key at https://exercism.io/my/settings

API Reachability
----------------

GitHub:
    * https://api.github.com
    * [Get https://api.github.com: proxyconnect tcp: EOF]
    * 3.0241ms

Exercism:
    * https://api.exercism.io/v1/ping
    * [Get https://api.exercism.io/v1/ping: proxyconnect tcp: EOF]
    * 3.0241ms


If you are having trouble please file a GitHub issue at
https://github.com/exercism/exercism.io/issues and include
this information.
```
</details>

_Edited for formatting -kytrinyx_",Did you happen to use successfully any other versions of v3 prior to 3.0.9?,"<details>
<summary> Troubleshooting Information</summary>

```
```
</details>

_Edited for formatting -kytrinyx_"
exercism/exercism,https://github.com/exercism/exercism/issues/5155,exercism_exercism_issues_5155,"Feature request: Better exercise navigation in practice mode

This would be extra helpful for us doing things in practice mode to choose the ""core exercises"" over side exercises.

For example: Allow filtering of exercises by (preferably check-box) core / side.

*Edit by @sshine: Changed title into example in body.*",What is the reason you want to choose between core and side in practice mode?,"For example: Allow filtering of exercises by (preferably check-box) core / side.

*Edit by @sshine: Changed title into example in body.*"
ARMmbed/mbed-os,https://github.com/ARMmbed/mbed-os/issues/8146,ARMmbed_mbed-os_issues_8146,"Error at compile MCC app with K64F bootloader

### Description

Evaluating 5.10 (RC2) and the Pelion device management feature with mbed-cloud-client-example-sources-internal app (sorry internal only).

I'm seeing an error at the last step of the compile process (merge with bootloader)

```
mbed import mbed-cloud-client-example-sources-internal
cd mbed-cloud-client-example-sources-internal
mbed update 2.0.0-RC2
<CLOUD_SDK_API_KEY already set>
mbed dm init -d ""arm.com"" --model-name ""mbed"" -v -q --force
mbed compile -t GCC_ARM -m K64F -c -v
...
Merging Regions
  Filling region bootloader with /Users/ms/mbed/OOB/5.10/mbed-cloud-client-example-sources-internal/mbed-os/features/FEATURE_BOOTLOADER/targets/TARGET_Freescale/TARGET_MCUXpresso_MCUS/TARGET_MCU_K64F/TARGET_FRDM/mbed-bootloader-k64f-block_device-sotp-v3_4_0.bin
  Padding region bootloader with 0x9a4 bytes
Traceback (most recent call last):
  File ""/Users/ms/mbed/OOB/5.10/mbed-cloud-client-example-sources-internal/mbed-os/tools/make.py"", line 293, in <module>
    ignore=options.ignore
  File ""/Users/ms/mbed/OOB/5.10/mbed-cloud-client-example-sources-internal/mbed-os/tools/build_api.py"", line 548, in build_project
    merge_region_list(region_list, res, notify)
  File ""/Users/ms/mbed/OOB/5.10/mbed-cloud-client-example-sources-internal/mbed-os/tools/build_api.py"", line 423, in merge_region_list
    _fill_header(region_list, region).tofile(header_filename, format='hex')
  File ""/Users/ms/mbed/OOB/5.10/mbed-cloud-client-example-sources-internal/mbed-os/tools/build_api.py"", line 380, in _fill_header
    header.puts(start, struct.pack(fmt, time()))
struct.error: required argument is not an integer
[mbed] ERROR: ""/usr/local/opt/python/bin/python3.7"" returned error.
       Code: 1
       Path: ""/Users/ms/mbed/OOB/5.10/mbed-cloud-client-example-sources-internal""
       Command: ""/usr/local/opt/python/bin/python3.7 -u /Users/ms/mbed/OOB/5.10/mbed-cloud-client-example-sources-internal/mbed-os/tools/make.py -t GCC_ARM -m K64F --source . --build ./BUILD/K64F/GCC_ARM -c -v""
       Tip: You could retry the last command with ""-v"" flag for verbose output
---
```

This makes me think there is a problem with the bootloader, the tools or the app.

[ ] Question  
[ ] Enhancement  
[X] Bug  

EDIT: Environment
- OSX El Capital
- Mbed CLI 1.8.1
- Python 3.7
- Mbed Cloud SDK 2.0.1

@theotherjimmy @teetak01 can you please have a look and comment?",Might this be related to specific pip components versions or did you do any changes to mbed_app.json? I tested with python-sdk 2.0.0 and 2.0.1,"EDIT: Environment
- OSX El Capital
- Mbed CLI 1.8.1
- Python 3.7
- Mbed Cloud SDK 2.0.1"
ARMmbed/mbed-os,https://github.com/ARMmbed/mbed-os/issues/12587,ARMmbed_mbed-os_issues_12587,"Cellular: How to reconnecting cellular network

### Description of defect

My environment is not possible to connect to cellular network.
If an error occurs in connect (), calling disconnect () and connect () will freeze.
How is it correct to write code?

**Code snippet:**
```cpp
ctx = (AT_CellularContext*)CellularContext::get_default_instance();
if (ctx == NULL) abort();

while (true)
{
	nsapi_error_t ret;

        ...

	print_function(""connect()\n"");
	ctx->set_default_parameters();
	const uint16_t timeoutArray[]{ 60 };
	ctx->get_device()->set_retry_timeout_array(timeoutArray, extent<decltype(timeoutArray)>::value);
	if ((ret = ctx->connect()) != NSAPI_ERROR_OK)
	{
		print_function(""ret = %d\n"", (int)ret);

		print_function(""disconnect()\n"");
		ret = ctx->disconnect();
		print_function(""ret = %d\n"", (int)ret);
		continue;
	}

        ...
}
```
[log.txt](https://github.com/ARMmbed/mbed-os/files/4296576/log.txt)

See also:
[Network connectivity states](https://os.mbed.com/docs/mbed-os/v5.15/apis/network-interfaces.html)

#### Target(s) affected by this defect ?

QUECTEL/EC2X ([here](https://github.com/ARMmbed/mbed-os/tree/master/features/cellular/framework/targets/QUECTEL/EC2X))

#### Toolchain(s) (name and version) displaying this defect ?

GNU Arm Embedded Toolchain.
Version 9-2019-q4-major

#### What version of Mbed-os are you using (tag or sha) ?

mbed-os-5.15.0

#### What version(s) of tools are you using. List all that apply (E.g. mbed-cli)

mbed-cli with GCC_ARM

#### How is this defect reproduced ? 

Try connecting in a location where cellular communication is not possible.",Could you please update the issue header accordingly?,"Toolchain(s) (name and version) displaying this defect ?

GNU Arm Embedded Toolchain.
Version 9-2019-q4-major

#### .0
#### How is this defect reproduced ? 

Try connecting in a location where cellular communication is not possible."
ARMmbed/mbed-os,https://github.com/ARMmbed/mbed-os/issues/10352,ARMmbed_mbed-os_issues_10352,"ATHandler.cpp malloc undefined

<!--

   ************************************** WARNING **************************************

   The ciarcom bot parses this header automatically. Any deviation from the 
   template may cause the bot to automatically correct this header or may result in a 
   warning message, requesting updates.

   Please ensure that nothing follows the Issue request type section, all 
   issue details are within the Description section and no changes are made to the 
   template format (as detailed below).

   *************************************************************************************

-->

### Description
I am getting build errors if cellular traces are enabled. The error points to [this ](https://github.com/ARMmbed/mbed-os/blob/aff381579034006ece5c7df37633f2bca95f162b/features/cellular/framework/AT/ATHandler.cpp#L1292)line. Wouldn't it be better to use new/delete instead of malloc free as we are in .cpp?
```
Building project latestmbed (UBLOX_C027, ARMC5)
Scan: latestmbed
Compile [100.0%]: ATHandler.cpp
[Error] ATHandler.cpp@1292,0:  #20: identifier ""malloc"" is undefined
[Error] ATHandler.cpp@1322,0:  #20: identifier ""free"" is undefined
[ERROR] "".\mbed-os\features\cellular\framework\AT\ATHandler.cpp"", line 1292: Error:  #20: identifier ""malloc"" is undefined
"".\mbed-os\features\cellular\framework\AT\ATHandler.cpp"", line 1322: Error:  #20: identifier ""free"" is undefined
.\mbed-os\features\cellular\framework\AT\ATHandler.cpp: 0 warnings, 2 errors
```
<!--
    Required
    Add detailed description of what you are reporting.
    Good example: https://os.mbed.com/docs/mbed-os/latest/contributing/workflow.html
    Things to consider sharing:
    - What target does this relate to?
    - What toolchain (name + version) are you using?
    - What tools (name + version - is it mbed-cli, online compiler or IDE) are you using?
    - What is the SHA of Mbed OS (git log -n1 --oneline)?
    - Steps to reproduce. (Did you publish code or a test case that exhibits the problem?)
-->


### Issue request type

<!--
    Required
    Please add only one X to one of the following types. Do not fill multiple types (split the issue otherwise.)
    Please note this is not a GitHub task list, indenting the boxes or changing the format to add a '.' or '*' in front
    of them would change the meaning incorrectly. The only changes to be made are to add a description text under the
    description heading and to add a 'x' to the correct box.
-->
    [ ] Question
    [ ] Enhancement
    [X] Bug",May I ask the name and specs of the board you are using ?,"```
Building project latestmbed (UBLOX_C027, ARMC5)
Scan: latestmbed
Compile [100.0%]: ATHandler.cpp
[Error] ATHandler.cpp@1292,0:  #20: identifier ""malloc"" is undefined
[Error] ATHandler.cpp@1322,0:  #20: identifier ""free"" is undefined
[ERROR] "".\mbed-os\features\cellular\framework\AT\ATHandler.cpp"", line 1292: Error:  #20: identifier ""malloc"" is undefined
"".\mbed-os\features\cellular\framework\AT\ATHandler.cpp"", line 1322: Error:  #20: identifier ""free"" is undefined
.\mbed-os\features\cellular\framework\AT\ATHandler.cpp: 0 warnings, 2 errors
```"
ARMmbed/mbed-os,https://github.com/ARMmbed/mbed-os/issues/12788,ARMmbed_mbed-os_issues_12788,"CAN: Remote frame is not working for H743ZI2

<!--

   ************************************** WARNING **************************************

   The ciarcom bot parses this header automatically. Any deviation from the 
   template may cause the bot to automatically correct this header or may result in a 
   warning message, requesting updates.

   Please ensure all sections of the template below are filled in and no changes 
   are made to the template format. Only bugs should be raised here as issues. 
   Questions or enhancements should instead be raised on our forums:
   https://forums.mbed.com/ .

   *************************************************************************************

-->

### Description of defect
I am trying to send the remote type CAN message using the CAN API, the write function returns 1 (success), however at the receiver side its not being reflected as ""CANRemote"" Type. Other parameters are working as expected only the type(CANRemote) is having the issue. I've observed only on NUCLEO_H743ZI2, I am not sure about other NUCLEO targets. 
 
<!--
    Add detailed description of what you are reporting.
    Good example: https://os.mbed.com/docs/mbed-os/latest/contributing/workflow.html
-->


#### Target(s) affected by this defect ?
TARGET_NUCLEO_H743ZI2


#### Toolchain(s) (name and version) displaying this defect ?
GNU Arm Embedded Toolchain V7.2.1

#### What version of Mbed-os are you using (tag or sha) ?
<!--
    For a released version please provide the release tag (this can be found as per the instructions below)

    mbed-os version can be found in /platform/mbed_version.h. The tag can be reconstructed as follows:
    mbed-os-MBED_MAJOR_VERSION.MBED_MINOR_VERSION.MBED_PATCH_VERSION
 
    Master branch is indicated by 'mbed-os-99.99.99
    
    For an issue found on Master please provide the sha being used.
-->
mbed-os-5.14.1

#### What version(s) of tools are you using. List all that apply (E.g. mbed-cli)
NA

#### How is this defect reproduced ?

Observe only printf(""Data: %d, Type:CANData\n"", msg.data[0]); is being printed.

```
#include ""mbed.h""

Ticker ticker;

DigitalOut led1(LED1);
DigitalOut led2(LED2);

CAN can1(MBED_CONF_APP_CAN1_RD, MBED_CONF_APP_CAN1_TD);
CAN can2(MBED_CONF_APP_CAN2_RD, MBED_CONF_APP_CAN2_TD);
char counter = 0;

void send() {
  CANMessage msg;
  msg.id = 123;
  msg.type = CANRemote;
  msg.format = CANStandard;
  msg.len = 1;
  msg.data[0] = counter;
  if (can1.write(msg)) {
    counter++;
    printf(""Message sent: %d\n"", counter);
  }
  led1 = !led1;
}

int main() {
  ticker.attach( & send, 1);
  CANMessage msg;
  while (1) {
    if (can2.read(msg)) {
      if (msg.type == CANRemote) {
        printf(""Data: %d, Type:CANRemote\n"", msg.data[0]);
      } else {
        printf(""Data: %d, Type:CANData\n"", msg.data[0]);
      }
      led2 = !led2;
    }
    wait(0.2);
  }
}

```","What are mbed_app.json values?
Is your setup working with other targets?

Thx","<!--

   ************************************** WARNING **************************************

   The ciarcom bot parses this header automatically. Any deviation from the 
   template may cause the bot to automatically correct this header or may result in a 
   warning message, requesting updates.

   Please ensure all sections of the template below are filled in and no changes 
   are made to the template format. Only bugs should be raised here as issues. 
   Questions or enhancements should instead be raised on our forums:
   https://forums.mbed.com/ .

   *************************************************************************************

-->

Description of defect
I am trying to send the remote type CAN message using the CAN API, the write function returns 1 (success), however at the receiver side its not being reflected as ""CAN, I am not sure about other NUCLEO targets. 
 
<!--
    Add detailed description of what you are reporting.
    Good example: https://os.mbed.com/docs/mbed-os/latest/contributing/workflow.html
-->
TARET_What version of Mbed-os are you using (tag or sha) ?
<!--
    For a released version please provide the release tag (this can be found as per the instructions below)

    mbed-os version can be found in /platform/mbed_version.h. The tag can be reconstructed as follows:
    mbed-os-MBED_MAJOR_VERSION.MBED_MINOR_VERSION.MBED_PATC_VERSION
 
    Master branch is indicated by 'mbed-os-99.99.99
    
    For an issue found on Master please provide the sha being used.
-->
mbed-os-5.14.1

#### What version(s) of tools are you using. List all that apply (E.g. mbed-cli)
NA

#### H"
ARMmbed/mbed-os,https://github.com/ARMmbed/mbed-os/issues/12021,ARMmbed_mbed-os_issues_12021,"Problems exporting to keil uvision 

I have a NXP LPC1768 and I've exported a project from mbed online compiler to keil uvision but I can't build becuase there are several erros:
```

Rebuild started: Project: ___USBMIDI_HelloWorld
*** Using Compiler 'V6.12', folder: 'C:\Keil_v5\ARM\ARMCLANG\Bin'
Rebuild target '___USBMIDI_HelloWorld'
error: invalid value '' in '-std='
note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard
note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and GNU extensions' standard
note: use 'c++11' for 'ISO C++ 2011 with amendments' standard
note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU extensions' standard
note: use 'c++14' for 'ISO C++ 2014 with amendments' standard
note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU extensions' standard
note: use 'c++17' for 'ISO C++ 2017 with amendments' standard
note: use 'gnu++17' for 'ISO C++ 2017 with amendments and GNU extensions' standard
note: use 'c++2a' for 'Working draft for ISO C++ 2020' standard
note: use 'gnu++2a' for 'Working draft for ISO C++ 2020 with GNU extensions' standard
compiling main.cpp...
error: invalid value '' in '-std='
note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard
note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and GNU extensions' standard
note: use 'c++11' for 'ISO C++ 2011 with amendments' standard
note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU extensions' standard
note: use 'c++14' for 'ISO C++ 2014 with amendments' standard
note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU extensions' standard
note: use 'c++17' for 'ISO C++ 2017 with amendments' standard
note: use 'gnu++17' for 'ISO C++ 2017 with amendments and GNU extensions' standard
note: use 'c++2a' for 'Working draft for ISO C++ 2020' standard
note: use 'gnu++2a' for 'Working draft for ISO C++ 2020 with GNU extensions' standard
compiling USBMIDI.cpp...
USBMIDI/usbdevice.c(23): warning: In file included from...
USBMIDI/usbcore.h(26): warning: In file included from...
mbed\mbed.h(22): warning: In file included from...
mbed/DigitalIn.h(12): warning: In file included from...
mbed/Base.h(12): error: 'cstdlib' file not found
#include <cstdlib>
         ^~~~~~~~~
1 error generated.
compiling usbdevice.c...
USBMIDI/usbcore.c(23): warning: In file included from...
USBMIDI/usbcore.h(26): warning: In file included from...
mbed\mbed.h(22): warning: In file included from...
mbed/DigitalIn.h(12): warning: In file included from...
mbed/Base.h(12): error: 'cstdlib' file not found
#include <cstdlib>
         ^~~~~~~~~
1 error generated.
compiling usbcore.c...
"".\BUILD\___USBMIDI_HelloWorld.axf"" - 4 Error(s), 0 Warning(s).
Target not created.
Build Time Elapsed:  00:00:01

```

My uvision version is MDK-ARM Version 5.27.1.0, the tool form mbed compiler forces to me use the arm compiler v6 and the project is mbed 2, I use this version because I don't konw how I can make using a project with USB MIDI but I've tried projects with version 5 and they don't compile

The code that I'm using is USBMIDI_HelloWorld - main.cpp from https://os.mbed.com/cookbook/USBMIDI , I wanted to use this project as template

Thanks
Regards","What uvision do you have locally, what code are you cloning (version of Mbed OS) ?","My uvision version is MDK-ARM Version 5.27.1.0, the tool form mbed compiler forces to me use the arm compiler v6 and the project is mbed 2, I use this version because I don't konw how I can make using a project with USB MIDI using the mbed os 5."
ARMmbed/mbed-os,https://github.com/ARMmbed/mbed-os/issues/12773,ARMmbed_mbed-os_issues_12773,"call_every seems factor 10 too slow. 

<!--

   ************************************** WARNING **************************************

   The ciarcom bot parses this header automatically. Any deviation from the 
   template may cause the bot to automatically correct this header or may result in a 
   warning message, requesting updates.

   Please ensure all sections of the template below are filled in and no changes 
   are made to the template format. Only bugs should be raised here as issues. 
   Questions or enhancements should instead be raised on our forums:
   https://forums.mbed.com/ .

   *************************************************************************************

-->

### Description of defect

<!--
    Add detailed description of what you are reporting.
    Good example: https://os.mbed.com/docs/mbed-os/latest/contributing/workflow.html
-->

I use lpc1768 with newest firmware, os 5.15.1, GCC9, mbed-cli 1.10.2. 

Code: 
```
DigitalOut ledHeartBeat(LED4);

EventQueue evntQueue;

void toggleLedHeartBeat(void) {
  ledHeartBeat = !ledHeartBeat;
}

int main(void) {
  evntQueue.call_every(100, callback(toggleLedHeartBeat));
  evntQueue.dispatch();
}
```

but led inverts every second... i.e. 1000ms. 
According to documentation 100 is interpreted as ms. 
What is wrong here? 

#### Target(s) affected by this defect ?
LPC1768

#### Toolchain(s) (name and version) displaying this defect ?
GCC9

#### What version of Mbed-os are you using (tag or sha) ?
<!--
    For a released version please provide the release tag (this can be found as per the instructions below)

    mbed-os version can be found in /platform/mbed_version.h. The tag can be reconstructed as follows:
    mbed-os-MBED_MAJOR_VERSION.MBED_MINOR_VERSION.MBED_PATCH_VERSION
 
    Master branch is indicated by 'mbed-os-99.99.99
    
    For an issue found on Master please provide the sha being used.
-->
mbed-os-5.15.1

#### What version(s) of tools are you using. List all that apply (E.g. mbed-cli)
mbed cli 1.10.2

#### How is this defect reproduced ? 

occurs every time `mbed compile --flash` and reset.",Can you check via the link on that issue?,"<!--

   ************************************** WARNING **************************************

   The ciarcom bot parses this header automatically. Any deviation from the 
   template may cause the bot to automatically correct this header or may result in a 
   warning message, requesting updates.

   Please ensure all sections of the template below are filled in and no changes 
   are made to the template format. Only bugs should be raised here as issues. 
   Questions or enhancements should instead be raised on our forums:
   https://forums.mbed.com/ .

   *************************************************************************************

-->

### Description of defect

<!--
    Add detailed description of what you are reporting.
    Good example: https://os.mbed.com/docs/mbed-os/latest/contributing/workflow.html
-->"
sublimehq/sublime_text,https://github.com/sublimehq/sublime_text/issues/2471,sublimehq_sublime_text_issues_2471,"unexpected shortening

### Summary

As you can see from picture there is more longer sugesstions.
Why this is shortened? I can not see what it suggest me

### Expected behavior

there should not be shorttening

### Actual behavior

![__](https://user-images.githubusercontent.com/799021/47921596-a7312080-debd-11e8-8334-2e893c88e097.jpg)

this is `get_roles`

### Steps to reproduce

do not know

### Environment

* Operating system and version:
  * Linux Mint 18.3
* Sublime Text:
  * Build 3176
  * 64 bit


**UPD**  
shortening sometimes really useless:

![__](https://user-images.githubusercontent.com/799021/47983342-a970c600-e0db-11e8-9bfe-ca4ca28fdb03.jpg)","Can you paste a console log please?
Have you tried setting `""dpi_scale"": 1.0,` in your user preferences?","**UPD**  
shortening sometimes really useless:

![__](https://user-images.githubusercontent.com/799021/47983269-73334680-e0db-11e8-9302-02c3287e1f11.jpg)"
sublimehq/sublime_text,https://github.com/sublimehq/sublime_text/issues/1471,sublimehq_sublime_text_issues_1471,"Preserve extended attributes for files in the Windows Subsystem for Linux + within NTFS

**Update**: given that now native NTFS files can also have extended attributes, it would be great if Sublime could retain them everywhere, not just inside the **lxss** folder

### Summary

Files in the Windows Subsystem for Linux (WSL), located in **C:\Users\USERNAME\AppData\Local\lxss\** have extended attributes that make editing them directly from Windows very tricky - if I simply open and save such a file with the Windows version of Sublime Text, these attributes disappear and the file can't be edited in any new Bash in WSL session.

However, there seems to be a solution mentioned here https://github.com/Microsoft/BashOnWindows/issues/659#issuecomment-233333052

> One other workaround: I was able to get my Windows editor to stop making a backup of the file (probably moving the original to .bak, and creating a new one, haven't investigated), but rather to edit the file ""in place"".

Is there a way to enable/add such a mode to Sublime so that we could safely edit all those WSL files in our favourite editor?

More on file system handling in WSL is in this [blog post](https://blogs.msdn.microsoft.com/wsl/2016/06/15/wsl-file-system-support/)
### Expected behavior

Sublime retains extended attributes when editing WSL files, making them visible from within Bash on WSL
### Actual behavior

Sublime removes extended attributes on save of WSL fileswin
### Steps to reproduce
1. Open any file from **C:\Users\USERNAME\AppData\Local\lxss\** folder in the Windows version of Sublime, make any change and save
2. Try to open the same file from a new session of Bash on WSL in nano
### Environment
- Operating system and version:
  - Windows 10.0.14951
  - Ubuntu on Windows 16.04
- Sublime Text:
  - Build 3126","What's the value of your `atomic_save` preference?

```
// Save via writing to an alternate file, and then renaming it over the
// original file.
""atomic_save"": false,
```","**Update**: given that now native NTFS files can also have extended attributes, it would be great if Sublime could retain them everywhere, not just inside the **lxss** folder"
sublimehq/sublime_text,https://github.com/sublimehq/sublime_text/issues/2573,sublimehq_sublime_text_issues_2573,"Build 3186: Continuous 100% CPU and high RAM usage

### Description

Since the last update Sublime Text blocks 2 (edit: okay, it's 'only' one, my mistake) of my CPU cores with 100%. Also the memory consumptions takes between 10% and 15% of my 8 GB RAM (growing after opening, at some point dropping to 12% and starting to grow up to 15% again).
This starts as soon as a file/dir/project is opened. A single empty new ST Window takes 0,8% RAM and nearly no CPU.

I went back to 3184 for now (although I was really happy when I read the changelog).

### Steps to reproduce

Open something in ST (independent file is located in  a git repository or not).

### Environment

* Build: ST 3186, just upgraded via apt reposity from 3184
* git is used (2.20.1)
* SublimeMerge is installed at latest version (starting/stoping it does not change anything)
* Operating system and version: XUbuntu 18.04.1 LTS, 64bit, 4.15.0-43-generic
* [Linux] Desktop Environment and/or Window Manager: XFCE
* ST Theme seems not to be the culprit (switch to Default doesn't change anything)


![st_consumption](https://user-images.githubusercontent.com/1582492/51374850-8b283d00-1b04-11e9-9dcc-e9474584af32.jpg)","However, you said it happens when just loading a single file?

To see if it is related to git, you can try changing the `show_git_status` setting.","(edit: okay, it's 'only' one, my mistake)"
sublimehq/sublime_text,https://github.com/sublimehq/sublime_text/issues/2709,sublimehq_sublime_text_issues_2709,"Build 3200 using high CPU

### Description

Since installing the most recent update (3.2 build 3200) ST3 has been consistently taking up 40-90% of my CPU.  Even if I have no files/projects/folders open.

It is not currently indexing (Indexing status says ""Idle"").

I am editing this with new information.

### Steps to reproduce

1. Upgraded to 3.2 build 3200
1. Open Sublime Text with no folders/projects open.
1. CPU is very low (close to 1%).
1. Open any folder.  The one I was experimenting with had 9 text files in it (avg size of files around 1KB).
1. CPU jumps up to ~50%.

### Expected behavior

CPU goes back to reasonable levels.

### Actual behavior

CPU stays this way even if I close the project window.  And does not drop back down until I restart ST.

### Environment

* Build: 3200
* Operating system and version: macOS 10.13.6

I have uninstalled all my Packages (including Package Control).

Activity Monitor:
![Screen Shot 2019-03-14 at 11 13 57 AM](https://user-images.githubusercontent.com/10041/54352760-4b845a00-464a-11e9-98fb-6128ff77a43a.png)

No projects open:
![Screen Shot 2019-03-14 at 11 12 31 AM](https://user-images.githubusercontent.com/10041/54352690-2263c980-464a-11e9-972a-70d3b684007e.png)

Indexing status:
![Screen Shot 2019-03-14 at 11 13 13 AM](https://user-images.githubusercontent.com/10041/54352723-34456c80-464a-11e9-9d4d-756ae6dc4095.png)",Maybe some kind of initialization bug in one or the other of those features?,"teps to reproduce

1. Upgraded to 3.2 build 3200
1. Open Sublime  jumps up to ~50%.

### Expected behavior

CPU goes back to reasonable levels.

### Actual behavior

CPU stays this way even if I close the project window.  And does not drop back down until I restart ST.

I have uninstalled all my Packages (including Package Control)."
PowerDNS/pdns,https://github.com/PowerDNS/pdns/issues/7008,PowerDNS_pdns_issues_7008,"Lua2 backend unable to parse boolean value from 0/1 integer

  - Program: Authoritative
  - Issue type: Bug report

### Short description

Lua2 backend unable to parse boolean value from bit

### Environment

 - Operating system: Ubuntu 14.04 LTS x64
 - Software version: PowerDNS Authoritative Server 0.0.2463gc40b447
 - Software source: official repo

### Expected behaviour

Lua2 backend should be able to parse boolean from bit value

### Actual behaviour

Lua2 backend expects array of tables as result of certain methods such as 'dns_lookup' or 'dns_get_domain_keys'.
When returning the result and using bit (0/1) values for 'auth' ('dns_lookup') or 'active' ('dns_get_domain_keys') the backend fails with '(boost::bad_get: failed value get using boost::get)'

### Steps to reproduce

Using example from https://github.com/PowerDNS/pdns/blob/master/modules/lua2backend/regression-tests/lua2-dnssec.lua line 78 `table.insert(ret, { name = qname, type = newQType(k), content = row, ttl = 60, domain_id = d_id, auth = true })` will work but `table.insert(ret, { name = qname, type = newQType(k), content = row, ttl = 60, domain_id = d_id, auth = 1 })` will fail",Can you show some code so we understand what 'bit values' are?,"### Steps to reproduce

Using example from https://github.com/PowerDNS/pdns/blob/master/modules/lua2backend/regression-tests/lua2-dnssec.lua line 78 `table.insert(ret, { name = qname, type = newQType(k), content = row, ttl = 60, domain_id = d_id, auth = true })` will work but `table.insert(ret, { name = qname, type = newQType(k), content = row, ttl = 60, domain_id = d_id, auth = 1 })` will fail"
PowerDNS/pdns,https://github.com/PowerDNS/pdns/issues/6832,PowerDNS_pdns_issues_6832,"dnsdist: listen on specific prefix rather than single address

 - Program: dnsdist
 - Issue type: Feature request

### Short description
This is a feature request that I would intend to implement myself, but want to get a general idea of whether this functionality would be accepted in a pull request before I go forward, so I can weigh other implementation paths I could take before starting.

### Usecase
The ability to listen on a range of addresses easily rather than listening on `0.0.0.0`, to not interfere with other daemons on the same machine that need to listen for traffic on the same port, but on other addresses.

### Description
I would like to add the following functionality:

- The ability to listen on a specific prefix or address range rather than just individual addresses",Do you have a specific use case that would require that?,specific or address range
PowerDNS/pdns,https://github.com/PowerDNS/pdns/issues/6799,PowerDNS_pdns_issues_6799,"bogus dnssec validation for unsigned domains

 - Program: Recursor
 - Issue type: Bug report

### Short description
many bogus dnssec entries in log for domains that are not dnssec signed. problem is not reliably reproduceable for a given hostname. 

### Environment
 - Operating system: CentOS release 6.10 (Final)
 - Software version: pdns-recursor-4.1.3-1pdns.el6
 - Software source: repo.powerdns.com

### Steps to reproduce
- recursor.conf
```
setuid=pdns-recursor
setgid=pdns-recursor
root-nx-trust=yes
allow-from=127.0.0.0/8, <redacted>
disable-packetcache=yes
dnssec=log-fail
dnssec-log-bogus=yes
forward-zones-file=/etc/pdns-recursor/forward.conf
local-address=127.0.0.1, <redacted>
lua-config-file=/etc/pdns-recursor/recursor.lua
max-negative-ttl=10
packetcache-servfail-ttl=30
packetcache-ttl=30
threads=4
```
- recursor.lua sets NTA for a local domain:
`addNTA(""<redacted>"", ""do not validate local zone"");`

- forward.conf redirects some local domains to internal authoritative servers and some blacklists to a local rbldnsd:
```
redacted.dom=red.act.ed.ip, red.act.ed.ip
redacted.in-addr.arpa=red.act.ed.ip, red.act.ed.ip
redacted.in-addr.arpa=red.act.ed.ip, red.act.ed.ip

zen.spamhaus.org=127.0.0.1:530
dbl.spamhaus.org=127.0.0.1:530
sbl-xbl.spamhaus.org=127.0.0.1:530
pbl.spamhaus.org=127.0.0.1:530
sbl.spamhaus.org=127.0.0.1:530
```

### Expected behaviour
domain googlemail.com is unsigned, therefore it should not validate as bogus.

### Actual behaviour
log shows entries such as:
 - Answer to aspmx5.googlemail.com|A for redacted:45913 validates as Bogus
 - Answer to pdns12.domaincontrol.com|A for redacted:53415 validates as Bogus

however, this does not happen every time the recursor needs to resolve one of these host names!

### Other information
n/a",Can you please include the content of the /etc/pdns-recursor/forward.conf file ?,"- forward.conf redirects some local domains to internal authoritative servers and some blacklists to a local rbldnsd:
```
redacted.dom=red.act.ed.ip, red.act.ed.ip
redacted.in-addr.arpa=red.act.ed.ip, red.act.ed.ip
redacted.in-addr.arpa=red.act.ed.ip, red.act.ed.ip

zen.spamhaus.org=127.0.0.1:530
dbl.spamhaus.org=127.0.0.1:530
sbl-xbl.spamhaus.org=127.0.0.1:530
pbl.spamhaus.org=127.0.0.1:530
sbl.spamhaus.org=127.0.0.1:530
```"
PowerDNS/pdns,https://github.com/PowerDNS/pdns/issues/8931,PowerDNS_pdns_issues_8931,"getDomainInfo method of of remote-backend not working

<!-- Hi! Thanks for filing an issue. It will be read with care by human beings. Can we ask you to please fill out this template and not simply demand new features or send in complaints? Thanks! -->
<!-- Also please search the existing issues (both open and closed) to see if your report might be duplicate -->
<!-- Please don't file an issue when you have a support question, send support questions to the mailinglist or ask them on IRC (https://www.powerdns.com/opensource.html) -->

<!-- Tell us what is issue is about -->
 - Program: Authoritative (with pdns-backend enabled)
 - Issue type: Bug report

### Short description
Upon a HTTP `POST` to `api/v1/servers/localhost/zones`, pdns-backend issues a `getDomainInfo` method call, with the domain name _(e.g. 'foo.com')_ from the `POST` call.
No matter what JSON is returned to pdns-backend by my unix socket, it closes the unix socket and indicates a failure to the HTTP API, at which point a HTTP 422 error is returned to the client.

### Environment
<!-- Tell us about the environment -->
 - Operating system: Docker Container (Debian 10)
 - Software version: PDNS Authoritive and remote-backend 4.1.6 
 - Software source: Debian Package Repo

### Steps to reproduce
<!-- Tell us step-by-step how the issue can be triggered. Please include your configuration files and any (Lua) scripts that are loaded. -->
1. make a `POST` request to the web API to `api/v1/servers/localhost/zones` (domain passed in `POST` body JSON is assumed not to be in the backend)
2. remote-backend sends `Initialise` method (JSON formatted) to the underlying implementation (unix connector in my case)
3. return JSON response `{""result"":true}`
4. remote-backend sends `getDomanInfo` method (again JSON formatted)
5. [Docs](https://doc.powerdns.com/authoritative/backends/remote.html#getdomaininfo) are not clear as to what to return in this situation, but no matter what JSON response is returned to pdns-backend, the HTTP response to the `POST` call is a HTTP 422 error. (with varying body JSON as discussed below)

### Expected behaviour
Option 1:
If the domain is not present in the backend, then a JSON response to the `getDomainInfo` method of `{ ""result"": {}}` should be the most logical response. i.e. indicating that the domain as specified in `getDomainInfo` is not present in the underlying persistent storage.
After such response, a further method call by pdns-backend should then be received indicating that the domain needs to be created in the underlying persistent storage. 

Option 2:
The backend implementation discovers that such a domain does not exist, creates the record and returns a response such as `{ ""result"": { ""zone"": ""foo.com"" }}`

### Actual behaviour
upon sending the domain ""foo.com"" in the HTTP `POST` the following JSON were attempted in response to the ""getDomainInfo"" method.
```
{""result"":{}}
{""result"":""""}
{""result"":null}
{""result"":false}
{""result"":true}
{""result"": {""zone"":{}}}
{""result"":{""zone"":""""}}
{""result"":{""zone"":null}}
{""result"":{""zone"":""foo.com""}}
```
All of which ultimately return the HTTP 422, and all result in pdns-backend closing the unix socket.
If the `zone` attribute is not present in the backend response, the HTTP response body is `{""error"": ""Key 'zone' not present or not a String""}`
If the `zone` attribute is included in the backend response, the HTTP response body is `{""error"": ""Domain 'foo.com.' already exists""}`
If the backend response is `{""result"":false}` the HTTP response body is `{""error"": ""Creating domain 'foo.com.' failed""}`

### Other information
Despite setting loglevel=9 in the pdns config, nothing special is emitted. Here are the logs
```
Jan 25 00:38:34 Listening on controlsocket in '/var/run/pdns.controlsocket'
Jan 25 00:38:34 Guardian is launching an instance
Jan 25 00:38:34 Reading random entropy from '/dev/urandom'
Jan 25 00:38:34 Loading '/usr/lib/x86_64-linux-gnu/pdns/libremotebackend.so'
Jan 25 00:38:34 [RemoteBackend] This is the remote backend version 4.1.6
reporting
Jan 25 00:38:34 This is a guarded instance of pdns
Jan 25 00:38:34 UDP server bound to 0.0.0.0:53
Jan 25 00:38:34 UDPv6 server bound to [::]:53
Jan 25 00:38:34 TCP server bound to 0.0.0.0:53
Jan 25 00:38:34 TCPv6 server bound to [::]:53
Jan 25 00:38:34 PowerDNS Authoritative Server 4.1.6 (C) 2001-2018
PowerDNS.COM BV
Jan 25 00:38:34 Using 64-bits mode. Built using gcc 8.3.0.
Jan 25 00:38:34 PowerDNS comes with ABSOLUTELY NO WARRANTY. This is free
software, and you are welcome to redistribute it according to the terms of
the GPL version 2.
Jan 25 00:38:34 Listening for HTTP requests on 0.0.0.0:8081
Jan 25 00:38:34 Doing stub resolving, using resolvers: 172.18.112.1,
192.168.1.1
Jan 25 00:38:34 Question got answered by 192.168.1.1
Jan 25 00:38:34 Could not retrieve security status update for
'4.1.6-3.Debian' on
'auth-4.1.6-3.Debian.security-status.secpoll.powerdns.com.', RCODE =
Non-Existent domain
Jan 25 00:38:34 Creating backend connection for TCP
Jan 25 00:38:34 About to create 3 backend threads for UDP
Jan 25 00:38:35 Done launching threads, ready to distribute questions
Jan 25 00:38:56 HTTP: Handling request ""/api/v1/servers/localhost/zones""
Jan 25 00:38:56 Reconnecting to backend
Jan 25 00:38:57 closing socket connection
Jan 25 00:38:57 HTTP: Result for ""/api/v1/servers/localhost/zones"": 200,
body length: 2
Jan 25 00:38:57 HTTP: Handling request
""/api/v1/servers/localhost/statistics""
Jan 25 00:38:57 HTTP: Result for ""/api/v1/servers/localhost/statistics"":
200, body length: 3954
Jan 25 00:39:50 HTTP: Handling request ""/api/v1/servers/localhost/zones""
Jan 25 00:39:50 Reconnecting to backend
Jan 25 00:39:50 closing socket connection
Jan 25 00:39:50 HTTP: Result for ""/api/v1/servers/localhost/zones"": 422,
body length: 46
```

There are a few issues here - 
1. `getDomainInfo` appears to be faulty
2. [Docs](https://doc.powerdns.com/authoritative/backends/remote.html#getdomaininfo) on `getDomainInfo` is unclear on what to return when the domain cannot be found
3. A `setDomainInfo` method is not present in the [docs](https://doc.powerdns.com/authoritative/backends/remote.html#getdomaininfo), suggesting that the pdns-backend implementation is incomplete

If you need me to test anything to help with this issue, just ask.
I'm somewhat roadblocked without some help on this .",Does this code from the unittest help? https://github.com/PowerDNS/pdns/blob/master/modules/remotebackend/unittest.rb#L184,"body JSON d to pdns-backentrue}
{""result"":"
publiclab/plots2,https://github.com/publiclab/plots2/issues/5695,publiclab_plots2_issues_5695,"[inline maps only now] current Max Zoom Level not enough to show entire country

_NOTE: original issue solved, now considering extending this to inline maps._ 

Hello!!!!!
@sagarpreet-chadha i was hoping to connect on this idea :)

In our inline maps, precision (number of digits after the decimal) determines the zoom level that the map loads on, but India (and other countries) are so big, you can't chop off any more digits. So here's what publiclab.org/india looks like: 
![image-2](https://user-images.githubusercontent.com/161439/57476226-12d8b980-7264-11e9-89c4-ab9632a83cd4.png)

This screenshot shows the zoom level that corresponds to `00.` precision. So we need to think of an edge case for how to over-ride the zoom. Maybe `zoom:____` could be an override powertag

![screen_shot_2019-05-09_at_2 04 22_pm](https://user-images.githubusercontent.com/161439/57476302-43205800-7264-11e9-8d9a-d1289f25ea76.png)

How awesome will it be to figure this out and have the map of india load awesomely at this zoom that shows the entire country and right away shows all these people!!!
<img width=""1218"" alt=""Screen Shot 2019-05-09 at 2 06 47 PM"" src=""https://user-images.githubusercontent.com/161439/57476330-516e7400-7264-11e9-98fc-780c509fbb49.png"">

Thanks! 
What do you think?",What do you think ?,"_NOTE: original issue solved, now considering extending this to inline maps._"
publiclab/plots2,https://github.com/publiclab/plots2/issues/3359,publiclab_plots2_issues_3359,"Display message in collections in Public Lab Store

**We are preparing to participate in Google Code-in, and have reserved this issue for participants in GCI - but we'd love to have your help with another one! Please check out https://code.publiclab.org to see more.**
### Please describe the problem (or idea)

In the collections, collections that do not have any product (eg. photography) should have a message displayed below the heading _""Sorry, there are no products in this collection""_

Currently, it displays _""See more Photography ""_

### Please show us where to look

https://store.publiclab.org/collections
Photography section


### What's your PublicLab.org username?
asquare14
> This can help us diagnose the issue: 

> Many bugs are related to these -- please help us track it down and reproduce what you're seeing!


****

We are preparing to participate in Google Code-in, and have reserved this issue for participants in GCI - but we'd love to have your help with another one! Please check out https://code.publiclab.org to see more.","Can you please send patch to this bug?
Thanks","We are preparing to participate in Google Code-in, and have reserved this issue for participants in"
publiclab/plots2,https://github.com/publiclab/plots2/issues/3408,publiclab_plots2_issues_3408,"CERN Open Hardware License 1.1.  page not found

**We are preparing to participate in Google Code-in, and have reserved this issue for participants in GCI - but we'd love to have your help with another one! Please check out https://code.publiclab.org to see more.**

### Please describe the problem (or idea)
when click on this CERN Open Hardware License 1.1 then It's goes to no page found  and there is back button not work
![licence](https://user-images.githubusercontent.com/25536022/45932112-5b718a00-bf95-11e8-9d97-6298a03d8c8b.png)

> What happened just before the problem occurred? Or what problem could this idea solve?



> What did you expect to see that you didn't?



### Please show us where to look
this link is in footer but u can go by also this llink
https://www.ohwr.org/cernohl
https://publiclab.org/ ...


### What's your PublicLab.org username?

> This can help us diagnose the issue: 



### Browser, version, and operating system

> Many bugs are related to these -- please help us track it down and reproduce what you're seeing!


****

## Thank you!

Your help makes Public Lab better! We *deeply* appreciate your helping refine and improve this site. 

To learn how to write really great issues, which increases the chances they'll be resolved, see:

https://publiclab.org/wiki/developers#Contributing+for+non-coders",Can you find an up to date link to the OHL 1.1 ? We can make a first-timers-only issue for this!,"**We are preparing to participate in Google Code-in, and have reserved this issue for participants in GCI - but we'd love to have your help with another one! Please check out https://code.publiclab.org to see more.**"
publiclab/plots2,https://github.com/publiclab/plots2/issues/3617,publiclab_plots2_issues_3617,"Improve wiki page for mobile view / short width screen

**We are preparing to participate in Google Code-in, and have reserved this issue for participants in GCI - but we'd love to have your help with another one! Please check out https://code.publiclab.org to see more.**

Hi, this is a [first-timers-only issue](https://publiclab.github.io/community-toolbox/#r=all). This means we've worked to make it more legible to folks who either **haven't contributed to our codebase before, or even folks who haven't contributed to open source before**. 

If that's you, we're interested in helping you take the first step and can answer questions and help you out as you do. Note that we're especially interested in contributions from people from groups underrepresented in free and open source software!

We know that the process of creating a pull request is the biggest barrier for new contributors. This issue is for you 💝

If you have contributed before, **consider leaving this one for someone new**, and looking through our general [help wanted](https://github.com/publiclab/plots2/labels/help-wanted) issues. Thanks!

### 🤔 What you will need to know.

Nothing. This issue is meant to welcome you to Open Source :) We are happy to walk you through the process.

### Problem
https://publiclab.org/wiki in this page here is wiki's pages link where we click and render that particular page, this data are shown in html table but if we decrease the screen size or view this page in mobile 

 then like column in this table  will disappear.
- full screen size
![wiki2](https://user-images.githubusercontent.com/25536022/46533938-0e11e880-c8c4-11e8-99dc-4813d830b59f.png)

- short screen size / mobile view

![wiki3](https://user-images.githubusercontent.com/25536022/46534441-b8d6d680-c8c5-11e8-91b9-fcacc0c71c20.png)



### 📋Solution

- [ ] 🙋 **Claim this issue**: Comment below. If someone else has claimed it, ask if they've opened a pull request already and if they're stuck -- maybe you can help them solve a problem or move it along!

- [ ] 📝 **Update**  remove class=""hidden-xs""


Code links….
https://github.com/publiclab/plots2/blob/738d54d13c805a59c4d05c9717f81af24d830dc2/app/views/wiki/_wikis.html.erb#L15

- [ ] 💾 **Commit** your changes

- [ ] 🔀 **Start a Pull Request**. There are two ways how you can start a pull request:

1. If you are familiar with the terminal or would like to learn it, [here is a great tutorial](https://egghead.io/series/how-to-contribute-to-an-open-source-project-on-github) on how to send a pull request using the terminal.

2. You can also [edit files directly in your browser](https://help.github.com/articles/editing-files-in-your-repository/) and open a pull request from there. 

- [ ] 🏁 **Done** Ask in comments for a review :)


### 🤔❓ Questions?

Leave a comment below!

### Is someone else already working on this?

We encourage you to link to this issue by mentioning the issue # in your pull request, so we can see if someone's already started on it. **If someone seem stuck, offer them some help!** Otherwise, [take a look at some other issues you can help with](https://publiclab.github.io/community-toolbox/#r=all). Thanks!

(This issue was created by [First-Timers-Bot](https://github.com/hoodiehq/first-timers-bot).)",Can you please add the message and add labels?,"**We are preparing to participate in Google Code-in, and have reserved this issue for participants in GCI - but we'd love to have your help with another one! Please check out https://code.publiclab.org to see more.**"
publiclab/plots2,https://github.com/publiclab/plots2/issues/3561,publiclab_plots2_issues_3561,"Display top button in the bottom right corner of the screen.

The top button should always be displayed on the bottom right corner of the screen once the user scrolls down. The top button is placed in the footer.

Hi, this is a [first-timers-only issue](https://publiclab.github.io/community-toolbox/#r=all). This means we've worked to make it more legible to folks who either **haven't contributed to our codebase before, or even folks who haven't contributed to open source before**. 

If that's you, we're interested in helping you take the first step and can answer questions and help you out as you do. Note that we're especially interested in contributions from people from groups underrepresented in free and open source software!

We know that the process of creating a pull request is the biggest barrier for new contributors. This issue is for you 💝

If you have contributed before, **consider leaving this one for someone new**, and looking through our general [help wanted](https://github.com/publiclab/plots2/labels/help-wanted) issues. Thanks!

### 🤔 What you will need to know.

Nothing. This issue is meant to welcome you to Open Source :) We are happy to walk you through the process.

### 📋 Step by Step

- [ ] 🙋 **Claim this issue**: Comment below. If someone else has claimed it, ask if they've opened a pull request already and if they're stuck -- maybe you can help them solve a problem or move it along!

- [ ] 📝 **Update** the file [$FILENAME]($BRANCH_URL) in the `$REPO` repository (press the little pen Icon) and edit the line as shown below. 

[See this page](https://publiclab.github.io/community-toolbox/#r=all) for some help in taking your first steps!

Below is a ""diff"" showing in red (and a `-`) which lines to remove, and in green (and a `+`) which lines to add:

```diff
$DIFF
```


- [ ] 💾 **Commit** your changes

- [ ] 🔀 **Start a Pull Request**. There are two ways how you can start a pull request:

1. If you are familiar with the terminal or would like to learn it, [here is a great tutorial](https://egghead.io/series/how-to-contribute-to-an-open-source-project-on-github) on how to send a pull request using the terminal.


- [ ] 🏁 **Done** Ask in comments for a review :)


### 🤔❓ Questions?

Leave a comment below!

### Is someone else already working on this?


### Please show us where to look

https://publiclab.org/wiki/stories


### What's your PublicLab.org username?
roshni_ram001",Can I work on this issue?,"Hi, this is a [first-timers-only issue](https://publiclab.github.io/community-toolbox/#r=all). This means we've worked to make it more legible to folks who either **haven't contributed to our codebase before, or even folks who haven't contributed to open source before**. 

If that's you, we're interested in helping you take the first step and can answer questions and help you out as you do. Note that we're especially interested in contributions from people from groups underrepresented in free and open source software!

We know that the process of creating a pull request is the biggest barrier for new contributors. This issue is for you 💝

If you have contributed before, **consider leaving this one for someone new**, and looking through our general [help wanted](https://github.com/publiclab/plots2/labels/help-wanted) issues. Thanks!🤔 What you will need to know.

Nothing. This issue is meant to welcome you to Open Source :) We are happy to walk you through the process.

### 📋 Step by Step

- [ ] 🙋 **Claim this issue**: Comment below. If someone else has claimed it, ask if they've opened a pull request already and if they're stuck -- maybe you can help them solve a problem or move it along!

- [ ] 📝 **Update** the file [$FILENAME]($BRANCH_URL) in the `$REng your first steps!

Below is a ""diff"" showing in red (and a `-`) which lines to remove, and in green (and a `+`) which lines to add:

```diff
$DIFF
```


- [ ] 💾 **Commit** your changes

- [ ] 🔀 **Start a Pull Request**. There are two ways how you can start a pull request:

1. If you are familiar with the terminal or would like to learn it, [here is a great tutorial](https:🤔❓ Questions?

Leave a comment below!

### Is someone else already working on this?


### Please show us where to look

https://publiclab.org/wiki/stories


###"
publiclab/plots2,https://github.com/publiclab/plots2/issues/4607,publiclab_plots2_issues_4607,"Weekly Community Check-In #5 - ""Welcoming Newcomers Efficiently""

Hi everyone :wave: !

We all at Public Lab :balloon: - learn, grow, work, brainstorm ideas, contribute together so why not share about our weekly goals and the awesome work we have done at Public Lab with each other, so we can support and collaborate with each other better. Let's start a Community Check-In from this week onwards, where every community member would share something about their work from the past week and about their current week's goal :dart:. You are also welcome to share fun-fact :smile: , new ideas :bulb: , your learning goals :ballot_box_with_check: .

If you're new here, welcome :balloon:, and please comment a Hello message below, we love to work with you. If you're looking for new issues, please try some of our first-timers-only issues.

We're SO EXCITED to have your help!

Is there anything, you would like to share with us from past week's work? What is your plan for this week?

If you have not planned yet, just leave a Hello! so that we know that you are in sync with us :arrows_clockwise: and doing well!

As always, if you're waiting for a review, or if you're stuck, please request help here OR leave a comment with @publiclab/mentors @publiclab/reviewers for some input. :raised_hands:

### This Week's Theme

I thought of making this week's theme around the idea of `Welcoming Newcomers Efficiently`.
As we have [code.publiclab.org](https://code.publiclab.org) which provides a nice list of issues which can be solved by the newcomers to get up and running with the project, merging those PRs takes time sometimes...I think discussing the various ways which can improve and speed-up this process would enhance newcomer's experience to much greater extent.

If you have any suggestion or query, feel free to comment down below. 

Have a great week everyone :tada: :fireworks: :balloon: 

cc
@thesparks @faithngetich @DakshGondaliya @mohitRJranjan @milaaraujo @kevinzluo
@stefannibrasil @gauravano @ViditChitkara @tech4GT @mridulnagpal @namangupta01 @sagarpreet-chadha @Souravirus @jywarren @MayankKashyap @siaw23 @ryzokuken @ccpandhare @icarito @steviepubliclab @ebarry @jywarren, @sagarpreet-chadha, @icarito, @JonathanXu1, @uzorjchibuzor, @eli6, @kevinzluo, @ValentinaTironi, @rexagod, @sashadev-sky, @IshaGupta18, @milaaraujo, @dinaelhanan, @cesswairimu, @dependabot[bot], @oorjitchowdhary, @okonek, @wanzulfikri, @mohitRJranjan @publiclab/mentors @publiclab/image-sequencer-guides @publiclab/leaflet-environmental-layers-guides @Paarmita @vishalka98 @publiclab/reviewers @Divy123 @pomyo @bhavayAnand9 @ovipa017-xamk @Mridul97 @avsingh999 @Rishabh570 @subhahu123 @aSquare14 @Radhikadua123 @quinn-codes-synthesis @amychan331 @mardelvalle @narnt @hydro-m @love-opensource @romanrodriguez @shubhangi-chauhan @Dhiraj240 @geekychaser @codeIriss @CoderJolly 

### Summer of Code
@jywarren has started a brainstorming post for the ideas page for Summer of Code 2019 -It would be best get some ideas into discussion from the fellow community member before time. People have been brainstorming already - let's do it together!
https://publiclab.org/notes/warren/01-02-2019/brainstorming-for-summer-of-code-2019

### Software Contributors Survey
@ebarry reminded us about a survey that was conducted the year before and we are willing to hear it from you again. The idea discussed in 2017 is here: https://publiclab.org/questions/warren/10-25-2017/help-with-a-standard-mini-evaluation-for-assessing-software-outreach-efforts

Here's the survey as sent out on December 14, 2017: #1890 so, it would great to run the survey this time too.

### People who did the check-ins

- [x] Gaurav Sachdeva (@gauravano )
- [x] Sidharth Bansal (@SidharthBansal  )
- [x] Cess (@cesswairimu )
- [x] Harman Jolly (@CoderJolly )
- [x] Rishabh Rawat (@Rishabh570 )",Who will be willing to do the next weekly checkin? Please tell your name asap.,"### People who did the check-ins

- [x] Gaurav Sachdeva (@gauravano )
- [x] Sidharth Bansal (@SidharthBansal  )
- [x] Cess (@cesswairimu )
- [x] Harman Jolly (@CoderJolly )
- [x] Rishabh Rawat (@Rishabh570 )"
publiclab/plots2,https://github.com/publiclab/plots2/issues/4113,publiclab_plots2_issues_4113,"Recenter 'Read more' button for note previews

Hi, this is a [first-timers-only issue](https://code.publiclab.org/#r=all). This means we've worked to make it more legible to folks who either **haven't contributed to our codebase before, or even folks who haven't contributed to open source before**.

If that's you, we're interested in helping you take the first step and can answer questions and help you out as you do. Note that we're especially interested in contributions from people from groups underrepresented in free and open source software!

We know that the process of creating a pull request is the biggest barrier for new contributors. This issue is for you 💝

If you have contributed before, consider leaving this one for someone new, and looking through our general [help wanted](https://github.com/publiclab/plots2/labels/help-wanted) issues. Thanks!

### 🤔 What you will need to know.

Nothing. This issue is meant to welcome you to Open Source :) We are happy to walk you through the process.

## The problem
The 'notes' previews across the site are aligned right instead of centered! 
[https://publiclab.org/search/notes/balloon](https://publiclab.org/search/notes/balloon)

<img width=""573"" alt=""screen shot 2018-12-03 at 10 47 06 pm"" src=""https://user-images.githubusercontent.com/41092741/49417835-6ee76100-f74d-11e8-9e9d-640249fed7e8.png"">



## Solution
This is a pretty easy one -- let's remove the CSS declarations from the notes HTML file that are overwriting the button's previously centered alignment:

1) 
Delete line 69 (and line 70, which is overwritten by the declaration directly under it anyway):
https://github.com/publiclab/plots2/blob/c204b268cd8dc1a713aeae15cc4222f0099d4d73/app/views/notes/_notes.html.erb#L66-L72

2) 
Delete the entire inline `style` attribute.
https://github.com/publiclab/plots2/blob/c204b268cd8dc1a713aeae15cc4222f0099d4d73/app/views/notes/_notes.html.erb#L51

Thanks!!

## Steps to Fix
 
- [x] Claim this issue with a comment here, below, and ask any clarifying questions you need
- [x] Fork the repository and set it up locally following the main repo README instructions [https://github.com/publiclab/plots2](https://github.com/publiclab/plots2)
 - [x] Create a new feature branch with a unique name descriptive to the issue
- [x] Try to fix the issue following the steps above, but even before you're done, you can:
  commit your changes to your branch and start a pull request (see [contributing to Public Lab software](https://publiclab.org/wiki/contributing-to-public-lab-software)) but mark it as ""in progress"" if you have questions or if you haven't finished
- [x] Reference this issue in the pull request body
- [x] Once you submit your pull request, an additional checklist will be provided for getting it merged

##  💬  Get help
If you need any help - here are some options: 

- Comment below
- Join our gitter chat at https://gitter.im/publiclab/publiclab",Do I need to install Rails or something else before setting up the fork locally?  Thank you!,"##  💬  Get help
If you need any help"
publiclab/plots2,https://github.com/publiclab/plots2/issues/4595,publiclab_plots2_issues_4595,"Refactor _answer.html.erb

Hi, this is a [first-timers-only issue](https://publiclab.github.io/community-toolbox/#r=all). This means we've worked to make it more legible to folks who either **haven't contributed to our codebase before, or even folks who haven't contributed to open source before**. 

If that's you, we're interested in helping you take the first step and can answer questions and help you out as you do. Note that we're especially interested in contributions from people from groups underrepresented in free and open source software!

We know that the process of creating a pull request is the biggest barrier for new contributors. This issue is for you 💝

If you have contributed before, **consider leaving this one for someone new**, and looking through our general [help wanted](https://github.com/publiclab/plots2/labels/help-wanted) issues. Thanks!

### The problem

Line 62 in _answer.html.erb is considerably long. We need to break it into shorter lines for readability.
```
<a href=""<% if current_user %>'/answer_like/likes/<%= answer.id %>'<% else %>'#'<% end %>"" data-remote =""true"" tooltip-title=""Helpful? Like it"" class=""btn btn-default btn-sm btn-like"" id=""answer-like-button-<%= answer.id %>"" <% unless current_user %> popover-content=""You must be logged in to Like the answer"" <% end %> ><span id=""answer-like-star-<%= answer.id %>"" class=""fa fa-star<% if current_user && !answer.liked_by(current_user.uid) %>-o<% end %>""></span><span id=""answer-like-count-<%= answer.id %>""><%= answer.likers.length %></span> Likes</a>
```

### 🤔 What you will need to know.

Nothing. This issue is meant to welcome you to Open Source :) We are happy to walk you through the process.

### 📋 Step by Step solution

- [ ] 🙋 **Claim this issue**: Comment below. If someone else has claimed it, ask if they've opened a pull request already and if they're stuck -- maybe you can help them solve a problem or move it along!

- [ ] 📝 **Refactor** line 62, instead of one long line break it into smaller lines instead. 

**code link** - https://github.com/publiclab/plots2/blob/master/app/views/questions/_answer.html.erb




- [ ] 💾 **Commit** your changes

- [ ] 🔀 **Start a Pull Request**. There are two ways how you can start a pull request:

1. If you are familiar with the terminal or would like to learn it, [here is a great tutorial](https://egghead.io/series/how-to-contribute-to-an-open-source-project-on-github) on how to send a pull request using the terminal.

2. You can also [edit files directly in your browser](https://help.github.com/articles/editing-files-in-your-repository/) and open a pull request from there. 

- [ ] 🏁 **Done** Ask in comments for a review :)


### 🤔❓ Questions?

Leave a comment below!

### Is someone else already working on this?

We encourage you to link to this issue by mentioning the issue # in your pull request, so we can see if someone's already started on it. **If someone seem stuck, offer them some help!** Otherwise, [take a look at some other issues you can help with](https://publiclab.github.io/community-toolbox/#r=all). Thanks!","Would you like to recommend the optimal length?

Thanks!","Hi, this is a [first-timers-only issue](https://publiclab.github.io/community-toolbox/#r=all). This means we've worked to make it more legible to folks who either **haven't contributed to our codebase before, or even folks who haven't contributed to open source before**. 

If that's you, we're interested in helping you take the first step and can answer questions and help you out as you do. Note that we're especially interested in contributions from people from groups underrepresented in free and open source software!

We know that the process of creating a pull request is the biggest barrier for new contributors. This issue is for you 💝

If you have contributed before, **consider leaving this one for someone new**, and looking through our general [help wanted](https://github.com/publiclab/plots2/labels/help-wanted) issues. Thanks!

### The problem

, instead of one long line break it into smaller lines instead. 

**code link** - https://github.com/publiclab/plots2/blob/master"
SlimeKnights/TinkersConstruct,https://github.com/SlimeKnights/TinkersConstruct/issues/3783,SlimeKnights_TinkersConstruct_issues_3783,"Crash when using tinkers weapons in mob farm.

incredibly annoying crash. only happens when im using my ender io powered spawner mob farm for tool leveling.
https://pastebin.com/aBw4yZW2

**Versions:**
* Minecraft: 1.12.2
* Forge: 2768
* Mantle: 
Mantle-1.12-1.3.3.39
* Tinkers Construct: 
TConstruct-1.12.2-2.12.0.115

other mods required to my knowledge, havent tested with vanilla mod farms.
EDIT:
cuplrit has been discovered. crash is a particle effect conflict with the mod DynamicSurroundings, specific to the nether. simply use tinkers tools in the nether to attack mobs. eventually the game will randomly crash. 

SPECIAL THANKS TO Z-TUNIC FOR PUTTING IN THE TIME TO PINPOINT THE ISSUE","What is holding the sword in your mob farm? If the crash is only happening there, its possible some way they are calling the sword methods is the cause","EDIT:
cuplrit has been discovered. crash is a particle effect conflict with the mod DynamicSurroundings, specific to the nether. simply use tinkers tools in the nether to attack mobs. eventually the game will randomly crash. 

SPECIAL THANKS TO Z-TUNIC FOR PUTTING IN THE TIME TO PINPOINT THE ISSUE"
koreader/koreader,https://github.com/koreader/koreader/issues/4431,koreader_koreader_issues_4431,"Short taps on wakeup are interpreted as long taps (kobo glo hd N437)

* KOReader version: v2018.12-31-gf6743a4_2018_12_28
* Device: Kobo Glo HD, model N437

#### Issue
after I wake up my kobo (that has been put to sleep with short press on physical button on top), any tap on the screen is considered as a long tap. I tap to turn the page and a dictionary window pops up with highlighted word where I tapped; closing this popup window sometimes succeeds, sometimes it doesn't; I can sometimes move this popup window with the dictionary, but how koreader interprets my taps (single / double / swipe / drag and drop) is completely messed; the real long tap is also considered as a long tap, and doing long tap to kobo doesn't make short taps work;

what doesn't help:
1) having a screen cleaned up via Screensaver > Use Message as screensaver; I was hoping that re-drawing the page on wake up will unfreeze the tap sensor;
2) I'm not sure about the book format displayed; I think PDFs are not suffering from this issue;
3) putting kobo to sleep, and waking it up while holding finger on the screen without motion; having two fingers tap without motion while kobo wakes up and cleans the screen by redrawing white to black and back;
4) upgrading KSM (I used kobo start menu 08 for 1.5 years, and 2 weeks ago I upgraded to kobo start menu 09);
5) none of the koreader updates during 2018 addressed this issue - I didn't try every dev version, but ""just waiting for the fix"" didn't help :) 

what helps:
1) putting kobo to sleep, and waking it up while moving finger on the screen;
2) of course, full restart (twice, because first time kobo boots into nickel, after a forced long press; second time it boots to Kobo Start Menu 9 after second forced long press);

suggestion: koreader needs to initialize/reset the digitizer somehow (via kernel driver call?); it definitely has something to do with hardware, sensors, debouncing (as a hardware phenomenon) and kobo specifics; may be nickel has some weird code executed on wakeup that is visible under disassembler;

extra observations:
1) nickel (a factory rakuten reader software) never has this issue; while in nickel, putting to sleep by short pressing device's button on top and waking it up by the second press - always makes taps correct (never my taps to turn page are ""seen"" by nickel as long taps);
2) plato doesn't seem to have this issue, but I didn't use it too much yet (inconvenient folder access, I can't find a book I put into 3/4-level folder structure; with hundreds of books I need a listing and an explorer-like interface, instead of tags-like);
3) KSM never had this misinterpretation of taps (probably because it always starts from ""cold hardware"" reset state);

#### Steps to reproduce
1) get a kobo glo hd (if nobody else complains then probably only a single device that I have is broken);
2) install ANY version of koreader (I was observing this issue for 1 year hoping it will be fixed soon);
3) download any EPUB from Wiki;
4) do normal reading, turn the pages, put kobo to sleep;
5) every 10-15 ""wake-ups"" you will see exactly the same symptoms I described in the ISSUE section above;


#### MY BIG THANKS FOR:
1) a better ""reflow"" in PDFs;
2) wifi permanent connection and auto-restore of wifi connection on wakeup;
3) dictionaries that I can download from koreader top menu (before, it was a nightmare);
4) detailed (marked as dangerous) settings where I can mention that landscape will turn counter-clockwise (I couldn't prove it is working though, but may be next release);
5) text editor (!!) where I can put notes;
6) CSS styles applied to all books from the Style Tweaks menu - THIS IS GOLDEN!! Thank you

#### comparing to nickel, koreader is a gem!","Does this affect the very first touch input when koreader starts, too? Because that one is often wonky on my H20, FWIW...","6) CSS styles applied to all books from the Style Tweaks menu - THIS IS GOLDEN!! Thank you

####"
ValveSoftware/halflife,https://github.com/ValveSoftware/halflife/issues/2205,ValveSoftware_halflife_issues_2205,"[GoldSource/CS][Bug/Feature] Disable help & hud (autohelp)

~~Block messages of the type ""HudTextArgs"" (ex. ""Press the BUY key to purchase items"")~~

~~This should be cvar toggleable.~~

~~[Source & Code](https://forums.alliedmods.net/showthread.php?t=92992)~~

I. The function is bugged. See [Splatt581's reply](https://github.com/ValveSoftware/halflife/issues/2205#issuecomment-486169724)
II. There's no block for HUD/DHUD (as plugins messages). See [perforatorRU's reply](https://github.com/ValveSoftware/halflife/issues/2205#issuecomment-486145200)","Can you add cvar ""hud_msg 1/0""  (For HUD and DHUD messages) like this ""hud_saytext_internal 1/0"" ?","~~

I. The function is bugged. See [Splatt581's reply](https://github.com/ValveSoftware/halflife/issues/2205#issuecomment-486169724)
II. There's no block for HUD/DHUD (as plugins messages). See [perforatorRU's reply](https://github.com/ValveSoftware/halflife/issues/2205#issuecomment-486145200)"
ValveSoftware/halflife,https://github.com/ValveSoftware/halflife/issues/2358,ValveSoftware_halflife_issues_2358,"[CS 1.6] Auto-Retry: add checking for relevance

Auto-Retry
Need add check: if the Player is already connected to THIS server (IP:PORT = IP:PORT) - do nothing (not connect) or deactivate the Auto-Retry button or close the window. Why need connect to the same server, messing up the game's achievements and interrupting the gameplay?

![Auto-Retry](https://user-images.githubusercontent.com/11433503/56962035-2bf3b300-6b5e-11e9-8f4f-3394a40a45ba.png)",What if i waiting slot on full server and want spend this time on another server?,"- do nothing (not connect)  or close the window Why need connect to the same server, messing up the game's achievements and interrupting the gameplay?"
ValveSoftware/halflife,https://github.com/ValveSoftware/halflife/issues/2383,ValveSoftware_halflife_issues_2383,"[CS 1.6 and CS:CZ] Lag issue in any multiplayer game

@kisak-valve @mikela-valve 

Animation lag ( firing, jumping etc.) appears in CS 1.6 and CS:CZ multiplayer game (Online and LAN). Gameplay isn't smooth as other GoldSrc games.

When I set cl_lw to ""0"", the lag disaapears but i heard this command isn't a legal command in multiplayer servers.

This maybe a netcode (client and server rate values) problem. But the rate values are same in all GoldSrc games :/

I am sure this is a ""client-server"" issue because other GoldSrc games don't have this problem.This happens only in CS 1.6 and CS:CZ  multiplayer server.

**Note**: I tested in vanilla games (without any mods, cfgs etc.).  Also, i tried everything (formatting pc, scanning virus, tested compatibility modes, running as admin, updating drivers etc.).",Can you provide some videos to show this behavior?,"Also, i tried everything (formatting pc, scanning virus, tested compatibility modes, running as admin, updating drivers etc.)."
summernote/summernote,https://github.com/summernote/summernote/issues/3651,summernote_summernote_issues_3651,"image resize popover is not show when we click on the image.

when I click on the image `note-popover popover in note-image-popover bottom` style display changes to `block` from `none` but the `div` body is not showing there.

![Screenshot from 2020-04-01 14-11-23](https://user-images.githubusercontent.com/54055697/78118701-fcf85800-7424-11ea-9dbe-3f4618b4fa7c.jpg)",What are you using to initialise Summernote? I have a feeling that the image popover is being overridden when you are initialising Summernote.,![Screenshot from 2020-04-01 14-11-23](https://user-images.githubusercontent.com/54055697/78118701-fcf85800-7424-11ea-9dbe-3f4618b4fa7c.jpg)
modelica/ModelicaStandardLibrary,https://github.com/modelica/ModelicaStandardLibrary/issues/2675,modelica_ModelicaStandardLibrary_issues_2675,"Temperature jumping to 0K with V_flow = 0

Using Dymola 2019 FD01 Dev1 with the model [CoolingCircuit.zip](https://github.com/modelica/ModelicaStandardLibrary/files/2144475/CoolingCircuit.zip) the temperature exhibits discontinuities when the volume flow is set to 0 (temperature jumps to 0K). 

Notes:
- I used MSL Version: 3.2.3, 2018-08-01, build 1 (2018-08-01 12:00:00Z) - that comes with Dymola 2019 FD01 Dev1
- The problem was not existant with MSL 3.2.2 in Dymola 2019 FD01 Dev1 or Dymola 2019.
- The problem does exist in Dymola 2019 and 2018 FD01 with MSL 3.2.3
- The problem is resolved when the relative pressure sensor is removed from the simulation.","Which v3.2.3 is it exactly - beta.1, beta.2 or beta.3?","does exist in Dymola 2019 with MSL 3.2.3
- The problem"
mirumee/saleor,https://github.com/mirumee/saleor/issues/2886,mirumee_saleor_issues_2886,"STRICTNESS does not exist in my Django 2.1.1

### What I'm trying to achieve
I'm trying to compile your code with my Django 2.1.1 and python 3.5.2 from the demo branch. In your graphql/core/filters you are trying to import STRICTNESS from Django_filters but that does not exist, probably deprecated.



### What I expected to happen
compilation fails.

### Screenshots

  File ""/usr/lib/python3.5/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 665, in exec_mdule
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
  File ""/www/rbook.com/rbook/urls.py"", line 17, in <module>
    from .graphql.api import schema
  File ""/www/rbook.com/rbook/graphql/api.py"", line 14, in <module>
    from .menu.mutations import (
  File ""/www/rbook.com/rbook/graphql/menu/mutations.py"", line 7, in <module>
    from ..product.types import Category, Collection
  File ""/www/rbook.com/rbook/graphql/product/types.py"", line 13, in <module>
    from ..core.filters import DistinctFilterSet
  File ""/www/rbook.com/rbook/graphql/core/filters.py"", line 2, in <module>
    from django_filters.constants import STRICTNESS
ImportError: cannot import name 'STRICTNESS'",Whats the version of django filters youre using?,"raphql/menu/mutations.py"", line 7, in <module>
    from ..product.types import Category, Collection
  File ""/www/r"
mirumee/saleor,https://github.com/mirumee/saleor/issues/5047,mirumee_saleor_issues_5047,"Upgrade graphene-django to 2.7.0 and above (filters connection)

Blamed breaking changes: https://github.com/graphql-python/graphene-django/compare/v2.6.0...v2.7.0#diff-4693e93918b75fd2ff08fbe53fec5118R141


### What I'm trying to achieve

When I run the environment I can't run some graphql queries.

### Steps to reproduce the problem
1. Build and configure an environment (migrations synced, populatedb synced)
2. Run a products graphQL

**System information**
Operating system: macOs Mojave 10.14.6

Environment: Python 3.8.0 OR Docker Image (both result on same error)

After the latest updates (I am synchronized with the last head of the master branch # 440c9b18fce96a14827a59ec1c4c659c0fdf1a09) when I run a basic graphql query on products, eg:
```
query {
  products(first: 3) {
    edges {
      node {
        id
        name
        description
        category {
          name
        }
      }
    }
  }
}
```

I got the following error: 
```
{
    ""errors"": [
        {
            ""message"": ""connection_resolver() takes 10 positional arguments but 11 were given"",
            ""locations"": [
                {
                    ""line"": 2,
                    ""column"": 3
                }
            ],
            ""path"": [
                ""products""
            ],
            ""extensions"": {
                ""exception"": {
                    ""code"": ""TypeError"",
                    ""stacktrace"": [
                        ""Traceback (most recent call last):"",
                        ""  File \""/Users/u/Library/Caches/pypoetry/virtualenvs/saleor-py3.8/lib/python3.8/site-packages/promise/promise.py\"", line 487, in _resolve_from_executor"",
                        ""    executor(resolve, reject)"",
                        ""  File \""/Users/u/Library/Caches/pypoetry/virtualenvs/saleor-py3.8/lib/python3.8/site-packages/promise/promise.py\"", line 754, in executor"",
                        ""    return resolve(f(*args, **kwargs))"",
                        ""  File \""/Users/u/Library/Caches/pypoetry/virtualenvs/saleor-py3.8/lib/python3.8/site-packages/graphql/execution/middleware.py\"", line 75, in make_it_promise"",
                        ""    return next(*args, **kwargs)"",
                        ""TypeError: connection_resolver() takes 10 positional arguments but 11 were given""
                    ]
                }
            }
        }
    ],
    ""data"": {
        ""products"": null
    }
}
```

The same occurs on query **productVariants**, but if i try:
```
query {
  product(id: ""UHJvZHVjdDo2MQ=="") {
    id
    name
    description
    category {
      name
    }
  }
}
```

I got the correct result: 
```
{
    ""data"": {
        ""product"": {
            ""id"": ""UHJvZHVjdDo2MQ=="",
            ""name"": ""Nebula Night Sky Paint"",
            ""description"": ""Tonight, my love, let us take fat brushes and paint the skies with the shades of nebula tides. Get the dark, moody shades of the ether."",
            ""category"": {
                ""name"": ""Accessories""
            }
        }
    }
}
```

Is this problem only related to my environment? I've been testing for some time and I had no problem like that ...

I also did an extensive search on the repository's issues base and also tried hard to find something related to **graphene**, but as it is a bit generic error I found nothing that could help me.

In addition I rolled back to python version 3.7.4 and tested to see if it was anything to do with it (since the update to version 3.8.0 is recent) but the same error happened in version 3.7.

I had a bit of trouble debugging the connection_resolver method arguments, so I'm opening here .. hope you can help me! I apologize if I was not very clear.

Thanks guys","Can you share some details from the server logs (with exception)?
Did you try to reinstall requirements?",Blamed breaking changes: https://github.com/graphql-python/graphene-django/compare/v2.6.0...v2.7.0#diff-4693e93918b75fd2ff08fbe53fec5118R141
vatesfr/xen-orchestra,https://github.com/vatesfr/xen-orchestra/issues/4403,vatesfr_xen-orchestra_issues_4403,"Clone backup task option

Hi

The clone backup task would be very useful - for example right now if I want to create backup that have just different destination I need to create all task from the beginning. If the clone backup task would exist I could clone task, change backup settings (eg. remove two vms) and I'm done.

Question: in a matter of programming does it involves a lot of work?

![image](https://user-images.githubusercontent.com/20043789/62446809-05987180-b764-11e9-8647-fb6804d4a25b.png)","Why not using smart mode at the first place? When you have more than few VMs, smart mode is the solution (having eg backup on VM with some tags etc.)",(eg. remove two vms)
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/7116,umbraco_Umbraco-CMS_issues_7116,"keepalive/ping component should have some config options

Currently the KeepAlive component (see https://github.com/umbraco/Umbraco-CMS/blob/v8/dev/src/Umbraco.Web/Scheduling/KeepAlive.cs) uses the `_runtime.ApplicationUrl` to send a request to itself. Typically we require that an Umbraco website can send requests to itself based on the external configured URL for the website which normally requires configuring some internal DNS resolution. This might not always be possible in all hosting scenarios, so we want to be able to configure this component with some options:

* Best to create a new interface: IKeepAliveOptions
* The interface should contain 2x properties (for now, maybe more later)
  * Disable (bool) - which would forcibly disable keep alive from running
  * KeepAliveUrl (string) - this could be null and in which case the KeepAlive component would just continue to use the `_runtime.ApplicationUrl`
* The ctor of the `Umbraco.Web.Scheduling.KeepAlive` should then have another ctor parameter of type `IKeepAliveOptions` which could be an optional parameter that defaults to NULL
* Then the component's code needs to be updated to use these options if they are not null
* Then the `Umbraco.Web.Scheduling.SchedulerComponent` needs to be updated to pass in an instance of IKeepAliveOptions in the `RegisterKeepAlive`
  * For now, it will be easiest to create an internal class `KeepAliveOptions` which implements `IKeepAliveOptions` which reads from appSettings, these keys could be used (which could be added as constants to `Umbraco.Core.Constants.AppSettings`)
    * ""Umbraco.Web.KeepAlive.Disabled"" 
    * ""Umbraco.Web.KeepAlive.Url"" 

---
_(Original post below...)_


## Umbraco version

I am seeing this issue on Umbraco version: 8.1.3

Reproduction
------------

### Bug summary

The `Ping` action in the `KeepAliveController` only allows local request. If requests are not coming from localhost, the `OnlyLocalRequests` attribute returns a 404. 
In my case, the 'umbracoApplicationUrl' is set to 'https://admin.mysite.com/umbraco'. This setting is being used by the [`KeepAlive` RecurringTaskBase.](https://github.com/umbraco/Umbraco-CMS/blob/27223738c6af045b637bb9944b53134e681ce5e5/src/Umbraco.Web/Scheduling/KeepAlive.cs#L60).
The task sends an HTTP GET request to 'https://admin.mysite.com/umbraco/api/keepalive/ping'. When making that request, a 404 is return because of the `OnlyLocalRequests` attribute.

This is causing the logs to be full of 404 issues. 
_Can we change the behavior for the `KeepAlive` task so it can use a new base URL setting specifically for `KeepAlive`?
Alternatively, it would be great to be able to turn off the KeepAlive functionality?_

### Specifics

- umbracoApplicationUrl set to 'https://admin.mysite.com/umbraco'
- admin.mysite.com is proxied through Cloudflare
- site is hosted on Azure App Service",What do you think?,"Currently the KeepAlive component (see https://github.com/umbraco/Umbraco-CMS/blob/v8/dev/src/Umbraco.Web/Scheduling/KeepAlive.cs) uses the `_runtime.ApplicationUrl` to send a request to itself. Typically we require that an Umbraco website can send requests to itself based on the external configured URL for the website which normally requires configuring some internal DNS resolution. This might not always be possible in all hosting scenarios, so we want to be able to configure this component with some options:

* Best to create a new interface: IKeepAliveOptions
* The interface should contain 2x properties (for now, maybe more later)
  * Disable (bool) - which would forcibly disable keep alive from running
  * KeepAliveUrl (string) - this could be null and in which case the KeepAlive component would just continue to use the `_runtime.ApplicationUrl`
* The ctor of the `Umbraco.Web.Scheduling.KeepAlive` should then have another ctor parameter of type `IKeepAliveOptions` which could be an optional parameter that defaults to NULL
* Then the component's code needs to be updated to use these options if they are not null
* Then the `Umbraco.Web.Scheduling.SchedulerComponent` needs to be updated to pass in an instance of IKeepAliveOptions in the `RegisterKeepAlive`
  * For now, it will be easiest to create an internal class `KeepAliveOptions` which implements `IKeepAliveOptions` which reads from appSettings, these keys could be used (which could be added as constants to `Umbraco.Core.Constants.AppSettings`)
    * ""Umbraco.Web.KeepAlive.Disabled"" 
    * ""Umbraco.Web.KeepAlive.Url"" 

---
_(Original post below...)_"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/6215,umbraco_Umbraco-CMS_issues_6215,"Replace Ace with Monaco Editor (VS Code)

Hi i would like to suggest the change, to replace Ace with Monaco Editor instead.

I was able to get a sample running as a umbraco property in less than an hour.

Live running sample: https://microsoft.github.io/monaco-editor/

Samples: https://github.com/microsoft/monaco-editor-samples

Their api documentation is great: https://microsoft.github.io/monaco-editor/api/index.html

There is support for razor language.

We could over time add intellisense for models, methods etc.

Feature Comparision

IDE | Ace | Monaco
-- | -- | --
Autocomplete | Yes | Yes
Loader | Yes (AMD   loader) | Default   Loader.js is an AMD loader. Can use require.js
Themes | 20+ | 3
Code-folding | Yes | Yes
Multiple Cursur | Yes | Yes
**Diff Editor/Tool** | No | Yes *(Inline or split-view)*
Context Menu | *None*  | Yes
Command Palette | *None*  | Yes
Syntax Highligther | Yes | Yes
Browser Support | *Unable to find information* | IE 9/10/11, Edge, Chrome, Firefox, Safari and Opera *(Does not support mobile browsers. Scrolling does not work, writing jump etc.)*
Accessibility | No | Yes
Intellisense Support | Yes | Yes
Out-of-Box Intellisense | No | Yes
Live Syntax Checker | JavaScript/CoffeeScript/CSS/Xquery | TypeScript,   JavaScript, CSS, LESS, SCSS, JSON, HTML
**Syntax Colorization** | There   should be support for 110 modes. | XML, PHP, C#, C++,   Razor, Markdown, Diff, Java, VB,   CoffeeScript, Handlebars, Batch, Pug, F#, Lua, Powershell, Python, Ruby,   SASS, R, Objective-C, *(Maybe all 56)*
Languages | 110 | 56
**Rich IntelliSense, Validation**<br /> *(Syntax colorization plus errors, warnings, IntelliSense, formatting, outlining)* | None | **TypeScript, JavaScript, CSS, LESS, SCSS, JSON, HTML**
Github Stars | 20,300 | 16,792
Github Forks | 4,454 | 1,489
Github Used by | Unknown | 3,052
Github Watch | 640 | 467
Created At | Unkown | Unknown",Would you be willing to work on this as a pull request?,"Feature Comparision

IDE | Ace | Monaco
-- | -- | --
Autocomplete | Yes | Yes
Loader | Yes (AMD   loader) | Default   Loader.js is an AMD loader. Can use require.js
Languages | 110 | 56
Themes | 20+ | 3
Code-folding | Yes | Yes
Multiple   Cursur | Yes | Yes
Diff   Editor/Tool | No | Yes *(Inline or split-view)*
Context   Menu |   | Yes
Command   Palette |   | Yes
Syntax   Highligther | Yes | Yes
Browser   Support | Unable to find information | IE 9/10/11, Edge,   Chrome, Firefox, Safari and Opera   Does not support mobile browsers. Scrolling   does not work, writing jump etc.)
Accessibility | No | Yes
Intellisense   Support | Yes | Yes
Out-of-Box   intellisense | No | Yes
Github   Stars | 20,300 | 16,792
Github   Forks | 4,454 | 1,489
Github   Used by | Unknown | 3,052
Github   Watch | 640 | 467
Document   formatting |   | Javascript,   HTML, Raz
Live   Syntax Checker | JavaScript/CoffeeScript/CSS/Xquery | TypeScript,   JavaScript, CSS, LESS, SCSS, JSON, HTML
Syntax   Colorization | There   should be support for 110 modes. | XML, PHP, C#, C++,   Razor, Markdown, Diff, Java, VB,   CoffeeScript, Handlebars, Batch, Pug, F#, Lua, Powershell, Python, Ruby,   SASS, R, Objective-C
Rich IntelliSense,   Validation   *(Syntax colorization plus errors, warnings, IntelliSense, formatting,   outlining)* | None | **TypeScript, JavaScript, CSS, LESS, SCSS, JSON, HTML**"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/7756,umbraco_Umbraco-CMS_issues_7756,"Umbraco 8 very slow modifying a document type

I have an Umbraco 8.5.3 with lots of content and media items.
My examine index goes like 15512 documents
Published cache status: Database cache is ok. ContentStore contains 8898 items and has 1 generation and 1 snapshot. MediaStore contains 4341 items and has 1 generation and 1 snapshot.

At first everything was ok when site was empty but since we have that many content modifying (ie adding a property) a document type goes sometimes about a minute when saving. And sometimes it gets a timeout error. 
Creating an empty document type is very slow too. Deleting it too.
I think it is every document type operation related.
The rest, creating and saving content and media goes very fast.
The site loads very well, only problem at the backoffice when saving a document type.
I have tried removing custom code but the problem keeps happening.
I have Models builder disabled. And create the document types without template.
The problem happens both on my local dev machine (windows 10, sql express) and on azure web app with sql azure.



---
_This item has been added to our backlog [AB#5773](https://dev.azure.com/umbraco/243e7927-03b2-44e2-908f-d4ac7ea5daaa/_workitems/edit/5773)_",how much content and how many media items do you have? What breaks?,"---
_This item has been added to our backlog AB#5773_"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/4915,umbraco_Umbraco-CMS_issues_4915,"V8: Language Variants editable when language is not set in cultures & hostnames

It's currently possible to configure the language variants of a page even though the page is not available in that language.

<!--

If you haven't yet done so, please read the ""contributing guidelines""
thoroughly. Then, proceed by filling out the rest of the details in the issue
template below. The more details you can give us, the easier it will be for us
to determine the cause of a problem.

See: https://github.com/umbraco/Umbraco-CMS/blob/dev-v7/.github/CONTRIBUTING.md

-->



Reproduction
------------
### Specifics

<!--
    * Mention the URL where this bug occurs, if applicable
    * What version of Umbraco are you using (down to the very last digit!)
    * What browser and version you are using
    * Please mention if you've checked it in other browsers as well
    * Please include *full error messages* and *screenshots* if possible
-->
- Umbraco 8.0.0

### Steps to reproduce

<!--
    * Clearly mention the steps to reproduce the bug
-->
1. Clean install Umbraco 8
2. Settings > Language > Add new. For example: _German (Germany)_
3. Create a new document type, allow varying by culture. For example: _Homepage_
4. Create a homepage in the content tree, named 'United Kingdom'
5. Create another homepage in the content tree, named 'Germany'
6. Right-click 'United Kingdom' > Cultures and hostnames...
7. Add a domain with the English language
8. Right-click 'Germany' > Cultures and hostnames...
9. Add a domain with the German language
10. Open the 'United Kingdom' homepage
![image](https://user-images.githubusercontent.com/23453777/54031447-0b872800-41af-11e9-8b4c-0677ef718e83.png)


### Expected result

<!--
    * What did you _expect_ that would happen on your Umbraco site?
    * Describe the intended/desired outcome after you did the steps mentioned.
-->
I expect to be only able to change the English variant here, as this is the only culture I have configured.

### Actual result

<!--
    * What is the actual result of the above steps?
    * Describe the behaviour of the bug
    * Please, please include **error messages** and screenshots. They might mean
      nothing to you, but they are _very_ helpful to us.
-->
The actual result is that I am still able to configure (and publish) the German language in the United Kingdom homepage.
![image](https://user-images.githubusercontent.com/23453777/54031476-235eac00-41af-11e9-97ab-1de5c1b341f6.png)

![image](https://user-images.githubusercontent.com/23453777/54031553-5d2fb280-41af-11e9-95b7-e1c1ef861361.png)



---
_This item has been added to our backlog [AB#4499](https://dev.azure.com/umbraco/243e7927-03b2-44e2-908f-d4ac7ea5daaa/_workitems/edit/4499)_",Maybe the core team can advise on an extension point that lets you filter out the available variant languages based on the root level domains?,"---
_This item has been added to our backlog AB#4499_"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/5913,umbraco_Umbraco-CMS_issues_5913,"NC keys: When copying page nested content does not update properly

This issue description has been updated with a propsed solution and has been marked as up for grabs. Please read below about the original issue and the proposed solution. You can also scroll way down to read the entire discussion and history.

### Proposed solution

Taking some inspiration from the media tracking branch and looking at what we already have in core:

* Nested content (and any other property editor) can handle the `IDataValueEditor.FromEditor` to re-populate any missing keys. Nested content already overrides this method so it would be just adding the logic to check for empty keys. Empty keys may be sent up if the client side clears them when copying them with the clipboard service. Nested content calls FromEditor recursively so if there's an NC inside an NC this will still work.
* Create a new interface: `IDataValueCopying` which can be implemented by any `IDataValueEditor` (like like `IDataValueReference` for media tracking). It could have one method like: `object Copy(object input);`
* We create an external component to handle `ContentService.Copying`, the event handler will use the current `IContent` along with the `PropertyEditorCollection` to figure out if any of the `IDataValueEditor`s being used for any of the properties implement `IDataValueCopying` and if so, will invoke the `Copy` method and set the new property value to the result.
* the `NestedContentPropertyValueEditor` then implements this interface and it will have to deal with having nested nested contents but that shouldn't be too difficult.

## Original submitted issue

When we copy pages with Nested Content and edit a published element the copied page still shows values from the original content. For example an image block where we changed the image still gives us the original image when checking the strongly typed model. The source value of the property does update properly, as demonstrated in the image below:

![image](https://user-images.githubusercontent.com/22070292/61291409-be573a80-a7ce-11e9-843e-442e62c2598b.png)

Reproduction
------------
- Create a page with nested content
- copy the page
- change a property of a block in the nested content
- check the return values.

This bug appears in Umbraco version 8.0.2

---
_This item has been added to our backlog [AB#6684](https://dev.azure.com/umbraco/243e7927-03b2-44e2-908f-d4ac7ea5daaa/_workitems/edit/6684)_",Would you expect the elements on the copy to update automatically when you update elements on the original?,"---
_This item has been added to our backlog AB#3488_"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/5362,umbraco_Umbraco-CMS_issues_5362,"Caches refreshing too many things on publish/updates?

umbraco v8
after publish or update pages or articles or any document type, umbraco goes to update cache (database and files)
but when i have about 120,000 record it take about one hour!!! it need to wait about one hour to publish a not or update a document.

but we need just update updated document cache not all cache date, you remove all cache data and rebuild it from binning, it's not impossible for large data websites

---
_This item has been added to our backlog [AB#2860](https://umbraco.visualstudio.com/243e7927-03b2-44e2-908f-d4ac7ea5daaa/_workitems/edit/2860)_","Can you provide more details about this question? Like, how do you know we rebuild everything, how do you reproduce the situation, etc?","---
_This item has been added to our backlog AB#2860_"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/6157,umbraco_Umbraco-CMS_issues_6157,"umb-tree directive in custom property editor saves node on toggle

**NOTE: Please see the replacement issue here: https://github.com/umbraco/Umbraco-CMS/issues/6187**

Reproduction
------------

### Bug summary
In Umbraco 8.1.3, using the `<umb-tree>` directive in a custom property editor causes the node on which the property editor is included to be saved every time a tree item is expanded or collapsed. This seems to happen regardless of the settings on the <umb-tree> directive. This behavior does not occur in Umbraco 7.15.1.

### Steps to reproduce
In 8.1.3, create a custom property editor with the following HTML:

```
<umb-tree section=""content"" treealias=""content"" on-init=""""></umb-tree>
```

No JS file or other code is needed. Now, expand or collapse any item with children.

### Expected result
No actions are triggered automatically.

### Actual result
The current node is saved each time a tree item is expanded or collapsed.","Where does the custom tree go, is this in a custom section or..?","**NOTE: Please see my reply from 8/22/19 below, as this bug is broader than originally described.**"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/5835,umbraco_Umbraco-CMS_issues_5835,"Issue with dialogService.linkpicker after 7.15 upgrade

Hello,

After upgrading Umbraco from 7.14 to 7.15, we have encountered an issue where by anything that uses a **dialogService.linkpicker** doesn't work i.e the content tree doesn't load (shows as {{tree.name}}).

The browser console shows the following error:-

_Cannot read property 'dataTypeId' of undefined_

Which we've tracked down it down to this file:-

/umbraco/js/umbraco.controller.js

The code below was from 7.14

`        $scope.searchInfo = {
            searchFromId: null,
            searchFromName: null,
            showSearch: false,
            results: [],
            selectedSearchResults: []
        };
`

And the code from 7.15

`        $scope.searchInfo = {
            searchFromId: null,
            searchFromName: null,
            showSearch: false,
            dataTypeId: $scope.model.dataTypeId,
            results: [],
            selectedSearchResults: []
        };`

If we remove the extra line : dataTypeId: $scope.model.dataTypeId it works again.



---
_This item has been added to our backlog [AB#1693](https://umbraco.visualstudio.com/243e7927-03b2-44e2-908f-d4ac7ea5daaa/_workitems/edit/1693)_","How are you using `dialogService.linkpicker`, do you have example code for us to try out?","---
_This item has been added to our backlog AB#1693_"
umbraco/Umbraco-CMS,https://github.com/umbraco/Umbraco-CMS/issues/7870,umbraco_Umbraco-CMS_issues_7870,"New property in Element / Nested Content Not Being Saved Until Application Restart



<!--

Please fill out the rest of the details in the issue template below. 
The more details you can give us, the easier it will be for us
to determine the cause of a problem.

-->

## Umbraco version

I am seeing this issue on Umbraco version: 8.6


Reproduction
------------

### Bug summary
When one creates a new property like a TextString on an element type used within a nested content property one is unable to store the value of the property until the application is restarted.

<!--
    * Write a short summary of the bug
    * Try to pinpoint it as much as possible
    * Try to state the _actual problem_, and not just what you _think_ the
      solution might be.
-->

### Specifics
Browsers:
Firefox 74
Chrome 80

IDE:
Visual Studio 16.4.5
Debug Mode
Debugger Attached

<!--
    * Mention the URL where this bug occurs, if applicable
    * What version of Umbraco are you using (down to the very last digit!)
    * What browser and version you are using
    * Please mention if you've checked it in other browsers as well
    * Please include *full error messages* and *screenshots* if possible
-->

### Steps to reproduce
1. Use Umbraco Starter Template
2. Create new TextString property under ""Feature"" Document Type
3. Enter a value for the new TextString property under a ""Product"" for an existing ""Feature""
4. Click Save and Publsih
5. Refresh the page Ctrl+Shift+R

<!--
    * Clearly mention the steps to reproduce the bug
-->

### Expected result
The value saved for the new property should be filled in on refresh.
<!--
    * What did you _expect_ that would happen on your Umbraco site?
    * Describe the intended/desired outcome after you did the steps mentioned.
-->

### Actual result
The value for the new property is blank after refresh.
<!--
    * What is the actual result of the above steps?
    * Describe the behaviour of the bug
    * Please, please include **error messages** and screenshots. They might mean
      nothing to you, but they are _very_ helpful to us.
-->

### Work Around
Stop debugging. Start debugging. Once application reloads it works correctly.

---
_This item has been added to our backlog [AB#6260](https://dev.azure.com/umbraco/243e7927-03b2-44e2-908f-d4ac7ea5daaa/_workitems/edit/6260)_",What Umbraco version are you using?,"---
_This item has been added to our backlog AB#6260_"
processing/p5.js,https://github.com/processing/p5.js/issues/3450,processing_p5.js_issues_3450,"Examples involving keyboard events, only one works

<!--
Hi,

Was adding to the event keyboard examples and noticed  that only the 1st example actually functions and the following examples don't function.

-->

#### Nature of issue?

- [x] Found a bug

#### Most appropriate sub-area of p5.js?

- [x] Events

#### Which platform were you using when you encountered this?

- [x] Desktop/Laptop

#### Details about the bug: 

Was adding to the event keyboard examples and noticed  that only the 1st example actually functions and the following examples don't function.   see https://p5js.org/reference/#/p5/keyPressed

- Web browser and version: Chrome 71.0.3578.98 (Official Build) (64-bit)
- Operating System: Windows 10
- Steps to reproduce this:
Add a 2nd code example to keyboard.js see https://p5js.org/reference/#/p5/keyPressed",Where can I find the code where keyPressed() is implemented?,#### Which platform were you using when you encountered this?
processing/p5.js,https://github.com/processing/p5.js/issues/3693,processing_p5.js_issues_3693,"SaveBytes() new feature request

I was trying to save a variable as binary file and found there wasn't an easy way to do that in p5. 
I found some code that did this and was wondering how complex it would be to add to p5.
 Processing has a saveBytes() function

- [x] New feature request

#### Most appropriate sub-area of p5.js?
- [x] IO

#### New feature details:
from stackoverflow  https://stackoverflow.com/a/23451803/45966

```javascript
var sampleBytes = new Int8Array(size_required);
var saveByteArray = (function () {
    var a = document.createElement(""a"");
    document.body.appendChild(a);
    a.style = ""display: none"";
    return function (data, name) {
        var blob = new Blob(data, {type: ""octet/stream""}),
            url = window.URL.createObjectURL(blob);
            a.href = url;
            a.download = name;
            a.click();
            window.URL.revokeObjectURL(url);
    };
}());

saveByteArray([sampleBytes], 'output_file.bin');
```",Can you share a bit more about the use case?,Processing has a saveBytes() function
wesnoth/wesnoth,https://github.com/wesnoth/wesnoth/issues/4309,wesnoth_wesnoth_issues_4309,"1.15.1 Switching virtual desktops with full-screen wesnoth causes graphics issues

Steps to reproduce:
* start wesnoth
* open preferences > Display > enable ""full-screen"" checkbox
* start any game
* switch to another application
* switch back to wesnoth

Expected at this point:
* battlefield is shown normally

Actually:
![2019 09 02_22:35:19](https://user-images.githubusercontent.com/33452702/64150848-667d9d00-ce29-11e9-9dcf-ca6baa04d0aa.png)",Which operating system do you use? This may well be OS specific (and even depend on your window manager if you use GNU/Linux).,"* open preferences > Display > enable ""full-screen"" checkbox"
Tribler/tribler,https://github.com/Tribler/tribler/issues/4303,Tribler_tribler_issues_4303,"RuntimeError on Twisted

<!-- Delete non-relevant parts if this is not a bug report -->

#### Please, fill all relevant items: ####

- [x] I have read CONTRIBUTING.rst

- [x] I have tried with the latest pre-release version and I still can reproduce the issue.

##### Tribler version/branch+revision: #####

##### Operating system and version: #####

##### Steps to reproduce the behavior: #####

##### Expected behavior: #####

##### Actual behavior: #####

##### Relevant log file output: #####
```python
RuntimeError: Unhandled Error Traceback (most recent call last):
   File ""lib\site-packages\twisted\internet\base.py"", line 428, in fireEvent
        File ""lib\site-packages\twisted\internet\defer.py"", line 321, in addCallback
        File ""lib\site-packages\twisted\internet\defer.py"", line 310, in addCallbacks
        File ""lib\site-packages\twisted\internet\defer.py"", line 653, in _runCallbacks
```",Do you have any more information about this error? Did it happen when you performed a specific action in Tribler?,"```python
RuntimeError: Unhandled Error Traceback (most recent call last):   File ""lib\site-packages\twisted\internet\base.py"", line 428, in fireEvent        File ""lib\site-packages\twisted\internet\defer.py"", line 321, in addCallback        File ""lib\site-packages\twisted\internet\defer.py"", line 310, in addCallbacks        File ""lib\site-packages\twisted\internet\defer.py"", line 653, in _runCallbacks
```"
cmangos/issues,https://github.com/cmangos/issues/issues/2098,cmangos_issues_issues_2098,"🐛 [Bug Report] ERROR WorldSocket ProcessIncomingData client sent malformed packet size

## 🐛 Bugreport
<!-- Describe your issue in detail. Include screenshots if needed. Give us as much information as possible. -->
Not sure what this is, can't remember seeing this.  

2020-01-21 17:08:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" removed.
**2020-01-21 17:17:23 ERROR:WorldSocket::ProcessIncomingData: client sent malformed packet size = 1025 , cmd = 2109479168**
2020-01-21 17:28:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" started.
2020-01-21 17:38:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" removed.
2020-01-21 19:01:01 GameEvent 1024 ""Hourly Bells"" removed.
2020-01-21 19:08:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" removed.
**2020-01-21 19:15:23 ERROR:WorldSocket::ProcessIncomingData: client sent malformed packet size = 18245 , cmd = 539959380**  

2020-01-22 02:01:01 GameEvent 1024 ""Hourly Bells"" removed.
2020-01-22 02:08:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" removed.
2020-01-22 02:15:33 ERROR:WorldSocket::ProcessIncomingData: client sent malformed packet size = 18245 , cmd = 539959380
**2020-01-22 02:15:37 ERROR:WorldSocket::ProcessIncomingData: client sent malformed packet size = 5635 , cmd = 16777729**
2020-01-22 02:28:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" started.
2020-01-22 02:38:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" removed.  

2020-01-22 15:28:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" started.
2020-01-22 15:38:01 GameEvent 61 ""Stormwind City - Stockades Jail Break"" removed.
**2020-01-22 15:55:59 ERROR:Socket::Open() failed to get remote address.  Error: remote_endpoint: Transport endpoint is not connected
2020-01-22 15:55:59 ERROR:WorldSocket::ProcessIncomingData: client sent malformed packet size = 18501 , cmd = 790643777**

### Expected behavior
<!-- How should it work + proof -->
Error is Error.

### Version & Environment
<!--
  Client Version - is required
  Valid values are:
  - ""1.12.1"" (CLASSIC)
  - ""2.4.3"" (TBC)
  - ""3.3.5a"" (WOTLK)
-->
Client Version: 
  - ""1.12.1"" (CLASSIC)
<!--
  Commit Hash - is required
  Valid values are:
  - [CLASSIC](https://github.com/cmangos/mangos-classic/tree/9d7b13a0c0a8fc3678a6e6f2c5cecf37575b85d2)
  - [TBC](https://github.com/cmangos/mangos-tbc/tree/XXXX)
  - [WOTLK](https://github.com/cmangos/mangos-wotlk/tree/XXXX)

  To find XXXX use ""git log -1 --format=%H"" in your local CMaNGOS repo
-->
CMaNGOS Repo & Commit Hash: 
  - [CLASSIC](https://github.com/cmangos/mangos-classic/tree/9d7b13a0c0a8fc3678a6e6f2c5cecf37575b85d2)
<!--
  Database Version - is required
  Valid values are:
  - [CLASSIC](https://github.com/cmangos/classic-db/tree/4a299e914100f9ff118e86802bd4775abb2c5cab)
  - [TBC](https://github.com/cmangos/tbc-db/tree/XXXX)
  - [WOTLK](https://github.com/cmangos/wotlk-db/tree/XXXX)

  To find XXXX use ""git log -1 --format=%H"" in your local Database repo
-->
Database Repo & Commit Hash: 
  - [CLASSIC](https://github.com/cmangos/classic-db/tree/4a299e914100f9ff118e86802bd4775abb2c5cab)
<!--
  Operating System - optional
  Valid values are:
  - Win XX
  - MacOS XX
  - Linux Flavor
-->
Operating System: 
  - Linux Flavor - Raspberry Pi 4 - Ubuntu 19.10 Server
### Steps to reproduce
1. Start server yesterday.
2. Check logs today.
3. hm
4. ...
5. Profit

### Crashlog
<!-- If this is a crash report, include the crashlog from a debug build with https://gist.github.com/) -->
- None
Server still running.",Does it happen every time?,- Raspberry Pi 4 - Ubuntu 19.10 Server
qgis/QGIS-Documentation,https://github.com/qgis/QGIS-Documentation/issues/3068,qgis_QGIS-Documentation_issues_3068,"SAGA toolbox help buttons 403/404 errors

## Description
Help buttons in SAGA tools accessed from the processing toolbox open webpages with 403 or 404 errors.
These are from clicking the help button on the window that opens when double clicking on a SAGA tool.

QGIS 3.2.3 on windows 10 64bit. 

The documentation (and any kind of description for the tools) is therefore harder to reach and has to be searched for.
<!--
Include sentences with details describing the issue you have encountered (e.g., actual behavior, expected behavior, steps to reproduce).
-->

## Checklist
<!--
This is the issue/bug trackers for [QGIS Documentation](https://docs.qgis.org).
Cleaning the queue is a process done by project maintainers, mostly on a volunteer basis.
We try to keep the overhead as small as possible and appreciate if you help us to do so by completing the following items.

Replace the space between square brackets by an x if it's appropriate.
-->
- [ ] I'm aware this repository is about QGIS Documentation and the issue I'm reporting is related to its usage.
If it's related to QGIS application or website, please refer to http://qgis.org/en/site/getinvolved/development/bugreporting.html
for the right issue tracker or to the [support channels](http://qgis.org/en/site/forusers/support.html)
- [ ] I have added a link to the page concerned by the issue","Can you provide the kind of link that is returned by the help button before the failure, please? Thanks",on windows 10 64bit
geoadmin/mf-geoadmin3,https://github.com/geoadmin/mf-geoadmin3/issues/4752,geoadmin_mf-geoadmin3_issues_4752,"[MVT] OL differences with Mapbox rendering

OL does not use the same restrictions on the zoomlevels.

The most visible issue are the mountains, but there is the same problem also with other features.

Just compare them [here](https://codepen.io/pakb/pen/oJNRyK)


Here is a list of issues opened in olms that are mandatory to solve before we can go live

- [x] https://github.com/openlayers/ol-mapbox-style/issues/136 Multiple source : Label decluterring
- [x] https://github.com/openlayers/ol-mapbox-style/issues/137 Add support for font styling described in mapbox style
- [x] https://github.com/openlayers/ol-mapbox-style/issues/138 Interpret zoom level in the same way mapbox does
- [x] https://github.com/openlayers/ol-mapbox-style/issues/139 Rendering of small features, min-width?
- [x] https://github.com/openlayers/ol-mapbox-style/pull/168 text-halo isn't large enough
- [x] https://github.com/openlayers/ol-mapbox-style/issues/170 label margin-bottom is not big enough, and labels tend to overlap their point
- [ ] https://github.com/openlayers/ol-mapbox-style/issues/185 line-offset not supported
- [x] https://github.com/openlayers/ol-mapbox-style/issues/186 labels following polylines bend a lot",Could you change the permissions @danduk82 ?,"Here is a list of issues opened in olms that are mandatory to solve before we can go live

- [ ] https://github.com/openlayers/ol-mapbox-style/issues/136 Multiple source : Label decluterring
- [x] https://github.com/openlayers/ol-mapbox-style/issues/137 Add support for font styling described in mapbox style
- [ ] https://github.com/openlayers/ol-mapbox-style/issues/138 Interpret zoom level in the same way mapbox does
- [ ] https://github.com/openlayers/ol-mapbox-style/issues/139 Rendering of small features, min-width?"
dokku/dokku,https://github.com/dokku/dokku/issues/3674,dokku_dokku_issues_3674,"Allow users to override /etc/nginx/conf.d/dokku.conf

### High Level Plan

- Make `dokku.conf` a regular file in the built package (also handle from-source installs) that can be ignored during upgrades (apt has support for this built-in). If users wish to ignore changes to config files we ship, they can do so at their own risk.

### Original Post

Hi! I'm experimenting with heavily customizing nginx configuration on one of my servers but I noticed today that after an upgrade dokku has overwritten the changes I've made to `/etc/nginx/conf.d/dokku.conf`.

This behavior was verified when I looked into [plugins/nginx-vhosts/install:40](https://github.com/dokku/dokku/blob/2b93c76b1db83cca6682d52cf218222412f8f568/plugins/nginx-vhosts/install#L40). Interestingly enough just a few lines below there's a comment:

> allow users to override their server_names_hash_bucket_size

So I wonder if it there would be any issues if we made the same check before overriding `dokku.conf`. If you see no problems I'd be glad to send a PR.

Thanks!",What are you overriding in that global file?,"### High Level Plan

- Make `dokku.conf` a regular file in the built package (also handle from-source installs) that can be ignored during upgrades (apt has support for this built-in). If users wish to ignore changes to config files we ship, they can do so at their own risk.

### Original Post"
dokku/dokku,https://github.com/dokku/dokku/issues/3717,dokku_dokku_issues_3717,"Unable to install dokku on AWS ec2 instance

## Description of problem
Unable to install dokku on AWS ec2 instance

### How reproducible
wget https://raw.githubusercontent.com/dokku/dokku/v0.19.1/bootstrap.sh
sudo DOKKU_TAG=v0.19.1 bash bootstrap.sh

### Steps to Reproduce
1. Created a fresh instance
2. Ran sudo apt-get update
3. Ran installation commands

#### Actual Results
First Time the error was this.

Errors were encountered while processing: /tmp/apt-dpkg-install-OrzbyA/0-dokku_0.19.1_amd64.deb E: Sub-process /usr/bin/dpkg returned an error code (1)

After I ran again
sudo DOKKU_TAG=v0.19.1 bash bootstrap.sh

and the error changed to this.
Preparing to install v0.19.1 from https://github.com/dokku/dokku.git...
--> Ensuring we have the proper dependencies

E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).

#### Expected Results
it should install dokku

## Environment Information
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=18.04
DISTRIB_CODENAME=bionic
DISTRIB_DESCRIPTION=""Ubuntu 18.04.3 LTS""

The server is this one
![Screenshot 2019-10-18 at 3 39 32 PM](https://user-images.githubusercontent.com/2954644/67088108-c2c03480-f1bd-11e9-8304-d23ca7006700.png)
with 
64-bit (x86) selected",Can you paste which AMI you used to create this?,"First Time the error was this.

Errors were encountered while processing: /tmp/apt-dpkg-install-OrzbyA/0-dokku_0.19.1_amd64.deb E: Sub-process /usr/bin/dpkg returned an error code (1)

After I ran again
sudo DOKKU_TAG=v0.19.1 bash bootstrap.sh

and the error changed to this.

The server is this one
![Screenshot 2019-10-18 at 3 39 32 PM](https://user-images.githubusercontent.com/2954644/67088108-c2c03480-f1bd-11e9-8304-d23ca7006700.png)"
dokku/dokku,https://github.com/dokku/dokku/issues/3922,dokku_dokku_issues_3922,"Old herokuish images filling up the disk

## High Level Plan

- Update herokuish `post-install` to remove unused `gliderlabs/herokuish` images.

## Original Post

I've been happily running my app on dokku for more than 2 years, but then the disk got full (20GB) 
With running `sudo docker images` I noticed that old images of herokuish (each more than 1.2GB) are not cleaned up automatically. More than half of my disk was filled with these old images.  
I removed them manually with `sudo docker image rm IMAGE_ID`
I didn't see this documented so far.",Can you include *all* of the information we ask for in our [issue template](https://github.com/dokku/dokku/blob/master/ISSUE_TEMPLATE.md)? It is helpful for debugging problems. Thanks.,"## High Level Plan

- Update herokuish `post-install` to remove unused `gliderlabs/herokuish` images.

## Original Post"
pypa/warehouse,https://github.com/pypa/warehouse/issues/3733,pypa_warehouse_issues_3733,"valid email address deemed invalid

When trying to add an additional email address to my account, the email address is rejected. This email address however /is/ valid. The domain for the email address is `n--tree.net`. I guess the validator trips over the (admittedly uncommon) double dash in it. Hopefully this can be resolved. 

---

**Good First Issue**: This issue is good for first time contributors. If you've already contributed to Warehouse, work on [another issue without this label](https://github.com/pypa/warehouse/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+-label%3A%22good+first+issue%22) instead. If there is not a corresponding pull request for this issue, it is up for grabs. For directions for getting set up, see our [Getting Started Guide](https://warehouse.pypa.io/development/getting-started/). If you are working on this issue and have questions, feel free to ask them here, [`#pypa-dev` on Freenode](https://webchat.freenode.net/?channels=%23pypa-dev), or the [pypa-dev mailing list](https://groups.google.com/forum/#!forum/pypa-dev).",Would you raise the issue in their tracker instead? https://github.com/wtforms/wtforms/issues. Thanks for the report!,"---

**Good First Issue**: This issue is good for first time contributors. If you've already contributed to Warehouse, work on [another issue without this label](https://github.com/pypa/warehouse/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+-label%3A%22good+first+issue%22) instead. If there is not a corresponding pull request for this issue, it is up for grabs. For directions for getting set up, see our [Getting Started Guide](https://warehouse.pypa.io/development/getting-started/). If you are working on this issue and have questions, feel free to ask them here, [`#pypa-dev` on Freenode](https://webchat.freenode.net/?channels=%23pypa-dev), or the [pypa-dev mailing list](https://groups.google.com/forum/#!forum/pypa-dev)."
couchbase/couchbase-lite-ios,https://github.com/couchbase/couchbase-lite-ios/issues/2184,couchbase_couchbase-lite-ios_issues_2184,"replication fails after resetCheckpoint on ios build 2.1.0-216

### Environment
* Version:   2.1.0-216
* Client OS: iOS

### Steps to reproduce:
       1. create docs in cbl db1
       2. replicate docs to sg/cbl2 db with continous true and push replication
       3. purge docs in cbl db1
       4. replicate again using pull replicator
       5.Verify  purged docs should not get replicated
       6. stop replicator
       7. call reset api
       8. restart the replication using pull replicator

### Expected: 
       9. Verify all purged docs got back in CBL

### Result:
Got 0 docs in CBL",Can you double check the functional tests?,using pull replicator using pull replicator
couchbase/couchbase-lite-ios,https://github.com/couchbase/couchbase-lite-ios/issues/2197,couchbase_couchbase-lite-ios_issues_2197,"Crashes during sync

I’ve released my app with `CouchbaseLite-Swift 2.0.3`. During development and testing I didn’t spot any issues but when released to production to a larger number of users, number of crashes spiked. All of the issues seem to be linked to syncing. These are the 5 crashes that occur in CouchbaseLite-Swift 2.0.3. Each crash has a link to gist with stack trace, name of method where it crashes, number of total crashes and iOS versions distribution.

--------------

### [Crash report 1](https://gist.github.com/sammy-SC/69fe6ae5d15956ab71cb17d690bc638e)

- Crash in `CouchbaseLiteSwift uWS::WebSocketProtocol<false>::consume(char, unsigned int, void) + 44`
- **Total number of crashes**: 18 crashes
- Exception:
```
Crashed: Websocket C4 dispatch
EXC_BAD_ACCESS KERN_INVALID_ADDRESS 0x0000000000000001
```
- **iOS versions**
  - **11.4.1**: 82%
  - **11.2.5**: 6%
  - **11.4.0**: 6%
  - **11.3.1**: 6%

--------------

### [Crash report 2](https://gist.github.com/sammy-SC/aee25b87372f1f8dea22373836da0a30)

- Crash was introduced with `CouchbaseLite-Swift 2.0.3`, it does not have CouchbaseLiteSwift in stack trace however it seems to related to networking
- **Total number of crashes**: 6 crashes
- Exception:
```
Fatal Exception: std::__1::system_error
mutex lock failed: Invalid argument
```
- **iOS versions**
  - **11.4.1**: 66%
  - **11.4.0**: 17%
  - **11.3.1**: 17%

--------------

### [Crash report 3](https://gist.github.com/sammy-SC/b0e3a0a6f40756542b50035c4f0e0fdb)

- Crash in `CouchbaseLiteSwift litecore::blip::Connection::setWebSocket(litecore::websocket::WebSocket*, fleeceapi::AllocedDict const&) + 4256`
- **Total number of crashes**: 4 crashes
- Exception:
```
Crashed: Websocket C4 dispatch
EXC_BAD_ACCESS KERN_INVALID_ADDRESS 0x0000000000000048
```
- **iOS versions**
  - **11.4.1**: 50%
  - **11.3.0**: 50%

--------------

### [Crash report 4](https://gist.github.com/sammy-SC/96f84d1d45eca967c916086a6a43f1d0)

- Crashes in `CouchbaseLiteSwift litecore::websocket::WebSocketImpl::onReceive(fleece::slice) + 124`
- **Total number of crashes**: 2 crashes
- Exception:
```
Crashed: Websocket C4 dispatch
EXC_BAD_ACCESS KERN_INVALID_ADDRESS 0x0000000000000000
```
- **iOS versions**
  - **12.0.0**: 100%

--------------

### [Crash report 5](https://gist.github.com/sammy-SC/def0875e653933a569c9e0c4ea9fdb8e)

- Crashes in `CouchbaseLiteSwift c4socket_gotHTTPResponse + 48`
- **Total number of crashes**: 1 crash
- Exception:
```
Crashed: Websocket C4 dispatch
EXC_BAD_ACCESS KERN_INVALID_ADDRESS 0x7461747300000001
```
- **iOS versions**
  - **11.4.1**: 100%

----

Version:   CouchbaseLite-Swift 2.0.3
Server:    2.0.0",Why is this not prioritised for a hotfix?,"- Exception:
```
Crashed: Websocket C4 dispatch
EXC_BAD_ACCESS KERN_INVALID_ADDRESS 0x0000000000000001
```"
smeighan/xLights,https://github.com/smeighan/xLights/issues/1935,smeighan_xLights_issues_1935,"Add Start Address functionality for individual strings for Custom Models

Ability to define individual start channels for strings for custom models the same way you can for tree and matrix models.",Don't the numbers on the grid still define the offset from the start channel?  Do we automatically throw the different strings onto new ports for the controller upload?,art channels for st
lukesampson/scoop,https://github.com/lukesampson/scoop/issues/3541,lukesampson_scoop_issues_3541,"Start Menu Shortcuts on Uninstallation

Removing start menu shortcuts bug on Scoop uninstallation :/

$ scoop uninstall scoop

INFO: Win10 v1903 V1",What bug? What is not working?,INFO: Win10 v1903 V1
xunit/xunit,https://github.com/xunit/xunit/issues/1684,xunit_xunit_issues_1684,"xunit global CLI tool

I would like to be able to install an xunit console runner globally using the `dotnet tool install -g` feature of the 2.1.300 .NET Core CLI. I know there is already the `dotnet-xunit` tool, but this requires adding a DotNetCliToolReference to all .csproj files, which I find annoying.

IMO ideal usage looks like this
```
$ dotnet tool install -g xunit-cli
$ xunit MyTests.dll
```

Some open design questions:

 - Package name? packages cannot be both a DotNetCliToolRef and a global tool, so unless you want to drop support for `dotnet xunit`, we probably need a new package. I propose making a new package called `xunit-cli` for this.
 - Syntax? `xunit <blah>`. what is `<blah>`? A .dll? A .csproj? Both? IMO, I think you could probably make `xunit MyTests.csproj` and `xunit MyTests.dll` both work, and that would be ideal.
 - .NET Framework support? The initial process launched by a global tool is typically implemented in .NET Core, but the tool could launch `xunit.console.exe` for .NET Framework support on Windows. If we support `xunit file.dll` usage, what would .NET Framework usage look like? Should we attempt to auto-detect framework by looking for config files like `runtimeconfig.json` or `.dll.config` or by reading `System.Runtime.Versioning.TargetFrameworkAttribute` from the assembly? Require a switch to choose the runtime? something else

Happy to help contribute PRs to make this happen.

**Update June 2019**: I've built a prototype and published it for use. See https://github.com/natemcmaster/xunit-cli. 
```
dotnet tool install -g xunit-cli
xunit MyTests.dll
```

cc @bradwilson @onovotny",What about supporting .sln files? This is something that people try to do with `dotnet test` today (and run up against their limitations).,**Update June 2019**: I've built a prototype and published it for use. See https://github.com/natemcmaster/xunit-cli
xunit/xunit,https://github.com/xunit/xunit/issues/2052,xunit_xunit_issues_2052,"Not able to debug xunit test 'Access violation'.

I am not able to debug my xunit tests.

'dotnet.exe' (CoreCLR: clrhost): Loaded 'C:\Users\Ironhide91\source\repos\SomeLibrary\Tests\bin\Debug\netcoreapp3.0\xunit.runner.visualstudio.dotnetcore.testadapter.dll'. Symbols loaded.
The program '[13752] dotnet.exe' has exited with code -1073741819 (0xc0000005) 'Access violation'.

[14-11-2019 11:25:56.042 PM Informational] Store opened in 0.149 sec.
[14-11-2019 11:25:56.762 PM Informational] ---------- Discovery started ----------
[14-11-2019 11:25:58.250 PM Informational] [xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.1 (64-bit .NET Core 3.0.0)
[14-11-2019 11:25:59.901 PM Informational] [xUnit.net 00:00:01.67]   Discovering: SomeLibrary.Test
[14-11-2019 11:26:00.122 PM Informational] [xUnit.net 00:00:01.81]   Discovered:  SomeLibrary.Test
[14-11-2019 11:26:00.171 PM Informational] ========== Discovery finished: 97 tests found (0:00:03.4046552) ==========
[14-11-2019 11:26:05.305 PM Informational] ---------- Discovery started ----------
[14-11-2019 11:26:05.308 PM Informational] ========== Discovery skipped: All test containers are up to date ==========
[14-11-2019 11:26:05.312 PM Informational] ---------- Run started ----------
[14-11-2019 11:26:10.479 PM Informational] [xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.1 (64-bit .NET Core 3.0.0)
[14-11-2019 11:26:13.128 PM Informational] [xUnit.net 00:00:02.66]   Starting:    SomeLibrary.Test
[14-11-2019 11:26:16.191 PM Error] The active test run was aborted. Reason: Test host process crashed
[14-11-2019 11:26:16.727 PM Informational] ========== Run aborted: 0 tests run (0:00:10.9509734) ==========
[14-11-2019 11:26:27.839 PM Informational] ---------- Discovery started ----------
[14-11-2019 11:26:27.843 PM Informational] ========== Discovery skipped: All test containers are up to date ==========
[14-11-2019 11:26:27.978 PM Informational] ---------- Run started ----------
[14-11-2019 11:26:28.582 PM Informational] [xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.1 (64-bit .NET Core 3.0.0)
[14-11-2019 11:26:29.079 PM Informational] [xUnit.net 00:00:00.50]   Starting:    SomeLibrary.Test
[14-11-2019 11:26:55.623 PM Error] The active test run was aborted. Reason: Test host process crashed : Stack overflow.

[14-11-2019 11:26:55.658 PM Informational] ========== Run aborted: 0 tests run (0:00:27.651237) ==========


My project file attached.
[SomeLibrary.txt](https://github.com/xunit/xunit/files/3847876/SomeLibrary.txt)",Can you please provide the entire project?,"[14-11-2019 11:25:56.042 PM Informational] Store opened in 0.149 sec.
[14-11-2019 11:25:56.762 PM Informational] ---------- Discovery started ----------
[14-11-2019 11:25:58.250 PM Informational] [xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.1 (64-bit .NET Core 3.0.0)
[14-11-2019 11:25:59.901 PM Informational] [xUnit.net 00:00:01.67]   Discovering: SomeLibrary.Test
[14-11-2019 11:26:00.122 PM Informational] [xUnit.net 00:00:01.81]   Discovered:  SomeLibrary.Test
[14-11-2019 11:26:00.171 PM Informational] ========== Discovery finished: 97 tests found (0:00:03.4046552) ==========
[14-11-2019 11:26:05.305 PM Informational] ---------- Discovery started ----------
[14-11-2019 11:26:05.308 PM Informational] ========== Discovery skipped: All test containers are up to date ==========
[14-11-2019 11:26:05.312 PM Informational] ---------- Run started ----------
[14-11-2019 11:26:10.479 PM Informational] [xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.1 (64-bit .NET Core 3.0.0)
[14-11-2019 11:26:13.128 PM Informational] [xUnit.net 00:00:02.66]   Starting:    SomeLibrary.Test
[14-11-2019 11:26:16.191 PM Error] The active test run was aborted. Reason: Test host process crashed
[14-11-2019 11:26:16.727 PM Informational] ========== Run aborted: 0 tests run (0:00:10.9509734) ==========
[14-11-2019 11:26:27.839 PM Informational] ---------- Discovery started ----------
[14-11-2019 11:26:27.843 PM Informational] ========== Discovery skipped: All test containers are up to date ==========
[14-11-2019 11:26:27.978 PM Informational] ---------- Run started ----------
[14-11-2019 11:26:28.582 PM Informational] [xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.1 (64-bit .NET Core 3.0.0)
[14-11-2019 11:26:29.079 PM Informational] [xUnit.net 00:00:00.50]   Starting:    SomeLibrary.Test
[14-11-2019 11:26:55.623 PM Error] The active test run was aborted. Reason: Test host process crashed : Stack overflow.

[14-11-2019 11:26:55.658 PM Informational] ========== Run aborted: 0 tests run (0:00:27.651237) =========="
isaacs/github,https://github.com/isaacs/github/issues/1407,isaacs_github_issues_1407,"Git requests Password when GitHub actually requires Auth Token

This confusion arises if you have enabled 2FA. 

When you are asked to re-authenticate to GitHub from the Git command line it will ask you for your username and password. In this case, your username is your Git username (not your GitHub username) and your password will not work (because of 2FA), instead you will need to enter your GitHub auth token.

Proposed fix: Language in the Git command line should be updated so that it is not nonsense.",What is GitHub CLI?,". 

When you are asked to re-authenticate to GitHub from the Git command line it will ask you for your username and password. In this case"
isaacs/github,https://github.com/isaacs/github/issues/1490,isaacs_github_issues_1490,"Configurable tab-size for project/repo UI

Depending on complexity and/or nesting level various projects need to have different tab sizes on file and diff pages.

I think it should not be constant (as described in #170) and repository level configuration would be just fine.
And (maybe) it is better to have it not 8-space size (standard value in most browsers) by default.

 * * *

If you feel it like that, please consider upvoting the similar GitLab issue:
https://gitlab.com/gitlab-org/gitlab-ce/issues/57758",How is this related to `.editorconfig`?,"* * *

If you feel it like that, please consider upvoting the similar GitLab issue:
https://gitlab.com/gitlab-org/gitlab-ce/issues/57758"
PointCloudLibrary/pcl,https://github.com/PointCloudLibrary/pcl/issues/3428,PointCloudLibrary_pcl_issues_3428,"Suspected Memory Leak in pcl clipping

<!--- WARNING: This is an issue tracker. Before opening a new issue make sure you read https://github.com/PointCloudLibrary/pcl/blob/master/CONTRIBUTING.md#using-the-issue-tracker. -->

<!--- Provide a general summary of the issue in the Title above -->


## Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* Operating System and version: Ubuntu 18.04
* Compiler: Python3 and gcc for c++
* PCL Version: 1.8

## Context

Memory leak observed in python version of the code. That is when python wrapper is trying to access PCL C/C++ code to perform clipping. Python is unable to handle the memory 

**Code snippet causing memory leak**

    # build the filter
    condrem = cloud.make_ConditionalRemoval(range_cond)
    condrem.set_KeepOrganized(False)
    # apply filter
    cloud_filtered = condrem.filter()

**C++ equivalent implementation of the above code**

    // build the filter
   pcl::ConditionalRemoval<pcl::PointXYZ> condrem;
   condrem.setCondition (range_cond);
   condrem.setInputCloud (cloud);
   condrem.setKeepOrganized(true);
    // apply filter
    condrem.filter (*cloud_filtered);


## Code to Reproduce

**python code:**

import pcl
import numpy as np
import random
import os, psutil, gc, time

def main():
    cloud = pcl.PointCloud()
    cloud_filtered = pcl.PointCloud()

    points = np.zeros((5, 3), dtype=np.float32)
    RAND_MAX = 1024.0
    for i in range(0, 5):
        points[i][0] = 1024 * random.random() / RAND_MAX
        points[i][1] = 1024 * random.random() / RAND_MAX
        points[i][2] = 1024 * random.random() / RAND_MAX

    cloud.from_array(points)

    range_cond = cloud.make_ConditionAnd()

    range_cond.add_Comparison2('z', pcl.CythonCompareOp_Type.GT, 0.0)
    range_cond.add_Comparison2('z', pcl.CythonCompareOp_Type.LT, 0.8)

    # build the filter
    condrem = cloud.make_ConditionalRemoval(range_cond)
    condrem.set_KeepOrganized(False)
    # apply filter
    cloud_filtered = condrem.filter()

    #print('Cloud before filtering: ')
    for i in range(0, cloud.size):
        print('x: ' + str(cloud[i][0]) + ', y : ' +
              str(cloud[i][1]) + ', z : ' + str(cloud[i][2]))

    #print('Cloud after filtering: ')
    #for i in range(0, cloud_filtered.size):
        #print('x: ' + str(cloud_filtered[i][0]) + ', y : ' + str(
            #cloud_filtered[i][1]) + ', z : ' + str(cloud_filtered[i][2]))


if __name__ == ""__main__"":
    # import cProfile
    # cProfile.run('main()', sort='time')

    #for i in range(50):
    print(psutil.Process(os.getpid()).memory_info().rss)
    main()
    time.sleep(1)

C++ code
#include <iostream>
#include <pcl/point_types.h>
#include <pcl/filters/conditional_removal.h>
#include <unistd.h>

//using namespace std;

int parseLine(char* line){
    // This assumes that a digit will be found and the line ends in "" Kb"".
    int i = strlen(line);
    const char* p = line;
    while (*p <'0' || *p > '9') p++;
    line[i-3] = '\0';
    i = atoi(p);
    return i;
}

int getValue(){ //Note: this value is in KB!
    FILE* file = fopen(""/proc/self/status"", ""r"");
    int result = -1;
    char line[128];

    while (fgets(line, 128, file) != NULL){
        if (strncmp(line, ""VmRSS:"", 6) == 0){
            result = parseLine(line);
            break;
        }
    }
    fclose(file);
    return result;
}
int main()
{

 std::cerr << getValue() << std::endl;
 for (int i=0;i <  1; i++)
 {

  std::cerr << getValue() << std::endl;

  pcl::PointCloud<pcl::PointXYZ>::Ptr cloud (new pcl::PointCloud<pcl::PointXYZ>);
  pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_filtered (new pcl::PointCloud<pcl::PointXYZ>);

  // Fill in the cloud data
  cloud->width  = 5;
  cloud->height = 1;
  cloud->points.resize (cloud->width * cloud->height);

  for (size_t i = 0; i < cloud->points.size (); ++i)
  {
    cloud->points[i].x = 1024 * rand () / (RAND_MAX + 1.0f);
    cloud->points[i].y = 1024 * rand () / (RAND_MAX + 1.0f);
    cloud->points[i].z = 1024 * rand () / (RAND_MAX + 1.0f);
  }
   // build the condition
   pcl::ConditionAnd<pcl::PointXYZ>::Ptr range_cond (new
     pcl::ConditionAnd<pcl::PointXYZ> ());
   range_cond->addComparison (pcl::FieldComparison<pcl::PointXYZ>::ConstPtr (new
     pcl::FieldComparison<pcl::PointXYZ> (""z"", pcl::ComparisonOps::GT, 0.0)));
   range_cond->addComparison (pcl::FieldComparison<pcl::PointXYZ>::ConstPtr (new
     pcl::FieldComparison<pcl::PointXYZ> (""z"", pcl::ComparisonOps::LT, 0.8)));

    // build the filter

   pcl::ConditionalRemoval<pcl::PointXYZ> condrem;
   condrem.setCondition (range_cond);
   condrem.setInputCloud (cloud);
   condrem.setKeepOrganized(true);

    // apply filter
    condrem.filter (*cloud_filtered);


  std::cerr << ""Cloud before filtering: "" << std::endl;
  for (size_t i = 0; i < cloud->points.size (); ++i)
    std::cerr << ""    "" << cloud->points[i].x << "" ""
                        << cloud->points[i].y << "" ""
                        << cloud->points[i].z << std::endl;

  // display pointcloud after filtering

  std::cerr << ""Cloud after filtering: "" << std::endl;
  for (size_t i = 0; i < cloud_filtered->points.size (); ++i)
    std::cerr << ""    "" << cloud_filtered->points[i].x << "" ""
                        << cloud_filtered->points[i].y << "" ""
                        << cloud_filtered->points[i].z << std::endl; 
   usleep(1000000);
  }
  std::cerr << getValue() << std::endl;
  return 0;
}

Run Python code using python 3 or  higher version. Then run ""top "" command. The RAM memory keeps increasing.

However, when you run C++ version of the code the memory consumed is constant, and no significant fluctuations in memory are observed.

The problem of memory leak is observed in python code. That is when we are trying to build and apply the filter 
# build the filter
    condrem = cloud.make_ConditionalRemoval(range_cond)
    condrem.set_KeepOrganized(False)
    # apply filter
    cloud_filtered = condrem.filter()

In the above python snippet the function cloud.make is accessing C++/C api's to perfrom point cloud clipping and unbale to handle the memory.

## Possible Solution
Is this issue resolved in 1.9.1 PCL


Request to kindly suggest next steps.",Which bindings are you using? I don't know of any official bindings provided by [PCL group on github](https://github.com/PointCloudLibrary),"std::cerr << ""Cloud before filtering: "" << std::endl;
  for (size_t i = 0; i < cloud->points.size (); ++i)
    std::cerr << ""    "" << cloud->points[i].x << "" ""
                        << cloud->points[i].y << "" ""
                        << cloud->points[i].z << std::endl;

_filtered_filtered_filtered_filtered"
rdkit/rdkit,https://github.com/rdkit/rdkit/issues/3057,rdkit_rdkit_issues_3057,"rdkit on win10, anaconda, DLL load failed

Hi, 
I installed rdkit to its own environment on Anaconda according to the instructions here.
https://www.rdkit.org/docs/Install.html
However, importing the module gives the error in the title.  
- RDKit Version:  2019.09.3.0 
- Operating system: Windows 10
- Python version (if relevant): 3.7.6
- Are you using conda? Yes
- If you are using conda, which channel did you install the rdkit from?
Default channel(?), installed with commands:
$ conda create -c rdkit -n rdkit2 rdkit

Using Jupyter notebook, with the correct kernel. Calling 
import rdkit
gives error:
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-3-6b72bd8913ab> in <module>
----> 1 import rdkit

~\.conda\envs\rdkit2\lib\site-packages\rdkit\__init__.py in <module>
      1 try:
----> 2   from .rdBase import rdkitVersion as __version__
      3 except ImportError:
      4   __version__ = 'Unknown'
      5   raise

ImportError: DLL load failed: The specified module could not be found.

Below is the full list of packages in the relevant conda environment:

# packages in environment at C:\Users\____\.conda\envs\rdkit2:
#
# Name                    Version                   Build  Channel
backcall                  0.1.0                    py37_0    anaconda
blas                      1.0                         mkl
ca-certificates           2020.1.1                      0    anaconda
cairo                     1.14.12              hf171d8a_3
certifi                   2019.11.28               py37_0    anaconda
colorama                  0.4.3                      py_0    anaconda
decorator                 4.4.2                      py_0    anaconda
freetype                  2.9.1                ha9979f8_1
icc_rt                    2019.0.0             h0cc432a_1
icu                       58.2                 ha66f8fd_1
intel-openmp              2020.0                      166
ipykernel                 5.1.4            py37h39e3cac_0    anaconda
ipython                   7.13.0           py37h5ca1d4c_0    anaconda
ipython_genutils          0.2.0                    py37_0    anaconda
jedi                      0.16.0                   py37_0    anaconda
jpeg                      9b                   hb83a4c4_2
jupyter_client            5.3.4                    py37_0    anaconda
jupyter_core              4.6.1                    py37_0    anaconda
libboost                  1.67.0               hd9e427e_4
libpng                    1.6.37               h2a8f88b_0
libsodium                 1.0.16               h9d3ae62_0    anaconda
libtiff                   4.1.0                h56a325e_0
mkl                       2020.0                      166
mkl-service               2.3.0            py37hb782905_0
mkl_fft                   1.0.15           py37h14836fe_0
mkl_random                1.1.0            py37h675688f_0
numpy                     1.18.1           py37h93ca92e_0
numpy-base                1.18.1           py37hc3f5095_1
olefile                   0.46                     py37_0
openssl                   1.1.1                he774522_0    anaconda
pandas                    1.0.1            py37h47e9c7a_0
parso                     0.6.1                      py_0    anaconda
pickleshare               0.7.5                    py37_0    anaconda
pillow                    7.0.0            py37hcc1f983_0
pip                       20.0.2                   py37_1
pixman                    0.38.0               he774522_0
prompt_toolkit            3.0.3                      py_0    anaconda
py-boost                  1.67.0           py37h8300f20_4
pygments                  2.5.2                      py_0    anaconda
python                    3.7.6                h60c2a47_2
python-dateutil           2.8.1                      py_0
pytz                      2019.3                     py_0
pywin32                   227              py37he774522_1    anaconda
pyzmq                     18.1.1           py37ha925a31_0    anaconda
rdkit                     2019.09.3.0      py37h3d1ada6_1    rdkit
setuptools                46.0.0                   py37_0
six                       1.14.0                   py37_0
sqlite                    3.31.1               he774522_0
tk                        8.6.8                hfa6e2cd_0
tornado                   6.0.4            py37he774522_1    anaconda
traitlets                 4.3.3                    py37_0    anaconda
vc                        14.1                 h0510ff6_4
vs2015_runtime            14.16.27012          hf0eaf9b_1
wcwidth                   0.1.8                      py_0    anaconda
wheel                     0.34.2                   py37_0
wincertstore              0.2                      py37_0
xz                        5.2.4                h2fa13f4_4
zeromq                    4.3.1                h33f27b4_3    anaconda
zlib                      1.2.11               h62dcd97_3
zstd                      1.3.7                h508b16e_0",Could it be that you forgot to install jupyter in your new `my-rdkit-env` environment?,"packages in environment at C:\Users\____\.conda\envs\rdkit2:
#
#"
badges/shields,https://github.com/badges/shields/issues/1899,badges_shields_issues_1899,"Frontend redesign

As mentioned in #1070, this will cover a complete redesign of the frontend.
The current frontend is rather useful than good looking. The goal is to make it both easy to use and giving it a modern look on both desktop and mobile devices.

**TODOs:**

- Designs
  - [ ] style form elements (*input*, *select*, *button*)
  - [ ] create visual designs for mobile and desktop viewports
- Adopt styled-components
  - [ ] Container
  - [ ] form elements
- UX errors
  - [ ] categories links aren't displayed on example pages
  - [ ] emphasize search box
  - [ ] ""donate"" link is nearly invisible
  - [ ] consistent naming of the left side of the badge (*label* -> *subject*)

I also thought about adding an about section to the index page with some information about the project.","What would be best, do you think?

cc @rozaxe","led-components
  - [ ]"
vim-airline/vim-airline,https://github.com/vim-airline/vim-airline/issues/1825,vim-airline_vim-airline_issues_1825,"Empty accented section can cause garbled status line with powerline fonts

#### environment

- vim: 8.1.0519
- vim-airline: git gada0ba8
- powerline-fonts 2.7
- OS: Arch Linux
- Have you reproduced with a minimal vimrc: yes
- What is your airline configuration: see below
if you are using terminal:
- terminal: tmux through terminator (but also happens tmux through konsole)
* EDIT: A variation of this happens in a tty without tmux, see comments
* EDIT: A variation of this happens in a gui terminal without tmux, see comments
- $TERM variable: tmux-256color
- color configuration (:set t_Co?): t_Co=256

**minimal ~/.vimrc**
* even commented out Arch's `/etc/vimrc`: `runtime! archlinux.vim`)
* no custom theme
* no other vim plugins - upstream vanilla vim, airline, and with the minimal `.vimrc` I even uninstalled vim-signify

```
set nocompatible
let g:airline_powerline_fonts=1

function! GetFoo()
   return ''
endfunction
call airline#parts#define_function('foo', 'GetFoo')
call airline#parts#define_accent('foo', 'red')
let g:airline_section_b=airline#section#create(['foo'])
```

#### actual behavior

So, this one's fun.  Section that is empty and should collapse down has an additional ""greater-than style triangular powerline character for a section border"".  First character or two in filename being displayed in the next section `airline_section_c` shows as a degree symbol `°` in the background color of `airline_section_b`.  It also shifts everything to the right by a character, so the final red triangle (<s>still not sure what that's for</s> for the empty last section) isn't on the screen anymore.

NOTE: Although in the third part of the screenshot below I show the working colored hunks, in the minimal reproduction, none of that is even defined.

#### expected behavior

For `airline_section_b` to display as empty, not have a random powerline character, not to have invalid degree characters in the wrong background in `airline_section_c` in place of filename characters.

#### additional

If I resize my terminal horizontally, the degree symbol in the wrong background color goes away and the entire status line is displayed properly.  If I go into insert mode, it displays wrong again.  (But, when I exit insert mode, it displays correctly again for 3 seconds then switches back to displaying wrongly.  If it's displaying correctly, and I hit `CTRL+L` to re-draw vim, it displays wrong again.

If I remove `let g:airline_powerline_fonts=1`, it displays properly, just without the powerline fonts.

If I have `GetFoo()` return even a single character, it displays properly.

If I don't define an accent on the empty part, it displays properly.

<s>If I don't run through tmux, it displays properly.</s> (EDIT: See comment.)

If I define another empty accented part and use `section#create(['foo', 'bar'])`, it still displays wrong.  But, if `bar` returns even a single character, it displays properly.

So, I guess this happens when there's an empty section that should auto-hide/collapse down, has accented empty parts, and the powerline fonts are being used<s>, and it's running through tmux</s>.

I want to have the beginning of `airline_section_b` display diff hunks using `signify`.  I have it working so the 3 hunks displays are separate parts, so are separately colorable.  If `non_zero_only` is set and it's not a git tracked file, so thee's no branch either, the entire section is empty except for accents around nothing.

#### best thought

If an empty section but with unused accents inside can be made to internally be seen the same as an empty section, I'm thinking this would stop.

#### screenshots

![Screenshots](https://i.imgur.com/OfzsZsp.png)

#### related

Maybe, maybe not: #696 - There, it put extra characters on the following line rather than hiding them off to the right.  He was using powerline fonts, was using accents, and was getting an extra powerline triangle.  Note using `<%` at the beginning of `airline_section_b` has no effect.  (Not sure what that does, don't see it in docs.)","Can you check, if it happens in a gui? What about tmux in xterm? How about a different powerline font?","* EDIT: A variation of this happens in a tty without tmux, see comments
* EDIT: A variation of this happens in a gui terminal without tmux, see comments
<s></s> for the empty last sectiones<s></s> (EDIT: See comment.)and <s></s>"
badges/shields,https://github.com/badges/shields/issues/1899,badges_shields_issues_1899,"Frontend redesign

As mentioned in #1070, this will cover a complete redesign of the frontend.
The current frontend is rather useful than good looking. The goal is to make it both easy to use and giving it a modern look on both desktop and mobile devices.

**TODOs:**

- Designs
  - [ ] style form elements (*input*, *select*, *button*)
  - [ ] create visual designs for mobile and desktop viewports
- Adopt styled-components
  - [ ] Container
  - [ ] form elements
- UX errors
  - [ ] categories links aren't displayed on example pages
  - [ ] emphasize search box
  - [ ] ""donate"" link is nearly invisible
  - [ ] consistent naming of the left side of the badge (*label* -> *subject*)

I also thought about adding an about section to the index page with some information about the project.","What would be best, do you think?

cc @rozaxe","led-components
  - [ ]"
vim-airline/vim-airline,https://github.com/vim-airline/vim-airline/issues/1825,vim-airline_vim-airline_issues_1825,"Empty accented section can cause garbled status line with powerline fonts

#### environment

- vim: 8.1.0519
- vim-airline: git gada0ba8
- powerline-fonts 2.7
- OS: Arch Linux
- Have you reproduced with a minimal vimrc: yes
- What is your airline configuration: see below
if you are using terminal:
- terminal: tmux through terminator (but also happens tmux through konsole)
* EDIT: A variation of this happens in a tty without tmux, see comments
* EDIT: A variation of this happens in a gui terminal without tmux, see comments
- $TERM variable: tmux-256color
- color configuration (:set t_Co?): t_Co=256

**minimal ~/.vimrc**
* even commented out Arch's `/etc/vimrc`: `runtime! archlinux.vim`)
* no custom theme
* no other vim plugins - upstream vanilla vim, airline, and with the minimal `.vimrc` I even uninstalled vim-signify

```
set nocompatible
let g:airline_powerline_fonts=1

function! GetFoo()
   return ''
endfunction
call airline#parts#define_function('foo', 'GetFoo')
call airline#parts#define_accent('foo', 'red')
let g:airline_section_b=airline#section#create(['foo'])
```

#### actual behavior

So, this one's fun.  Section that is empty and should collapse down has an additional ""greater-than style triangular powerline character for a section border"".  First character or two in filename being displayed in the next section `airline_section_c` shows as a degree symbol `°` in the background color of `airline_section_b`.  It also shifts everything to the right by a character, so the final red triangle (<s>still not sure what that's for</s> for the empty last section) isn't on the screen anymore.

NOTE: Although in the third part of the screenshot below I show the working colored hunks, in the minimal reproduction, none of that is even defined.

#### expected behavior

For `airline_section_b` to display as empty, not have a random powerline character, not to have invalid degree characters in the wrong background in `airline_section_c` in place of filename characters.

#### additional

If I resize my terminal horizontally, the degree symbol in the wrong background color goes away and the entire status line is displayed properly.  If I go into insert mode, it displays wrong again.  (But, when I exit insert mode, it displays correctly again for 3 seconds then switches back to displaying wrongly.  If it's displaying correctly, and I hit `CTRL+L` to re-draw vim, it displays wrong again.

If I remove `let g:airline_powerline_fonts=1`, it displays properly, just without the powerline fonts.

If I have `GetFoo()` return even a single character, it displays properly.

If I don't define an accent on the empty part, it displays properly.

<s>If I don't run through tmux, it displays properly.</s> (EDIT: See comment.)

If I define another empty accented part and use `section#create(['foo', 'bar'])`, it still displays wrong.  But, if `bar` returns even a single character, it displays properly.

So, I guess this happens when there's an empty section that should auto-hide/collapse down, has accented empty parts, and the powerline fonts are being used<s>, and it's running through tmux</s>.

I want to have the beginning of `airline_section_b` display diff hunks using `signify`.  I have it working so the 3 hunks displays are separate parts, so are separately colorable.  If `non_zero_only` is set and it's not a git tracked file, so thee's no branch either, the entire section is empty except for accents around nothing.

#### best thought

If an empty section but with unused accents inside can be made to internally be seen the same as an empty section, I'm thinking this would stop.

#### screenshots

![Screenshots](https://i.imgur.com/OfzsZsp.png)

#### related

Maybe, maybe not: #696 - There, it put extra characters on the following line rather than hiding them off to the right.  He was using powerline fonts, was using accents, and was getting an extra powerline triangle.  Note using `<%` at the beginning of `airline_section_b` has no effect.  (Not sure what that does, don't see it in docs.)","Can you check, if it happens in a gui? What about tmux in xterm? How about a different powerline font?","* EDIT: A variation of this happens in a tty without tmux, see comments
* EDIT: A variation of this happens in a gui terminal without tmux, see comments
<s></s> for the empty last sectiones<s></s> (EDIT: See comment.)and <s></s>"
vim-airline/vim-airline,https://github.com/vim-airline/vim-airline/issues/1991,vim-airline_vim-airline_issues_1991,"bufferline disappers on save, corrupted status line

#### environment

- vim: nvim

NVIM v0.3.8
Build type: Release
LuaJIT 2.1.0-beta3
Compilation: /usr/bin/cc -g -O2 -fdebug-prefix-map=/build/neovim-Bljd1N/neovim-0.3.8=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=1 -DDISABLE_LOG -Wdate-time -D_FORTIFY_SOURCE=1 -Wconversion -O2 -DNDEBUG -DMIN_LOG_LEVEL=3 -Wall -Wextra -pedantic -Wno-unused-parameter -Wstrict-prototypes -std=gnu99 -Wimplicit-fallthrough -Wvla -fstack-protector-strong -fdiagnostics-color=auto -Wno-array-bounds -DINCLUDE_GENERATED_DECLARATIONS -D_GNU_SOURCE -DNVIM_MSGPACK_HAS_FLOAT32 -DNVIM_UNIBI_HAS_VAR_FROM -I/build/neovim-Bljd1N/neovim-0.3.8/build/config -I/build/neovim-Bljd1N/neovim-0.3.8/src -I/usr/include -I/build/neovim-Bljd1N/neovim-0.3.8/build/src/nvim/auto -I/build/neovim-Bljd1N/neovim-0.3.8/build/include
Compiled by team+vim@tracker.debian.org

Features: +acl +iconv -jemalloc +tui 
See "":help feature-compile""

   system vimrc file: ""$VIM/sysinit.vim""
  fall-back for $VIM: ""/usr/share/nvim""

Run :checkhealth for more info

- vim-airline: most recently dowloaded via dein

- OS: ubuntu 19.10

- Have you reproduced with a minimal vimrc: no

- What is your airline configuration:

if !exists('g:airline_symbols')
    let g:airline_symbols = {}
endif
let g:airline_theme='minimalist'
let g:airline_powerline_fonts = 1
let g:airline#extensions#tabline#enabled = 1
let g:airline#extensions#tabline#formatter = 'unique_tail_improved'

if you are using terminal:
- terminal: ????
- $TERM variable: rxvt-unicode-256color
- color configuration (:set t_Co?):
if you are using Neovim:
- does it happen in Vim: yes

#### actual behavior

on save, the buffer line disappears and the status line gets corrupted

~I have before and after screenshots but github not allowing me to upload right now~
https://imgur.com/a/NlhvOmE

#### expected behavior

i'd prefer this not to happen

Talk me through troubleshooting this better. I just went through some major revisions to my dotvimfiles situation so theres that e.g. AirlineExtensions shows that denite extension isnt loaded but should be. I've tried walking back the setup to something simpler, but it still happens. Tried reloading the entire plugin cache still happens. 


output from opening 3 files, saving 1 causing the behavior to occur
https://ufile.io/y3g5x9rp


only seems to happen when editing vimrc files so I'm not sure whats going on there yet or why
doesn't appear to impact files or view outside of editing the vimrc files",Can you provide some screenshots?,"Talk me through troubleshooting this better. I just went through some major revisions to my dotvimfiles situation so theres that e.g. AirlineExtensions shows that denite extension isnt loaded but should be. I've tried walking back the setup to something simpler, but it still happens. Tried reloading the entire plugin cache still happens."
bookshelf/bookshelf,https://github.com/bookshelf/bookshelf/issues/2025,bookshelf_bookshelf_issues_2025,"I am getting error - TypeError: this.hasMany is not a function

## Introduction

_I am getting error - TypeError: this.hasMany is not a function._
please note that below code works when i do INSERT operation - i have not given that code just to avoid confusion.

## Issue Description

my files and code in them as follows

db/bookshelf.js
------------------------------
var knex = require('knex')({
    client: config.DBserver.CLIENT,
    adapter: config.DBserver.ADAPTER,
    connection: {
        host: config.DBserver.DBHOST,
        user: config.DBserver.DBUSER,
        password: config.DBserver.DBPASSWORD,
        database: config.DBserver.DBNAME,
        port: config.DBserver.DBPORT
    }
  });

const bookshelf = require('bookshelf')(knex)
module.exports = bookshelf

models/jobs.js file
------------------------------------------------
const bookshelf = require('../db/bookshelf')
const Job = bookshelf.model('Job', {
    tableName: 'jobs',
    job_status() {
        return this.hasMany(job_status)
    }
})

const job_status = bookshelf.model('job_status', {
    tableName: 'job_status',
    job(){
        return this.belongsTo('Job')
    }   
})

module.exports.updateJob = function(job){
    try {
        return new Promise((resolve,reject)=>{
            Job
            .where('id', job.id)
            .fetch()
            .then(function(job) {
                job
                .save(job)
                .then((saved)=> {
                    console.log(saved)
                    return resolve(saved)
                }).catch((err)=>{
                    console.log(err)
                    return reject(err)
                });
            }).catch((err)=>{
                console.log(err)
                return reject(err)
            });
        })        
    } catch (error) {
        console.log('Error inside try-catch of model '+error)
        throw error
    }
}

event-manager/jobs.js
-----------------------------------------
const event = require('./emitter.js');
const model = require('../models/jobs')

event.on(""JobExistingUpdated"", function(data) {
    console.log('handling --UPDATE-- event')
    model.updateJob(data)
    .then(saved=>{
        console.log('JOB UPDATED')
    }).catch(err=>{
        console.log(err)
    })
});

event-manager/emitter.js
-----------------------------------------
const EventEmitter = require('events');
var emitter = new EventEmitter();

module.exports = emitter;

setInterval(function() {
    console.log('emitting UPDATE event')
    const title = new Date().getTime().toString()
    emitter.emit(""JobExistingUpdated"", 
    {id:'e195a520-e930-4d2b-be43-c7e224d1aa04', 
    title: title,job_type:'full',salary:1234,description:'react'});
}, 5 * 1000); 

server.js
-----------
const jobEventEmitter = require('./event-manager/emitter')
const jobEventHandler = require('./event-manager/jobs')

when i run server.js like  node server.js
i can see the error TypeError: this.hasMany is not a function
Please note that i run server.js first which include event-emitter like this -> require('event-emitter') and 
jobs model like this ->  require('./event-manager/jobs') 

event emitter start emitting events which is required by jobs.js model like so ->
const event = require('./emitter.js');

then it subscribe to events emitted by emitter and then inside calls job models updateJob function as follows
event.on(""JobExistingUpdated"", function(data) {
    console.log('handling --UPDATE-- event')
    model.updateJob(data)
    .then(saved=>{
        console.log('JOB UPDATED')
    }).catch(err=>{
        console.log(err)
    })
});

This works for INSERT opration but UPDATE operation fails.","What version of Bookshelf and Knex are you using?
Can you fix/update the code snippets by wrapping them in opening and closing ""```"" so its parsed by GitHub markdown?","please note that below code works when i do INSERT operation - i have not given that code just to avoid confusion.function(data) {
    console.log('handling --UPDATE-- event')
    model.updateJob(data)
    .then(saved=>{
        console.log('JOB UPDATED')
    }).catch(err=>{
        console.log(err)
    })
});

This"
modoboa/modoboa,https://github.com/modoboa/modoboa/issues/1662,modoboa_modoboa_issues_1662,"Search button

# Impacted versions

* Modoboa: 1.13.0
* Safari 10.0.2 or Chrome OSX 71.

If we type something in the search entry field and click on the search icon, the entry field is cleared.

Is this normal behavior?

![capture d ecran 2019-01-25 a 17 37 00](https://user-images.githubusercontent.com/12907102/51759357-526e0200-20c8-11e9-83fa-dffcefa30e26.png)",What is your browser?,* Safari 10.0.2 or Chrome OSX 71.
ramda/ramda,https://github.com/ramda/ramda/issues/2850,ramda_ramda_issues_2850,"Clone does  not do a deep clone

Steps to reproduce: 
1. Go to https://ramdajs.com/repl/?v=0.26.1 and open your developer console. 
2. Copy the below snippet and run it in console

```javascript
(() => {
     //
    let initialObj = [{
        attr1: 'value1',
        attr2: 'value2',
        attr3: 'value3',
        attr4: 'value4',
        attr5: 'value5',
    }];

    // the new constructed object
    let foo = {
        bar: initialObj[0],
        baz: initialObj[0]
    }


    let clonedFoo = R.clone(foo);

    console.log(clonedFoo);
    clonedFoo.bar[0] = 'valueChanged';
    console.log(clonedFoo);

})()
```

The expected behaviour: 

When the attribute(`bar`) of the cloned object(`clonedFoo`) is changed it will change the other attribute(`baz`) as well. While *deep* clone should be a complete new clone of the object...",Why do you think this should be changed?  Do you have a convincing use-case?,"constructed object
    let foo = {
        bar: initial            attribute(`bar`) o"
stefvanbuuren/mice,https://github.com/stefvanbuuren/mice/issues/125,stefvanbuuren_mice_issues_125,"Post-processing: conditional imputation with continuous variables

Dear Stef Van Buuren,

I am trying to use some of your code from your book ""Flexible Imputation of Missing Data"" to my issue of conditional imputation. In your book, it seems you only treat conditional imputation of categorical variables, which permits to create a special category in the post argument to treat the conditional imputation. My question is how should we proceed to treat conditional continuous variables (as is the case with the option conditional of the ice function of STATA)?

In my Data, I have a continuous variable (Vcontinuous) which couln't have any value before a date LimiDate (variable date coded in continuous variable). Vcontinuous is also a predictor variable in imputation. Thus, I would like use Vcontinuous only for date>=LimiDate for imputation. My first idea was to force Vcontinuous to be missing for date < LimiDate by using the following code :

```
init = mice(myData, maxit=0) 
post=init$post
post[""Vcontinuous""] <- ""imp[[j]][init$data$date[!r[,j]]<LimiDate ,i])<-NA""
imp<-mice(myData)
```
But MICE does not authorize introduction of NA in post-processing.

Do you have any suggestions for dealing with this problem?

I thank you in advance for you help.

Sincerely,

Cécile Sommen",Can you define a simple `myData` data frame?,">=LimiDate for imputation. My first idea was to force Vcontinuous to be missing for date  
``````"
maildev/maildev,https://github.com/maildev/maildev/issues/278,maildev_maildev_issues_278,"bug: die after a while

```bash
$(yarn global bin)/maildev --smtp 2525 &
```",doesn't everyone ?,"```bash
$(yarn global bin)/maildev --smtp 2525 &
```"
salomvary/soundcleod,https://github.com/salomvary/soundcleod/issues/178,salomvary_soundcleod_issues_178,"Support gnu/linux distribiutions

- [x] Configure AppImage build
- [ ] Add application icon
- [ ] Fix Controls menu items
- [ ] Enable code signing (?)
- [ ] Enable AppImage build on the pipeline
- [ ] Add Linux related docs and links to the website
- [ ] Release a new version","What's the cross-distro way of shipping standalone Linux apps nowadays?

Anyway, contributions in this direction are welcome!","- [x] Configure AppImage build
- [ ] Add application icon
- [ ] Fix Controls menu items
- [ ] Enable code signing (?)
- [ ] Enable AppImage build on the pipeline
- [ ] Add Linux related docs and links to the website
- [ ] Release a new version"
oakmac/chessboardjs,https://github.com/oakmac/chessboardjs/issues/161,oakmac_chessboardjs_issues_161,"Creation of git tags

If a git tag were to be created, chessboard.js would be supported by cdnjs, which would be great for the library. (See here: https://github.com/cdnjs/cdnjs/issues/12943#issuecomment-431529802 )


Edit: I feel like I should be elaborating on why git tags are nice. For one, by being on cdnjs, (which requires git tags) chessboard.js gets automatically hosted, minified, and cache-configured on Cloudflare's edge network, which is sweet. Besides that, though, it lets you add npm hooks, which might help with deployment for some users.",What tag(s) are needed for this?,"Edit: I feel like I should be elaborating on why git tags are nice. For one, by being on cdnjs, (which requires git tags) chessboard.js gets automatically hosted, minified, and cache-configured on Cloudflare's edge network, which is sweet. Besides that, though, it lets you add npm hooks, which might help with deployment for some users."
JuliaOpt/Gurobi.jl,https://github.com/jump-dev/Gurobi.jl/issues/250,jump-dev_Gurobi.jl_issues_250,"Remove `x ≈ bnd` checks when querying `ConstraintDual` for `SingleVariable` constraints

When querying the dual variable associated to a `MOI.SingleVariable`-in-`S`, the wrapper first check whether the corresponding variable is at its lower/upper bound, e.g.:
```julia
    if x ≈ ub
        return _dual_multiplier(model) * get_dblattrelement(model.inner, ""RC"", column)
    else
        return 0.0
    end
```
(the offending code is for [`LessThan`](https://github.com/JuliaOpt/Gurobi.jl/blob/master/src/MOI_wrapper.jl#L1846) and [`GreaterThan`](https://github.com/JuliaOpt/Gurobi.jl/blob/master/src/MOI_wrapper.jl#L1860))

I would argue it is dangerous to do so, and may lead to returning incorrect values. Specifically:
* ~Even if a variable is at its lower/upper bound, it may still be basic (#degeneracy), and thus may have a non-zero reduced cost.~ [edit: I was wrong, this is indeed not a problem]
* More problematic, if the lower/upper bound is zero, then `x ≈ ub` will evaluate to `false` whenever `x` is not _exactly_ zero. This happens all the time when solving with barrier and no crossover, and more generally because of numerical tolerances.
* For `x-in-Interval`, there is no bound check ([here](https://github.com/JuliaOpt/Gurobi.jl/blob/master/src/MOI_wrapper.jl#L1881))",What would a bound check do in this case?,"~~ [edit: I was wrong, this is indeed not a problem]"
noisymime/speeduino,https://github.com/noisymime/speeduino/issues/187,noisymime_speeduino_issues_187,"Missing INJ pulse with 12-1 cam wheel set at 4 pulses

For a 4 cyl when set to 12-1 missing tooth Cam speed, 4 INJ pulses Alternating, IGN set on Seq, on the Base Tune, one pulse at TDC is missing on ch#1 - #2 is fine -. Set to 8 cyl and all 4 pulses. Tested on 2 Speedys.
Forum - http://speeduino.com/forum/viewtopic.php?f=11&t=2526
MEGA missing pulse
https://www.mediafire.com/convkey/035e/457dq6iyz41uz0s6g.jpg
video
https://youtu.be/LVXC8l_4zdk

FW - Oct18 
V3.6
Potential engine damage on this setting.



<bountysource-plugin>

---
Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/68709938-missing-inj-pulse-with-12-1-cam-wheel-set-at-4-pulses?utm_campaign=plugin&utm_content=tracker%2F706250&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F706250&utm_medium=issues&utm_source=github).
</bountysource-plugin>",Which injector channel were you testing on?,"<bountysource-plugin>

---
Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/68709938-missing-inj-pulse-with-12-1-cam-wheel-set-at-4-pulses?utm_campaign=plugin&utm_content=tracker%2F706250&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F706250&utm_medium=issues&utm_source=github).
</bountysource-plugin>"
kohler/gifsicle,https://github.com/kohler/gifsicle/issues/132,kohler_gifsicle_issues_132,"gifsicle can't run resize or scale command

I have an animated gif like this
![image](https://user-images.githubusercontent.com/40488299/41768143-9fbc447e-7635-11e8-9733-96591e318eb2.gif)
I want to resize it using the command
`gifsicle --resize _x50 image.gif > image_resized.gif`
But a window popped out and said ""gifsicle.exe has stopped working""
Other commands worked fine except this one (and scale). What did i do wrong?

**UPDATE**: Now I can resize with --resize-method sample. I wonder why other resize methods don't work?","Can you verify the version (run `gifsicle --version`)? Did you compile it from git sources?

I was unable to reproduce using version 2b1a0d7bc7b07ce162105c5a3a00371f116f0319 on Linux.",**UPDATE**: Now I can resize with --resize-method sample. I wonder why other resize methods don't work?
browscap/browscap-php,https://github.com/browscap/browscap-php/issues/247,browscap_browscap-php_issues_247,"Misleading browser info due to incomplete programmatical update for PHP_INI_FULL

No matter how many times I try purging and repopulating the cache, I always end up getting the following (one or more) message(s) in my app log: `cache key ""browscap.iniparts.a8d"" not found` (where the last triplet varies depending on which piece is missing). This is observed only with invoking BrowscapUpdater from my app, the CLI script seems to work well.

This results in a generic browser info, `...""browser"":""Default Browser"",""browser_type"":""unknown""...` instead of `...,""browser"":""Chrome"",""browser_type"":""Browser"",...`

My code on PHP 7.2.5 + browscap-php 4.1 + apache2 + Ubuntu:

    ini_set('memory_limit','1024M');
    ini_set('max_execution_time', 3000);
    $bc = new \BrowscapPHP\BrowscapUpdater($this->browscap_cache, $this->logger );
    $bc->update(\BrowscapPHP\Helper\IniLoaderInterface::PHP_INI_FULL);

I tried with both filecache and memcache - same outcome. Also tried debugging the code, no error and no Exceptions are thrown.

Any suggestions towards troubleshooting or resolving this issue would be greatly appreciated",Did you get any errormessages in your log during the update?,". This is observed only with invoking BrowscapUpdater from my app, CLI script seems to work well."
Shazwazza/Examine,https://github.com/Shazwazza/Examine/issues/64,Shazwazza_Examine_issues_64,"OrderBy string is case sensitive - Needs unit tests

We need unit tests written and working for both case sensitve and insensitive searching.

## Original description: 

Is there a way to order by a string case insensitively?",What are you using?,"We need unit tests written and working for both case sensitve and insensitive searching.

## Original description:"
egulias/EmailValidator,https://github.com/egulias/EmailValidator/issues/236,egulias_EmailValidator_issues_236,"Strict Length Validation for Local is valid when split by numbers

Using the laravel form validation set to strict mode we are coming accross an issue with length checking.

It seems like numbers chars are acting as a divider causing the the second half to validate successfully as it's then under the char limit.

**Case 1**
aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa@example.com
Expected: Invalid
Result: Invalid

**Case 2**
a5aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa@example.com
Expected: Invalid
Result: Valid

**Case 3**
aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa@example.com
Expected: Valid
Result: Valid",Would you mind submitting a failing unit test with the second case please?,"a
**Case 3**
aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa@example.com
Expected: Valid
Result: Valid"
Pkcs11Interop/Pkcs11Interop,https://github.com/Pkcs11Interop/Pkcs11Interop/issues/96,Pkcs11Interop_Pkcs11Interop_issues_96,"Xamarin.Android Error

Net.Standard 2.0
Android Project
Device: Xiaomi Mi5s Android 7
Using librtpkcs11ecp.so 

I'm trying to create object Pkcs11 and when invoking 

```
NativeULong rv = _delegates.C_Initialize(initArgs);
```

I get error:

```
12-20 16:24:14.978 E/mono-rt ( 3070):   at <unknown> <0xffffffff>
12-20 16:24:14.978 E/mono-rt ( 3070):   at (wrapper managed-to-native) object.wrapper_native_0x32a50000 (Net.Pkcs11Interop.LowLevelAPI41.CK_C_INITIALIZE_ARGS) <0x00037>
12-20 16:24:14.978 E/mono-rt ( 3070):   at Net.Pkcs11Interop.LowLevelAPI41.Pkcs11.C_Initialize (Net.Pkcs11Interop.LowLevelAPI41.CK_C_INITIALIZE_ARGS) [0x0001c] in C:\git\Pkcs11Interop\src\Pkcs11Interop\Pkcs11Interop\LowLevelAPI41\Pkcs11.cs:116
12-20 16:24:14.978 E/mono-rt ( 3070):   at Net.Pkcs11Interop.HighLevelAPI41.Pkcs11.Initialize (Net.Pkcs11Interop.Common.AppType) [0x00039] in C:\git\Pkcs11Interop\src\Pkcs11Interop\Pkcs11Interop\HighLevelAPI41\Pkcs11.cs:177
12-20 16:24:14.978 E/mono-rt ( 3070):   at Net.Pkcs11Interop.HighLevelAPI41.Pkcs11..ctor (Net.Pkcs11Interop.HighLevelAPI.Pkcs11Factories,string,Net.Pkcs11Interop.Common.AppType) [0x0005a] in C:\git\Pkcs11Interop\src\Pkcs11Interop\Pkcs11Interop\HighLevelAPI41\Pkcs11.cs:116
12-20 16:24:14.978 E/mono-rt ( 3070):   at FirstModule.ViewModel.FirstPageViewModel.Test () [0x00071] in C:\...\XamarinFormsLab\FirstModule\ViewModel\FirstPageViewModel.cs:55
12-20 16:24:14.978 E/mono-rt ( 3070):   at (wrapper runtime-invoke) object.runtime_invoke_void__this__ (object,intptr,intptr,intptr) [0x0004f] in <fe08c003e91342eb83df1ca48302ddbb>:0
12-20 16:24:14.978 E/mono-rt ( 3070):   at <unknown> <0xffffffff>
12-20 16:24:14.979 E/mono-rt ( 3070):   at (wrapper managed-to-native) System.Reflection.MonoMethod.InternalInvoke (System.Reflection.MonoMethod,object,object[],System.Exception&) <0x00043>
12-20 16:24:14.979 E/mono-rt ( 3070):   at System.Reflection.MonoMethod.Invoke (object,System.Reflection.BindingFlags,System.Reflection.Binder,object[],System.Globalization.CultureInfo) [0x00041] in <fe08c003e91342eb83df1ca48302ddbb>:0
12-20 16:24:14.979 E/mono-rt ( 3070):   at System.Reflection.MethodBase.Invoke (object,object[]) [0x00006] in <fe08c003e91342eb83df1ca48302ddbb>:0
12-20 16:24:14.979 E/mono-rt ( 3070):   at GalaSoft.MvvmLight.Helpers.WeakAction.Execute () [0x0003e] in C:\Users\lbugn\Documents\MVVMLight\GalaSoft.MvvmLight\GalaSoft.MvvmLight (PCL)\Helpers\WeakAction.cs:343
12-20 16:24:14.979 E/mono-rt ( 3070):   at GalaSoft.MvvmLight.Command.RelayCommand.Execute (object) [0x0002b] in C:\Users\lbugn\Documents\MVVMLight\GalaSoft.MvvmLight\GalaSoft.MvvmLight (PCL)\Command\RelayCommand.cs:228
12-20 16:24:14.979 E/mono-rt ( 3070):   at Xamarin.Forms.Button.SendClicked () [0x00008] in D:\a\1\s\Xamarin.Forms.Core\Button.cs:150
12-20 16:24:14.979 E/mono-rt ( 3070):   at Xamarin.Forms.Platform.Android.AppCompat.ButtonRenderer/ButtonClickListener.OnClick (Android.Views.View) [0x0000b] in D:\a\1\s\Xamarin.Forms.Platform.Android\AppCompat\ButtonRenderer.cs:329
12-20 16:24:14.979 E/mono-rt ( 3070):   at Android.Views.View/IOnClickListenerInvoker.n_OnClick_Landroid_view_View_ (intptr,intptr,intptr) [0x00013] in <ad2f15102b3a4d36b40e9b0cbc11c376>:0
12-20 16:24:14.980 E/mono-rt ( 3070):   at (wrapper dynamic-method) object.26 (intptr,intptr,intptr) [0x00017] in <fe08c003e91342eb83df1ca48302ddbb>:0
12-20 16:24:14.980 E/mono-rt ( 3070):   at (wrapper native-to-managed) object.26 (intptr,intptr,intptr) [0x00022] in <fe08c003e91342eb83df1ca48302ddbb>:0
```

Could you help me?",Could you please test our sample Android application [Pkcs11Interop.Android.Tests](https://github.com/Pkcs11Interop/Pkcs11Interop/tree/4.0.0/src/Pkcs11Interop.Android) on your device?,"``

I get error:

```

``"
j256/ormlite-android,https://github.com/j256/ormlite-android/issues/115,j256_ormlite-android_issues_115,"ORMLite Android - Prevent Upgrade inside catch

I'm trying find a way to prevent the database version from updating in the event that something goes wrong inside the ```onUpgrade``` method.

I have the following helper class

```
public class DatabaseHelper extends OrmLiteSqliteOpenHelper
{
   private DatabaseHelper(Context context)
   {
      super(context, DATABASE_NAME, null, DATABASE_VERSION, R.raw.ormlite_config);
   }

   @Override
   public void onUpgrade(SQLiteDatabase db, ConnectionSource connectionSource, int oldVersion, int newVersion)
   {
       try
       {
         MigrationHelper.RunMigrations(mContext,oldVersion,this);
       }
       catch (Exception e)
       {
            //How can I prevent the version from updating if the migration fails?
       }
    }
}

```

Prefferably I want to be able to show a message dialog to the user so just throwing an unhandled exception (that would cause the application to crash) isn't really ideal.

Thanks in advance

### Edit:

I found a way to do what i needed.  I'm not sure if this is the best way to go about it but it accomplishes what I need.

First I created a new interface that looks something like this:
```
public interface MigrationFailedListener
{
    void onMigrationFailed(String message);
}
```

And then I modified my ```DatabaseHelper``` to look something like this:
```
public class DatabaseHelper extends OrmLiteSqliteOpenHelper
{
    public static MigrationFailedListener migrationFailedListener;
    
     @Override
       public void onUpgrade(SQLiteDatabase db, ConnectionSource connectionSource, int oldVersion, int newVersion)
    {
        Log.e(""onUpgrade"", ""oldVersion: "" + oldVersion + "" newVersion: "" + newVersion);
        try
        {
            MigrationHelper.RunMigrations(mContext.get(),oldVersion,this);
        }
        catch (Exception e)
        {
            //Notify the listener that the migration has failed
            if(migrationFailedListener != null)
            {
                migrationFailedListener.onMigrationFailed(e.getMessage());
            }
            //Throwing a RuntimeException appears to be caught by the OrmLiteSqliteOpenHelper and 
            //prevents version increasing (So next to the app is run it will try to upgrade again)
            throw new RuntimeException(e.getMessage());
        }
    }

}
```

Then I simply set the the ```migrationFailedListener``` before any database calls are made like so:
```
//Set the Migration failed callback
DatabaseHelper.migrationFailedListener = message ->
{
   DatabaseHelper.clearInstance();
   okDialog = new OkDialog(LoginActivity.this, ""Database Migration Failed"", ""There was an issue while migrating database. Application will now close"", view ->
    {
      okDialog.cancel();
      finishAndRemoveTask();
     });
    okDialog.show();
};
```",Can you add some comments to help others @Murded ?,"Edit:

I found a way to do what i needed.  I'm not sure if this is the best way to go about it but it accomplishes what I need.

First I created a new interface that looks something like this:
```
public interface MigrationFailedListener
{
    void onMigrationFailed(String message);
}
```

And then I modified my ```DatabaseHelper``` to look something like this:
```
public class DatabaseHelper extends OrmLiteSqliteOpenHelper
{
    public static MigrationFailedListener migrationFailedListener;
    
     @Override
       public void onUpgrade(SQLiteDatabase db, ConnectionSource connectionSource, int oldVersion, int newVersion)
    {
        Log.e(""onUpgrade"", ""oldVersion: "" + oldVersion + "" newVersion: "" + newVersion);
        try
        {
            MigrationHelper.RunMigrations(mContext.get(),oldVersion,this);
        }
        catch (Exception e)
        {
            //Notify the listener that the migration has failed
            if(migrationFailedListener != null)
            {
                migrationFailedListener.onMigrationFailed(e.getMessage());
            }
            //Throwing a RuntimeException appears to be caught by the OrmLiteSqliteOpenHelper and 
            //prevents version increasing (So next to the app is run it will try to upgrade again)
            throw new RuntimeException(e.getMessage());
        }
    }

}
```

Then I simply set the the ```migrationFailedListener``` before any database calls are made like so:
```
//Set the Migration failed callback
DatabaseHelper.migrationFailedListener = message ->
{
   DatabaseHelper.clearInstance();
   okDialog = new OkDialog(LoginActivity.this, ""Database Migration Failed"", ""There was an issue while migrating database. Application will now close"", view ->
    {
      okDialog.cancel();
      finishAndRemoveTask();
     });
    okDialog.show();
};
```"
talgalili/installr,https://github.com/talgalili/installr/issues/133,talgalili_installr_issues_133,"GraphicsMagick – unable to install

Error installing ""GraphicsMagick"" through GUI:
```r
installr::installr()
```

![image](https://user-images.githubusercontent.com/12725868/62849276-aa2c2d80-bce7-11e9-86ba-bb5db22059fc.png)


**UPDATE** Correct print-screen uploaded.


After pressing ""OK"" :
```r
Explanation of the error: You didn't enter a valid .EXE URL. 
This is likely to have happened because there was a change in the URL of the installer file in the download page of the software (making our function unable to know what to download). 

This might have already been fixed in the latest version of installr. Install the latest version of installr using devtools::install_github('talgalili/installr') and try again.

If this doesn't help please e-mail: tal.galili@gmail.com and let me know this function needs updating/fixing (please include the output of sessionInfo() ) - thanks!
```


```
R version 3.6.1 (2019-07-05)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

other attached packages:
[1] installr_0.22.0
```","Can you please run:
install.ImageMagick()
And see if that works or not?","86-aa2c2d0-bce86ba-bb5db2205


**UPDATE** Correct print-screen uploaded."
alallier/reload,https://github.com/alallier/reload/issues/221,alallier_reload_issues_221,"reload works on mac but not on windows

Goal: server-side email templates re-render in browser on code changes.

The idea is that node.js developers can create email templates on the serverside in development (not for production) and on email template code changes the browser refreshes.

So the app is using contentful. It grabs the requested email template and contentful post id through the url query and finds the email template declared and queries the post data from contentful. It's pretty neat and works on mac without issue. 

This flow allows for iterative email design templating with real data and browser refreshes on code changes. Example usage without contentful:  https://github.com/devpies/mjml-react-reload/blob/master/src/server/express.js 

The repo above has a README.md file that explains how to start the app. Please try to replicate on windows. Make some change to the email template and then watch the browser reload but the browser doesn't receive the updates.

The code below is showing a subset of our real app that uses contentful. I believe the repo above has the same issue with auto-refreshing the browser on code changes.

So for example, in local development, and in our real app, a developer could go in the browser and request: http://localhost:9000/pulsotecnico&59RbVejPRdZbh23B39peWC
which would render the email template in the browser with the post data from contentful.

```
import ""./setup/env"";
import cors from ""cors"";
import http from ""http"";
import watch from ""watch"";
import reload from ""reload"";
import express, { Request, Response } from ""express"";
import bodyParser from ""body-parser"";
import { sendEmail } from ""./core/email/services"";
import logger from ""./core/middleware/logger"";
import getTemplate from ""./core/middleware/getTemplate"";
import getContentfulEntry from ""./core/middleware/getContentfulEntry"";
import { IAppRequest, IContentfulEntry } from ""./core/types"";
import { triggerBuild } from ""./helpers"";
import { TEN_MINUTES_IN_MILLISECONDS } from ""./constants"";

const app = express();
const env = process.env.NODE_ENV;

const corsOptions = {
  origin: [""http://localhost:8000"", ""https://api.contentful.com""],
  exposedHeaders: [],
  optionsSuccessStatus: 200
};

app.use(logger);
app.use(cors(corsOptions));
app.set(""port"", process.env.PORT || 9000);
app.options(""*"", cors(corsOptions));
app.use(
  bodyParser.json({ type: ""application/vnd.contentful.management.v1+json"" })
);

app.get(
  ""/:template&:entryId"",
  getContentfulEntry,
  getTemplate,
  (req: IAppRequest, res: Response) => {
    return res.send(req.html);
  }
);

app.post(""/entry-web-hook"", async (req: Request, res: Response) => {
  if (env !== ""production"") return;

  const payload: IContentfulEntry = req.body;
  const frontend = process.env.FRONTEND_BUILD_URL || """";

  await triggerBuild(frontend);

  const isFirstVersion = ({ sys }: IContentfulEntry) => sys.revision === 1;

  if (!isFirstVersion(payload)) {
    res.status(202).send();
    return;
  }

  try {
    const emailList = [
      ""ivor@devpie.io"",
      ""dan@quadricular.ai"",
    ];
    await sendEmail(emailList, payload);
    res.status(200).send();
  } catch (error) {
    res.status(404).send({ error });
  }
});

// start app

const port = app.get(""port"");

if (env === ""production"") {
  const server = app.listen(port, () => console.log(`listen on port: ${port}`));
  server.setTimeout(TEN_MINUTES_IN_MILLISECONDS);
} else {
  // development
  const startServer = async function() {
    const server = http.createServer(app);
    try {
      const reloadReturned = await reload(app); // enable serverside browser refresh, (useful when designing email templates)

      watch.watchTree(__dirname + ""/core/email"", function() {
        reloadReturned.reload();
      });
      server.listen(port, () => console.log(`\n listening on port ${port}\n`));
    } catch (error) {
      console.error(""Reload could not start server."", error);
    }
  };
  startServer();
}

```",Can you provide reproduction steps?,"server-side email templates re-render in browser on code changes.

The idea is that node.js developers can create email templates on the serverside in development (not for production) and on email template code changes the browser refreshes.

So the app is using contentful. It grabs the requested email template and contentful post id through the url query and finds the email template declared and queries the post data from contentful. It's pretty neat and works on mac without issue. 

This flow allows for iterative email design templating with real data and browser refreshes on code changes. Example usage without contentful:  https://github.com/devpies/mjml-react-reload/blob/master/src/server/express.js 

The README.md explains how to start the app.

The code below is showing a subset of our real app that uses contentful. I believe the repo above has the same issue with auto-refreshing the browser on code changes.

So for example, in local development, and in our real app, a developer could go in the browser and request: http://localhost:9000/pulsotecnico&59RbVejPRdZbh23B39peWC
which would render the email template in the browser with the post data from contentful.

```
import ""./setup/env"";
import cors from ""cors"";
import http from ""http"";
import watch from ""watch"";
import reload from ""reload"";
import express, { Request, Response } from ""express"";
import bodyParser from ""body-parser"";
import { sendEmail } from ""./core/email/services"";
import logger from ""./core/middleware/logger"";
import getTemplate from ""./core/middleware/getTemplate"";
import getContentfulEntry from ""./core/middleware/getContentfulEntry"";
import { IAppRequest, IContentfulEntry } from ""./core/types"";
import { triggerBuild } from ""./helpers"";
import { TEN_MINUTES_IN_MILLISEC"
MinimallyCorrect/TickProfiler,https://github.com/MinimallyCorrect/TickProfiler/issues/100,MinimallyCorrect_TickProfiler_issues_100,"[1.12.2-0.0.4] - `/profile c 10` returns Could not process command (NPE)

When running `/profile c 10`, the following error shows up in chat: `An Unknown error occurred while attempting to run this command` and the following is logged to the server console:
```
[22:20:54] [Server thread/WARN] [net.minecraft.command.CommandHandler]: Couldn't process command: profile c 10
java.lang.NullPointerException: null
        at org.minimallycorrect.tickprofiler.minecraft.profiling.EntityCountingProfiler.start(EntityCountingProfiler.java:34) ~[EntityCountingProfiler.class:?]
        at org.minimallycorrect.tickprofiler.minecraft.profiling.Profile.start(Profile.java:52) ~[Profile.class:?]
        at org.minimallycorrect.tickprofiler.minecraft.commands.ProfileCommand.process(ProfileCommand.java:71) ~[ProfileCommand.class:?]
        at org.minimallycorrect.tickprofiler.minecraft.commands.ProfileCommand.processCommand(ProfileCommand.java:30) ~[ProfileCommand.class:?]
        at org.minimallycorrect.tickprofiler.minecraft.commands.Command.func_184881_a(Command.java:45) ~[Command.class:?]
        at com.feed_the_beast.ftbutilities.ranks.CommandOverride.func_184881_a(CommandOverride.java:82) ~[CommandOverride.class:?]
        at net.minecraft.command.CommandHandler.func_175786_a(CommandHandler.java:119) [bj.class:?]
        at net.minecraft.command.CommandHandler.func_71556_a(CommandHandler.java:91) [bj.class:?]
        at net.minecraft.network.NetHandlerPlayServer.func_147361_d(NetHandlerPlayServer.java:958) [pa.class:?]
        at net.minecraft.network.NetHandlerPlayServer.func_147354_a(NetHandlerPlayServer.java:937) [pa.class:?]
        at net.minecraft.network.play.client.CPacketChatMessage.func_148833_a(SourceFile:37) [la.class:?]
        at net.minecraft.network.play.client.CPacketChatMessage.func_148833_a(SourceFile:9) [la.class:?]
        at net.minecraft.network.PacketThreadUtil$1.run(SourceFile:13) [hv$1.class:?]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_171]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_171]
        at net.minecraft.util.Util.func_181617_a(SourceFile:528) [h.class:?]
        at net.minecraft.server.MinecraftServer.func_71190_q(MinecraftServer.java:723) [MinecraftServer.class:?]
        at net.minecraft.server.dedicated.DedicatedServer.func_71190_q(DedicatedServer.java:396) [nz.class:?]
        at net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java:668) [MinecraftServer.class:?]
        at net.minecraft.server.MinecraftServer.run(MinecraftServer.java:526) [MinecraftServer.class:?]
        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_171]
```",What mods are you running? Are you using sponge?,following error shows u
ifsnop/mysqldump-php,https://github.com/ifsnop/mysqldump-php/issues/172,ifsnop_mysqldump-php_issues_172,"Allowed memory size XXX, or, many tables

Hi, when i backup the database, i have no problem when the table has millions of values, but, when i have many tables, like 10.000++, in another database, i receive this issue. 

For now, i solve increasing de memory_limit in php.ini.

Don't ask me why the database has 10.000 tables, when i get here, the shit was already done.

---
Here :D , looks like is an array in 524 
![Captura de Tela 2019-09-03 às 10 16 02](https://user-images.githubusercontent.com/7443043/64176687-5323ff00-ce34-11e9-9a1c-126bdb519778.png)","Could you please update with the line number where mysqldump-php runs out
of memory? I would like to try to fix it.","---
Here :D , looks like is an array in 524 
![Captura de Tela 2019-09-03 às 10 16 02](https://user-images.githubusercontent.com/7443043/64176687-5323ff00-ce34-11e9-9a1c-126bdb519778.png)"
onetimesecret/onetimesecret,https://github.com/onetimesecret/onetimesecret/issues/113,onetimesecret_onetimesecret_issues_113,"onetimesecret.com in maintainance mode?

Just checking, the onetimesecret.com website is in 'maintenance' mode for more than 24 hours. Are you aware of this and is there any plan to bring it back online?","Maybe it's a good place to ask, any recommended alternatives?",for more than 24 hours
apache/cordova-plugin-splashscreen,https://github.com/apache/cordova-plugin-splashscreen/issues/174,apache_cordova-plugin-splashscreen_issues_174,"Android Build Resource Loading Problem on launch

I build my Android app through Meteor-Cordova.

All is well when I build a new version of the app using the latest code base.

However, when I deploy a new code base to my prod server, I encounter a resource not found error on subsequent launches of the app.

` ImageView: android.content.res.Resources$NotFoundException: Resource ID #0x7f010000`

The app is able to launch and function properly upon the first launch after install, even older builds. It's always the subsequent launches that face this error.

The current way I ""fix"" it is to rebuilt the mobile app BUT having to change the version of the plugin used (I toggle between 5.0.2 and 4.1.0).

I haven't got a clue when this really started or what's causing this issue. I don't have custom launch screens or icons yet and I use Meteor's default resources for the splash.

EDIT:
I think this error persists even if the app is able to properly function after a new build is made after I change the version of the plugin. Still unsure what might the issue be though.",Can you share how you fixed this? Future readers (looking for similar problems via Google) might benefit. Thanks.,"EDIT:
I think this error persists even if the app is able to properly function after a new build is made after I change the version of the plugin. Still unsure what might the issue be though."
apache/cordova-plugin-geolocation,https://github.com/apache/cordova-plugin-geolocation/issues/119,apache_cordova-plugin-geolocation_issues_119,"Getting location with high accuracy taking time more than 4 mins 

   let getOptions = { enableHighAccuracy: true };
    this.geolocation.getCurrentPosition(getOptions).then(position => {
 //code to use location
});

Device : Nokia 6(Android Oreo), iPhone 6 (iOS 11) 

version information
""cordova-plugin-geolocation"": ""^4.0.1"",
 ""ionic-angular"": ""3.9.2"",","Do you mean Android 6 maybe?
@GPlay97 What platform and device are your experiences with?
@shokry055 What platform and device? What does `return code 3 TO` mean?",(Android Oreo)Phone 6 (i
blakeembrey/pluralize,https://github.com/blakeembrey/pluralize/issues/123,blakeembrey_pluralize_issues_123,"whisky vs whiskey, when from plural to singular 

```
    console.log(""whisky"", pluralize(""whisky"")) // whisky whiskies
    console.log(""whiskey"", pluralize(""whiskey"")) // whiskey whiskies

    console.log(""whiskies"", pluralize.singular(""whiskies"")) // whiskies whiskey.
    ~console.log(""whiskeys"", pluralize.singular(""whiskey"")) // whiskeys whiskey~
    EDIT: made a mistake here ^^^. meant this 
    console.log(""whiskeys"", pluralize.singular(""whiskeys"")) // whiskeys whiskey
```

so `whisky` to plural =>  `whiskies` and back to singular and we have new word => `whiskey`","What’s the issue here? Are you saying the singular word is incorrect, i.e. it’s not whiskey? There’s no possible way you can singularize to two different words magically.","~"")) // whiskeys whiskey~
    EDIT: made a mistake here ^^^. meant this 
    console.log(""whiskeys"", pluralize.singular(""whiskeys"
markstory/lint-review,https://github.com/markstory/lint-review/issues/216,markstory_lint-review_issues_216,"Source file not found

I was testing the code by trying to verify some simple pull requests. (I'm running through docker.) However when I open a pull request, I get the following error:
```
E902 IOError: [Errno 2] No such file or directory: '/src/foo.py'
```",Where does it hang if you enable debug logging?,"[Edit: I know this code probably doesn't make much sense, I don't use much docker, but please keep reading]"
ArangoDB-Community/arangodb-tinkerpop-provider,https://github.com/ArangoDB-Community/arangodb-tinkerpop-provider/issues/57,ArangoDB-Community_arangodb-tinkerpop-provider_issues_57,"ArangoDB plugin unable to load graph:  java.lang.NullPointerException on open

Hi!

I'm trying to learn Gremlin by using it over ArangoDB. It looks quite straigtforward as only the console and a plugin seem to be needed.

I'm getting a java.lang.NullPointerException when loading the graph. Before that, I was warned to declare a missing relation in the config file, but as soon as the config file seems correct, the exception is thrown without further info.

The only piece might be missing is the Tinkerpop server, but the doc says that ArangoDB is compatible with the console ""out of the box"", and the connection is there because the collections are being checked if there is a config error.

This is my test graph:
![Captura de pantalla 2020-01-22 a las 11 22 32](https://user-images.githubusercontent.com/10059639/72886766-b42c7080-3d0a-11ea-894e-b5287ce3e263.jpg)
![Captura de pantalla 2020-01-22 a las 11 22 03](https://user-images.githubusercontent.com/10059639/72886865-e2aa4b80-3d0a-11ea-9790-0487e26736fe.jpg)

This is my config:
```
gremlin.graph = com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph
gremlin.arangodb.conf.graph.vertex = testfrom
gremlin.arangodb.conf.graph.vertex = testto
gremlin.arangodb.conf.graph.edge = testedge
gremlin.arangodb.conf.graph.relation = testedge:testfrom->testto
gremlin.arangodb.conf.graph.shouldPrefixCollectionNames = false
gremlin.arangodb.conf.graph.db = Test02
gremlin.arangodb.conf.graph.name = Test02Graph01
gremlin.arangodb.conf.arangodb.user = xxxxx
gremlin.arangodb.conf.arangodb.password = xxxxx
gremlin.arangodb.conf.arangodb.hosts = 127.0.0.1:8529
gremlin.arangodb.conf.arangodb.usessl = false
```
note: on OSX 10.14.6, Java SE RE (build 1.8.0_161-b12)

This is the error:
```
gremlin> :plugin list
==>tinkerpop.server[active]
==>tinkerpop.gephi
==>tinkerpop.utilities[active]
==>tinkerpop.arangodb[active]
==>tinkerpop.sugar
==>tinkerpop.credentials
==>tinkerpop.tinkergraph[active]
gremlin> config = new org.apache.commons.configuration.PropertiesConfiguration(""/Users/xxxxx/Applications/TinkerPop/arangotest.properties"")
==>org.apache.commons.configuration.PropertiesConfiguration@2b917fb0
gremlin> g = ArangoDBGraph.open(config)
java.lang.NullPointerException
Type ':help' or ':h' for help.
Display stack trace? [yN]_
java.lang.NullPointerException
	at com.arangodb.tinkerpop.gremlin.client.ArangoDBGraphClient.getGraphVariables(ArangoDBGraphClient.java:494)
	at com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph.<init>(ArangoDBGraph.java:601)
	at com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph.open(ArangoDBGraph.java:543)
	...
```

I know that there is an obvious misstep somewhere.
Can someone please point me in the right direction?

Thanks!

PS: if I delete the line 
gremlin.arangodb.conf.graph.edge = testedge
in the config, the error changes, so there is a nice connection:
```
gremlin> g = ArangoDBGraph.open(config)
WARN  com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph  - Empty edges collection(s), the default 'edge' collection will be used.
java.lang.NullPointerException
```

PS2: Problem is similar with the gremlin server.

Config (properties):
```
gremlin.graph = com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph
gremlin.arangodb.conf.graph.db = Test02
gremlin.arangodb.conf.graph.name = Test02Graph01
gremlin.arangodb.conf.graph.vertex = testfrom
gremlin.arangodb.conf.graph.vertex = testto
gremlin.arangodb.conf.graph.edge = testedge
gremlin.arangodb.conf.graph.relation = testedge:testfrom->testto
gremlin.arangodb.conf.graph.shouldPrefixCollectionNames = false
gremlin.arangodb.conf.arangodb.hosts = 127.0.0.1:8529
gremlin.arangodb.conf.arangodb.user = xxxx
gremlin.arangodb.conf.arangodb.password = xxxx
```
Config (yaml):

```
host: localhost
port: 8182
scriptEvaluationTimeout: 30000
channelizer: org.apache.tinkerpop.gremlin.server.channel.WebSocketChannelizer
graphs: {
  modern: /Users/pelayo/Applications/TinkerPop/arangotest_server.properties}
scriptEngines: {
  gremlin-groovy: {
    plugins: { org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin: {},
               org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin: {},
               com.arangodb.tinkerpop.gremlin.jsr223.ArangoDBGremlinPlugin: {},
               org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin: {classImports: [java.lang.Math], methodImports: [java.lang.Math#*]},
               org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin: {files: [scripts/empty-sample.groovy]}}}}
serializers:
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistryV3d0] }}             # application/vnd.gremlin-v3.0+gryo
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0, config: { serializeResultToString: true }}                                                                       # application/vnd.gremlin-v3.0+gryo-stringd
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV3d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistryV3d0] }}         # application/json
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV2d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistryV2d0] }}         # application/vnd.gremlin-v2.0+json
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphBinaryMessageSerializerV1 }                                                                                                            # application/vnd.graphbinary-v1.0
processors:
  - { className: org.apache.tinkerpop.gremlin.server.op.session.SessionOpProcessor, config: { sessionTimeout: 28800000 }}
  - { className: org.apache.tinkerpop.gremlin.server.op.traversal.TraversalOpProcessor, config: { cacheExpirationTime: 600000, cacheMaxSize: 1000 }}
metrics: {
  consoleReporter: {enabled: true, interval: 180000},
  csvReporter: {enabled: true, interval: 180000, fileName: /tmp/gremlin-server-metrics.csv},
  jmxReporter: {enabled: true},
  slf4jReporter: {enabled: true, interval: 180000}}
strictTransactionManagement: false
idleConnectionTimeout: 0
keepAliveInterval: 0
maxInitialLineLength: 4096
maxHeaderSize: 8192
maxChunkSize: 8192
maxContentLength: 65536
maxAccumulationBufferComponents: 1024
resultIterationBatchSize: 64
writeBufferLowWaterMark: 32768
writeBufferHighWaterMark: 65536
ssl: {
  enabled: false}
```

Output:
```
/Users/xxxx/Applications/apache-tinkerpop-gremlin-server-3.4.4/bin/gremlin-server.sh /Users/xxxx/Applications/TinkerPop/arangodb_server.yaml
[INFO] GremlinServer - 3.4.4
         \,,,/
         (o o)
-----oOOo-(3)-oOOo-----

[INFO] GremlinServer - Configuring Gremlin Server from /Users/xxxxx/Applications/TinkerPop/arangodb_server.yaml
[INFO] MetricManager - Configured Metrics ConsoleReporter configured with report interval=180000ms
[INFO] MetricManager - Configured Metrics CsvReporter configured with report interval=180000ms to fileName=/tmp/gremlin-server-metrics.csv
[INFO] MetricManager - Configured Metrics JmxReporter configured with domain= and agentId=
[INFO] MetricManager - Configured Metrics Slf4jReporter configured with interval=180000ms and loggerName=org.apache.tinkerpop.gremlin.server.Settings$Slf4jReporterMetrics
[INFO] ArangoDBGraph - Creating new ArangoDB Graph from configuration
[INFO] ArangoDBGraphClient - Initiating the ArangoDb Client
**[INFO] ArangoDBUtil - Creating EdgeRelation from testedge:testfrom->testto**
[WARN] DefaultGraphManager - Graph [modern] configured at [/Users/xxxx/Applications/TinkerPop/arangotest_server.properties] could not be instantiated and will not be available in Gremlin Server.  GraphFactory message: GraphFactory could not instantiate this Graph implementation [class com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph]
java.lang.RuntimeException: GraphFactory could not instantiate this Graph implementation [class com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph]
	at org.apache.tinkerpop.gremlin.structure.util.GraphFactory.open(GraphFactory.java:82)
	at org.apache.tinkerpop.gremlin.structure.util.GraphFactory.open(GraphFactory.java:70)
	at org.apache.tinkerpop.gremlin.structure.util.GraphFactory.open(GraphFactory.java:104)
	at org.apache.tinkerpop.gremlin.server.util.DefaultGraphManager.lambda$new$0(DefaultGraphManager.java:57)
	at java.util.LinkedHashMap$LinkedEntrySet.forEach(LinkedHashMap.java:671)
	at org.apache.tinkerpop.gremlin.server.util.DefaultGraphManager.<init>(DefaultGraphManager.java:55)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor.<init>(ServerGremlinExecutor.java:80)
	at org.apache.tinkerpop.gremlin.server.GremlinServer.<init>(GremlinServer.java:122)
	at org.apache.tinkerpop.gremlin.server.GremlinServer.<init>(GremlinServer.java:86)
	at org.apache.tinkerpop.gremlin.server.GremlinServer.main(GremlinServer.java:345)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.tinkerpop.gremlin.structure.util.GraphFactory.open(GraphFactory.java:78)
	... 13 more
**Caused by: java.lang.NullPointerException**
	at com.arangodb.tinkerpop.gremlin.client.ArangoDBGraphClient.getGraphVariables(ArangoDBGraphClient.java:494)
	at com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph.<init>(ArangoDBGraph.java:601)
	at com.arangodb.tinkerpop.gremlin.structure.ArangoDBGraph.open(ArangoDBGraph.java:543)
	... 18 more
[INFO] ServerGremlinExecutor - Initialized Gremlin thread pool.  Threads in pool named with pattern gremlin-*
[INFO] ServerGremlinExecutor - Initialized GremlinExecutor and preparing GremlinScriptEngines instances.
[ERROR] DefaultGremlinScriptEngineManager - Could not create GremlinScriptEngine for gremlin-groovy
java.lang.IllegalStateException: javax.script.ScriptException: javax.script.ScriptException: groovy.lang.MissingPropertyException: No such property: graph for class: Script1
	at org.apache.tinkerpop.gremlin.jsr223.DefaultGremlinScriptEngineManager.lambda$createGremlinScriptEngine$16(DefaultGremlinScriptEngineManager.java:464)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:270)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at org.apache.tinkerpop.gremlin.jsr223.DefaultGremlinScriptEngineManager.createGremlinScriptEngine(DefaultGremlinScriptEngineManager.java:450)
	at org.apache.tinkerpop.gremlin.jsr223.DefaultGremlinScriptEngineManager.getEngineByName(DefaultGremlinScriptEngineManager.java:219)
	at org.apache.tinkerpop.gremlin.jsr223.CachedGremlinScriptEngineManager.lambda$getEngineByName$0(CachedGremlinScriptEngineManager.java:57)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at org.apache.tinkerpop.gremlin.jsr223.CachedGremlinScriptEngineManager.getEngineByName(CachedGremlinScriptEngineManager.java:57)
	at org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor.lambda$eval$0(GremlinExecutor.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: javax.script.ScriptException: javax.script.ScriptException: groovy.lang.MissingPropertyException: No such property: graph for class: Script1
	at org.apache.tinkerpop.gremlin.groovy.jsr223.GremlinGroovyScriptEngine.eval(GremlinGroovyScriptEngine.java:378)
	at javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:264)
	at org.apache.tinkerpop.gremlin.jsr223.DefaultGremlinScriptEngineManager.lambda$createGremlinScriptEngine$16(DefaultGremlinScriptEngineManager.java:460)
	... 24 more
Caused by: javax.script.ScriptException: groovy.lang.MissingPropertyException: No such property: graph for class: Script1
	at org.apache.tinkerpop.gremlin.groovy.jsr223.GremlinGroovyScriptEngine.eval(GremlinGroovyScriptEngine.java:697)
	at org.apache.tinkerpop.gremlin.groovy.jsr223.GremlinGroovyScriptEngine.eval(GremlinGroovyScriptEngine.java:376)
	... 26 more
Caused by: groovy.lang.MissingPropertyException: No such property: graph for class: Script1
	at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.unwrap(ScriptBytecodeAdapter.java:65)
	at org.codehaus.groovy.runtime.callsite.PogoGetPropertySite.getProperty(PogoGetPropertySite.java:51)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callGroovyObjectGetProperty(AbstractCallSite.java:309)
	at Script1.run(Script1.groovy:45)
	at org.apache.tinkerpop.gremlin.groovy.jsr223.GremlinGroovyScriptEngine.eval(GremlinGroovyScriptEngine.java:674)
	... 27 more
[WARN] ServerGremlinExecutor - Could not initialize gremlin-groovy GremlinScriptEngine as init script could not be evaluated
java.util.concurrent.CompletionException: java.lang.IllegalArgumentException: gremlin-groovy is not an available GremlinScriptEngine
	at java.util.concurrent.CompletableFuture.reportJoin(CompletableFuture.java:375)
	at java.util.concurrent.CompletableFuture.join(CompletableFuture.java:1934)
	at org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor.lambda$new$4(ServerGremlinExecutor.java:141)
	at java.util.LinkedHashMap$LinkedKeySet.forEach(LinkedHashMap.java:559)
	at org.apache.tinkerpop.gremlin.server.util.ServerGremlinExecutor.<init>(ServerGremlinExecutor.java:136)
	at org.apache.tinkerpop.gremlin.server.GremlinServer.<init>(GremlinServer.java:122)
	at org.apache.tinkerpop.gremlin.server.GremlinServer.<init>(GremlinServer.java:86)
	at org.apache.tinkerpop.gremlin.server.GremlinServer.main(GremlinServer.java:345)
Caused by: java.lang.IllegalArgumentException: gremlin-groovy is not an available GremlinScriptEngine
	at org.apache.tinkerpop.gremlin.jsr223.CachedGremlinScriptEngineManager.registerLookUpInfo(CachedGremlinScriptEngineManager.java:95)
	at org.apache.tinkerpop.gremlin.jsr223.CachedGremlinScriptEngineManager.getEngineByName(CachedGremlinScriptEngineManager.java:58)
	at org.apache.tinkerpop.gremlin.groovy.engine.GremlinExecutor.lambda$eval$0(GremlinExecutor.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[INFO] OpLoader - Adding the standard OpProcessor.
[INFO] OpLoader - Adding the session OpProcessor.
[INFO] OpLoader - Adding the traversal OpProcessor.
[INFO] TraversalOpProcessor - Initialized cache for TraversalOpProcessor with size 1000 and expiration time of 600000 ms
[INFO] GremlinServer - idleConnectionTimeout was set to 0 which resolves to 0 seconds when configuring this value - this feature will be disabled
[INFO] GremlinServer - keepAliveInterval was set to 0 which resolves to 0 seconds when configuring this value - this feature will be disabled
[WARN] AbstractChannelizer - The org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 serialization class is deprecated.
[INFO] AbstractChannelizer - Configured application/vnd.gremlin-v3.0+gryo with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0
[WARN] AbstractChannelizer - The org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 serialization class is deprecated.
[INFO] AbstractChannelizer - Configured application/vnd.gremlin-v3.0+gryo-stringd with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0
[INFO] AbstractChannelizer - Configured application/vnd.gremlin-v3.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV3d0
[INFO] AbstractChannelizer - Configured application/json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV3d0
[INFO] AbstractChannelizer - Configured application/vnd.gremlin-v2.0+json with org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV2d0
[INFO] AbstractChannelizer - application/json already has org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV3d0 configured - it will not be replaced by org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV2d0, change order of serialization configuration if this is not desired.
[INFO] AbstractChannelizer - Configured application/vnd.graphbinary-v1.0 with org.apache.tinkerpop.gremlin.driver.ser.GraphBinaryMessageSerializerV1
[INFO] GremlinServer$1 - Gremlin Server configured with worker thread pool of 1, gremlin pool of 4 and boss thread pool of 1.
[INFO] GremlinServer$1 - Channel started at port 8182.
```","Can you try creating a collection with this name, as in TINKERPOP-GRAPH-VARIABLES, in your db and see if that solves the problem?","(properties)
```
Config (yaml):

```
host: localhost
port: 8182
scriptEvaluationTimeout: 30000
channelizer: org.apache.tinkerpop.gremlin.server.channel.WebSocketChannelizer
graphs: {
  modern: /Users/pelayo/Applications/TinkerPop/arangotest_server.properties}
scriptEngines: {
  gremlin-groovy: {
    plugins: { org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin: {},
               org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin: {},
               com.arangodb.tinkerpop.gremlin.jsr223.ArangoDBGremlinPlugin: {},
               org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin: {classImports: [java.lang.Math], methodImports: [java.lang.Math#*]},
               org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin: {files: [scripts/empty-sample.groovy]}}}}
serializers:
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistryV3d0] }}             # application/vnd.gremlin-v3.0+gryo
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0, config: { serializeResultToString: true }}                                                                       # application/vnd.gremlin-v3.0+gryo-stringd
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV3d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistryV3d0] }}         # application/json
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV2d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistryV2d0] }}         # application/vnd.gremlin-v2.0+json
  - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphBinaryMessageSerializerV1 }                                                                                                            # application/vnd.graphbinary-v1.0
processors:
  - { className: org.apache.tinkerpop.gremlin.server.op.session.SessionOpProcessor, config: { sessionTimeout: 28800000 }}
  - { className: org.apache.tinkerpop.gremlin.server.op.traversal.TraversalOpProcessor, config: { cacheExpirationTime: 600000, cacheMaxSize: 1000 }}
metrics: {
  consoleReporter: {enabled: true, interval: 180000},
  csvReporter: {enabled: true, interval: 180000, fileName: /tmp/gremlin-server-metrics.csv},
  jmxReporter: {enabled: true},
  slf4jReporter: {enabled: true, interval: 180000}}
strictTransactionManagement: false
idleConnectionTimeout: 0
keepAliveInterval: 0
maxInitialLineLength: 4096
maxHeaderSize: 8192
maxChunkSize: 8192
maxContentLength: 65536
maxAccumulationBufferComponents: 1024
resultIterationBatchSize: 64
writeBufferLowWaterMark: 32768
writeBufferHighWaterMark: 65536
ssl: {
  enabled: false}"
faye/websocket-driver-ruby,https://github.com/faye/websocket-driver-ruby/issues/63,faye_websocket-driver-ruby_issues_63,"Feature request: documentation

This gem desperately lacks documentation of the code. Navigating the code trying to figure out where something is instantiated and used when using it with my own code that's using EventMachine takes a lot of effort. Documenting the code would make this much easier.

I'm creating this feature request to track this effort.","Could you be a little more specific about ways in which the documentation is not serving your needs, or what questions it's not answering?",of the code. Navigating the code trying to figure out where something is instantiated and used when using it with my own code that's using EventMachine takes a lot of effort. Documenting the code would make this much easier
EconForge/interpolation.py,https://github.com/EconForge/interpolation.py/issues/52,EconForge_interpolation.py_issues_52,"Not possible to use `eval_linear` with interpolation option (""xto.*"") within jitted function

Hi and thanks for this very excellent work. This is an extremely useful project!

Big picture: I am numbafying a complete policy function iteration, which I suppose is a rather standard use case for this package. Therefore I am interpolating within a jitted function (via `eval_linear`).
The return vector has the same dimensionality as the input vector, which is multivariate. While `eval_linear` with univariate output can be successfully called within a jitted function independently of whether interpolation options are used (such as `xto.Linear`), this does not work for multivariate output. 

Here a simple example based on your quick guide:
```
import numpy as np
from numba import njit
from interpolation.splines import eval_linear, UCGrid, nodes
from interpolation.splines import extrap_options as xto

f = lambda x,y: np.sin(x**3+y**2+0.00001)/np.sqrt(x**2+y**2+0.00001)
g = lambda x,y: np.sin(x**3+y**2+0.00001)/np.sqrt(x**2+y**2+0.00001)

grid = UCGrid((-1.0, 1.0, 10), (-1.0, 1.0, 10))
gp = nodes(grid)   # 100x2 matrix

mvalues = np.concatenate([
   f(gp[:,0], gp[:,1]).reshape((10,10))[:,:,None],
   g(gp[:,0], gp[:,1]).reshape((10,10))[:,:,None]
],axis=2) # 10x10x2 array

points = np.random.random((1000,2))

@njit
def fun():
    eval_linear(grid, mvalues, points)

@njit
def no_fun():
    eval_linear(grid, mvalues, points, xto.LINEAR)

fun()       # works happily
no_fun()    # does not :'(
```

Environment is arch linux with:
    Python 3.7.4
    numba 0.45
    numpy 1.17
    interpolation.py master branch

I tried to dig into your code but I admit that I got lost in codegen.py. I am happy about hints.",Could you try master a few minutes from now ?,from interpolation.splines import extrap_options as xto
noirello/bonsai,https://github.com/noirello/bonsai/issues/34,noirello_bonsai_issues_34,"bonsai.errors.LDAPError: Operations error

Hi, I am running into the following error with the code. 

I am working with a virtual active directory connection,(Ldap3 over SSL)

Code: 
```
compiled_search_filter = '(&(objectCategory=person)(objectClass=user)(memberOf:1.2.840.113556.1.4.1941:=CN=ADgroup,OU=test,OU=sys,DC=a,DC=b,DC=com))'
async with client.connect(is_async=True) as conn:
        res = []
        result = await conn.paged_search(base="""", scope=2, filter_exp=compiled_search_filter,
                                         attrlist=['employeeID', 'sAMAccountName','objectClass','DistinguishedName'],
                                         timeout=10,attrsonly=True,page_size=1000)
        async for r in result:
            res.append(r)
```

> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3326, in run_code
>     exec(code_obj, self.user_global_ns, self.user_ns)
>   File ""<ipython-input-2-9347d89bb5c8>"", line 1, in <module>
>     runfile('/Users/bawer/Documents/Automation Projects/Test/Bonsai_AD_Domains.py', wdir='/Users/bawer/Documents/Automation Projects/Test')
>   File ""/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 197, in runfile
>     pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
>   File ""/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
>     exec(compile(contents+""\n"", file, 'exec'), glob, loc)
>   File ""/Users/bawer/Documents/Automation Projects/Test/Bonsai_AD_Domains.py"", line 87, in <module>
>     res = loop.run_until_complete(get_members(group_name))
>   File ""/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py"", line 579, in run_until_complete
>     return future.result()
>   File ""/Users/bawer/Documents/Automation Projects/Test/Bonsai_AD_Domains.py"", line 70, in get_members
>     attrlist=['employeeID', 'sAMAccountName','objectClass','DistinguishedName'],timeout=10,attrsonly=True,page_size=1000)
>   File ""/usr/local/lib/python3.7/site-packages/bonsai-1.2.0-py3.7-macosx-10.14-x86_64.egg/bonsai/asyncio/aioconnection.py"", line 64, in _poll
[debug.txt](https://github.com/noirello/bonsai/files/3640251/debug.txt)

>     raise exc
>   File ""/usr/local/lib/python3.7/site-packages/bonsai-1.2.0-py3.7-macosx-10.14-x86_64.egg/bonsai/asyncio/aioconnection.py"", line 59, in _poll
>     return await asyncio.wait_for(fut, timeout)
>   File ""/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for
>     return fut.result()
>   File ""/usr/local/lib/python3.7/site-packages/bonsai-1.2.0-py3.7-macosx-10.14-x86_64.egg/bonsai/asyncio/aioconnection.py"", line 45, in _ready
>     res = super().get_result(msg_id)
> bonsai.errors.LDAPError: Operations error. (0x0001 [1])

The query seems to work with JXplorer. It seems the connection might be timing out.

Debug logs attached 

With `is_async=False` I get the following error -

>   File ""/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py"", line 579, in run_until_complete
>     return future.result()
>   File ""/Users/bawer/Documents/Automation Projects/Test/Bonsai_AD_Domains.py"", line 23, in find_dn
>     async with client.connect(is_async=False) as conn:
> AttributeError: __aexit__",Did it produce the same result?,"With `is_async=False` I get the following error -

>   File ""/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py"", line 579, in run_until_complete
>     return future.result()
>   File ""/Users/bawer/Documents/Automation Projects/Test/Bonsai_AD_Domains.py"", line 23, in find_dn
>     async with client.connect(is_async=False) as conn:
> AttributeError: __aexit__"
google/pinject,https://github.com/google/pinject/issues/36,google_pinject_issues_36,"Nested dependency resolving issue

Hi there
I'm having a difficulty using pinject when I'm trying to resolve a dependency which has inner nested dependencies as well.

```py
import pinject

class User:

    def __init__(self, user_id=None, username=None):
        self.user_id = user_id
        self.username = username

    def get_user_id(self):
        return self.user_id

    def get_username(self):
        return self.username

    def __str__(self):
        return str(self.__dict__)

    def __eq__(self, other):
        return self.__dict__ == other.__dict__

class QueueUserRepository(BaseUserRepository):

    def __init__(self, data_provider):
        self.data_provider = data_provider

    def get_user(self):
        user_data = self.data_provider.get_data('user')
        return User(user_data['user_id'], user_data['username'])

    def get_users_batch(self):
        return UserBatch(self.data_provider.get_data('users'))



class QueueDataProvider:
    class DataDoesNotExistsError(Exception):
        pass

    def __init__(self, provider_data):
        print(provider_data)        
        self.data = self.normalize_data(provider_data)

    @staticmethod
    def normalize_data(data):
        return data

    def get_data(self, key):
        try:
            return self.data[key]
        except KeyError:
            raise self.DataDoesNotExistsError('{} key does not exists'.format(key))

class MyBindingSpec(pinject.BindingSpec):
    def configure(self, bind):
        bind('provider_data', to_instance={'user': {'username': 'super', 'user_id': 'y'}})
        bind('data_provider', to_instance=QueueDataProvider)

class TestQueueUserRepository(unittest.TestCase):
    def setUp(self):
        self.container = pinject.new_object_graph(binding_specs=[MyBindingSpec()])
        
    def test_if_can_get_user(self):
        z = self.container.provide(QueueUserRepository)
        u = User('y', 'super')
        self.assertEqual(r.get_user(), u)
```

It seems pinject does not care about 'dependency of dependencies' as QueueDataProvider constructor does not seem to be called at all

The above code does not work however when I manually build objects, it works perfectly fine.

As I searched a lot in the documentation, I could not find any proper explanation with this.

Could you please help me with this.

EDIT:
I really tried so hard but I could not get code highlight support in this ...

UPADTE:
Unit tests are added.
To be more clear: QueueDataProvider is not receiving 'provider_data' on creation. I can say the QueueDataProvider's constructor is not called at all as far as I checked.","Could you provide a unit test to confirm this problem? If you could, then we will be able to look into it later.","User:

    def __init__(self, user_id=None, username=None):
        self.user_id = user_id
        self.username = username

    def get_user_id(self):
        return self.user_id

    def get_username(self):
        return self.username

    def __str__(self):
        return str(self.__dict__)

    def __eq__(self, other):
        return self.__dict__ == other.__dict__

class ), u"
brianloveswords/base64url,https://github.com/brianloveswords/base64url/issues/44,brianloveswords_base64url_issues_44,"Doesnt work with Angular 7 still getting buffer is not defined

Doesnt work with Angular 7 still getting buffer is not defined, can someone else confirm?

_Originally posted by @Gabb1995 in https://github.com/brianloveswords/base64url/issues/33#issuecomment-481248229_

Package.json
```""@agm/core"": ""^1.0.0-beta.5"",
    ""@angular/animations"": ""^7.1.4"",
    ""@angular/cdk"": ""^7.3.2"",
    ""@angular/common"": ""~7.1.0"",
    ""@angular/compiler"": ""~7.1.0"",
    ""@angular/core"": ""~7.1.0"",
    ""@angular/flex-layout"": ""^7.0.0-beta.23"",
    ""@angular/forms"": ""~7.1.0"",
    ""@angular/material"": ""^7.3.2"",
    ""@angular/platform-browser"": ""~7.1.0"",
    ""@angular/platform-browser-dynamic"": ""~7.1.0"",
    ""@angular/router"": ""~7.1.0"",
    ""@fortawesome/fontawesome-free"": ""^5.7.2"",
    ""@ngx-translate/core"": ""^11.0.1"",
    ""@ngx-translate/http-loader"": ""^4.0.0"",
    ""base64url"": ""^3.0.1"",
    ""core-js"": ""^2.5.4"",
    ""dayjs"": ""^1.8.11"",
    ""hammerjs"": ""^2.0.8"",
    ""lodash"": ""^4.17.11"",
    ""ngx-color-picker"": ""^7.3.1"",
    ""ngx-openlayers"": ""^0.8.22"",
    ""rxjs"": ""^6.3.3"",
    ""tslib"": ""^1.9.0"",
    ""zone.js"": ""~0.8.26""

ReferenceError: ""Buffer is not defined""
    decode base64url.js:14
    getConfigFromLegacy whitelabel.service.ts:294
    load whitelabel.service.ts:45
    ZoneAwarePromise Angular
    load whitelabel.service.ts:44
    ngOnInit app.component.ts:74
    RxJS 3
app.component.ts:80:32
    ngOnInit app.component.ts:80
    Angular 10",Can you make a minimal reproduction? A very small project that can recreate the error? If you can put that together it will be much easier to fix,"```ReferenceError: ""Buffer is not defined""
    decode base64url.js:14
    getConfigFromLegacy whitelabel.service.ts:294
    load whitelabel.service.ts:45
    ZoneAwarePromise Angular
    load whitelabel.service.ts:44
    ngOnInit app.component.ts:74
    RxJS 3
app.component.ts:80:32
    ngOnInit app.component.ts:80
    Angular 10"
maxmind/MaxMind-DB-Reader-XS,https://github.com/maxmind/MaxMind-DB-Reader-XS/issues/28,maxmind_MaxMind-DB-Reader-XS_issues_28,"problem installing on macOS Mojave

Installing MaxMind::DB::Reader::XS from cpan on Mojave
halts with the message that maxminddb_config.h is not provided.
It's right there next to maxminddb.h.",What error do you get?,"Installing MaxMind::DB::Reader::XS from cpan on Mojave
halts with the message that maxminddb_config.h is not provided.
It's right there next to maxminddb.h."
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/20681,ionic-team_ionic_issues_20681,"bug: SplitPane not working when Menu is wrapped in a Component

<!-- Before submitting an issue, please consult our docs (https://ionicframework.com/docs/). -->

<!-- Please make sure you are posting an issue pertaining to the Ionic Framework. If you are having an issue with the Ionic Appflow services (Ionic View, Ionic Deploy, etc.) please consult the Ionic Appflow support portal (https://ionic.zendesk.com/hc/en-us) -->

<!-- Please do not submit support requests or ""How to"" questions here. Instead, please use one of these channels: https://forum.ionicframework.com/ or http://ionicworldwide.herokuapp.com/ -->

<!-- ISSUES MISSING IMPORTANT INFORMATION MAY BE CLOSED WITHOUT INVESTIGATION. -->

# Bug Report
When wrappen the  menu inside a SpliePane in it's own component (e.g. `<my-menu>`) the SplitPane is not working as expected (2 Panes are shown)

**Ionic version:**
<!-- (For Ionic 1.x issues, please use https://github.com/ionic-team/ionic-v1) -->
<!-- (For Ionic 2.x & 3.x issues, please use https://github.com/ionic-team/ionic-v3) -->
[x] **5.x**
latest

**Current behavior:**
<!-- Describe how the bug manifests. -->
When wrapping the menu inside a SplitPane in it's own component (e.g. <my-menu>)
2 Panes are shwon

**Expected behavior:**
<!-- Describe what the behavior would be without the bug. -->
The SplitPane should work as if i would put the `<ion-menu>` right underneath the SplitPane

**Steps to reproduce:**
<!--  Please explain the steps required to duplicate the issue, especially if you are able to provide a sample application. -->

**Related code:**
not working:
```
<ion-split-pane when=""xl"" contentId=""main"">
  <my-menu></my-menu>

  <ion-router-outlet main id=""main""></ion-router-outlet>
</ion-split-pane>
```

working:
```
<ion-split-pane when=""xl"" contentId=""main"">
  <ion-menu>...</ion-menu>

  <ion-router-outlet main id=""main""></ion-router-outlet>
</ion-split-pane>
```

<!-- If you are able to illustrate the bug or feature request with an example, please provide a sample application via one of the following means:

A sample application via GitHub

StackBlitz (https://stackblitz.com)
Ionic Angular StackBlitz: https://stackblitz.com/edit/ionic-v4-angular-tabs

Plunker (http://plnkr.co/edit/cpeRJs?p=preview)

-->

```
insert short code snippets here
```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:**
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
insert the output from ionic info here
```",Can you provide a repo with the code required to reproduce this issue?,"``

````
insert the output from ionic info here
```"
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/16786,ionic-team_ionic_issues_16786,"[4.0.0-beta.19] Navigate back in tabs highlight bug

# Bug Report

**Ionic version:**
4.0.0-beta.19

**Current behavior:**
When I choose a tab, it highlights the text/icon, and the other unselected tabs are grayed out. However, when I press the back button and navigate to a previous tab, the selected tab gets highlighted, but the previous tab stays highlighted

**Expected behavior:**
Previous tab should be grayed out

**Steps to reproduce:**
See explanation

**Related code:**
```<ion-tabs #tabs>
  <ion-tab-bar slot=""bottom"" color=""secondary"" selected-tab=""home"">
    <ion-tab-button tab=""home"">
      <ion-icon name=""home""></ion-icon>
      <ion-label>home</ion-label>
    </ion-tab-button>
    <ion-tab-button tab=""search"">
      <ion-icon name=""search""></ion-icon>
      <ion-label>search</ion-label>
    </ion-tab-button>
    <ion-tab-button tab=""library"" >
      <ion-icon src=""/assets/ic_books.svg""></ion-icon>
      <ion-label>library</ion-label>
    </ion-tab-button>
  </ion-tab-bar>
</ion-tabs>
```
Routes:
```
const routes: Routes = [
  {
    path: 'tabs',
    component: TabsPage,
    children: [
      {
        path: 'home',
        children: [
          {
            path: '',
            loadChildren: '../home/home.module#HomePageModule'
          },
        ]
      },
      {
        path: 'library',
        children: [
          {
            path: '',
            loadChildren: '../library/library.module#LibraryPageModule'
          },
        ]

      },
  {
    path: '',
    redirectTo: '/tabs/home',
    pathMatch: 'full'
  },
```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:** 
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
insert the output from ionic info here
```",Can you share your markup and routes?,"Routes:
```
const routes: Routes = [
  {
    path: 'tabs',
    component: TabsPage,
    children: [
      {
        path: 'home',
        children: [
          {
            path: '',
            loadChildren: '../home/home.module#HomePageModule'
          },
        ]
      },
      {
        path: 'library',
        children: [
          {
            path: '',
            loadChildren: '../library/library.module#LibraryPageModule'
          },
        ]

      },
  {
    path: '',
    redirectTo: '/tabs/home',
    pathMatch: 'full'
  },
```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:** 
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
insert the output from ionic info here
```"
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/16648,ionic-team_ionic_issues_16648,"Memory Leak on Modals after dismiss

<!-- Before submitting an issue, please consult our docs (https://beta.ionicframework.com/docs/) and API reference (https://beta.ionicframework.com/docs/api/) -->

<!-- Please make sure you are posting an issue pertaining to the Ionic Framework. If you are having an issue with the Ionic Appflow services (Ionic View, Ionic Deploy, etc.) please consult the Ionic Appflow support portal (https://ionic.zendesk.com/hc/en-us) -->

<!-- Please do not submit support requests or ""How to"" questions here. Instead, please use one of these channels: https://forum.ionicframework.com/ or http://ionicworldwide.herokuapp.com/ -->

<!-- ISSUES MISSING IMPORTANT INFORMATION MAY BE CLOSED WITHOUT INVESTIGATION. -->

# Bug Report

**Ionic version:**
<!-- (For Ionic 1.x issues, please use https://github.com/ionic-team/ionic-v1) -->
<!-- (For Ionic 2.x & 3.x issues, please use https://github.com/ionic-team/ionic-v3) -->
[x] **4.0.0-beta.13**

**Current behavior:**
<!-- Describe how the bug manifests. -->
When Modal (pop up) is displayed and then dismissed, it leaved Detached HTMLElement (memory leaks) behind.

**Expected behavior:**
<!-- Describe what the behavior would be without the bug. -->
Modal dismiss should clean up the memory allocation

**Steps to reproduce:**
<!--  Please explain the steps required to duplicate the issue, especially if you are able to provide a sample application. -->
The sample given at the docs is enough to produce the problem. When you have larger components used as the base for the modal, the issue becomes more dramatic.

**Related code:**

The code to launch the modal:

export class HomePage {
    constructor(public modalController: ModalController) {
    }

    async presentProfileModal() {        
        const modal = await this.modalController.create({
            component: TestModalComponent,
            componentProps: { value: 123 }
        });

        await modal.present();
    }         
}

Please find the component code below. The only added method is related to modal dismiss.

  **closeModal() {
      this.modalController.dismiss();
  }**

<!-- If you are able to illustrate the bug or feature request with an example, please provide a sample application via one of the following means:

A sample application via GitHub

StackBlitz (https://stackblitz.com)

Plunker (http://plnkr.co/edit/cpeRJs?p=preview)

-->

```

```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:** 
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
Ionic:

   ionic (Ionic CLI) : 4.2.1

System:

   NodeJS : v8.9.4
   npm    : 6.4.1
   OS     : Windows 7
```","Can you please follow the issue template? Ionic 4.2.1 is not the ionic version, but the CLI version","<!-- Before submitting an issue, please consult our docs (https://beta.ionicframework.com/docs/) and API reference (https://beta.ionicframework.com/docs/api/) -->

<!-- Please make sure you are posting an issue pertaining to the Ionic Framework. If you are having an issue with the Ionic Appflow services (Ionic View, Ionic Deploy, etc.) please consult the Ionic Appflow support portal (https://ionic.zendesk.com/hc/en-us) -->

<!-- Please do not submit support requests or ""****he only method is related to modal dismiss.

export class T**"
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/16857,ionic-team_ionic_issues_16857,"ion-searchbar: Animated with background different

<!-- Before submitting an issue, please consult our docs (https://beta.ionicframework.com/docs/) and API reference (https://beta.ionicframework.com/docs/api/) -->

<!-- Please make sure you are posting an issue pertaining to the Ionic Framework. If you are having an issue with the Ionic Appflow services (Ionic View, Ionic Deploy, etc.) please consult the Ionic Appflow support portal (https://ionic.zendesk.com/hc/en-us) -->

<!-- Please do not submit support requests or ""How to"" questions here. Instead, please use one of these channels: https://forum.ionicframework.com/ or http://ionicworldwide.herokuapp.com/ -->

<!-- ISSUES MISSING IMPORTANT INFORMATION MAY BE CLOSED WITHOUT INVESTIGATION. -->

# Bug Report

**Ionic version:**
<!-- (For Ionic 1.x issues, please use https://github.com/ionic-team/ionic-v1) -->
<!-- (For Ionic 2.x & 3.x issues, please use https://github.com/ionic-team/ionic-v3) -->
[x] **4.x**

**Current behavior:**
<!-- Describe how the bug manifests. -->
![captura de tela 2018-12-21 as 16 27 43](https://user-images.githubusercontent.com/3674885/50357721-1b8f5400-053e-11e9-9c19-a1dcd6ea6d85.png)


There are different styles (background) between the inputs.

Compare the background between a `default` and another `animated` field. I understand a field with class `.searchbar-animated` it has an `opacity` that makes this difference in style (background).

**Related code:**

<!-- If you are able to illustrate the bug or feature request with an example, please provide a sample application via one of the following means:
-->

https://beta.ionicframework.com/docs/api/searchbar/",Could you please elaborate on what the issue is? I'm not seeing a problem. Thanks!,"re are different styles (background) between the inputs.

Compare the background between a"
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/18069,ionic-team_ionic_issues_18069,"bug: I have in trouble when I used ion-item-sliding. If I click ion-item after a incomplete drag at the end of ion-item ，it can trigger ion-item-option

<!-- Before submitting an issue, please consult our docs (https://ionicframework.com/docs/). -->

<!-- Please make sure you are posting an issue pertaining to the Ionic Framework. If you are having an issue with the Ionic Appflow services (Ionic View, Ionic Deploy, etc.) please consult the Ionic Appflow support portal (https://ionic.zendesk.com/hc/en-us) -->

<!-- Please do not submit support requests or ""How to"" questions here. Instead, please use one of these channels: https://forum.ionicframework.com/ or http://ionicworldwide.herokuapp.com/ -->

<!-- ISSUES MISSING IMPORTANT INFORMATION MAY BE CLOSED WITHOUT INVESTIGATION. -->

# Bug Report
I have in trouble when I used ion-item-sliding.
If I click ion-item after a  incomplete drag at the end of ion-item
 ，it can  trigger ion-item-option
**Ionic version:**
<!-- (For Ionic 1.x issues, please use https://github.com/ionic-team/ionic-v1) -->
<!-- (For Ionic 2.x & 3.x issues, please use https://github.com/ionic-team/ionic-v3) -->
[x] **4.3.0**

**Current behavior:**
<!-- Describe how the bug manifests. -->
When I drag the point that I marked  incompletely and click ，it trigger  ion-item-option
![31299333-4A4F-4091-B3E7-7A1E71A20FD6](https://user-images.githubusercontent.com/46949975/56344041-0a560b80-61ef-11e9-96c1-328e9f4b76f4.png)
![B52F87EA-7A51-4016-9C6F-4B84AA9F720A](https://user-images.githubusercontent.com/46949975/56344043-0aeea200-61ef-11e9-9691-8c4c5558c90b.png)

**Expected behavior:**
<!-- Describe what the behavior would be without the bug. -->
It only shoulds trigger  ion-item-option when I drag completely and click  ion-item-option
**Steps to reproduce:**
<!--  Please explain the steps required to duplicate the issue, especially if you are able to provide a sample application. -->



**Steps to reproduce:**
<!--  Please explain the steps required to duplicate the issue, especially if you are able to provide a sample application. -->

**Related code:**

<!-- If you are able to illustrate the bug or feature request with an example, please provide a sample application via one of the following means:

A sample application via GitHub

StackBlitz (https://stackblitz.com)

Plunker (http://plnkr.co/edit/cpeRJs?p=preview)

-->

```
 <ion-item-sliding onIonDrag={() => {console.log('拖动')}} >
    <ion-item onClick={(e) => {console.log(""点击item"");e.stopPropagation()}}>
      <ion-label>
        hello world
      </ion-label>
    </ion-item>
    <ion-item-options side=""end"">
     
      <ion-item-option color=""secondary"">
     
       <ion-label onClick={() => {console.log('触发删除')}}>删除</ion-label> 
      </ion-item-option>
    </ion-item-options>
  </ion-item-sliding  >
```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:**
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
insert the output from ionic info here
```","Can you provide a repository with the code required to reproduce this issue? Also can you provide the output of running `ionic info`?

Thanks!","**Steps to reproduce:**
 Please explain the steps required to duplicate the issue, especially if you are able to provide a sample application. -->

**Related code:**

<!--"
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/18751,ionic-team_ionic_issues_18751,"bug: ion-select popover items in radio group not updating

<!-- Before submitting an issue, please consult our docs (https://ionicframework.com/docs/). -->

<!-- Please make sure you are posting an issue pertaining to the Ionic Framework. If you are having an issue with the Ionic Appflow services (Ionic View, Ionic Deploy, etc.) please consult the Ionic Appflow support portal (https://ionic.zendesk.com/hc/en-us) -->

<!-- Please do not submit support requests or ""How to"" questions here. Instead, please use one of these channels: https://forum.ionicframework.com/ or http://ionicworldwide.herokuapp.com/ -->

<!-- ISSUES MISSING IMPORTANT INFORMATION MAY BE CLOSED WITHOUT INVESTIGATION. -->

# Bug Report

**Ionic version:**
<!-- (For Ionic 1.x issues, please use https://github.com/ionic-team/ionic-v1) -->
<!-- (For Ionic 2.x & 3.x issues, please use https://github.com/ionic-team/ionic-v3) -->
[x] **4.4.2** (@ionic/angular)

**Current behavior:**
<!-- Describe how the bug manifests. -->
When the ion-select-options are updated, the popover radio options aren't updated to reflect that.

**Expected behavior:**

I would expect the popover radio options to be updated to match the ion-select-options.

**Steps to reproduce:**
<!--  Please explain the steps required to duplicate the issue, especially if you are able to provide a sample application. -->
On this occasion I am using ion-select in a header component to present a list of languages. When a user logs in, they may not have the full array of languages available to then you the list is updated. I can see that in the HTML markup that the ion-select-options are updated but the ion-items in the popover aren't.

**Related code:**

<!-- If you are able to illustrate the bug or feature request with an example, please provide a sample application via one of the following means:

A sample application via GitHub

StackBlitz (https://stackblitz.com)

Plunker (http://plnkr.co/edit/cpeRJs?p=preview)

-->


**header-bar.component.html**
```
<ion-header>
  <ion-toolbar>
    <ion-buttons>
      <ion-select *ngIf=""(router.url === '/' && languagesRadioGroup.length > 1) || (router.url === '/log-in' && languagesRadioGroup.length > 1) || (global.session.activeUser.languages.length > 1)"" interface=""popover"" placeholder=""{{ 'labels.language' | translate }}"" [(ngModel)]=""global.currentLanguage"" (ionChange)=""selectLanguage($event)"">
        <ion-select-option *ngFor=""let language of languagesRadioGroup"" value=""{{language.value}}"">{{language.label}}</ion-select-option>
      </ion-select>
    </ion-buttons>
  </ion-toolbar>
</ion-header>
```

**log-in.page.html** and **home.page.html**
```
<app-header-bar [languagesRadioGroup]=""global.languagesRadioGroup""></app-header-bar>
```

**global.service.ts** (imported into each page)
```
this.languages = [
  {
    label: 'English',
    value: 'en'
  },
  {
    label: 'Deutsche',
    value: 'de'
  },
  {
    label: 'Español',
    value: 'es'
  },
  {
    label: 'Français',
    value: 'fr'
  },
  {
    label: 'Italiano',
    value: 'it'
  },
  {
    label: 'Nederlands',
    value: 'nl'
  }
]

this._session = {
  ""activeLanguage"":""en"",
  ""activeUser"":{
    ""languages"":[""en"",""es""],
    ""countries"":[""GB""],
    ""defaults"":{""language"":""en"",""country"":""GB""}
  },
  ""activeCountry"":""""
}

public loadLanguages() {
    this.languagesRadioGroup = [];
    return new Promise((resolve) => {
      if (!(this._session.activeUser === undefined || this._session.activeUser.languages === undefined)) {
        for (let i = 0; i < this.languages.length; i++) {
          const language = this.languages[i];
          let defaultLanguage;
          if (this._session.activeUser.languages.includes(this._session.activeLanguage)) {
            defaultLanguage = this._session.activeLanguage;
            this.currentLanguage = this._session.activeLanguage;
          } else {
            defaultLanguage = this._session.activeUser.defaults.language;
            this.currentLanguage = this._session.activeUser.defaults.language;
          }
          if (this._session.activeUser.languages.includes(language.value)) {
            language.name = 'language' + i;
            language.type = 'radio';
            if (language.value === defaultLanguage) {
              language.checked = true;
            } else {
              language.checked = false;
            }
            this.languagesRadioGroup.push(language);
          }

          if (i === (this.languages.length - 1)) {
            resolve(this.languagesRadioGroup);
          }
        }
      } else {
        for (let i = 0; i < this.languages.length; i++) {
          const language = this.languages[i];
          language.name = 'language' + i;
          language.type = 'radio';
          this.languagesRadioGroup.push(language);

          if (i === (this.languages.length - 1)) {
            resolve(this.languagesRadioGroup);
          }
        }
      }
    });
  }
```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:**
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
Ionic:

   Ionic CLI                     : 5.0.2 (C:\Users\xxxxxx\AppData\Roaming\nvm\v12.4.0\node_modules\ionic)
   Ionic Framework               : @ionic/angular 4.4.2
   @angular-devkit/build-angular : 0.12.4
   @angular-devkit/schematics    : 7.2.4
   @angular/cli                  : 7.3.9
   @ionic/angular-toolkit        : 1.2.3

Cordova:

   Cordova CLI       : 8.1.2 (cordova-lib@8.1.1)
   Cordova Platforms : android 7.1.4, browser 5.0.4
   Cordova Plugins   : cordova-plugin-ionic-keyboard 2.1.3, cordova-plugin-ionic-webview 4.0.1, (and 17 other plugins)

Utility:

   cordova-res : not installed
   native-run  : 0.2.3

System:

   Android SDK Tools : 26.1.1 (C:\Users\xxxxxx\AppData\Local\Android\Sdk)
   NodeJS            : v12.4.0 (C:\Program Files\nodejs\node.exe)
   npm               : 6.9.0
   OS                : Windows 10
```",How are you updating the `languagesRadioGroup ` array?,"**header-bar.component.html**
            
    </ion-buttons>
  </ion-toolbar>
</ion-header>
```

**log-in.page.html**
```
<app-header-bar [languagesRadioGroup]=""global.languagesRadioGroup""></app-header-bar>
```

**home.page.html**
```
<app-header-bar [languagesRadioGroup]=""global.languagesRadioGroup""></app-header-bar>
```

**global.service.ts** (imported into each page)
```
this._session = {
  ""activeLanguage"":""en"",
  ""activeUser"":{
    ""languages"":[""en"",""es""],
    ""countries"":[""GB""],
    ""defaults"":{""language"":""en"",""country"":""GB""}
  },
  ""activeCountry"":""""
}

public loadLanguages() {
    this.languagesRadioGroup = [];
    return new Promise((resolve) => {
      if (!(this._session.activeUser === undefined || this._session.activeUser.languages === undefined)) {
        for (let i = 0; i < this.languages.length; i++) {
          const language = this.languages[i];
          let defaultLanguage;
          if (this._session.activeUser.languages.includes(this._session.activeLanguage)) {
            defaultLanguage = this._session.activeLanguage;
            this.currentLanguage = this._session.activeLanguage;
          } else {
            defaultLanguage = this._session.activeUser.defaults.language;
            this.currentLanguage = this._session.activeUser.defaults.language;
          }
          if (this._session.activeUser.languages.includes(language.value)) {
            language.name = 'language' + i;
            language.type = 'radio';
            if (language.value === defaultLanguage) {
              language.checked = true;
            } else {
              language.checked = false;
            }
            this.languagesRadioGroup.push(language);
          }

          if (i === (this.languages.length - 1)) {
            resolve(this.languagesRadioGroup);
          }
        }
      } else {
        for (let i = 0; i < this.languages.length; i++) {
          const language = this.languages[i];
          language.name = 'language' + i;
          language.type = 'radio';
          this.languagesRadioGroup.push(language);

          if (i === (this.languages.length - 1)) {
            resolve(this.languagesRadioGroup);
          }
        }
      }
    });
  }"
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/20381,ionic-team_ionic_issues_20381,"bug: ion-segment and ion-segment-button href not working

# Bug Report

**Ionic version:**
[x] **5.x**

**Current behavior:**
when using the ion-segments with href navigation doesn't work. as a workaround, I wrapped  ion-segment-button with <a [routerLink] = ""..."" </a> and used   [routerLinkActive]= ""..."" in  ion-segment-button. 
This worked fine in V 4 but is now broken
I need the links for SEO so (ionChaneg)  won't do the trick

**Expected behavior:**
should be able to navigate and determine active segment based on url e.g. 
https://cubesolver.app/tabs/guide/advanced/pll/f should go to the right page and mark ""Advanced"", ""PLL"", and ""f"" segments as active (the link above is to a working V4

 

**Steps to reproduce:**
see code example below...

**Related code:**

```
<ion-segment [(ngModel)]=""segment""  >
  <a [routerLink]=""'/tabs/guide/using'"" >
    <ion-segment-button  value=""using"" [routerLinkActive]=""'segment-button-checked segment-activated'"" >
      <div class=""container icon-container"">
        <div class=""sprite-png sprite-png-custom""></div>
      </div>
      <div class=""container text-container"">Using</div>
    </ion-segment-button>
  </a>

  <a [routerLink]=""'/tabs/guide/solving'"">
    <ion-segment-button value=""solving""   [routerLinkActive]=""'segment-button-checked segment-activated'"" >
      <div class=""container icon-container"">
        <div class=""sprite-png sprite-png-solve""></div>
      </div>
      <div class=""container text-container"">Solving</div>
    </ion-segment-button>
  </a>
  <a [routerLink]=""'/tabs/guide/advanced'"">
    <ion-segment-button value=""f2l""   [routerLinkActive]=""'segment-button-checked segment-activated'"">
      <div class=""container icon-container"">
        <div class=""sprite-png sprite-png-advanced""></div>
      </div>
      <div class=""container text-container"">Advanced</div>
    </ion-segment-button>
  </a>
</ion-segment>
```

<!-- If you are able to illustrate the bug or feature request with an example, please provide a sample application via one of the following means:

A sample application via GitHub

StackBlitz (https://stackblitz.com)
Ionic Angular StackBlitz: https://stackblitz.com/edit/ionic-v4-angular-tabs

Plunker (http://plnkr.co/edit/cpeRJs?p=preview)

-->

```
insert short code snippets here
```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:**
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
insert the output from ionic info here
```",Can you clarify the issue you are running into? I am seeing that navigation using routerLink on the site you included in the description.,"```
insert short code snippets here
```"
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/20473,ionic-team_ionic_issues_20473,"bug: ion-segment mode=""md"" 

<!-- Before submitting an issue, please consult our docs (https://ionicframework.com/docs/). -->

<!-- Please make sure you are posting an issue pertaining to the Ionic Framework. If you are having an issue with the Ionic Appflow services (Ionic View, Ionic Deploy, etc.) please consult the Ionic Appflow support portal (https://ionic.zendesk.com/hc/en-us) -->

<!-- Please do not submit support requests or ""How to"" questions here. Instead, please use one of these channels: https://forum.ionicframework.com/ or http://ionicworldwide.herokuapp.com/ -->

<!-- ISSUES MISSING IMPORTANT INFORMATION MAY BE CLOSED WITHOUT INVESTIGATION. -->

# Bug Report

**Ionic version:**
<!-- (For Ionic 1.x issues, please use https://github.com/ionic-team/ionic-v1) -->
<!-- (For Ionic 2.x & 3.x issues, please use https://github.com/ionic-team/ionic-v3) -->
[x] **5.x**

**Current behavior:**
<!-- Describe how the bug manifests. -->
The default segment (as set via code/model) when the ion-segment mode is explicitly set to md (mode=""md"") doesn't appear selected. Everything appears to work when the mode is not set or is set to ""ios"".

UPDATE: Same behavior on web and mobile devices

UPDATE: in some circumstances, the segments work the first time the screen is opened but then in subsequent openings the segments don't work.  

UPDATE: it appears that the style ""segment-button-checked"" is not being set

**Expected behavior:**
<!-- Describe what the behavior would be without the bug. -->
The default segment is selected

**Steps to reproduce:**
<!--  Please explain the steps required to duplicate the issue, especially if you are able to provide a sample application. -->


**Related code:**

<!-- If you are able to illustrate the bug or feature request with an example, please provide a sample application via one of the following means:

A sample application via GitHub

StackBlitz (https://stackblitz.com)
Ionic Angular StackBlitz: https://stackblitz.com/edit/ionic-v4-angular-tabs

Plunker (http://plnkr.co/edit/cpeRJs?p=preview)

-->

```
<ion-segment [(ngModel)]=""courseDetailSegment"" mode=""md"">
    <ion-segment-button value=""detail"">
      <ion-label>Details</ion-label>
    </ion-segment-button>
    <ion-segment-button value=""tees"">
      <ion-label>Tees</ion-label>
    </ion-segment-button>
</ion-segment>
```

**Other information:**
<!-- List any other information that is relevant to your issue. Stack traces, related issues, suggestions on how to fix, Stack Overflow links, forum links, etc. -->

**Ionic info:**
<!-- (run `ionic info` from a terminal/cmd prompt and paste output below): -->

```
There is no output or error messages
```",What is the value of `courseDetailSegment`?,UPDATE: Same behavior on web and mobile devices
ionic-team/ionic,https://github.com/ionic-team/ionic/issues/20769,ionic-team_ionic_issues_20769,"bug: App hangs on white screen after splash screen on devices and emulator

Ionic version: 5.0.3

The app hangs on a white screen after the splash screen (iOS and android). The debugger console gives no relevant information, however, I notice that in the Dom, app-root is empty. Sometimes, there is a 404 on all Javascript files, but that doesn’t seem to be consistent throughout all the changes I’ve made. The project works when running the emulator with live reload.
The project works fine when I run 'ionic serve'

Here is a repo that reproduces the issue
https://github.com/jplemieux66/ionic-blank-screen

Here is what I tried to fix this bug:

Followed the instructions on this link (in the white screen section):
https://ionicframework.com/docs/v3/wkwebview/

Tried the solutions mentioned in this issue:
https://github.com/ionic-team/cordova-plugin-ionic-webview/issues/95

Tried downgrading Cordova to 8.1.1
Tried downgrading Ionic CLI to 5.1.4
Tried removing all Cordova plugins and building again

**Other information:**
Dependencies:
""dependencies"": {
    ""@angular/animations"": ""9.0.3"",
    ""@angular/common"": ""9.0.3"",
    ""@angular/core"": ""9.0.3"",
    ""@angular/forms"": ""9.0.3"",
    ""@angular/platform-browser"": ""9.0.3"",
    ""@angular/platform-browser-dynamic"": ""9.0.3"",
    ""@angular/router"": ""9.0.3"",
    ""@ionic-native/clipboard"": ""5.22.0"",
    ""@ionic-native/core"": ""5.22.0"",
    ""@ionic-native/in-app-browser"": ""5.22.0"",
    ""@ionic-native/screen-orientation"": ""5.22.0"",
    ""@ionic-native/splash-screen"": ""5.22.0"",
    ""@ionic-native/status-bar"": ""5.22.0"",
    ""@ionic/angular"": ""5.0.3"",
    ""@ngrx/effects"": ""8.6.0"",
    ""@ngrx/entity"": ""8.6.0"",
    ""@ngrx/store"": ""8.6.0"",
    ""@ngrx/store-devtools"": ""8.6.0"",
    ""@swimlane/ngx-datatable"": ""16.0.3"",
    ""angular-gridster2"": ""9.0.2"",
    ""angular-svg-icon"": ""9.0.0"",
    ""cordova-android"": ""8.1.0"",
    ""cordova-clipboard"": ""1.3.0"",
    ""cordova-ios"": ""5.1.1"",
    ""cordova-ios-plugin-no-export-compliance"": ""~0.0.5"",
    ""cordova-plugin-device"": ""2.0.3"",
    ""cordova-plugin-inappbrowser"": ""3.2.0"",
    ""cordova-plugin-intercom"": ""^8.0.0"",
    ""cordova-plugin-ionic-keyboard"": ""2.2.0"",
    ""cordova-plugin-screen-orientation"": ""3.0.2"",
    ""cordova-plugin-splashscreen"": ""5.0.3"",
    ""cordova-plugin-statusbar"": ""2.4.3"",
    ""cordova-plugin-whitelist"": ""1.3.4"",
    ""core-js"": ""2.5.4"",
    ""d3"": ""5.0.0"",
    ""es6-promise-plugin"": ""4.2.2"",
    ""javascript-time-ago"": ""2.0.1"",
    ""logrocket"": ""1.0.6"",
    ""moment"": ""2.24.0"",
    ""moment-timezone"": ""0.5.26"",
    ""ng-intercom"": ""8.0.2"",
    ""ngx-avatar"": ""3.7.0"",
    ""ngx-infinite-scroll"": ""8.0.0"",
    ""ngx-spinner"": ""8.0.3"",
    ""ngx-stripe"": ""7.4.4"",
    ""ngx-toastr"": ""^12.0.0"",
    ""ngx-toggle-switch"": ""2.0.5"",
    ""normalize.css"": ""8.0.1"",
    ""prettier"": ""1.19.1"",
    ""prettier-tslint"": ""0.4.2"",
    ""resize-observer-polyfill"": ""1.5.1"",
    ""rollbar"": ""2.8.1"",
    ""rxjs"": ""6.5.4"",
    ""sancronos-validator"": ""1.2.0"",
    ""save-svg-as-png"": ""1.4.14"",
    ""tslib"": ""1.11.0"",
    ""zone.js"": ""0.10.2""
  },
  ""devDependencies"": {
    ""@angular-builders/custom-webpack"": ""^8.4.0"",
    ""@angular-devkit/architect"": ""0.900.3"",
    ""@angular-devkit/build-angular"": ""0.900.3"",
    ""@angular-devkit/core"": ""9.0.3"",
    ""@angular-devkit/schematics"": ""9.0.3"",
    ""@angular/cli"": ""9.0.3"",
    ""@angular/compiler"": ""9.0.3"",
    ""@angular/compiler-cli"": ""9.0.3"",
    ""@angular/language-service"": ""9.0.3"",
    ""@ionic/angular-toolkit"": ""2.2.0"",
    ""@ngrx/schematics"": ""8.6.0"",
    ""@types/d3"": ""5.0.0"",
    ""@types/jasmine"": ""2.8.8"",
    ""@types/jasminewd2"": ""2.0.3"",
    ""@types/moment-timezone"": ""^0.5.12"",
    ""@types/node"": ""12.0.0"",
    ""codelyzer"": ""5.1.0"",
    ""jasmine-core"": ""2.99.1"",
    ""jasmine-spec-reporter"": ""4.2.1"",
    ""karma"": ""4.1.0"",
    ""karma-chrome-launcher"": ""2.2.0"",
    ""karma-coverage-istanbul-reporter"": ""2.0.1"",
    ""karma-jasmine"": ""1.1.2"",
    ""karma-jasmine-html-reporter"": ""0.2.2"",
    ""protractor"": ""5.4.0"",
    ""ts-node"": ""8.3.0"",
    ""tslint"": ""5.17.0"",
    ""typescript"": ""3.7.5""
  }

Config.xml:
```xml
<?xml version='1.0' encoding='utf-8'?>
<widget id=""xxxxxx"" version=""2.2.0"" xmlns=""http://www.w3.org/ns/widgets"" xmlns:cdv=""http://cordova.apache.org/ns/1.0"">
    <name>Example</name>
    <description>Example</description>
    <content src=""index.html"" />
    <access origin=""*"" />
    <allow-navigation href=""https://*youtube.com/*"" />
    <allow-intent href=""http://*/*"" />
    <allow-intent href=""https://*/*"" />
    <allow-intent href=""tel:*"" />
    <allow-intent href=""sms:*"" />
    <allow-intent href=""mailto:*"" />
    <allow-intent href=""geo:*"" />
    <preference name=""ScrollEnabled"" value=""false"" />
    <preference name=""android-minSdkVersion"" value=""21"" />
    <preference name=""BackupWebStorage"" value=""none"" />
    <preference name=""SplashMaintainAspectRatio"" value=""true"" />
    <preference name=""FadeSplashScreenDuration"" value=""300"" />
    <preference name=""SplashShowOnlyFirstTime"" value=""false"" />
    <preference name=""SplashScreen"" value=""screen"" />
    <preference name=""SplashScreenDelay"" value=""3000"" />
    <preference name=“intercom-app-id” value=“xxxxxx” />
    <preference name=“intercom-ios-api-key” value=“ios_sdk-xxxxxx” />
    <preference name=“intercom-android-api-key” value=“android_sdk-xxxxxx” />
    <preference name=""CordovaWebViewEngine"" value=""CDVUIWebViewEngine"" />
    <platform name=""android"">
        <edit-config file=""app/src/main/AndroidManifest.xml"" mode=""merge"" target=""/manifest/application"" xmlns:android=""http://schemas.android.com/apk/res/android"">
            <application android:networkSecurityConfig=""@xml/network_security_config"" />
        </edit-config>
        <resource-file src=""resources/android/xml/network_security_config.xml"" target=""app/src/main/res/xml/network_security_config.xml"" />
        <allow-intent href=""market:*"" />
        <icon density=""ldpi"" src=""resources/android/icon/drawable-ldpi-icon.png"" />
        <icon density=""mdpi"" src=""resources/android/icon/drawable-mdpi-icon.png"" />
        <icon density=""hdpi"" src=""resources/android/icon/drawable-hdpi-icon.png"" />
        <icon density=""xhdpi"" src=""resources/android/icon/drawable-xhdpi-icon.png"" />
        <icon density=""xxhdpi"" src=""resources/android/icon/drawable-xxhdpi-icon.png"" />
        <icon density=""xxxhdpi"" src=""resources/android/icon/drawable-xxxhdpi-icon.png"" />
        <splash density=""land-ldpi"" src=""resources/android/splash/drawable-land-ldpi-screen.png"" />
        <splash density=""land-mdpi"" src=""resources/android/splash/drawable-land-mdpi-screen.png"" />
        <splash density=""land-hdpi"" src=""resources/android/splash/drawable-land-hdpi-screen.png"" />
        <splash density=""land-xhdpi"" src=""resources/android/splash/drawable-land-xhdpi-screen.png"" />
        <splash density=""land-xxhdpi"" src=""resources/android/splash/drawable-land-xxhdpi-screen.png"" />
        <splash density=""land-xxxhdpi"" src=""resources/android/splash/drawable-land-xxxhdpi-screen.png"" />
        <splash density=""port-ldpi"" src=""resources/android/splash/drawable-port-ldpi-screen.png"" />
        <splash density=""port-mdpi"" src=""resources/android/splash/drawable-port-mdpi-screen.png"" />
        <splash density=""port-hdpi"" src=""resources/android/splash/drawable-port-hdpi-screen.png"" />
        <splash density=""port-xhdpi"" src=""resources/android/splash/drawable-port-xhdpi-screen.png"" />
        <splash density=""port-xxhdpi"" src=""resources/android/splash/drawable-port-xxhdpi-screen.png"" />
        <splash density=""port-xxxhdpi"" src=""resources/android/splash/drawable-port-xxxhdpi-screen.png"" />
    </platform>
    <platform name=""ios"">
        <allow-intent href=""itms:*"" />
        <allow-intent href=""itms-apps:*"" />
        <icon height=""57"" src=""resources/ios/icon/icon.png"" width=""57"" />
        <icon height=""114"" src=""resources/ios/icon/icon@2x.png"" width=""114"" />
        <icon height=""29"" src=""resources/ios/icon/icon-small.png"" width=""29"" />
        <icon height=""58"" src=""resources/ios/icon/icon-small@2x.png"" width=""58"" />
        <icon height=""87"" src=""resources/ios/icon/icon-small@3x.png"" width=""87"" />
        <icon height=""20"" src=""resources/ios/icon/icon-20.png"" width=""20"" />
        <icon height=""40"" src=""resources/ios/icon/icon-20@2x.png"" width=""40"" />
        <icon height=""60"" src=""resources/ios/icon/icon-20@3x.png"" width=""60"" />
        <icon height=""48"" src=""resources/ios/icon/icon-24@2x.png"" width=""48"" />
        <icon height=""55"" src=""resources/ios/icon/icon-27.5@2x.png"" width=""55"" />
        <icon height=""29"" src=""resources/ios/icon/icon-29.png"" width=""29"" />
        <icon height=""58"" src=""resources/ios/icon/icon-29@2x.png"" width=""58"" />
        <icon height=""87"" src=""resources/ios/icon/icon-29@3x.png"" width=""87"" />
        <icon height=""40"" src=""resources/ios/icon/icon-40.png"" width=""40"" />
        <icon height=""80"" src=""resources/ios/icon/icon-40@2x.png"" width=""80"" />
        <icon height=""120"" src=""resources/ios/icon/icon-40@3x.png"" width=""120"" />
        <icon height=""88"" src=""resources/ios/icon/icon-44@2x.png"" width=""88"" />
        <icon height=""50"" src=""resources/ios/icon/icon-50.png"" width=""50"" />
        <icon height=""100"" src=""resources/ios/icon/icon-50@2x.png"" width=""100"" />
        <icon height=""60"" src=""resources/ios/icon/icon-60.png"" width=""60"" />
        <icon height=""120"" src=""resources/ios/icon/icon-60@2x.png"" width=""120"" />
        <icon height=""180"" src=""resources/ios/icon/icon-60@3x.png"" width=""180"" />
        <icon height=""72"" src=""resources/ios/icon/icon-72.png"" width=""72"" />
        <icon height=""144"" src=""resources/ios/icon/icon-72@2x.png"" width=""144"" />
        <icon height=""76"" src=""resources/ios/icon/icon-76.png"" width=""76"" />
        <icon height=""152"" src=""resources/ios/icon/icon-76@2x.png"" width=""152"" />
        <icon height=""167"" src=""resources/ios/icon/icon-83.5@2x.png"" width=""167"" />
        <icon height=""172"" src=""resources/ios/icon/icon-86@2x.png"" width=""172"" />
        <icon height=""196"" src=""resources/ios/icon/icon-98@2x.png"" width=""196"" />
        <icon height=""1024"" src=""resources/ios/icon/icon-1024.png"" width=""1024"" />
        <splash height=""480"" src=""resources/ios/splash/Default~iphone.png"" width=""320"" />
        <splash height=""960"" src=""resources/ios/splash/Default@2x~iphone.png"" width=""640"" />
        <splash height=""1024"" src=""resources/ios/splash/Default-Portrait~ipad.png"" width=""768"" />
        <splash height=""768"" src=""resources/ios/splash/Default-Landscape~ipad.png"" width=""1024"" />
        <splash height=""1125"" src=""resources/ios/splash/Default-Landscape-2436h.png"" width=""2436"" />
        <splash height=""1242"" src=""resources/ios/splash/Default-Landscape-736h.png"" width=""2208"" />
        <splash height=""2048"" src=""resources/ios/splash/Default-Portrait@2x~ipad.png"" width=""1536"" />
        <splash height=""1536"" src=""resources/ios/splash/Default-Landscape@2x~ipad.png"" width=""2048"" />
        <splash height=""2732"" src=""resources/ios/splash/Default-Portrait@~ipadpro.png"" width=""2048"" />
        <splash height=""2048"" src=""resources/ios/splash/Default-Landscape@~ipadpro.png"" width=""2732"" />
        <splash height=""1136"" src=""resources/ios/splash/Default-568h@2x~iphone.png"" width=""640"" />
        <splash height=""1334"" src=""resources/ios/splash/Default-667h.png"" width=""750"" />
        <splash height=""2208"" src=""resources/ios/splash/Default-736h.png"" width=""1242"" />
        <splash height=""2436"" src=""resources/ios/splash/Default-2436h.png"" width=""1125"" />
        <splash height=""2732"" src=""resources/ios/splash/Default@2x~universal~anyany.png"" width=""2732"" />
        <icon height=""216"" src=""resources/ios/icon/icon-108@2x.png"" width=""216"" />
        <splash height=""2688"" src=""resources/ios/splash/Default-2688h~iphone.png"" width=""1242"" />
        <splash height=""1242"" src=""resources/ios/splash/Default-Landscape-2688h~iphone.png"" width=""2688"" />
        <splash height=""1792"" src=""resources/ios/splash/Default-1792h~iphone.png"" width=""828"" />
        <splash height=""828"" src=""resources/ios/splash/Default-Landscape-1792h~iphone.png"" width=""1792"" />
    </platform>
    <allow-navigation href=""http://localhost:8100"" sessionid=""dd66d80a"" />
    <allow-navigation href=""http://localhost:8080/*"" />
    <plugin name=""cordova-plugin-intercom"" spec=""^8.0.0"" />
    <plugin name=""cordova-plugin-splashscreen"" spec=""~5.0.3"" />
    <plugin name=""cordova-clipboard"" spec=""~1.3.0"" />
    <plugin name=""cordova-ios-plugin-no-export-compliance"" spec=""~0.0.5"" />
    <config-file parent=""UIUserInterfaceStyle"" platform=""ios"" target=""*-Info.plist"">
        <string>Light</string>
    </config-file>
    <engine name=""android"" spec=""^8.1.0"" />
    <engine name=""ios"" spec=""^5.1.1"" />
</widget>
```

**Ionic info:**

Ionic:

   Ionic CLI                     : 6.1.0 (/usr/local/lib/node_modules/@ionic/cli)
   Ionic Framework               : @ionic/angular 5.0.3
   @angular-devkit/build-angular : 0.900.3
   @angular-devkit/schematics    : 9.0.3
   @angular/cli                  : 9.0.3
   @ionic/angular-toolkit        : 2.2.0

Cordova:

   Cordova CLI       : 9.0.0 (cordova-lib@9.0.1)
   Cordova Platforms : ios 5.1.1
   Cordova Plugins   : cordova-plugin-ionic-keyboard 2.2.0, (and 9 other plugins)

Utility:

   cordova-res                          : 0.10.0
   native-run (update available: 0.3.0) : 0.2.9

System:

   ios-sim : 8.0.2
   NodeJS  : v12.16.1 (/usr/local/bin/node)
   npm     : 6.13.4
   OS      : macOS Catalina
   Xcode   : Xcode 11.3.1 Build version 11C504",Can you provide a repo with the code required to reproduce this issue?,"The project works fine when I run 'ionic serve'


Config.xml:
<?xml version='1.0' encoding='utf-8'?>
<widget id=""com.obkio.app"" version=""2.2.0"" xmlns=""http://www.w3.org/ns/widgets"" xmlns:cdv=""http://cordova.apache.org/ns/1.0"">
    <name>Obkio</name>
    <description>Obkio Performance Monitoring App</description>
    <author email=""support@obkio.com"" href=""https://obkio.com/"">Obkio Team</author>
    <content src=""index.html"" />
    <access origin=""*"" />
    <allow-navigation href=""https://*youtube.com/*"" />
    <allow-intent href=""http://*/*"" />
    <allow-intent href=""https://*/*"" />
    <allow-intent href=""tel:*"" />
    <allow-intent href=""sms:*"" />
    <allow-intent href=""mailto:*"" />
    <allow-intent href=""geo:*"" />
    <preference name=""ScrollEnabled"" value=""false"" />
    <preference name=""android-minSdkVersion"" value=""21"" />
    <preference name=""BackupWebStorage"" value=""none"" />
    <preference name=""SplashMaintainAspectRatio"" value=""true"" />
    <preference name=""FadeSplashScreenDuration"" value=""300"" />
    <preference name=""SplashShowOnlyFirstTime"" value=""false"" />
    <preference name=""SplashScreen"" value=""screen"" />
    <preference name=""SplashScreenDelay"" value=""3000"" />
    <preference name=""intercom-app-id"" value=""clbytz3j"" />
    <preference name=""intercom-ios-api-key"" value=""ios_sdk-69f084d503f4e4786e9661016bd9a57b9d9d851c"" />
    <preference name=""intercom-android-api-key"" value=""android_sdk-38593e29d5392f77e14adb5be1b53695f476a5b0"" />
    <preference name=""CordovaWebViewEngine"" value=""CDVUIWebViewEngine"" />
    <platform name=""android"">
        <edit-config file=""app/src/main/AndroidManifest.xml"" mode=""merge"" target=""/manifest/application"" xmlns:android=""http://schemas.android.com/apk/res/android"">
            <application android:networkSecurityConfig=""@xml/network_security_config"" />
        </edit-config>
        <resource-file src=""resources/android/xml/network_security_config.xml"" target=""app/src/main/res/xml/network_security_config.xml"" />
        <allow-intent href=""market:*"" />
        <icon density=""ldpi"" src=""resources/android/icon/drawable-ldpi-icon.png"" />
        <icon density=""mdpi"" src=""resources/android/icon/drawable-mdpi-icon.png"" />
        <icon density=""hdpi"" src=""resources/android/icon/drawable-hdpi-icon.png"" />
        <icon density=""xhdpi"" src=""resources/android/icon/drawable-xhdpi-icon.png"" />
        <icon density=""xxhdpi"" src=""resources/android/icon/drawable-xxhdpi-icon.png"" />
        <icon density=""xxxhdpi"" src=""resources/android/icon/drawable-xxxhdpi-icon.png"" />
        <splash density=""land-ldpi"" src=""resources/android/splash/drawable-land-ldpi-screen.png"" />
        <splash density=""land-mdpi"" src=""resources/android/splash/drawable-land-mdpi-screen.png"" />
        <splash density=""land-hdpi"" src=""resources/android/splash/drawable-land-hdpi-screen.png"" />
        <splash density=""land-xhdpi"" src=""resources/android/splash/drawable-land-xhdpi-screen.png"" />
        <splash density=""land-xxhdpi"" src=""resources/android/splash/drawable-land-xxhdpi-screen.png"" />
        <splash density=""land-xxxhdpi"" src=""resources/android/splash/drawable-land-xxxhdpi-screen.png"" />
        <splash density=""port-ldpi"" src=""resources/android/splash/drawable-port-ldpi-screen.png"" />
        <splash density=""port-mdpi"" src=""resources/android/splash/drawable-port-mdpi-screen.png"" />
        <splash density=""port-hdpi"" src=""resources/android/splash/drawable-port-hdpi-screen.png"" />
        <splash density=""port-xhdpi"" src=""resources/android/splash/drawable-port-xhdpi-screen.png"" />
        <splash density=""port-xxhdpi"" src=""resources/android/splash/drawable-port-xxhdpi-screen.png"" />
        <splash density=""port-xxxhdpi"" src=""resources/android/splash/drawable-port-xxxhdpi-screen.png"" />
    </platform>
    <platform name=""ios"">
        <allow-intent href=""itms:*"" />
        <allow-intent href=""itms-apps:*"" />
        <icon height=""57"" src=""resources/ios/icon/icon.png"" width=""57"" />
        <icon height=""114"" src=""resources/ios/icon/icon@2x.png"" width=""114"" />
        <icon height=""29"" src=""resources/ios/icon/icon-small.png"" width=""29"" />
        <icon height=""58"" src=""resources/ios/icon/icon-small@2x.png"" width=""58"" />
        <icon height=""87"" src=""resources/ios/icon/icon-small@3x.png"" width=""87"" />
        <icon height=""20"" src=""resources/ios/icon/icon-20.png"" width=""20"" />
        <icon height=""40"" src=""resources/ios/icon/icon-20@2x.png"" width=""40"" />
        <icon height=""60"" src=""resources/ios/icon/icon-20@3x.png"" width=""60"" />
        <icon height=""48"" src=""resources/ios/icon/icon-24@2x.png"" width=""48"" />
        <icon height=""55"" src=""resources/ios/icon/icon-27.5@2x.png"" width=""55"" />
        <icon height=""29"" src=""resources/ios/icon/icon-29.png"" width=""29"" />
        <icon height=""58"" src=""resources/ios/icon/icon-29@2x.png"" width=""58"" />
        <icon height=""87"" src=""resources/ios/icon/icon-29@3x.png"" width=""87"" />
        <icon height=""40"" src=""resources/ios/icon/icon-40.png"" width=""40"" />
        <icon height=""80"" src=""resources/ios/icon/icon-40@2x.png"" width=""80"" />
        <icon height=""120"" src=""resources/ios/icon/icon-40@3x.png"" width=""120"" />
        <icon height=""88"" src=""resources/ios/icon/icon-44@2x.png"" width=""88"" />
        <icon height=""50"" src=""resources/ios/icon/icon-50.png"" width=""50"" />
        <icon height=""100"" src=""resources/ios/icon/icon-50@2x.png"" width=""100"" />
        <icon height=""60"" src=""resources/ios/icon/icon-60.png"" width=""60"" />
        <icon height=""120"" src=""resources/ios/icon/icon-60@2x.png"" width=""120"" />
        <icon height=""180"" src=""resources/ios/icon/icon-60@3x.png"" width=""180"" />
        <icon height=""72"" src=""resources/ios/icon/icon-72.png"" width=""72"" />
        <icon height=""144"" src=""resources/ios/icon/icon-72@2x.png"" width=""144"" />
        <icon height=""76"" src=""resources/ios/icon/icon-76.png"" width=""76"" />
        <icon height=""152"" src=""resources/ios/icon/icon-76@2x.png"" width=""152"" />
        <icon height=""167"" src=""resources/ios/icon/icon-83.5@2x.png"" width=""167"" />
        <icon height=""172"" src=""resources/ios/icon/icon-86@2x.png"" width=""172"" />
        <icon height=""196"" src=""resources/ios/icon/icon-98@2x.png"" width=""196"" />
        <icon height=""1024"" src=""resources/ios/icon/icon-1024.png"" width=""1024"" />
        <splash height=""480"" src=""resources/ios/splash/Default~iphone.png"" width=""320"" />
        <splash height=""960"" src=""resources/ios/splash/Default@2x~iphone.png"" width=""640"" />
        <splash height=""1024"" src=""resources/ios/splash/Default-Portrait~ipad.png"" width=""768"" />
        <splash height=""768"" src=""resources/ios/splash/Default-Landscape~ipad.png"" width=""1024"" />
        <splash height=""1125"" src=""resources/ios/splash/Default-Landscape-2436h.png"" width=""2436"" />
        <splash height=""1242"" src=""resources/ios/splash/Default-Landscape-736h.png"" width=""2208"" />
        <splash height=""2048"" src=""resources/ios/splash/Default-Portrait@2x~ipad.png"" width=""1536"" />
        <splash height=""1536"" src=""resources/ios/splash/Default-Landscape@2x~ipad.png"" width=""2048"" />
        <splash height=""2732"" src=""resources/ios/splash/Default-Portrait@~ipadpro.png"" width=""2048"" />
        <splash height=""2048"" src=""resources/ios/splash/Default-Landscape@~ipadpro.png"" width=""2732"" />
        <splash height=""1136"" src=""resources/ios/splash/Default-568h@2x~iphone.png"" width=""640"" />
        <splash height=""1334"" src=""resources/ios/splash/Default-667h.png"" width=""750"" />
        <splash height=""2208"" src=""resources/ios/splash/Default-736h.png"" width=""1242"" />
        <splash height=""2436"" src=""resources/ios/splash/Default-2436h.png"" width=""1125"" />
        <splash height=""2732"" src=""resources/ios/splash/Default@2x~universal~anyany.png"" width=""2732"" />
        <icon height=""216"" src=""resources/ios/icon/icon-108@2x.png"" width=""216"" />
        <splash height=""2688"" src=""resources/ios/splash/Default-2688h~iphone.png"" width=""1242"" />
        <splash height=""1242"" src=""resources/ios/splash/Default-Landscape-2688h~iphone.png"" width=""2688"" />
        <splash height=""1792"" src=""resources/ios/splash/Default-1792h~iphone.png"" width=""828"" />
        <splash height=""828"" src=""resources/ios/splash/Default-Landscape-1792h~iphone.png"" width=""1792"" />
    </platform>
    <allow-navigation href=""http://localhost:8100"" sessionid=""dd66d80a"" />
    <allow-navigation href=""http://localhost:8080/*"" />
    <plugin name=""cordova-plugin-intercom"" spec=""^8.0.0"" />
    <plugin name=""cordova-plugin-splashscreen"" spec=""~5.0.3"" />
    <plugin name=""cordova-clipboard"" spec=""~1.3.0"" />
    <plugin name=""cordova-ios-plugin-no-export-compliance"" spec=""~0.0.5"" />
    <config-file parent=""UIUserInterfaceStyle"" platform=""ios"" target=""*-Info.plist"">
        <string>Light</string>
    </config-file>
    <engine name=""android"" spec=""^8.1.0"" />
    <engine name=""ios"" spec=""^5.1.1"" />
</widget>"
home-assistant/core,https://github.com/home-assistant/core/issues/23704,home-assistant_core_issues_23704,"Problems controlling Flux Led Smart Lights through Homeassistant

**Home Assistant release with the issue:**
`0.92.2`

**Operating environment (Hass.io/Docker/Windows/etc.):**
`Hass.io`
`Raspbian GNU/Linux 9 (stretch)`
`Linux raspberrypi 4.14.98-v7+ #1200 SMP Tue Feb 12 20:27:48 GMT 2019 armv7l GNU/Linux`
`Raspberry Pi 3 statel B 64bit`

**Component/platform:**
`light`
https://www.home-assistant.io/components/flux_led/

**Description of problem:**
Ever since I bought ""Flux Led Smart Bulb"" https://www.amazon.com/Flux-Bluetooth-LED-Smart-Bulb/dp/B00GWBBZ2I I've been having issues controlling it through my Homeassistant. However, there was no problem utilizing the bulbs through an official app, or through Flux Light's Alexa/Google Home skill that would route requests over their servers (not Homeassistant). I didn't like later approach since my smart bulbs had to send data (and could potentially be controlled from) to some unknown remote server. 
That's why I configured them along with my Homeassistant instance, but right away I noticed that the lights could not be properly controlled through Homeassistant's Google Home component. 

For example, Flux Led Smart Bulb works in 3 states (RGBW, static Warm White, and static Cool White) where Warm White and Cool White states cannot be replicated using RGBW:
![image](https://user-images.githubusercontent.com/8620461/57188101-07ce0400-6ec7-11e9-8410-f6189bf8a236.png)
Warm white is essentially a ""normal incandescent"" color, that's separated from RGBW, the brightest possible level the light can operate in:
![image](https://user-images.githubusercontent.com/8620461/57188135-9a6ea300-6ec7-11e9-83bc-182a4fbffa99.png)

If you try to replicate the color in RGBW, it will be a much fainter color:
![image](https://user-images.githubusercontent.com/8620461/57188171-1f59bc80-6ec8-11e9-8e46-41e39d0308ba.png)

The main problem with controlling these lights through Homeassistant's Google Home component was that I could not set those 2 special states warm white and cool white. I started looking at the implementation of the component, and I realized that it is a simple wrapper around https://github.com/beville/flux_led utility (that's not an official API for Flux led, but rather a script ""reverse-engineered by studying packet captures between a bulb and the controlling mobile app""), so it does have its downsides.
Anyways, I started investigating how does `beville/flux_led` sets those 2 special states, and I found out the following. The script has a CLI interface that calls methods from `WifiLedBulb` class (the same class used in Homeassistant's flux_led component. And if I wanted to set bulbs to warm white state, I'd have to execute the following CLI command: `<script> --warmwhite=<level 1-100>`. Then I looked at the stack that this command evaluates, it calls `bulb.setWarmWhite(level=options.ww, ...)`, then calls a wrapper `self.setWarmWhite255(level=utils.percentToByte(level), ...)`, and then finally calls a method `self.setRgbw(r=None, g=None, b=None, w=level, brightness=None, w2=None, ...)`. 

As you can see, in order to activate warm white state, `rgb` values as well as `brightness` and `w2` should all be set to None. I played around with the script, and discovered the following:

1. In order to activate warm white state, all values *but* `w` should be `None`, while `w` can be between 0 and 255. If any other parameter is not `None`, the call will not result in *any action*

2. In order to activate cool white state, all values *but* `w2` should be `None`, while `w2` can be between 0 and 255. If any other parameter is not `None`, the call will not result in *any action*

3. In order to set lights to a particular RGB color (3rd state), `r`, `g`, `b` variables should be set to any value between 0 and 255, *while* `w` and `w2` variables must be set to `None`. However, `brightness` becomes an optional variable in RGB state, it can be `None`, but it also can be a value between 1 and 100, that will be used to calculate new rgb triplet:
```
# beville/flux_led
if brightness != None:
    (r, g, b) = self._calculateBrightness((r, g, b), brightness)
```
Ex., `(0,0,255)` with brightness set to `50` will result in a new triplet `(0,0,127)`.

After I finished investigating inner workings of `beville/flux_led` script, I switched back to Homeassistant's `flux_led` component to understand where does it fail to utilize the script in an intended way.

The entry point is `_turn_on` method in `flux_led.py` file. Where it calls internal `beville/flux_led` methods. Here is what I found:
```
if self._mode == MODE_RGBW:
    if white is None:
        self._bulb.setRgbw(*color_util.color_hsv_to_RGB(*color))
    else:
        self._bulb.setRgbw(w=white)
```
Where the first call `setRgbw(*color_util.color_hsv_to_RGB(*color))` (""rgbw"" state) falls under condition (3) from above i.e. `r`, `b`, `b` triplet is non-null and  `w=None`, `brightness=None`, `w2=None`. 
Then the second call `setRgbw(w=white)` (""warm-white state) falls under condition (1) from above i.e. `w` variable is non-null and `r=None`, `g=None`, `b=None`, `w=None`, `brightness=None`, `w2=None`.

Both calls work successfully, however there are two caveats:
1. There is no way in `flux_led` component to set a ""cold-white"" state i.e. condition listed under (2) where `w2` is non-null and `r=None`, `g=None`, `b=None`, `w=None`, `brightness=None`, `w=None`
2. You cannot set ""warm-white"" state from your smart speaker i.e. Google Home or Alexa. The problem is that if you ask them to ""set light to warm-white/cold-white"", homeassistant never sets ""white"" value `white = kwargs.get(ATTR_WHITE_VALUE)`, therefore `self._bulb.setRgbw(w=white)` never gets called. Instead, it passes warm-white as ` (29.6, 58.824)` hs_color that gets converted to RGB triplet, and then calls `setRgbw(*color_util.color_hsv_to_RGB(*color))`. And as I explained above, ""warm-white"" cannot be replicated using RGB.

As, you can see this confusion was caused by 3 mutually exclusive states that could not be handled properly by homeassistant.

Here is my proposal, create 2 special cases in `flux_led` component:
```
# Special case warm-white mode
if hs_color == (29.6, 58.824):
      # will eventually call `setRgbw(w=white)`
# Special case cool-white mode
else if hs_color == (60.0, 16.0):
     # will eventually call `setRgbw(w2=cool-white)`
```


I summon @Sidney @balloob to look at my report and consider a proposal.

Meanwhile, I'll create a PR and attach it under this issue.",Do you still get `hs_color` if you add `SUPPORT_COLOR_TEMP` to `SUPPORT_FLUX_LED` ?,"255. If any other parameter is not `None`, the call will not result in *any action*

2. In order to activate cool white state, all values *but* `w2` should be `None`, while `w2` can be between"
home-assistant/core,https://github.com/home-assistant/core/issues/34371,home-assistant_core_issues_34371,"Fail unit tests on I/O inside event loop

<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/core/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->
## The problem
<!-- 
  Describe the issue you are experiencing here to communicate to the
  maintainers. Tell us what you were trying to do and what happened.
-->
While developing https://github.com/home-assistant/core/pull/31240 I stumbled over this message:
```
2020-04-18 14:21:44 WARNING (MainThread) [homeassistant.util.async_] Detected I/O inside the event loop. This is causing stability issues. Please report issue for fritzbox doing I/O at homeassistant/components/fritzbox/binary_sensor.py, line 16: for device in fritz.get_devices():
```
Could and should this fail in the unit tests? This concrete message is not the problem, it's a general question.

## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant Core release with the issue: 
- Last working Home Assistant Core release (if known): 
- Operating environment (Home Assistant/Supervised/Docker/venv): 
- Integration causing this issue: 
- Link to integration documentation on our website: 

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->

```yaml

```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt

```

## Additional information",Should we have a label for integrations doing io inside the loop?,"This concrete message is not the problem, it's a general question."
home-assistant/core,https://github.com/home-assistant/core/issues/15362,home-assistant_core_issues_15362,"MQTT sensor fails to read if more then 255 characters in payload

**Home Assistant release with the issue:**
0.73

**Last working Home Assistant release (if known):**
??

**Operating environment (Hass.io/Docker/Windows/etc.):**
Hassio on raspberry pi 3b with embedded MQTT broker

**Component/platform:**
MQTT sensor


**Description of problem:**
If my JSON is 255 characters or less, the sensor works. If it is 256 characters or more, it just doesn't see the message at all. 


**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```
- platform: mqtt
  name: james_oneplus_5_info
  state_topic: 'zanzito/jamesop5/device_info'
  qos: 1
  json_attributes: 
    - time
    - device_info
    - charge_type
    - battery_charging
    - battery_level
    - current_foreground_app
    - screen_locked
    - screen_on
    - screen_orientation
    - current_wifi
    - current_operator
```

**Traceback (if applicable):**
```

2018-07-09 06:47:05 ERROR (MainThread) [homeassistant.core] Error doing job: Task exception was never retrieved
Traceback (most recent call last):
  File ""/usr/lib/python3.6/site-packages/homeassistant/helpers/entity.py"", line 279, in async_update_ha_state
    self.entity_id, state, attr, self.force_update)
  File ""/usr/lib/python3.6/site-packages/homeassistant/core.py"", line 757, in async_set
    state = State(entity_id, new_state, attributes, last_changed)
  File ""/usr/lib/python3.6/site-packages/homeassistant/core.py"", line 552, in __init__
    ""State max length is 255 characters."").format(entity_id))
homeassistant.exceptions.InvalidStateError: Invalid state encountered for entity id: sensor.james_oneplus_5_info. State max length is 255 characters.
```

**Additional information:**
E.g: the filtering is read in HA, but anything longer is not.

{""time"":1234567890,""device_info"":""A5000 (8.1.0)"",""charge_type"":""AC"",""battery_charging"":true,""battery_level"":79,""current_foreground_app"":""abc"",""screen_locked"":false,""screen_on"":true,""screen_orientation"":""Pt"",""current_wifi"":""\""Jan\"""",""current_operator"":""3""}

Using a n MQTT client and subscribing to the topic works ok, so I think the problem is with the HA MQTT sensor side of things, not the broker.",Could you please fill in your config and error log in issue template?,"**Traceback (if applicable):**
exception was never retrieved
Traceback"
home-assistant/core,https://github.com/home-assistant/core/issues/19128,home-assistant_core_issues_19128,"Google Assistant now exposes all devices

**Home Assistant release with the issue:**
0.83.3
**Last working Home Assistant release (if known):**
unsure

**Operating environment (Hass.io/Docker/Windows/etc.):**
hassio on hassos on pi 3b

**Component/platform:**
Google Assistant
**Description of problem:**
Google assistant no longer seems to respect expose_by_default: false

**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```
google_assistant:
  project_id: jamesking420fake
  api_key: NoTR3aLFak3y5sgTdbdfTWmAVsewhugrehger
  expose_by_default: false
  entity_config: !include configuration_files/google_assistant.yaml
```
google_assistant,yaml (heavily truncated but you get the idea!)
```
switch.my_pc:
  expose: true
  aliases:
    - the pc
    - the computer
    - my computer
```

**Traceback (if applicable):**

**Additional information:**
I did ""sync my devices"" on google home and now I have loads of stuff listed under the google home app, booleans, thermostats (which I don't need exposed via home asisstant), switches, scripts, lights which I haven't exposed deliberately.  I only wanted these specific devices in my list to be exposed.",Did you try directly including the entities without the `include` to ensure that the problem is not with the file? Just test it out with one entity.,"```
google_assistant,yaml (heavily truncated but you get the idea!)
```switch.my_pc:
  expose: true
  aliases:
    - the pc
    - the computer
    - my computer"
home-assistant/core,https://github.com/home-assistant/core/issues/17653,home-assistant_core_issues_17653,"apple tv 4k after change ip can't work

**Home Assistant release with the issue:**
0.81.6

**Last working Home Assistant release (if known):**
Never (In my experience)

**Operating environment (Hass.io/Docker/Windows/etc.):**
Ubuntu 18.04 server

**Component/platform:**
https://www.home-assistant.io/components/apple_tv/

**Description of problem:**
at firest,this plug working fine,after apple tv 4k reboot, the ip was change,so i write the right ip to config file and reboot ha service,the apple tv not working,then i try to resert my apple tv,also not working,but the homeassistant can find my tv in apple_tv_scan service
apple tv version: tvos12.0.1
python version:3.6.5

**Problem-relevant configuration.yaml entries and (fill out even if it seems unimportant):**
```
apple_tv:
  - host: 10.111.100.242
    login_id: xxxxxx-xxx-xxxx-xxxx-xxxxx
    credentials:xxxxxxxxxxxxx
```
**Traceback (if applicable):**
```
Oct 21 10:55:32 hp-gen8 hass[47431]: 2018-10-21 10:55:32 ERROR (MainThread) [homeassistant.core] Error doing job: Task exception was never retrieved
Oct 21 10:55:32 hp-gen8 hass[47431]: Traceback (most recent call last):
Oct 21 10:55:32 hp-gen8 hass[47431]:   File ""/srv/homeassistant/homeassistant_venv/lib/python3.6/site-packages/homeassistant/helpers/entity_platform.py"", line 339, in _async_add_entity
Oct 21 10:55:32 hp-gen8 hass[47431]:     'Invalid entity id: {}'.format(entity.entity_id))
Oct 21 10:55:32 hp-gen8 hass[47431]: homeassistant.exceptions.HomeAssistantError: Invalid entity id: media_player.
Oct 21 10:55:32 hp-gen8 hass[47431]: 2018-10-21 10:55:32 ERROR (MainThread) [homeassistant.core] Error doing job: Task exception was never retrieved
Oct 21 10:55:32 hp-gen8 hass[47431]: Traceback (most recent call last):
Oct 21 10:55:32 hp-gen8 hass[47431]:   File ""/srv/homeassistant/homeassistant_venv/lib/python3.6/site-packages/homeassistant/helpers/entity_platform.py"", line 339, in _async_add_entity
Oct 21 10:55:32 hp-gen8 hass[47431]:     'Invalid entity id: {}'.format(entity.entity_id))
Oct 21 10:55:32 hp-gen8 hass[47431]: homeassistant.exceptions.HomeAssistantError: Invalid entity id: remote.
```",What does your config for the appletv media_player look like?,ingapple tv 4k   i write the right ip to config file and reboot ha service
home-assistant/core,https://github.com/home-assistant/core/issues/28876,home-assistant_core_issues_28876,"Remove lg_soundbar from integrations

Home Assistant release with the issue:
hassos: ""2.12""
homeassistant: 0.101.3
machine: raspberrypi3
supervisor: ""192""

Operating environment (Hass.io/Docker/Windows/etc.):
Hass.io

Component/platform:
lg_soundbar

Description of problem:
The whole integration isn't working with current firmware updates/lg soundbars. In my opinion the integration has to be completely reworked or removed from HA.

Here are some details:

1. Seems like this integration isn't working without discovery, thus having HA and the LG device on the same subnet is mandatory. That's not a bug, it's a design issue. I already explained that [here](https://github.com/home-assistant/home-assistant/issues/23752), to workaround this problem you have to put HA and the LG device on the same subnet.

2. According to [instructions](https://www.home-assistant.io/integrations/lg_soundbar/) there is nothing else to do and the integration should detect any LG soundbars (SK series), that's not the case. I have ""default_config:"" set but there is no LG device discovered. The LG SK6 soundbar has chromecast builtin, maybe that's the problem. For this to workaround you have to ignore ""google_cast"" from discovery and add ""lg_soundbar"" to media_players:

```
discovery:
  ignore:
    - google_cast
media_player:
  - platform: lg_soundbar
```

3. If both workarounds are implemented you are getting a non functional media_player like [this](https://github.com/home-assistant/home-assistant/issues/23752#issuecomment-532217191).

Regards
Richard","Could you please use the issue template provided when creating an issue?

Do you have some stack traces, error logs or anything else that might be helpful?","Home Assistant release with the issue:
hassos: ""2.12""
homeassistant: 0.101.3
machine: raspberrypi3
supervisor: ""192""

Operating environment (Hass.io/Docker/Windows/etc.):
Hass.io

Component/platform:
lg_soundbar

Description of problem:
Here are some details:

1. Seems like this integration isn't working without discovery, thus having HA and the LG device on the same subnet is mandatory. That's not a bug, it's a design issue. I already explained that [here](https://github.com/home-assistant/home-assistant/issues/23752), to workaround this problem you have to put HA and the LG device on the same subnet.

2. According to [instructions](https://www.home-assistant.io/integrations/lg_soundbar/) there is nothing else to do and the integration should detect any LG soundbars (SK series), that's not the case. I have ""default_config:"" set but there is no LG device discovered. For this to workaround you have to ignore ""google_cast"" from discovery and add ""lg_soundbar"" to media_players:

```
discovery:
  ignore:
    - google_cast
media_player:
  - platform: lg_soundbar
```

The LG SK6 soundbar has chromecast builtin, maybe that's the problem.

3."
home-assistant/core,https://github.com/home-assistant/core/issues/19353,home-assistant_core_issues_19353,"IHC manual setup - not working after upgrade til 0.84

<!-- READ THIS FIRST:
- If you need additional help with this template please refer to https://www.home-assistant.io/help/reporting_issues/
- Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
- Frontend issues should be submitted to the home-assistant-polymer repository: https://github.com/home-assistant/home-assistant-polymer/issues
- Do not report issues for components if you are using custom components: files in <config-dir>/custom_components
- This is for bugs only. Feature and enhancement requests should go in our community forum: https://community.home-assistant.io/c/feature-requests
- Provide as many details as possible. Paste logs, configuration sample and code into the backticks. Do not delete any text from this template!
-->

**Home Assistant release with the issue:**
<!--
- Frontend -> Developer tools -> Info
- Or use this command: hass --version
-->


**Last working Home Assistant release (0.83):**


**Operating environment (Hass.io):**
<!--
Please provide details about your environment.
-->

**Component/platform:**
https://www.home-assistant.io/components/ihc/
<!--
Please add the link to the documentation at https://www.home-assistant.io/components/ of the component/platform in question.
-->


**Description of problem:**

After upgrade manual setup of IHC is not possible - If used with auto_setup: true - lights gets listed...

when using below config - it doesn´t work

**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```yaml
ihc:
  - url: 'http://192.168.100.90'
    username: !secret ihc_username
    password: !secret ihc_password
    auto_setup: false
    lights:
      - id: 2582109
        name: Spisebord
        dimmable: True
      - id: 3717469
        name: Køkken
        dimmable: True
      - id: 3076189
        name: Entre & Repos
        dimmable: True
      - id: 715613
        name: Vaskerum
        dimmable: True
      - id: 3003997
        name: Stue (TV)
        dimmable: True
      - id: 3902301
        name: Stue (Sofa)
        dimmable: True
      - id: 3103326
        name: Pavillion loft
      - id: 3867998
        name: Gang Kælder
      - id: 4035422
        name: Terrasse væg
    switches:
      - id: 3851612
        name: Entre_1
      - id: 3852124
        name: Entre_3
      - id: 4031580
        name: Sove_1_1
      - id: 4031836
        name: Sove_1_2
      - id: 4032092
        name: Sove_1_3
      - id: 4032348
        name: Sove_1_4
      - id: 4034396
        name: Stueterrasse_1_1
      - id: 4034652
        name: Stueterrasse_1_2
      - id: 4034908
        name: Stueterrasse_1_3
      - id: 4035164
        name: Stueterrasse_1_4
      - id: 4026972
        name: Ringeklokke
```


**Traceback (if applicable):**
```

```

**Additional information:**",What doesn't work?,"**Traceback (if applicable):**
```"
home-assistant/core,https://github.com/home-assistant/core/issues/26729,home-assistant_core_issues_26729,"Google Device Tracker - Invalid Session/Error setting up platform legacy

<!-- READ THIS FIRST:
- If you need additional help with this template please refer to https://www.home-assistant.io/help/reporting_issues/
- Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
- Frontend issues should be submitted to the home-assistant-polymer repository: https://github.com/home-assistant/home-assistant-polymer/issues
- iOS issues should be submitted to the home-assistant-iOS repository: https://github.com/home-assistant/home-assistant-iOS/issues
- Do not report issues for integrations if you are using a custom integration: files in <config-dir>/custom_components
- This is for bugs only. Feature and enhancement requests should go in our community forum: https://community.home-assistant.io/c/feature-requests
- Provide as many details as possible. Paste logs, configuration sample and code into the backticks. Do not delete any text from this template!
-->

**Home Assistant release with the issue:**
 0.99.0 (Now - 0.99.2)
<!--
- Frontend -> Developer tools -> Info
- Or use this command: hass --version
-->


**Last working Home Assistant release (if known):**
 0.98.5


**Operating environment (Hass.io/Docker/Windows/etc.):**
<!--
Please provide details about your environment.
-->

arch | x86_64
-- | --
dev | false
docker | false
hassio | false
os_name | Linux
python_version | 3.7.3
timezone | America/Chicago
version | 0.99.0
virtualenv | true



**Component/platform:**
<!--
Please add the link to the documentation at https://www.home-assistant.io/components/ of the component/platform in question.
-->
Google Device Tracker

**Description of problem:**

### **Updated** - Have to redo the cookie file, restart, then it only updates a Single time. Location services never updates again. This is also relate to Chrome cookie export or python based.  

Google device tracker no longer tracking. Only two messages provided in the logs.  Have regenerated new cookie yielding same results. 

2019-09-19 10:18:08 ERROR (SyncWorker_9) [homeassistant.components.google_maps.device_tracker] The cookie file provided does not provide a valid session. Please create another one and try again.

2019-09-19 10:18:08 ERROR (MainThread) [homeassistant.components.device_tracker] Error setting up platform legacy


**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```yaml

```

**Traceback (if applicable):**
```

```

**Additional information:**","did u try the new cookie method?

https://www.home-assistant.io/components/google_maps/","(Now - 0.99.2)

### **Updated** - Have to redo the cookie file, restart, then it only updates a Single time. Location services never updates again."
home-assistant/core,https://github.com/home-assistant/core/issues/26711,home-assistant_core_issues_26711,"Stream component does not work. (Component error: stream - Requirements for stream not found: [‘av == 6.1.2’])

<!-- READ THIS FIRST:
- If you need additional help with this template please refer to https://www.home-assistant.io/help/reporting_issues/
- Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
- Frontend issues should be submitted to the home-assistant-polymer repository: https://github.com/home-assistant/home-assistant-polymer/issues
- iOS issues should be submitted to the home-assistant-iOS repository: https://github.com/home-assistant/home-assistant-iOS/issues
- Do not report issues for integrations if you are using a custom integration: files in <config-dir>/custom_components
- This is for bugs only. Feature and enhancement requests should go in our community forum: https://community.home-assistant.io/c/feature-requests
- Provide as many details as possible. Paste logs, configuration sample and code into the backticks. Do not delete any text from this template!
-->

**Home Assistant release with the issue:**
<!--
- Frontend -> Developer tools -> Info
- Or use this command: hass --version
-->
arch - armv7
dev - false
docker - false
hassio - false
os name - Linux
python version - 3.7.3
version - 0.98.5
virtualenv - true

**Operating environment (Hass.io/Docker/Windows/etc.):**
Home assistant virtualenv (Raspberry PI)

**Description of problem:**
Hello.
I have problems with the stream component. I have never used it and want to configure it. I include this component in the configuration file. I do a configuration check.
I have such an error:

“Configuration invalid
Component error: stream - Requirements for stream not found: [‘av == 6.1.2’]”.

**The ffmpeg component is installed. The cameras are work:**
```
$ ffmpeg -i INPUT -an -f null -
ffmpeg version N-94610-g9bcb1cb6ed Copyright (c) 2000-2019 the FFmpeg developers
  built with gcc 8 (Raspbian 8.3.0-6 + rpi1)
  configuration: --arch = armel --target-os = linux --enable-gpl --enable-libx264 --enable-nonfree
  libavutil 56.33.100 / 56.33.100
  libavcodec 58. 55.100 / 58. 55.100
  libavformat 58.31.101 / 58.31.101
libavdevice 58.9.100 / 58.9.100
  libavfilter 7. 58.100 / 7. 58.100
  libswscale 5. 6.100 / 5. 6.100
  libswresample 3. 6.100 / 3. 6.100
  libpostproc 55.6.100 / 55.600
INPUT: No such file or directory
```

**All dependencies are installed**
**In the log the following error:**
```
2019-09-18 08:28:11 ERROR (SyncWorker_5) [homeassistant.util.package] Unable to install package av == 6.1.2: Failed building wheel for av
Command “/ srv / homeassistant / bin / python3 -u -c” import setuptools, tokenize; __ file __ = ‘/ tmp / pip-install-55s03uo5 / av / setup.py’; f = getattr (tokenize, ‘open’, open ) (__ file __); code = f.read (). replace (’\ r \ n’, ‘\ n’); f.close (); exec (compile (code, file, ‘exec’)) ""install - -record /tmp/pip-record-lzi8uto4/install-record.txt --single-version-externally-managed
–compile --install-headers /srv/homeassistant/include/site/python3.7/av ""failed with error code 1 in / tmp / pip-install-55s03uo5 / av /`
**I switched the Python version from 2 to 3. The problem is not resolved.**
`~ $ python --version
Python 3.7.3
```

**I executed the following command, and that’s what I got:**
```
(homeassistant) homeassistant@raspberrypi:/home/pi $ pip3 install --upgrade av==6.1.2
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Collecting av==6.1.2
  Using cached https://files.pythonhosted.org/packages/05/e4/205b787753d25da5d927b59b7cf59c0b7563e3d18f35d228101658792c05/av-6.1.2.tar.gz
Building wheels for collected packages: av
  Running setup.py bdist_wheel for av ... error
  Complete output from command /srv/homeassistant/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-install-c75qlob2/av/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" bdist_wheel -d /tmp/pip-wheel-uclg7cwl --python-tag cp37:
  running bdist_wheel
  running build
  running build_py
  creating build
  creating build/lib.linux-armv7l-3.7
  creating build/lib.linux-armv7l-3.7/av
  copying av/datasets.py -> build/lib.linux-armv7l-3.7/av
  copying av/__main__.py -> build/lib.linux-armv7l-3.7/av
  copying av/__init__.py -> build/lib.linux-armv7l-3.7/av
  copying av/deprecation.py -> build/lib.linux-armv7l-3.7/av
  creating build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/cctx_encode.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/merge-filmstrip.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/glproxy.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/encode_frames.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/remux.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/decode_threads.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/second_seek_example.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/encode.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/qtproxy.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/audio_player.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/show_frames_opencv.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/average.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/decode.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/save_subtitles.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/cctx_decode.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/graph.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/player.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/filmstrip.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/__init__.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/audio.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/dump_format.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/experimental.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/frame_seek_example.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/resource_use.py -> build/lib.linux-armv7l-3.7/scratchpad
  copying scratchpad/seekmany.py -> build/lib.linux-armv7l-3.7/scratchpad
  creating build/lib.linux-armv7l-3.7/av/audio
  copying av/audio/__init__.py -> build/lib.linux-armv7l-3.7/av/audio
  creating build/lib.linux-armv7l-3.7/av/container
  copying av/container/__init__.py -> build/lib.linux-armv7l-3.7/av/container
  creating build/lib.linux-armv7l-3.7/av/codec
  copying av/codec/__init__.py -> build/lib.linux-armv7l-3.7/av/codec
  creating build/lib.linux-armv7l-3.7/av/data
  copying av/data/__init__.py -> build/lib.linux-armv7l-3.7/av/data
  creating build/lib.linux-armv7l-3.7/av/video
  copying av/video/__init__.py -> build/lib.linux-armv7l-3.7/av/video
  creating build/lib.linux-armv7l-3.7/av/filter
  copying av/filter/__init__.py -> build/lib.linux-armv7l-3.7/av/filter
  creating build/lib.linux-armv7l-3.7/av/subtitles
  copying av/subtitles/__init__.py -> build/lib.linux-armv7l-3.7/av/subtitles
  running build_ext
  running config
  pkg-config returned flags we don't understand: -pthread -pthread

  Failed building wheel for av
  Running setup.py clean for av
Failed to build av
Installing collected packages: av
  Running setup.py install for av ... error
    Complete output from command /srv/homeassistant/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-install-c75qlob2/av/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-record-1i_gtkhp/install-record.txt --single-version-externally-managed --compile --install-headers /srv/homeassistant/include/site/python3.7/av:
    running install
    running build
    running build_py
    creating build
    creating build/lib.linux-armv7l-3.7
    creating build/lib.linux-armv7l-3.7/av
    copying av/datasets.py -> build/lib.linux-armv7l-3.7/av
    copying av/__main__.py -> build/lib.linux-armv7l-3.7/av
    copying av/__init__.py -> build/lib.linux-armv7l-3.7/av
    copying av/deprecation.py -> build/lib.linux-armv7l-3.7/av
    creating build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/cctx_encode.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/merge-filmstrip.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/glproxy.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/encode_frames.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/remux.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/decode_threads.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/second_seek_example.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/encode.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/qtproxy.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/audio_player.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/show_frames_opencv.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/average.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/decode.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/save_subtitles.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/cctx_decode.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/graph.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/player.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/filmstrip.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/__init__.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/audio.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/dump_format.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/experimental.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/frame_seek_example.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/resource_use.py -> build/lib.linux-armv7l-3.7/scratchpad
    copying scratchpad/seekmany.py -> build/lib.linux-armv7l-3.7/scratchpad
    creating build/lib.linux-armv7l-3.7/av/audio
    copying av/audio/__init__.py -> build/lib.linux-armv7l-3.7/av/audio
    creating build/lib.linux-armv7l-3.7/av/container
    copying av/container/__init__.py -> build/lib.linux-armv7l-3.7/av/container
    creating build/lib.linux-armv7l-3.7/av/codec
    copying av/codec/__init__.py -> build/lib.linux-armv7l-3.7/av/codec
    creating build/lib.linux-armv7l-3.7/av/data
    copying av/data/__init__.py -> build/lib.linux-armv7l-3.7/av/data
    creating build/lib.linux-armv7l-3.7/av/video
    copying av/video/__init__.py -> build/lib.linux-armv7l-3.7/av/video
    creating build/lib.linux-armv7l-3.7/av/filter
    copying av/filter/__init__.py -> build/lib.linux-armv7l-3.7/av/filter
    creating build/lib.linux-armv7l-3.7/av/subtitles
    copying av/subtitles/__init__.py -> build/lib.linux-armv7l-3.7/av/subtitles
    running build_ext
    running config
    pkg-config returned flags we don't understand: -pthread -pthread

Command ""/srv/homeassistant/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-install-c75qlob2/av/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-record-1i_gtkhp/install-record.txt --single-version-externally-managed --compile --install-headers /srv/homeassistant/include/site/python3.7/av"" failed with error code 1 in /tmp/pip-install-c75qlob2/av/
```

I tried uninstalling ffmpeg and reinstalling.  I used RPI hardware acceleration by compiling and following most of the instructions [here](https://maniaclander.blogspot.com/2017/08/ffmpeg-with-pi-hardware-acceleration.html)
This solved the problem with the stream component. But the video stopped working. When you click on a preview image, the video stream does not play. Moreover, the ffmpeg has disappeared from the folder /usr/bin/ffmpeg. And in the folder /usr/local/bin/ffmpeg did not work.
And I restored everything back.
Help me please, what else can I do to make the component work?


**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```yaml
stream: 
ffmpeg:
  ffmpeg_bin: /usr/bin/ffmpeg
```

**Traceback (if applicable):**
```

```

**Additional information:**","Did you try these steps?

 https://www.home-assistant.io/components/stream#troubleshooting","``

````

````

``"
home-assistant/core,https://github.com/home-assistant/core/issues/35055,home-assistant_core_issues_35055,"Roomba: start_pause service, error message/code

<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/core/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->
## The problem
<!-- 
  Describe the issue you are experiencing here to communicate to the
  maintainers. Tell us what you were trying to do and what happened.
-->
1) There is no `vacuum.start_pause` service in new integration. It's return: 'RoombaVacuumCarpetBoost' object has no attribute 'async_start_pause'. But it was ok in HA 0.108.
2) There is no attribute `error` with error message (in 0.108 and earlier too). But, please, make separate attributes with numeric code and text.


## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->
- Home Assistant Core release with the issue: 0.109.2
- Last working Home Assistant Core release (if known): 0.108
- Operating environment (Home Assistant/Supervised/Docker/venv): Home Assistant
- Integration causing this issue: Roomba
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/roomba/

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->

```yaml

```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt

```

## Additional information","Would you be so kind to update the opening post of your issue to have the issue template?

Thanks 👍","<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/core/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->

<!-- 
  Describe the issue you are experiencing here to communicate to the
  maintainers. Tell us what you were trying to do and what happened.
-->

<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->
- Home Assistant Core release with the issue: 
- Last working Home Assistant Core release (if known): 
- Operating environment (Home Assistant/Supervised/Docker/venv): 
- Integration causing this issue: 
- Link to integration documentation on our website: 

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->

```yaml

```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt

```

## Additional information"
home-assistant/core,https://github.com/home-assistant/core/issues/33479,home-assistant_core_issues_33479,"Cant connect in QVR Pro integration

<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/core/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->
## The problem
<!-- 
  Describe the issue you are experiencing here to communicate to the
  maintainers. Tell us what you were trying to do and what happened.
-->
Can't connect, full rights given to the user. It seems that it can't connect with https, it has both http and https access, but will of course default to https. It is not currently set up to force https.
The nas has a proper certificate, and the URL suits the certificate, but it seems to try and connect via IP instead?
The port it shows in the log is the https port.

## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant Core release with the issue: 0.107.6
- Last working Home Assistant Core release (if known): New integration
- Operating environment (Home Assistant/Supervised/Docker/venv):  Supervised
- Integration causing this issue: QVR PRO
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/qvr_pro/

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->
From the configuration
```yaml
qvr_pro:
  host: private.url.dk
  username: !secret qvruser
  password: !secret qvrpass
```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt
2020-03-31 20:39:44 ERROR (MainThread) [homeassistant.setup] Error during setup of component qvr_pro
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connection.py"", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File ""/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py"", line 84, in create_connection
    raise err
  File ""/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py"", line 74, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py"", line 672, in urlopen
    chunked=chunked,
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py"", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File ""/usr/local/lib/python3.7/http/client.py"", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/usr/local/lib/python3.7/http/client.py"", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/usr/local/lib/python3.7/http/client.py"", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/usr/local/lib/python3.7/http/client.py"", line 1026, in _send_output
    self.send(msg)
  File ""/usr/local/lib/python3.7/http/client.py"", line 966, in send
    self.connect()
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connection.py"", line 184, in connect
    conn = self._new_conn()
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connection.py"", line 169, in _new_conn
    self, ""Failed to establish a new connection: %s"" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0xffff7b2de890>: Failed to establish a new connection: [Errno 101] Network unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/requests/adapters.py"", line 449, in send
    timeout=timeout
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py"", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File ""/usr/local/lib/python3.7/site-packages/urllib3/util/retry.py"", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='my.url.dk', port=8080): Max retries exceeded with url: /cgi-bin/authLogin.cgi?user=ha-qvr-pro&pwd=elRFaGp4YWR1bnM2UFc4NHNqdkVwenRG&serviceKey=1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0xffff7b2de890>: Failed to establish a new connection: [Errno 101] Network unreachable'))
```

## Additional information
QNAP QTS 4.4.1.16",Could you please take a look at this issue @oblogic7? Thanks 👍,"2020-03-31 20:39:44 ERROR (MainThread) [homeassistant.setup] Error during setup of component qvr_pro
OSError: [Errno 101] Network unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
urllib3/connectionpool.py"", line 672, in urlopen
    chunked=chunked,
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py"", line 387, in _make_httplib_request_12, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/usr/local/lib/python3.7/http/client.py"", line 12<urllib3.connection."
home-assistant/core,https://github.com/home-assistant/core/issues/30555,home-assistant_core_issues_30555,"Nabu Casa error - Remote UI unreachable

<!-- READ THIS FIRST:
- If you need additional help with this template please refer to https://www.home-assistant.io/help/reporting_issues/
- Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
- Frontend issues should be submitted to the home-assistant-polymer repository: https://github.com/home-assistant/home-assistant-polymer/issues
- iOS issues should be submitted to the home-assistant-iOS repository: https://github.com/home-assistant/home-assistant-iOS/issues
- Do not report issues for integrations if you are using a custom integration: files in <config-dir>/custom_components
- This is for bugs only. Feature and enhancement requests should go in our community forum: https://community.home-assistant.io/c/feature-requests
- Provide as many details as possible. Paste logs, configuration sample and code into the backticks. Do not delete any text from this template!
-->

**Home Assistant release with the issue:**
0.103.6

**Last working Home Assistant release (if known):**
0.103.5

**Operating environment (Hass.io/Docker/Windows/etc.):**
Hass.io on Ubuntu host

**Integration:**

**Description of problem:**
After upgrading to 0.103.6 (from .5) the GUI in unreachable from its Nabu Casa URL. It is still reachable on its DuckDNS url.

**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**

**Traceback (if applicable):**
Errors in log, persising after Docker restarts:
```
2020-01-07 19:12:41 ERROR (MainThread) [hass_nabucasa.remote] Can't handle request-connection without backend
2020-01-07 19:12:41 ERROR (MainThread) [hass_nabucasa.iot] Error handling message
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/hass_nabucasa/iot.py"", line 90, in _async_handle_handler_message
    result = await handler(self.cloud, message[""payload""])
  File ""/usr/local/lib/python3.7/site-packages/hass_nabucasa/iot.py"", line 143, in async_handle_remote_sni
    await cloud.remote.handle_connection_requests(caller_ip)
  File ""/usr/local/lib/python3.7/site-packages/hass_nabucasa/remote.py"", line 216, in handle_connection_requests
    raise RemoteNotConnected()
hass_nabucasa.remote.RemoteNotConnected
```

**Additional information:**
Edit: downgrading to 0.103.5 immediately fixed this issue. Definitely seems to be related to 0.103.6 then.
Edit2: seems it's not related to 0.103.6 after all. Now on 0.103.5, after most HA restarts the remote UI is unreachable for me. Logs are below in the comments.",Do you have any other errors in your logs ?,"Edit2: seems it's not related to 0.103.6 after all. Now on 0.103.5, after most HA restarts the remote UI is unreachable for me. Logs are below in the comments."
home-assistant/core,https://github.com/home-assistant/core/issues/34865,home-assistant_core_issues_34865,"panasonic_viera regression in 0.109: WOL broadcast address configuration

## The problem
I had added support for broadcast_address in the `panasonic_viera` component here: https://github.com/home-assistant/core/pull/28793

For 0.109.0 this component was rewritten to use config flow: https://github.com/home-assistant/core/pull/33829

The support for a WOL broadcast address was not carried to the new config flow, and I see no discussion about removing it, so I think it's a regression.


## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant Core release with the issue: 0.109.0
- Last working Home Assistant Core release (if known): 0.108.x
- Operating environment (Home Assistant/Supervised/Docker/venv): Supervised
- Integration causing this issue: panasonic_viera
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/panasonic_viera/

## Problem-relevant `configuration.yaml`
```yaml
panasonic_viera:
  host: 10.52.110.10
  broadcast_address: 10.52.110.255
  mac: 8c:c1:21:xx:xx:xx
  name: ""Basement TV""
```

## Traceback/Error logs
N/A

## Additional information",Could you please update your report with the issue template provided when opening up a new issue? Thanks! 👍,"## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant Core release with the issue: 0.109.0
- Last working Home Assistant Core release (if known): 0.108.x
- Operating environment (Home Assistant/Supervised/Docker/venv): Supervised
- Integration causing this issue: panasonic_viera
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/panasonic_viera/

## Problem-relevant `configuration.yaml`
```yaml
panasonic_viera:
  host: 10.52.110.10
  broadcast_address: 10.52.110.255
  mac: 8c:c1:21:xx:xx:xx
  name: ""Basement TV""
```

## Traceback/Error logs
N/A

## Additional information"
home-assistant/core,https://github.com/home-assistant/core/issues/27138,home-assistant_core_issues_27138,"Home Assistant can't reliably access family relationships

<!-- READ THIS FIRST:
- If you need additional help with this template please refer to https://www.home-assistant.io/help/reporting_issues/
- Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
- Frontend issues should be submitted to the home-assistant-polymer repository: https://github.com/home-assistant/home-assistant-polymer/issues
- iOS issues should be submitted to the home-assistant-iOS repository: https://github.com/home-assistant/home-assistant-iOS/issues
- Do not report issues for integrations if you are using custom integration: files in <config-dir>/custom_components
- This is for bugs only. Feature and enhancement requests should go in our community forum: https://community.home-assistant.io/c/feature-requests
- Provide as many details as possible. Paste logs, configuration sample and code into the backticks. Do not delete any text from this template!
-->

**Home Assistant release with the issue:**
<!--
- Frontend -> Developer tools -> Info
- Or use this command: hass --version
-->


**Last working Home Assistant release (if known):**


**Operating environment (Hass.io/Docker/Windows/etc.):**
<!--
Please provide details about your environment.
-->

**Integration:**
<!--
Please add the link to the documentation at https://www.home-assistant.io/integrations/ of the integration in question.
-->


**Description of problem:**

Assistant can't access information that it has

**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```yaml

```

**Traceback (if applicable):**
```

```

**Additional information:**",What integration has family relationships?,Assistant can't access information that it has
home-assistant/core,https://github.com/home-assistant/core/issues/29956,home-assistant_core_issues_29956,"404 while syncing google assistant devices via cloud integration

**Temporary solution:**

Just in case you didn't know, you can sync devices from google just by saying `ok google sync devices` until this issue will be resolved.

<!-- READ THIS FIRST:
- If you need additional help with this template please refer to https://www.home-assistant.io/help/reporting_issues/
- Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
- Frontend issues should be submitted to the home-assistant-polymer repository: https://github.com/home-assistant/home-assistant-polymer/issues
- iOS issues should be submitted to the home-assistant-iOS repository: https://github.com/home-assistant/home-assistant-iOS/issues
- Do not report issues for integrations if you are using a custom integration: files in <config-dir>/custom_components
- This is for bugs only. Feature and enhancement requests should go in our community forum: https://community.home-assistant.io/c/feature-requests
- Provide as many details as possible. Paste logs, configuration sample and code into the backticks. Do not delete any text from this template!
-->

**Home Assistant release with the issue:**
<!--
- Frontend -> Developer tools -> Info
- Or use this command: hass --version
-->
0.103.0

**Last working Home Assistant release (if known):**
0.102.0, possibly some betas after

**Operating environment (Hass.io/Docker/Windows/etc.):**
<!--
Please provide details about your environment.
-->
Hass.io
**Integration:**
<!--
Please add the link to the documentation at https://www.home-assistant.io/integrations/ of the integration in question.
-->
https://www.home-assistant.io/integrations/

**Description of problem:**
404 while trying to sync my devices
https:/MyDoMaIn.duckdns.org:8123/api/cloud/google_actions/sync
<img width=""241"" alt=""image"" src=""https://user-images.githubusercontent.com/1587606/70860227-37022480-1f30-11ea-9c6a-6e448ae2941f.png"">


**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```yaml
default_config:
```

**Traceback (if applicable):**
```

```

**Additional information:**",Could you check which tempsensor that is and which integration it is?,"**Temporary solution:**

Just in case you didn't know, you can sync devices from google just by saying `ok google sync devices` until this issue will be resolved."
home-assistant/core,https://github.com/home-assistant/core/issues/29961,home-assistant_core_issues_29961,"OTGW losing connection after a few hours

**Home Assistant release with the issue:**
Home Assistant 0.103.0


**Last working Home Assistant release (if known):**
Unknown

**Operating environment (Hass.io/Docker/Windows/etc.):**
Running Hass.io (supervisor 192) on an x64 Debian server

**Integration:**
[OTGW](https://www.home-assistant.io/integrations/opentherm_gw/)


**Description of problem:**
When the server starts I get a few errors (Timed out waiting for command) but the integration works without problems. However after a few hours (last time lasted 3,5 hours) the updates stop coming in and the connection no longer works. After a restart of Home Assistant it all works again for a few hours, so it seems it doesn't try to reconnect without a restart of HA.

**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```yaml

```

**Traceback (if applicable):**
```
Exception in set_characteristics: 1
14 december 2019 21:32 components/homekit/type_thermostats.py (ERROR) - bericht kwam voor het eerst om 14 december 2019 21:32 en verschijnt 3 malen
Timed out waiting for command: PR, value: S.
14 december 2019 18:25 components/opentherm_gw/__init__.py (ERROR)
```
These are the only errors mentioning OTGW or thermostat

**Additional information:**
The OTGW itself is a wifi version with a NodeMCU from nodo-shop. The wifi is an Unifi setup so it should be stable enough and the NodeMCU is close to an AP so wifi should be fine",Could you please adjust your opening post to contain it? Thanks! 👍,"ocker/Windows/etc.):**
Running Hass.io (supervisor 192) on an x64 DHowever after a few hours (last time lasted 3,5 hours) the updates stop coming in and the connection no longer works. After a restart of Home Assistant it all works again for a few hours, so it seems it doesn't try to reconnect without a restart of HA.

**Problem-relevant `configuration.yaml` entries and (fill out even if it seems unimportant):**
```yaml

```

**or thermostat

**Additional information:**
The OTGW"
home-assistant/core,https://github.com/home-assistant/core/issues/30289,home-assistant_core_issues_30289,"yeelink.light.lamp2 will make the cpu 100%

Last working Home Assistant release (if known):Home Assistant 0.103.5
Operating environment (Hass.io/Docker/Windows/etc.):Hass.io 193
Description of problem:
yeelink.light.lamp2 will make the cpu 100%
Problem-relevant configuration.yaml entries and (fill out even if it seems unimportant):
```yaml
yeelight:
  devices:
    192.168.31.108:
      name: desklamppro
```
Additional information:
this device's mode is yeelink.light.lamp2",Could you please adjust your issue report to use that template? Thanks! 👍,"Last working Home Assistant release (if known):Home Assistant 0.103.5
Operating environment (Hass.io/Docker/Windows/etc.):Hass.io 193
Integration:
Description of problem:
yeelink.light.lamp2 will make the cpu 100%
Additional information:"
home-assistant/core,https://github.com/home-assistant/core/issues/31947,home-assistant_core_issues_31947,"Automation not always triggered with value_template although the state changed

## The problem
I have an automation to turn a light on and off when I am connected to a certain AP Mac address.
Even tough that I can see by printing ` {{ state_attr('device_tracker.iphone11', 'ap_mac') }}` that the Mac address is the one that should trigger the action, sometimes it is not triggered.


## Environment
HA version 0.105.5
Operating environment: Docker

- Home Assistant release with the issue: 
- Last working Home Assistant release (if known): NA
- Operating environment (Hass.io/Docker/Windows/etc.): Docker
- Integration causing this issue: automations
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/automation/

## Problem-relevant `configuration.yaml`

```yaml
- id: ga.light.on
  alias: light on
  trigger:
  - platform: template
    value_template: ""{% if is_state_attr('device_tracker.iphone11', 'ap_mac', '18:e8:29:93:f4:ea') %} True {% else %} False {% endif %}""
  condition: []
  action:
  - data:
      payload: 'on'
      topic: shellies/shelly1pm-B1E13B/relay/0/command
    service: mqtt.publish
```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt

```

## Additional information",Maybe try to create a binary template sensor and trigger based off that? Should make the automation cleaner.,%} True {% else %} False {% endif
home-assistant/core,https://github.com/home-assistant/core/issues/31688,home-assistant_core_issues_31688,"Opentherm gateway: Received erroneous message


<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->
## The problem
<!-- 
  Describe the issue you are experiencing here to communicate to the
  maintainers. Tell us what you were trying to do and what happened instead.
-->


I have the Opentherm gateway running and regularly receive error messages like below. Any idea what the problem is?

## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant release with the issue: 0.105.2
- Last working Home Assistant release (if known): n/a
- Operating environment (Hass.io/Docker/Windows/etc.): docker
- Integration causing this issue: opentherm gateway
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/opentherm_gw/

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->
n/a, standard configuration via integration screen.

```yaml

```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->


```
2020-02-10 09:21:51 WARNING (MainThread) [pyotgw.protocol] Received erroneous message, ignoring: b'\x00\x7f\xff\x00'
2020-02-10 09:22:21 WARNING (MainThread) [pyotgw.protocol] Received erroneous message, ignoring: b'\x10\x10\x15\xff'
2020-02-10 09:24:18 WARNING (MainThread) [pyotgw.protocol] Received erroneous message, ignoring: b'\x07\xff\xff\x00'
```


## Additional information",Can you please fill out the full issue template? There is now a lot of information missing. Thanks!,"---
name: Report a bug with Home Assistant 
about: Report an issue with Home Assistant
---
<!-- READ THthe Opentherm gateway running and regularly receive 

## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant release with the issue: 0.105.2
- Last working Home Assistant release (if known): n/a
- Operating environment (Hass.io/Docker/Windows/etc.): docker
- Integration causing this issue: opentherm gateway
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/opentherm_gw/

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->
n/a, standard configuration via integration screen.

```yaml

```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->


## Additional information"
home-assistant/core,https://github.com/home-assistant/core/issues/32392,home-assistant_core_issues_32392,"History Graph Card Configuration - Hours to show issue

I have two identical cards after each other. The only difference is one should show 50 hours and the other should show 3 hours.  When setting them up everything is fine, but after a refresh they both show the same (3 hour) graph.
Have also reset the database without success.

Environment:

Pi4 2Gig

arch | armv7l
-- | --
dev | false
docker | true
hassio | true
os_name | Linux
python_version | 3.7.6
timezone | America/New_York
version | 0.106.2
virtualenv | false

Lovelace:
mode | storage
-- | --
resources | 0
views | 11

Should look like this:
![IMG_20200301_094306](https://user-images.githubusercontent.com/15312957/75715425-6442b100-5c9b-11ea-9bfd-5f359aa870f5.jpg)

But looks like this after a refresh!
![IMG_20200301_094326](https://user-images.githubusercontent.com/15312957/75715347-41180180-5c9b-11ea-8892-01d45e0df4b9.jpg)",Could you please adjust? Thanks! 👍,"Environment:

arch | armv7l
-- | --
dev | false
docker | true
hassio | true
os_name | Linux
python_version | 3.7.6
timezone | America/New_York
version | 0.106.2
virtualenv | false

Lovelace:
mode | storage
-- | --
resources | 0
views | 11

Should look like this:
![IMG_20200301_094306](https://user-images.githubusercontent.com/15312957/75715425-6442b100-5c9b-11ea-9bfd-5f359aa870f5.jpg)

But looks like this after a refresh!
![IMG_20200301_094326](https://user-images.githubusercontent.com/15312957/75715347-41180180-5c9b-11ea-8892-01d45e0df4b9.jpg)"
home-assistant/core,https://github.com/home-assistant/core/issues/32465,home-assistant_core_issues_32465,"Linky Integration

<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->
## The problem
Enedis.fr changed there website recently to cope with data privacy requirement as well as to add new features such as the capability to add more electric meters to the user workspace, e.g. you have two houses and you want to see both meters in one workspace. I did it and have now two meters for which I can see the data in a single workspace.
This morning Home assistant card collecting previous day electric consumption reports data ""unavailable"".
I deleted the card, as well as the integration in the HA UI and tried to recreate the Integration which fails.
I guess logic has changed too for HA Integration access to Enedis.fr
<!-- 
 
-->


## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant release with the issue: Home Assistant 0.106.2
- Last working Home Assistant release (if known): Home Assistant 0.106.2
- Operating environment (Hass.io/Docker/Windows/etc.): Docker
- Integration causing this issue: Linky
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/linky/

## Problem-relevant `configuration.yaml`
<!--
  N/A
-->

```yaml

```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt

```

## Additional information","Could you please edit the opening post to add more information?


Thanks! 👍","Enedis.fr changed there website recently to cope with data privacy requirement as well as to add new features such as the capability to add more electric meters to the user workspace, e.g. you have two houses and you want to see both meters in one workspace. I did it and have now two counters.
This morning Home assistant card collecting previous day electric consumption reports unavailable.
I deleted the card, as well as the integration in the HA UI and tried to recreate the Integration which fails.
I guess logic has changed too for HA Integration access to Enedis.fr"
home-assistant/core,https://github.com/home-assistant/core/issues/32475,home-assistant_core_issues_32475,"Toon not working.

Home Assistant release with the issue:
0.106

Operating environment (HassOS/Generic):
Hass.io

Description of problem:
When people try to login it doesnt work. It seems like Toonalib (do i say that right) have to be changed because toon developers build in a new second login. 
Integration:
https://www.home-assistant.io/integrations/toon/
https://github.com/home-assistant/home-assistant.io/blob/current/source/_integrations/toon.markdown

I'm not the only one with this problem. People who are logged in already seems to have data but new users / users who needed to login again got a error:
Login is invalid. 

Pls fix.
ps, i hope i'm on the right place for this issue? newbie so sorry if the place is wrong.

This is the only reason i'm not yet been Nabu Casa-account member. I would like to pay 5 dollars a month if Toon is working.

regards, 
Tim.",can you please post the error you received?,This is the only reason i'm not yet been Nabu Casa-account member. I would like to pay 5 dollars a month if Toon is working.
home-assistant/core,https://github.com/home-assistant/core/issues/33163,home-assistant_core_issues_33163,"modbus switch - verify_register ignored

<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->
## The problem
<!-- 
  Describe the issue you are experiencing here to communicate to the
  maintainers. Tell us what you were trying to do and what happened instead.
-->
If the modbus *holding register* switch type with *verify_state* is used, the current switch state is not read from `verify_register` address.

Home assistant writes command_on/off values to register address 24640 withou problem. But the problem occurs when I set status in the connected device and switch should readback it from address 24616.


## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant release with the issue: 0.107.5
- Last working Home Assistant release (if known): --
- Operating environment (Hass.io/Docker/Windows/etc.): docker
- Integration causing this issue: modbus switch
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/switch.modbus/

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->

```yaml
modbus:
  - type: tcp
    host: 192.168.101.223
    port: 502
    name: plc_irrigation
    timeout: 3

switch:
  - platform: modbus
    registers:
      - name: pump enable
        hub: plc_irrigation
        slave: 1
        register: 24640
        register_type: holding
        command_on: 4
        command_off: 1
        verify_state: true
        verify_register: 24616
        state_on: 4
        state_off: 1
      - name: pump run
        hub: plc_irrigation
        slave: 1
        register: 24641
        register_type: holding
        command_on: 4
        command_off: 1
        verify_state: true
        verify_register: 24617
        state_on: 4
        state_off: 1
```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt

```

## Additional information

I think the problem is here:
https://github.com/home-assistant/core/blob/8423d18d8d6d423b5c82403372fe255303af2ff8/homeassistant/components/modbus/switch.py#L289",Can you please update your openings post on this issue? Thanks! 👍,"<!-- READ THIS FIRST:
  - If you need additional help with this template, please refer to https://www.home-assistant.io/help/reporting_issues/
  - Make sure you are running the latest version of Home Assistant before reporting an issue: https://github.com/home-assistant/home-assistant/releases
  - Do not report issues for integrations if you are using custom components or integrations.
  - Provide as many details as possible. Paste logs, configuration samples and code into the backticks.
  DO NOT DELETE ANY TEXT from this template! Otherwise, your issue may be closed without comment.
-->
## The problem
<!-- 
  Describe the issue you are experiencing here to communicate to the
  maintainers. Tell us what you were trying to do and what happened instead.
-->


Home assistant writes command_on/off values to register address 24640 withou problem. But the problem occurs when I set status in the connected device and switch should readback it from address 24616.


## Environment
<!--
  Provide details about the versions you are using, which helps us to reproduce
  and find the issue quicker. Version information is found in the
  Home Assistant frontend: Developer tools -> Info.
-->

- Home Assistant release with the issue: 0.107.5
- Last working Home Assistant release (if known): --
- Operating environment (Hass.io/Docker/Windows/etc.): docker
- Integration causing this issue: modbus switch
- Link to integration documentation on our website: https://www.home-assistant.io/integrations/switch.modbus/

## Problem-relevant `configuration.yaml`
<!--
  An example configuration that caused the problem for you. Fill this out even
  if it seems unimportant to you. Please be sure to remove personal information
  like passwords, private URLs and other credentials.
-->

```yaml
modbus:
  - type: tcp
    host: 192.168.101.223
    port: 502
    name: plc_irrigation
    timeout: 3

switch:
  - platform: modbus
    registers:
      - name: pump enable
        hub: plc_irrigation
        slave: 1
        register: 24640
        register_type: holding
        command_on: 4
        command_off: 1
        verify_state: true
        verify_register: 24616
        state_on: 4
        state_off: 1
      - name: pump run
        hub: plc_irrigation
        slave: 1
        register: 24641
        register_type: holding
        command_on: 4
        command_off: 1
        verify_state: true
        verify_register: 24617
        state_on: 4
        state_off: 1
```

## Traceback/Error logs
<!--
  If you come across any trace or error logs, please provide them.
-->

```txt

```

## Additional information"
home-assistant/core,https://github.com/home-assistant/core/issues/34459,home-assistant_core_issues_34459,"Slow start up

## The problem
I updated from 0.107.7 to 0.108.6 and now, when I want to start HA, it takes like 4 times more to start all the services.


## Environment
Home assistant 0.108.6

- Home Assistant Core release with the issue: 0.108.6 
- Last working Home Assistant Core release (if known): 0.107.7 
- Operating environment (Home Assistant/Supervised/Docker/venv): HA


## Traceback/Error logs
No error

## Additional information
4 times more to start HA

P.S. I see a lot of ""attempting install"" in the logs, even if all the requirements are met... in particular the ones related to the front end... which take a lot of time","Could you please use and fill out the issue template that is presented when creating an issue?

Thanks! 👍","## The problem


## Environment
Home assistant 0.108.6

- Home Assistant Core release with the issue: 0.108.6 
- Last working Home Assistant Core release (if known): 0.107.7 
- Operating environment (Home Assistant/Supervised/Docker/venv): HA


## Traceback/Error logs
No error

## Additional information
4 times more to start HA"
home-assistant/core,https://github.com/home-assistant/core/issues/34366,home-assistant_core_issues_34366,"ZHA Rollershutters as switch instead of cover

**Environment :** 
Home Assistant 0.108.5
Operating environment : Docker on Unraid
Zigate USB 3.1c
Integration https://www.home-assistant.io/integrations/zha/

**Problem :** 
I pair my new profalux shutter with the zigate and home assistant added it as switch entities instead of a cover entity. Does anyone know how to fix that?
Let me know if you need more details or zigbee.db file.

**Logs**
I have this message in the logs

> 2020-04-18 11:25:09 ERROR (MainThread) [zigpy_zigate.api] Received unhandled response 0x8035

**Additional informations**
Screenshots of the remote and the shutter in ZHA configuration
![zha2](https://user-images.githubusercontent.com/57676204/79639503-8a111000-818c-11ea-936d-a15fe4048d7d.png)
![zha1](https://user-images.githubusercontent.com/57676204/79639504-8aa9a680-818c-11ea-8fdc-6eb566b6624d.png)


Thanks !","Could you please use the issue template provided when creating an issue?

Thanks! 👍","**Environment :** 

Operating environment : Docker on Unraids://www.home-assistant.io/integrations/zha/

**Problem :** 
I p**Additional informations**
Screenshots of the remote and the shutter in ZHA configuration
![zha2](https://user-images.githubusercontent.com/57676204/79639503-8a111000-818c-11ea-936d-a15fe4048d7d.png)
![zha1](https://user-images.githubusercontent.com/57676204/79639504-8aa9a680-818c-11ea-8fdc-6eb566b6624d.png)"
home-assistant/core,https://github.com/home-assistant/core/issues/35368,home-assistant_core_issues_35368,"Bump python-broadlink to 0.14.0

## The problem
Please bump python-broadlink version to 0.14.0 for newer devices support (RM4C mini).
## Environment
## Problem-relevant `configuration.yaml`
## Traceback/Error logs
## Additional information","Could you please update your issue to use that template?

Thanks already! 👍","## Environment
## Problem-relevant `configuration.yaml`
## Traceback/Error logs
## Additional information"
influxdata/influxdb,https://github.com/influxdata/influxdb/issues/12170,influxdata_influxdb_issues_12170,"tasks: should be able to find task by name

tasks: should be able to find task by name
@goller asked that I add this.

- [x] Check swagger to understand how other resources are searched by name
    - This should determine the type of search (prefix, exact, wildcard, etc)
- [x] Replicate behavior for finding tasks",What is the consequence of finding a task with a non unique name? Would we error or return 'first'? Or maybe find task by name is a task list action?,"- [ ] Check swagger to understand how other resources are searched by name
- [ ] Replicate behavior for finding tasks"
influxdata/influxdb,https://github.com/influxdata/influxdb/issues/15316,influxdata_influxdb_issues_15316,"Unable to re-add bucket to a scoped token after re-creating it

__Steps to reproduce:__
List the minimal actions needed to reproduce the behavior.

1. Create a bucket
2. Create a token to read/write scoped to that bucket
3. Verify that the token works
4. Delete and create a new bucket with the same name
5. The previously created token does not work ; there is no way to re-add new bucket to the existing token

__Expected behavior:__
Be able to edit buckets that token can read from / write to, or at least be able to re-use token for a bucket with same name.

__Actual behavior:__
No option to perform it in the UI.

__Environment info:__
Version 2.0.0 (732c0cc)

__Config:__
N/A

__Logs:__
N/A

__Performance:__
N/A",Could you describe the use case for this?,"with the same name, or at least be able to re-use token for a bucket with same name"
influxdata/influxdb,https://github.com/influxdata/influxdb/issues/17411,influxdata_influxdb_issues_17411,"Public, shareable dashboards and charts

<!--

Thank you for suggesting an idea to improve InfluxDB. 

* Please ask usage questions on the Influx Community site.
    * https://community.influxdata.com/
* Please add a :+1: or comment on a similar existing feature request instead of opening a new one.
    * https://github.com/influxdata/influxdb/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+is%3Aclosed+sort%3Aupdated-desc+label%3A%22kind%2Ffeature+request%22+

-->

__Proposal:__
Give users a way to easily share dashboards and individual charts without requiring a login.

Shared dashboards should be accessible via a relatively short, simple URL in one of the following formats.

**For InfluxDB OSS 2:**

hostname:9999/chart/GUID.js

Example:

localhost:9999/chart/33533452sfa345235scxgdsfg.js

**For InfluxDB Cloud 2:**

influxdata.com/chart/GUID.js

Example:

influxdata.com/chart/33533452sfa345235scxgdsfg.js

__Current behavior:__

Currently, sharing charts requires logging into InfluxDB, which in turn requires logging into an InfluxDB account. 

__Desired behavior:__

There are two personas below: 

1) **InfluxDB admin**: a person who has admin access to an InfluxDB instance and knows how to setup InfluxDB dashboards.
2) **Chart consumer**: a person who views InfluxDB charts. They don't necessarily have admin access to InfluxDB, nor how to set up InfluxDB dashboards.

An **InfluxDB admin** clicks on an icon in a dashboard or individual chart, which copies a URL to the clipboard. user can then past it into a URL, Slack message, email, text, or other location. 

A **chart consumer** clicks the URL, and their browser sees a live-updated version of the chart. The chart consumer can embed the URL into a webpage using the <script> HTML element, and the chart will be embedded into their page. 
 
This chart is live updated, defaulting to the same parameters, refresh rate, and time window as the original.

To simplify the initial version of this feature, do not allow chart consumers to adjust the timeframe, refresh rate, or parameters. 

Users should NOT, however, see the underlying query, let alone edit it, for security reasons.

Do not rely on iframes to embed this chart, since those have security risks. Here's on article: https://medium.com/@bluepnume/iframes-are-just-terrible-heres-how-they-could-be-better-974b731f0fb4

By making this a .js file, similar to GitHub gists, we should avoid these security issues.

__Alternatives considered:__

We could use the Telegraf output to DataDog, and use DataDog's public sharing capability: 

https://docs.datadoghq.com/dashboards/sharing/#screenboards

... but that means a customer needs to create a DataDog account, which is time consuming and expensive.

__Use case:__
Why is this important (helps with prioritizing requests)?

Share time-series data stored in InfluxDB broadly within an organization, without requiring a login. Other charting software lets you do that. The more people who can access your charts, the more value you unlock in your data to drive smart decisions. 

Ultimately, charts are a form of communication, and they need to mesh with other digital communcation mechanisms we commonly use: Slack, email, Jira, GitHub, web pages, etc. 

In addition to what DataDog does (above), here's what Grafana does... 

Share an entire dashboard: 
https://grafana.com/docs/grafana/latest/reference/share_dashboard/

Share a panel (analogous to an InfluxDB cell):
https://grafana.com/docs/grafana/latest/reference/share_panel/

And here's what Domo does:

https://knowledge.domo.com/Engage/Sharing_Content_Outside_of_Domo/Sharing_Cards_Outside_of_Domo_Using_Domo_Embed",Do the other products that have this feature charge for queries?,".js.js.js.js

A **chart consumer** clicks the URL, and their browser sees a live-updated version of the chart."
vuejs/vue,https://github.com/vuejs/vue/issues/9325,vuejs_vue_issues_9325,"Modifier to propagate/forward events to parent

### What problem does this feature solve?
Currently, and as far as I know, if we want to propagate an event fired by a child component to the parent (the child's grandparent) we need to $emit the event again, and we need to pass all the arguments one more time. This can become a problem, for example, if the event has a variable number of arguments because we need to specify them manually or pass the whole array as a new argument.

The current way would be something like
```
@blur=""$emit('blur')""
@create=""$emit('create', arguments[0])""
@input=""$emit('input', arguments[0], arguments[1])""
```

### What does the proposed API look like?
```
@blur.propagate
@create.propagate
@input.propagate
```
And if we want to both handle the event and propagate it to the parent, we would use
```
@input.propagate=""someFunction""
```
----
EDIT: Maybe since .propagate may be confused with the function .stopPropagation(), a better term could be simply .emit

<!-- generated by vue-issues. DO NOT REMOVE -->","why not just `@input=""$emit('input', arguments)""` ?

I do like having a dedicated keyword though",EDIT: since  the functionemit
vuejs/vue,https://github.com/vuejs/vue/issues/9375,vuejs_vue_issues_9375,"Lags when updating the class

### Version
2.6.0-beta.2

### Reproduction link
[https://codepen.io/danyadev/pen/wNGaQo](https://codepen.io/danyadev/pen/wNGaQo)







### Steps to reproduce
1) Scroll to end (hide button)
2) Scroll up (show button)

### What is expected?
No lags (everything is fine in versions below 2.6-beta.1)

### What is actually happening?
Lags while scrolling (if they are not, then increase the number of elements in v-for)

<!-- generated by vue-issues. DO NOT REMOVE -->","Did you mean that `expected` is `actually happening` and vice-versa?

Also, same lags on Vue 2.5.2 when showing the button by scrolling up from the bottom.","No lags (everything is fine in versions below 2.6-beta.1)

### What is actually happening?"
snipe/snipe-it,https://github.com/snipe/snipe-it/issues/5667,snipe_snipe-it_issues_5667,"Error when Checking Out Assets After Upgrade

#### Please confirm you have done the following before posting your bug report:

- [ X ] I have enabled debug mode 
- [ X ] I have read [checked the Common Issues page](https://snipe-it.readme.io/docs/common-issues)

**Describe the bug**
After Upgrading From 4.1.14 to 4.4.1 (Manually) I can no longer Check Out Software Assets.
When I try to checkout an software asset it tells me ""Whoops, looks like something went wrong.""

**To Reproduce**
I went to Software > Selected a App > Clicked one of the Check Out Buttons > land on a page with the following Error Message ""Whoops, looks like something went wrong.""

**Expected behavior**
I should be able to check out items.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Server (please complete the following information):**
 - Snipe-IT Version: 4.4.1
 - OS: Ubuntu 16.04.4   (with Webuzo)
 - Web Server: Apache
 - PHP Version: 7.2

**Desktop (please complete the following information):**
 - OS: Win 10
 - Browser: Chrome 
 - Version: 67.0.3396.62

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Error Messages**
(2/2) ErrorException
Trying to get property 'require_acceptance' of non-object (View: /home/webuser/public_html/www/i/resources/views/licenses/checkout.blade.php)

in License.php (line 205)
at CompilerEngine->handleViewException(object(ErrorException), 0)
in PhpEngine.php (line 44)
at PhpEngine->evaluatePath('/home/webuser/public_html/www/i/storage/framework/views/6cf65b0317bb0c0ede74d9bada26126cfc54e2cf.php', array('__env' => object(Factory), 'app' => object(Application), 'errors' => object(ViewErrorBag), 'debug_in_production' => true, 'signedIn' => true, 'user' => object(User), 'license' => object(License), 'snipeSettings' => object(Setting)))
in CompilerEngine.php (line 59)
at CompilerEngine->get('/home/webuser/public_html/www/i/resources/views/licenses/checkout.blade.php', array('__env' => object(Factory), 'app' => object(Application), 'errors' => object(ViewErrorBag), 'debug_in_production' => true, 'signedIn' => true, 'user' => object(User), 'license' => object(License), 'snipeSettings' => object(Setting)))
in View.php (line 137)
...CROPPED 


**Additional context**
Upgrade method: (For Reference)
Using Webuzo, I installed the latest version using their built in scripts.
I then ran the copy commands listed in the manual upgrade guide.
..And I was up and running.

I tried migrating over to the git hub install method, but kept getting an error 500.
I did do it under the webuser account (not root) and did set the 755 permissions.


<bountysource-plugin>

---
Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/59335117-error-when-checking-out-assets-after-upgrade?utm_campaign=plugin&utm_content=tracker%2F505106&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F505106&utm_medium=issues&utm_source=github).
</bountysource-plugin>","What is Webuzo? 

That error is referencing `/home/webuser/public_html/www/i/resources/views/licenses/checkout.blade.php`, which is for licenses, not assets. 

Can you reproduce this on the demo at all?","<bountysource-plugin>

---
Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/59335117-error-when-checking-out-assets-after-upgrade?utm_campaign=plugin&utm_content=tracker%2F505106&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F505106&utm_medium=issues&utm_source=github).
</bountysource-plugin>"
snipe/snipe-it,https://github.com/snipe/snipe-it/issues/6792,snipe_snipe-it_issues_6792,"Pie Chart shows dummy data

## This issue relates to in-development code (`develop` branch)

#### Please confirm you have done the following before posting your bug report:

- [x] I have enabled debug mode 
- [x] I have read [checked the Common Issues page](https://snipe-it.readme.io/docs/common-issues)

**Describe the bug**
Pie chart on dashboard is showing dummy data.

**To Reproduce**
Steps to reproduce the behavior:
1. Look at it","Can you be sure to note that these issues are on develop moving forward? At first glance, these open issues make it look like our product is really broken :)",## This issue relates to in-development code (`develop` branch)
OctopusDeploy/Issues,https://github.com/OctopusDeploy/Issues/issues/6219,OctopusDeploy_Issues_issues_6219,"Can't modify a tenant that was cloned from a deleted tenant

# Prerequisites

- [x] I have verified the problem exists in the latest version
- [x] I have searched [open](https://github.com/OctopusDeploy/Issues/issues) and [closed](https://github.com/OctopusDeploy/Issues/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aclosed) issues to make sure it isn't already reported
- [x] I have written a descriptive issue title
- [x] I have linked the original source of this report
- [x] I have tagged the issue appropriately (area/*, kind/bug, tag/regression?)

# The bug

If you have a tenant that was cloned from another tenant that has been deleted, you're unable to modify the cloned tenant.

## What I expected to happen

<!-- What would you like to happen instead of this? e.g. Azure script steps should work regardless of where they are executed. -->

## Steps to reproduce

1. Create a tenant ~and add a tag to it~
2. Clone the tenant
3. Delete the first tenant
4. Attempt to modify the cloned tenant (e.g. rename, add a tag, or connect to another project)
5. See error

### Screen capture

![cloned_tenant_edit](https://user-images.githubusercontent.com/20388190/75731371-3614ae00-5d3b-11ea-9c31-057b89a55d5f.png)

### Log exerpt

```
One or more referenced resources do not exist: ""Tenants-41"" provided for ClonedFromTenantId
```

## Affected versions

Reproduced in Octopus Server 2019.13.7

## Links

Report: https://help.octopus.com/t/unable-to-adjust-tenant-tags-if-tenant-it-was-cloned-from-was-deleted/24772
Additional reports: 
- https://secure.helpscout.net/conversation/1164917624/64587/ (Internal link)
- https://secure.helpscout.net/conversation/1109105579/58858?folderId=2845830 (Internal link)",Do we know if or when this is going to be investigated?,"Additional reports: 
- https://secure.helpscout.net/conversation/1164917624/64587/ (Internal link)
- https://secure.helpscout.net/conversation/1109105579/58858?folderId=2845830 (Internal link)"
Icinga/icinga2,https://github.com/Icinga/icinga2/issues/6484,Icinga_icinga2_issues_6484,"Packages from https://packages.icinga.com are not Systemd Type=notify enabled?

Trying 2.9.1 from the Icinga Apt repo for Ubuntu xenial.

If the packages are built from the definitions ~[in this repo](https://github.com/Icinga/pkg-icinga2-debian)~ [not that repo], then I think the systemd support is not compiled in? Is the libsystemd build-dep missing?

I would prefer the `Type=notify` mode to `simple` or `forking`. And I would like to enable `WatchdogSec=`.

When I tried to switch to `Type=notify` the `icinga2.service` unit stays in `Activating` state forever because the `READY=1` notification never happens.

## Expected Behavior
- Run icinga2.service using the `Type=notify` mode of systemd.
- Run icinga2.service using the `WatchdogSec=` setting of systemd.

## Current Behavior
The Icinga2 Changelog for 2.9 announce the support of the systemd startup notification 
> #2287 (help wanted, wishlist): Please support systemd startup notification

and for the systemd service watchdog:
> #5996 (PR): Add systemd watchdog and adjust reload behaviour

Neither of these are enabled in the icinga2.service systemd init file shipping in the official packages from https://packages.icinga.com/

Manually editing the icinga2.service file to enable the `Type=notify` mode shows that the notification socket is never written to with the `READY=1` message. 

In the same way, the `WATCHDOG=1` message is not emitted when the `WatchdogSec=` feature, which is meant to supervise the Icinga daemon, is enabled.

## Possible Solution
It is expected that adding `Build-Depends` on libsystemd headers will aktucally compile in the new systemd support:

https://github.com/Icinga/icinga2/blob/a80c8259211382da760c4e9d42167046ff7fa508/lib/base/application.cpp#L306

Perhaps also the `#ifdef HAVE_SYSTEMD` is not set at all.

## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include configuration, logs, etc. to reproduce, if relevant -->
1. Change `Type=simple` to `Type=notify` in `icinga2.service`
2. `systemctl daemon-reload`
3. Restart Icinga2 using `systemctl restart icinga2.service`
4. Watch status, it will never go into state `active` and stay in `activating`: `systemctl status icinga2.service`


## Your Environment
<!--- Include as many relevant details about the environment you experienced the problem in -->
* Version used (`icinga2 --version`):
```
$ icinga2 --version
icinga2 - The Icinga 2 network monitoring daemon (version: r2.9.1-1)

Copyright (c) 2012-2018 Icinga Development Team (https://www.icinga.com/)
License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl2.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Application information:
  Installation root: /usr
  Sysconf directory: /etc
  Run directory: /run
  Local state directory: /var
  Package data directory: /usr/share/icinga2
  State path: /var/lib/icinga2/icinga2.state
  Modified attributes path: /var/lib/icinga2/modified-attributes.conf
  Objects path: /var/cache/icinga2/icinga2.debug
  Vars path: /var/cache/icinga2/icinga2.vars
  PID path: /run/icinga2/icinga2.pid

System information:
  Platform: Ubuntu
  Platform version: 16.04.4 LTS (Xenial Xerus)
  Kernel: Linux
  Kernel version: 4.4.0-130-generic
  Architecture: x86_64

Build information:
  Compiler: GNU 5.3.1
  Build host: 1b4c52bdc470
```

* Operating System and version:

```
# cat /etc/os-release 
NAME=""Ubuntu""
VERSION=""16.04.4 LTS (Xenial Xerus)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 16.04.4 LTS""
VERSION_ID=""16.04""
HOME_URL=""http://www.ubuntu.com/""
SUPPORT_URL=""http://help.ubuntu.com/""
BUG_REPORT_URL=""http://bugs.launchpad.net/ubuntu/""
VERSION_CODENAME=xenial
UBUNTU_CODENAME=xenial
```

* Enabled features (`icinga2 feature list`):
```
# icinga2 feature list
Disabled features: compatlog debuglog elasticsearch gelf influxdb livestatus opentsdb perfdata statusdata syslog
Enabled features: api checker command graphite ido-mysql mainlog notification
```

* Config validation (`icinga2 daemon -C`):
```
[2018-08-12 16:21:41 +0200] information/cli: Finished validating the configuration file(s).
```","Would you recreate the issue there?

Off topic: pkg-icinga2-debian we can probably delete or at least put a message that it is not relevant anymore.","~~ [not that repo]

## Expected Behavior
- Run icinga2.service using the `Type=notify` mode of systemd.
- Run icinga2.service using the `WatchdogSec=` setting of systemd.

## Current Behavior
The Icinga2 Changelog for 2.9 announce the support of the systemd startup notification 
> #2287 (help wanted, wishlist): Please support systemd startup notification
and for the systemd service watchdog:
> #5996 (PR): Add systemd watchdog and adjust reload behaviour

Neither of these are enabled in the icinga2.service systemd init file shipping in the official packages from https://packages.icinga.com/

Manually editing the icinga2.service file to enable the `Type=notify` mode shows that the notification socket is never written to with the `READY=1` message. 

In the same way, the `WATCHDOG=1` message is not emitted when the `WatchdogSec=` feature, which is meant to supervise the Icinga daemon, is enabled.

## Possible Solution
It is expected that adding `Build-Depends` on libsystemd headers will aktucally compile in the new systemd support

## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include configuration, logs, etc. to reproduce, if relevant -->
1. Change `Type=simple` to `Type=notify` in `icinga2.service`
2. `systemctl daemon-reload`
3. Restart Icinga2 using `systemctl restart icinga2.service`
4. Watch status, it will never go into state `active` and stay in `activating`: `systemctl status icinga2.service`


## Your Environment
<!--- Include as many relevant details about the environment you experienced the problem in -->
* Version used (`icinga2 --version`):
```
$ icinga2 --version
icinga2 - The Icinga 2 network monitoring daemon (version: r2.9.1-1)

Copyright (c) 2012-2018 Icinga Development Team (https://www.icinga.com/)
License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl2.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Application information:
  Installation root: /usr
  Sysconf directory: /etc
  Run directory: /run
  Local state directory: /var
  Package data directory: /usr/share/icinga2
  State path: /var/lib/icinga2/icinga2.state
  Modified attributes path: /var/lib/icinga2/modified-attributes.conf
  Objects path: /var/cache/icinga2/icinga2.debug
  Vars path: /var/cache/icinga2/icinga2.vars
  PID path: /run/icinga2/icinga2.pid

System information:
  Platform: Ubuntu
  Platform version: 16.04.4 LTS (Xenial Xerus)
  Kernel: Linux
  Kernel version: 4.4.0-130-generic
  Architecture: x86_64

Build information:
  Compiler: GNU 5.3.1
  Build host: 1b4c52bdc470
```

* Operating System and version:

```
# cat /etc/os-release 
NAME=""Ubuntu""
VERSION=""16.04.4 LTS (Xenial Xerus)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 16.04.4 LTS""
VERSION_ID=""16.04""
HOME_URL=""http://www.ubuntu.com/""
SUPPORT_URL=""http://help.ubuntu.com/""
BUG_REPORT_URL=""http://bugs.launchpad.net/ubuntu/""
VERSION_CODENAME=xenial
UBUNTU_CODENAME=xenial
```

* Enabled features (`icinga2 feature list`):
```
# icinga2 feature list
Disabled features: compatlog debuglog elasticsearch gelf influxdb livestatus opentsdb perfdata statusdata syslog
Enabled features: api checker command graphite ido-mysql mainlog notification
```

* Config validation (`icinga2 daemon -C`):
```
[2018-08-12 16:21:41 +0200] information/cli: Finished validating the configuration file(s).
```"
Icinga/icinga2,https://github.com/Icinga/icinga2/issues/6442,Icinga_icinga2_issues_6442,"Error while evaluating ""assign where match"" expression: std::bad_cast

## Current Behavior
The new Icinga2 update to version 2.9.0 seems to have broken certain match expressions. I have a notification object with the following apply rule:

```
assign where match(""workstation*"", host.vars.int)
```

Using `icinga2 daemon -C` gives me an error for every host with an instance of `host.vars.int`, and each error is the following:

```
critical/config: Error: Error while evaluating expression: std::bad_cast
```

The contents of `host.vars.int` can vary in between the following:
```
vars.int[""Interface display name""] = {
  int = ""Interface name""
  port_type = ""workstation""
}
```
or
```
vars.int[""Interface display name""] = {
  int = ""Interface name""
}
```

## Steps to Reproduce
1. Create an 'apply Notification' object and try to use the match expression that I showed initially

## Context
I tested this using a v2.8.4 box and it works as expected, something has changed in between then and now (v2.9.0) concerning match expressions, which I did not see mentioned in the docs.

## Your Environment
<!--- Include as many relevant details about the environment you experienced the problem in -->
* Version used (`icinga2 --version`): r2.9.0-1
* Operating System and version: CentOS 7
* Enabled features (`icinga2 feature list`): api, checker, command, ido-mysql, influxdb, mainlog, notification
* Icinga Web 2 version and modules (System - About): v2.5.3, director, monitoring, doc
* Config validation (`icinga2 daemon -C`): There are ~500 instances of the following error because of the how many `host.vars.int` I have:

```
...

[2018-07-17 11:44:43 -1000] critical/config: Error: Error while evaluating expression: std::bad_cast
Location: in /etc/icinga2/zones.d/global-templates/notifications.conf: 36:16-36:50
/etc/icinga2/zones.d/global-templates/notifications.conf(34):   period = ""offhours""
/etc/icinga2/zones.d/global-templates/notifications.conf(35): 
/etc/icinga2/zones.d/global-templates/notifications.conf(36):   assign where match(""workstation"", host.vars.int)
                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/etc/icinga2/zones.d/global-templates/notifications.conf(37): }
/etc/icinga2/zones.d/global-templates/notifications.conf(38): 

	(0) Evaluating 'apply' rule (in /etc/icinga2/zones.d/global-templates/notifications.conf: 29:1-29:50)
	(1) Evaluating 'apply' rules for service 'icinga-host!eth0'

...
```",What's the content of `vars.int` on the host object?,"```

The contents of `host.vars.int` can vary in between the following:
```
vars.int[""Interface display name""] = {
  int = ""Interface name""
  port_type = ""workstation""
}
```
or
```
vars.int[""Interface display name""] = {
  int = ""Interface name""
}"
Icinga/icinga2,https://github.com/Icinga/icinga2/issues/6945,Icinga_icinga2_issues_6945,"Updating custom vars via API creates way too many MySQL queries from Icinga 2.9.2

<!--- Provide a general summary of the issue in the Title above -->
When updating custom variables for host/service objects Icinga2 makes huge amount of queries to MySQL. For example:
```
[2019-02-07 07:05:25 +0100] information/WorkQueue: #7 (IdoMysqlConnection, ido-mysql) items: 2846523, rate: 801.2/s (48072/min 296525/5min 940974/15min); empty in 42 minutes and 26 seconds
[2019-02-07 07:08:04 +0100] information/WorkQueue: #7 (IdoMysqlConnection, ido-mysql) items: 2731102, rate: 889.033/s (53342/min 311865/5min 919937/15min); empty in 8 hours, 53 minutes and 22 seconds
[2019-02-07 07:56:43 +0100] information/WorkQueue: #7 (IdoMysqlConnection, ido-mysql) items: 6174085, rate: 679.317/s (40759/min 311286/5min 841534/15min); empty in 12 hours, 37 minutes and 10 seconds
```
Most of them are being repeated multiple times. It fills up ido-mysql connector queue which causes Icingaweb2 to display outdated data until it flushes.

<!-- If you are reporting a problem or a bug, please ensure to read https://github.com/Icinga/icinga2/blob/master/doc/15-troubleshooting.md first. Formatting tips: GitHub supports Markdown: https://guides.github.com/features/mastering-markdown/ -->

## Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->
Icinga2 should update MySQL database promptly and should not cause delays in Icingaweb2.

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->
ido-mysql connectors queue fills up with vast amounts of queries to mysql, causing a delay which makes Icingaweb2 display incorrect/outdated data. 

## Possible Solution
<!--- Not obligatory, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement:  the addition or change -->
Optimize the way custom variables are being updated.

## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include configuration, logs, etc. to reproduce, if relevant -->
1. Enable debug logging on Icinga:

    icinga2 feature enable debuglog

2. Create a host object:

    curl -u USERNAME:PASSWORD -k -H 'Accept: application/json' -X PUT https://node2.domain.com:5665/v1/objects/hosts/newhost -d '{ ""attrs"": { ""vars.app_env"": ""debug"", ""check_command"": ""hostalive"", "" address"": ""127.0.0.1"" } }'

3. Update the host object with addidional variables:

    curl -u USERNAME:PASSWORD -k -H 'Accept: application/json' -X POST https://node2.domain.com:5665/v1/objects/hosts/newhost -d '{ ""attrs"": { ""vars.a"": ""a"", ""vars.b"": ""b"", ""vars.c"": ""c"", ""vars.d"": ""d"", ""vars.e"": ""e"", ""vars.f"": ""f"", ""vars.g"": ""g"", ""vars.h"": ""h""} }'

4. Additional variable updates causes the same behavior.


## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->
We are allowing our developers to update host/service status via API. They add additional information into custom variables for these host/service objects. Sometimes they would post a couple of updates in the same second to Icinga2. We noticed that sometimes Icingaweb2 was unable to display the latest data, for example when someone changes the service status by hand. We noticed that WorkQueue of ido-mysql connector contains millions of items that could not be commited to MySQL server. Upon further inspection we noticed that most of them are the same queries.



## Your Environment
<!--- Include as many relevant details about the environment you experienced the problem in -->
* Version used (`icinga2 --version`): 2.9.2
* Operating System and version: RHEL7.6
* Enabled features (`icinga2 feature list`): Enabled features: api checker command ido-mysql influxdb mainlog notification
* Icinga Web 2 version and modules (System - About): v2.6.1 with monitoring v2.6.1
* Config validation (`icinga2 daemon -C`): all good
* If you run multiple Icinga 2 instances, the `zones.conf` file (or `icinga2 object list --type Endpoint` and `icinga2 object list --type Zone`) from all affected nodes.
```
object Endpoint ""node1.domain.com"" {
}

object Endpoint ""node2.domain.com"" {
  host = ""node2.domain.com"";
  port = ""5665"";
}

object Zone ""master"" {
  endpoints = [""node1.domain.com"",""node2.domain.com""];
}
```
node1 is config master, node2 mainly serves as an active node for Icingaweb2.

Attaching debug.log from node2 to show the queries which are being repeated.
[debug.log](https://github.com/Icinga/icinga2/files/2851768/debug.log)",Do you have a concrete example here?,```````````` which are being repeated
Icinga/icinga2,https://github.com/Icinga/icinga2/issues/7363,Icinga_icinga2_issues_7363,"critical/cli: Could not fetch valid response. Please check the master log.

Ubuntu 18.04.2 LTS server 

icinga2 version:

root@master-207:/var/lib/icinga2/ca# icinga2 --version |head
icinga2 - The Icinga 2 network monitoring daemon (version: r2.10.5-1)

root@node1:/var/lib/icinga2/certs# icinga2 --version |head
icinga2 - The Icinga 2 network monitoring daemon (version: r2.10.5-1)

# client 
```
sudo icinga2 node wizard

critical/cli: Could not fetch valid response. Please check the master log.
critical/cli: Failed to fetch signed certificate from master '10.0.0.207, 5665'. Please try again.
```

# server log
```
[2019-07-26 19:11:07 +0800] information/ApiListener: No data received on new API connection. Ensure that the remote endpoints are properly configured in a cluster setup.
[2019-07-26 19:11:17 +0800] information/ApiListener: New client connection for identity 'node1' from [10.0.0.206]:23802 (certificate validation failed: code 18: self signed certificate)
[2019-07-26 19:11:27 +0800] warning/ApiListener: No data received on new API connection for identity 'node1'. Ensure that the remote endpoints are properly configured in a cluster setup.
Context:
        (0) Handling new API client connection
```

refer this url ,but not result
https://icinga.com/2017/08/30/advisory-for-ssl-problems-with-leading-zeros-on-openssl-1-1-0/

```
root@master-207:/var/lib/icinga2/ca# openssl x509 -text -in ca.crt |head
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            95:f9:2b:a8:fd:00:21:88:91:d8:1b:81:47:3e:69:cc:3b:62:2c:07
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN = Icinga CA
        Validity
            Not Before: Jul 26 09:45:10 2019 GMT
            Not After : Jul 22 09:45:10 2034 GMT

root@node1:/var/lib/icinga2/certs# openssl req -text -in node1.csr |head
Certificate Request:
    Data:
        Version: 1 (0x0)
        Subject: CN = node1
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                RSA Public-Key: (4096 bit)

root@node1:/var/lib/icinga2/certs# openssl x509 -text -in node1.crt |head
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            d9:78:4b:14:d9:f3:89:eb:db:70:92:91:bd:b6:3f:90:5b:40:f5:fa
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN = node1
        Validity
            Not Before: Jul 26 11:22:49 2019 GMT
            Not After : Jul 22 11:22:49 2034 GMT
```","Can you make a connection using openssl s_server and s_client?

This should work if you need a guide: https://superhero.ninja/2015/07/22/create-a-simple-https-server-with-openssl-s_server/","``````

``````

```
```"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/7696,jhipster_generator-jhipster_issues_7696,"Many To Many recursive calls in test createEntity 

<!--
- Please follow the issue template below for bug reports.
- If you have a support request rather than a bug, please use [Stack Overflow](http://stackoverflow.com/questions/tagged/jhipster) with the JHipster tag.
- For bug reports it is mandatory to run the command `jhipster info` in your project's root folder, and paste the result here.
- Tickets opened without any of these pieces of information will be **closed** without any explanation.
-->

##### **Overview of the issue**

When you generate the code that has a many to many relationship to the same class (ex: parent, child) 
the test has class createEntity that will class it self and test will get stack.

##### **Motivation for or Use Case**

<!-- Explain why this is a bug for you -->

##### **Reproduce the error**

use A JDL like this:

```
entity TaskType {
    name String required
}

relationship ManyToMany {
    TaskType{parent(name)} to TaskType{child(name)}
}
```

##### **Related issues**

<!-- Has a similar issue been reported before? Please search both closed & open issues -->

##### **Suggest a Fix**

check when generating that the class is different, also check if it doesn't happen for manyToOne/OneToMany (don't think so)

##### **JHipster Version(s)**

<!--
Which version of JHipster are you using, is it a regression?
-->
4.14.4 and I understand if it's not fixed until the 2.x like the others

##### **JHipster configuration**

<!--
To provide all information we need, you should run `jhipster info` in the project root folder, and
copy/paste the result here.
The `.yo-rc.json` file generated in the root folder is mandatory for bug reports. This will help us to replicate the scenario.
You should remove any sensitive information like the rememberMe key or the jwtSecretKey key.
-->

##### **Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

```
{
    ""fluentMethods"": true,
    ""relationships"": [
        {
            ""relationshipType"": ""many-to-many"",
            ""otherEntityRelationshipName"": ""child"",
            ""relationshipName"": ""parent"",
            ""otherEntityName"": ""taskType"",
            ""otherEntityField"": ""name"",
            ""ownerSide"": true
        }
    ],
    ""fields"": [
        {
            ""fieldName"": ""name"",
            ""fieldType"": ""String"",
            ""fieldValidateRules"": [
                ""required""
            ]
        }
    ],
    ""changelogDate"": ""20180519154932"",
    ""entityTableName"": ""task_type"",
    ""dto"": ""mapstruct"",
    ""pagination"": ""no"",
    ""service"": ""serviceImpl"",
    ""jpaMetamodelFiltering"": true,
    ""microserviceName"": ""processing""
}
```

yo-rc.json

```
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""com.test"",
      ""nativeLanguage"": ""en""
    },
    ""jhipsterVersion"": ""4.14.3"",
    ""baseName"": ""processman"",
    ""packageName"": ""com.test"",
    ""packageFolder"": ""com/test"",
    ""serverPort"": ""8083"",
    ""authenticationType"": ""oauth2"",
    ""cacheProvider"": ""hazelcast"",
    ""enableHibernateCache"": true,
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""mysql"",
    ""prodDatabaseType"": ""mysql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": ""eureka"",
    ""buildTool"": ""gradle"",
    ""enableSocialSignIn"": false,
    ""enableSwaggerCodegen"": false,
    ""jwtSecretKey"": ""seceretkey"",
    ""enableTranslation"": true,
    ""applicationType"": ""microservice"",
    ""testFrameworks"": [],
    ""jhiPrefix"": ""jhi"",
    ""nativeLanguage"": ""en"",
    ""languages"": [
      ""en"",
      ""fr""
    ],
    ""clientPackageManager"": ""npm"",
    ""skipClient"": true,
    ""skipUserManagement"": true
  }
}
```

<!--
If the error is during an entity creation or associated with a specific entity.
If you are using JDL, please share that configuration as well.
-->

##### **Browsers and Operating System**

<!-- What OS are you on? is this a problem with all browsers or only IE8? -->
OSX
- [X] Checking this box is mandatory (this is just to show you read everything)

<!-- Love JHipster? Please consider supporting our collective:
👉  https://opencollective.com/generator-jhipster/donate -->",Could you add your project's `.yo-rc.json` please?  I couldn't reproduce with just your entity JDL,"yo-rc.json

```
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""com.test"",
      ""nativeLanguage"": ""en""
    },
    ""jhipsterVersion"": ""4.14.3"",
    ""baseName"": ""processman"",
    ""packageName"": ""com.test"",
    ""packageFolder"": ""com/test"",
    ""serverPort"": ""8083"",
    ""authenticationType"": ""oauth2"",
    ""cacheProvider"": ""hazelcast"",
    ""enableHibernateCache"": true,
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""mysql"",
    ""prodDatabaseType"": ""mysql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": ""eureka"",
    ""buildTool"": ""gradle"",
    ""enableSocialSignIn"": false,
    ""enableSwaggerCodegen"": false,
    ""jwtSecretKey"": ""seceretkey"",
    ""enableTranslation"": true,
    ""applicationType"": ""microservice"",
    ""testFrameworks"": [],
    ""jhiPrefix"": ""jhi"",
    ""nativeLanguage"": ""en"",
    ""languages"": [
      ""en"",
      ""fr""
    ],
    ""clientPackageManager"": ""npm"",
    ""skipClient"": true,
    ""skipUserManagement"": true
  }
}
```"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/11124,jhipster_generator-jhipster_issues_11124,"Firefox: If you edit any entity it does not look like Chrome (it's much worse)

Firefox: If you edit any entity it does not look like Chrome: DatePicker does not really work. HTML looks and feels pretty weird.

##### **Overview of the issue**

It is not a big issue, but may be it is easy to fix. I do not know.

##### **Motivation for or Use Case**

Make it look as Chrome

##### **Reproduce the error**

No errors, just the weird look and feel. See image

##### **Related issues**

No

##### **Suggest a Fix**

No idea

##### **JHipster Version(s)**

V6.6.0

##### **JHipster configuration**

<details>
<summary>.yo-rc.json file</summary>

<pre>
{
    ""generator-jhipster"": {
        ""promptValues"": {
            ""packageName"": ""es.mibar.web"",
            ""nativeLanguage"": ""es""
        },
        ""jhipsterVersion"": ""6.6.0"",
        ""applicationType"": ""monolith"",
        ""baseName"": ""mibar"",
        ""packageName"": ""es.mibar.web"",
        ""packageFolder"": ""es/mibar/web"",
        ""serverPort"": ""8080"",
        ""authenticationType"": ""session"",
        ""cacheProvider"": ""ehcache"",
        ""enableHibernateCache"": true,
        ""websocket"": false,
        ""databaseType"": ""sql"",
        ""devDatabaseType"": ""h2Disk"",
        ""prodDatabaseType"": ""postgresql"",
        ""searchEngine"": false,
        ""messageBroker"": false,
        ""serviceDiscoveryType"": false,
        ""buildTool"": ""gradle"",
        ""enableSwaggerCodegen"": false,
        ""rememberMeKey"": ""94e48c3cf2531fcabaf1f1cf2dda23614015c47e7e42f82dde2f70373993b967b64b9376b5be2809b959ccd6403d8321f234"",
        ""embeddableLaunchScript"": false,
        ""useSass"": true,
        ""clientPackageManager"": ""npm"",
        ""clientFramework"": ""angularX"",
        ""clientTheme"": ""none"",
        ""clientThemeVariant"": """",
        ""creationTimestamp"": 1577988308462,
        ""testFrameworks"": [],
        ""jhiPrefix"": ""jhi"",
        ""entitySuffix"": """",
        ""dtoSuffix"": ""DTO"",
        ""otherModules"": [],
        ""enableTranslation"": true,
        ""nativeLanguage"": ""es"",
        ""languages"": [
            ""es"",
            ""en""
        ],
        ""blueprints"": [],
        ""herokuAppName"": ""mibar-es"",
        ""herokuDeployType"": ""jar""
    }
}
</pre>
</details>

##### **Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**
<details>
<summary>JDL entity definitions</summary>

<pre>
entity DailyMenu {
    creationDate Instant required,
    menuDate Instant required,
    name String minlength(2) maxlength(250),
    description String minlength(2) maxlength(25000),
    bread Boolean,
    waitersvc Boolean,
    price Double,
    unit Unit,
    currency String
}

</pre>
</details>
<!--
If the error is during an entity creation or associated with a specific entity.
If you are using JDL, please share that configuration as well.
-->

##### **Browsers and Operating System**

Firefox 72.0.1 (64-bit)

-   [x] Checking this box is mandatory (this is just to show you read everything)

<!-- Love JHipster? Please consider supporting our collective:
👉  https://opencollective.com/generator-jhipster/donate -->


![FirefoxDatePicker](https://user-images.githubusercontent.com/11610877/72555231-7956b280-389c-11ea-84d6-b6b752f8f81d.png)","Can you please fill out the rest of the template so that someone can try to reproduce/fix?

A screenshot showing the differences would also be helpful.","the weird . See image

![FirefoxDatePicker](https://user-images.githubusercontent.com/11610877/72554952-fafa1080-389b-11ea-8cd7-da03538c23e7.png)"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/8143,jhipster_generator-jhipster_issues_8143,"jhipster kubernetes doesn't generate keycloak yaml

##### **Overview of the issue**

I generated an app with keycloak for oidc and postgres for db.
I then used the kubernetes subgenerator. It generates the yaml for the app & postgres but not keycloak

##### **Motivation for or Use Case**

Kubernetes integration

##### **Reproduce the error**

Run 
```
jhipster (selecting keycloak option)
jhipster kubernetes
# Result: no K8s yaml generated for keycloak
```

##### **Related issues**

<!-- Has a similar issue been reported before? Please search both closed & open issues -->

##### **Suggest a Fix**

<!-- If you can't fix the bug yourself, perhaps you can point to what might be
  causing the problem (line of code or commit) -->

##### **JHipster Version(s)**

JHipster Docker Image tag: v5.2.1

##### **JHipster configuration**

jhipster info
Using JHipster version installed locally in current project's node_modules
Executing jhipster:info
Options:
Welcome to the JHipster Information Sub-Generator

##### **JHipster Version(s)**

```
app@0.0.0 /home/jhipster/app
`-- generator-jhipster@5.2.1

```


##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**


<details>
<summary>.yo-rc.json file</summary>
<pre>
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""com.mycompany.myapp""
    },
    ""jhipsterVersion"": ""5.2.1"",
    ""applicationType"": ""monolith"",
    ""baseName"": ""app"",
    ""packageName"": ""com.mycompany.myapp"",
    ""packageFolder"": ""com/mycompany/myapp"",
    ""serverPort"": ""8080"",
    ""authenticationType"": ""oauth2"",
    ""cacheProvider"": ""no"",
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""postgresql"",
    ""prodDatabaseType"": ""postgresql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": false,
    ""buildTool"": ""maven"",
    ""enableSwaggerCodegen"": false,
    ""clientFramework"": ""angularX"",
    ""useSass"": false,
    ""clientPackageManager"": ""yarn"",
    ""testFrameworks"": [],
    ""jhiPrefix"": ""jhi"",
    ""enableTranslation"": false,
    ""appsFolders"": [
      ""app""
    ],
    ""directoryPath"": ""../"",
    ""jwtSecretKey"": ""replaced-by-jhipster-info"",
    ""dockerRepositoryName"": ""mydocker.registry.mycompnay.com"",
    ""dockerPushCommand"": ""docker push"",
    ""kubernetesNamespace"": ""default"",
    ""kubernetesServiceType"": ""Ingress"",
    ""ingressDomain"": ""mycompnay.com"",
    ""monitoring"": ""no"",
    ""istio"": ""no"",
    ""istioRoute"": false
  }
}
</pre>
</details>


##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<details>
<summary>JDL entity definitions</summary>

<pre>

</pre>
</details>


##### **Environment and Tools**

openjdk version ""1.8.0_171""
OpenJDK Runtime Environment (build 1.8.0_171-8u171-b11-0ubuntu0.18.04.1-b11)
OpenJDK 64-Bit Server VM (build 25.171-b11, mixed mode)

git version 2.17.1

node: v8.11.4

npm: 6.4.0

yeoman: 2.0.5

yarn: 1.9.4

##### **Browsers and Operating System**

Latest Chrome & Docker for Windows

- [x] Checking this box is mandatory (this is just to show you read everything)

<!-- Love JHipster? Please consider supporting our collective:
👉  https://opencollective.com/generator-jhipster/donate -->","Could you follow the guidelines and post your config, so I can try to reproduce?","jhipster info
Using JHipster version installed locally in current project's node_modules
Executing jhipster:info
Options:
Welcome to the JHipster Information Sub-Generator

##### **JHipster Version(s)**


app@0.0.0 /home/jhipster/app
`-- generator-jhipster@5.2.1

```


##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**


<details>
<summary>.yo-rc.json file</summary>
<pre>
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""com.mycompany.myapp""
    },
    ""jhipsterVersion"": ""5.2.1"",
    ""applicationType"": ""monolith"",
    ""baseName"": ""app"",
    ""packageName"": ""com.mycompany.myapp"",
    ""packageFolder"": ""com/mycompany/myapp"",
    ""serverPort"": ""8080"",
    ""authenticationType"": ""oauth2"",
    ""cacheProvider"": ""no"",
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""postgresql"",
    ""prodDatabaseType"": ""postgresql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": false,
    ""buildTool"": ""maven"",
    ""enableSwaggerCodegen"": false,
    ""clientFramework"": ""angularX"",
    ""useSass"": false,
    ""clientPackageManager"": ""yarn"",
    ""testFrameworks"": [],
    ""jhiPrefix"": ""jhi"",
    ""enableTranslation"": false,
    ""appsFolders"": [
      ""app""
    ],
    ""directoryPath"": ""../"",
    ""jwtSecretKey"": ""replaced-by-jhipster-info"",
    ""dockerRepositoryName"": ""mydocker.registry.mycompnay.com"",
    ""dockerPushCommand"": ""docker push"",
    ""kubernetesNamespace"": ""default"",
    ""kubernetesServiceType"": ""Ingress"",
    ""ingressDomain"": ""mycompnay.com"",
    ""monitoring"": ""no"",
    ""istio"": ""no"",
    ""istioRoute"": false
  }
}
</pre>
</details>


##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<details>
<summary>JDL entity definitions</summary>

<pre>

</pre>
</details>


##### **Environment and Tools**"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/9043,jhipster_generator-jhipster_issues_9043,"Cucumber StepDefs -  Please ensure only one glue class configures the spring context

##### **Overview of the issue**

JHipster creates Cucumber test for User which is great but a second test cannot be created because of a change to how Cucumber works.

https://github.com/cucumber/cucumber-jvm/issues/1420 describes the problem and a solution.

> Spring is setup such that only one class can provide the context configuration. Past implementations of cucumber picked an arbitrary class in an undefined manner. There was some logic to prevent you from shooting yourself in the foot. 

The error:
```
[ERROR] initializationError(com.example.foo.cucumber.CucumberTest)  Time elapsed: 0.008 s  <<< ERROR!
cucumber.runtime.CucumberException: Glue class class com.example.foo.cucumber.stepdefs.UserStepDefs and class com.example.foo.cucumber.stepdefs.UserStepDefs2 both attempt to configure the spring context. Please ensure only one glue class configures the spring context
```

##### **Motivation for or Use Case**

I want to create Cucumber tests.

##### **Reproduce the error**

Create a working folder:
```
mkdir tmp
cd tmp
```
Create basic JDL file, `jdl.jh`, file:
```
application {
  config {
    baseName foo
    packageName com.example.foo
    testFrameworks [cucumber]
  }
  entities *
}
```

Generate the application from the JDL file:
```
jhipster import-jdl jdl.jh
```

Test with no errors:
```
mvnw test
```

Create a second test:
`src/test/java/com/example/foo/cucumber/stepdefs/UserStepDefs2.java`
```
package com.example.foo.cucumber.stepdefs;

import com.example.foo.web.rest.UserResource;
import cucumber.api.java.Before;
import cucumber.api.java.en.Then;
import cucumber.api.java.en.When;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.MediaType;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.setup.MockMvcBuilders;

import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;

public class UserStepDefs2 extends StepDefs {

    @Autowired
    private UserResource userResource;

    private MockMvc restUserMockMvc;

    @Before
    public void setup() {
        this.restUserMockMvc = MockMvcBuilders.standaloneSetup(userResource).build();
    }

}
```

Test again and get the following error:
```
[INFO] Running com.example.foo.cucumber.CucumberTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.622 s <<< FAILURE! - in com.example.foo.cucumber.CucumberTest
[ERROR] initializationError(com.example.foo.cucumber.CucumberTest)  Time elapsed: 0.007 s  <<< ERROR!
cucumber.runtime.CucumberException: Glue class class com.example.foo.cucumber.stepdefs.UserStepDefs and class com.example.foo.cucumber.stepdefs.UserStepDefs2 both attempt to configure the spring context. Please ensure only one glue class configures the spring context
```

##### **Related issues**

https://github.com/cucumber/cucumber-jvm/issues/1420

##### **Suggest a Fix**

Remove context configuration from `src/test/java/com/example/foo/cucumber/stepdefs/StepDefs.java`:
```
package com.example.foo.cucumber.stepdefs;

import org.springframework.test.web.servlet.ResultActions;

public abstract class StepDefs {

    protected ResultActions actions;

}
```

And add context configuration to new file `src/test/java/com/example/foo/cucumber/stepdefs/CucumberContextConfiguration.java`:
```
package com.example.foo.cucumber.stepdefs;

import com.example.foo.FooApp;

import cucumber.api.java.Before;
import org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.ContextConfiguration;

@SpringBootTest
@AutoConfigureMockMvc
@ContextConfiguration(classes = FooApp.class)
public class CucumberContextConfiguration  {

    @Before
    public void setup_cucumber_spring_context(){
        // Dummy method so cucumber will recognize this class as glue
        // and use its context configuration.
    }
}
```

Now `mvnw test` passes.

##### **JHipster configuration**

##### **JHipster Version(s)**

```
foo@0.0.0 /Users/jeffjohnson/Projects/adt/jhipster-test/tmp
└── generator-jhipster@5.7.2 

```


##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**


<details>
<summary>.yo-rc.json file</summary>
<pre>
{
  ""generator-jhipster"": {
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""h2Disk"",
    ""enableHibernateCache"": true,
    ""enableSwaggerCodegen"": false,
    ""enableTranslation"": true,
    ""jhiPrefix"": ""jhi"",
    ""languages"": [
      ""en"",
      ""fr""
    ],
    ""messageBroker"": false,
    ""nativeLanguage"": ""en"",
    ""packageName"": ""com.example.foo"",
    ""packageFolder"": ""com/example/foo"",
    ""prodDatabaseType"": ""mysql"",
    ""searchEngine"": false,
    ""serviceDiscoveryType"": false,
    ""skipClient"": false,
    ""skipServer"": false,
    ""testFrameworks"": [
      ""cucumber""
    ],
    ""websocket"": false,
    ""baseName"": ""foo"",
    ""jhipsterVersion"": ""5.7.2"",
    ""buildTool"": ""maven"",
    ""skipUserManagement"": false,
    ""clientPackageManager"": ""npm"",
    ""applicationType"": ""monolith"",
    ""authenticationType"": ""jwt"",
    ""cacheProvider"": ""ehcache"",
    ""clientFramework"": ""angularX"",
    ""serverPort"": ""8080"",
    ""useSass"": true,
    ""jwtSecretKey"": ""bXktc2VjcmV0LXRva2VuLXRvLWNoYW5nZS1pbi1wcm9kdWN0aW9uLWFuZC10by1rZWVwLWluLWEtc2VjdXJlLXBsYWNl"",
    ""otherModules"": []
  },
  ""entities"": []
}
</pre>
</details>


##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<details>
<summary>JDL entity definitions</summary>

<pre>

</pre>
</details>


##### **Environment and Tools**

java version ""1.8.0_191""
Java(TM) SE Runtime Environment (build 1.8.0_191-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)

git version 2.19.1

node: v11.6.0

npm: 6.5.0

yeoman: 2.0.5

Docker version 18.09.0, build 4d60db4

docker-compose version 1.21.2, build a133471",Do you plan do to a PR?,"om.example.foo.FooApp;

import cimport org.springframework.test.context.ContextConfiguration;

@ContextConfiguration(classes = FooApp.class)"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/9345,jhipster_generator-jhipster_issues_9345,"version 5.8.1 broken due to HTTP version missing in jHipsterProperties class

<!--
- Please follow the issue template below for bug reports.
- If you have a support request rather than a bug, please use [Stack Overflow](http://stackoverflow.com/questions/tagged/jhipster) with the JHipster tag.
- For bug reports it is mandatory to run the command `jhipster info` in your project's root folder, and paste the result here.
- Tickets opened without any of these pieces of information will be **closed** without any explanation.
-->

##### **Overview of the issue**

NOte: I upgraded from 5 to 5.8.1 version

1)jHipsterProperties.getHttp().getVersion()
getHttp().getVersion() is not found.
in WebConfigurer.java  , JHipsterProperties.Http.Version.V_2_0 
Version is not found and it  is not in HTTP()
compilation error.


##### **Motivation for or Use Case**

This was working till a few days back with new build it fails

##### **Reproduce the error**

generate any project with 5.8.1 and check for compilation error or do a build

##### **Related issues**

<!-- Has a similar issue been reported before? Please search both closed & open issues -->

##### **Suggest a Fix**

<!-- If you can't fix the bug yourself, perhaps you can point to what might be
  causing the problem (line of code or commit) -->

##### **JHipster Version(s)**

5.8.1

##### **JHipster configuration**

##### **JHipster Version(s)**

```
uaa@0.0.0 /Users/pranavsingh/Desktop/test
└── generator-jhipster@5.8.1 

```


##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**


<details>
<summary>.yo-rc.json file</summary>
<pre>
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""com.sb.uaa""
    },
    ""jhipsterVersion"": ""5.8.1"",
    ""applicationType"": ""uaa"",
    ""baseName"": ""uaa"",
    ""packageName"": ""com.sb.uaa"",
    ""packageFolder"": ""com/sb/uaa"",
    ""serverPort"": ""9999"",
    ""authenticationType"": ""uaa"",
    ""cacheProvider"": ""hazelcast"",
    ""enableHibernateCache"": true,
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""postgresql"",
    ""prodDatabaseType"": ""postgresql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": false,
    ""buildTool"": ""gradle"",
    ""enableSwaggerCodegen"": false,
    ""testFrameworks"": [],
    ""jhiPrefix"": ""jhi"",
    ""entitySuffix"": """",
    ""dtoSuffix"": ""DTO"",
    ""otherModules"": [],
    ""enableTranslation"": false,
    ""clientPackageManager"": ""npm"",
    ""skipClient"": true
  }
}
</pre>
</details>


##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<details>
<summary>JDL entity definitions</summary>

<pre>

</pre>
</details>


##### **Environment and Tools**

java version ""1.8.0_181""
Java(TM) SE Runtime Environment (build 1.8.0_181-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)

git version 2.15.1 (Apple Git-101)

node: v10.13.0

npm: 6.8.0

yeoman: 2.0.5

yarn: 1.10.1

Docker version 18.09.2, build 6247962

docker-compose version 1.23.2, build 1110ad01


##### **Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<!--
If the error is during an entity creation or associated with a specific entity.
If you are using JDL, please share that configuration as well.
-->

##### **Browsers and Operating System**

<!-- What OS are you on? is this a problem with all browsers or only IE8? -->

-   [ ] Checking this box is mandatory (this is just to show you read everything)

<!-- Love JHipster? Please consider supporting our collective:
👉  https://opencollective.com/generator-jhipster/donate -->",Did you try by cleaning your local `~/.m2/repository` repository?,".V_2_0 
Version is not found and it  is not in HTTP"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/9808,jhipster_generator-jhipster_issues_9808,"Pagination problem when filtering

<!--
- Please follow the issue template below for bug reports.
- If you have a support request rather than a bug, please use [Stack Overflow](http://stackoverflow.com/questions/tagged/jhipster) with the JHipster tag.
- For bug reports it is mandatory to run the command `jhipster info` in your project's root folder, and paste the result here.
- Tickets opened without any of these pieces of information will be **closed** without any explanation.
-->

##### **Overview of the issue**

Using JHipster with Angular and pagination, if you access a entity list with more than one page, go to page 2 and use a filter with few results that only need one page to show,, a page change to page one is not performed.

##### **Motivation for or Use Case**

This behaviour is not present in the audit list (which is also a paginated list) so the other tables should be consistent with it.

##### **Reproduce the error**

- Access a list with more than one page
- Go to page 2
- Filter results leaving few results (<pageSize)
- In the audit list a page change to page 1 is done
- In any other paginated entity list stays in page 2

##### **Suggest a Fix**

I don't know exactly the reason but is related with the ngif of the ouside div (entity-management.component.html.ejs):

`    <div *ngIf=""<%=entityInstancePlural %> && <%=entityInstancePlural %>.length"">
        <div class=""row justify-content-center"">
            <jhi-item-count [page]=""page"" [total]=""totalItems"" [maxSize]=""5"" [itemsPerPage]=""itemsPerPage""></jhi-item-count>
        </div>
        <div class=""row justify-content-center"">
            <ngb-pagination [collectionSize]=""totalItems"" [(page)]=""page"" [pageSize]=""itemsPerPage"" [maxSize]=""5"" [rotate]=""true"" [boundaryLinks]=""true"" (pageChange)=""loadPage(page)""></ngb-pagination>
        </div>
    </div>
    <%_ } _%>`

My guess is that the ngIf prevents the inner tags to be in the DOM when the event should be raised and because of that, when it evaluates to true is too late and the event is never thrown. In fact, if I change the ngIf with a hidden, everything works.

##### **JHipster Version(s)**

I'm using JHipster 5.8.2 but the code affected hasn't changed in JHipster 6

##### **JHipster Version(s)**

```
managementApp@0.0.0 T:\workspace\app
`-- generator-jhipster@5.8.2

```


##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**


<details>
<summary>.yo-rc.json file</summary>
<pre>
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""com.app.management"",
      ""nativeLanguage"": ""es""
    },
    ""jhipsterVersion"": ""5.8.2"",
    ""applicationType"": ""monolith"",
    ""baseName"": ""management"",
    ""packageName"": ""com.app.management"",
    ""packageFolder"": ""com/app/management"",
    ""serverPort"": ""8080"",
    ""authenticationType"": ""jwt"",
    ""cacheProvider"": ""no"",
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""mysql"",
    ""prodDatabaseType"": ""mysql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": false,
    ""buildTool"": ""maven"",
    ""enableSwaggerCodegen"": false,
    ""jwtSecretKey"": """",
    ""clientFramework"": ""angularX"",
    ""useSass"": true,
    ""clientPackageManager"": ""npm"",
    ""testFrameworks"": [],
    ""jhiPrefix"": ""jhi"",
    ""entitySuffix"": """",
    ""dtoSuffix"": ""DTO"",
    ""otherModules"": [],
    ""enableTranslation"": true,
    ""nativeLanguage"": ""es"",
    ""languages"": [
      ""es"",
      ""en""
    ]
  }
}
</pre>
</details>

##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<details>
<summary>JDL entity definitions</summary>

<pre>
entity Idioma {
  codigo String required maxlength(8),
  codigoISO String required maxlength(2)
}
dto Idioma with mapstruct
paginate Idioma with pagination
service Idioma with serviceClass

</pre>
</details>

##### **Environment and Tools**

java version ""1.8.0_201""
Java(TM) SE Runtime Environment (build 1.8.0_201-b09)
Java HotSpot(TM) Client VM (build 25.201-b09, mixed mode, sharing)

node: v8.12.0

npm: 6.4.1

yeoman: 2.0.5",Can you please supply your `jhipster info` output so we can easily reproduce?,"##### **JHipster Version(s)**

```
managementApp@0.0.0 T:\workspace\app
`-- generator-jhipster@5.8.2

```


##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**


<details>
<summary>.yo-rc.json file</summary>
<pre>
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""com.app.management"",
      ""nativeLanguage"": ""es""
    },
    ""jhipsterVersion"": ""5.8.2"",
    ""applicationType"": ""monolith"",
    ""baseName"": ""management"",
    ""packageName"": ""com.app.management"",
    ""packageFolder"": ""com/app/management"",
    ""serverPort"": ""8080"",
    ""authenticationType"": ""jwt"",
    ""cacheProvider"": ""no"",
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""mysql"",
    ""prodDatabaseType"": ""mysql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": false,
    ""buildTool"": ""maven"",
    ""enableSwaggerCodegen"": false,
    ""jwtSecretKey"": """",
    ""clientFramework"": ""angularX"",
    ""useSass"": true,
    ""clientPackageManager"": ""npm"",
    ""testFrameworks"": [],
    ""jhiPrefix"": ""jhi"",
    ""entitySuffix"": """",
    ""dtoSuffix"": ""DTO"",
    ""otherModules"": [],
    ""enableTranslation"": true,
    ""nativeLanguage"": ""es"",
    ""languages"": [
      ""es"",
      ""en""
    ]
  }
}
</pre>
</details>

##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<details>
<summary>JDL entity definitions</summary>

<pre>
entity Idioma {
  codigo String required maxlength(8),
  codigoISO String required maxlength(2)
}
dto Idioma with mapstruct
paginate Idioma with pagination
service Idioma with serviceClass

</pre>
</details>

##### **Environment and Tools**

java version ""1.8.0_201""
Java(TM) SE Runtime Environment (build 1.8.0_201-b09)
Java HotSpot(TM) Client VM (build 25.201-b09, mixed mode, sharing)

node: v8.12.0

npm: 6.4.1

yeoman: 2.0.5"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/11401,jhipster_generator-jhipster_issues_11401,"@PreAuthorize @PostAuthorize @Secured not working

<!--
- Please follow the issue template below for bug reports.
- If you have a support request rather than a bug, please use [Stack Overflow](http://stackoverflow.com/questions/tagged/jhipster) with the JHipster tag.
- For bug reports it is mandatory to run the command `jhipster info` in your project's root folder, and paste the result here.
- Tickets opened without any of these pieces of information will be **closed** without any explanation.
-->

##### **Overview of the issue**
1. perform `jhipster upgrade` from 6.6.0 to `6.7.1` for jhipster UAA
2. `@PreAuthorize`, `@PostAuthorize`, `@Secured` is not work anymore, espcially `UserResource.java`

This file `MethodSecurityConfiguration.java` was deleted during upgrade.
This happen when upgrade other microservice application also.


##### **Motivation for or Use Case**

<!-- Explain why this is a bug for you -->

##### **Reproduce the error**

<!-- For bug reports, an unambiguous set of steps to reproduce the error -->

##### **Related issues**

<!-- Has a similar issue been reported before? Please search both closed & open issues -->

##### **Suggest a Fix**

<!-- If you can't fix the bug yourself, perhaps you can point to what might be
  causing the problem (line of code or commit) -->

##### **JHipster Version(s)**

$ jhipster info
INFO! Using JHipster version installed globally
INFO! Executing jhipster:info
INFO! Options: from-cli: true
Welcome to the JHipster Information Sub-Generator

##### **JHipster Version(s)**

```
uaa@0.0.0 /home/kent/workspaces/jhipster/microservice/uaa
└── (empty)

```


##### **JHipster configuration, a `.yo-rc.json` file generated in the root folder**


<details>
<summary>.yo-rc.json file</summary>
<pre>
{
  ""generator-jhipster"": {
    ""promptValues"": {
      ""packageName"": ""io.uaa"",
      ""nativeLanguage"": ""en""
    },
    ""jhipsterVersion"": ""6.7.1"",
    ""applicationType"": ""uaa"",
    ""baseName"": ""uaa"",
    ""packageName"": ""io.uaa"",
    ""packageFolder"": ""io/uaa"",
    ""serverPort"": ""9999"",
    ""authenticationType"": ""uaa"",
    ""cacheProvider"": ""hazelcast"",
    ""enableHibernateCache"": true,
    ""websocket"": false,
    ""databaseType"": ""sql"",
    ""devDatabaseType"": ""mysql"",
    ""prodDatabaseType"": ""mysql"",
    ""searchEngine"": false,
    ""messageBroker"": false,
    ""serviceDiscoveryType"": ""eureka"",
    ""buildTool"": ""gradle"",
    ""enableSwaggerCodegen"": false,
    ""jwtSecretKey"": ""bXktc2VjcmV0LXRva2VuLXRvLWNoYW5nZS1pbi1wcm9kdWN0aW9uLWFuZC10by1rZWVwLWluLWEtc2VjdXJlLXBsYWNl"",
    ""embeddableLaunchScript"": false,
    ""testFrameworks"": [""gatling""],
    ""jhiPrefix"": ""jhi"",
    ""entitySuffix"": """",
    ""dtoSuffix"": ""DTO"",
    ""otherModules"": [],
    ""enableTranslation"": true,
    ""clientPackageManager"": ""npm"",
    ""nativeLanguage"": ""en"",
    ""languages"": [""en"", ""zh-cn"", ""zh-tw""],
    ""blueprints"": [],
    ""skipClient"": true,
    ""creationTimestamp"": 1577936444933
  }
}

</pre>
</details>


##### **JDL for the Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<details>
<summary>JDL entity definitions</summary>

<pre>

</pre>
</details>


##### **Environment and Tools**

java version ""1.8.0_181""
Java(TM) SE Runtime Environment (build 1.8.0_181-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)

git version 1.8.3.1

node: v10.18.1

npm: 6.13.4

yeoman: 2.0.6

yarn: 1.21.1

Docker version 19.03.5, build 633a0ea

docker-compose version 1.16.1, build 6d1ac21

INFO! Congratulations, JHipster execution is complete!


##### **JHipster configuration**

<!--
To provide all information we need, you should run `jhipster info` in the project root folder, and
copy/paste the result here.
The `.yo-rc.json` file generated in the root folder is mandatory for bug reports. This will help us to replicate the scenario.
You should remove any sensitive information like the rememberMe key or the jwtSecretKey key.
---
If you have a JDL please wrap it in below structure
  <details>
  <summary>JDL definitions</summary>
  <pre>
     JDL content here
  </pre>
  </details>
-->

##### **Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**

<!--
If the error is during an entity creation or associated with a specific entity.
If you are using JDL, please share that configuration as well.
-->

##### **Browsers and Operating System**

<!-- What OS are you on? is this a problem with all browsers or only IE8? -->

-   [x] Checking this box is mandatory (this is just to show you read everything)

<!-- Love JHipster? Please consider supporting our collective:
👉  https://opencollective.com/generator-jhipster/donate -->",Does this happen if you create a brand new app with 6.7.1?,"entity definitions</summary>

<pre>

</pre>
</details>


##### **Environment and Tools**

java version ""1.8.0_181""
Java(TM) SE Runtime Environment (build 1.8.0_181-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)

git version 1.8.3.1

node: v10.18.1

npm: 6.13.4

yeoman: 2.0.6

yarn: 1.21.1

Docker version 19.03.5, build 633a0ea

docker-compose version 1.16.1, build 6d1ac21

INFO! Congratulations, JHipster execution is complete!


##### **JHipster configuration**

<!--
To provide all information we need, you should run `jhipster info` in the project root folder, and
copy/paste the result here.
The `.yo-rc.json` file generated in the root folder is mandatory for bug reports. This will help us to replicate the scenario.
You should remove any sensitive information like the rememberMe key or the jwtSecretKey key.
---
If you have a JDL please wrap it in below structure
  <details>
  <summary>JDL"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/10933,jhipster_generator-jhipster_issues_10933,"Npm build failing with Docker [SOLVED]

<!--
- Please follow the issue template below for bug reports.
- If you have a support request rather than a bug, please use [Stack Overflow](http://stackoverflow.com/questions/tagged/jhipster) with the JHipster tag.
- For bug reports it is mandatory to run the command `jhipster info` in your project's root folder, and paste the result here.
- Tickets opened without any of these pieces of information will be **closed** without any explanation.
-->

##### **Overview of the issue**

<!-- Explain the bug, if an error is being thrown a stack trace helps -->
I'm trying to build a react front-end web app with Docker but it's failing when run command `npm run webpack:build`, following docker output:


	ERROR in /usr/src/app/src/main/webapp/app/routes.tsx
	ERROR in /usr/src/app/src/main/webapp/app/routes.tsx(39,35):
	TS2322: Type 'typeof LoadableComponent' is not assignable to type 'ComponentClass<any, any> | FunctionComponent<any> | ComponentClass<RouteComponentProps<any, StaticContext, any>, any> | FunctionComponent<RouteComponentProps<any, StaticContext, any>>'.
	  Type 'typeof LoadableComponent' is not assignable to type 'FunctionComponent<any>'.
	    Type 'LoadableComponent' is missing the following properties from type 'ReactElement<any, string | ((props: any) => ReactElement<any, string | ... | (new (props: any) => Component<any, any, any>)>) | (new (props: any) => Component<any, any, any>)>': type, props, key

	ERROR in /usr/src/app/src/main/webapp/app/routes.tsx
	ERROR in /usr/src/app/src/main/webapp/app/routes.tsx(40,37):
	TS2322: Type 'typeof LoadableComponent' is not assignable to type 'ComponentClass<any, any> | FunctionComponent<any> | ComponentClass<RouteComponentProps<any, StaticContext, any>, any> | FunctionComponent<RouteComponentProps<any, StaticContext, any>>'.
	  Type 'typeof LoadableComponent' is not assignable to type 'FunctionComponent<any>'.

	ERROR in /usr/src/app/src/test/javascript/spec/enzyme-setup.ts
	ERROR in /usr/src/app/src/test/javascript/spec/enzyme-setup.ts(5,22):
	TS2350: Only a void function can be called with the 'new' keyword.
	npm ERR! code ELIFECYCLE
	npm ERR! errno 2
	npm ERR! spendingbetter@0.0.0 webpack: `node --max_old_space_size=4096 node_modules/webpack/bin/webpack.js ""--config"" ""webpack/webpack.dev.js"" ""--env.stats=minimal""`
	npm ERR! Exit status 2
	npm ERR! 
	npm ERR! Failed at the spendingbetter@0.0.0 webpack script.
	npm ERR! This is probably not a problem with npm. There is likely additional logging output above.

	npm ERR! A complete log of this run can be found in:
	npm ERR!     /root/.npm/_logs/2019-12-12T08_31_57_422Z-debug.log
	npm ERR! code ELIFECYCLE
	npm ERR! errno 2
	npm ERR! spendingbetter@0.0.0 webpack:build:main: `npm run webpack -- --config webpack/webpack.dev.js --env.stats=minimal`
	npm ERR! Exit status 2
	npm ERR! 
	npm ERR! Failed at the spendingbetter@0.0.0 webpack:build:main script.
	npm ERR! This is probably not a problem with npm. There is likely additional logging output above.

	npm ERR! A complete log of this run can be found in:
	npm ERR!     /root/.npm/_logs/2019-12-12T08_31_57_438Z-debug.log
	npm ERR! code ELIFECYCLE
	npm ERR! errno 2
	npm ERR! spendingbetter@0.0.0 webpack:build: `npm run cleanup && npm run webpack:build:main`
	npm ERR! Exit status 2
	npm ERR! 
	npm ERR! Failed at the spendingbetter@0.0.0 webpack:build script.
	npm ERR! This is probably not a problem with npm. There is likely additional logging output above.



##### **Motivation for or Use Case**

<!-- Explain why this is a bug for you -->
Use case is to ship a react front-end app using docker

##### **Reproduce the error**

<!-- For bug reports, an unambiguous set of steps to reproduce the error -->
To reproduce this issue you can run the following docker command
`docker build --quiet --build-arg PORT=$REACT_WEBAPP_PORT -t eu.gcr.io/${GCP_PROJECT_ID}/${DOCKER_IMAGE}:$TRAVIS_COMMIT .`

Dockerfile

	FROM node:10.15.3-slim as builder
	ARG PORT

	# Create app directory
	WORKDIR /usr/src/app

	ENV PATH /usr/src/app/node_modules/.bin:$PATH

	# Install app dependencies
	# A wildcard is used to ensure both package.json AND package-lock.json are copied
	# where available (npm@5+)
	COPY package*.json ./

	COPY node_modules/ ./

	RUN apt-get update && apt-get install netcat-openbsd -y

	RUN npm install --silent --only=production

	# Bundle app source
	COPY . .

	RUN npm run webpack:build

	### STAGE 2: Production Environment ###
	FROM nginx:1.13.12-alpine
	ARG PORT

	ENV PORT=$PORT


	COPY --from=builder /usr/src/app/build /usr/share/nginx/html
	COPY --from=builder /usr/src/app/nginx.conf /etc/nginx/conf.d/default.conf

	RUN echo ""PORT = $PORT""

	RUN sed -i 's/PORT/'""$PORT""'/g' /etc/nginx/conf.d/default.conf

	RUN echo ""daemon off;"" >> /etc/nginx/nginx.conf

	EXPOSE $PORT

	ENV JAVA_CMD=""nginx""
	CMD [""nginx""]


##### **Related issues**

<!-- Has a similar issue been reported before? Please search both closed & open issues -->


##### **JHipster Version(s)**

<!--
Which version of JHipster are you using, is it a regression?
-->
v6.3.1

##### **JHipster configuration**

<!--
To provide all information we need, you should run `jhipster info` in the project root folder, and
copy/paste the result here.
The `.yo-rc.json` file generated in the root folder is mandatory for bug reports. This will help us to replicate the scenario.
You should remove any sensitive information like the rememberMe key or the jwtSecretKey key.
---
If you have a JDL please wrap it in below structure
  <details>
  <summary>JDL definitions</summary>
  <pre>
     JDL content here
  </pre>
  </details>
-->
	{
	  ""generator-jhipster"": {
	    ""promptValues"": {
	      ""nativeLanguage"": ""en""
	    },
	    ""jhipsterVersion"": ""6.3.1"",
	    ""applicationType"": ""monolith"",
	    ""baseName"": ""spendingbetter"",
	    ""useSass"": true,
	    ""clientPackageManager"": ""npm"",
	    ""clientFramework"": ""react"",
	    ""clientTheme"": ""none"",
	    ""clientThemeVariant"": """",
	    ""authenticationType"": ""jwt"",
	    ""cacheProvider"": ""no"",
	    ""databaseType"": ""mongodb"",
	    ""devDatabaseType"": ""mongodb"",
	    ""prodDatabaseType"": ""mongodb"",
	    ""testFrameworks"": [],
	    ""jhiPrefix"": ""jhi"",
	    ""entitySuffix"": """",
	    ""dtoSuffix"": ""DTO"",
	    ""otherModules"": [],
	    ""enableTranslation"": true,
	    ""nativeLanguage"": ""en"",
	    ""languages"": [
	      ""en"",
	      ""pt-br""
	    ],
	    ""skipServer"": true,
	    ""blueprints"": []
	  }
	}

##### **Entity configuration(s) `entityName.json` files generated in the `.jhipster` directory**
	entity Person {
		id String required
	    fullName String required
	    dateOfBirth LocalDate
	    createdByUser String
	    createdDate Instant
	    lastModifiedByUser String
	    lastModifiedDate Instant
	}
	skipServer Person

	/**
	entity Child {
	id String required
		name String required
	    dateOfBirth LocalDate required
	}
	skipServer Child
	skipClient Child

	// an ignored comment
	entity Address {
		id String required
		address String required
		postalCode String required
		city String required
		stateOrProvince String required
	    country String required
	}
	skipServer Address
	skipClient Address

	relationship OneToOne {
		Person{address} to Address
	    Address{person} to Person
	}

	// defining multiple OneToMany relationships with comments
	relationship OneToMany {
		Person{children} to Child,
	}
	*/

	// Set pagination options
	paginate all with infinite-scroll

<!--
If the error is during an entity creation or associated with a specific entity.
If you are using JDL, please share that configuration as well.
-->

##### **Browsers and Operating System**

Docker version 19.03.5, build 633a0ea838
docker-compose version 1.23.1, build b02f1306

##### **Source Code**

https://github.com/rodrigorodrigues/microservices-design-patterns/tree/fixed-jhipster-app - branch `fixed-jhipster-app`

<!-- What OS are you on? is this a problem with all browsers or only IE8? -->

-   [X] Checking this box is mandatory (this is just to show you read everything)

<!-- Love JHipster? Please consider supporting our collective:
👉  https://opencollective.com/generator-jhipster/donate -->","Can you please fill out the rest of the issue template?  That will enable us to use the same config you do, the issue could relate to your prompt choices.","Use case is to ship a react front-end app using docker
To reproduce this issue you can run the following docker command
`docker build --quiet --build-arg PORT=$REACT_WEBAPP_PORT -t eu.gcr.io/${GCP_PROJECT_ID}/${DOCKER_IMAGE}:$TRAVIS_COMMIT .`

Dockerfile

	FROM node:10.15.3-slim as builder
	ARG PORT

	# Create app directory
	WORKDIR /usr/src/app

	ENV PATH /usr/src/app/node_modules/.bin:$PATH

	# Install app dependencies
	# A wildcard is used to ensure both package.json AND package-lock.json are copied
	# where available (npm@5+)
	COPY package*.json ./

	COPY node_modules/ ./

	RUN apt-get update && apt-get install netcat-openbsd -y

	RUN npm install --silent --only=production

	# Bundle app source
	COPY . .

	RUN npm run webpack:build

	### STAGE 2: Production Environment ###
	FROM nginx:1.13.12-alpine
	ARG PORT

	ENV PORT=$PORT


	COPY --from=builder /usr/src/app/build /usr/share/nginx/html
	COPY --from=builder /usr/src/app/nginx.conf /etc/nginx/conf.d/default.conf

	RUN echo ""PORT = $PORT""

	RUN sed -i 's/PORT/'""$PORT""'/g' /etc/nginx/conf.d/default.conf

	RUN echo ""daemon off;"" >> /etc/nginx/nginx.conf

	EXPOSE $PORT

	ENV JAVA_CMD=""nginx""
	CMD [""nginx""]



v6.3.1ormation we need, you should run `jhipster info` in the project root folder, and
copy/paste the result here.
The `.yo-rc.json` file generated in the root folder is mandatory for bug reports. This will help us to replicate the scenario.
You should remove any sensitive information like the rememberMe key or the jwtSecretKey key.
---
If you have a(s) `entityName.json` files generated in the `.jhipster` directory	entity Person {
		id String required
	    fullName String required
	    dateOfBirth LocalDate
	    createdByUser String
	    createdDate Instant
	    lastModifiedByUser String
	    lastModifiedDate Instant
	}
	skipServer Person

	/**
	entity Child {
	id String required
		name String required
	    dateOfBirth LocalDate required
	}
	skipServer Child
	skipClient Child

	// an ignored comment
	entity Address {
		id String required
		address String required
		postalCode String required
		city String required
		stateOrProvince String required
	    country String required
	}
	skipServer Address
	skipClient Address

	relationship OneToOne {
		Person{address} to Address
	    Address{person} to Person
	}

	// defining multiple OneToMany relationships with comments
	relationship OneToMany {
		Person{children} to Child,
	}
	*/

	// Set pagination options
	paginate all with infinite-scroll"
jhipster/generator-jhipster,https://github.com/jhipster/generator-jhipster/issues/11617,jhipster_generator-jhipster_issues_11617,"JHipster 6 hangs on import-jdl then continues after 3-5 Minutes

##### **Overview of the issue**

When starting jdl import there is big delay / hang

##### **Motivation for or Use Case**
It just shows ""Using JHipster version installed globally"" and hangs, not clear if this is because of proxy stuff, or connectivity or performance etc
>jhipster import-jdl my.jdl
INFO! Using JHipster version installed globally
-> Here it hangs 3-5 Minutes
INFO! Executing import-jdl my.jdl
INFO! Options: from-cli: true, inline: 
INFO! Found .yo-rc.json on path. This is an existing app
INFO! The JDL is being parsed.
INFO! Found entities: MyEntity.
INFO! The JDL has been successfully parsed
INFO! Generating 1 entity.

##### **Reproduce the error**

Follow official tutorial for any new jhipster app

##### **Suggest a Fix**

Is it possible to enable tracing? Perhaps there are some additional steps between those two:
Step1: INFO! Using JHipster version installed globally

Step2: INFO! Executing import-jdl my.jdl

OS: Win10 64bit node: 12.16.2 npm: 6.14.4",What version of jhipster are you running?,OS: Win10 64bit node: 12.16.2 npm: 6.14.4
mautic/mautic,https://github.com/mautic/mautic/issues/7106,mautic_mautic_issues_7106,"CSRF token error message and PHP SessionHandler Warnings

## Bug Description
I am getting the following error message displayed in the Mautic UI:
""CSRF token error. Try to refresh the page and try again.""
![screenshot 2019-01-05 11 49 34](https://user-images.githubusercontent.com/863419/50728690-e01a8b00-10e2-11e9-8a63-a7f194461e3e.png)

It happens when I've had the Mautic window open for several hours or overnight and then return to it. It looks like I remain signed into Mautic but the error displays until I refresh the browser. Upon refreshing it continues to work normally. Note: I have selected for Mautic to remember me so I don't have to sign in again.


| Q   | A
| --- | ---
| Mautic version | 2.15.0
| PHP version | 7.1.25
| Browser | Chrome Version 71.0.3578.98 (Official Build) (64-bit), Safari version 12.0.2 (14606.3.4)

### Steps to reproduce
1. Sign into Mautic, choose to stay signed in.
2. Have any Mautic page open, and leave it open for several hours or overnight.
3. Observe the error message appears in the UI.
4. Refresh the browser and observe error message goes away.
5. Can reproduce again by going to step 2.
 
### Log errors
From mautic/app/logs:
[2019-01-04 17:23:49] mautic.WARNING: PHP Warning - SessionHandler::read(): The session id is too long or contains illegal characters, valid characters are a-z, A-Z, 0-9 and '-,' - in file /home/afonseca/public_html/mautic/vendor/symfony/http-foundation/Session/Storage/Proxy/SessionHandlerProxy.php - at line 62 [] []
[2019-01-04 17:23:50] mautic.WARNING: PHP Warning - SessionHandler::write(): The session id is too long or contains illegal characters, valid characters are a-z, A-Z, 0-9 and '-,' - in file /home/afonseca/public_html/mautic/vendor/symfony/http-foundation/Session/Storage/Proxy/SessionHandlerProxy.php - at line 70 [] []
[2019-01-04 17:23:50] mautic.WARNING: PHP Warning - session_write_close(): Failed to write session data using user defined save handler. (session.save_path: /var/cpanel/php/sessions/ea-php71) - in file /home/afonseca/public_html/mautic/vendor/symfony/http-foundation/Session/Storage/NativeSessionStorage.php - at line 241 [] []

[//]: # ( Invisible comment:
Please check for related errors in the latest log file in [mautic root]/app/log/ and/or the web server's logs and post them here. Be sure to remove sensitive information if applicable. )",Did it not happen with other browsers?,) | Safari version 12.0.2 (14606.3.4
mautic/mautic,https://github.com/mautic/mautic/issues/6339,mautic_mautic_issues_6339,"Multiple value on List-Unsubscribe header

What type of report is this:

| Q  | A
| ---| ---
| Bug report? | Y
| Feature request? | N
| Enhancement? | N

## Description:
I found multiple value on List-Unsubscribe header in every email sent via Mautic if using the Monitored Inbox feature. This happens to all emails sent directly, campaigns, broadcasts, or actions on the form.

![](https://user-images.githubusercontent.com/40631294/43300962-709daab2-918c-11e8-976f-5c4300c42d53.png)

## If a bug:

| Q   | A
| --- | ---
| Mautic version | 2.14.0
| PHP version | 5.6.36

## Steps to reproduce:
1. Complete all fields in Monitored Inbox Settings.
2. Perform the procedure to send emails to contacts in any way.
3. Check the header of email that the contact received.
 
## Log errors: 
Nothing.",Does this only happen when email is queued to the filesystem and processed by a cron job?,"Description:
I found same multiple value on List-Unsubscribe header in every email sent via Mautic if using the Monitored Inbox feature. This happens to all emails sent directly, campaigns, broadcasts, or actions on the form.


## Steps to reproduce:
1. Complete all entries in Monitored Inbox Settings.
2. Perform the procedure to send emails to contacts in any way.
3. Check the header of email that the contact received.
 
## Log errors: 
Nothing."
mautic/mautic,https://github.com/mautic/mautic/issues/7174,mautic_mautic_issues_7174,"Email Overview Stats Don't Match Send Stats

[//]: # ( Invisible comment: 
IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
Before you create the issue:
IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
Search for similar report among other reported issues.
Learn how to troubleshoot at https://www.mautic.org/docs/en/tips/troubleshooting.html
Use drag&drop to attach images or other files )

## Bug Description
The stats that are in the overview don't actually match what was sent. The data shown in the graphs are correct, but the overview stats are not. Could this be a caching issue?

I've cleared the cache and the issue still remains. Any ideas?

| Q   | A
| --- | ---
| Mautic version | 2.15.0
| PHP version | 
| Browser | Chrome

### Steps to reproduce
1. Send out an email campaign.
2. View the send stats and compare to the detail stats. 

The images below are from a campaign that went out to 33,885 contacts. As you can see below the email send stats are way out of whack, nor are they consistent.

Email Overview stats: - The reads is  correct, but obviously the read rate is wrong.
![stats2](https://user-images.githubusercontent.com/41902603/51827122-8c195580-22e0-11e9-9cc9-75d76936666b.PNG)

Email sent records:
![stats3](https://user-images.githubusercontent.com/41902603/51827131-90457300-22e0-11e9-8216-ae1d255fe9e2.PNG)


Email Stats:
![stats](https://user-images.githubusercontent.com/41902603/51826920-1ca36600-22e0-11e9-95d3-63e1ca637a35.PNG)
 
### Log errors

`[2019-01-28 09:20:16] mautic.NOTICE: PHP Notice - Undefined index: ct - in file /opt/bitnami/apps/mautic/htdocs/app/bundles/PageBundle/Controller/PublicController.php - at line 452 [] []
[2019-01-28 09:20:56] mautic.NOTICE: PHP Notice - Undefined index: preferred_locale - in file /opt/bitnami/apps/mautic/htdocs/app/bundles/LeadBundle/Deduplicate/ContactMerger.php - at line 201 [] []
[2019-01-28 09:24:16] mautic.NOTICE: PHP Notice - Undefined index: ct - in file /opt/bitnami/apps/mautic/htdocs/app/bundles/PageBundle/Controller/PublicController.php - at line 452 [] []
[2019-01-28 09:24:19] mautic.NOTICE: PHP Notice - Undefined index: ct - in file /opt/bitnami/apps/mautic/htdocs/app/bundles/PageBundle/Controller/PublicController.php - at line 452 [] []`



[//]: # ( Invisible comment:
Please check for related errors in the latest log file in [mautic root]/app/log/ and/or the web server's logs and post them here. Be sure to remove sensitive information if applicable. )",What wast the original intent with this part of the code?,ined index: ct - in 26ined index: preined index: ct - in
mautic/mautic,https://github.com/mautic/mautic/issues/7763,mautic_mautic_issues_7763,"email_stats table bloat

[//]: # ( Invisible comment: 
IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
Before you create the issue:
IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
Search for similar report among other reported issues.
Learn how to troubleshoot at https://www.mautic.org/docs/en/tips/troubleshooting.html
Use drag&drop to attach images or other files )

## Bug Description
This issue persisted in Mautic for quite a long time, but seems like recent update made it worse.

Given: quite big Mautic installation, servicing 500k+ contacts, 65+ segments, sending 1m+ emails weekly. email_stats and other mautic tables are using InnoDB engine on MariaDB 10.2

After a day or two disk size of email_stats table becomes much more than data it holds. In our case the table can grow to 90Gb on disk in 1-2 days.

Steps we did to mitigate the issue:

- clear tokens column (found this recommendation a long time ago)
- clear open_details column;
- clear last_opened coluimn;
- optimize the table

After those steps the table size would go back to normal 2-3Gb from 90Gb.

It happens so often we even wrote a script doing this every night.

I wonder if there is a better way to approach the problem?


| Q   | A
| --- | ---
| Mautic version | 2.14.1 
| PHP version | 7.2
| Browser | any 

### Steps to reproduce

Just install Mautic with 500k+customers
 
### Log errors


[//]: # ( Invisible comment:
Please check for related errors in the latest log file in [mautic root]/app/log/ and/or the web server's logs and post them here. Be sure to remove sensitive information if applicable. )","How do you clear the columns, just setting them to `NULL`?",+++ on MariaDB 10.2
mautic/mautic,https://github.com/mautic/mautic/issues/7792,mautic_mautic_issues_7792,"Bundle doesn't read config changes

[//]: # ( Invisible comment: 
IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
Before you create the issue:
IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
Search for similar report among other reported issues.
Learn how to troubleshoot at https://www.mautic.org/docs/en/tips/troubleshooting.html
Use drag&drop to attach images or other files )

## Bug Description
Im new to bundle development for mautic. Im using this as a base: [HelloWorldBundle](https://github.com/anoop904/mautic/tree/master/storage/HelloWorldBundle).

My plugin I'm developing is installed and when I update the config I go back to Mautic and Click Install/Upgrade Plugins which should pick up the new plugin config but it doesn't as the menu items do not display.

My config looks like this:

```
<?php
// plugins/HelloWorldBundle/Config/config.php

return array(
    'name'        => 'Hello World Bundle',
    'description' => 'This is an example config file for a simple Hello World plugin.',
    'author'      => 'Marty Mautibot',
    'version'     => '2.0.0',
    'menu'     => array(
        'main' => array(
            'items'    => array(
                'plugin.helloworld.index' => array(
                    'id'        => 'plugin_helloworld_index',
                    'iconClass' => 'fa-globe',
                    'access'    => 'plugin:helloworld:worlds:view',
                    'parent'    => 'mautic.core.channels',
                    'children'  => array(
                        'plugin.helloworld.manage_worlds'     => array(
                            'route' => 'plugin_helloworld_list'
                        ),
                        'mautic.category.menu.index' => array(
                            'bundle' => 'plugin:helloWorld'
                        )
                    )
                )
            )
        )
    )
);
```

| Q   | A
| --- | ---
| Mautic version | 2.15.2
| PHP version | 7.1.30
| Browser | Chrome

### Steps to reproduce
1. Install Bundle into Bundles Folder
2. Click Install/Upgrade Plugins
3. Update Bundle Config
4. Clear Cache
5. Click Install/Upgrade Plugins

 
### Log errors
No errors...

[//]: # ( Invisible comment:
Please check for related errors in the latest log file in [mautic root]/app/log/ and/or the web server's logs and post them here. Be sure to remove sensitive information if applicable. )",Did you clear the cache after the config change?,"ear Cache
5. Cl"
etcd-io/etcd,https://github.com/etcd-io/etcd/issues/9851,etcd-io_etcd_issues_9851,"etcd 3.2.20 single node cannot start, logging 'etcdserver: publish error: etcdserver: request timed out'

**etcd version:** v3.2.20
**docker version:** Docker version 18.03.1-ce, build 9ee9f40
**host info:**
```bash
Linux daffodil-loc 4.4.0-47-generic #68~14.04.1-Ubuntu SMP Wed Oct 26 19:42:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
root@daffodil-loc:/srv/docker/volumes/etcd# lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.5 LTS
Release:	14.04
Codename:	trusty
```

**Symptoms:**
Unfortunately this happens randomly, but we noticed this happens on fresh ectd start, when data directories are empty.
Sometimes fresh single node etcd in docker cannot start, logs are spammed with message:
```text
etcdserver: publish error: etcdserver: request timed out
```
Moreover, any etcdctl commands end with `Error:  context deadline exceeded`.


**Attached etcd logs, data and config:**
[etcd.bug.tar.gz](https://github.com/coreos/etcd/files/2102593/etcd.bug.tar.gz)
In general we run etcd under docker with dedicated moutpoint for etcd under lvm, something like 10GB, while there is about 500MB of data.

**Fix:**
Delete data dir, so that it is empty, and start container again. Which may be problematic during docker deployments....",What's your configuration?,"**************Attached etcd logs, data and config:**
[etcd.bug.tar.gz](https://github.com/coreos/etcd/files/2102593/etcd.bug.tar.gz)

****"
etcd-io/etcd,https://github.com/etcd-io/etcd/issues/9881,etcd-io_etcd_issues_9881,"potential issue in unstable.maybeTerm function?

In func maybeTerm:

```go
        func (u *unstable) maybeTerm(i uint64) (uint64, bool) {
	if i < u.offset {
		if u.snapshot == nil {
			return 0, false
		}
		if u.snapshot.Metadata.Index == i {
			return u.snapshot.Metadata.Term, true
		}
		return 0, false
	}

	last, ok := u.maybeLastIndex()
	if !ok {
		return 0, false
	}
	if i > last {
		return 0, false
	}
	return u.entries[i-u.offset].Term, true
}
```
If unstable has snapshot, u.maybeLastIndex may return (u.snapshot.Metadata.Index, true) as below:

```go
        if u.snapshot != nil {
		return u.snapshot.Metadata.Index, true
	}
```
for this case, unstable should not have any entries, so below line of maybeTerm may fail?

```go
     return u.entries[i-u.offset].Term, true
```",Could you write a simple test case to explain the issue?,"```go
        ``````go
```
```go
```"
etcd-io/etcd,https://github.com/etcd-io/etcd/issues/10320,etcd-io_etcd_issues_10320,"Ambiguous short proto imports make it difficult to build etcd as part of a larger project

Inconsistent import paths between .protos complicate the build process, especially when imports assume that the current directory is present in the import path. This affects larger projects that use etcd as an embedded library.

Due to the directory layout, [raft_internal.proto](https://github.com/etcd-io/etcd/blob/v3.3.10/etcdserver/etcdserverpb/raft_internal.proto) gets incorporated into the [public API](https://godoc.org/github.com/coreos/etcd/etcdserver/etcdserverpb). Imports like `import ""rpc.proto"";` only work if protoc has been invoked with `github.com/coreos/etcd/etcdserver/etcdserverpb/` in the import search path.

Moving this internal proto out of the public API might be complex, so an easier fix would be to use the same format as the other imports: `import ""etcd/etcdserver/etcdserverpb/rpc.proto"";`",can you split them to multiple issues? thank you!,Moving this internal proto out of the public
aspnetboilerplate/aspnetboilerplate,https://github.com/aspnetboilerplate/aspnetboilerplate/issues/4602,aspnetboilerplate_aspnetboilerplate_issues_4602,"abp PagedResult list throw error 

```csharp
public async Task<PagedResultDto<TpmProjectListDto>> GetPaged(GetTpmProjectsInput input)
		{

            var query = _entityRepository.GetAllIncluding(t => t.CreatorUser)
               .WhereIf(!input.ProjName.IsNullOrWhiteSpace(), t => t.projName.Contains(input.ProjName))
               .WhereIf(!input.CreatorUserName.IsNullOrWhiteSpace(), t => t.CreatorUser.Name == input.CreatorUserName)
               .WhereIf(input.IsMyself, t => t.CreatorUserId == AbpSession.UserId)
               .WhereIf(input.AuditState.HasValue, t => t.AuditStatus == input.AuditState)
               .WhereIf(input.Status.HasValue, t => t.Status == input.Status);

            var count = await query.CountAsync();

			var entityList = await query
                    .OrderBy(""CreationTime"").AsNoTracking()
                    .PageBy(input)
					.ToListAsync();

			var entityListDtos =entityList.MapTo<List<TpmProjectListDto>>();

			return new PagedResultDto<TpmProjectListDto>(count,entityListDtos);
		}
```

this is my code ,but exec throw error
error pointing 
`var entityList = await query .OrderBy(""CreationTime"").AsNoTracking() .PageBy(input).ToListAsync();`

I clicked the query button a few times and the problem didn't exist.

```
> ERROR 2019-06-10 23:00:27,213 [13   ] Mvc.ExceptionHandling.AbpExceptionFilter - Collection was modified; enumeration operation may not execute.
System.InvalidOperationException: Collection was modified; enumeration operation may not execute.
   at System.Collections.Generic.List`1.Enumerator.MoveNextRare()
   at Microsoft.EntityFrameworkCore.Query.Expressions.SelectExpression.PushDownSubquery()
   at Microsoft.EntityFrameworkCore.SqlServer.Query.Sql.Internal.SqlServerQuerySqlGenerator.RowNumberPagingExpressionVisitor.VisitSelectExpression(SelectExpression selectExpression)
   at Microsoft.EntityFrameworkCore.SqlServer.Query.Sql.Internal.SqlServerQuerySqlGeneratorFactory.CreateDefault(SelectExpression selectExpression)
   at Microsoft.EntityFrameworkCore.Query.Internal.ShaperCommandContext.GetRelationalCommand(IReadOnlyDictionary`2 parameters)
   at Microsoft.EntityFrameworkCore.Query.Internal.AsyncQueryingEnumerable`1.AsyncEnumerator.BufferlessMoveNext(DbContext _, Boolean buffer, CancellationToken cancellationToken)
   at Microsoft.EntityFrameworkCore.SqlServer.Storage.Internal.SqlServerExecutionStrategy.ExecuteAsync[TState,TResult](TState state, Func`4 operation, Func`4 verifySucceeded, CancellationToken cancellationToken)
   at Microsoft.EntityFrameworkCore.Query.Internal.AsyncQueryingEnumerable`1.AsyncEnumerator.MoveNext(CancellationToken cancellationToken)
   at System.Linq.AsyncEnumerable.SelectEnumerableAsyncIterator`2.MoveNextCore(CancellationToken cancellationToken) in D:\a\1\s\Ix.NET\Source\System.Interactive.Async\Select.cs:line 106
   at System.Linq.AsyncEnumerable.AsyncIterator`1.MoveNext(CancellationToken cancellationToken) in D:\a\1\s\Ix.NET\Source\System.Interactive.Async\AsyncIterator.cs:line 98
   at Microsoft.EntityFrameworkCore.Query.Internal.AsyncLinqOperatorProvider.ExceptionInterceptor`1.EnumeratorExceptionInterceptor.MoveNext(CancellationToken cancellationToken)
   at System.Linq.AsyncEnumerable.Aggregate_[TSource,TAccumulate,TResult](IAsyncEnumerable`1 source, TAccumulate seed, Func`3 accumulator, Func`2 resultSelector, CancellationToken cancellationToken) in D:\a\1\s\Ix.NET\Source\System.Interactive.Async\Aggregate.cs:line 120
   at TgNetJZ.Project.TpmProjectAppService.GetPaged(GetTpmProjectsInput input) in 
   at lambda_method(Closure , Object )
   at Microsoft.AspNetCore.Mvc.Internal.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)
   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()
   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()
   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)
   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)
   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()
   at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextExceptionFilterAsync()
```",Can you provide a project to reproduce this problem?,"``csharp``
``
```
```"
aspnetboilerplate/aspnetboilerplate,https://github.com/aspnetboilerplate/aspnetboilerplate/issues/1418,aspnetboilerplate_aspnetboilerplate_issues_1418,"ResultWrapperHandler tries to wrap files content

Hi, 
i have several web api which returns file content ( like images or pdfs ) depending on the Accept type of the rest call ( i implemented some MediaTypeFormatter to do this ). When i set 

`webapiConfig.DefaultWrapResultAttribute.WrapOnSuccess = true;`

ResultWrapperHandler tries to wrap file content. To solve this problem i inherit ResultWrapperHandler class like this

```

public class CustomResultWrapperHandler : ResultWrapperHandler, ITransientDependency
{
        private readonly IAbpWebApiConfiguration webApiConfiguration;

        public CustomResultWrapperHandler(IAbpWebApiConfiguration webApiConfiguration)
            : base(webApiConfiguration)
        {
            this.webApiConfiguration = webApiConfiguration;
        }


    protected override void WrapResultIfNeeded(HttpRequestMessage request, HttpResponseMessage response)
    {
        if (!response.IsSuccessStatusCode)
        {
            return;
        }

        if (!request.Headers.Accept.Any(a => a.MediaType == ""application/json""))
        {
            return;
        }


        base.WrapResultIfNeeded(request, response);
    }
}


```
I think that Abp should include the test on the ""Accept"" header in ResultWrapperHandler , what do you think ?",How do you return file as JSON result? Are you returning byte[] ?,"public class CustomResultWrapperHandler : ResultWrapperHandler, ITransientDependency
{
        private readonly IAbpWebApiConfiguration webApiConfiguration;

        public CustomResultWrapperHandler(IAbpWebApiConfiguration webApiConfiguration)
            : base(webApiConfiguration)
        {
            this.webApiConfiguration = webApiConfiguration;
        }


        {"
aspnetboilerplate/aspnetboilerplate,https://github.com/aspnetboilerplate/aspnetboilerplate/issues/4487,aspnetboilerplate_aspnetboilerplate_issues_4487,"Building errors using electron

When I build the angular application to be used for Electron, I get errors mention below.


```
ERROR in src\app\users\reset-password\reset-password.component.html(21,42): : Property 'loading' does not exist on type 'ResetPasswordDialogComponent'. Did you mean 'isLoading'?
src\app\users\reset-password\reset-password.component.html(24,73): : Property 'loading' does not exist on type 'ResetPasswordDialogComponent'. Did you mean 'isLoading'?
src\app\users\reset-password\reset-password.component.html(21,63): : Expected 1 arguments, but got 0.
```

fix:
```
<button mat-button type=""button"" [disabled]=""isLoading"" (click)=""close()"">
```

```
ERROR in src\app\users\reset-password\reset-password.component.html(24,73): : Property 'loading' does not exist on type 'ResetPasswordDialogComponent'. Did you mean 'isLoading'?
src\app\users\reset-password\reset-password.component.html(21,65): : Expected 1 arguments, but got 0.
```

fix:
```
<button mat-flat-button type=""submit"" flex=""15"" color=""primary"" [disabled]=""!resetPasswordModal.form.valid || isLoading"">
```

```
ERROR in src\app\users\reset-password\reset-password.component.html(21,65): : Expected 1 arguments, but got 0.
```

fix:
```
<button mat-button type=""button"" [disabled]=""isLoading"" (click)=""close(false)"">
```",When did you download your solution?,"``````

``````

``````

``````


```"
SleepyTrousers/EnderIO,https://github.com/SleepyTrousers/EnderIO/issues/5089,SleepyTrousers_EnderIO_issues_5089,"Cannot paint vanilla blocks, such as trapdoors

### Issue description:

The vanilla wooden trap door, iron trap door, and crafting table all have the tooltip “Not painted,” yet I am unable to paint them in the painting machine. I can’t place them in the right slot of the painting machine.

### Steps to reproduce:

1. Get a wooden trapdoor or iron trapdoor.
2. Try to paint it in the painting machine.

### Affected versions

* Ender IO: 5.0.40
* EnderCore: 0.5.45
* Minecraft: 1.12.2
* Forge: 14.23.5.2781
* SpongeForge: No
* OptiFine: Yes
* Single-player or server: Server

(By the way, while I’m here, does the farmer have the same ranges as the 1.10.2 version of Ender IO [15×15 with an octadic capacitor) in the 1.12.2 version?)",Do you also have LiteLoader in the pack? LiteLoader is known to interfere with Forge's feature to replace vanilla blocks and items.,the painting machine. I can’t place them in the right slot of
gohugoio/hugo,https://github.com/gohugoio/hugo/issues/6819,gohugoio_hugo_issues_6819,"The comments page has a link to an indecent page!

Hello,

I was just going through the various comments systems on this page: https://gohugo.io/content-management/comments/

But one of them,`txtpen` is probably hacked, it redirects to an indecent / obscene page.

Please update/remove it or fix the link issue.

Thanks!

P.S. Also please note that `utterance` is not working at the moment due to a CORS error.

Update: `utterance` is now working.",Maybe check your own DNS settings?,Update: `utterance` is now working.
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/4308,backdrop_backdrop-issues_issues_4308,"PHP 7.4: Notice: Trying to access array offset on value of type <int, null>

**Description of the bug**
There are a few places where we check the first character of a string or int using the array access syntax. As of PHP 7.4 this now gives an error notice. We should convert each of these to use substr() for checking the string.

**Steps To Reproduce**
To reproduce the behavior:
1. Upgrade to PHP 7.4
2. Try to use anything with AJAX or submit a form

---
PR by @hosef: https://github.com/backdrop/backdrop/pull/3079",Did you find additional places?,"---
PR by @hosef: https://github.com/backdrop/backdrop/pull/3079"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/4265,backdrop_backdrop-issues_issues_4265,"Enforce some basic password constraints: no username, no email

**Description of the need**
Currently Backdrop (and D7) allow anything to be entered in the password. I think that's okay for the most part (contrib modules like Password Policy (d7-only?) can provide more constraints) but I do feel that there are a couple obvious constraints that should be enforced: **username** and **email address**.

**Proposed solution**
Don't allow users to enter username or email in their password.

---
PR by @indigoxela: https://github.com/backdrop/backdrop/pull/3053",What do people think?,"---
PR by @indigoxela: https://github.com/backdrop/backdrop/pull/3053"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/382,backdrop_backdrop-issues_issues_382,"[UX] Better Taxonomy permissions

Since discovering it 8 months ago, I have been installing the [Taxonomy access fix module](https://www.drupal.org/project/taxonomy_access_fix) on all my sites. It is a great, simple module that fixes the lacking Taxonomy permissions in Drupal core. I recommend implementing it (or something similar) in Backdrop.

Basically, it adds additional permissions for accessing Vocabulary pages and _adding_ new terms (currently to have to give users the 'Administer vocabularies and terms' permission to do this).

There is an issue for doing the same thing in Drupal 8 core here: https://www.drupal.org/node/1848686 (which might be helpful if we decide to do the same).

---
PR by @BWPanda: https://github.com/backdrop/backdrop/pull/508","Could we review exactly what changes we want to port over from Taxonomy access fix module, or if there's anything we _don't_ want from it?","---
PR by @BWPanda: https://github.com/backdrop/backdrop/pull/508"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/3622,backdrop_backdrop-issues_issues_3622,"Warning when creating custom options for list field

**Description of the bug**
I was creating a list (text) field and added some custom options, including custom keys. When I saved the form I got the following warnings:

> Warning: A non-numeric value encountered in _form_options_from_text() (line 334 of /[SNIP]/core/modules/field/modules/options/options.element.inc).

**Steps To Reproduce**
To reproduce the behavior:
1. Add a new field to a content type
2. Select 'List (text)' as the field type
3. In Field Settings, tick 'Custom keys' and add some custom keys/labels (e.g. 'first > First one, second > Next one, third > Last one')
4. Click 'Save Field Settings'

**Actual behavior**
The above warning is displayed for each option you added (e.g. 3 options, 3 warnings).

**Expected behavior**
No warnings, carry on as normal.

---
PR by @herbdool: https://github.com/backdrop/backdrop/pull/2565",Do you see the same error in D7 with options_element module?,"---
PR by @herbdool: https://github.com/backdrop/backdrop/pull/2565"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/3485,backdrop_backdrop-issues_issues_3485,"PHP Fatal error: Cannot redeclare form_options_from_text

*Describe the bug:**
1) Attempt to upgrade core from 1.11.3 (contrib ""Options element"" v 1.x-1.0 is enabled for using with ""Webform"" module) to 1.12.0:
`PHP Fatal error:  Cannot redeclare form_options_from_text() (previously declared in  /DOC_ROOT/core/modules/field/modules/options/options.module:567) in  /DOC_ROOT/modules/contrib/options_element/options_element.module on line 173`
2) Attempt to uninstall previously disabled contrib module fire the same fatal error again. 
**Workaround:**
Disable contrib ""Options element"" - upgrade going as expected, but module cannot be uninstalled, disabled only.
**Expected behavior:**
Check if this contrib exists, then disable/uninstall it before going to core upgrade.
**Additional information:**
- Operating System and its version: Debian GNU/Linux 9.6 as is
- Web server and its version: Apache/PHP/MariaDB from Debian distribution
- Browser(s) and their versions: any

---
PR by @klonos: https://github.com/backdrop/backdrop/pull/2564",Should you uninstall options element before upgrade?,"---
PR by @klonos: https://github.com/backdrop/backdrop/pull/2564"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/1259,backdrop_backdrop-issues_issues_1259,"Custom block content not updated if you are switched to Source mode before saving the block in Layouts or modal window

**Issue Summary (as of October 1, 2019):**

If you edit a custom block in the source mode while using the block in the layouts or modal window, the changes are lost. 

This does not seem to be an issue with CKEditor, since it is not a problem in other situations, only the specific conditions mentioned. @serundeputy Tested this issue against this pull request which did not solve the problem. https://github.com/backdrop/backdrop/pull/2361

**Steps to reproduce:**

- Download and install Backdrop v1.11.2
- Create a custom block. (/admin/structure/block/add)
- Add a layout (/admin/structure/layouts/add)
- Add the custom block to the layout.
- Click the ""Configure"" button to the right of the custom block.
- In the ""Block content"" editor input, click the ""Source"" button.
- Edit the block content.
- Click ""Update block""
- Click ""Save layout""

**Original Issue:**

If we try to change image URL (created before in our block) then it would not be saved if it is done in Source mode. You need to switch to normal mode after the change then it will be saved.

![block](https://cloud.githubusercontent.com/assets/13515302/10119532/78d60fbe-64a1-11e5-9352-8ba809937c0b.gif)

![block2](https://cloud.githubusercontent.com/assets/13515302/10119535/8550a7ea-64a1-11e5-8bef-d881b78a3aee.gif)",what software/app/plugin do you use to take screenshot and add the text + arrows?,"**Issue Summary:**

If you edit a custom block in the source mode while using the block in the layouts or modal window, the changes are lost. 

This does not seem to be an issue with CKEditor, since it is not a problem in other situations, only the specific conditions mentioned. 

**Original Issue:**"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/2474,backdrop_backdrop-issues_issues_2474,"[UX] Add better description text for file directory setting

We should improve the description text for the `Public file system path ` setting. Here's what we have now: 

`A local file system path where public files will be stored. This directory must exist and be writable by Backdrop. This directory must be relative to the Backdrop installation directory and be accessible over the web.`

Original issue follows.

---

Hello Developers,

I upgraded to Backdrop 1.6.0 yesterday. Everything works but unfortunately the pictures can not be found in the blog post in the text.

My file system is located in the FTP account under **/files**.

In the backend of the Backdrop CMS I have the directory `files`. This is also recognized. Unfortunately, the image from `/files/files/styles` in the frontend does not load.

The Google Chrome Inspector shows me that the image can not be found. But the picture still exists.

You can see this under the URL http://wpzweinull.ch/cms/backdrop/backdropcms-1-6-0-update-online-mit-bugfixes-neuen-features times. Probably something is wrong with me, only what exactly?

Thanks for the help in advance.",Can you give some information to this question?,"We should improve the description text for the `Public file system path ` setting. Here's what we have now: 

`A local file system path where public files will be stored. This directory must exist and be writable by Backdrop. This directory must be relative to the Backdrop installation directory and be accessible over the web.`

Original issue follows.

---"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/3862,backdrop_backdrop-issues_issues_3862,"Exclude content with hidden path display from search results if the user has no permission to view such content.

**Description of the bug**
Content of types with the setting ""Hide path display"" (introduced in #100) is displayed in Backdrop core search results. While I'm not sure if it's clearly a bug, at least I didn't expect such content to show up, and in my opinion it also doesn't make sense.

**Steps To Reproduce**

0. If not already done, enable the Search functionality of Backdrop core.
1. Enable ""Hide path display"" in the *Display settings* of the content type above, e.g. for Posts.
2. Go to `admin/config/search/settings`, and invalidate the search index.
3. Rebuild the search index by running cron several times, until it's 100%.
4. Search for a string which exists in content of the 'hidden path' type.

**Actual behavior**

There are items of the 'hidden path' content type in the search results.

**Expected behavior**

Hidden path content items don't show up in the search results.

**Additional information**

- Backdrop CMS version: 1.12.x:

---
PR by @herbdool: https://github.com/backdrop/backdrop/pull/2824","Does the search result display a link that is broken, or just list the content with no link?","---
PR by @herbdool: https://github.com/backdrop/backdrop/pull/2824"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/3587,backdrop_backdrop-issues_issues_3587,"Add a mod_php7 block to .htaccess

The PHP directives in the default core .htaccess file are all inside `<IfModule mod_php5.c>`. I noticed when I ran over max_input_vars trying to sort a large vocabulary.

---

PR by @klonos: https://github.com/backdrop/backdrop/pull/2534",Maybe we should craft a mix of Drupal 7 & 8 .htaccess file ?,"---

PR by @klonos: https://github.com/backdrop/backdrop/pull/2534"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/3972,backdrop_backdrop-issues_issues_3972,"Add new translatable  HTML5 date form elements: html_datetime, html_date, html_time

**Description of the bug**
If the strings ""am"" and ""pm"" (context ampm) have translations in the currently used language, these translations prevent date validation of node ""Authored on"" and ""Publish on"" date.

**Steps To Reproduce**
To reproduce the behavior:
1. Install an additional language in Backdrop
2. Go to admin/config/regional/translate and translate ""am"" and ""pm"" (if there's no translation yet)
3. Make sure, the core date module is enabled (it is by default)
4. Add or edit a node on the _additional_ language (not ""en"") and try to save it

**Actual behavior**
Error for german (as an example):
Die Werteingabe für das Feld ist ungültig: The date ""2019-08-08 01:11 vormittags"" does not match the expected format.

The problem is that ""am"" got translated to ""vormittags"" and of course this won't validate. A date string like ""2019-08-11 08:24 vormittags"" will always return FALSE in strtotime().

**Expected behavior**
I'd expect that either the ""Authored on"" date isn't translated or a proper date format for current language is used, that validates.

**Additional information**
- Backdrop CMS version: 1.13.3 (fresh install)
- german translation from https://localize.backdropcms.org/translate/downloads, latest, german (which has translation for am/pm)

Validation fails in [class BackdropDateTime](https://github.com/backdrop/backdrop/blob/1.x/core/includes/date.class.inc)

The date pattern in use is defined in core/modules/node/node.pages.inc, hardcoded to 'Y-m-d g:i a'.

My current workaround is to delete the translations for am/pm via translation interface. Translating it to am/pm is another option.

**Same bug in Drupal**
Here's the related Drupal [date module Issue](https://www.drupal.org/project/date/issues/2359653). Please note that the provided patch there doesn't fix the problem.

---

PR by @indigoxela adding html 5 date input https://github.com/backdrop/backdrop/pull/2852

~PR by @klonos (crossport of the patch in https://www.drupal.org/project/date/issues/2359653#comment-9393607): https://github.com/backdrop/backdrop/pull/2813~ [Crossing out since it seems that testing was primarily focused on @indigoxela's PR.",Do you know if it happens in Drupal 7 as well?,"---
PR by @klonos (crossport of the patch in https://www.drupal.org/project/date/issues/2359653#comment-9393607): https://github.com/backdrop/backdrop/pull/2813"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/3966,backdrop_backdrop-issues_issues_3966,"Dashboard module conflicts with Block Reference Module

When attempting to view a node type containing a block reference field (with a value), I am getting the following error:

""Error: Call to a member function hasContexts() on null in dashboard_preprocess_block() (line 218...""


dashboard_preprocess_block function in dashboard.module @line 217 to 218 is:

```
$layout = $variables['layout'];
if ($layout->hasContexts(array('dashboard'))) {
```
The problem with this appears to be that a block called through a block ref field may not have a layout assigned.  This will result in $layout being Null, which causes the error.

Having a null check at the beginning of the if statement @line 218 solves this issue:

```
if (!is_null($layout) && $layout->hasContexts(array('dashboard'))) {
```

---

PR by @olafgrabienski: https://github.com/backdrop/backdrop/pull/2839",Can you please provide step by step instructions? Thanks.,"---

PR by @olafgrabienski: https://github.com/backdrop/backdrop/pull/2839"
backdrop/backdrop-issues,https://github.com/backdrop/backdrop-issues/issues/4225,backdrop_backdrop-issues_issues_4225,"Per vocabulary permissions do not appear to do anything

giving a role permission to edit terms in a particular vocabulary does not allow users with that role to edit terms in the vocabulary UNLESS they also have the ""administer vocabularies and terms"" permission, which defeats the purpose of having per-vocabulary permissions.

my scenario:

there are permissions defined for editing and deleting each defined vocabulary, on the permissions page (/admin/config/people/permissions).

i have checked the edit permission on a vocabulary for a defined role ""content editor"" (i do NOT want to give them access to any other vocabularies), and saved. i have cleared all caches.

but when i log in as a user with the ""content editor"" role, and i try to access the term edit form for a term in that vocabulary (/taxonomy/term/47/edit), i get an access denied from backdrop.

hopefully this is enough information. if not, please let me know what more i can provide.

---
~~PR by @indigoxela: https://github.com/backdrop/backdrop/pull/3052 (rename permission, closed in favor of the more lightweight change)~~
PR by @quicksketch: https://github.com/backdrop/backdrop/pull/3067 (update access check)",Can you have a look at it?,"---
PR by @indigoxela: https://github.com/backdrop/backdrop/pull/3052"
salesagility/SuiteCRM,https://github.com/salesagility/SuiteCRM/issues/8320,salesagility_SuiteCRM_issues_8320,"Error importing Accounts limiting imports to 100 at a time

<!--- Provide a general summary of the issue in the **Title** above -->
<!--- Before you open an issue, please check if a similar issue already exists or has been closed before. --->
<!--- If you have discovered a security risk please report it by emailing security@suitecrm.com. This will be delivered to the product team who handle security issues. Please don't disclose security bugs publicly until they have been handled by the security team. --->

When importing Accounts from a CSV file we get the following error:

NOTICE: [8] Array to string conversion on line 630 in file /modules/jjwg_Maps/jjwg_Maps.php

#### Issue
<!--- Provide a more detailed introduction to the issue itself, and why you consider it to be a bug -->
<!--- Ensure that all code ``` is surrounded ``` by triple back quotes. This can also be done over multiple lines -->
Line 630

` $GLOBALS['log']->debug(__METHOD__.' $aInfo: '.$aInfo);`
$aInfo is returned a couple of lines above from the function: defineMapsAddress.

defineMapsAddress returns an array OR false, hence if you get an array into $aInfo you get an array to string conversion error.

#### Expected Behavior
<!--- Tell us what should happen -->

#### Actual Behavior
<!--- Tell us what happens instead -->
<!--- Also please check relevant logs (suitecrm.log, php error.log etc.) -->

Should not get this error, without the error the import will process properly.

#### Possible Fix
<!--- Not obligatory, but suggest a fix or reason for the bug -->
replicate the standard code used in the line above this one for adding to the debug log:

`$GLOBALS['log']->debug(__METHOD__.' $aInfo: '.print_r($aInfo,true));`

#### Steps to Reproduce
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug include code to reproduce, if relevant -->
1. Geocoding Turned ON
2.Pre-existing Addresses already Geocoded
3.Address Caching Turned ON
4.Use an Address already in the Cache
5. Import file with aforementioned address already in cache (probably as a new account)

#### Context
<!--- How has this bug affected you? What were you trying to accomplish? -->
<!--- If you feel this should be a low/medium/high priority then please state so -->
Probably a medium to high priority, as potential users start using SuiteCRM they will be default be importing data, this would be a  hurdle for them that wouldn't be hard to fix.

#### Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
* SuiteCRM Version used: 7.11.x
* Browser name and version (e.g. Chrome Version 51.0.2704.63 (64-bit)): Chrome/FF/NA
* Environment name and version (e.g. MySQL, PHP 7): MariaDB 10/PHP7.1
* Operating System and version (e.g Ubuntu 16.04):Debian Stretch","Could you please provide further steps to reproduce? The error you pointed out is only a notice and shouldn't cause the import to fail

Thanks :+1:",", hence if you get an array into $aInfo you get an array to string conversion errorGeocoding Turned ON
2.Pre-existing Addresses already Geocoded
3.Address Caching Turned ON
4.Use an Address already in the Cache
5."
ShareX/ShareX,https://github.com/ShareX/ShareX/issues/4510,ShareX_ShareX_issues_4510,"Thumbnail previews not updating

`2019-12-04 21:16:03.321 - Exception:
System.InvalidOperationException: Object is currently in use elsewhere.
   at System.Drawing.Image.get_Width()
   at ShareX.HelpersLib.ImageHelpers.ResizeImage(Image img, Int32 width, Int32 height, Boolean allowEnlarge, Boolean centerImage, Color backColor)
   at ShareX.HelpersLib.ImageHelpers.ResizeImage(Image img, Size size, Boolean allowEnlarge, Boolean centerImage)
   at ShareX.TaskThumbnailPanel.UpdateThumbnail(Image image)`

![image](https://user-images.githubusercontent.com/8891586/70206173-76807380-16db-11ea-89a8-52808647e55f.png)

I've tried reinstalling it but that didn't seem to fix it, I'm not too sure what I did in the settings to cause this to happen. Other than having my personal folder on my SSD and my bulk screenshot storage on my HDD

EDIT: Seems having the ShareX window unminimized from taskbar fixes it but closing it and having it sit in the taskbar/tray area causes it at least from what I've tested so far",What is your after capture tasks?,Seems having the ShareX window unminimized from taskbar fixes it but closing it and having it sit in the taskbar/tray area causes it at least from what I've tested so far
cockpit-project/cockpit,https://github.com/cockpit-project/cockpit/issues/12559,cockpit-project_cockpit_issues_12559,"Physical DIMMs Not Displaying Correct (Dual Channel DIMMs)

Cockpit version: 200
OS: Fedora 30
Page: /system/hwinfo

In a system with dual rank DIMMs the page only displays the last processed DIMM from the `dmidecode -t memory` command for the particular rank. This may apply to quad rank systems too.

[Problem area](https://github.com/cockpit-project/cockpit/blob/master/pkg/lib/machine-info.js#L216-L218) is here. Probably need to differentiate on more than locator here - might need to add channel to the information.

Steps to reproduce:

1. Using `dmidecode -t memory` print the information for the system on one with dual ranked DIMMs that are in the same rank but different channels.
2. Compare the output from `dmidecode -t memory` to the `/system/hwinfo` page.

```
# dmidecode 3.2
Getting SMBIOS data from sysfs.
SMBIOS 2.8 present.

Handle 0x0033, DMI type 16, 23 bytes
Physical Memory Array
	Location: System Board Or Motherboard
	Use: System Memory
	Error Correction Type: None
	Maximum Capacity: 32 GB
	Error Information Handle: Not Provided
	Number Of Devices: 4

Handle 0x0035, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 0
	Bank Locator: CHANNEL A
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer0
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum0
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V

Handle 0x0036, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 1
	Bank Locator: CHANNEL A
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer1
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum1
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V

Handle 0x0037, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 0
	Bank Locator: CHANNEL B
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer2
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum2
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V

Handle 0x0038, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 1
	Bank Locator: CHANNEL B
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer3
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum3
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V
```","Can you please attach the output of `dmidecode -t memory` here, so that this becomes reproducible?","```
# dmidecode 3.2
Getting SMBIOS data from sysfs.
SMBIOS 2.8 present.

Handle 0x0033, DMI type 16, 23 bytes
Physical Memory Array
	Location: System Board Or Motherboard
	Use: System Memory
	Error Correction Type: None
	Maximum Capacity: 32 GB
	Error Information Handle: Not Provided
	Number Of Devices: 4

Handle 0x0035, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 0
	Bank Locator: CHANNEL A
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer0
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum0
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V

Handle 0x0036, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 1
	Bank Locator: CHANNEL A
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer1
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum1
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V

Handle 0x0037, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 0
	Bank Locator: CHANNEL B
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer2
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum2
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V

Handle 0x0038, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x0033
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 8192 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 1
	Bank Locator: CHANNEL B
	Type: DDR3
	Type Detail: Synchronous Unbuffered (Unregistered)
	Speed: 1866 MT/s
	Manufacturer: A1_Manufacturer3
	Serial Number: 00000000
	Asset Tag: A1_AssetTagNum3
	Part Number: R938G2401U2S      
	Rank: 2
	Configured Memory Speed: 1866 MT/s
	Minimum Voltage: 1.5 V
	Maximum Voltage: 1.5 V
	Configured Voltage: 1.5 V
```"
wenzhixin/bootstrap-table,https://github.com/wenzhixin/bootstrap-table/issues/3878,wenzhixin_bootstrap-table_issues_3878,"Internal method “setFieldIndex” has bug？

内部方法setFieldIndex中的124~129行：
In bootstrap-table.js, Line 124 to 129 in the Method 'setFieldIndex' :
```
for (k = 0; k < rowspan; k++) {
    flag[i + k][index] = true;
}
for (k = 0; k < colspan; k++) {
    flag[i][index + k] = true;
}
```
这两个循环并不能很好的设置标志位，对于占用两行两列的表头有问题，我认为应该改为：
It is not good to set up the flag in these two loop,There is a problem for the head of two rows and two columns,I think it should be changed to:
```
for (k = 0; k < rowspan; k++) {
    for (l = 0; l < colspan; l++) {
         flag[i + k][index + l] = true;
    }
}
```","Can you translate this issue to english, please?","In bootstrap-table.js, Line 124 to 129 in the Method 'setFieldIndex' :It is not good to set up the flag in these two loop,There is a problem for the head of two rows and two columns,I think it should be changed to:"
wenzhixin/bootstrap-table,https://github.com/wenzhixin/bootstrap-table/issues/3913,wenzhixin_bootstrap-table_issues_3913,"使用BootStrap Table封装js 时 detailView detailFormatter的问题

**The environmental background of the problem and what methods have been tried by yourself.**
**It's okay to use the following method：**
```
$('#tableCompany').bootstrapTable({
               height: 650,
               detailView: true,
              detailFormatter: function (index, row) {
                 return 'Remark：' + row.Remark + ';'>LogDate：row.LogTime;},
             columns: [
                   ],
            });
```

**There's a problem with the following JS：**
```
   var tableList = { id:""listTable""};
    $(function () {
        var defaultColunms = tableList.initColumn();
         var config = {
            detailView: true,
                detailFormatter: function (index, row) {
                    return 'Remark：' + row.Remark + ';'>LogDate：row.LogTime;},
                }}
        var table = new BSTable(tableList.id, ""/Company/GetJsonData"", defaultColunms,config );
        tableList.table = table.init();
    });

    tableList.initColumn = function () {
    return []}
```

**Related code**
```
(function () {

var BSTable = function (bstableId, url, columns, extendConfig) {
    this.btInstance = null;
    this.bstableId = bstableId; 
    this.url = url;
    this.method = ""get"";
    this.paginationType = ""server"";
    this.toolbarId = bstableId + ""Toolbar"";
    this.columns = columns;
    this.height = 690;
    this.data = {};
    this.queryParams = {}; 
    this.extendConfig = extendConfig;
};

BSTable.prototype = {
    /**
     * 初始化bootstrap table
     */
    init: function () {
        var tableId = this.bstableId;
        var qParams = this.queryParams;
        var defaultConfig = {
            contentType: ""application/json"",
            url: this.url,             
            method: this.method,        
            ajaxOptions: {           
                data: this.data
            },
            toolbar: ""#"" + this.toolbarId,
            striped: true,            
            cache: false,            
            pagination: true,          
            sortable: true,            
            sortOrder: ""asc"",      
            pageNumber: 1,               
            pageSize: 15,             
            pageList: [15, 30, 50, 100],    
            queryParamsType: 'limit',  
            queryParams: function (params) {
                var temp = {
                    rows: params.limit,
                    page: (params.offset) / params.limit + 1,
                    sidx: params.sort,
                    sord: params.order,
                    keywords: params.search
                };
                return $.extend(temp, qParams);
            }, 
            sidePagination: this.paginationType,  
            search: true,            
            strictSearch: false,         
            showColumns: true,        
            showRefresh: true,         
            minimumCountColumns: 2,    
            clickToSelect: true,       
            searchOnEnterKey: false,     
            columns: this.columns,      
            height: this.height,
            icons: {
                refresh: 'glyphicon-repeat',
                toggle: 'glyphicon-list-alt',
                columns: 'glyphicon-list'
            },
            iconSize: 'outline'
        };
        var bsTableConfig = {};
        if (typeof this.extendConfig == ""object"") {
            bsTableConfig = $.extend(defaultConfig, this.extendConfig);
        }
        else {
            bsTableConfig = defaultConfig;
        }
        console.log(bsTableConfig);
        this.btInstance =
            $('#' + tableId).bootstrapTable(bsTableConfig);
        return this;
    },
    /**
     * @param param
     */
    setQueryParams: function (param) {
        this.queryParams = param;
    },
    /**
     *server / client
     */
    setPaginationType: function (type) {
        this.paginationType = type;
    },
    /**
     * data
     */
    set: function (key, value) {
        if (typeof key == ""object"") {
            for (var i in key) {
                if (typeof i == ""function"")
                    continue;
                this.data[i] = key[i];
            }
        } else {
            this.data[key] = (typeof value == ""undefined"") ? $(""#"" + key).val() : value;
        }
        return this;
    },
    /**
     * setData
     */
    setData: function (data) {
        this.data = data;
        return this;
    },
    /**
     * clear
     */
    clear: function () {
        this.data = {};
        return this;
    },
    /**
     * Refresh the remote server data,
     * you can set {silent: true} to refresh the data silently,
     * and set {url: newUrl} to change the url.
     * To supply query params specific to this request, set {query: {foo: 'bar'}}
     */
    refresh: function (parms) {
        if (typeof parms != ""undefined"") {
            this.btInstance.bootstrapTable('refresh', parms);
        } else {
            this.btInstance.bootstrapTable('refresh');
        }
    },
    /**
   *getSelections
   */
    getSelections: function () {
        return this.btInstance.bootstrapTable('getSelections');
    }
};
window.BSTable = BSTable;
}());
```
**What is the result of your expectation? What's the wrong information you actually see?**

**Expected results：**

![default](https://user-images.githubusercontent.com/17944114/43239274-2a73ec68-90c4-11e8-8251-6ee8d1f7d245.PNG)


**The results displayed with the above JS：**
![default](https://user-images.githubusercontent.com/17944114/43239283-3434b124-90c4-11e8-8840-90b51b964b3b.PNG)

Is it wrong where I wrote the wrong thing？","Can you translate this issue to english, please?","},

Is it wrong where I wrote the wrong thing？"
wenzhixin/bootstrap-table,https://github.com/wenzhixin/bootstrap-table/issues/3960,wenzhixin_bootstrap-table_issues_3960,"通过jquery的.html()功能产生的表格内容，在点击排序或者搜索之后就会消失

通过jquery的$(""#test"").html(“task is finished”)功能，在表格的第二列显示一些内容，这些内容（“task is finished”）在点击排序或者在本地搜索框输入内容之后就会全部消失，且不能还原，这个问题如何解决
--------------------------------------------------------------------
I try to translate this issue to english.
when i use the bootstrap-table.
html code:

### **<td** id=""test""></td>

jquery codes:

$(""#test"").html(“task is finished”)

when i try to use the data-search=""true"" or sort to filter data,""task is finished"" is disappeared","Can you translate this issue to english, please?","--------------------------------------------------------------------
I try to translate this issue to english.
when i use the bootstrap-table.
html code:jquery codes:
try to  to filter data"
Komodo/KomodoEdit,https://github.com/Komodo/KomodoEdit/issues/3725,Komodo_KomodoEdit_issues_3725,"Reproduced Step In inconsistency stopping on first executable line and not stopping

<!--
Please fill out the requested fields to the best of your ability.

Some general guidelines:

 - Context is important,  please include all steps you took to produce the issue.
 - Always use the github web interface to respond. Email responses get mangled and may include personal information.
 - Please be courteous. Toxic and obnoxious behavior will not be tolerated.
 - For general usage questions please refer to our forums: http://community.komodoide.com/
-->

### Short Summary
Reproduced Step In inconsistency stopping on first executable line and not stopping on first executable line. 


### Steps to Reproduce
Started Komodo IDE in Safe Mode, First run Wizard completed, Opened PHP code file for local debugging.  I selected _Step In_ option under Debug on Menu started the debugger and it run through without stopping on first executable line.  Then I did the same again, this time the debugger did stop on the first executable line.


### Expected results
I expected consistent behavior for debug/step in option in Komodo IDE to always stop at first executable line of code.  


### Actual results
I got inconsistent behavior for debug/step in option in Komodo IDE to always stop at first executable line of code.  Trial 1 did NOT stop, Trial 2 DID stop.


### Platform Information
Komodo IDE, version 11.1.0, build 91033, platform win32-x86.
Built on Wed May 30 10:04:55 2018.

*Operating System (and version)?*  Windows 10 -Home
Version 1903
Installed on 3/16/2019
OS Build  18356.16

### Additional Information

Forum post reference: https://community.komodoide.com/t/local-php-debugging-trouble/4609

<!--
![Screenshot (530)](https://user-images.githubusercontent.com/14288390/55129028-018c8100-50ec-11e9-91ac-6c6b829a1b28.png)

eg. Error logs, screenshots, workarounds

You can find your error log via Help > Troubleshooting > View Log File
-->
 [2019-03-27 23:38:52,871] [INFO] Startup: Welcome to Komodo IDE 11.1.0 build 91033 (platform win32-x86, running on Windows post2012Server version 6.3.9600)
[2019-03-27 23:38:52,871] [INFO] Startup: C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\komodo.exe built on Wed May 30 10:04:55 2018
[2019-03-27 23:38:54,183] [WARNING] console-logger: mutating the [[Prototype]] of an object will cause your code to run very slowly; instead create the object with the correct initial [[Prototype]] value using Object.create (1) in resource://gre/modules/Preferences.jsm:381
[2019-03-27 23:38:54,430] [WARNING] root: [object Object].logging has been converted to a CommonJS module; use require(""ko/logging"") instead (since Komodo 9.0.0a1).
    @chrome://komodo/content/komodo.js:15:1

[2019-03-27 23:38:55,210] [WARNING] keybindings: [Ctrl+0] was used for 'cmd_goToQuickBookmark_0', overriding to use 'cmd_fontZoomReset'
[2019-03-27 23:38:55,236] [WARNING] ko.widgets: Can't load 'ui.tabs.sidepanes.state' from 'prefpath': 
[2019-03-27 23:38:55,509] [DEBUG] ko.launch: versioncheck on http://docs.komodoide.com/changelog/11
[2019-03-27 23:38:55,733] [INFO] koInitService: Adding pre startup service for 'koFileStatusService': '@activestate.com/koFileStatusService;1'
[2019-03-27 23:38:56,207] [INFO] codeintel/process: Starting CodeIntel
[2019-03-27 23:38:56,210] [DEBUG] codeintel/process: PYTHONPATH: C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\python\..\lib\python2.7;C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\support\dbgp\pythonlib;C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\extensions\codeintel@activestate.com\content\..\pylib\codeintel\lib;C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\extensions\codeintel@activestate.com\content\..\pylib\codeintel\env\Lib\site-packages
[2019-03-27 23:38:56,417] [INFO] elastic_tabstops: Elastic tabstops loaded.
[2019-03-27 23:38:56,457] [INFO] komodospellchecker: Spell checker loaded.
[2019-03-27 23:38:56,457] [INFO] komodospellchecker: Using dictionary en-US
[2019-03-27 23:38:57,806] [WARNING] console-logger: mutating the [[Prototype]] of an object will cause your code to run very slowly; instead create the object with the correct initial [[Prototype]] value using Object.create (1) in file:///C:/Program%20Files%20(x86)/ActiveState%20Komodo%20IDE%2011/lib/mozilla/components/koamAddonManager.js:138
[2019-03-27 23:38:57,953] [WARNING] console-logger: XUL box for tab element contained an inline #text child, forcing all its children to be wrapped in a block. (1) in file:///C:/Program%20Files%20(x86)/ActiveState%20Komodo%20IDE%2011/lib/mozilla/components/koLessProtocolHandler.js:154
[2019-03-27 23:38:57,953] [WARNING] console-logger: XUL box for tab element contained an inline #text child, forcing all its children to be wrapped in a block. (1) in file:///C:/Program%20Files%20(x86)/ActiveState%20Komodo%20IDE%2011/lib/mozilla/components/koLessProtocolHandler.js:154
[2019-03-27 23:38:57,953] [WARNING] console-logger: XUL box for tab element contained an inline #text child, forcing all its children to be wrapped in a block. (1) in file:///C:/Program%20Files%20(x86)/ActiveState%20Komodo%20IDE%2011/lib/mozilla/components/koLessProtocolHandler.js:154
[2019-03-27 23:38:58,454] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,454] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,454] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,454] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,454] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,456] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,456] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,456] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,456] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,456] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,456] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,457] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,457] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,457] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,457] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,457] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,457] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,459] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,459] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,459] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,459] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,459] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,460] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,461] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,461] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,461] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,461] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,461] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,463] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,464] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,464] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,464] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,464] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,464] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,464] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,466] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,466] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,466] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,509] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,509] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,509] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,509] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,510] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,510] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,510] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,510] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,510] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,512] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,512] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,512] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,512] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,512] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,513] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,515] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,515] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,515] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,515] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,516] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,517] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,517] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,519] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,520] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,520] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,520] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,522] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,522] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,522] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,522] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,523] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,525] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,525] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,525] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,525] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,525] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,526] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,526] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,526] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,526] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,526] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,526] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,526] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,528] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,528] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,528] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,529] [WARNING] koLanguage: Asked for unknown language: 'HTML-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,532] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,533] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,533] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,535] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,535] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,535] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,535] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,535] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,536] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,538] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,538] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,538] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,538] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,538] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,539] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,540] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,540] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,540] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,540] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,542] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,543] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,543] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,543] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,543] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,543] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,545] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,545] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,545] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,545] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,545] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,545] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,546] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,548] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,548] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,548] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,548] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,548] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,549] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,551] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,551] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,551] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,551] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,561] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,561] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,561] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,561] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,561] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,562] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,563] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,563] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,563] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,563] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,563] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,565] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,566] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,566] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,566] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,568] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,568] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,568] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,568] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,568] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,569] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,571] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,571] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,571] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,571] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,572] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,573] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,573] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,573] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,573] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,573] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,575] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,576] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,576] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,576] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,576] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,576] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,578] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,579] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,579] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,579] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,579] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,579] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,579] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,579] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,581] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,581] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,582] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,584] [WARNING] koLanguage: Asked for unknown language: 'JavaScript-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,625] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,627] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,627] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,627] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,628] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,630] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,630] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,630] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,631] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,632] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,632] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,634] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,637] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,637] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,637] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,637] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,637] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,638] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,640] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,640] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,640] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,640] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,640] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,641] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,648] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,648] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,648] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,648] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,648] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,650] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,650] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,650] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,650] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,650] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,651] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,653] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,653] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,653] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,653] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,653] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,653] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,654] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,655] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,655] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,655] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,655] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,655] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,655] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,655] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,657] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:58,658] [WARNING] koLanguage: Asked for unknown language: 'Python-common'
[2019-03-27 23:38:59,186] [WARNING] console-logger: XUL box for tab element contained an inline #text child, forcing all its children to be wrapped in a block. (1) in chrome://unittest/content/views/panel.xul:0
[2019-03-27 23:38:59,186] [WARNING] console-logger: XUL box for tab element contained an inline #text child, forcing all its children to be wrapped in a block. (1) in chrome://unittest/content/views/panel.xul:0
[2019-03-27 23:38:59,186] [WARNING] console-logger: XUL box for tab element contained an inline #text child, forcing all its children to be wrapped in a block. (1) in chrome://unittest/content/views/panel.xul:0
[2019-03-27 23:38:59,420] [ERROR] console-logger: TypeError: n is undefined (2) in chrome://komodo/content/contrib/commonjs/underscore.js:5
Traceback (most recent call last):
  File ""chrome://komodo/content/contrib/commonjs/underscore.js"", line 5, in 

[2019-03-27 23:38:59,440] [INFO] koInitService: Adding pre startup service for 'KoMemoryReporter': '@activestate.com/koMemoryReporter;1'
[2019-03-27 23:38:59,444] [INFO] koInitService: Adding pre startup service for 'koCommandmentService': '@activestate.com/koCommandmentService;1'
[2019-03-27 23:38:59,457] [INFO] koInitService: Adding pre startup service for 'koDBGPManager': '@activestate.com/koDBGPManager;1'
[2019-03-27 23:38:59,538] [ERROR] koAppInfo: Failed to check version of executable C:\Users\jim\AppData\Local\Microsoft\WindowsApps\python.exe
Traceback (most recent call last):
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\components\koAppInfo.py"", line 190, in _isValidExecutable
    isvalid = self._isValidExecutableVersion(exe)
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\components\koAppInfo.py"", line 162, in _isValidExecutableVersion
    versionParts = invocationutils.split_short_ver(ver, intify=True)
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\python\komodo\invocationutils.py"", line 94, in split_short_ver
    raise ValueError(""%r is not a valid short version string"" % ver_str)
ValueError: '' is not a valid short version string
[2019-03-27 23:38:59,849] [DEBUG] ko.launch: Response: http://docs.komodoide.com/__omnigollum__/auth/github?origin=%2Fcreate%2Fchangelog%2F11 (404)
[2019-03-27 23:38:59,851] [DEBUG] ko.launch: versioncheck on http://docs.komodoide.com/changelog/111
[2019-03-27 23:39:00,322] [ERROR] koAppInfo: Failed to check version of executable C:\Users\jim\AppData\Local\Microsoft\WindowsApps\python3.exe
Traceback (most recent call last):
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\components\koAppInfo.py"", line 190, in _isValidExecutable
    isvalid = self._isValidExecutableVersion(exe)
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\components\koAppInfo.py"", line 162, in _isValidExecutableVersion
    versionParts = invocationutils.split_short_ver(ver, intify=True)
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\python\komodo\invocationutils.py"", line 94, in split_short_ver
    raise ValueError(""%r is not a valid short version string"" % ver_str)
ValueError: '' is not a valid short version string
[2019-03-27 23:39:00,585] [DEBUG] ko.launch: Response: http://komodo.activestate.com/static/popup/11/index.html (200)
[2019-03-27 23:39:01,463] [ERROR] koAppInfo: Failed to check version of executable C:\Users\jim\AppData\Local\Microsoft\WindowsApps\python.exe
Traceback (most recent call last):
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\components\koAppInfo.py"", line 190, in _isValidExecutable
    isvalid = self._isValidExecutableVersion(exe)
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\components\koAppInfo.py"", line 162, in _isValidExecutableVersion
    versionParts = invocationutils.split_short_ver(ver, intify=True)
  File ""C:\Program Files (x86)\ActiveState Komodo IDE 11\lib\mozilla\python\komodo\invocationutils.py"", line 94, in split_short_ver
    raise ValueError(""%r is not a valid short version string"" % ver_str)
ValueError: '' is not a valid short version string
[2019-03-27 23:39:01,598] [WARNING] console-logger: Expected end of value but found 'dotted'.  Error in parsing value for 'text-decoration'.  Declaration dropped. (1) in http://komodo.activestate.com/static/popup/11/css/normalize.css:80
[2019-03-27 23:39:01,598] [WARNING] console-logger: Unknown pseudo-class or pseudo-element '-webkit-inner-spin-button'.  Ruleset ignored due to bad selector. (1) in http://komodo.activestate.com/static/popup/11/css/normalize.css:272
[2019-03-27 23:39:01,598] [WARNING] console-logger: Unknown pseudo-class or pseudo-element '-webkit-search-decoration'.  Ruleset ignored due to bad selector. (1) in http://komodo.activestate.com/static/popup/11/css/normalize.css:291
[2019-03-27 23:39:01,598] [WARNING] console-logger: Unknown pseudo-class or pseudo-element '-webkit-file-upload-button'.  Ruleset ignored due to bad selector. (1) in http://komodo.activestate.com/static/popup/11/css/normalize.css:300
[2019-03-27 23:39:01,598] [WARNING] console-logger: Unknown pseudo-class or pseudo-element 'selection'.  Ruleset ignored due to bad selector. (1) in http://komodo.activestate.com/static/popup/11/css/main.css:34
[2019-03-27 23:39:01,598] [WARNING] console-logger: Expected media feature name but found '-webkit-min-device-pixel-ratio'. (1) in http://komodo.activestate.com/static/popup/11/css/main.css:207
[2019-03-27 23:39:03,006] [DEBUG] codeintel/process: stdout: 
port:62913

pid:24476

[2019-03-27 23:39:03,006] [INFO] codeintel/process: CodeIntel started on port 62913
[2019-03-27 23:39:03,007] [DEBUG] codeintel/process: Calling callbacks for: started, number: 1
[2019-03-27 23:39:08,194] [DEBUG] console: error: {}
[2019-03-27 23:40:02,237] [WARNING] views: Inconsistent view count in view_closed event
[2019-03-27 23:40:02,451] [WARNING] views: Inconsistent view count in view_opened event
[2019-03-27 23:40:16,467] [ERROR] console-logger: TypeError: tab is undefined (2) in viewbrowser:133
Traceback (most recent call last):
  File ""viewbrowser"", line 133, in 

[2019-03-27 23:40:46,996] [ERROR] debugSessionTab: 
-- EXCEPTION START --
TypeError: ko.dbg.manager.currentSession is null
+ stack
    outputTabManager.prototype.tabSwitch@chrome://komodo/content/debugger/debugSessionTab.js:1261:13
    ko_dbg_createTab_tabSelectListener@chrome://komodo/content/debugger/debugSessionTab.js:998:17
    _dispatchEvent@chrome://komodo/content/bindings/pane.xml:1075:11
    onxblselect@chrome://komodo/content/bindings/pane.xml:1890:17
    set_selectedIndex@chrome://global/content/bindings/tabbox.xml:406:15
    set_selectedItem@chrome://global/content/bindings/tabbox.xml:431:34
    onxblmousedown@chrome://komodo/content/bindings/scrolltabs.xml:518:21
-- EXCEPTION END --
[2019-03-27 23:41:17,039] [WARNING] console-logger: Key event not available on GTK2: key=""u"" modifiers=""control,shift"" (1) in chrome://komodo/content/komodo.xul:0
[2019-03-27 23:58:08,405] [WARNING] console-logger: Key event not available on GTK2: key=""u"" modifiers=""control,shift"" (1) in chrome://komodo/content/tail/tail.xul:0","Could you try all three and see if any of them act differently?  

A code sample might help too.  i'm just using a PHP block with `phpinfo()` inside.",Forum post reference: https://community.komodoide.com/t/local-php-debugging-trouble/4609
Komodo/KomodoEdit,https://github.com/Komodo/KomodoEdit/issues/3623,Komodo_KomodoEdit_issues_3623,"Use interpolation string instead of hardcoded binary names in default unit testing commands

### Update From Dev

Ref: https://github.com/Komodo/KomodoEdit/issues/3623#issuecomment-439081744

We should update all the applicable unit testing default commands to use an interpolation string for the binary instead of a hard coded binary name. That way it will look at the users prefs before looking at the system path.

### WORKAROUND

Make a custom Unit Testing entry using the same default command but change the hard coded binary to the interpolation version.

Ref: http://docs.komodoide.com/manual/shortcuts#interpolation-shortcuts_interpolation-code-list

### Short Summary
I don't have Pytest installed to the global/system install of Python so running the unit tests throws up the message in stderr `c:\python36\python.exe: No module named pytest`


### Steps to Reproduce

1. Create a fresh Python3 project
2. Assign project to use a specific virtualenv's copy of Python
3. Write some code, write a test
4. Click on the edit symbol in widget to create a new test
5. Leave all fields as default, 
6. click OK and then click run


### Expected results
It feels like it should just automatically use %(python) and not be hardcoded to use ""python3"" in the `Command` field.



### Platform Information

Komodo IDE, version 11.1.0, build 91033, platform win32-x86. Built on Wed May 30 10:04:55 2018.

### Additional Information

A super quick fix to this - 

In the ""Edit Unittest config"" pop up box, 
1. change Framework dropdown to custom
2. fill command input with `%(python3) -m pytest --tb short --color no -vr a`
3. ensure Parser is set to `pytest`
4. voila

I always have virtualenvs per project so I can't remember how Komodo handles magic command line vars like %(python) or %(python3) but if it just defaults to whatever is on $PATH (%PATH% for Windows) then why not just have the default command text box argument just use the magic inject vars by default?",Why would you do this?  You're using Python 3 so the interpolation string should be `%(python3)`,"### Update From Dev

Ref: https://github.com/Komodo/KomodoEdit/issues/3623#issuecomment-439081744

We should update all the applicable unit testing default commands to use an interpolation string for the binary instead of a hard coded binary name. That way it will look at the users prefs before looking at the system path.

### WORKAROUND

Make a custom Unit Testing entry using the same default command but change the hard coded binary to the interpolation version.

Ref: http://docs.komodoide.com/manual/shortcuts#interpolation-shortcuts_interpolation-code-list"
uikit/uikit,https://github.com/uikit/uikit/issues/3629,uikit_uikit_issues_3629,"UK Sticky `bottom: true` does not recalculate in conjunction with uk-img & uk-img placeholder not working

<!-- BUG REPORT TEMPLATE -->
### UIkit version
<!-- Check if the issue is reproducible with the latest stable version. -->
3.0.0-rc.20

### Browser
Chrome

### Reproduction Link
http://dev.peterandpaul.co.uk/uikit/
http://dev.peterandpaul.co.uk/uikit/download.zip (To check source code)

### Steps to reproduce
1. Add a sticky element.
2. Add an image that loads using uk-img. 
3. Add `bottom: true`. 

### What is Expected?
The sticky element should stop when it reaches the bottom of the parent. This shouldn't happen as uk-img with the width and height should have a placeholder. However, the placeholder doesn't happen before uk-sticky is calculated? 

### What is actually happening?
It doesn't do this due to not being recalculated when the images are loaded.",Did you add `width` and `height` attributes to your image?,"Reproduction Link
http://dev.peterandpaul.co.uk/uikit/
http://dev.peterandpaul.co.uk/uikit/download.zip (To check source code)

###"
uikit/uikit,https://github.com/uikit/uikit/issues/3580,uikit_uikit_issues_3580,"uk-flex not working in safari on iPhone (reproducable codepen and browserstack screenshots)

<!-- BUG REPORT TEMPLATE -->
### UIkit version
<!-- Check if the issue is reproducible with the latest stable version. -->
3.0.0-rc.16

### Browser
Safari/Chrome, iPhone 5S iOSv7
Safari/Chrome, iPhone 6 iOSv8
Safari/Chrome, iPhone 6 Plus iOSv8

### Reproduction Link

Live View:
https://codepen.io/oshihirii/live/mGvJaW

Live View at browserstack.com
![uk-flex-not-working-in-safari](https://user-images.githubusercontent.com/5090307/45800408-314d6d00-bcf4-11e8-96a4-9a15af26a8e9.png)

Pen View:
https://codepen.io/oshihirii/pen/mGvJaW  

### What is Expected?

Flex items will display inline.  

### What is actually happening?

Flex is not being recognised and flex items are stacked as block elements.",Which iOS and Safari version are you using?,"/Chrome5S iOSv7
Safari/Chrome, iPhone  iOSv8
Safari/Chrome, iPhone 6 Plus iOSv8"
checkstyle/checkstyle,https://github.com/checkstyle/checkstyle/issues/6132,checkstyle_checkstyle_issues_6132,"Confiruration xml inclusion/import

Let's assume we have several different projects supported by different teams inside one company.
There are common checkstyle rules for all, and there are specific cases per each project
If we had url http://checkstyle-repo/shared-config.xml, which provides something like this:
```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<!DOCTYPE module PUBLIC
    ""-//Puppy Crawl//DTD Check Configuration 1.3//EN""
    ""http://www.puppycrawl.com/dtds/configuration_1_3.dtd"">
<!-- shared config -->
<module name=""Checker"">
    <module name=""TreeWalker"">
        <module name=""MissingOverride""/>
        <module name=""LineLength"">
            <property name=""max"" value=""120""/>
        </module>
    </module>
</module>
```
we could use something like this
```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<!DOCTYPE module PUBLIC
    ""-//Puppy Crawl//DTD Check Configuration 1.3//EN""
    ""http://www.puppycrawl.com/dtds/configuration_1_3.dtd"">
<import resource=""http://checkstyle-repo/shared-config.xml"" />
<module name=""Checker"">
    <module name=""TreeWalker"">
        <module name=""AvoidStarImport""/>
        <module name=""LineLength"">
            <property name=""max"" value=""150""/>
        </module>
    </module>
</module>
```
assuming the result
```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<!DOCTYPE module PUBLIC
    ""-//Puppy Crawl//DTD Check Configuration 1.3//EN""
    ""http://www.puppycrawl.com/dtds/configuration_1_3.dtd"">
<module name=""Checker"">
    <module name=""TreeWalker"">
        <module name=""MissingOverride""/>
        <module name=""AvoidStarImport""/>
        <module name=""LineLength"">
            <property name=""max"" value=""150""/>
        </module>
    </module>
</module>
```
What is the point? if we decided to add new common check, we just change one file and provide it to all the consumers instead of editing each configuration

Are there any pitfalls on this feature? 
If it's ok, I'm going to try to implement it. 
Looks pretty easy - requires changes in ConfigLoader and DTD

p.s. I found no issues on subj, but if exists - I'm sorry",Do you mean you want to extend/copy an existing XML in a new one?,"Let's assume we have several different projects supported by different teams inside one company.
There are common checkstyle rules for all, and there are specific cases per each project
If we had url http://checkstyle-repo/shared-config.xml, which provides something like this:
```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<!DOCTYPE module PUBLIC
    ""-//Puppy Crawl//DTD Check Configuration 1.3//EN""
    ""http://www.puppycrawl.com/dtds/configuration_1_3.dtd"">
<!-- shared config -->
<module name=""Checker"">
    <module name=""TreeWalker"">
        <module name=""MissingOverride""/>
        <module name=""LineLength"">
            <property name=""max"" value=""120""/>
        </module>
    </module>
</module>
```
we could use something like this
```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<!DOCTYPE module PUBLIC
    ""-//Puppy Crawl//DTD Check Configuration 1.3//EN""
    ""http://www.puppycrawl.com/dtds/configuration_1_3.dtd"">
<import resource=""http://checkstyle-repo/shared-config.xml"" />
<module name=""Checker"">
    <module name=""TreeWalker"">
        <module name=""we just change one file and provide it to all the consumers instead of editing each configuration

Are there any pitfalls on this feature? 
If it's ok,"
rathena/rathena,https://github.com/rathena/rathena/issues/4646,rathena_rathena_issues_4646,"skill ""AL_TELEPORT"" and ""TF_POISON"" invalid.

<!-- NOTE: Anything within these brackets will be hidden on the preview of the Issue. -->

* **rAthena Hash**: cee7242

<!-- Please specify the rAthena [GitHub hash](https://help.github.com/articles/autolinked-references-and-urls/#commit-shas) on which you encountered this issue. 
How to get your GitHub Hash:
1. cd your/rAthena/directory/
2. git rev-parse --short HEAD
3. Copy the resulting hash.
-->

* **Client Date**: 20180620

<!-- Please specify the client date you used. -->

* **Server Mode**: RE

<!-- Which mode does your server use: Pre-Renewal or Renewal? -->

* **Description of Issue**: 

![02](https://user-images.githubusercontent.com/7490388/74609743-de195d00-5127-11ea-85e5-beb11c26d5a8.png)

![01](https://user-images.githubusercontent.com/7490388/74609744-e1144d80-5127-11ea-80c8-eb2fc00bae0c.png)

  * Result: <!-- Describe the issue that you experienced in detail. -->
  * Expected Result: <!-- Describe what you would expect to happen in detail. -->
  * How to Reproduce: An error occurred using itemID: 601 or 602, and skill ""AL_TELEPORT"" invalid.<!-- If you have not stated in the description of the result already, please give us a short guide how we can reproduce your issue. -->
  * Official Information:<!-- If possible, provide information from official servers (kRO or other sources) which prove that the result is wrong. Please take into account that iRO (especially iRO Wiki) is not always the same as kRO. -->
  <!-- * _NOTE: Make sure you quote ``` `@atcommands` ``` just like this so that you do not tag uninvolved GitHub users!_ -->

* **Modifications that may affect results**: 
  <!-- * Please provide any information that could influence the expected result. -->
  <!-- * This can be either configurations you changed, database values you changed, or even external source modifications. -->",Can you please provide a little more detail?,": 

![02](https://user-images.githubusercontent.com/7490388/74609743-de195d00-5127-11ea-85e5-beb11c26d5a8.png)

![01](https://user-images.githubusercontent.com/7490388/74609744-e1144d80-5127-11ea-80c8-eb2fc00bae0c.png)

  * Result: <!-- Describe the issue that you experienced in detail. -->
  * Expected Result: <!-- Describe what you would expect to happen in detail. -->
  * How to Reproduce"
rathena/rathena,https://github.com/rathena/rathena/issues/4199,rathena_rathena_issues_4199,"Pet Error

<!-- NOTE: Anything within these brackets will be hidden on the preview of the Issue. -->

* **rAthena Hash**: 

Latest commit 34971e5

* **Client Date**: 

2018-11-07

* **Server Mode**: 

Renewal

* **Description of Issue**: 
  * Result: When using Incubator (Item 643) to shock the pets 'eggs, the window that opens is not closed immediately after invoking the pet, pets' eggs are also not removed from the inventory. It is necessary to exit the character and enter again so that the items are removed from the inventory every time.
Ao usar Incubadora (Item 643) para chocar os ovos de pets, a janela que abre não é fechada logo após invocar o pet, os ovos de pets também não são removidos do inventário. É nessesario sair do personagem e entrar novamenta para que os itens sejam removidos do inventário todas as vezes.
  * Expected Result: <!-- Describe what you would expect to happen in detail. -->
  * How to Reproduce: <!-- If you have not stated in the description of the result already, please give us a short guide how we can reproduce your issue. -->
  * Official Information:<!-- If possible, provide information from official servers (kRO or other sources) which prove that the result is wrong. Please take into account that iRO (especially iRO Wiki) is not always the same as kRO. -->
  <!-- * _NOTE: Make sure you quote ``` `@atcommands` ``` just like this so that you do not tag uninvolved GitHub users!_ -->

* **Modifications that may affect results**: 
  <!-- * Please provide any information that could influence the expected result. -->
  <!-- * This can be either configurations you changed, database values you changed, or even external source modifications. -->","How to Reproduce?
please follow the template","s window that opens is not closed immediately after invoking the pet, pets'"
rathena/rathena,https://github.com/rathena/rathena/issues/4778,rathena_rathena_issues_4778,"Vending problem

<!-- NOTE: Anything within these brackets will be hidden on the preview of the Issue. -->

* **rAthena Hash**: ce42168b0d2d25f66ab8a5fc5e2ef24d988274ae

<!-- Please specify the rAthena [GitHub hash](https://help.github.com/articles/autolinked-references-and-urls/#commit-shas) on which you encountered this issue. 
How to get your GitHub Hash:
1. cd your/rAthena/directory/
2. git rev-parse --short HEAD
3. Copy the resulting hash.
-->

* **Client Date**: 20151104

<!-- Please specify the client date you used. -->

* **Server Mode**: Pre-Renewal ( running with epoll, debug, with 4096 max concurrent connection )

<!-- Which mode does your server use: Pre-Renewal or Renewal? -->

* **Description of Issue**: 
  * Result: The vendor put up the item for 1,500,000z but only sold for 10,000z <!-- Describe the issue that you experienced in detail. -->
  * Expected Result: The vendor should received the amount he put up<!-- Describe what you would expect to happen in detail. -->
  * How to Reproduce: I can't reproduce this it doesn't show any problems in the server side :( <!-- If you have not stated in the description of the result already, please give us a short guide how we can reproduce your issue. -->
  * Official Information: This issue started when I tried to enable epoll in my server to increase the max capacity of my concurrent connections. I don't know if this is related to that or not but this problem occurs when I have more than 1.5k players in-game... <!-- If possible, provide information from official servers (kRO or other sources) which prove that the result is wrong. Please take into account that iRO (especially iRO Wiki) is not always the same as kRO. -->
  <!-- * _NOTE: Make sure you quote ``` `@atcommands` ``` just like this so that you do not tag uninvolved GitHub users!_ -->

* **Modifications that may affect results**: 
  <!-- * Please provide any information that could influence the expected result. -->
  <!-- * This can be either configurations you changed, database values you changed, or even external source modifications. -->

Please check the video here : https://www.youtube.com/watch?v=DLZydLH3YD0",What is your vending tax config set to?,"( running with epoll, debug, with 4096 max concurrent connection ) This issue started when I tried to enable epoll in my server to increase the max capacity of my concurrent connections. I don't know if this is related to that or not but this problem occurs when I have more than 1.5k players in-game..."
MultiMC/MultiMC5,https://github.com/MultiMC/MultiMC5/issues/2906,MultiMC_MultiMC5_issues_2906,"resource packs not sticking when loading Fabric Instance via MultiMC

<!--
Before submitting this issue, please make sure you have:

 1. Filled out this form completely, the only optional field is ""additional info"".
    - Use as many details as possible and state the problem clearly.
 2. Proof-read your ENTIRE issue report.
    - Grammar and spelling mistakes make issue reports harder to understand.
 3. Made sure your problem is not caused by an issue in your own modpack.
    - We provide support for MultiMC, not your modpack. Problems with your modpack will be ignored.
 4. Given the issue a descriptive title.
    - A good title includes a brief summary of the issue and avoids things such as ""Help"" and ""What?!"".
      Use of UPPERCASE is discouraged, as it reads like someone is screaming.
 5. Place all information below the ---- of lines.
    - It makes the issue look pretty
 
If you believe your issue to be a bug, please make sure you check the wiki page: https://github.com/MultiMC/MultiMC5/wiki/Report-a-Bug
-->

System Information
-----------------------------
MultiMC version: 0.6.7-1375

Operating System: Windows 10

Summary of the issue or suggestion:
----------------------------------------------
When I open an instance of Minecraft running FabricMC via MultiMC and select a resource pack, the selection is not remembered after I close and reopen the instance. I have to constantly keep selecting my resource pack.


What should happen:
------------------------------
With the normal minecraft launcher, I start an instance of the game select a resource pack from my world and it always remembers it.

Steps to reproduce the issue (Add more if needed):
-------------------------------------------------------------
1. Create a new fabric instance in MultiMC

2. Start a new world and select a resource pack other than the default one

3. Close the instance and start the instance again.

4. The game resets the resource pack back to the default

Suspected cause:
---------------------------
Not sure if it is MultiMC or Fabric. MultiMC and Vanilla don't seems to be a problem. Fabric with Default Minecraft Launcher also does not see this problem.

Logs/Screenshots:
----------------------------
[//]: # (Please refer to https://github.com/MultiMC/MultiMC5/wiki/Log-Upload for instructions on how to attach your logs.)


Additional Info:
---------------------------","Could you like, add info to work with? Elaborate the problem!","0.6.7-1375 Windows 10en I open an instance of Minecraft running FabricMC via MultiMC and select a resource pack, the selection is not remembered after I close and reopen the instance. I have to constantly keep selecting my resource pack.


WhWith the normal minecraft launcher, I start an instance of the game select a resource pack from my world and it always remembers it. Create a new instance in MultiMC Start a new world and select a resource pack other than the default one Close the instance and start the instance again.

4. The game resets the resource pack back to the defaultNot sure if it is MultiMC or Fabric. MultiMC and Vanilla don't seems to be a problem."
MultiMC/MultiMC5,https://github.com/MultiMC/MultiMC5/issues/2980,MultiMC_MultiMC5_issues_2980,"Linux Package (tar.gz) should also contain the project (infinity) icon

System Information
-----------------------------
MultiMC version: 0.6.7-1290

Operating System: Linux using the tar.gz-package

Summary of the issue or suggestion:
----------------------------------------------
There is no project (infinity) icon in the `tar.gz` file (e.g. for creating a nice desktop launcher). 

What should happen:
------------------------------
For integration into the desktop menu the icon file should be provided to create a nice `MultiMC.desktop` file.

---
better:
At the first start (setup) a `MultiMC.desktop` file could be generated at `~/.local/share/applications` with the correct paths (without `wget ...icon`).

Additional Info:
---------------------------
I think every relevant Linux desktop has implemented the [Desktop Entry Specification](https://www.freedesktop.org/wiki/Specifications/desktop-entry-spec/)",Which distro are you using?,in the `tar.gz` file
whatwg/html,https://github.com/whatwg/html/issues/3338,whatwg_html_issues_3338,"Proposal: Storage Access API

# Details to be discussed in the W3C Privacy CG

**We've moved this to the W3C Privacy CG where you can file individual issues on the things you want to discuss: https://github.com/privacycg/storage-access**

---

# Original issue

Hi! John Wilander from WebKit here. We hope this can extend existing specifications rather than create some whole new spec. It was [originally filed under whatwg/dom](https://github.com/whatwg/dom/issues/560) but I was advised to move it here.

# Storage Access API

## Problem

**Tl;dr**: Browsers that block access to third-party cookies break authenticated embeds such as commenting widgets and subscribed video services.

In the context of cross-origin resource loads, cookies are popularly referred to as third-party cookies. In reality, these cookies are often the same as the first-party cookies so what we really mean with third-party cookies is access to first-party cookies in a third-party context.

A browser may have rules for third-party cookies that go beyond cookie policy rules such as scheme, host, path, secure attribute etc. These additional rules may be:

- Third-parties aren't allowed to set cookies,
- Third-parties have their cookies partitioned or double-keyed, or
- Third-parties have no cookie access.

However, certain services are intended to be embedded as third-party content and need access to first-party cookies for authentication. Examples are commenting widgets, video embeds, payment provider integration, document embeds, and social media action widgets. These break if the third-party content has no access to its first-party cookies.

The same problem exists for other kinds of storage such as IndexedDB and LocalStorage, except they are not tied to the HTTP protocol and are typically not used for authentication purposes. From here on we will refer to cookies except when the distinction between cookies and other storage makes sense.

## Proposed Solution

**Tl;dr**: A new API with which cross-origin iframes can request access to their first-party cookies when processing a user gesture such as a tap or a click. This allows third-party embeds to authenticate on user interaction.

We propose two new functions on the document:

```
partial interface Document {
    Promise<bool> hasStorageAccess();
    Promise<void> requestStorageAccess();
};
```
The reasons these are on the document is that 1) storage access is granted to the particular document (see Access Removal) and 2) it changes document.cookie.

hasStorageAccess() can be called at any time to check whether access is already granted and it doesn't require user interaction.

requestStorageAccess() should only be called on user interaction such as a tap or a click. It will check a set of rules and grant access if the rules are fulfilled. Access to first-party cookies in the given iframe can be assumed if the returned promise resolves. From that point, any sub resource load in the iframe will have first-party cookies sent and incoming cookies will be set in the first-party cookie jar.

Note that no other third-party resources on that webpage are affected by the storage access status of an individual iframe.

## Algorithm for requestStorageAccess()

1. If the document already has been granted access, resolve.
2. If the document has a null origin, reject.
3. If the document's frame is the main frame, resolve.
4. If the sub frame's origin is equal to the main frame's, resolve.
5. If the sub frame is not sandboxed, skip to step 7.
6. If the sub frame doesn't have the token ""allow-storage-access-by-user-activation"", reject.
7. If the sub frame's parent frame is not the top frame, reject.
8. If the browser is not processing a user gesture, reject.
9. Check any additional rules that the browser has. Examples: Whitelists, blacklists, on-device classification, user settings, anti-clickjacking heuristics, or prompting the user for explicit permission. Reject if some rule is not fulfilled.
10. Grant the document access to cookies and store that fact for the purposes of future calls to hasStorageAccess() and requestStorageAccess().
11. 

## Access Removal

Storage access is granted for the life of the document and as long as the document's frame is attached to the DOM. This means:

- Access is removed when the sub frame navigates.
- Access is removed when the sub frame is detached from the DOM.
- Access is removed when the top frame navigates.
- Access is removed when the webpage goes away, such as a tab close.

In addition, the browser may decide to remove access on a timeout basis or on some dedicated user action such as switching cookie policy.

## WebKit Specifics

WebKit's implementation of Storage Access API will be available in Safari Technology Preview soon and on by default. It only covers cookie access, i.e. no other storage mechanisms and the partitioning of them is affected by a call to requestStorageAccess() at this point.",How is the partitioning of the cookies affected by calling requestStorageAccess()? Thanks in advance.,"# Details to be discussed in the W3C Privacy CG

**We've moved this to the W3C Privacy CG where you can file individual issues on the things you want to discuss: https://github.com/privacycg/storage-access**

---

# Original issue"
whatwg/html,https://github.com/whatwg/html/issues/5437,whatwg_html_issues_5437,"Configure credentials of cookies for WebSocket

### Proposal

Add an option to _WebSocket_ to configure the sending of cookies in the HTTP handshake with the same behavior as the [`credentials` option of _fetch_](https://fetch.spec.whatwg.org/#cors-protocol-and-credentials).

### API

The _WebSocket_ constructor could take an `init` parameter: `new WebSocket (input, init = {})` which would contain the :

- `protocols`: Either a single protocol string or an array of protocol strings.
- `credentials`: The request credentials you want to use for the request: `omit`, `same-origin`, or `include`.
- and maybe other options such as the `init` parameter of _fetch_.

### Other languages

Clients in other languages allow you to directly modify the request headers (and thus the cookies).

- Node.js: [ws](https://github.com/websockets/ws/blob/master/doc/ws.md#new-websocketaddress-protocols-options), [websocket](https://github.com/theturtle32/WebSocket-Node/blob/master/docs/WebSocketClient.md#connectrequesturl-requestedprotocols-origin-headers-requestoptions)
- Rust: [websocket](https://docs.rs/websocket/0.24.0/websocket/client/builder/struct.ClientBuilder.html#method.custom_headers)
- Java: [spring-websocket](https://javadoc.io/doc/org.springframework/spring-websocket/latest/index.html)

_fetch_ doesn't allow you to modify the cookies (probably security related), that's why I propose to add the `credentials` option.

### Motivation

I develop a webextension that connects to a _WebSocket_ server. The server doesn't accept requests bigger than _1024_ bytes. But other services that are on the same domain name (with different ports), set cookies that are sent unnecessarily to the _WebSocket_ and increase the size of the request. I would like to add the option `{ credentials: ""omit"" }` to not send cookies.

And if options are useful for _fetch_, they should be useful for _WebSocket_ HTTP handshake.

### Related links

- Other proposal to custom _headers_ of HTTP handshake. #3062.
- Proposal to add _credentials_ in _WebSocketStream_. https://github.com/ricea/websocketstream-explainer/issues/3
- Question to disable cookies in WebSocket. https://stackoverflow.com/q/27983153",What would `keepalive` mean?,"in the HTTP handshake.

### Other languages

Clients in other languages allow you to directly modify the request headers"
palantir/tslint,https://github.com/palantir/tslint/issues/3947,palantir_tslint_issues_3947,"Inserts Spaces on autofix

### Bug Report

- __TSLint version__:5.10.0
- __TypeScript version__:2.9.1
- __Running TSLint via__: VSCode

#### TypeScript code being linted

Video: https://i.gyazo.com/442e252625e11504e983a5f3fec1a12f.mp4
```ts
export const getModels = () => {
  const files = fs.readdirSync('./Models');
  const Models = {};
  files.forEach(file => {
    Models[file] = // after save, it inserts spaces here.
  });
};
```

with `tslint.json` configuration:

```json
{
  ""defaultSeverity"": ""error"",
  ""extends"": [""tslint-config-airbnb""],
  ""jsRules"": {},
  ""rules"": {
    ""no-console"": false,
    ""member-access"": false,
    ""object-literal-sort-keys"": false,
    ""ordered-imports"": false,
    ""interface-name"": false,
    ""variable-name"": false
  },
  ""rulesDirectory"": []
}
```

#### Actual behavior

When I save the file (I've enabled autoFixOnSave) it Inserts spaces.

#### Expected behavior

Should not insert spaces.


Even tho the code is wrong, the editor shouldn't insert spaces. It's scary behavior, and let's assume you've saved the file accidentally and you see random spaces there.",does it still insert spaces once you've assigned a right hand value? seems like lightweight user error to me.,"Even tho the code is wrong, the editor shouldn't insert spaces. It's scary behavior, and let's assume you've saved the file accidentally and you see random spaces there."
palantir/tslint,https://github.com/palantir/tslint/issues/4836,palantir_tslint_issues_4836,"'ignored' option badly handled in file-name-casing 

### Bug Report

- __TSLint version__: 5.19
- __TypeScript version__: 3.2
- __Running TSLint via__: CLI

#### Reproduction

Try using  `file-name-casing` having `ignored` option.
TSLint will show you a warning `Warning: file-name-casing - Unexpected casing option provided: ignored`.
This is because of line https://github.com/palantir/tslint/blob/master/src/rules/fileNameCasingRule.ts#L87
since `validCasingOptions` does not contian 'ignored' option. Since line https://github.com/palantir/tslint/blob/master/src/rules/fileNameCasingRule.ts#L43 misses it.

tslint.yaml:
```
rules:
    file-name-casing: [true, {""AppComponent.ts"": ""ignored"", "".*"": ""kebab-case"" } ]
```
Tried using like in here https://palantir.github.io/tslint/rules/file-name-casing/ 
```
""file-name-casing"": [true, {"".ts"": ""ignored"", "".tsx"": ""pascal-case""}]
```

#### Actual behavior
`ignored` option claimed in docs but cannot be used.

#### Expected behavior
ability to use `ignored` option.",Can you paste your exact tslint config? It's hard to tell if it's a config error or a bug in the rule.,"tslint.yaml:
```
rules:
    file-name-casing: [true, {""AppComponent.ts"": ""ignored"", "".*"": ""kebab-case"" } ]
```
Tried using like in here https://palantir.github.io/tslint/rules/file-name-casing/ 
```
""file-name-casing"": [true, {"".ts"": ""ignored"", "".tsx"": ""pascal-case""}]
```"
ZeroK-RTS/Zero-K,https://github.com/ZeroK-RTS/Zero-K/issues/3329,ZeroK-RTS_Zero-K_issues_3329,"Map texture issue with latest engine version

Playing on the test version ""Zero-K test-14821-00cc6f1"" I get texture issues with maps; the heights of all landscaping seem to be fine, but the textures are all messed up. I included screenshots.
![zerok](https://user-images.githubusercontent.com/6074608/48308503-a428d680-e534-11e8-8373-aa148ac8d754.png)


![screenshot 12](https://user-images.githubusercontent.com/6074608/48308522-11d50280-e535-11e8-815e-e714aae9e407.png)




[infolog.txt](https://github.com/ZeroK-RTS/Zero-K/files/2569025/infolog.txt)",Can you attach an infolog?,"![screenshot 13](https://user-images.githubusercontent.com/6074608/48308768-3206c080-e539-11e8-93c9-b440e3d82c0d.png)


![screenshot 14](https://user-images.githubusercontent.com/6074608/48308770-34691a80-e539-11e8-936f-f1b4e327027d.png)


![screenshot 15](https://user-images.githubusercontent.com/6074608/48308772-36cb7480-e539-11e8-9c81-c6f039ff6b32.png)"
ZeroK-RTS/Zero-K,https://github.com/ZeroK-RTS/Zero-K/issues/3400,ZeroK-RTS_Zero-K_issues_3400,"Units abandon commands at waypoints

Units sometimes discard their command when a waypoint is reached. This happens for move, attack-move and patrol commands (and likely others like waypoints added by the ""smart"" unit AI).

To reproduce: 
1 Order a factory to attack-move to several locations.
2 Produce some units and watch some of them stop before reaching the final destination.",Can you make a short replay in a demonstration game?,"like waypoints added by the ""smart"" unit AI"
dotnet/reactive,https://github.com/dotnet/reactive/issues/1053,dotnet_reactive_issues_1053,"Why does auto connect take an Action of IDisposable?

When would this be called more than once? Why not use a SingleAssignmentDisposable instead of an Action?

The ""minObservers"" is more of a ""total of all previous subscriptions"", i.e.

var sub1 = consumer1.Subscribe();
sub1.Dispose();

var sub2 = consumer2.Subscribe();

// This is two subscribers, even though only one is ""active"", since it doesn't ever decrement the _count.

Should AutoConnect mandate consumers need to provide an action or single assignment disposable?  It's currently optional and I can foresee many people not realizing they should be cleaning something up.

We also have a bug if we go over int.MaxValue subscriptions in the lifetime of the app, since it will overflow and then subscribe again... after quite some time I guess!

```
internal AutoConnect(IConnectableObservable<T> source, int minObservers, Action<IDisposable> onConnect)
    {
        _source = source;
        _minObservers = minObservers;
        _onConnect = onConnect;
    }

    public IDisposable Subscribe(IObserver<T> observer)
    {
        var d = _source.Subscribe(observer);

        if (Volatile.Read(ref _count) < _minObservers)
        {
            if (Interlocked.Increment(ref _count) == _minObservers)
            {
                var c = _source.Connect();
                _onConnect?.Invoke(c);
            }
        }
        return d;
    }
}
```",Why is this a problem for you?,Should AutoConnect mandate consumers need to provide an action or single assignment disposable?  It's currently optional and I can foresee many people not realizing they should be cleaning something up.
exercism/cli,https://github.com/exercism/cli/issues/728,exercism_cli_issues_728,"Update usage documentation for submit

It was discovered while discussing #724 that the documentation for `exercism submit` could be improved including showing optional additional files.

As a user I would like documentation showing the proper use of `submit` including any optional flags.

EDIT:
currently when a user enters `exercism submit -h` the output is 
```
Submit your solution to an Exercism exercise.

	Call the command with the list of files you want to submit.

Usage:
   submit [flags]

Aliases:
  submit, s

Flags:
  -h, --help   help for submit

Global Flags:
      --timeout int   override the default HTTP timeout (seconds)
  -v, --verbose       verbose output
```

The output should be updated to 
```
Submit your solution to an Exercism exercise.

	Call the command with the list of files you want to submit.

Usage:
   submit [flags] FILE1 [FILE2 ...]

Aliases:
  submit, s

Flags:
  -h, --help   help for submit

Global Flags:
      --timeout int   override the default HTTP timeout (seconds)
  -v, --verbose       verbose output
```",Do you mean the documentation that is shown when running `exercism -h`?,"EDIT:
currently when a user enters `exercism submit -h` the output is 
```
Submit your solution to an Exercism exercise.

	Call the command with the list of files you want to submit.

Usage:
   submit [flags]

Aliases:
  submit, s

Flags:
  -h, --help   help for submit

Global Flags:
      --timeout int   override the default HTTP timeout (seconds)
  -v, --verbose       verbose output
```

The output should be updated to 
```
Submit your solution to an Exercism exercise.

	Call the command with the list of files you want to submit.

Usage:
   submit [flags] FILE1 [FILE2 ...]

Aliases:
  submit, s

Flags:
  -h, --help   help for submit

Global Flags:
      --timeout int   override the default HTTP timeout (seconds)
  -v, --verbose       verbose output
```"
Particular/ServicePulse,https://github.com/Particular/ServicePulse/issues/646,Particular_ServicePulse_issues_646,"Rendering issue graphs in Servicepulse Monitoring view

## Problem statement
When there is no data for throughput but there is for retries the large graph displaying both of those values can be rendered on the left of the graph.

## Reported Case
We just updated to the latest ServicePulse and ServiceControl version and experience a display issue when looking at the monitoring view.
In particular when displaying a single endpoint under Monitoring -> Select an endpoint.
Some of the graphs seem off and go off the grid, see the screenshot below:
![issue_servicepulse](https://user-images.githubusercontent.com/3135878/42624425-aa25b0b8-85c5-11e8-9c56-3dc6e70f76d9.png)
It does not happen for all of our services but we can not figure out any pattern.
I tried different browsers and it persists in Firefox Quantum, Internet Explorer and Edge.

Thank you for looking into it.

***************

*Technical information if reporting a bug:*

- **ServicePulse version:** v1.14.3
- **ServiceControl version:** v2.1.1
- **Browser version:** Firefox Quantum 59.0.2 (64-bit)",Could you specify which version of ServiceControl.Monitoring nuget package are you using?,"## Problem statement
When there is no data for throughput but there is for retries the large graph displaying both of those values can be rendered on the left of the graph.

## Reported Case"
obsproject/obs-studio,https://github.com/obsproject/obs-studio/issues/2415,obsproject_obs-studio_issues_2415,"Bug: Test (GDI+) Outline not applied to Innter 

<!--- The OBS Studio GitHub issue tracker is **ONLY** to be used for reporting bugs that have replication steps. New features should be discussed on our Discord (https://obsproject.com/discord/) or Ideas page (https://ideas.obsproject.com/). For support issues, use the Discord or forums (https://obsproject.com/forum/) -->

<!--- Provide a general summary of the issue in the Title above -->

## Expected Behavior
<!--- Tell us what should happen -->
The ID of fonts should also have the outline effect applied.
This typically only effect letters that are enclosed like 8, B etc.. 
While some others are not effected. Like: D, 0, Q
This appears to be an issue with smaller ID's?

## Current Behavior
<!--- Tell us what happens instead of the expected behavior. -->
<!--- Please include a log file here if possible. -->
The outline should also be applied inside the fonts.

## Steps to Reproduce
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code to reproduce, if relevant. Pictures -->
<!--- and video are encouraged if applicable. -->
The Font used is the Rubik Black Regular font by google available at:
* [https://fonts.google.com/download?family=Rubik](https://fonts.google.com/download?family=Rubik)
* Outline is set to 20
Screen shot at: [https://imgur.com/a/AGjlgmp](https://imgur.com/a/AGjlgmp)","Can you please fill out the template to provide more information on this, most importantly with replication steps and an explanation of the issue?","The ID of fonts should have the ID of the fonts also have the outline effect applied.
This typically only effect letters that are enclosed like 8, B etc.. 
While some others are not effected. Like: D, 0, Q
This appears to be an issue with smaller ID's?
The outline should also be applied inside the fonts."
obsproject/obs-studio,https://github.com/obsproject/obs-studio/issues/2760,obsproject_obs-studio_issues_2760,"[BUG] Apple VT Encoder doesn't record at 30 or 60 fps, it only records on 25 or 50 fps

## Platform
Operating system and version: macOS Mojave (10.14.6)
OBS Studio version: 25.0.7

## Expected Behavior
Streaming and Recording must record the files with the selected frame rate on OBS

## Current Behavior
Streaming and Recording are recorded with 25 fps (even if I set OBS for 30fps) and 50fps (even if I set OBS for 60fps)
This doesn't happen with x264. On x264 the recording will respect the OBS frame rate.

## Steps to Reproduce
Set OBS for 30 fps and record the video using Apple VT Hardware Encoder.

## Additional information
I've tried a lot of versions of OBS, but this problem occurs with all version, in any macOS I've tested (Yosemite, El Capitan, High Sierra and Mojave)
![Captura de Tela 2020-04-19 às 21 52 56](https://user-images.githubusercontent.com/10005660/79705133-f5410c00-828a-11ea-976d-c52a240ade1e.png)",Can you please properly fill out the bug report template?,"Operating system and version: macOS Mojave (10.14.6)
OBS Studio version: 25.0.7

## Expected Behavior
Streaming and Recording must record the files with the selected frame rate on OBS

## Current Behavior
Streaming and Recording are recorded with 25 fps (even if Hard"
poliastro/poliastro,https://github.com/poliastro/poliastro/issues/478,poliastro_poliastro_issues_478,"Displaying plots using OrbitPlotter3D on Mac OS X

Attempting to generate a 3D plot for an orbit using OrbitPlotter3D. I'm running Python ver. 3.6.5 from the Anaconda Distribution on a Mac Pro (desktop, Late 2012) under Mac OS X ver. 10.12.6 (Sierra).

🐞 **Problem**
No plot generated.

The Python script used is contained in the following file.
[Keplerian-Trajectory-Plots-1.py.txt](https://github.com/poliastro/poliastro/files/2513363/Keplerian-Trajectory-Plots-1.py.txt)


🖥 **Please paste the output of following commands**

`conda info -a`

<details>

```
     active environment : None
       user config file : /Users/user/.condarc
 populated config files : /Users/user/.condarc
          conda version : 4.5.11
    conda-build version : 3.8.0
         python version : 3.6.5.final.0
       base environment : /Users/user/anaconda3  (writable)
           channel URLs : https://repo.anaconda.com/pkgs/main/osx-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/free/osx-64
                          https://repo.anaconda.com/pkgs/free/noarch
                          https://repo.anaconda.com/pkgs/r/osx-64
                          https://repo.anaconda.com/pkgs/r/noarch
                          https://repo.anaconda.com/pkgs/pro/osx-64
                          https://repo.anaconda.com/pkgs/pro/noarch
          package cache : /Users/user/anaconda3/pkgs
                          /Users/user/.conda/pkgs
       envs directories : /Users/user/anaconda3/envs
                          /Users/user/.conda/envs
               platform : osx-64
             user-agent : conda/4.5.11 requests/2.18.4 CPython/3.6.5 Darwin/16.7.0 OSX/10.12.6
                UID:GID : 503:20
             netrc file : None
           offline mode : False

# conda environments:
#
                         /Users/user/.julia/packages/Conda/hsaaN/deps/usr
base                  *  /Users/user/anaconda3
pagmo                    /Users/user/anaconda3/envs/pagmo
prova                    /Users/user/anaconda3/envs/prova

sys.version: 3.6.5 | packaged by conda-forge | (defau...
sys.prefix: /Users/user/anaconda3
sys.executable: /Users/user/anaconda3/bin/python
conda location: /Users/user/anaconda3/lib/python3.6/site-packages/conda
conda-build: /Users/user/anaconda3/bin/conda-build
conda-convert: /Users/user/anaconda3/bin/conda-convert
conda-develop: /Users/user/anaconda3/bin/conda-develop
conda-env: /Users/user/anaconda3/bin/conda-env
conda-index: /Users/user/anaconda3/bin/conda-index
conda-inspect: /Users/user/anaconda3/bin/conda-inspect
conda-metapackage: /Users/user/anaconda3/bin/conda-metapackage
conda-render: /Users/user/anaconda3/bin/conda-render
conda-server: /Users/user/anaconda3/bin/conda-server
conda-skeleton: /Users/user/anaconda3/bin/conda-skeleton
conda-verify: /Users/user/anaconda3/bin/conda-verify
user site dirs: ~/.local/lib/python2.7
                ~/.local/lib/python3.5
                ~/.local/lib/python3.6

CIO_TEST: <not set>
CONDA_ROOT: /Users/user/anaconda3
DYLD_LIBRARY_PATH: /Applications/Absoft18.0/shlib64:/Applications/Absoft18.0/shlib:
JULIAPATH: /Applications/Julia-1.0.app/Contents/Resources/julia/
LD_LIBRARY_PATH: /usr/lib:/usr/local/lib:/usr/local/opt:/Users/user/cestam/lib
MANPATH: /Users/user/perl5/perlbrew/perls/perl-5.18.4/man:/usr/local/opt/coreutils/libexec/gnuman:/Users/user/Library/Enthought/Canopy_64bit/User/share/man:/usr/share/man:/usr/local/share/man:/opt/subversion/man:/Applications/Absoft18.0/man:/opt/X11/share/man:/Library/Frameworks/Mono.framework/Versions/Current/share/man:/Library/TeX/texbin/man:/sw/share/man:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/man:/Applications/Xcode.app/Contents/Developer/usr/share/man:/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/share/man
MATLABPATH: /Users/user/ODTBX_6_5/mice/lib
PATH: /Users/user/local/lib/python3.6/site-packages/ester:/Users/user/anaconda3/lib:/Users/user/anaconda3/bin:/Users/user/anaconda3/include:/Library/Frameworks/Python.framework/Versions/3.6/bin:/Applications/Julia-1.0.app/Contents/Resources/julia//bin:/Users/user/gnu:/Users/user/.local/bin/python3.6:/usr/local/atlas/include:/usr/local/atlas/lib:/usr/local/pcre/bin:/Applications/Absoft18.0/bin:/bin:/usr/bin:/usr/local/bin:/usr/sbin:/usr/local/sbin:/Users/user/perl5/perlbrew/bin:/Users/user/perl5/perlbrew/perls/perl-5.18.4/bin:/Users/user/Library/Enthought/Canopy_64bit/User/bin:/Users/user/dislin/bin:/usr/local/texlive/2013/bin:/usr/include:/usr/local/include:/opt/subversion/bin:/Users/user/apache-maven-3.3.9/bin:/Applications/Absoft18.0/bin:/Applications/Absoft18.0/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/share/dotnet:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Library/TeX/texbin:/Applications/Xamarin
PERLBREW_MANPATH: /Users/user/perl5/perlbrew/perls/perl-5.18.4/man
PERLBREW_PATH: /Users/user/perl5/perlbrew/bin:/Users/user/perl5/perlbrew/perls/perl-5.18.4/bin
PYTHONPATH: /Users/user/anaconda3:/Users/user/local/lib/python3.6/site-packages/ester
REQUESTS_CA_BUNDLE: <not set>
S2PATH: /Users/user/s2plot-3.2.1
S2PLOT_TEXPATH: /Users/user/s2plot-3.2.1/textures
SSL_CERT_FILE: <not set>
ester_path: /Users/user/local/bin
evpath: /Users/user/TWIN/TWIN

License directories:
    /Users/user/.continuum
    /Users/user/Library/Application Support/Anaconda
    /Users/user/anaconda3/licenses
License files (license*.txt):
Package/feature end dates:
Samuels-Mac-Pro:~ user$ 
```
</details>


`conda list`

<details>

```
# packages in environment at /Users/user/anaconda3:
#
# Name                    Version                   Build  Channel
_ipyw_jlab_nb_ext_conf    0.1.0            py36h2fc01ae_0  
_license                  1.1                      py36_1  
_r-mutex                  1.0.0                     mro_2  
ad                        1.3.2                     <pip>
aiohttp                   3.4.4                     <pip>
alabaster                 0.7.10                   py36_1    conda-forge
algopy                    0.5.7                      py_0    conda-forge
ampl-mp                   3.1.0                         0    conda-forge
anaconda                  custom           py36ha4fed55_0  
anaconda-client           1.6.14                     py_0    conda-forge
anaconda-navigator        1.9.2                    py36_0  
anaconda-project          0.8.2                    py36_0    conda-forge
anyqt                     0.0.8                    py36_1    conda-forge
APLpy                     1.1.1                     <pip>
aplus                     0.11.0                   py36_0    conda-forge
appnope                   0.1.0                    py36_0    conda-forge
appscript                 1.0.1                    py36_0    conda-forge
asdf                      1.3.3                      py_0    conda-forge
asn1crypto                0.24.0                   py36_0    conda-forge
asteval                   0.9.12                   py36_0    conda-forge
astro-gala                0.2.2                    py36_0    conda-forge
astroid                   1.6.3                    py36_0    conda-forge
astroML                   0.3                       <pip>
astroML-addons            0.2.2                     <pip>
astroplan                 0.4                       <pip>
astropy                   3.0.1                    py36_1    conda-forge
astropy-healpix           0.2                      py36_0    conda-forge
astropy-helpers           2.0                      py36_0    astropy
astroquery                0.3.7                    py36_2    conda-forge
astroquery                0.3.8                     <pip>
astroscrappy              1.0.5                    py36_1    conda-forge
async-timeout             3.0.1                     <pip>
attrs                     17.4.0                     py_0    conda-forge
autobahn                  18.3.1                     py_0    vpython
automat                   0.7.0                    py36_0  
babel                     2.5.3                    py36_0    conda-forge
backcall                  0.1.0                      py_0    conda-forge
backports                 1.0                      py36_1    conda-forge
backports.functools_lru_cache 1.5                      py36_0    conda-forge
backports.shutil_get_terminal_size 1.0.0                      py_3    conda-forge
beautifulsoup4            4.6.0                    py36_0    conda-forge
beyond                    0.5                       <pip>
bitarray                  0.8.1                    py36_0    conda-forge
bkcharts                  0.2                      py36_0    conda-forge
blas                      1.1                    openblas    conda-forge
blaze                     0.11.3                   py36_0    conda-forge
bleach                    2.1.3                      py_0    conda-forge
blinker                   1.4                        py_0    conda-forge
bokeh                     0.12.15                  py36_0    conda-forge
boost                     1.66.0                   py36_1    conda-forge
boost-cpp                 1.66.0                        1    conda-forge
boost-vpython             1.55.0                        0    mwcraig
boto                      2.48.0           py36hdbc59ac_1  
boto3                     1.7.62                   py36_1  
botocore                  1.10.62                  py36_0  
bottleneck                1.2.1                    py36_1    conda-forge
bqplot                    0.10.5                   py36_0    conda-forge
bwidget                   1.9.11                        0  
bz2file                   0.98                     py36_0  
bzip2                     1.0.6                         1    conda-forge
ca-certificates           2018.03.07                    0  
cachetools                2.0.1                      py_0    conda-forge
cairo                     1.14.12              hc4e6be7_4  
CALLHORIZONS              1.0.12                    <pip>
cartopy                   0.16.0                   py36_0    conda-forge
ccdproc                   1.3.0                    py36_0    astropy
cctools                   895                  h7512d6f_0  
certifi                   2018.10.15               py36_0  
cffi                      1.11.5                   py36_0    conda-forge
chaospy                   2.3.2                      py_0    conda-forge
chardet                   3.0.4                    py36_0    conda-forge
clang                     4.0.1                h662ec87_0  
clang_osx-64              4.0.1               h1ce6c1d_10  
clangxx                   4.0.1                hc9b4283_0  
clangxx_osx-64            4.0.1               h22b1bf0_10  
click                     6.7                        py_1    conda-forge
cloudpickle               0.5.2                      py_0    conda-forge
cluster-lensing           0.1.2                    py36_0    conda-forge
clyent                    1.2.2                    py36_0    conda-forge
colorama                  0.3.9                    py36_0    conda-forge
commonmark                0.7.5                      py_0    conda-forge
compiler-rt               4.0.1                h5487866_0  
conda                     4.5.11                   py36_0  
conda-build               3.8.0                    py36_0    conda-forge
conda-env                 2.6.0                         0    conda-forge
conda-verify              2.0.0                    py36_0    conda-forge
constantly                15.1.0           py36h28b3542_0  
contextlib2               0.5.5                    py36_1    conda-forge
corner                    2.0.1                     <pip>
corner                    2.0.1                    py36_0    astropy
coverage                  4.5.1                    py36_0    conda-forge
cryptography              2.2.1                    py36_0    conda-forge
curl                      7.59.0                        0    conda-forge
cycler                    0.10.0                   py36_0    conda-forge
cyrus-sasl                2.1.26                        1    conda-forge
cython                    0.28.1                   py36_0    conda-forge
cytoolz                   0.9.0.1                  py36_0    conda-forge
dask                      0.17.2                     py_0    conda-forge
dask-core                 0.17.2                     py_0    conda-forge
datashape                 0.5.4                    py36_0    conda-forge
dateparser                0.7.0                      py_0    conda-forge
dbus                      1.10.22                       0    conda-forge
de405                     1997.1                    <pip>
de406                     1997.1                    <pip>
de421                     2008.1                    <pip>
de422                     2009.1                    <pip>
de423                     2010.1                    <pip>
decorator                 4.2.1                    py36_0    conda-forge
decorator                 4.3.0                     <pip>
dill                      0.2.7.1                  py36_0    conda-forge
distributed               1.21.6                   py36_0    conda-forge
Django                    1.8.19                    <pip>
docopt                    0.6.2                     <pip>
docrep                    0.2.2                    py36_0    conda-forge
docutils                  0.14                     py36_0    conda-forge
drms                      0.5.5                      py_0    conda-forge
eigen                     3.3.3                         0    conda-forge
emcee                     2.2.1                    py36_3    conda-forge
entrypoints               0.2.3                    py36_1    conda-forge
ephem                     3.7.6.0                  py36_1    conda-forge
et_xmlfile                1.0.1                    py36_0    conda-forge
expat                     2.2.5                         0    conda-forge
extinction                0.3.0            py36h7eb728f_0    conda-forge
f90nml                    0.21                     py36_0    conda-forge
fast-histogram            0.3                      py36_0    glueviz
fastcache                 1.0.2                    py36_0    conda-forge
fasteners                 0.14.1                   py36_2    conda-forge
ffmpeg                    4.0                  h01ea3c9_0  
filelock                  3.0.4                    py36_0    conda-forge
filterpy                  1.4.4                     <pip>
flake8                    3.5.0                    py36_0    conda-forge
flask                     0.12.2                   py36_0    conda-forge
flask-cors                3.0.3                    py36_0    conda-forge
FoBiS.py                  2.2.8                     <pip>
font-ttf-dejavu-sans-mono 2.37                 h6964260_0  
font-ttf-inconsolata      2.001                hcb22688_0  
font-ttf-source-code-pro  2.030                h7457263_0  
font-ttf-ubuntu           0.83                 h8b1ccd4_0  
fontconfig                2.13.0               h5d5b041_1  
fonts-anaconda            1                    h8fa9717_0  
FORD                      5.0.6                     <pip>
freetype                  2.9.1                hb4e5f40_0  
freexl                    1.0.5                         0    conda-forge
fribidi                   1.0.4                h1de35cc_0  
funcargparse              0.2.0                    py36_0    conda-forge
future                    0.16.0                   py36_0    conda-forge
galpy                     1.3.0                    py36_0    astropy
gammapy                   0.7                      py36_0    conda-forge
gdal                      2.2.2            py36hd505dc6_1  
gensim                    3.4.0            py36h917ab60_0  
geos                      3.6.2                         1    conda-forge
geotiff                   1.4.2                         1    conda-forge
get_terminal_size         1.0.0                h7520d66_0  
gettext                   0.19.8.1                      0    conda-forge
gevent                    1.3a1                    py36_0    conda-forge
gfortran_osx-64           4.8.5                h22b1bf0_3  
giflib                    5.1.4                         0    conda-forge
ginga                     2.7.0                      py_0    conda-forge
glib                      2.56.1               h35bc53a_0  
glob2                     0.5                      py36_0    conda-forge
glue-core                 0.13.3                   py36_0    conda-forge
glue-vispy-viewers        0.10                     py36_0    conda-forge
glymur                    0.8.14                   py36_2    conda-forge
gmp                       6.1.2                         0    conda-forge
gmpy2                     2.0.8                    py36_1    conda-forge
gnutls                    3.5.17                        0    conda-forge
graphite2                 1.3.11                        0    conda-forge
graphviz                  2.38.0               hd4f1ed2_9    conda-forge
graphviz                  0.8.2                     <pip>
greenlet                  0.4.13                   py36_0    conda-forge
gsl                       2.2.1           blas_openblash47a8a8e_5  [blas_openblas]  conda-forge
gwcs                      0.8.0                    py36_0    conda-forge
h5netcdf                  0.5.0                      py_0    conda-forge
h5py                      2.8.0            py36h470a237_0    conda-forge
halotools                 0.6                      py36_0    conda-forge
harfbuzz                  1.8.8                hb8d4a28_0  
hdf4                      4.2.13                        0    conda-forge
hdf5                      1.10.1                        2    conda-forge
heapdict                  1.0.0                    py36_0    conda-forge
hgtools                   6.3                      py36_0    openastronomy
html5lib                  1.0.1                      py_0    conda-forge
humanize                  0.5.1                    py36_0    conda-forge
humanize                  0.5.1                     <pip>
hyperlink                 18.0.0                   py36_0  
hypothesis                3.56.5                   py36_0    conda-forge
icu                       58.2                          0    conda-forge
idna                      2.6                      py36_1    conda-forge
idna-ssl                  1.1.0                     <pip>
imageio                   2.3.0                    py36_0    conda-forge
imagesize                 1.0.0                    py36_0    conda-forge
imexam                    0.8.0                     <pip>
iminuit                   1.2                      py36_0    astropy
incremental               17.5.0                   py36_0  
intel-openmp              2018.0.0                      8  
ipopt                     3.12.9          blas_openblas_0  [blas_openblas]  conda-forge
ipyevents                 0.2.0                    py36_0    conda-forge
ipykernel                 4.8.2                    py36_0    conda-forge
ipyleaflet                0.7.3                    py36_0    conda-forge
ipympl                    0.1.1                     <pip>
ipympl                    0.2.1                    py36_0    conda-forge
ipyparallel               6.0.2                    py36_0    conda-forge
ipython                   6.3.1                    py36_0    conda-forge
ipython_genutils          0.2.0                    py36_0    conda-forge
ipyvolume                 0.4.6                      py_1    conda-forge
ipyvolume                 0.4.5                     <pip>
ipywebrtc                 0.3.0                    py36_0    conda-forge
ipywidgets                7.2.0                    py36_0    conda-forge
isort                     4.3.4                    py36_0    conda-forge
itsdangerous              0.24                       py_2    conda-forge
jasper                    1.900.1                       4    conda-forge
jbig                      2.1                           0    conda-forge
jcc                       3.1.dev1                 py36_1    conda-forge
jdcal                     1.3                      py36_0    conda-forge
jedi                      0.11.1                   py36_0    conda-forge
jinja2                    2.10                     py36_0    conda-forge
jmespath                  0.9.3                    py36_0  
joblib                    0.11                     py36_0    conda-forge
jpeg                      9c                   h470a237_1    conda-forge
jplephem                  2.7                      py36_0    conda-forge
json-c                    0.12.1                        0    conda-forge
jsonschema                2.6.0                    py36_1    conda-forge
jupyter                   1.0.0                      py_1    conda-forge
jupyter_client            5.2.3                    py36_0    conda-forge
jupyter_console           5.2.0                    py36_0    conda-forge
jupyter_core              4.4.0                      py_0    conda-forge
jupyterlab                0.35.2                   py36_0  
jupyterlab_launcher       0.11.2                   py36_0  
jupyterlab_server         0.2.0                    py36_0  
kapteyn                   2.3              py36h18b3941_2    conda-forge
kealib                    1.4.7                         4    conda-forge
keyring                   12.0.1                   py36_0    conda-forge
keyrings.alt              1.2                      py36_0    conda-forge
kiwisolver                1.0.1                    py36_1    conda-forge
krb5                      1.14.6                        0    conda-forge
lapack                    3.6.1                         1    conda-forge
lazy-object-proxy         1.3.1                    py36_0    conda-forge
ld64                      274.2                h7c2db76_0  
libboost                  1.65.1               hcc95346_4    anaconda
libcurl                   7.61.0               hf30b1f0_0  
libcxx                    4.0.1                h579ed51_0  
libcxxabi                 4.0.1                hebd6815_0  
libdap4                   3.19.2                        1    conda-forge
libedit                   3.1.20170329         haf1bffa_1    conda-forge
libffi                    3.2.1                         3    conda-forge
libgdal                   2.2.2                h3559a57_1  
libgfortran               3.0.1                h93005f0_2  
libiconv                  1.15                          0    conda-forge
libidn11                  1.33                          0    conda-forge
libkml                    1.3.0                         6    conda-forge
libnetcdf                 4.4.1.1                      10    conda-forge
libntlm                   1.4                           1    conda-forge
libopus                   1.2.1                h169cedb_0  
libpng                    1.6.34               he12f830_0  
libpq                     10.3                 hf30b1f0_0  
libsodium                 1.0.16                        0    conda-forge
libspatialite             4.3.0a                       19    conda-forge
libssh2                   1.8.0                         2    conda-forge
libtiff                   4.0.9                         0    conda-forge
libvpx                    1.7.0                h378b8a2_0  
libxcb                    1.13                          0    conda-forge
libxml2                   2.9.8                         0    conda-forge
libxslt                   1.1.32                        0    conda-forge
llvm                      4.0.1                hc748206_0  
llvm-lto-tapi             4.0.1                h6701bc3_0  
llvm-openmp               4.0.1                hda82c8b_0  
llvmlite                  0.24.0                    <pip>
llvmlite                  0.24.0                   py36_0    conda-forge
lmfit                     0.9.9                      py_0    conda-forge
locket                    0.2.0                    py36_1    conda-forge
Logbook                   1.3.0                     <pip>
lxml                      4.2.1                    py36_0    conda-forge
lzo                       2.10                          0    conda-forge
Markdown                  2.6.11                    <pip>
markdown-include          0.5.1                     <pip>
markupsafe                1.0                      py36_0    conda-forge
Mathics                   1.0                       <pip>
matplotlib                3.0.0            py36h54f8f79_0  
matplotlib2tikz           0.6.16                    <pip>
maya                      0.3.4                      py_0    conda-forge
mccabe                    0.6.1                    py36_0    conda-forge
md-environ                0.1.0                     <pip>
metakernel                0.20.14                    py_0    conda-forge
metis                     5.1.0                         3    conda-forge
mistune                   0.8.3                      py_0    conda-forge
mkl                       2018.0.2                      1  
mkl-service               1.1.2            py36h7ea6df4_4  
mkl_fft                   1.0.1                    py36_1    conda-forge
mock                      2.0.0                    py36_0    conda-forge
monotonic                 1.4                      py36_0    conda-forge
more-itertools            4.1.0                      py_0    conda-forge
mpc                       1.0.3                         4    conda-forge
mpfr                      3.1.5                         0    conda-forge
mpi                       1.0                       mpich    conda-forge
mpi4py                    3.0.0                    py36_0    conda-forge
mpich                     3.2.1                         0    conda-forge
mpl-scatter-density       0.3                        py_1    conda-forge
mpmath                    1.0.0                     <pip>
mpmath                    1.0.0                      py_0    conda-forge
msgpack-python            0.5.6                    py36_0    conda-forge
multidict                 4.4.2                     <pip>
multipledispatch          0.5.0                    py36_0    conda-forge
mumps                     5.0.2           blas_openblas_208  [blas_openblas]  conda-forge
naima                     0.8.1                    py36_0    astropy
navigator-updater         0.1.0            py36h7aee5fb_0  
nbconvert                 5.3.1                      py_1    conda-forge
nbformat                  4.4.0                    py36_0    conda-forge
nbsphinx                  0.3.3                     <pip>
ncurses                   6.1                  hfc679d8_1    conda-forge
netcdf4                   1.3.1                    py36_1    conda-forge
nettle                    3.3                           0    conda-forge
networkx                  2.1                      py36_0    conda-forge
newton                    0.1                       <pip>
nlopt                     2.4.2                    py36_2    conda-forge
nltk                      3.2.5            py36h1190bce_0    anaconda
nodepy                    0.7                       <pip>
nose                      1.3.7                    py36_2    conda-forge
notebook                  5.7.0                    py36_0  
numba                     0.39.0                    <pip>
numba                     0.39.0           py36h6440ff4_0  
numdifftools              0.9.20                     py_0    conda-forge
numexpr                   2.6.4                    py36_1    conda-forge
numpy                     1.15.2          py36_blas_openblashd3ea46f_0  [blas_openblas]  conda-forge
numpy                     1.14.4                    <pip>
numpydoc                  0.8.0                    py36_0    conda-forge
oauthlib                  2.0.7                      py_0    conda-forge
oct2py                    4.0.6                    py36_0    conda-forge
octave_kernel             0.28.2                   py36_0    conda-forge
odelab                    0.0.0                     <pip>
odo                       0.5.1                    py36_0    conda-forge
olefile                   0.45.1                   py36_0    conda-forge
omnifit                   0.2.1                    py36_0    astropy
openblas                  0.2.20                        7    conda-forge
openjdk                   8.0.121                       1  
openjpeg                  2.3.0                         2    conda-forge
openpyxl                  2.5.1                    py36_0    conda-forge
openssl                   1.0.2p               h1de35cc_0  
orange3                   3.16.0           py36h6440ff4_0  
OrbitalPy                 0.7.0                     <pip>
orekit                    9.1                      py36_0    conda-forge
owslib                    0.16.0                     py_0    conda-forge
packaging                 17.1                       py_0    conda-forge
padexp                    0.1                       <pip>
pandas                    0.22.0                   py36_0    conda-forge
pandoc                    2.1.3                         0    conda-forge
pandocfilters             1.4.1                    py36_0    conda-forge
pango                     1.40.14              he752989_2    conda-forge
param                     1.6.0                         1    conda-forge
parso                     0.1.1                      py_0    conda-forge
partd                     0.3.8                    py36_0    conda-forge
path.py                   10.3.1                   py36_0    conda-forge
pathlib2                  2.3.0                    py36_0    conda-forge
patsy                     0.5.0                    py36_0    conda-forge
pbr                       4.0.2                      py_0    conda-forge
pcre                      8.42                 h378b8a2_0  
PeakUtils                 1.1.1                     <pip>
peewee                    3.7.1                     <pip>
pendulum                  1.4.4                    py36_0    conda-forge
pendulum                  1.4.4                     <pip>
pep8                      1.7.1                      py_0    conda-forge
pew                       1.1.5                     <pip>
pexpect                   4.4.0                    py36_0    conda-forge
pgplot                    5.2.2                         2    conda-forge
photutils                 0.5              py36h470a237_0    astropy
pickleshare               0.7.4                    py36_0    conda-forge
pillow                    5.2.0            py36hb68e598_0  
pip                       9.0.3                    py36_0    anaconda
pip                       18.1                      <pip>
pipenv                    11.9.0                    <pip>
pixman                    0.34.0                        1    conda-forge
pkginfo                   1.4.2                    py36_0    conda-forge
plotly                    3.1.0                      py_0    conda-forge
plotly                    3.1.0                     <pip>
pluggy                    0.6.0                      py_0    conda-forge
ply                       3.11                     py36_0    conda-forge
poliastro                 0.11.0                     py_0    conda-forge
poppler                   0.65.0               ha097c24_1  
poppler-data              0.4.9                         0  
port-for                  0.4                      py36_0    conda-forge
progressbar2              3.34.3                   py36_0    conda-forge
proj4                     4.9.3                         5    conda-forge
prometheus_client         0.3.1                    py36_0  
prompt_toolkit            1.0.15                   py36_0    conda-forge
psutil                    5.4.3                    py36_0    conda-forge
psycopg2                  2.7.5            py36hdbc3d79_0    anaconda
psyplot                   1.1.0.post1               <pip>
psyplot                   1.1.0.post1              py36_0    conda-forge
psyplot-gui               1.1.0                    py36_0    conda-forge
ptyprocess                0.5.2                    py36_0    conda-forge
py                        1.5.3                      py_0    conda-forge
py-boost                  1.65.1           py36h1439ea1_4    anaconda
pycairo                   1.16.3                   py36_0    conda-forge
pycodestyle               2.3.1                    py36_0    conda-forge
pycosat                   0.6.3                    py36_0    conda-forge
pycparser                 2.18                     py36_0    conda-forge
pycrypto                  2.6.1                    py36_1    conda-forge
pycurl                    7.43.0.1         py36hdbc3d79_0  
pydl                      0.6.0                     <pip>
pyephem                   3.7.6.0                  py36_0    conda-forge
pyepsg                    0.3.2                    py36_0    conda-forge
pyFFTW                    0.10.4                    <pip>
pyflakes                  1.6.0                    py36_0    conda-forge
pygments                  2.2.0                    py36_0    conda-forge
pygraphviz                1.3              py36h1de35cc_1  
pyjwt                     1.6.1                      py_0    conda-forge
pykalman                  0.9.5                     <pip>
pykep                     2.1                      py36_1    conda-forge
pylint                    1.8.4                    py36_0    conda-forge
pyodbc                    4.0.23           py36h0a44026_0  
pyopengl                  3.1.1a1                  py36_0    conda-forge
pyopenssl                 17.5.0                   py36_1    conda-forge
pyparsing                 2.2.0                    py36_0    conda-forge
pyproj                    1.9.5.1                  py36_0    conda-forge
pyqt                      5.6.0                    py36_4    conda-forge
pyqtgraph                 0.10.0                   py36_2    conda-forge
pyregion                  2.0                      py36_0    conda-forge
pysal                     1.14.4.post1             py36_1  
pyshp                     1.2.12                     py_0    conda-forge
pysocks                   1.6.8                    py36_1    conda-forge
pytables                  3.4.2                    py36_7    conda-forge
pytest                    3.5.1                    py36_0  
pytest-arraydiff          0.2                        py_0    conda-forge
pytest-astropy            0.2.1                      py_0    conda-forge
pytest-cov                2.5.1                     <pip>
pytest-doctestplus        0.1.2                      py_0    conda-forge
pytest-mock               1.10.0                   py36_0    conda-forge
pytest-mpl                0.9                        py_0    astropy
pytest-openfiles          0.2.0                      py_0    conda-forge
pytest-remotedata         0.2.0                      py_0    conda-forge
pytest-runner             4.2                        py_0    conda-forge
python                    3.6.5                         1    conda-forge
python-cpl                0.7.2                    py36_0    conda-forge
python-crfsuite           0.9.2                    py36_0    conda-forge
python-dateutil           2.7.2                      py_0    conda-forge
python-louvain            0.11             py36h28b3542_0  
python-markdown-mathjax   1.0.4                     <pip>
python-utils              2.3.0                    py36_0    conda-forge
python.app                1.2                      py36_0    conda-forge
pytz                      2018.4                    <pip>
pytz                      2018.3                     py_0    conda-forge
pytzdata                  2018.3                     py_0    conda-forge
pytzdata                  2018.3                    <pip>
pyvo                      0.6.1                    py36_0    conda-forge
pywavelets                0.5.2                    py36_1    conda-forge
pywwt                     0.3.0                     <pip>
pyyaml                    3.12                     py36_1    conda-forge
pyzmq                     17.0.0                   py36_4    conda-forge
qt                        5.6.2                h9e3eb04_4    conda-forge
qtawesome                 0.4.4                    py36_0    conda-forge
qtconsole                 4.3.1                    py36_0    conda-forge
qtpy                      1.4.2                    py36_0  
r-abind                   1.4_5            r351h6115d3f_0    conda-forge
r-assertthat              0.2.0            r351h6115d3f_1    conda-forge
r-backports               1.1.2            r351hc070d10_1    conda-forge
r-base                    3.5.1                h4fe35fd_1    conda-forge
r-base64enc               0.1_3            r351hc070d10_2    conda-forge
r-bh                      1.66.0_1                 r351_1    conda-forge
r-bindr                   0.1.1            r351h6115d3f_1    conda-forge
r-bindrcpp                0.2.2            r351h9d2a408_1    conda-forge
r-bit                     1.1_12           r351h470a237_2    conda-forge
r-bit64                   0.9_7            r351hc070d10_0    conda-forge
r-bitops                  1.0_6            r351hc070d10_2    conda-forge
r-blob                    1.1.1                    r351_1    conda-forge
r-boot                    1.3_20                   r351_0    conda-forge
r-broom                   0.5.0            r351h6115d3f_2    conda-forge
r-callr                   3.0.0            r351h6115d3f_0    conda-forge
r-caret                   6.0_80           r351hc070d10_1    conda-forge
r-catools                 1.17.1.1         r351h9d2a408_2    conda-forge
r-cellranger              1.1.0            r351h6115d3f_1    conda-forge
r-class                   7.3_14           r351hc070d10_2    conda-forge
r-cli                     1.0.0            r351h6115d3f_1    conda-forge
r-clipr                   0.4.1            r351h6115d3f_1    conda-forge
r-cluster                 2.0.7_1          r351h364d78e_0    conda-forge
r-codetools               0.2_15           r351h6115d3f_1    conda-forge
r-colorspace              1.3_2            r351hc070d10_2    conda-forge
r-config                  0.3              r351h6115d3f_1    conda-forge
r-crayon                  1.3.4            r351h6115d3f_1    conda-forge
r-curl                    3.2              r351hc070d10_2    conda-forge
r-cvst                    0.2_2            r351h6115d3f_0    conda-forge
r-data.table              1.11.4           r351hc070d10_2    conda-forge
r-dbi                     1.0.0            r351h6115d3f_1    conda-forge
r-dbplyr                  1.2.2            r351h6115d3f_1    conda-forge
r-ddalpha                 1.3.4            r351he0ffe0d_1    conda-forge
r-deoptimr                1.0_8            r351h6115d3f_1    conda-forge
r-dichromat               2.0_0            r351hf348343_4  
r-digest                  0.6.18           r351hc070d10_0    conda-forge
r-dimred                  0.1.0            r351h6115d3f_2    conda-forge
r-dplyr                   0.7.6            r351h9d2a408_1    conda-forge
r-drr                     0.0.3            r351h6115d3f_1    conda-forge
r-essentials              3.5.1                    r351_0  
r-evaluate                0.11             r351h6115d3f_0    conda-forge
r-fansi                   0.3.0            r351hc070d10_0    conda-forge
r-forcats                 0.3.0            r351h6115d3f_1    conda-forge
r-foreach                 1.4.4            r351h6115d3f_1    conda-forge
r-foreign                 0.8_71           r351hc070d10_2    conda-forge
r-formatr                 1.5              r351h6115d3f_1    conda-forge
r-geometry                0.3_6            r351hc070d10_2    conda-forge
r-ggplot2                 3.0.0            r351h6115d3f_1    conda-forge
r-glmnet                  2.0_16           r351h364d78e_1    conda-forge
r-glue                    1.3.0            r351h470a237_2    conda-forge
r-gower                   0.1.2            r351hc070d10_2    conda-forge
r-gtable                  0.2.0            r351h6115d3f_1    conda-forge
r-haven                   1.1.2            r351h9d2a408_2    conda-forge
r-hexbin                  1.27.2           r351h364d78e_2    conda-forge
r-highr                   0.7              r351h6115d3f_1    conda-forge
r-hms                     0.4.2            r351h6115d3f_0    conda-forge
r-htmltools               0.3.6            r351hfc679d8_2    conda-forge
r-htmlwidgets             1.2              r351h6115d3f_0    conda-forge
r-httpuv                  1.4.5            r351hfc679d8_1    conda-forge
r-httr                    1.3.1            r351h6115d3f_1    conda-forge
r-ipred                   0.9_7            r351hc070d10_1    conda-forge
r-irdisplay               0.5.0            r351hf348343_0  
r-irkernel                0.8.12                   r351_0  
r-iterators               1.0.10           r351h6115d3f_1    conda-forge
r-jsonlite                1.5              r351hc070d10_2    conda-forge
r-kernlab                 0.9_27           r351h9d2a408_0    conda-forge
r-kernsmooth              2.23_15          r351h364d78e_2    conda-forge
r-knitr                   1.20             r351h6115d3f_1    conda-forge
r-labeling                0.3              r351h6115d3f_1    conda-forge
r-later                   0.7.3            r351h9d2a408_0    conda-forge
r-lattice                 0.20_35          r351hc070d10_0    conda-forge
r-lava                    1.6.3            r351h6115d3f_1    conda-forge
r-lazyeval                0.2.1            r351hc070d10_2    conda-forge
r-lubridate               1.7.4            r351h9d2a408_1    conda-forge
r-magic                   1.5_8            r351h6115d3f_0    conda-forge
r-magrittr                1.5              r351h6115d3f_1    conda-forge
r-maps                    3.3.0            r351hc070d10_2    conda-forge
r-markdown                0.8              r351hc070d10_3    conda-forge
r-mass                    7.3_50           r351hc070d10_2    conda-forge
r-matrix                  1.2_14           r351hc070d10_2    conda-forge
r-mgcv                    1.8_24           r351hc070d10_2    conda-forge
r-mime                    0.5              r351hc070d10_2    conda-forge
r-miniui                  0.1.1.1          r351h6115d3f_0    conda-forge
r-mnormt                  1.5_5            r351h364d78e_1    conda-forge
r-modelmetrics            1.1.0            r351h9d2a408_2    conda-forge
r-modelr                  0.1.2            r351h6115d3f_1    conda-forge
r-mongolite               1.6              r351h6402f54_0  
r-munsell                 0.5.0            r351h6115d3f_1    conda-forge
r-nlme                    3.1_137          r351h364d78e_0    conda-forge
r-nnet                    7.3_12           r351hc070d10_2    conda-forge
r-numderiv                2016.8_1         r351h6115d3f_1    conda-forge
r-odbc                    1.1.5            r351h0a44026_0  
r-openssl                 1.0.2            r351h9f97512_0    conda-forge
r-packrat                 0.4.9_3          r351h6115d3f_1    conda-forge
r-pbdzmq                  0.3_3            r351h32998d9_0  
r-pillar                  1.3.0            r351h6115d3f_0    conda-forge
r-pkgconfig               2.0.2            r351h6115d3f_1    conda-forge
r-pki                     0.1_5.1          r351hc070d10_0    conda-forge
r-plogr                   0.2.0            r351h6115d3f_1    conda-forge
r-pls                     2.7_0            r351h6115d3f_0    conda-forge
r-plyr                    1.8.4            r351h9d2a408_2    conda-forge
r-prettyunits             1.0.2            r351h6115d3f_1    conda-forge
r-processx                3.2.0            r351hc070d10_1    conda-forge
r-prodlim                 2018.04.18       r351h9d2a408_2    conda-forge
r-profvis                 0.3.5            r351h6402f54_0  
r-promises                1.0.1            r351h9d2a408_0    conda-forge
r-ps                      1.1.0            r351hc070d10_1    conda-forge
r-psych                   1.8.4            r351h6115d3f_1    conda-forge
r-purrr                   0.2.5            r351hc070d10_1    conda-forge
r-quantmod                0.4_13           r351hf348343_0  
r-r6                      2.2.2            r351h6115d3f_1    conda-forge
r-randomforest            4.6_14           r351h364d78e_0    conda-forge
r-rappdirs                0.3.1            r351hc070d10_2    conda-forge
r-rbokeh                  0.6.3                    r351_0  
r-rcolorbrewer            1.1_2            r351h6115d3f_1    conda-forge
r-rcpp                    0.12.17          r351h9d2a408_2    conda-forge
r-rcpproll                0.3.0            r351h9d2a408_0    conda-forge
r-rcurl                   1.95_4.11        r351h86b9717_2    conda-forge
r-readr                   1.1.1            r351h9d2a408_2    conda-forge
r-readxl                  1.1.0            r351h9d2a408_2    conda-forge
r-recipes                 0.1.3            r351h6115d3f_1    conda-forge
r-recommended             3.5.1                    r351_1    conda-forge
r-rematch                 1.0.1            r351h6115d3f_1    conda-forge
r-repr                    0.15.0           r351hf348343_0  
r-reprex                  0.2.0            r351h6115d3f_1    conda-forge
r-reshape2                1.4.3            r351h9d2a408_2    conda-forge
r-rjava                   0.9_10           r351h6402f54_0  
r-rjdbc                   0.2_7.1          r351hf348343_0  
r-rjsonio                 1.3_0            r351h9d2a408_2    conda-forge
r-rlang                   0.2.2            r351h470a237_0    conda-forge
r-rmarkdown               1.10             r351h6115d3f_1    conda-forge
r-robustbase              0.93_2           r351h364d78e_0    conda-forge
r-rpart                   4.1_13           r351hc070d10_2    conda-forge
r-rprojroot               1.3_2            r351h6115d3f_1    conda-forge
r-rsconnect               0.8.8            r351h6115d3f_0    conda-forge
r-rstudioapi              0.7              r351h6115d3f_1    conda-forge
r-rvest                   0.3.2            r351h6115d3f_1    conda-forge
r-scales                  1.0.0            r351h9d2a408_1    conda-forge
r-selectr                 0.4_1            r351h6115d3f_0    conda-forge
r-sfsmisc                 1.1_2            r351h6115d3f_0    conda-forge
r-shiny                   1.1.0                    r351_0    conda-forge
r-sourcetools             0.1.7            r351hfc679d8_0    conda-forge
r-sparklyr                0.8.4            r351h6115d3f_1    conda-forge
r-spatial                 7.3_11           r351hc070d10_2    conda-forge
r-squarem                 2017.10_1        r351h6115d3f_1    conda-forge
r-stringi                 1.2.4            r351h9d2a408_1    conda-forge
r-stringr                 1.3.1            r351h6115d3f_1    conda-forge
r-survival                2.42_6           r351hc070d10_1    conda-forge
r-tibble                  1.4.2            r351hc070d10_2    conda-forge
r-tidyr                   0.8.1            r351h9d2a408_2    conda-forge
r-tidyselect              0.2.4            r351h9d2a408_2    conda-forge
r-tidyverse               1.2.1            r351h6115d3f_1    conda-forge
r-timedate                3043.102         r351h6115d3f_0    conda-forge
r-tinytex                 0.8              r351h6115d3f_0    conda-forge
r-ttr                     0.23_4           r351h364d78e_0    conda-forge
r-utf8                    1.1.4            r351hc070d10_0    conda-forge
r-uuid                    0.1_2            r351hc070d10_1    conda-forge
r-viridislite             0.3.0            r351h6115d3f_1    conda-forge
r-whisker                 0.3_2            r351h6115d3f_1    conda-forge
r-withr                   2.1.2            r351h6115d3f_0    conda-forge
r-xfun                    0.3              r351h6115d3f_1    conda-forge
r-xml2                    1.2.0            r351h9d2a408_2    conda-forge
r-xtable                  1.8_3                    r351_0    conda-forge
r-xts                     0.11_1           r351hc070d10_0    conda-forge
r-yaml                    2.2.0            r351hc070d10_1    conda-forge
r-zoo                     1.8_3            r351hc070d10_0    conda-forge
ratelimiter               1.2.0.post0               <pip>
readline                  7.0                  hc1231fa_4  
regex                     2018.02.21               py36_0    conda-forge
regions                   0.2                      py36_0    conda-forge
Represent                 1.5.1                     <pip>
reproject                 0.4                      py36_0    astropy
requests                  2.18.4                   py36_1    conda-forge
requests-oauthlib         0.8.0                    py36_1    conda-forge
retrying                  1.3.3                     <pip>
retrying                  1.3.3                      py_2    conda-forge
rope                      0.10.7                   py36_0    conda-forge
rstudio                   1.1.423              hb125a76_0  
ruamel.yaml               0.15.37                  py36_0    conda-forge
ruamel_yaml               0.15.35                  py36_0    conda-forge
runstats                  1.7.1                     <pip>
s3transfer                0.1.13                   py36_0  
scikit-image              0.14.0           py36h0a44026_1    anaconda
scikit-learn              0.19.1          py36_blas_openblas_201  [blas_openblas]  conda-forge
scipy                     1.1.0           py36_blas_openblash7943236_201  [blas_openblas]  conda-forge
scotch                    6.0.4                         4    conda-forge
semantic_version          2.6.0                    py36_0  
send2trash                1.5.0                      py_0    conda-forge
serverfiles               0.2.1                      py_0    conda-forge
setproctitle              1.1.10                   py36_0    conda-forge
setuptools                39.0.1                   py36_0    conda-forge
setuptools                39.1.0                    <pip>
sgp4                      1.4                      py36_2    conda-forge
shapely                   1.6.4                    py36_0    conda-forge
simplegeneric             0.8.1                    py36_0    conda-forge
singledispatch            3.4.0.3                  py36_0    conda-forge
sip                       4.18                     py36_1    conda-forge
six                       1.11.0                   py36_1    conda-forge
skyfield                  1.9                       <pip>
skyfield                  1.2                        py_1    conda-forge
smart_open                1.6.0                    py36_0    anaconda
sncosmo                   1.5.3                    py36_0    conda-forge
snowballstemmer           1.2.1                    py36_0    conda-forge
sortedcollections         0.6.1                    py36_0    conda-forge
sortedcontainers          1.5.9                    py36_0    conda-forge
space-command             0.3                       <pip>
spacetrack                0.13.1                    <pip>
spectral-cube             0.4.0                    py36_0    conda-forge
specutils                 0.2.2                    py36_0    conda-forge
spherical-geometry        1.1.0                    py36_0    conda-forge
sphinx                    1.7.4                    py36_0  
Sphinx                    1.5.6                     <pip>
sphinx_rtd_theme          0.3.0                    py36_0    conda-forge
sphinxcontrib             1.0              py36h9364dc8_1  
sphinxcontrib-websupport  1.0.1                    py36_0    conda-forge
spiceypy                  2.1.2                    py36_1    andrewannex
spyder                    3.3.1                    py36_1  
spyder-kernels            0.2.4                    py36_0  
sqlalchemy                1.2.6                    py36_0    conda-forge
sqlite                    3.20.1                        0    conda-forge
statsmodels               0.8.0                    py36_0    conda-forge
suds-jurko                0.6                      py36_1    conda-forge
sunpy                     0.9.2                    py36_0    conda-forge
sympy                     1.0                       <pip>
tblib                     1.3.2                    py36_0    conda-forge
terminado                 0.8.1                    py36_0    conda-forge
testpath                  0.3.1                    py36_0    conda-forge
tk                        8.6.8                ha92aebf_0    conda-forge
tktable                   2.10                 h1de35cc_0  
toolz                     0.9.0                      py_0    conda-forge
toposort                  1.5                       <pip>
tornado                   5.0.1                    py36_1    conda-forge
traitlets                 4.3.2                    py36_0    conda-forge
traittypes                0.0.6                    py36_0    conda-forge
twisted                   17.5.0                   py36_0  
twython                   3.6.0                    py36_0    conda-forge
txaio                     2.9.0                      py_0    vpython
typing                    3.6.4                    py36_0    conda-forge
tzlocal                   1.5.1                      py_0    conda-forge
ujson                     1.35                     py36_0    conda-forge
unicodecsv                0.14.1                   py36_0    conda-forge
unixodbc                  2.3.7                h09ba92c_0    conda-forge
urllib3                   1.22                     py36_0    conda-forge
vaex                      1.0.0b7                    py_0    conda-forge
vaex-astro                0.1.5                    py36_0    conda-forge
vaex-core                 0.1.9                    py36_0    conda-forge
vaex-distributed          0.1.0                      py_0    conda-forge
vaex-hdf5                 0.1.4                      py_0    conda-forge
vaex-jupyter              0.2.1                      py_0    conda-forge
vaex-server               0.1.2                      py_0    conda-forge
vaex-ui                   0.2.0                      py_0    conda-forge
vaex-viz                  0.3.0                      py_0    conda-forge
virtualenv                15.2.0                    <pip>
virtualenv-clone          0.3.0                     <pip>
vpnotebook                0.1.3                    py36_1    vpython
vpython                   7.4.3                    py36_0    vpython
wcwidth                   0.1.7                    py36_0    conda-forge
webencodings              0.5                      py36_0    conda-forge
werkzeug                  0.14.1                     py_0    conda-forge
wheel                     0.31.0                   py36_0    conda-forge
widgetsnbextension        3.2.0                    py36_0    conda-forge
wrapt                     1.10.11                  py36_0    conda-forge
x264                      20131217                      3    conda-forge
xarray                    0.10.2                   py36_0    conda-forge
xerces-c                  3.2.0                         0    conda-forge
xlrd                      1.1.0                      py_2    conda-forge
xlsxwriter                1.0.2                      py_0    conda-forge
xlwings                   0.11.7                   py36_0    conda-forge
xlwt                      1.3.0                    py36_0    conda-forge
xonsh                     0.6.0                    py36_2    conda-forge
xorg-kbproto              1.0.7                         1    conda-forge
xorg-libice               1.0.9                h470a237_4    conda-forge
xorg-libsm                1.2.3                h470a237_0    conda-forge
xorg-libx11               1.6.5                         0    conda-forge
xorg-libxau               1.0.8                         3    conda-forge
xorg-libxdmcp             1.1.2                         3    conda-forge
xorg-libxext              1.3.3                h470a237_4    conda-forge
xorg-libxrender           0.9.10               h470a237_2    conda-forge
xorg-renderproto          0.11.1               h470a237_2    conda-forge
xorg-xextproto            7.3.0                h470a237_2    conda-forge
xorg-xproto               7.0.31                        6    conda-forge
xz                        5.2.4                h1de35cc_4  
yaml                      0.1.7                         0    conda-forge
yarl                      1.2.6                     <pip>
zeromq                    4.2.5                         1    conda-forge
zict                      0.1.3                      py_0    conda-forge
zlib                      1.2.11               hf3cbc9b_2  
zope                      1.0                      py36_0  
zope.interface            4.5.0            py36h1de35cc_0  
```
</details>

`pip freeze | grep astropy`

``` 
astropy==3.0.1
astropy-healpix==0.2
astropy-helpers==2.0
pytest-astropy==0.2.1
```

`pip freeze | grep poliastro`

```
poliastro==0.11.0
```

<!--- If this Issue is a feature request, please ignore the next command.-->
<!--- Please make sure you have installed ""pytest"" in your machine for this command.-->

`python -c ""import poliastro.testing; poliastro.testing.test()""`

<details>

```
Samuels-Mac-Pro:~ user$ python -c ""import poliastro.testing; poliastro.testing.test()""
================================================== test session starts ===================================================
platform darwin -- Python 3.6.5, pytest-3.5.1, py-1.5.3, pluggy-0.6.0
INTERNALERROR> Traceback (most recent call last):
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/_pytest/main.py"", line 105, in wrap_session
INTERNALERROR>     config.hook.pytest_sessionstart(session=session)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/__init__.py"", line 617, in __call__
INTERNALERROR>     return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/__init__.py"", line 222, in _hookexec
INTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/__init__.py"", line 216, in <lambda>
INTERNALERROR>     firstresult=hook.spec_opts.get('firstresult'),
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/callers.py"", line 201, in _multicall
INTERNALERROR>     return outcome.get_result()
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/callers.py"", line 76, in get_result
INTERNALERROR>     raise ex[1].with_traceback(ex[2])
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/callers.py"", line 180, in _multicall
INTERNALERROR>     res = hook_impl.function(*args)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/_pytest/terminal.py"", line 441, in pytest_sessionstart
INTERNALERROR>     config=self.config, startdir=self.startdir)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/__init__.py"", line 617, in __call__
INTERNALERROR>     return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/__init__.py"", line 222, in _hookexec
INTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/__init__.py"", line 216, in <lambda>
INTERNALERROR>     firstresult=hook.spec_opts.get('firstresult'),
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/callers.py"", line 201, in _multicall
INTERNALERROR>     return outcome.get_result()
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/callers.py"", line 76, in get_result
INTERNALERROR>     raise ex[1].with_traceback(ex[2])
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pluggy/callers.py"", line 180, in _multicall
INTERNALERROR>     res = hook_impl.function(*args)
INTERNALERROR>   File ""/Users/user/anaconda3/lib/python3.6/site-packages/pytest_mpl/plugin.py"", line 75, in pytest_report_header
INTERNALERROR>     import matplotlib.ft2font
INTERNALERROR> ImportError: dlopen(/Users/user/anaconda3/lib/python3.6/site-packages/matplotlib/ft2font.cpython-36m-darwin.so, 2): Symbol not found: _inflateValidate
INTERNALERROR>   Referenced from: /Users/user/anaconda3/lib/libpng16.16.dylib
INTERNALERROR>   Expected in: /usr/lib/libz.1.dylib
INTERNALERROR>  in /Users/user/anaconda3/lib/libpng16.16.dylib

Samuels-Mac-Pro:~ user$ pythonw -c ""import poliastro.testing; poliastro.testing.test()""
============================================================================ test session starts =============================================================================
platform darwin -- Python 3.6.5, pytest-3.5.1, py-1.5.3, pluggy-0.6.0
Matplotlib: 3.0.0
Freetype: 2.9.1
rootdir: /Users/user, inifile:
plugins: xonsh-0.6.0, remotedata-0.2.0, openfiles-0.2.0, mpl-0.9, mock-1.10.0, doctestplus-0.1.2, cov-2.5.1, arraydiff-0.2, hypothesis-3.56.5
collected 474 items                                                                                                                                                          

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_bodies.py ......                                                                                            [  1%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_coordinates.py ...                                                                                          [  1%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_frames.py ..........................                                                                        [  7%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_hyper.py ...........                                                                                        [  9%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_iod.py .........                                                                                            [ 11%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_jit.py ...                                                                                                  [ 12%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_maneuver.py ......                                                                                          [ 13%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_patched_conics.py ....                                                                                      [ 14%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting.py ..........                                                                                      [ 16%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting2d.py ........                                                                                      [ 18%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting3d.py .........                                                                                     [ 20%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_stumpff.py ...                                                                                              [ 20%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_twobody.py ..                                                                                               [ 21%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_util.py .....                                                                                               [ 22%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_neos/test_dastcom5.py .........                                                                            [ 24%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_neos/test_neos_neows.py ......                                                                             [ 25%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_threebody/test_flybys.py ..                                                                                [ 25%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_threebody/test_restricted.py .                                                                             [ 25%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_angles.py ................................................................................... [ 43%]
............................................................................................................................                                           [ 69%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_decorators.py ..                                                                              [ 70%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_orbit.py ........................x....................                                        [ 79%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_perturbations.py .xxxx........s.                                                              [ 82%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_propagation.py .........................xs...                                                 [ 89%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_sample.py ........................                                                            [ 94%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_states.py ..........                                                                          [ 96%]
anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_thrust.py .s................                                                                  [100%]

============================================================================== warnings summary ==============================================================================
anaconda3/lib/python3.6/site-packages/poliastro/tests/test_patched_conics.py::test_compute_soi
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:200: TimeScaleWarning:
  
  Input time was converted to scale='tdb' with value J2000.000. Use Time(..., scale='tdb') instead.
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_patched_conics.py::test_compute_missing_body_soi_raises_error[missing_body0]
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:200: TimeScaleWarning:
  
  Input time was converted to scale='tdb' with value J2000.000. Use Time(..., scale='tdb') instead.
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_patched_conics.py::test_compute_missing_body_soi_raises_error[missing_body1]
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:200: TimeScaleWarning:
  
  Input time was converted to scale='tdb' with value J2000.000. Use Time(..., scale='tdb') instead.
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting.py::test_plot_solar_system[True-8]
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting.py::test_plot_solar_system[False-4]
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting.py::test_plot_trajectory_sets_label
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting2d.py::test_plot_trajectory_plots_a_trajectory
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting2d.py::test_show_calls_prepare_plot
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting2d.py::test_savefig_calls_prepare_plot
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting3d.py::test_plot_trajectory_plots_a_trajectory
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting3d.py::test_show_calls_prepare_plot
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/test_plotting3d.py::test_savefig_calls_prepare_plot
  /Users/user/anaconda3/lib/python3.6/site-packages/poliastro/twobody/orbit.py:494: UserWarning:
  
  Frame <class 'astropy.coordinates.builtin_frames.icrs.ICRS'> does not support 'obstime', time values were not returned
  

anaconda3/lib/python3.6/site-packages/poliastro/tests/tests_twobody/test_propagation.py::test_long_propagations_kepler_agrees_mean_motion
  /Users/user/anaconda3/lib/python3.6/site-packages/astropy/_erfa/core.py:118: ErfaWarning:
  
  ERFA function ""taiutc"" yielded 1 of ""dubious year (Note 4)""
  

-- Docs: http://doc.pytest.org/en/latest/warnings.html
====================================================== 465 passed, 3 skipped, 6 xfailed, 13 warnings in 492.24 seconds =======================================================
Samuels-Mac-Pro:~ user$ 
```",Could you please confirm if that fixes your issue?,"<details>

`````
</details>

`

``` ``

``

``
````

<details>

`````"
poliastro/poliastro,https://github.com/poliastro/poliastro/issues/904,poliastro_poliastro_issues_904,"Lambert method for in-plane transfer

I'm trying to solve the transfer between a circular orbit with 200km radius and an orbit with 200km perigee and 8000km apogee.

The optimal transfer is hoffman, however, izzo.lambert gives different result. 

My code: 
```
from astropy import units as u
from poliastro.bodies import Earth
from poliastro.iod import izzo
from poliastro.core.elements import coe2rv
from poliastro.util import norm
import math
import time

Earth_k = Earth.k
Req = Earth.R.to(u.km).value

def keplerian2cartesian(kepler):

    a=(kepler[0]+kepler[1]+Req*2)*1000/2 * u.m
    e=(kepler[0]-kepler[1])/(kepler[0]+kepler[1]+Req*2)

    (R,V)=coe2rv(Earth.k,a,e,kepler[2],kepler[3],kepler[4],kepler[5])

    return [R * u.m] + [V * u.m/u.s]

# Checking different transfer times
def transfer_time(DV_min,vector0,vector,period):

    init_t=10
    t_value=init_t
    (r0,r,v0,v)=(vector0[0],vector[0],vector0[1],vector[1])

    while init_t<period:

        tof = init_t * u.min

        try:
            (f_v0, f_v), = izzo.lambert(Earth_k, r0, r, tof)
        except:
            init_t+=1
            continue

        DV0=norm(f_v0-v0).value*1000
        DV=norm(f_v-v).value*1000

        if(DV0+DV<DV_min):
            t_value=init_t
            DV0_value=DV0
            DV_value=DV
            DV_min=DV0+DV

        init_t+=1

    return (t_value,DV_value,DV0_value)


# Checking different initial and final true anomalies
def transfer_tetta(kepler0,kepler):
    DV_min=100000
    final_tetta=0

    a=(kepler[0]+kepler[1]+Req*2)*1000/2
    period=math.ceil(math.sqrt((a**3/Earth.k.value)*4*(math.pi)**2)/60)

    while final_tetta<360:
        init_tetta=0
        while init_tetta<360:
            vector0=keplerian2cartesian(kepler0 + [init_tetta*math.pi/180])
            vector =keplerian2cartesian(kepler  + [final_tetta*math.pi/180])
            try:
                (init_t,DV,DV0)=transfer_time(DV_min,vector0,vector,period)
            except:
                init_tetta+=5
                continue

            if DV+DV0<DV_min:
                DV_min=DV+DV0
                (t_value,DV0_value,DV_value,init_tetta_value,final_tetta_value)=(init_t,DV0,DV,init_tetta,final_tetta)

            init_tetta+=5
        final_tetta+=5

    print(""t: "", t_value, ""DV_init: "", DV0_value,""DV_final: "", DV_value)
    print(""DV: "", DV_min)
    print(""Init tetta: "", init_tetta_value, ""Final tetta: "", final_tetta_value)

# 1->2
transfer_tetta([200,  200, 64.3*math.pi/180, 0, 300*math.pi/180],[8000, 200, 64.3*math.pi/180, 0, 300*math.pi/180])

```","Could you please share the code you're using? If it's long, you can upload it to https://gist.github.com/","My code: 
```
from astropy import units as u
from poliastro.bodies import Earth
from poliastro.iod import izzo
import math
import time

Earth_k = Earth.k
Req = Earth.R.to(u.km).value
g0=9.80665

def norm(vector):
    return math.sqrt(vector[0]**2+vector[1]**2+vector[2]**2)
    
#kepler a,p,i,OMEGA,omega,tetta   
def keplerian2cartesian(kepler):

    a=(kepler[0]+kepler[1]+Req*2)*1000/2
    e=(kepler[0]-kepler[1])/(kepler[0]+kepler[1]+Req*2)
    i=kepler[2]
    OMEGA=kepler[3]
    omega=kepler[4]
    tetta=kepler[5]

    gamma=math.atan((e*math.sin(tetta))/(1+e*math.cos(tetta)))
  
    r=(a*(1-e**2))/(1+e*math.cos(tetta))
    v=math.sqrt(Earth_k.value*(2/r-1/a))
   
    X=r*( math.cos(tetta+omega)*math.cos(OMEGA) - math.sin(tetta+omega)*math.cos(i)*math.sin(OMEGA) )
    Y=r*( math.cos(tetta+omega)*math.sin(OMEGA) + math.sin(tetta+omega)*math.cos(i)*math.cos(OMEGA) )
    Z=r*( math.sin(tetta+omega)*math.sin(i) )
  
    Vx=v*( -math.sin(tetta+omega-gamma)*math.cos(OMEGA) - math.cos(tetta+omega-gamma)*math.cos(i)*math.sin(OMEGA) )
    Vy=v*( -math.sin(tetta+omega-gamma)*math.sin(OMEGA) + math.cos(tetta+omega-gamma)*math.cos(i)*math.cos(OMEGA) )
    Vz=v*(  math.cos(tetta+omega-gamma)*math.sin(i) )
  
    return [X/1000,Y/1000,Z/1000,Vx/1000,Vy/1000,Vz/1000]

# Checking different transfer times
def transfer_time(DV_max,vector0,vector):

    init_t=30
    r0=vector0[0:3] * u.km
    r =vector[0:3]  * u.km
    v0=vector0[3:6] * u.km / u.s
    v =vector[3:6]  * u.km / u.s

    t_value=init_t

    while init_t<60*24:
        
        tof = init_t * u.min

        try:        
            (f_v0, f_v), = izzo.lambert(Earth_k, r0, r, tof)
        except:
            init_t+=30
            continue
            
        DV0=norm((f_v0-v0).value)*1000
        DV=norm((f_v-v).value)*1000
        
        if(DV0+DV<DV_max):    
            t_value=init_t
            DV0_value=DV0
            DV_value=DV
            DV_max=DV0+DV

        init_t+=30
    
    return (t_value,DV_value,DV0_value)


# Checking different initial and final true anomalies
def transfer_tetta(kepler0,kepler):
    DV_max=100000
    final_tetta=0
    while final_tetta<360:
        init_tetta=0
        while init_tetta<360:
            vector0=keplerian2cartesian(kepler0 + [init_tetta*math.pi/180])
            vector =keplerian2cartesian(kepler  + [final_tetta*math.pi/180]) 

            try:        
                (init_t,DV,DV0)=transfer_time(DV_max,vector0,vector)
            except:
                init_tetta+=5
                continue
            
            if DV+DV0<DV_max:
                DV_max=DV+DV0
                (t_value,DV0_value,DV_value,init_tetta_value,final_tetta_value)=(init_t,DV0,DV,init_tetta,final_tetta)
                
            init_tetta+=5   
        final_tetta+=5

    print(""DV_init: "", DV0_value,""DV_final: "", DV_value)
    print(""Init tetta: "", init_tetta_value, ""Final tetta: "", final_tetta_value)
    
# 1->2
transfer_tetta([200,  200, 64.3*math.pi/180, 0, 300*math.pi/180],[8000, 200, 64.3*math.pi/180, 0, 300*math.pi/180])
```"
EddyVerbruggen/Calendar-PhoneGap-Plugin,https://github.com/EddyVerbruggen/Calendar-PhoneGap-Plugin/issues/473,EddyVerbruggen_Calendar-PhoneGap-Plugin_issues_473,"Android listCallendars crashes app

Hello, running some tests on AWS Device Farm I have found that this plugin crashes when we call _listCalendars_.

The ""_isPrimary_"" key is not present on some devices, I have found Samsung Galaxy Note 2, 3 and 4 on _Amazon Web Services Device Farm_ with Android 4.4 and 5.

The code crashes because of a cursor with the wrong index in the method _getActiveCalendars_ on _AbstractCalendarAccessor.java_. It looks that the ""_isPrimary_"" key is not present on all devices.
https://stackoverflow.com/questions/25870556/check-if-calendar-is-primary

The call _cursor.getColumnIndex(this.getKey(KeyIndex.IS_PRIMARY))_ returns _-1_. After that, the cursor looking for a -1 index crashes the app.

```
calendar.put(""isPrimary"", ""1"".equals(cursor.getString(cursor.getColumnIndex(this.getKey(KeyIndex.IS_PRIMARY)))));
```

The docs say that it has to do to the owner... I don't really know what they mean:
https://developer.android.com/reference/android/provider/CalendarContract.CalendarColumns

```
public final JSONArray getActiveCalendars() throws JSONException {
    Cursor cursor = queryCalendars(
            new String[]{
                    this.getKey(KeyIndex.CALENDARS_ID),
                    this.getKey(KeyIndex.CALENDARS_NAME),
                    this.getKey(KeyIndex.CALENDARS_DISPLAY_NAME),
                    this.getKey(KeyIndex.IS_PRIMARY)
            },
            this.getKey(KeyIndex.CALENDARS_VISIBLE) + ""=1"", null, null
    );
    if (cursor == null) {
        return null;
    }
    JSONArray calendarsWrapper = new JSONArray();
    if (cursor.moveToFirst()) {
        do {
            JSONObject calendar = new JSONObject();
            calendar.put(""id"", cursor.getString(cursor.getColumnIndex(this.getKey(KeyIndex.CALENDARS_ID))));
            calendar.put(""name"", cursor.getString(cursor.getColumnIndex(this.getKey(KeyIndex.CALENDARS_NAME))));
            calendar.put(""displayname"", cursor.getString(cursor.getColumnIndex(this.getKey(KeyIndex.CALENDARS_DISPLAY_NAME))));
            calendar.put(""isPrimary"", ""1"".equals(cursor.getString(cursor.getColumnIndex(this.getKey(KeyIndex.IS_PRIMARY)))));
            calendarsWrapper.put(calendar);
        } while (cursor.moveToNext());
        cursor.close();
    }
    return calendarsWrapper;
}
```

Here is the log from the crash.

```
06-07 11:15:56.236 12285 12471 E CursorWindow: Failed to read row 0, column -1 from a CursorWindow which has 1 rows, 4 columns.
06-07 11:15:56.236 12285 12471 W dalvikvm: threadid=23: thread exiting with uncaught exception (group=0x41e61c08)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: FATAL EXCEPTION: pool-1-thread-2
06-07 11:15:56.241 12285 12471 E AndroidRuntime: Process: me.tararea.calendar, PID: 12285
06-07 11:15:56.241 12285 12471 E AndroidRuntime: java.lang.IllegalStateException: Couldn't read row 0, col -1 from CursorWindow.  Make sure the Cursor is initialized correctly before accessing data from it.
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at android.database.CursorWindow.nativeGetString(Native Method)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at android.database.CursorWindow.getString(CursorWindow.java:439)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at android.database.AbstractWindowedCursor.getString(AbstractWindowedCursor.java:51)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at android.database.CursorWrapper.getString(CursorWrapper.java:114)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at nl.xservices.plugins.accessor.AbstractCalendarAccessor.getActiveCalendars(AbstractCalendarAccessor.java:291)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at nl.xservices.plugins.Calendar$3.run(Calendar.java:270)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1112)
06-07 11:15:56.241 12285 12471 E AndroidRuntime: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:587)
```

A quick way to test:

- create a cordova app that calls listCalendar
- create a free, 1000 minutes account on AWS Device Farm
- test the app on Samsung Galaxy Note 2.


Thank you very much for your work.",Would you be willing to attempt doing a pull request to fix it?,"Here is the log from the crash.

A quick way to test:

- create a cordova app that calls listCalendar
- create a free, 1000 minutes account on AWS Device Farm
- test the app on Samsung Galaxy Note 2."
Rust-SDL2/rust-sdl2,https://github.com/Rust-SDL2/rust-sdl2/issues/851,Rust-SDL2_rust-sdl2_issues_851,"SDL_RenderGetMetalLayer returns nothing when using `bundled`

`SDL_RenderGetMetalLayer` doesn't return anything when using `bundled` it works without any features or when using `use_mac_framework` but not with `bundled`

Running on `macOS Mojave` and `rust-sdl2` `0.32.1`

I would much like to have
```toml
[dependencies.sdl2]
version = ""0.32.1""
features = [""bundled"", ""static-link""]
```

But the same issue happens when targeting macOS. 
Using `static-link` alone for `macOS` doesn't seem to work even if `SDL2` is installed via homebrew, the only thing that seem to work is loading it dynamically at runtime from `usr/local/lib`

Also it fails to compile with `cargo build --target aarch64-apple-ios` 
It's related to sdl2-sys build script.","Can you try with 0.32? I think there was a patch about Mojave in 0.32, perhaps it will fix your issue?","I would much like to have
```toml
[dependencies.sdl2]
version = ""0.32.1""
features = [""bundled"", ""static-link""]
```

But the same issue happens when targeting macOS. 

Also it fails to compile with `cargo build --target aarch64-apple-ios` 
It's related to sdl2-sys build script."
Rust-SDL2/rust-sdl2,https://github.com/Rust-SDL2/rust-sdl2/issues/958,Rust-SDL2_rust-sdl2_issues_958,"#947 broke building on x86_64-pc-windows-msvc/i686-pc-windows-msvc with VS2019

```text
[sdl2-sys 0.32.6] SDL_string.obj : error LNK2019: Verweis auf nicht aufgel�stes externes Symbol ""memset"" in Funktion ""SDL_vsnprintf_REAL"". [...\target\x86_64-pc-windows-msvc\debug\build\sdl2-sys-48b20b00f4980a00\out\build\SDL2.vcxproj]
[sdl2-sys 0.32.6] ...\target\x86_64-pc-windows-msvc\debug\build\sdl2-sys-48b20b00f4980a00\out\build\Release\SDL2.dll : fatal error LNK1120: 1 nicht aufgel�ste Externe [...\target\x86_64-pc-windows-msvc\debug\build\sdl2-sys-48b20b00f4980a00\out\build\SDL2.vcxproj]
```",What did it break exactly? What's the error message?,"```text
[sdl2-sys 0.32.6] SDL_string.obj : error LNK2019: Verweis auf nicht aufgel�stes externes Symbol ""memset"" in Funktion ""SDL_vsnprintf_REAL"". [...\target\x86_64-pc-windows-msvc\debug\build\sdl2-sys-48b20b00f4980a00\out\build\SDL2.vcxproj]
[sdl2-sys 0.32.6] ...\target\x86_64-pc-windows-msvc\debug\build\sdl2-sys-48b20b00f4980a00\out\build\Release\SDL2.dll : fatal error LNK1120: 1 nicht aufgel�ste Externe [...\target\x86_64-pc-windows-msvc\debug\build\sdl2-sys-48b20b00f4980a00\out\build\SDL2.vcxproj]
```"
zsh-users/zsh-autosuggestions,https://github.com/zsh-users/zsh-autosuggestions/issues/398,zsh-users_zsh-autosuggestions_issues_398,"Tab not showing hidden directories with globdots enabled

Hi!
After updating to v0.5.0, tab completion doesn't show hidden directories. I tested with v0.4.3 and it works as expected.

Minimal .zshrc:
```
setopt globdots
source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh
```

**Edit: providing more details**
Running:
```
% zsh -f
% source ~/.zshrc
% mkdir test
% mkdir test/visible
% mkdir test/.hidden
% cd test
% cd <press TAB>
```
I get using v0.4.3:
```
% cd (test autosuggested)
.hidden/  visible/
```
I get using v0.5.0:
```
% cd visible/
```
I've tried with these 3 .zshrc, getting the same results for each version:
```
setopt globdots
source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh
```
```
setopt autocd
setopt globdots
source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh
```
```
setopt noautocd
setopt globdots
source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh
```",Can you post an example of what you have typed into the buffer when tab completion fails? This may be a dup of #379.,"**Edit: providing more details**
Running:
```
% zsh -f
% source ~/.zshrc
% mkdir test
% mkdir test/visible
% mkdir test/.hidden
% cd test
% cd <press TAB>
```
I get using v0.4.3:
```
% cd (test autosuggested)
.hidden/  visible/
```
I get using v0.5.0:
```
% cd visible/
```
I've tried with these 3 .zshrc, getting the same results for each version:
```
setopt globdots
source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh
```
```
setopt autocd
setopt globdots
source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh
```
```
setopt noautocd
setopt globdots
source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh
```"
keyboardio/Kaleidoscope,https://github.com/keyboardio/Kaleidoscope/issues/798,keyboardio_Kaleidoscope_issues_798,"Caps lock not in sync with indicator under MacOS Catalina

When pressing the caps lock key on my Model 01, the indicator light on the Mac does not come on (even though caps lock is now on). If the indicator was on, pressing caps lock again does not turn it off (even though caps lock would be off).

OS: MacOS Catalina 10.15.2
Firmware: Chrysalis 0.6.2 default",Can you tell us a bit more about what you're seeing?,"OS: MacOS Catalina 10.15.2
Firmware: Chrysalis 0.6.2 default"
infobyte/faraday,https://github.com/infobyte/faraday/issues/295,infobyte_faraday_issues_295,"Deleted ~/.faraday and now Faraday does not start

I deleted the Kali install's .faraday folder after uninstall it using --purge. I did a clean install for Faraday but when running the server I get the following:

```
2018-10-15 15:24:40,376 - faraday-server.__main__ - ERROR {MainThread} [faraday-server.py:102 - check_postgresql() ]  

Could not connect to PostgreSQL.
Please check: 
  * if database is running 
  * configuration settings are correct. 

For first time installations execute: 

  python manage.py initdb
```

What is the preferred method to reinstall Faraday from scratch? I don't have access to the Postgre database anymore and Ideally I don't want to purge the install of Postegre as other utilities on Kali use that database too.

## Faraday version
3.1.1

## Expected results
I expected all configs to be returned to defaults after purging Faraday from Kali and running a new install of python-faraday 

## Environment information
Kali 2018.2 updated

### Configuration files
The config file is recreated when I run the server for the first time.

### OS

Provide information on your operating system. Example:

$ cat /etc/lsb-release
DISTRIB_ID=Kali
DISTRIB_RELEASE=kali-rolling
DISTRIB_CODENAME=kali-rolling
DISTRIB_DESCRIPTION=""Kali GNU/Linux Rolling""",Did the command returned an error? Can you paste it here?,I don't have access to the Postgre database anymore and Ideally I don't want to purge the install of Postegre as other utilities on Kali use that database too.
OpenLiberty/ci.maven,https://github.com/OpenLiberty/ci.maven/issues/423,OpenLiberty_ci.maven_issues_423,"Maven  3.5.0+ is required

~Should update the readme for to use Maven 3.5.0+ instead of 3.x to build the Liberty plug-ins and archetypes?~

In somewhere, should tell users to use Maven 3.5.0+ to run Liberty maven plug-ins",Did you run into a problem using an earlier version of 3.x? Please provide any additional info you may have.,"~~
In somewhere, should tell users to use Maven 3.5.0+ to run Liberty maven plug-ins"
passff/passff,https://github.com/passff/passff/issues/425,passff_passff_issues_425,"Passff stopped working

### General information. Describe your environment
<!-- Please give as much information as possible, thanks! -->

- Versions
  - Operating system: Ubuntu 18.04
  - Browser: Firefox 70.0.1
  - PassFF: 1.9
  - Host app: newest VERSION=1.2.1
  - `% pass --version v1.7.1`

Status line output: `[hh:mm:ss] show -> (0)`
[18:16:12] ls -> (-1) PassFF failed to execute the host app

---

### Actual behaviour
Not working at all

### Expected behaviour
Working ;)",Why are you using the outdated version 1.7.1 of PassFF?,- `% pass --version v1.7.1`
nmslib/nmslib,https://github.com/nmslib/nmslib/issues/359,nmslib_nmslib_issues_359,"Importing nmslib, cannot load any more object with static TLS

I am getting a dlopen error when importing nmslib after tensorflow:

```
python -c ""import tensorflow; print(tensorflow.contrib); import nmslib""
 File ""<string>"", line 1, in <module>
<module 'tensorflow.contrib' from ...>
ImportError: dlopen: cannot load any more object with static TLS
```

(printing tensorflow contrib simulates importing a module that uses tensorflow, e.g. extending its classes)

switching the order gives no error, and everything works correctly. But in the context of a large code base, it is hard to ensure that nmslib is always imported first, since there are many entry-points. The same thing happens with tensorflow, and it looks similar to this issue: https://stackoverflow.com/questions/50398358/import-error-when-unit-testing-flask-application-with-nmslib

This does not happen on my mac, but only on our Circle CI build, running in a `circleci/python:3.6` docker image. 

Any suggestions for how to fix this?
I have tried setting the env variable `CXXFLAGS=""-fPIC -ftls-model=global-dynamic""` when pip installing nmslib.",does tls-model=global-dynamic help?,"print(tensorflow.contrib); <module 'tensorflow.contrib' from ...>


(printing tensorflow contrib simulates importing a module that uses tensorflow, e.g. extending its classes)"
berrberr/streamkeys,https://github.com/berrberr/streamkeys/issues/517,berrberr_streamkeys_issues_517,"[BUG] Working randomly in ubuntu

The plugin randomly work with ubuntu. 

When not working, ubuntu shows the block warning, that means no player found to play/pause (screenshot)

When i disable and enable the plugin again (and reload the player page) it starts working again...

![image](https://user-images.githubusercontent.com/6114888/58331412-7e4b8b00-7e0f-11e9-9848-91fd64ad213f.png)

## How to reproduce it:
(using an ubuntu with chrome and the extension already installed)

1. Open chorme and open some player such as spotify
2. use the keyboard play/pause button (ubuntu will show the block icon, meaning that there is no player to use it)
3. right click the extension icon > manage extension
4. disable and re-enable the extension
5. refresh the player page and try to use the keyboard play/pause again (it will work)

if you close and open chrome again, the problem returns :cry:",Did you try to bind different keys? If I am not mistaken some operating systems block media keys. Does the popup work?,"## How to reproduce it:
(using an ubuntu with chrome and the extension already installed)

1. Open chorme and open some player such as spotify
2. use the keyboard play/pause button (ubuntu will show the block icon, meaning that there is no player to use it)
3. right click the extension icon > manage extension
4. disable and re-enable the extension
5. refresh the player page and try to use the keyboard play/pause again (it will work)

if you close and open chrome again, the problem returns :cry:"
DIGImend/digimend-kernel-drivers,https://github.com/DIGImend/digimend-kernel-drivers/issues/292,DIGImend_digimend-kernel-drivers_issues_292,"Stopped Working With Huion GT 191

(Edit: Huion KAMVAS GT 191 Works With This Driver!)
Problem has been fixed.

Hello,

I recently bought the Huion KAMVAS GT 191.

I installed this driver and it worked fine for a few hours. The pen was not mapped to the single screen though. I have a multiple screen setup and the pen mapping was stretched between all three screens. I was working on finding a terminal command to make it map to the single screen. If I turned off all my other monitors, It worked great.

A few hours after I installed it, It stopped working. The screen still works like a regular monitor, but the pen isn't working anymore. I plugged the tablet into a different computer and installed the driver, but it did not work.

I am on Linux Mint 19 Cinnamon.

If anyone can help I'd appreciate it. Thanks.","Could you please reconnect your tablet and post the output of `sudo dmesg|tail -n20`, `xinput list` and `xsetwacom list`?","1.

I installed this driver and it worked fine for a few hours. The pen was not mapped to the single screen though. I have a multiple screen setup and the pen mapping was stretched between all three screens. I was working on finding a terminal command to make it map to the single screen. If I turned off all my other monitors, It worked great.

A few hours after I installed it, It stopped working. The screen still works like a regular monitor, but the pen isn't working anymore. I plugged the tablet into a different computer and installed the driver, but it did not work.

I am on Linux Mint 19"
gonum/plot,https://github.com/gonum/plot/issues/481,gonum_plot_issues_481,"imports path

Please, change imports correct paths to `github.com/gonum/plot'` from `gonum.org/v1/plot`  
gonum.org/v1/plot has 404

and problems: 
```
dep init 
```",Maybe this is related to the cert problems we are having with tests?,"and problems: 
```
dep init 
```"
ontop/ontop,https://github.com/ontop/ontop/issues/288,ontop_ontop_issues_288,"Duplicate classes ""org.apache.http.conn.ssl.SSLSocketFactory"" in different JARs, have different implementations, which leads to semantic conflicts

Be similar as issue #287,
 
in **ontop-ontop-3.0.0-beta-2** (**\engine\system\sql\owlapi** module), duplicate classes with the same fully-qualified name _**org.apache.http.conn.ssl.SSLSocketFactory**_ are included in two different libraries, i.e., **org.apache.httpcomponents:httpclient-osgi:4.5.2** and **org.apache.httpcomponents:httpclient:4.2.5**.

Similarly, according to _""first declaration wins""_ class loading strategy, only this class in **_org.apache.httpcomponents:httpclient-osgi:4.5.2_** can be loaded, and that in _**org.apache.httpcomponents:httpclient:4.2.5**_ will be shadowed.

In total, there are **_17 conflicting API pairs_** between these two library version.

For instance, your project expects to invoke method **_<org.apache.http.conn.ssl.SSLSocketFactory: java.net.Socket connectSocket(java.net.Socket,java.net.InetSocketAddress,java.net.InetSocketAddress,org.apache.http.params.HttpParams)>_**  in _**org.apache.httpcomponents:httpclient:4.2.5**_. As it has been shadowed, so that this method defined in **_org.apache.httpcomponents:httpclient-osgi:4.5.2_** is actually forced to be referenced via the following invocation path:
```
<it.unibz.inf.ontop.injection.impl.OntopSQLOWLAPIConfigurationImpl$OntopSQLOWLAPIBuilderMixin: it.unibz.inf.ontop.injection.OntopSQLOWLAPIConfiguration$Builder ontologyFile(java.net.URL)> D:\testcase\TestProject\ontop-ontop-3.0.0-beta-2\engine\system\sql\owlapi\target\classes
<it.unibz.inf.ontop.injection.impl.OntopMappingOntologyBuilders$StandardMappingOntologyBuilderFragment: it.unibz.inf.ontop.injection.OntopMappingOntologyConfiguration$Builder ontologyFile(java.net.URL)> D:\cEnvironment\repository\it\unibz\inf\ontop\ontop-mapping-owlapi\3.0.0-beta-2\ontop-mapping-owlapi-3.0.0-beta-2.jar
<org.apache.http.impl.client.cache.AsynchronousValidationRequest: void run()> D:\cEnvironment\repository\org\apache\httpcomponents\httpclient-cache\4.2.5\httpclient-cache-4.2.5.jar
<org.apache.http.impl.client.cache.CachingHttpClient: org.apache.http.HttpResponse revalidateCacheEntry(org.apache.http.HttpHost,org.apache.http.HttpRequest,org.apache.http.protocol.HttpContext,org.apache.http.client.cache.HttpCacheEntry)> D:\cEnvironment\repository\org\apache\httpcomponents\httpclient-cache\4.2.5\httpclient-cache-4.2.5.jar
<org.apache.http.impl.client.CloseableHttpClient: org.apache.http.HttpResponse execute(org.apache.http.HttpHost,org.apache.http.HttpRequest,org.apache.http.protocol.HttpContext)> 
<org.apache.http.impl.client.CloseableHttpClient: org.apache.http.client.methods.CloseableHttpResponse execute(org.apache.http.HttpHost,org.apache.http.HttpRequest,org.apache.http.protocol.HttpContext)> 
<org.apache.http.impl.client.AbstractHttpClient: org.apache.http.client.methods.CloseableHttpResponse doExecute(org.apache.http.HttpHost,org.apache.http.HttpRequest,org.apache.http.protocol.HttpContext)> 
<org.apache.http.impl.client.DefaultRequestDirector: org.apache.http.HttpResponse execute(org.apache.http.HttpHost,org.apache.http.HttpRequest,org.apache.http.protocol.HttpContext)> 
<org.apache.http.impl.client.DefaultRequestDirector: org.apache.http.HttpResponse tryExecute(org.apache.http.impl.client.RoutedRequest,org.apache.http.protocol.HttpContext)> 
<org.apache.http.impl.conn.ManagedClientConnectionImpl: void open(org.apache.http.conn.routing.HttpRoute,org.apache.http.protocol.HttpContext,org.apache.http.params.HttpParams)> 
<org.apache.http.impl.conn.DefaultClientConnectionOperator: void openConnection(org.apache.http.conn.OperatedClientConnection,org.apache.http.HttpHost,java.net.InetAddress,org.apache.http.protocol.HttpContext,org.apache.http.params.HttpParams)> 
<org.apache.http.conn.ssl.SSLSocketFactory: java.net.Socket connectSocket(java.net.Socket,java.net.InetSocketAddress,java.net.InetSocketAddress,org.apache.http.params.HttpParams)>

```
Although both of these two conflicting classes contain the referenced methods (with the same signature), they have different implementations. This issue will not lead to runtime crashes, but it can introduce inconsistent semantic hehavior by changing the control flows and data flows.

**_Workaround solution:_**
A solution to workaround the problem is **_reversing the declaration order_** of these two libraries in pom file. 

Then, according to **_""first declaration wins""_** class loading strategy, class _**org.apache.http.conn.ssl.SSLSocketFactory**_ in _**org.apache.httpcomponents:httpclient:4.2.5**_ can be loaded (the version that **ontop** expects to reference by static analysis).

**_The detailed informantion of the remaining 16 conflicting API pairs can be found in the following attachment._**
[17 conflicting API pair in project ontop.txt](https://github.com/ontop/ontop/files/4174053/17.conflicting.API.pair.in.project.ontop.txt)


Dependency tree---
[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ ontop-system-sql-owlapi ---
[INFO] it.unibz.inf.ontop:ontop-system-sql-owlapi:jar:3.0.0-beta-2
**....**
[INFO] |  +- it.unibz.inf.ontop:ontop-reformulation-sql:jar:3.0.0-beta-2:compile
[INFO] |  |  \- it.unibz.inf.ontop:ontop-rdb:jar:3.0.0-beta-2:compile
[INFO] |  +- it.unibz.inf.ontop:ontop-mapping-sql-all:jar:3.0.0-beta-2:compile
[INFO] |  |  +- it.unibz.inf.ontop:ontop-mapping-sql-core:jar:3.0.0-beta-2:compile
[INFO] |  |  +- it.unibz.inf.ontop:ontop-mapping-native:jar:3.0.0-beta-2:compile
[INFO] |  |  +- it.unibz.inf.ontop:ontop-mapping-r2rml:jar:3.0.0-beta-2:compile
[INFO] |  |  |  +- org.eclipse.rdf4j:rdf4j-rio-turtle:jar:2.2.2:compile
[INFO] |  |  |  |  +- org.eclipse.rdf4j:rdf4j-rio-datatypes:jar:2.2.2:runtime
[INFO] |  |  |  |  \- org.eclipse.rdf4j:rdf4j-rio-languages:jar:2.2.2:runtime
[INFO] |  |  |  +- eu.optique-project:r2rml-api-core:jar:0.6.0:compile
[INFO] |  |  |  +- eu.optique-project:r2rml-api-rdf4j-binding:jar:0.6.0:compile
[INFO] |  |  |  |  \- org.apache.commons:commons-rdf-rdf4j:jar:0.3.0-incubating:compile
[INFO] |  |  |  |     +- org.apache.commons:commons-rdf-simple:jar:0.3.0-incubating:compile
[INFO] |  |  |  |     +- org.eclipse.rdf4j:rdf4j-repository-api:jar:2.2.2:compile
[INFO] |  |  |  |     +- org.eclipse.rdf4j:rdf4j-rio-ntriples:jar:2.2.2:compile
[INFO] |  |  |  |     +- org.eclipse.rdf4j:rdf4j-rio-nquads:jar:2.1.1:compile
[INFO] |  |  |  |     +- org.eclipse.rdf4j:rdf4j-rio-rdfxml:jar:2.2.2:compile
[INFO] |  |  |  |     +- org.eclipse.rdf4j:rdf4j-rio-trig:jar:2.1.1:compile
[INFO] |  |  |  |     +- org.eclipse.rdf4j:rdf4j-rio-jsonld:jar:2.1.1:compile
[INFO] |  |  |  |     +- org.eclipse.rdf4j:rdf4j-sail-memory:jar:2.1.1:compile
[INFO] |  |  |  |     |  +- org.eclipse.rdf4j:rdf4j-sail-base:jar:2.1.1:compile
[INFO] |  |  |  |     |  +- org.eclipse.rdf4j:rdf4j-sail-inferencer:jar:2.1.1:compile
[INFO] |  |  |  |     |  |  +- org.eclipse.rdf4j:rdf4j-queryparser-serql:jar:2.1.1:runtime
[INFO] |  |  |  |     |  |  \- org.eclipse.rdf4j:rdf4j-sail-model:jar:2.1.1:compile
[INFO] |  |  |  |     |  \- org.eclipse.rdf4j:rdf4j-queryalgebra-evaluation:jar:2.2.2:compile
[INFO] |  |  |  |     |     +- org.eclipse.rdf4j:rdf4j-repository-sparql:jar:2.2.2:compile
[INFO] |  |  |  |     |     |  \- org.eclipse.rdf4j:rdf4j-queryresultio-sparqlxml:jar:2.2.2:compile
[INFO] |  |  |  |     |     \- org.mapdb:mapdb:jar:1.0.8:compile
[INFO] |  |  |  |     \- org.eclipse.rdf4j:rdf4j-repository-sail:jar:2.1.1:compile
[INFO] |  |  |  |        +- org.eclipse.rdf4j:rdf4j-sail-api:jar:2.2.2:compile
[INFO] |  |  |  |        \- org.eclipse.rdf4j:rdf4j-http-client:jar:2.1.1:compile
[INFO] |  |  |  |           +- org.eclipse.rdf4j:rdf4j-http-protocol:jar:2.1.1:compile
[INFO] |  |  |  |           \- org.eclipse.rdf4j:rdf4j-queryresultio-api:jar:2.2.2:compile
[INFO] |  |  |  \- eu.optique-project:r2rml-api-jena-binding:jar:0.6.0:compile
[INFO] |  |  |     +- org.apache.commons:commons-rdf-jena:jar:0.3.0-incubating:compile
[INFO] |  |  |     |  +- org.apache.jena:jena-osgi:jar:3.1.1:compile
[INFO] |  |  |     |  |  +- _**org.apache.httpcomponents:httpclient-osgi:jar:4.5.2:compile**_
[INFO] |  |  |     |  |  +- org.apache.httpcomponents:httpcore-osgi:jar:4.4.4:compile
[INFO] |  |  |     |  |  +- org.apache.commons:commons-csv:jar:1.3:compile
[INFO] |  |  |     |  |  +- org.apache.thrift:libthrift:jar:0.9.3:compile
[INFO] |  |  |     |  |  +- org.apache.commons:commons-lang3:jar:3.4:compile
[INFO] |  |  |     |  |  \- org.osgi:org.osgi.core:jar:6.0.0:compile
[INFO] |  |  |     |  +- org.apache.servicemix.bundles:org.apache.servicemix.bundles.xerces:jar:2.11.0_1:compile
[INFO] |  |  |     |  |  \- xml-apis:xml-apis:jar:1.4.01:compile
[INFO] |  |  |     |  \- com.github.andrewoma.dexx:collection:jar:0.6:compile
[INFO] |  |  |     \- org.apache.jena:jena-core:jar:3.1.1:compile
[INFO] |  |  |        +- org.apache.jena:jena-iri:jar:3.1.1:compile
[INFO] |  |  |        +- xerces:xercesImpl:jar:2.11.0:compile
[INFO] |  |  |        +- commons-cli:commons-cli:jar:1.3:compile
[INFO] |  |  |        \- org.apache.jena:jena-base:jar:3.1.1:compile
[INFO] |  |  |           \- org.apache.jena:jena-shaded-guava:jar:3.1.1:compile
[INFO] |  |  \- com.github.jsqlparser:jsqlparser:jar:1.0:compile
[INFO] |  +- org.apache.tomcat:tomcat-jdbc:jar:9.0.0.M22:compile
[INFO] |  |  \- org.apache.tomcat:tomcat-juli:jar:9.0.0.M22:compile
[INFO] |  \- com.zaxxer:HikariCP:jar:2.6.3:compile
[INFO] +- it.unibz.inf.ontop:ontop-mapping-sql-owlapi:jar:3.0.0-beta-2:compile
[INFO] |  +- it.unibz.inf.ontop:ontop-mapping-owlapi:jar:3.0.0-beta-2:compile
[INFO] |  |  \- it.unibz.inf.ontop:ontop-mapping-core:jar:3.0.0-beta-2:compile
[INFO] |  |     +- org.apache.commons:commons-rdf-api:jar:0.3.0-incubating:compile
[INFO] |  |     \- org.antlr:antlr4-runtime:jar:4.7:compile
[INFO] |  +- net.sourceforge.owlapi:owlapi-api:jar:4.2.8:compile
[INFO] |  |  +- org.tukaani:xz:jar:1.5:compile
[INFO] |  |  +- net.sf.trove4j:trove4j:jar:3.0.3:compile
[INFO] |  |  +- com.google.inject.extensions:guice-multibindings:jar:4.0:compile
[INFO] |  |  \- commons-io:commons-io:jar:2.4:compile
[INFO] |  \- net.sourceforge.owlapi:owlapi-apibinding:jar:4.2.8:compile
[INFO] |     +- net.sourceforge.owlapi:owlapi-impl:jar:4.2.8:compile
[INFO] |     +- net.sourceforge.owlapi:owlapi-parsers:jar:4.2.8:compile
[INFO] |     +- net.sourceforge.owlapi:owlapi-oboformat:jar:4.2.8:compile
[INFO] |     +- net.sourceforge.owlapi:owlapi-tools:jar:4.2.8:compile
[INFO] |     +- net.sourceforge.owlapi:owlapi-fixers:jar:4.2.8:compile
[INFO] |     \- net.sourceforge.owlapi:owlapi-rio:jar:4.2.8:compile
[INFO] |        +- org.openrdf.sesame:sesame-model:jar:2.7.16:compile
[INFO] |        |  \- org.openrdf.sesame:sesame-util:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-api:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-languages:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-datatypes:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-binary:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-n3:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-nquads:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-ntriples:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-rdfjson:jar:2.7.16:compile
[INFO] |        |  \- com.fasterxml.jackson.core:jackson-core:jar:2.2.1:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-rdfxml:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-trix:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-turtle:jar:2.7.16:compile
[INFO] |        +- org.openrdf.sesame:sesame-rio-trig:jar:2.7.16:compile
[INFO] |        +- com.github.jsonld-java:jsonld-java-sesame:jar:0.5.0:compile
[INFO] |        |  \- com.github.jsonld-java:jsonld-java:jar:0.5.0:compile
[INFO] |        |     +- com.fasterxml.jackson.core:jackson-databind:jar:2.3.3:compile
[INFO] |        |     |  \- com.fasterxml.jackson.core:jackson-annotations:jar:2.3.0:compile
[INFO] |        |     +- org.apache.httpcomponents:httpclient-cache:jar:4.2.5:compile
[INFO] |        |     +- _**org.apache.httpcomponents:httpclient:jar:4.2.5:compile**_
[INFO] |        |     |  +- org.apache.httpcomponents:httpcore:jar:4.2.4:compile
[INFO] |        |     |  \- commons-codec:commons-codec:jar:1.6:compile
[INFO] |        |     \- org.slf4j:jcl-over-slf4j:jar:1.7.7:compile
**......**
Thank you very much.
Best,
Coco","Could you have a look at the version3 branch and see similar issues exist?

Btw, how did you find such potential conflicts? Are you using some static code analysis tools?","In total, there are **_17 conflicting etween these two librar**_The detailed informantion of the remaining 16 conflicting API pairs can be found in the following attachment._**
[17 conflicting API pair in project ontop.txt](https://github.com/ontop/ontop/files/4174053/17.conflicting.API.pair.in.project.ontop.txt)"
antlr/intellij-plugin-v4,https://github.com/antlr/intellij-plugin-v4/issues/380,antlr_intellij-plugin-v4_issues_380,"Performance issue in parsing html

Cannot parse the following html 

https://bulbapedia.bulbagarden.net/wiki/Ability#List_of_Abilities

using the html grammar from https://github.com/antlr/grammars-v4/tree/master/html

When I tried to generate the parse tree, the plugin in intellij 2019.03 simply stop responding.

@bjansen",Could you be more specific? What grammar are you using? Do you have any errors (OutOfMemoryException maybe)?,"using the html grammar from https://github.com/antlr/grammars-v4/tree/master/html

When I tried to generate the parse tree, the plugin in intellij 2019.03 simply stop responding.

@bjansen"
pypa/twine,https://github.com/pypa/twine/issues/231,pypa_twine_issues_231,"PEP 484 type annotations for Twine

**Update 4/25/2020**: See https://github.com/pypa/twine/issues/231#issuecomment-619359423 below for the current roadmap to completion.

I am considering adding type annotations to Twine to help my team do static analysis of code that depends on it. Would a pull request containing type annotations be merge back?

More info on type annotations:
    PEP 484: https://www.python.org/dev/peps/pep-0484/
    mypy, the type-checker of choice these days: http://mypy-lang.org/

Given the need to support Python 2.x, the preferred format for annotations would be as Type Comments, but I would be open to do .pyi stubs if that makes it easier for everyone.

Please provide guidance and requirements and I will take it from there.","Would it be acceptable to store them in a separate directory from the source, e.g., `_stubs`?",**Update 4/25/2020**: See https://github.com/pypa/twine/issues/231#issuecomment-619359423 below for the current roadmap to completion.
simbody/simbody,https://github.com/simbody/simbody/issues/653,simbody_simbody_issues_653,"getThisExecutablePath() should check for errors

The original issue was resolved by #672, but another bug was reported in the comments below. I have retitled the issue to reflect the remaining problem.

Original report:
```
        Start  21: TestPlugin
 21/107 Test  #21: TestPlugin .....................................***Failed    0.01 sec
```

FreeBSD 11.2",Can you give the test's log? `ctest -R TestPlugin -V`.,"The original issue was resolved by #672, but another bug was reported in the comments below. I have retitled the issue to reflect the remaining problem.

Original report:"
atom/fuzzy-finder,https://github.com/atom/fuzzy-finder/issues/403,atom_fuzzy-finder_issues_403,"`Fast` scoring doesn't match underscore as path separators on Windows

<!--

Have you read Atom's Code of Conduct? By filing an Issue, you are expected to comply with it, including treating everyone with respect: https://github.com/atom/.github/blob/master/CODE_OF_CONDUCT.md

Do you want to ask a question? Are you looking for support? The Atom message board is the best place for getting support: https://discuss.atom.io

-->

### Prerequisites

* [X] Put an X between the brackets on this line if you have done all of the following:
    * Reproduced the problem in Safe Mode: <https://flight-manual.atom.io/hacking-atom/sections/debugging/#using-safe-mode>
    * Followed all applicable steps in the debugging guide: <https://flight-manual.atom.io/hacking-atom/sections/debugging/>
    * Checked the FAQs on the message board for common solutions: <https://discuss.atom.io/c/faq>
    * Checked that your issue isn't already filed: <https://github.com/issues?utf8=✓&q=is%3Aissue+user%3Aatom>
    * Checked that there is not already an Atom package that provides the described functionality: <https://atom.io/packages>

### Description

(I'm afraid I don't have the version numbers to hand)
When using Fuzzy Finder, I used to be able to just dump my entire class name into it, and it'd split it based on underscores and correctly find the file. For example if my class was `Mob_NPC_Human_Merchant`, and I put my class name into the fuzzy finder, it would bring up the file `Mob/NPC/Human/Merchant.php`, it stopped working when fast mode was enabled, so I disabled it, and now after the most recent update it doesn't work at all anymore. It's been working correctly for over a year.

### Steps to Reproduce

1. Place a file in nested folders
2. Attempt to fuzzy find the file using underscores instead of slashes

*Edit by @rsese to add more detailed repro steps*

Using Git Bash on Windows and with `Settings > Packages > Fuzzy Finder > Scoring System` set to `fast`:

1. `mkdir -p Mob/NPC/Human`
2. `touch Mob/NPC/Human/Merchant.php`
3. `atom .`
4. <kbd>Ctrl+t</kbd>
5. Copy/paste ""Mob_NPC_Human_Merchant""
 
**Expected behavior:**

It brings up ""Mob/NPC/Human/Merchant.php"" as a result of your search.

**Actual behavior:**

It brings up no files at all.

**Reproduces how often:**

Everytime.

### Versions

I'm currently running 1.39.1, it worked before I updated.

### Additional Information

None, if this change is intended I understand, but I hope there is some configuration option that lets me go back to how it used to work, else my main reason for using fuzzy find with my project has kinda gone out the window.",What operating system are you on @JulianHQ?  I'll test on Windows and see if there's any difference there.,"Edit by @rsese to add more detailed repro steps*

Using Git Bash on Windows and with `Settings > Packages > Fuzzy Finder > Scoring System` set to `fast`:

1. `mkdir -p Mob/NPC/Human`
2. `touch Mob/NPC/Human/Merchant.php`
3. `atom .`
4. <kbd>Ctrl+t</kbd>
5. Copy/paste ""Mob_NPC_Human_Merchant""
 
*"
elixir-ecto/postgrex,https://github.com/elixir-ecto/postgrex/issues/446,elixir-ecto_postgrex_issues_446,"GenServer terminating upon start

Hi

I have a running Phoenix app connected to a Postgresql db, which is running fine on my local machine. However, after deploying, I get the following error (4 times):

```
13:56:10.221 [error] GenServer #PID<0.142.0> terminating
** (ArgumentError) unknown registry: Postgrex.TypeManager
    (elixir) lib/registry.ex:1125: Registry.key_info!/1
    (elixir) lib/registry.ex:529: Registry.lookup/2
    (postgrex) lib/postgrex/type_supervisor.ex:29: Postgrex.TypeSupervisor.locate/2
    (postgrex) lib/postgrex/protocol.ex:771: Postgrex.Protocol.bootstrap/3
    (postgrex) lib/postgrex/protocol.ex:576: Postgrex.Protocol.handshake/2
    (db_connection) lib/db_connection/connection.ex:66: DBConnection.Connection.connect/2
    (connection) lib/connection.ex:622: Connection.enter_connect/5
    (stdlib) proc_lib.erl:249: :proc_lib.init_p_do_apply/3
Last message: nil
```

The main difference between my local and online setup is that the former has a postgres server running locally whereas the latter connects to a remote Postgres db. Does the online machine requires something installed before being able to connect to a remote machine?

For now, it is only a basic Debian machine, nothing db-related installed.

Thank you!

FYI:

Remote psql: PostgreSQL 10.6 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9), 64-bit
Elixir 1.7.4
Erlang/OTP 21 [erts-10.2]

Output for `mix deps`:
```
* parse_trans 3.3.0 (Hex package) (rebar3)
  locked at 3.3.0 (parse_trans) 09765507
  ok
* gen_state_machine 2.0.5 (Hex package) (mix)
  locked at 2.0.5 (gen_state_machine) 9ac15ec6
  ok
* base64url 0.0.1 (Hex package) (rebar)
  locked at 0.0.1 (base64url) 36a90125
  ok
* mimerl 1.2.0 (Hex package) (rebar3)
  locked at 1.2.0 (mimerl) 67e2d3f5
  ok
* file_system 0.2.6 (Hex package) (mix)
  locked at 0.2.6 (file_system) fd4dc3af
  ok
* connection 1.0.4 (Hex package) (mix)
  locked at 1.0.4 (connection) a1cae722
  ok
* decorator 1.2.4 (Hex package) (mix)
  locked at 1.2.4 (decorator) 31dfff61
  ok
* nimble_parsec 0.5.0 (Hex package) (mix)
  locked at 0.5.0 (nimble_parsec) 90e2eca3
  ok
* makeup 0.8.0 (Hex package) (mix)
  locked at 0.8.0 (makeup) 9cf32aea
  ok
* metrics 1.0.1 (Hex package) (rebar3)
  locked at 1.0.1 (metrics) 25f094de
  ok
* unicode_util_compat 0.4.1 (Hex package) (rebar3)
  locked at 0.4.1 (unicode_util_compat) d869e4c6
  ok
* idna 6.0.0 (Hex package) (rebar3)
  locked at 6.0.0 (idna) 689c46cb
  ok
* gettext 0.16.1 (Hex package) (mix)
  locked at 0.16.1 (gettext) e2130b25
  ok
* logger_papertrail_backend 1.0.3 (Hex package) (mix)
  locked at 1.0.3 (logger_papertrail_backend) 54950db8
  ok
* gen_stage 0.14.1 (Hex package) (mix)
  locked at 0.14.1 (gen_stage) 9d46723f
  ok
* jose 1.9.0 (Hex package) (mix)
  locked at 1.9.0 (jose) 4167c5f6
  ok
* ranch 1.7.1 (Hex package) (rebar3)
  locked at 1.7.1 (ranch) 6b1fab51
  ok
* telemetry 0.3.0 (Hex package) (rebar3)
  locked at 0.3.0 (telemetry) 099a7f3c
  ok
* decimal 1.7.0 (Hex package) (mix)
  locked at 1.7.0 (decimal) 30d6b52c
  ok
* parallel_stream 1.0.6 (Hex package) (mix)
  locked at 1.0.6 (parallel_stream) b967be2b
  ok
* jason 1.1.2 (Hex package) (mix)
  locked at 1.1.2 (jason) b03dedea
  ok
* poison 3.1.0 (Hex package) (mix)
  locked at 3.1.0 (poison) d9eb6366
  ok
* json_web_token 0.2.10 (Hex package) (mix)
  locked at 0.2.10 (json_web_token) 61041d56
  ok
* ssl_verify_fun 1.1.4 (Hex package) (mix)
  locked at 1.1.4 (ssl_verify_fun) f0eafff8
  ok
* dialyxir 0.5.1 (Hex package) (mix)
  locked at 0.5.1 (dialyxir) b331b091
  ok
* exconstructor 1.1.0 (Hex package) (mix)
  locked at 1.1.0 (exconstructor) 272623a7
  ok
* gen_retry 1.2.0 (Hex package) (mix)
  locked at 1.2.0 (gen_retry) 6ac4411c
  ok
* combine 0.10.0 (Hex package) (mix)
  locked at 0.10.0 (combine) eff8224e
  ok
* csv 2.1.1 (Hex package) (mix)
  locked at 2.1.1 (csv) a4c1a7c3
  ok
* certifi 2.5.1 (Hex package) (rebar3)
  locked at 2.5.1 (certifi) 867ce347
  ok
* hackney 1.15.1 (Hex package) (rebar3)
  locked at 1.15.1 (hackney) 9f8f471c
  ok
* tzdata 0.5.19 (Hex package) (mix)
  locked at 0.5.19 (tzdata) 7962a399
  ok
* timex 3.5.0 (Hex package) (mix)
  locked at 3.5.0 (timex) b0a23167
  ok
* earmark 1.3.1 (Hex package) (mix)
  locked at 1.3.1 (earmark) 73812f44
  ok
* sweet_xml 0.6.6 (Hex package) (mix)
  locked at 0.6.6 (sweet_xml) fc3e91ec
  ok
* ex_aws 2.1.0 (Hex package) (mix)
  locked at 2.1.0 (ex_aws) b9265152
  ok
* ex_aws_s3 2.0.1 (Hex package) (mix)
  locked at 2.0.1 (ex_aws_s3) 9e09366e
  ok
* db_connection 2.0.5 (Hex package) (mix)
  locked at 2.0.5 (db_connection) ddb2ba67
  ok
* httpoison 1.5.0 (Hex package) (mix)
  locked at 1.5.0 (httpoison) 71ae9f30
  ok
* goth 0.8.2 (Hex package) (mix)
  locked at 0.8.2 (goth) edd1359f
  ok
* ecto 3.0.7 (Hex package) (mix)
  locked at 3.0.7 (ecto) 44dda84a
  ok
* crontab 1.1.5 (Hex package) (mix)
  locked at 1.1.5 (crontab) 2c943950
  ok
* makeup_elixir 0.13.0 (Hex package) (mix)
  locked at 0.13.0 (makeup_elixir) be7a4779
  ok
* ex_doc 0.19.3 (Hex package) (mix)
  locked at 0.19.3 (ex_doc) 3c7b0f02
  ok
* phoenix_pubsub 1.1.2 (Hex package) (mix)
  locked at 1.1.2 (phoenix_pubsub) 496c303b
  ok
* oauth2 0.9.4 (Hex package) (mix)
  locked at 0.9.4 (oauth2) 632e8e88
  ok
* cowlib 2.7.0 (Hex package) (rebar3)
  locked at 2.7.0 (cowlib) 3ef16e77
  ok
* cowboy 2.6.1 (Hex package) (rebar3)
  locked at 2.6.1 (cowboy) f2e06f75
  ok
* mime 1.3.1 (Hex package) (mix)
  locked at 1.3.1 (mime) 30ce04ab
  ok
* libring 1.4.0 (Hex package) (mix)
  locked at 1.4.0 (libring) 41246ba2
  ok
* swarm 3.4.0 (Hex package) (mix)
  locked at 3.4.0 (swarm) 64f8b300
  ok
* quantum 2.3.4 (Hex package) (mix)
  locked at 2.3.4 (quantum) 72a0e885
  ok
* postgrex 0.14.1 (Hex package) (mix)
  locked at 0.14.1 (postgrex) 63247d4a
  ok
* ecto_sql 3.0.5 (Hex package) (mix)
  locked at 3.0.5 (ecto_sql) 7e44172b
  ok
* artificery 0.4.1 (Hex package) (mix)
  locked at 0.4.1 (artificery) 90b1fced
  ok
* distillery 2.0.12 (Hex package) (mix)
  locked at 2.0.12 (distillery) 6e78fe04
  ok
* edeliver 1.6.0 (Hex package) (mix)
  locked at 1.6.0 (edeliver) 8bfdde1b
  ok
* plug_crypto 1.0.0 (Hex package) (mix)
  locked at 1.0.0 (plug_crypto) 18e49317
  ok
* plug 1.7.2 (Hex package) (mix)
  locked at 1.7.2 (plug) d7b7db7f
  ok
* bamboo 1.2.0 (Hex package) (mix)
  locked at 1.2.0 (bamboo) 8aebd24f
  ok
* plug_cowboy 2.0.1 (Hex package) (mix)
  locked at 2.0.1 (plug_cowboy) d798f8ee
  ok
* phoenix 1.4.1 (Hex package) (mix)
  locked at 1.4.1 (phoenix) 801f9d63
  ok
* guardian 1.2.1 (Hex package) (mix)
  locked at 1.2.1 (guardian) bdc8dd3d
  ok
* phoenix_live_reload 1.2.0 (Hex package) (mix)
  locked at 1.2.0 (phoenix_live_reload) 3bb31a9f
  ok
* phoenix_html 2.13.1 (Hex package) (mix)
  locked at 2.13.1 (phoenix_html) fa8f034b
  ok
* ueberauth 0.5.0 (Hex package) (mix)
  locked at 0.5.0 (ueberauth) 4570ec94
  ok
* ueberauth_google 0.8.0 (Hex package) (mix)
  locked at 0.8.0 (ueberauth_google) dc0e8417
  ok
* sentry 7.0.4 (Hex package) (mix)
  locked at 7.0.4 (sentry) a9a00b48
  ok
* appsignal 1.9.4 (Hex package) (mix)
  locked at 1.9.4 (appsignal) f4706fe8
  ok
* phoenix_ecto 4.0.0 (Hex package) (mix)
  locked at 4.0.0 (phoenix_ecto) c43117a1
  ok
```

My `mix.exs`:
```
defmodule MyApp.Mixfile do
  use Mix.Project

  def project do
    [
      app: :my_app,
      version: ""2.0.0"",
      elixir: ""~> 1.4"",
      elixirc_paths: elixirc_paths(Mix.env()),
      compilers: [:phoenix, :gettext] ++ Mix.compilers(),
      aliases: aliases(),
      start_permanent: Mix.env() == :prod,
      deps: deps(),
      dialyzer: [plt_add_deps: :transitive]
    ]
  end

  # Configuration for the OTP application.
  #
  # Type `mix help compile.app` for more information.
  def application do
    [
      mod: {MyApp.Application, []},
      extra_applications: [
        :logger,
        :runtime_tools,
        :appsignal,
        :ueberauth,
        :gen_retry,
        :ueberauth_google
      ]
    ]
  end

  # Specifies which paths to compile per environment.
  defp elixirc_paths(:test), do: [""lib"", ""test/support""]
  defp elixirc_paths(_), do: [""lib""]

  # Specifies your project dependencies.
  #
  # Type `mix help deps` for examples and options.
  defp deps do
    [
      {:bamboo, ""~> 1.2.0""},
      {:plug_cowboy, ""~> 2.0""},
      {:plug, ""~> 1.7""},
      {:csv, ""~> 2.1.1""},
      {:dialyxir, ""~> 0.5"", only: [:dev], runtime: false},
      {:distillery, ""~> 2.0.4""},
      {:decimal, ""~> 1.0""},
      {:edeliver, ""~> 1.6""},
      {:ex_machina, ""~> 2.2"", only: :test},
      {:ex_aws, ""~> 2.0""},
      {:ex_aws_s3, ""~> 2.0""},
      {:ecto_sql, ""~> 3.0""},
      {:jason, ""~> 1.1""},
      {:gettext, ""~> 0.16""},
      {:goth, ""~> 0.8.0""},
      {:guardian, ""~> 1.0""},
      {:hackney, ""~> 1.12""},
      {:httpoison, ""~> 1.4""},
      {:ex_doc, ""~> 0.19"", only: :dev, runtime: false},
      {:logger_papertrail_backend, ""~> 1.0""},
      {:phoenix, ""~> 1.4.0""},
      {:phoenix_ecto, ""~> 4.0""},
      {:phoenix_html, ""~> 2.10""},
      {:phoenix_live_reload, ""~> 1.0"", only: :dev},
      {:phoenix_pubsub, ""~> 1.1""},
      {:ueberauth, ""~> 0.3""},
      {:ueberauth_google, ""~> 0.7""},
      {:quantum, ""~> 2.3""},
      {:postgrex, "">= 0.0.0""},
      {:gen_retry, ""~> 1.2.0""},
      {:sentry, ""~> 7.0""},
      {:sweet_xml, ""~> 0.6""},
      {:timex, ""~> 3.5.0""},
      {:appsignal, ""~> 1.9.4""}
    ]
  end

  defp aliases do
    [
      ""ecto.setup"": [""ecto.create"", ""ecto.migrate"", ""run priv/repo/seeds.exs""],
      ""ecto.reset"": [""ecto.drop"", ""ecto.setup""],
    ]
  end
end
```","Can you please include your mix.exs, as well as the output of “mix deps”?
Thanks.
-- 


*José Valim*
www.plataformatec.com.br
Skype: jv.ptec
Founder and Director of R&D","Output for `mix deps`:
```
* parse_trans 3.3.0 (Hex package) (rebar3)
  locked at 3.3.0 (parse_trans) 09765507
  ok
* gen_state_machine 2.0.5 (Hex package) (mix)
  locked at 2.0.5 (gen_state_machine) 9ac15ec6
  ok
* base64url 0.0.1 (Hex package) (rebar)
  locked at 0.0.1 (base64url) 36a90125
  ok
* mimerl 1.2.0 (Hex package) (rebar3)
  locked at 1.2.0 (mimerl) 67e2d3f5
  ok
* file_system 0.2.6 (Hex package) (mix)
  locked at 0.2.6 (file_system) fd4dc3af
  ok
* connection 1.0.4 (Hex package) (mix)
  locked at 1.0.4 (connection) a1cae722
  ok
* decorator 1.2.4 (Hex package) (mix)
  locked at 1.2.4 (decorator) 31dfff61
  ok
* nimble_parsec 0.5.0 (Hex package) (mix)
  locked at 0.5.0 (nimble_parsec) 90e2eca3
  ok
* makeup 0.8.0 (Hex package) (mix)
  locked at 0.8.0 (makeup) 9cf32aea
  ok
* metrics 1.0.1 (Hex package) (rebar3)
  locked at 1.0.1 (metrics) 25f094de
  ok
* unicode_util_compat 0.4.1 (Hex package) (rebar3)
  locked at 0.4.1 (unicode_util_compat) d869e4c6
  ok
* idna 6.0.0 (Hex package) (rebar3)
  locked at 6.0.0 (idna) 689c46cb
  ok
* gettext 0.16.1 (Hex package) (mix)
  locked at 0.16.1 (gettext) e2130b25
  ok
* logger_papertrail_backend 1.0.3 (Hex package) (mix)
  locked at 1.0.3 (logger_papertrail_backend) 54950db8
  ok
* gen_stage 0.14.1 (Hex package) (mix)
  locked at 0.14.1 (gen_stage) 9d46723f
  ok
* jose 1.9.0 (Hex package) (mix)
  locked at 1.9.0 (jose) 4167c5f6
  ok
* ranch 1.7.1 (Hex package) (rebar3)
  locked at 1.7.1 (ranch) 6b1fab51
  ok
* telemetry 0.3.0 (Hex package) (rebar3)
  locked at 0.3.0 (telemetry) 099a7f3c
  ok
* decimal 1.7.0 (Hex package) (mix)
  locked at 1.7.0 (decimal) 30d6b52c
  ok
* parallel_stream 1.0.6 (Hex package) (mix)
  locked at 1.0.6 (parallel_stream) b967be2b
  ok
* jason 1.1.2 (Hex package) (mix)
  locked at 1.1.2 (jason) b03dedea
  ok
* poison 3.1.0 (Hex package) (mix)
  locked at 3.1.0 (poison) d9eb6366
  ok
* json_web_token 0.2.10 (Hex package) (mix)
  locked at 0.2.10 (json_web_token) 61041d56
  ok
* ssl_verify_fun 1.1.4 (Hex package) (mix)
  locked at 1.1.4 (ssl_verify_fun) f0eafff8
  ok
* dialyxir 0.5.1 (Hex package) (mix)
  locked at 0.5.1 (dialyxir) b331b091
  ok
* exconstructor 1.1.0 (Hex package) (mix)
  locked at 1.1.0 (exconstructor) 272623a7
  ok
* gen_retry 1.2.0 (Hex package) (mix)
  locked at 1.2.0 (gen_retry) 6ac4411c
  ok
* combine 0.10.0 (Hex package) (mix)
  locked at 0.10.0 (combine) eff8224e
  ok
* csv 2.1.1 (Hex package) (mix)
  locked at 2.1.1 (csv) a4c1a7c3
  ok
* certifi 2.5.1 (Hex package) (rebar3)
  locked at 2.5.1 (certifi) 867ce347
  ok
* hackney 1.15.1 (Hex package) (rebar3)
  locked at 1.15.1 (hackney) 9f8f471c
  ok
* tzdata 0.5.19 (Hex package) (mix)
  locked at 0.5.19 (tzdata) 7962a399
  ok
* timex 3.5.0 (Hex package) (mix)
  locked at 3.5.0 (timex) b0a23167
  ok
* earmark 1.3.1 (Hex package) (mix)
  locked at 1.3.1 (earmark) 73812f44
  ok
* sweet_xml 0.6.6 (Hex package) (mix)
  locked at 0.6.6 (sweet_xml) fc3e91ec
  ok
* ex_aws 2.1.0 (Hex package) (mix)
  locked at 2.1.0 (ex_aws) b9265152
  ok
* ex_aws_s3 2.0.1 (Hex package) (mix)
  locked at 2.0.1 (ex_aws_s3) 9e09366e
  ok
* db_connection 2.0.5 (Hex package) (mix)
  locked at 2.0.5 (db_connection) ddb2ba67
  ok
* httpoison 1.5.0 (Hex package) (mix)
  locked at 1.5.0 (httpoison) 71ae9f30
  ok
* goth 0.8.2 (Hex package) (mix)
  locked at 0.8.2 (goth) edd1359f
  ok
* ecto 3.0.7 (Hex package) (mix)
  locked at 3.0.7 (ecto) 44dda84a
  ok
* crontab 1.1.5 (Hex package) (mix)
  locked at 1.1.5 (crontab) 2c943950
  ok
* makeup_elixir 0.13.0 (Hex package) (mix)
  locked at 0.13.0 (makeup_elixir) be7a4779
  ok
* ex_doc 0.19.3 (Hex package) (mix)
  locked at 0.19.3 (ex_doc) 3c7b0f02
  ok
* phoenix_pubsub 1.1.2 (Hex package) (mix)
  locked at 1.1.2 (phoenix_pubsub) 496c303b
  ok
* oauth2 0.9.4 (Hex package) (mix)
  locked at 0.9.4 (oauth2) 632e8e88
  ok
* cowlib 2.7.0 (Hex package) (rebar3)
  locked at 2.7.0 (cowlib) 3ef16e77
  ok
* cowboy 2.6.1 (Hex package) (rebar3)
  locked at 2.6.1 (cowboy) f2e06f75
  ok
* mime 1.3.1 (Hex package) (mix)
  locked at 1.3.1 (mime) 30ce04ab
  ok
* libring 1.4.0 (Hex package) (mix)
  locked at 1.4.0 (libring) 41246ba2
  ok
* swarm 3.4.0 (Hex package) (mix)
  locked at 3.4.0 (swarm) 64f8b300
  ok
* quantum 2.3.4 (Hex package) (mix)
  locked at 2.3.4 (quantum) 72a0e885
  ok
* postgrex 0.14.1 (Hex package) (mix)
  locked at 0.14.1 (postgrex) 63247d4a
  ok
* ecto_sql 3.0.5 (Hex package) (mix)
  locked at 3.0.5 (ecto_sql) 7e44172b
  ok
* artificery 0.4.1 (Hex package) (mix)
  locked at 0.4.1 (artificery) 90b1fced
  ok
* distillery 2.0.12 (Hex package) (mix)
  locked at 2.0.12 (distillery) 6e78fe04
  ok
* edeliver 1.6.0 (Hex package) (mix)
  locked at 1.6.0 (edeliver) 8bfdde1b
  ok
* plug_crypto 1.0.0 (Hex package) (mix)
  locked at 1.0.0 (plug_crypto) 18e49317
  ok
* plug 1.7.2 (Hex package) (mix)
  locked at 1.7.2 (plug) d7b7db7f
  ok
* bamboo 1.2.0 (Hex package) (mix)
  locked at 1.2.0 (bamboo) 8aebd24f
  ok
* plug_cowboy 2.0.1 (Hex package) (mix)
  locked at 2.0.1 (plug_cowboy) d798f8ee
  ok
* phoenix 1.4.1 (Hex package) (mix)
  locked at 1.4.1 (phoenix) 801f9d63
  ok
* guardian 1.2.1 (Hex package) (mix)
  locked at 1.2.1 (guardian) bdc8dd3d
  ok
* phoenix_live_reload 1.2.0 (Hex package) (mix)
  locked at 1.2.0 (phoenix_live_reload) 3bb31a9f
  ok
* phoenix_html 2.13.1 (Hex package) (mix)
  locked at 2.13.1 (phoenix_html) fa8f034b
  ok
* ueberauth 0.5.0 (Hex package) (mix)
  locked at 0.5.0 (ueberauth) 4570ec94
  ok
* ueberauth_google 0.8.0 (Hex package) (mix)
  locked at 0.8.0 (ueberauth_google) dc0e8417
  ok
* sentry 7.0.4 (Hex package) (mix)
  locked at 7.0.4 (sentry) a9a00b48
  ok
* appsignal 1.9.4 (Hex package) (mix)
  locked at 1.9.4 (appsignal) f4706fe8
  ok
* phoenix_ecto 4.0.0 (Hex package) (mix)
  locked at 4.0.0 (phoenix_ecto) c43117a1
  ok
```

My `mix.exs`:
```
defmodule MyApp.Mixfile do
  use Mix.Project

  def project do
    [
      app: :my_app,
      version: ""2.0.0"",
      elixir: ""~> 1.4"",
      elixirc_paths: elixirc_paths(Mix.env()),
      compilers: [:phoenix, :gettext] ++ Mix.compilers(),
      aliases: aliases(),
      start_permanent: Mix.env() == :prod,
      deps: deps(),
      dialyzer: [plt_add_deps: :transitive]
    ]
  end

  # Configuration for the OTP application.
  #
  # Type `mix help compile.app` for more information.
  def application do
    [
      mod: {MyApp.Application, []},
      extra_applications: [
        :logger,
        :runtime_tools,
        :appsignal,
        :ueberauth,
        :gen_retry,
        :ueberauth_google
      ]
    ]
  end

  # Specifies which paths to compile per environment.
  defp elixirc_paths(:test), do: [""lib"", ""test/support""]
  defp elixirc_paths(_), do: [""lib""]

  # Specifies your project dependencies.
  #
  # Type `mix help deps` for examples and options.
  defp deps do
    [
      {:bamboo, ""~> 1.2.0""},
      {:plug_cowboy, ""~> 2.0""},
      {:plug, ""~> 1.7""},
      {:csv, ""~> 2.1.1""},
      {:dialyxir, ""~> 0.5"", only: [:dev], runtime: false},
      {:distillery, ""~> 2.0.4""},
      {:decimal, ""~> 1.0""},
      {:edeliver, ""~> 1.6""},
      {:ex_machina, ""~> 2.2"", only: :test},
      {:ex_aws, ""~> 2.0""},
      {:ex_aws_s3, ""~> 2.0""},
      {:ecto_sql, ""~> 3.0""},
      {:jason, ""~> 1.1""},
      {:gettext, ""~> 0.16""},
      {:goth, ""~> 0.8.0""},
      {:guardian, ""~> 1.0""},
      {:hackney, ""~> 1.12""},
      {:httpoison, ""~> 1.4""},
      {:ex_doc, ""~> 0.19"", only: :dev, runtime: false},
      {:logger_papertrail_backend, ""~> 1.0""},
      {:phoenix, ""~> 1.4.0""},
      {:phoenix_ecto, ""~> 4.0""},
      {:phoenix_html, ""~> 2.10""},
      {:phoenix_live_reload, ""~> 1.0"", only: :dev},
      {:phoenix_pubsub, ""~> 1.1""},
      {:ueberauth, ""~> 0.3""},
      {:ueberauth_google, ""~> 0.7""},
      {:quantum, ""~> 2.3""},
      {:postgrex, "">= 0.0.0""},
      {:gen_retry, ""~> 1.2.0""},
      {:sentry, ""~> 7.0""},
      {:sweet_xml, ""~> 0.6""},
      {:timex, ""~> 3.5.0""},
      {:appsignal, ""~> 1.9.4""}
    ]
  end

  defp aliases do
    [
      ""ecto.setup"": [""ecto.create"", ""ecto.migrate"", ""run priv/repo/seeds.exs""],
      ""ecto.reset"": [""ecto.drop"", ""ecto.setup""],
    ]
  end
end
```"
elixir-ecto/postgrex,https://github.com/elixir-ecto/postgrex/issues/493,elixir-ecto_postgrex_issues_493,"Argument Error happening *sometimes* in Docker running tests

This is super strange. Not having this error while running locally or while running releases in Docker. This error happens _sometimes_ (1/4 or so runs) while running tests in docker. Two separate docker containers running Elixir and Postgres.

I thought it may be because Docker is caching so I pruned the docker images between runs and it still fails on the first run sometimes.

The migration runs but fails the first time the code tries to use the DB.

**Edit: Upon further inspection this is happening *every* time but sometimes it will recover and finish running the tests and sometimes it completely fails.

```
14:54:00.712 pid=<0.607.0> [error] GenServer #PID<0.607.0> terminating
** (ArgumentError) unknown registry: Postgrex.TypeManager
    (elixir) lib/registry.ex:1243: Registry.key_info!/1
    (elixir) lib/registry.ex:568: Registry.lookup/2
    (postgrex) lib/postgrex/type_supervisor.ex:29: Postgrex.TypeSupervisor.locate/2
    (postgrex) lib/postgrex/protocol.ex:772: Postgrex.Protocol.bootstrap/3
    (postgrex) lib/postgrex/protocol.ex:577: Postgrex.Protocol.handshake/2
    (db_connection) lib/db_connection/connection.ex:69: DBConnection.Connection.connect/2
    (connection) lib/connection.ex:622: Connection.enter_connect/5
    (stdlib) proc_lib.erl:249: :proc_lib.init_p_do_apply/3
Last message: nil
State: Postgrex.Protocol
** (ArgumentError) argument error
    (stdlib) :ets.lookup_element(Ecto.Repo.Registry, #PID<0.626.0>, 3)
    (ecto) lib/ecto/repo/registry.ex:18: Ecto.Repo.Registry.lookup/1
    (ecto) lib/ecto/repo/queryable.ex:137: Ecto.Repo.Queryable.execute/4
    (gamgee_elixir) lib/gamgee_elixir/db/db_impl/db_impl.ex:43: GamgeeElixir.DBImpl.reset_db/0
    test/test_helper.exs:12: (file)
```
Dockerfile:
```
FROM elixir:1.9.4-alpine

ENV MIX_ENV=test
ENV DATABASE_HOST=**

WORKDIR /opt/app

RUN mix local.rebar --force && \
  mix local.hex --force

COPY . .

RUN mix do deps.get, deps.compile, compile
```

docker-compose.xml:

```
version: ""3.5""

services:
  elixir_test:
    build:
      context: ../
      dockerfile: ./test/Dockerfile
    volumes:
      - ""./log:/opt/app/log""
    depends_on:
      - postgresql
    command: mix test

  postgresql:
    image: postgres:10-alpine
    environment:
      POSTGRES_DB: **
      POSTGRES_USER: **
      POSTGRES_PASSWORD: **
```","Can you please provide an application with the dockerfile that reproduces the error? The more specific you can be, the better. For example:

    $ start_docker_container
    $ curl address_n_times

Thank you!",".

**Edit: Upon further inspection this is happening *every* time but sometimes it will recover and finish running the tests and sometimes it completely fails"
tomopy/tomopy,https://github.com/tomopy/tomopy/issues/423,tomopy_tomopy_issues_423,"Request for x-ray diffraction tomography algorithms

Does `tomopy` implement xray diffraction tomography (XDT) sub-module memtioned at the paper?  I looked at the code roughly but can't find the XDT sub-module.",Which paper are you referring to?,xray diffraction tomography ()
googlemaps/google-maps-ios-utils,https://github.com/googlemaps/google-maps-ios-utils/issues/294,googlemaps_google-maps-ios-utils_issues_294,"This application is modifying the autolayout engine from a background thread

#### Environment details
Google Maps ios utils
iPhone SE iOS 13.4
Library version 3.1.1

#### Description
I have an iOS app that use Google Maps to show a map with different clusters. The crashes after show map an load some markers with this message:

""This application is modifying the autolayout engine from a background thread after the engine was accessed from the main thread. This can lead to engine corruption and weird crashes""

The app crashes without doing anything. Just loading the map with markers and waiting for a few seconds.
If I don't load any markers on the map, this crash don't appear.

I can't find where the UI is been modified from a background thread.

#### Podfile
```
source 'https://github.com/CocoaPods/Specs.git'
platform :ios, '11.0'
use_frameworks!

target 'WatchmanDoor' do

    pod 'DropDown', '2.3.13'
    pod 'GoogleMaps'
    pod 'GooglePlaces'
    pod 'Google-Maps-iOS-Utils', '~> 3.1.1'
    pod 'DKImagePickerController', '4.2.1'
    pod 'Alamofire', '4.9.1'
    pod 'iOSDFULibrary', '4.6.1'
    pod 'RxSwift', '~> 5.0.1'
    pod 'RxCocoa', '~> 5.0.1'
    pod 'Swinject', '~> 2.7.1'
    pod 'SwinjectAutoregistration', '~> 2.7.0'
    pod 'SwinjectStoryboard', '~> 2.2.0'
    pod 'FittedSheets', :git => 'https://github.com/WatchmanDoor/FittedSheets.git', :commit => '9824dd171499967226a4dd160aedc7d4d9db3a11'
    pod 'SDWebImage', '~> 5.5.0'
    pod 'NavigationDrawer', '1.0.2'
    pod 'RealmSwift'

end
```
### Some code snippets

This methods initialise the mapView and clusterManager, and are called from viewDidLoad:

```
private func initMapView() {
        DispatchQueue.main.async {
            self.mapView.isMyLocationEnabled = false
            self.mapView.setMinZoom(4, maxZoom: 20)
            self.mapView.clear()
            self.mapView.isMyLocationEnabled = true
            self.mapView.isBuildingsEnabled = false
            self.mapView.isIndoorEnabled = false
            self.mapView.delegate = self

            self.initClusterManager()
        }
    }

    private func initClusterManager() {
        DispatchQueue.main.async {
            let renderer = GMUDefaultClusterRenderer(mapView: self.mapView,
                                                     clusterIconGenerator: GMUDefaultClusterIconGenerator())
            renderer.delegate = self
            self.clusterManager = GMUClusterManager(map: self.mapView,
                                               algorithm: GMUNonHierarchicalDistanceBasedAlgorithm(),
                                               renderer: renderer)
            self.clusterManager?.setDelegate(self, mapDelegate: self)
        }
    }
```


This is how I load markers into the mapview. It comes from the an observable of a ViewModel:

```
viewModel.outputs.onLoadDone
                .bind { [weak self] mapInfo in
                    guard nil != self else { return }
                    self!.loadMap(mapInfo: mapInfo)
                }

private func loadMap(mapInfo: MapInfoModel) {
        DispatchQueue.main.async {
            self.clusterManager?.clearItems()
            self.clusterManager?.add(mapInfo.clusterList)
            self.clusterManager?.cluster()
        }
    }

class MapInfoModel {

    let assetList: [APIAssetModel]
    let clusterList: [ClusterMarkerItem]
    let path: GMSMutablePath

    init(assetList: [APIAssetModel], clusterList: [ClusterMarkerItem], locationList: [CLLocationCoordinate2D]) {
        self.assetList = assetList
        self.clusterList = clusterList
        self.path = GMSMutablePath()
        
        locationList.forEach { location in
            if CLLocationCoordinate2DIsValid(location) { self.path.add(location) }
        }
    }

}
```

This are the delegate methods:

```
extension GoogleMainMapViewController: GMUClusterManagerDelegate, GMUClusterRendererDelegate, GMSMapViewDelegate {

    func clusterManager(_ clusterManager: GMUClusterManager, didTap cluster: GMUCluster) -> Bool {
        viewModel.inputs.clusterTap.onNext(cluster)

        return true
    }

    func clusterManager(_ clusterManager: GMUClusterManager, didTap clusterItem: GMUClusterItem) -> Bool {
        viewModel.inputs.markerTap.onNext(clusterItem)

        return true
    }

    func renderer(_ renderer: GMUClusterRenderer, willRenderMarker marker: GMSMarker) {
        DispatchQueue.main.async {
            guard marker.userData != nil else { return }

            if marker.userData is GMUCluster {
                self.renderCluster(marker: marker)
            } else {
                self.renderSingleMarker(marker: marker)
            }
        }
    }

    private func renderCluster(marker: GMSMarker) {
        DispatchQueue.main.async {
            if let customView = Bundle.main.loadNibNamed(""CustomClusterIconView"", owner: self, options: nil)?.first as? CustomClusterIconView {
                customView.customInit(items: (marker.userData as! GMUCluster).items.count)
                marker.iconView = customView
            }
        }
    }

    private func renderSingleMarker(marker: GMSMarker) {
        DispatchQueue.main.async {
            if let customView = Bundle.main.loadNibNamed(""CustomClusterIconView"", owner: self, options: nil)?.first as? CustomClusterIconView {
                customView.customInit(items: (marker.userData as? ClusterMarkerItem)?.asset.productsCount ?? 1)
                marker.iconView = customView
            }
        }
    }

} // GMUClusterManagerDelegate, GMUClusterRendererDelegate
```


#### Stack trace
```
Incident Identifier: 34A039F6-9E4A-4E5C-B9B4-AB531A8E8D93
CrashReporter Key:   5f326dac824b350bd2afaacbdb938d680de621bc
Hardware Model:      iPhone8,4
Process:             WatchmanDoor [476]
Path:                /private/var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/WatchmanDoor
Identifier:          com.stmseguridad.WatchmanDoor
Version:             1 (2.0.9)
Code Type:           ARM-64 (Native)
Role:                Foreground
Parent Process:      launchd [1]
Coalition:           com.stmseguridad.WatchmanDoor [625]


Date/Time:           2020-04-16 14:21:00.9449 +0200
Launch Time:         2020-04-16 14:18:12.7530 +0200
OS Version:          iPhone OS 13.4 (17E255)
Release Type:        User
Baseband Version:    9.52.01
Report Version:      104

Exception Type:  EXC_BREAKPOINT (SIGTRAP)
Exception Codes: 0x0000000000000001, 0x00000001a9d2d6e0
Termination Signal: Trace/BPT trap: 5
Termination Reason: Namespace SIGNAL, Code 0x5
Terminating Process: exc handler [476]
Triggered by Thread:  3

Last Exception Backtrace:
0   CoreFoundation                	0x1aa0cc5f0 __exceptionPreprocess + 224
1   libobjc.A.dylib               	0x1a9deebcc objc_exception_throw + 55
2   Foundation                    	0x1aa5a3dac _AssertAutolayoutOnAllowedThreadsOnly + 419
3   Foundation                    	0x1aa3b0c2c -[NSISEngine _optimizeWithoutRebuilding] + 67
4   Foundation                    	0x1aa3b0b48 -[NSISEngine optimize] + 111
5   Foundation                    	0x1aa3b07bc -[NSISEngine performPendingChangeNotifications] + 111
6   UIKitCore                     	0x1ae6132d0 -[UIView+ 15499984 (Hierarchy) layoutSubviews] + 307
7   UIKitCore                     	0x1ae625c7c -[UIView+ 15576188 (CALayerDelegate) layoutSublayersOfLayer:] + 2143
8   QuartzCore                    	0x1b0bbf4ac -[CALayer layoutSublayers] + 283
9   QuartzCore                    	0x1b0bc5604 CA::Layer::layout_if_needed+ 1406468 (CA::Transaction*) + 467
10  QuartzCore                    	0x1b0bd0148 CA::Layer::layout_and_display_if_needed+ 1450312 (CA::Transaction*) + 139
11  QuartzCore                    	0x1b0b18e34 CA::Context::commit_transaction+ 699956 (CA::Transaction*, double) + 295
12  QuartzCore                    	0x1b0b427c4 CA::Transaction::commit+ 870340 () + 675
13  QuartzCore                    	0x1b0b43764 CA::Transaction::release_thread+ 874340 (void*) + 227
14  libsystem_pthread.dylib       	0x1a9de5f8c _pthread_tsd_cleanup + 579
15  libsystem_pthread.dylib       	0x1a9de2df4 _pthread_exit + 79
16  libsystem_pthread.dylib       	0x1a9de3e64 _pthread_wqthread_exit + 95
17  libsystem_pthread.dylib       	0x1a9de3c04 _pthread_wqthread + 415
18  libsystem_pthread.dylib       	0x1a9de6740 start_wqthread + 7


Thread 0 name:  Dispatch queue: com.apple.main-thread
Thread 0:
0   libobjc.A.dylib               	0x00000001a9deab4c objc_msgSend + 44
1   AppleMetalGLRenderer          	0x00000001c4b60624 GLDContextRec::setRenderState+ 54820 (unsigned int) + 84
2   AppleMetalGLRenderer          	0x00000001c4b67084 gldRenderVertexArray+ 82052 (GLDContextRec*, unsigned int, unsigned int, int, int, unsigned int, void const*, int, void const*) + 1108
3   GLEngine                      	0x00000001c4ae3cd0 glDrawElements_ACC_ES2Exec + 416
4   WatchmanDoor                  	0x0000000103a12fcc 0x102c50000 + 14430156
5   WatchmanDoor                  	0x0000000103a17be0 0x102c50000 + 14449632
6   WatchmanDoor                  	0x0000000103ad4bb0 0x102c50000 + 15223728
7   WatchmanDoor                  	0x0000000103a1088c 0x102c50000 + 14420108
8   WatchmanDoor                  	0x0000000103a9ece8 0x102c50000 + 15002856
9   WatchmanDoor                  	0x0000000103a82788 0x102c50000 + 14886792
10  WatchmanDoor                  	0x0000000103acfc5c 0x102c50000 + 15203420
11  WatchmanDoor                  	0x0000000103a80da8 0x102c50000 + 14880168
12  WatchmanDoor                  	0x0000000103a7fc74 0x102c50000 + 14875764
13  QuartzCore                    	0x00000001b0a7f368 CA::Display::DisplayLink::dispatch_items+ 70504 (unsigned long long, unsigned long long, unsigned long long) + 516
14  IOKit                         	0x00000001ab010628 IODispatchCalloutFromCFMessage + 480
15  CoreFoundation                	0x00000001aa021bc0 __CFMachPortPerform + 172
16  CoreFoundation                	0x00000001aa04b200 __CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE1_PERFORM_FUNCTION__ + 56
17  CoreFoundation                	0x00000001aa04a90c __CFRunLoopDoSource1 + 444
18  CoreFoundation                	0x00000001aa0456c0 __CFRunLoopRun + 1888
19  CoreFoundation                	0x00000001aa044c34 CFRunLoopRunSpecific + 424
20  GraphicsServices              	0x00000001b418e38c GSEventRunModal + 160
21  UIKitCore                     	0x00000001ae17722c UIApplicationMain + 1932
22  WatchmanDoor                  	0x000000010360fa9c 0x102c50000 + 10222236
23  libdyld.dylib                 	0x00000001a9ecc800 start + 4

Thread 1 name:  com.apple.uikit.eventfetch-thread
Thread 1:
0   libsystem_kernel.dylib        	0x00000001a9ea0198 mach_msg_trap + 8
1   libsystem_kernel.dylib        	0x00000001a9e9f60c mach_msg + 72
2   CoreFoundation                	0x00000001aa04a3b4 __CFRunLoopServiceMachPort + 148
3   CoreFoundation                	0x00000001aa0453e8 __CFRunLoopRun + 1160
4   CoreFoundation                	0x00000001aa044c34 CFRunLoopRunSpecific + 424
5   Foundation                    	0x00000001aa387bcc -[NSRunLoop+ 31692 (NSRunLoop) runMode:beforeDate:] + 228
6   Foundation                    	0x00000001aa387aac -[NSRunLoop+ 31404 (NSRunLoop) runUntilDate:] + 88
7   UIKitCore                     	0x00000001ae219160 -[UIEventFetcher threadMain] + 152
8   Foundation                    	0x00000001aa4b69d0 __NSThread__start__ + 848
9   libsystem_pthread.dylib       	0x00000001a9de2d98 _pthread_start + 156
10  libsystem_pthread.dylib       	0x00000001a9de674c thread_start + 8

Thread 2:
0   libsystem_pthread.dylib       	0x00000001a9de6738 start_wqthread + 0

Thread 3 Crashed:
0   libsystem_c.dylib             	0x00000001a9d2d6e0 __abort + 144
1   libsystem_c.dylib             	0x00000001a9d2d6e0 __abort + 144
2   libsystem_c.dylib             	0x00000001a9d2d650 __abort + 0
3   libc++abi.dylib               	0x00000001a9e95cc0 __cxxabiv1::__aligned_malloc_with_fallback+ 76992 (unsigned long) + 0
4   libc++abi.dylib               	0x00000001a9e87e10 demangling_unexpected_handler+ 19984 () + 0
5   libobjc.A.dylib               	0x00000001a9deee80 _objc_terminate+ 24192 () + 124
6   libc++abi.dylib               	0x00000001a9e9514c std::__terminate(void (*)+ 74060 ()) + 16
7   libc++abi.dylib               	0x00000001a9e97bd8 __cxa_get_exception_ptr + 0
8   libc++abi.dylib               	0x00000001a9e97b98 __cxxabiv1::exception_cleanup_func+ 84888 (_Unwind_Reason_Code, _Unwind_Exception*) + 0
9   libobjc.A.dylib               	0x00000001a9deecf8 _objc_exception_destructor+ 23800 (void*) + 0
10  Foundation                    	0x00000001aa5a3dac -[NSISEngine tryToOptimizeReturningMutuallyExclusiveConstraints] + 0
11  Foundation                    	0x00000001aa3b0c2c -[NSISEngine _optimizeWithoutRebuilding] + 68
12  Foundation                    	0x00000001aa3b0b48 -[NSISEngine optimize] + 112
13  Foundation                    	0x00000001aa3b07bc -[NSISEngine performPendingChangeNotifications] + 112
14  UIKitCore                     	0x00000001ae6132d0 -[UIView+ 15499984 (Hierarchy) layoutSubviews] + 308
15  UIKitCore                     	0x00000001ae625c7c -[UIView+ 15576188 (CALayerDelegate) layoutSublayersOfLayer:] + 2144
16  QuartzCore                    	0x00000001b0bbf4ac -[CALayer layoutSublayers] + 284
17  QuartzCore                    	0x00000001b0bc5604 CA::Layer::layout_if_needed+ 1406468 (CA::Transaction*) + 468
18  QuartzCore                    	0x00000001b0bd0148 CA::Layer::layout_and_display_if_needed+ 1450312 (CA::Transaction*) + 140
19  QuartzCore                    	0x00000001b0b18e34 CA::Context::commit_transaction+ 699956 (CA::Transaction*, double) + 296
20  QuartzCore                    	0x00000001b0b427c4 CA::Transaction::commit+ 870340 () + 676
21  QuartzCore                    	0x00000001b0b43764 CA::Transaction::release_thread+ 874340 (void*) + 228
22  libsystem_pthread.dylib       	0x00000001a9de5f8c _pthread_tsd_cleanup + 580
23  libsystem_pthread.dylib       	0x00000001a9de2df4 _pthread_exit + 80
24  libsystem_pthread.dylib       	0x00000001a9de3e64 _pthread_wqthread_legacy_worker_wrap + 0
25  libsystem_pthread.dylib       	0x00000001a9de3c04 _pthread_wqthread + 416
26  libsystem_pthread.dylib       	0x00000001a9de6740 start_wqthread + 8

Thread 4 name:  com.apple.NSURLConnectionLoader
Thread 4:
0   libsystem_kernel.dylib        	0x00000001a9ea0198 mach_msg_trap + 8
1   libsystem_kernel.dylib        	0x00000001a9e9f60c mach_msg + 72
2   CoreFoundation                	0x00000001aa04a3b4 __CFRunLoopServiceMachPort + 148
3   CoreFoundation                	0x00000001aa0453e8 __CFRunLoopRun + 1160
4   CoreFoundation                	0x00000001aa044c34 CFRunLoopRunSpecific + 424
5   CFNetwork                     	0x00000001ad309c44 0x1ad308000 + 7236
6   Foundation                    	0x00000001aa4b69d0 __NSThread__start__ + 848
7   libsystem_pthread.dylib       	0x00000001a9de2d98 _pthread_start + 156
8   libsystem_pthread.dylib       	0x00000001a9de674c thread_start + 8

Thread 5 name:  com.google.Maps.LabelingBehavior
Thread 5:
0   libsystem_kernel.dylib        	0x00000001a9ea0198 mach_msg_trap + 8
1   libsystem_kernel.dylib        	0x00000001a9e9f60c mach_msg + 72
2   CoreFoundation                	0x00000001aa04a3b4 __CFRunLoopServiceMachPort + 148
3   CoreFoundation                	0x00000001aa0453e8 __CFRunLoopRun + 1160
4   CoreFoundation                	0x00000001aa044c34 CFRunLoopRunSpecific + 424
5   Foundation                    	0x00000001aa387bcc -[NSRunLoop+ 31692 (NSRunLoop) runMode:beforeDate:] + 228
6   WatchmanDoor                  	0x0000000103b4e330 0x102c50000 + 15721264
7   Foundation                    	0x00000001aa4b69d0 __NSThread__start__ + 848
8   libsystem_pthread.dylib       	0x00000001a9de2d98 _pthread_start + 156
9   libsystem_pthread.dylib       	0x00000001a9de674c thread_start + 8

Thread 6:
0   libsystem_pthread.dylib       	0x00000001a9de6738 start_wqthread + 0

Thread 7:
0   libsystem_pthread.dylib       	0x00000001a9de6738 start_wqthread + 0

Thread 8:
0   libsystem_pthread.dylib       	0x00000001a9de6738 start_wqthread + 0

Thread 3 crashed with ARM Thread State (64-bit):
    x0: 0x0000000000000000   x1: 0x0000000000000000   x2: 0x0000000000000000   x3: 0x0000000000000001
    x4: 0x0000000000000000   x5: 0x0000000000989680   x6: 0x000000000000006e   x7: 0x0000000000000001
    x8: 0x0000000000000000   x9: 0x0000000000000002  x10: 0x000000002daafd89  x11: 0x000000000000000b
   x12: 0x00000001e48ea080  x13: 0x0000000000000000  x14: 0x0000000000000010  x15: 0x0000000000000000
   x16: 0x0000000000000030  x17: 0x00000002d7ffffff  x18: 0x0000000000000000  x19: 0x000000016d57ec48
   x20: 0x00000001f3404c80  x21: 0x000000016d57ed00  x22: 0x0000000169ba05b0  x23: 0x00000001e4b8c000
   x24: 0x0000000000000001  x25: 0x0000000000000068  x26: 0x000000000000009c  x27: 0x0000000000000068
   x28: 0x000000002b310019   fp: 0x000000016d57ec60   lr: 0x00000001a9d2d6e0
    sp: 0x000000016d57ec30   pc: 0x00000001a9d2d6e0 cpsr: 0x80000000
   esr: 0xf2000001  Address size fault

Binary Images:
0x102c50000 - 0x103fbffff WatchmanDoor arm64  <6aa3fbbb03af37a386681ee85fc2c8df> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/WatchmanDoor
0x105540000 - 0x1055fffff CropViewController arm64  <c65d8a8911cd3934818fb5eec6416d7c> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/CropViewController.framework/CropViewController
0x10565c000 - 0x1056d3fff DKCamera arm64  <4dd4e30eb89c3d758dd221dcaa42b43e> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/DKCamera.framework/DKCamera
0x105744000 - 0x10576bfff FLAnimatedImage arm64  <d6f061dc1dd63939aa6071f934be4911> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/FLAnimatedImage.framework/FLAnimatedImage
0x10578c000 - 0x10579ffff NavigationDrawer arm64  <01d869b190c73f8ea7046c1796c97323> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/NavigationDrawer.framework/NavigationDrawer
0x1057dc000 - 0x10583ffff dyld arm64  <23eead922ec9376cbb08574507ab6177> /usr/lib/dyld
0x1058b8000 - 0x105a53fff Alamofire arm64  <d714cfc18e4132298ec5557e344a68ac> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/Alamofire.framework/Alamofire
0x105bb8000 - 0x105d93fff DKImagePickerController arm64  <0aced42a776838f187dd12c3bcb19165> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/DKImagePickerController.framework/DKImagePickerController
0x105f44000 - 0x1060dffff DKPhotoGallery arm64  <36e26c0583613b859923b35801141f07> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/DKPhotoGallery.framework/DKPhotoGallery
0x106238000 - 0x1062affff DropDown arm64  <8cdfb0ccdde93fbb91d3a04ca21d75a4> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/DropDown.framework/DropDown
0x10631c000 - 0x106387fff FittedSheets arm64  <77d1b5269e903f33848b78f392d883e4> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/FittedSheets.framework/FittedSheets
0x106408000 - 0x1072cbfff Realm arm64  <6879e554d804316387d416075dda1ad9> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/Realm.framework/Realm
0x1082d0000 - 0x1083ebfff RealmSwift arm64  <d82b926159013bd8ac060ec8b43e1443> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/RealmSwift.framework/RealmSwift
0x108530000 - 0x10877ffff RxCocoa arm64  <eba90ca9ea463807a2450a2cd5524373> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/RxCocoa.framework/RxCocoa
0x108998000 - 0x1089a7fff RxRelay arm64  <e80717b153b9389cbb758a98af646915> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/RxRelay.framework/RxRelay
0x1089c4000 - 0x108e67fff RxSwift arm64  <a6074055d1e9352fbfc5b0c825d94f91> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/RxSwift.framework/RxSwift
0x1091bc000 - 0x1092effff SDWebImage arm64  <67eb1313fe2a33d790515f93622dfebc> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/SDWebImage.framework/SDWebImage
0x109394000 - 0x1093a3fff SDWebImageFLPlugin arm64  <2e04e72a4dd73ba49d56562eece1530b> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/SDWebImageFLPlugin.framework/SDWebImageFLPlugin
0x1093bc000 - 0x109443fff Swinject arm64  <b26af52063423e919504ce354d0d2316> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/Swinject.framework/Swinject
0x1094b0000 - 0x109687fff SwinjectAutoregistration arm64  <e78da0e394e83675add3c3737027bba0> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/SwinjectAutoregistration.framework/SwinjectAutoregistration
0x1096f4000 - 0x10970bfff SwinjectStoryboard arm64  <547fa60556d03996aaf59908d1c88a9d> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/SwinjectStoryboard.framework/SwinjectStoryboard
0x109730000 - 0x1097c7fff ZIPFoundation arm64  <36a4d7a60a5a33f1a82ff11ac587ad89> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/ZIPFoundation.framework/ZIPFoundation
0x10983c000 - 0x109a17fff iOSDFULibrary arm64  <f55757c5874e3490b10592c7e45b42bd> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/iOSDFULibrary.framework/iOSDFULibrary
0x109c24000 - 0x109c67fff WDCommon arm64  <332890e4938f396ca6e5fa89d990e9d0> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/WDCommon.framework/WDCommon
0x109cd4000 - 0x109cf7fff WDNetwork arm64  <1eba7aad282c3d7bbe3ad7249ce66ca9> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/WDNetwork.framework/WDNetwork
0x109d40000 - 0x109dd3fff WDConnectivity arm64  <867702ad286132898c87fc1195a66a2a> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/WDConnectivity.framework/WDConnectivity
0x109ec8000 - 0x109f4bfff libclang_rt.asan_ios_dynamic.dylib arm64  <8bc18eecf63031e090e3099f9f7160cf> /var/containers/Bundle/Application/717E7E5E-4E42-4950-B8C8-FC2042C09EDC/WatchmanDoor.app/Frameworks/libclang_rt.asan_ios_dynamic.dylib
0x16cfe0000 - 0x16cfebfff libobjc-trampolines.dylib arm64  <2df134bae62230edb227eb9333bfa4d9> /usr/lib/libobjc-trampolines.dylib
0x1a9c71000 - 0x1a9c87fff libsystem_trace.dylib arm64  <f67d8aff28893f9abf166036c3203325> /usr/lib/system/libsystem_trace.dylib
0x1a9c88000 - 0x1a9cb9fff libxpc.dylib arm64  <9e9d069de3b136fa85755e1d9e6b6b54> /usr/lib/system/libxpc.dylib
0x1a9cba000 - 0x1a9cbafff libsystem_blocks.dylib arm64  <0afa438b8355370794f5015ad81f32df> /usr/lib/system/libsystem_blocks.dylib
0x1a9cbb000 - 0x1a9d36fff libsystem_c.dylib arm64  <8d39ff48e14c3f868e1090f54896bb65> /usr/lib/system/libsystem_c.dylib
0x1a9d37000 - 0x1a9dabfff libdispatch.dylib arm64  <5a83d0cf8fb937278a32012d20a47ec8> /usr/lib/system/libdispatch.dylib
0x1a9dac000 - 0x1a9dccfff libsystem_malloc.dylib arm64  <a0a7d67af0f3399a8f006f92716d8e6f> /usr/lib/system/libsystem_malloc.dylib
0x1a9dcd000 - 0x1a9dd7fff libsystem_platform.dylib arm64  <a5d5822c76223859b0c0b869b7e244b5> /usr/lib/system/libsystem_platform.dylib
0x1a9dd8000 - 0x1a9de8fff libsystem_pthread.dylib arm64  <fb1dd49f0cfb3114bdb40ef7be44f6bc> /usr/lib/system/libsystem_pthread.dylib
0x1a9de9000 - 0x1a9e1afff libobjc.A.dylib arm64  <091241f8e94c39ba9ca67352e998bb41> /usr/lib/libobjc.A.dylib
0x1a9e1b000 - 0x1a9e82fff libcorecrypto.dylib arm64  <28c07c08a95635b1b04e88d84542020b> /usr/lib/system/libcorecrypto.dylib
0x1a9e83000 - 0x1a9e9bfff libc++abi.dylib arm64  <f07199ac8a903127b17f0a906ffb7302> /usr/lib/libc++abi.dylib
0x1a9e9c000 - 0x1a9ecafff libsystem_kernel.dylib arm64  <b422ba38a9f63062be28d28d39e3fe25> /usr/lib/system/libsystem_kernel.dylib
0x1a9ecb000 - 0x1a9efdfff libdyld.dylib arm64  <876fb49abfba37bfad376ffc90f7f981> /usr/lib/system/libdyld.dylib
0x1a9efe000 - 0x1a9f06fff libsystem_darwin.dylib arm64  <fc50d2ff80ac31179ff0608fa6cff3a3> /usr/lib/system/libsystem_darwin.dylib
0x1a9f07000 - 0x1a9f60fff libc++.1.dylib arm64  <d7934e7f3eed3c078d1342fe55250c88> /usr/lib/libc++.1.dylib
0x1a9f61000 - 0x1a9fa1fff libsystem_info.dylib arm64  <6a94223de5dc3df6b89780ba56191d92> /usr/lib/system/libsystem_info.dylib
0x1a9fa2000 - 0x1aa315fff CoreFoundation arm64  <409609cd841038e1ba5dbded609d2018> /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation
0x1aa316000 - 0x1aa37ffff SystemConfiguration arm64  <b1f843cc55883c0ba02fc5b80883cc9c> /System/Library/Frameworks/SystemConfiguration.framework/SystemConfiguration
0x1aa380000 - 0x1aa637fff Foundation arm64  <1a46239df2fc34b695bc9f38869f0c85> /System/Library/Frameworks/Foundation.framework/Foundation
0x1aa638000 - 0x1aa66afff libCRFSuite.dylib arm64  <b5116ed3cf69347d85687d2c8d5d76c0> /usr/lib/libCRFSuite.dylib
0x1aa66b000 - 0x1aa7e5fff CoreServices arm64  <43035d98ba1c3d5d972fd61df826fcb3> /System/Library/Frameworks/CoreServices.framework/CoreServices
0x1aa7e6000 - 0x1aa846fff libSparse.dylib arm64  <fd83188d02163838a7c012b81f36e440> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libSparse.dylib
0x1aa847000 - 0x1aad31fff ImageIO arm64  <428fc36a6d0234b5a10cc2cf6f9e0674> /System/Library/Frameworks/ImageIO.framework/ImageIO
0x1aad32000 - 0x1aad34fff ConstantClasses arm64  <07aead6b70b73890b27f7aea1cd02350> /System/Library/PrivateFrameworks/ConstantClasses.framework/ConstantClasses
0x1aad35000 - 0x1aaed3fff CoreText arm64  <3a068b6f533e36b18e9823833c815854> /System/Library/Frameworks/CoreText.framework/CoreText
0x1aaed4000 - 0x1ab009fff Security arm64  <d5a88c36cb0932a6906055bbc4b6817d> /System/Library/Frameworks/Security.framework/Security
0x1ab00a000 - 0x1ab0adfff IOKit arm64  <d138895882be3a12964aa53ca8da1b74> /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit
0x1ab0ae000 - 0x1ab0e5fff libMobileGestalt.dylib arm64  <fe7d38beb09530eca24b70bc964ec273> /usr/lib/libMobileGestalt.dylib
0x1ab0e6000 - 0x1ab142fff libprotobuf.dylib arm64  <027d49d7fea839cda49a4a4fb32c7f6f> /usr/lib/libprotobuf.dylib
0x1ab143000 - 0x1ab154fff libprotobuf-lite.dylib arm64  <2c82919a66fa30a7841320190f2c202d> /usr/lib/libprotobuf-lite.dylib
0x1ab155000 - 0x1ab3a5fff libicucore.A.dylib arm64  <e00735d86bab31f8acbac8fdb01f290e> /usr/lib/libicucore.A.dylib
0x1ab3a6000 - 0x1ab3cffff CoreServicesInternal arm64  <7b6acc45f64532258e2012c49fbcde7a> /System/Library/PrivateFrameworks/CoreServicesInternal.framework/CoreServicesInternal
0x1ab3d0000 - 0x1ab417fff WirelessDiagnostics arm64  <dc60c14089ab3ecb916e94fb63a2ae46> /System/Library/PrivateFrameworks/WirelessDiagnostics.framework/WirelessDiagnostics
0x1ab418000 - 0x1ab451fff libAWDSupport.dylib arm64  <52926ffdcfd0397881e93a4df6893672> /usr/lib/libAWDSupport.dylib
0x1ab452000 - 0x1ab8d6fff CoreAudio arm64  <e467570caf523683bf36ce2594f1c98e> /System/Library/Frameworks/CoreAudio.framework/CoreAudio
0x1ab8d7000 - 0x1abba3fff CoreImage arm64  <4aee50c9e546312ead5d721a6afdb059> /System/Library/Frameworks/CoreImage.framework/CoreImage
0x1abba4000 - 0x1abc92fff LanguageModeling arm64  <1d022988ea363113a096c2f107568542> /System/Library/PrivateFrameworks/LanguageModeling.framework/LanguageModeling
0x1abc93000 - 0x1abcd9fff Lexicon arm64  <9d08273daeac34e78493ff7bff76cab2> /System/Library/PrivateFrameworks/Lexicon.framework/Lexicon
0x1abcda000 - 0x1abe5cfff libsqlite3.dylib arm64  <4fadb9ee56a73afca3604780ddf3411b> /usr/lib/libsqlite3.dylib
0x1abe5d000 - 0x1abe8ffff MobileKeyBag arm64  <6cf66de926bb32089688747ed1dbd888> /System/Library/PrivateFrameworks/MobileKeyBag.framework/MobileKeyBag
0x1abe90000 - 0x1abe99fff libsystem_notify.dylib arm64  <21a918766a2c3f89855046e0f854018a> /usr/lib/system/libsystem_notify.dylib
0x1abe9a000 - 0x1ac07bfff CoreDuet arm64  <5640bda664273303800ed189c16e8049> /System/Library/PrivateFrameworks/CoreDuet.framework/CoreDuet
0x1ac07c000 - 0x1ac1befff Montreal arm64  <69a3d186833f35c5963a43e4d365e897> /System/Library/PrivateFrameworks/Montreal.framework/Montreal
0x1ac1bf000 - 0x1ac2a5fff NLP arm64  <22401c0f186737c295999afaf82b1840> /System/Library/PrivateFrameworks/NLP.framework/NLP
0x1ac2a6000 - 0x1ac2c3fff CellularPlanManager arm64  <c88939c958243367b5401c11b803b8d1> /System/Library/PrivateFrameworks/CellularPlanManager.framework/CellularPlanManager
0x1ac2c4000 - 0x1ac301fff AppSupport arm64  <1731e2fba0303bdbb0cf8b02e5e56ecd> /System/Library/PrivateFrameworks/AppSupport.framework/AppSupport
0x1ac302000 - 0x1ac7d3fff libnetwork.dylib arm64  <cf9b76bf435b38d2aed3fb2c050d9216> /usr/lib/libnetwork.dylib
0x1ac7d4000 - 0x1ac8e0fff ManagedConfiguration arm64  <a40f654260d932528c5ebff3f5575cab> /System/Library/PrivateFrameworks/ManagedConfiguration.framework/ManagedConfiguration
0x1ac8e1000 - 0x1ac90afff CoreServicesStore arm64  <c16b4fad3e753a2e85d67639481e8080> /System/Library/PrivateFrameworks/CoreServicesStore.framework/CoreServicesStore
0x1ac90b000 - 0x1ac92bfff UserManagement arm64  <ad5afd364e75332288e4a3bbcce41b5a> /System/Library/PrivateFrameworks/UserManagement.framework/UserManagement
0x1ac92c000 - 0x1acbe3fff CoreML arm64  <4b1ed9735bef37929aa9775df017a4f2> /System/Library/Frameworks/CoreML.framework/CoreML
0x1acbe4000 - 0x1acbfafff ProtocolBuffer arm64  <4e652067e296363bbfa380eba32585ad> /System/Library/PrivateFrameworks/ProtocolBuffer.framework/ProtocolBuffer
0x1acbfb000 - 0x1acc15fff CommonUtilities arm64  <8c65f3b91e6d322ebeedf8a0e60e717a> /System/Library/PrivateFrameworks/CommonUtilities.framework/CommonUtilities
0x1acc16000 - 0x1acc16fff libenergytrace.dylib arm64  <b9fc54b519c53301bda0c5607f0e7806> /usr/lib/libenergytrace.dylib
0x1acc17000 - 0x1acc4dfff RunningBoardServices arm64  <c78723a9f231370b8944596226f2b836> /System/Library/PrivateFrameworks/RunningBoardServices.framework/RunningBoardServices
0x1acc4e000 - 0x1acccbfff BaseBoard arm64  <33a252545a9730ab9cc7fad0345d4758> /System/Library/PrivateFrameworks/BaseBoard.framework/BaseBoard
0x1acccc000 - 0x1ad221fff SiriTTS arm64  <f4cc905a59803fe5b6283c8d3b2e70c7> /System/Library/PrivateFrameworks/SiriTTS.framework/SiriTTS
0x1ad222000 - 0x1ad294fff CoreLocation arm64  <c8b1e677d38435d38b12bab96c65a426> /System/Library/Frameworks/CoreLocation.framework/CoreLocation
0x1ad2a2000 - 0x1ad2f6fff Accounts arm64  <75940abf4f773731855da69467dbb796> /System/Library/Frameworks/Accounts.framework/Accounts
0x1ad2f7000 - 0x1ad307fff SharedWebCredentials arm64  <1393d99cb36e3c7083e82748f44855b0> /System/Library/PrivateFrameworks/SharedWebCredentials.framework/SharedWebCredentials
0x1ad308000 - 0x1ad66afff CFNetwork arm64  <c4865497192b3dbe81e984a99b788adf> /System/Library/Frameworks/CFNetwork.framework/CFNetwork
0x1ad66b000 - 0x1ad74afff UIFoundation arm64  <5633754447e039efbb34f207fda2553c> /System/Library/PrivateFrameworks/UIFoundation.framework/UIFoundation
0x1ad74b000 - 0x1ae85ffff UIKitCore arm64  <3062ff32218237a2a5f9b38f6fb6b8c3> /System/Library/PrivateFrameworks/UIKitCore.framework/UIKitCore
0x1ae860000 - 0x1ae86dfff AssertionServices arm64  <eff14a5c8feb33c1ac3004921caa2a25> /System/Library/PrivateFrameworks/AssertionServices.framework/AssertionServices
0x1ae86e000 - 0x1ae940fff CoreTelephony arm64  <f04a58a0c439319784c1f4ea154f6363> /System/Library/Frameworks/CoreTelephony.framework/CoreTelephony
0x1ae941000 - 0x1ae946fff AggregateDictionary arm64  <e0ce74236eb13c98bb05186b7f4e3d2b> /System/Library/PrivateFrameworks/AggregateDictionary.framework/AggregateDictionary
0x1ae947000 - 0x1ae95dfff libsystem_asl.dylib arm64  <24190e9ac7db3006b4dfc5e64e85774a> /usr/lib/system/libsystem_asl.dylib
0x1ae95e000 - 0x1ae9d6fff CloudDocs arm64  <c2f43b62730b3b8ba93d6acca741d864> /System/Library/PrivateFrameworks/CloudDocs.framework/CloudDocs
0x1ae9d7000 - 0x1aecfffff CoreData arm64  <a654d396b79c3f469e3fbe9ec0ee1af4> /System/Library/Frameworks/CoreData.framework/CoreData
0x1aed00000 - 0x1aef25fff Vision arm64  <958d82a44f733f0f96350b6f68bd9381> /System/Library/Frameworks/Vision.framework/Vision
0x1aef26000 - 0x1aef68fff PhotoFoundation arm64  <9e49f30ca736349893a9716346e41898> /System/Library/PrivateFrameworks/PhotoFoundation.framework/PhotoFoundation
0x1aef69000 - 0x1aef94fff BoardServices arm64  <728b59e6907e31e5892de5b2c55c48ce> /System/Library/PrivateFrameworks/BoardServices.framework/BoardServices
0x1aef95000 - 0x1af04afff libboringssl.dylib arm64  <e764c033b42637618fe522445b621fcf> /usr/lib/libboringssl.dylib
0x1af04b000 - 0x1af059fff libsystem_networkextension.dylib arm64  <3a3722da76863c2a99c2cce0e3924bf7> /usr/lib/system/libsystem_networkextension.dylib
0x1af05a000 - 0x1af07afff CoreAnalytics arm64  <85843ee0a89b3316a3e68531eba75336> /System/Library/PrivateFrameworks/CoreAnalytics.framework/CoreAnalytics
0x1af07b000 - 0x1af1ebfff CloudKit arm64  <d54d14692ec130d7b5af5f852438dc3e> /System/Library/Frameworks/CloudKit.framework/CloudKit
0x1af1ec000 - 0x1af239fff SpringBoardServices arm64  <50878840805636d7bff4a6aa6d6cdfa9> /System/Library/PrivateFrameworks/SpringBoardServices.framework/SpringBoardServices
0x1af23a000 - 0x1af2acfff FrontBoardServices arm64  <ca8e712fa22732ae842b65567f6046bb> /System/Library/PrivateFrameworks/FrontBoardServices.framework/FrontBoardServices
0x1af2ad000 - 0x1af3d4fff Network arm64  <38a032852b86333e95c553eb41e5d3e5> /System/Library/Frameworks/Network.framework/Network
0x1af3d5000 - 0x1af431fff libusrtcp.dylib arm64  <10fe0faf8a4d3bcfbc43e8a951656957> /usr/lib/libusrtcp.dylib
0x1af432000 - 0x1af439fff libsystem_symptoms.dylib arm64  <a0e89bc6db7f3c578468bdc9ae67fdcb> /usr/lib/system/libsystem_symptoms.dylib
0x1af43a000 - 0x1b0324fff GeoServices arm64  <d2fc5b30d98a352d952013a5b60a073b> /System/Library/PrivateFrameworks/GeoServices.framework/GeoServices
0x1b0325000 - 0x1b032dfff TCC arm64  <e8eb1bfdf24d34f2a53b5d0700632050> /System/Library/PrivateFrameworks/TCC.framework/TCC
0x1b032e000 - 0x1b0387fff IMFoundation arm64  <b2d85b147b823944beebc644d365b564> /System/Library/PrivateFrameworks/IMFoundation.framework/IMFoundation
0x1b0388000 - 0x1b04fbfff CoreUtils arm64  <b642c3a48cdc3b1aba6d651b7e00d61c> /System/Library/PrivateFrameworks/CoreUtils.framework/CoreUtils
0x1b04fc000 - 0x1b05adfff IMSharedUtilities arm64  <7e3c3dc898663d13b83dffaa5a1170a5> /System/Library/PrivateFrameworks/IMSharedUtilities.framework/IMSharedUtilities
0x1b05ae000 - 0x1b05e3fff ImageCaptureCore arm64  <99700767f48d36cb8ccb1d9e33962eda> /System/Library/Frameworks/ImageCaptureCore.framework/ImageCaptureCore
0x1b05e4000 - 0x1b05edfff libsystem_containermanager.dylib arm64  <4764ee5a2f0a3fbb8a756f60f0e02cd8> /usr/lib/system/libsystem_containermanager.dylib
0x1b05ee000 - 0x1b0669fff AppleAccount arm64  <972cea5083b43105b83f737be8ad7a43> /System/Library/PrivateFrameworks/AppleAccount.framework/AppleAccount
0x1b066a000 - 0x1b0684fff ApplePushService arm64  <61a7d33046ff3eec8d22ddd488a37581> /System/Library/PrivateFrameworks/ApplePushService.framework/ApplePushService
0x1b0685000 - 0x1b076dfff IDS arm64  <cf2b018761f736d4a1dfad15aa703c85> /System/Library/PrivateFrameworks/IDS.framework/IDS
0x1b076e000 - 0x1b0898fff IDSFoundation arm64  <a6bd395156ff3624b78997bb3ed24a06> /System/Library/PrivateFrameworks/IDSFoundation.framework/IDSFoundation
0x1b0899000 - 0x1b089afff libCTGreenTeaLogger.dylib arm64  <2ab5f36320803bda84913992c492743e> /usr/lib/libCTGreenTeaLogger.dylib
0x1b08ff000 - 0x1b09fffff CoreMedia arm64  <b9bf44cd041a37af8879451f66687468> /System/Library/Frameworks/CoreMedia.framework/CoreMedia
0x1b0a00000 - 0x1b0a0ffff UIKitServices arm64  <0eeb42c795483dba82a142eeda85503e> /System/Library/PrivateFrameworks/UIKitServices.framework/UIKitServices
0x1b0a10000 - 0x1b0a6dfff BackBoardServices arm64  <6f0540d2fedc308eacff631bff19cd69> /System/Library/PrivateFrameworks/BackBoardServices.framework/BackBoardServices
0x1b0a6e000 - 0x1b0cbffff QuartzCore arm64  <ba9eccee9f613baab8a88eb3b7e0a24f> /System/Library/Frameworks/QuartzCore.framework/QuartzCore
0x1b0cc0000 - 0x1b0d87fff ColorSync arm64  <503c108270703f1786df14588e7f9ff7> /System/Library/PrivateFrameworks/ColorSync.framework/ColorSync
0x1b0d88000 - 0x1b12f7fff CoreGraphics arm64  <e068b7652d603d90aba30df6da3578bc> /System/Library/Frameworks/CoreGraphics.framework/CoreGraphics
0x1b12f8000 - 0x1b1427fff Contacts arm64  <18807e6ef924349a9384161c92390665> /System/Library/Frameworks/Contacts.framework/Contacts
0x1b1428000 - 0x1b1456fff UserNotifications arm64  <44b07041e9723af2a6446a04bc8588a7> /System/Library/Frameworks/UserNotifications.framework/UserNotifications
0x1b1457000 - 0x1b147afff LocationSupport arm64  <470b39d55daf3170b1a38841292d494d> /System/Library/PrivateFrameworks/LocationSupport.framework/LocationSupport
0x1b147b000 - 0x1b15d6fff Sharing arm64  <34759ac26e85385f9cca89d83469028d> /System/Library/PrivateFrameworks/Sharing.framework/Sharing
0x1b15d7000 - 0x1b1c16fff WebKit arm64  <0d71fc8cc7e331948094d1c767c7bc09> /System/Library/Frameworks/WebKit.framework/WebKit
0x1b1c17000 - 0x1b39cbfff WebCore arm64  <fbf9a3b9df503629af395c41d3e4e83a> /System/Library/PrivateFrameworks/WebCore.framework/WebCore
0x1b39cc000 - 0x1b39e6fff libAccessibility.dylib arm64  <f55983edebf933948322efaefe1ecbca> /usr/lib/libAccessibility.dylib
0x1b39e7000 - 0x1b39f2fff AXCoreUtilities arm64  <c9ced073466a32208dbabf96d0a50f15> /System/Library/PrivateFrameworks/AXCoreUtilities.framework/AXCoreUtilities
0x1b39f3000 - 0x1b3a66fff ContactsFoundation arm64  <0ba958ac9959337ca4d72b34bd2d50aa> /System/Library/PrivateFrameworks/ContactsFoundation.framework/ContactsFoundation
0x1b3a67000 - 0x1b3a7bfff PowerLog arm64  <eec0214c57da38818a8622fde679829c> /System/Library/PrivateFrameworks/PowerLog.framework/PowerLog
0x1b3a7c000 - 0x1b3a8dfff IOSurface arm64  <4abf1719833c3f8db61863ff9b392891> /System/Library/Frameworks/IOSurface.framework/IOSurface
0x1b3a8e000 - 0x1b418afff MediaToolbox arm64  <bce0f04fbe4d3f55bce62184be284bfd> /System/Library/Frameworks/MediaToolbox.framework/MediaToolbox
0x1b418b000 - 0x1b4193fff GraphicsServices arm64  <aea26bf9483739a29902950b92b52592> /System/Library/PrivateFrameworks/GraphicsServices.framework/GraphicsServices
0x1b427c000 - 0x1b4474fff AVFoundation arm64  <20bfceb457453bd2a5b3ce71ea50c1b2> /System/Library/Frameworks/AVFoundation.framework/AVFoundation
0x1b4475000 - 0x1b44acfff OnBoardingKit arm64  <e2e88272c1933ba4b9f2245bc7dba1e1> /System/Library/PrivateFrameworks/OnBoardingKit.framework/OnBoardingKit
0x1b44ad000 - 0x1b44fbfff MobileWiFi arm64  <3e4f5fc8825839f084694f7c77d62907> /System/Library/PrivateFrameworks/MobileWiFi.framework/MobileWiFi
0x1b44fc000 - 0x1b4514fff MobileAsset arm64  <9a597efb899f383a867473d91b06eb94> /System/Library/PrivateFrameworks/MobileAsset.framework/MobileAsset
0x1b4515000 - 0x1b4522fff libGSFont.dylib arm64  <59fe7a3b9b8437a7a992bdae0faab9d6> /System/Library/PrivateFrameworks/FontServices.framework/libGSFont.dylib
0x1b4523000 - 0x1b452cfff FontServices arm64  <2b26f3985f9030d39a40bfe0df98686b> /System/Library/PrivateFrameworks/FontServices.framework/FontServices
0x1b452d000 - 0x1b4676fff libFontParser.dylib arm64  <cac8dc5601323efd9875a5e886d92ea8> /System/Library/PrivateFrameworks/FontServices.framework/libFontParser.dylib
0x1b46c6000 - 0x1b47fffff SearchFoundation arm64  <e91f6d1fcdd23a1595d49b7ed678ec0a> /System/Library/PrivateFrameworks/SearchFoundation.framework/SearchFoundation
0x1b4800000 - 0x1b491efff Preferences arm64  <9cb3558569ea3b2c8a520db57aba8688> /System/Library/PrivateFrameworks/Preferences.framework/Preferences
0x1b491f000 - 0x1b4f8dfff PhotoLibraryServices arm64  <7e2dec0b4e49338fb908b97df773b12a> /System/Library/PrivateFrameworks/PhotoLibraryServices.framework/PhotoLibraryServices
0x1b4f8e000 - 0x1b51f2fff vImage arm64  <1987440ca5e638368a23cd7341b1932a> /System/Library/Frameworks/Accelerate.framework/Frameworks/vImage.framework/vImage
0x1b51f3000 - 0x1b5427fff AudioToolbox arm64  <9eea0978fcad33cc9e3035ea939b2143> /System/Library/Frameworks/AudioToolbox.framework/AudioToolbox
0x1b5428000 - 0x1b545afff libAudioToolboxUtility.dylib arm64  <5e0ec0bf47f03853a777ea0123cdecaa> /usr/lib/libAudioToolboxUtility.dylib
0x1b545b000 - 0x1b5617fff ContactsUI arm64  <f9dc4b6c059f37809b709240dcc469ac> /System/Library/Frameworks/ContactsUI.framework/ContactsUI
0x1b5682000 - 0x1b5886fff Photos arm64  <beb29988134830ce91e9ba3af86440a0> /System/Library/Frameworks/Photos.framework/Photos
0x1b5887000 - 0x1b591bfff ShareSheet arm64  <0e75ee0b6aeb34c69e1403fe2a0b602a> /System/Library/PrivateFrameworks/ShareSheet.framework/ShareSheet
0x1b5930000 - 0x1b59e4fff PDFKit arm64  <d8c1fee5d77635d895bbd3b646f269fc> /System/Library/Frameworks/PDFKit.framework/PDFKit
0x1b5a62000 - 0x1b5a8ffff DocumentManager arm64  <df6155e3a82c3b98aad02755b34ffac2> /System/Library/PrivateFrameworks/DocumentManager.framework/DocumentManager
0x1b5ceb000 - 0x1b5d62fff AuthKit arm64  <2fda46a0c0c03b0e8222936e5ef11f24> /System/Library/PrivateFrameworks/AuthKit.framework/AuthKit
0x1b5d63000 - 0x1b617ffff Intents arm64  <4c28f731a5bf380abec95b89347dcca6> /System/Library/Frameworks/Intents.framework/Intents
0x1b6180000 - 0x1b6194fff libCGInterfaces.dylib arm64  <e2a730f6b7b63f2aa3be0ed27cf3cab5> /System/Library/Frameworks/Accelerate.framework/Frameworks/vImage.framework/Libraries/libCGInterfaces.dylib
0x1b6195000 - 0x1b62f4fff WebKitLegacy arm64  <dd6cd4bf7b9535ea92c9c5d914af546b> /System/Library/PrivateFrameworks/WebKitLegacy.framework/WebKitLegacy
0x1b62f5000 - 0x1b635ffff TextInput arm64  <982b9b2cc64d3667aeb3863f355e5f6f> /System/Library/PrivateFrameworks/TextInput.framework/TextInput
0x1b63db000 - 0x1b63defff XCTTargetBootstrap arm64  <5c185207156334bcbfddbae1d7470d2b> /System/Library/PrivateFrameworks/XCTTargetBootstrap.framework/XCTTargetBootstrap
0x1b63df000 - 0x1b6493fff CorePDF arm64  <4068ec815d3438b59ad58c2ae7167ef4> /System/Library/PrivateFrameworks/CorePDF.framework/CorePDF
0x1b64cf000 - 0x1b6880fff MediaPlayer arm64  <2730d66693cf3968b472685e5323ea96> /System/Library/Frameworks/MediaPlayer.framework/MediaPlayer
0x1b6881000 - 0x1b6b98fff AppleMediaServices arm64  <bfd95f83910f387e9876e28ebdd4dd57> /System/Library/PrivateFrameworks/AppleMediaServices.framework/AppleMediaServices
0x1b6b99000 - 0x1b6bbffff CacheDelete arm64  <0c48aade3fe43589acc552d3e119c591> /System/Library/PrivateFrameworks/CacheDelete.framework/CacheDelete
0x1b6bc0000 - 0x1b6d87fff CoreMotion arm64  <70ed3ef1d8263d55b5eae657ac5e8057> /System/Library/Frameworks/CoreMotion.framework/CoreMotion
0x1b6d88000 - 0x1b6e75fff AVFAudio arm64  <1df3312395353945983fb139a4216fa9> /System/Library/Frameworks/AVFoundation.framework/Frameworks/AVFAudio.framework/AVFAudio
0x1b6e76000 - 0x1b7092fff RawCamera arm64  <1bf4eb4c14f636da870cb1a1b23a7e77> /System/Library/CoreServices/RawCamera.bundle/RawCamera
0x1b7093000 - 0x1b7149fff CoreUI arm64  <d90479e8d57435b1a4cbab0423d21770> /System/Library/PrivateFrameworks/CoreUI.framework/CoreUI
0x1b714a000 - 0x1b716efff AppSupportUI arm64  <7264f3b8500e30b0ad4e3f00500d64bd> /System/Library/PrivateFrameworks/AppSupportUI.framework/AppSupportUI
0x1b716f000 - 0x1b71a4fff CoreVideo arm64  <443ef021c4123a32a3970433993d16fe> /System/Library/Frameworks/CoreVideo.framework/CoreVideo
0x1b71a5000 - 0x1b73dbfff AudioToolboxCore arm64  <5cc99c07d3b3317aa0aa90b7edb05d00> /System/Library/PrivateFrameworks/AudioToolboxCore.framework/AudioToolboxCore
0x1b73dc000 - 0x1b741ffff CoreDuetContext arm64  <badc9da39c60341aa29c34542cb16158> /System/Library/PrivateFrameworks/CoreDuetContext.framework/CoreDuetContext
0x1b7420000 - 0x1b745afff SetupAssistant arm64  <3f5a75d178773381875c6c41678d79e1> /System/Library/PrivateFrameworks/SetupAssistant.framework/SetupAssistant
0x1b745b000 - 0x1b7517fff TelephonyUtilities arm64  <5c63d78ffe1433738deae30f6c98838d> /System/Library/PrivateFrameworks/TelephonyUtilities.framework/TelephonyUtilities
0x1b7518000 - 0x1b7542fff PlugInKit arm64  <5d4ad58191a23317a0d2ee6357784767> /System/Library/PrivateFrameworks/PlugInKit.framework/PlugInKit
0x1b7543000 - 0x1b78c5fff libswiftCore.dylib arm64  <dcbc2d499c313dbebcf3b0f5205f87fe> /usr/lib/swift/libswiftCore.dylib
0x1b78c6000 - 0x1b7a01fff AssistantServices arm64  <a8b7086d107935e5a99f4496e472e170> /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
0x1b7a02000 - 0x1b7a61fff ProactiveSupport arm64  <f139ee3c405538eb8b0e3157dfeb850b> /System/Library/PrivateFrameworks/ProactiveSupport.framework/ProactiveSupport
0x1b7a62000 - 0x1b7ca4fff MapKit arm64  <7029e175072a3830a8d7e0402b5e3436> /System/Library/Frameworks/MapKit.framework/MapKit
0x1b7ca5000 - 0x1b7cc1fff PrototypeTools arm64  <cc8e1d9d10a23e8785900518b23242dd> /System/Library/PrivateFrameworks/PrototypeTools.framework/PrototypeTools
0x1b7cc2000 - 0x1b7db3fff MediaExperience arm64  <d3696f197c97386d855765ea3931bdea> /System/Library/PrivateFrameworks/MediaExperience.framework/MediaExperience
0x1b7db4000 - 0x1b8088fff Celestial arm64  <f23ff8ceade230c2946daf42793d76ab> /System/Library/PrivateFrameworks/Celestial.framework/Celestial
0x1b8089000 - 0x1b80e5fff CallKit arm64  <43fdc2704c013b87a03e8d080c082b83> /System/Library/Frameworks/CallKit.framework/CallKit
0x1b82ab000 - 0x1b89a1fff VectorKit arm64  <5655a0aafafb3c3d8b69a2ef8e8e2146> /System/Library/PrivateFrameworks/VectorKit.framework/VectorKit
0x1b89a2000 - 0x1b8a71fff AVKit arm64  <2afc669447223d058ee6c706b54cbb35> /System/Library/Frameworks/AVKit.framework/AVKit
0x1b8a72000 - 0x1b8aa0fff Pegasus arm64  <8b990cff02533a6782f88bd0831837f4> /System/Library/PrivateFrameworks/Pegasus.framework/Pegasus
0x1b8aa1000 - 0x1b8aa3fff libapp_launch_measurement.dylib arm64  <2741e56c89873a20acde4979ee28be22> /usr/lib/libapp_launch_measurement.dylib
0x1b8ab9000 - 0x1b8b1bfff CoreSpotlight arm64  <73ad186f492c3a338c9f3cea760b172f> /System/Library/Frameworks/CoreSpotlight.framework/CoreSpotlight
0x1b8b1c000 - 0x1b8bb3fff AddressBookLegacy arm64  <e45307d41ffb3a969616fe7e59195de2> /System/Library/PrivateFrameworks/AddressBookLegacy.framework/AddressBookLegacy
0x1b8bb4000 - 0x1b8bc3fff CrashReporterSupport arm64  <8f50c9095b293180a908ffdbdeecede3> /System/Library/PrivateFrameworks/CrashReporterSupport.framework/CrashReporterSupport
0x1b8bc4000 - 0x1b8bd6fff MobileBluetooth arm64  <6c5b5fd25a743a74b69bc8e8fe200b70> /System/Library/PrivateFrameworks/MobileBluetooth.framework/MobileBluetooth
0x1b8bd7000 - 0x1b8c90fff LinkPresentation arm64  <652903c4cccb3fb38ef4495e900b809b> /System/Library/Frameworks/LinkPresentation.framework/LinkPresentation
0x1b8cc9000 - 0x1b8ccdfff libsystem_configuration.dylib arm64  <1f77794460993bc0a06207f2193781f6> /usr/lib/system/libsystem_configuration.dylib
0x1b8cce000 - 0x1b8d28fff RemoteUI arm64  <2f684cc557103242b20baf988113cb51> /System/Library/PrivateFrameworks/RemoteUI.framework/RemoteUI
0x1b8d29000 - 0x1b8d7efff AuthKitUI arm64  <629ab78d4fc83ddfb4d6a2126d3215f5> /System/Library/PrivateFrameworks/AuthKitUI.framework/AuthKitUI
0x1b8d7f000 - 0x1b8de4fff CoreRecognition arm64  <2ebd686e061537b7a7b8e68085e0fba0> /System/Library/PrivateFrameworks/CoreRecognition.framework/CoreRecognition
0x1b8de5000 - 0x1b8e67fff Social arm64  <286389b70f603f62ad78a0c38377938f> /System/Library/Frameworks/Social.framework/Social
0x1b8eb5000 - 0x1b8ec3fff HangTracer arm64  <f7cd6e3068023cb8b89cfb387970d104> /System/Library/PrivateFrameworks/HangTracer.framework/HangTracer
0x1b8ec4000 - 0x1b8f29fff CoreNLP arm64  <bc2c4aea12293a0fab1f92fc80182f74> /System/Library/PrivateFrameworks/CoreNLP.framework/CoreNLP
0x1b8f2a000 - 0x1b8f2bfff liblangid.dylib arm64  <e1c11f41cd7031148ffeb431b53b9fdd> /usr/lib/liblangid.dylib
0x1b8f2c000 - 0x1b9db7fff JavaScriptCore arm64  <aaf4e988dfd33f50af21779cf1258c80> /System/Library/Frameworks/JavaScriptCore.framework/JavaScriptCore
0x1b9db8000 - 0x1b9e45fff libTelephonyUtilDynamic.dylib arm64  <a187f39512fe32d99a85829691a49f64> /usr/lib/libTelephonyUtilDynamic.dylib
0x1b9e5a000 - 0x1ba0d8fff StoreServices arm64  <ec2375561d7b3b6aad035307560492cd> /System/Library/PrivateFrameworks/StoreServices.framework/StoreServices
0x1ba0d9000 - 0x1ba0e2fff IOMobileFramebuffer arm64  <7462439e125833758ae73bd083b45ae2> /System/Library/PrivateFrameworks/IOMobileFramebuffer.framework/IOMobileFramebuffer
0x1ba0e3000 - 0x1ba26afff SafariServices arm64  <140f2dc426773ad0a53b9091cc230645> /System/Library/Frameworks/SafariServices.framework/SafariServices
0x1ba45a000 - 0x1ba474fff CoreMaterial arm64  <0c57d0346b8038ac99da29d1c5756073> /System/Library/PrivateFrameworks/CoreMaterial.framework/CoreMaterial
0x1ba475000 - 0x1ba55afff libxml2.2.dylib arm64  <59363b79c5c93f4a8225d4514922256a> /usr/lib/libxml2.2.dylib
0x1bbdc9000 - 0x1bbe11fff MetadataUtilities arm64  <a6b4a006922d31b3a175503669bc8e3c> /System/Library/PrivateFrameworks/MetadataUtilities.framework/MetadataUtilities
0x1bbe12000 - 0x1bbe6afff UserActivity arm64  <5cee49c805f930de8cad926a2d5d9417> /System/Library/PrivateFrameworks/UserActivity.framework/UserActivity
0x1bc79b000 - 0x1bc9acfff NetworkExtension arm64  <b9952b5daeb134a6b570a193e0440119> /System/Library/Frameworks/NetworkExtension.framework/NetworkExtension
0x1bc9ad000 - 0x1bc9e2fff DataDetectorsCore arm64  <3d0a108f71733e29965b637096e09ec8> /System/Library/PrivateFrameworks/DataDetectorsCore.framework/DataDetectorsCore
0x1bc9e3000 - 0x1bca42fff CalendarFoundation arm64  <741401805340338b9af74bb4b3abbcec> /System/Library/PrivateFrameworks/CalendarFoundation.framework/CalendarFoundation
0x1bca43000 - 0x1bcb35fff EventKit arm64  <ccf2cfad170235068b9442ef6e9223c3> /System/Library/Frameworks/EventKit.framework/EventKit
0x1bcb36000 - 0x1bcb6cfff MediaServices arm64  <280846cf79173979b3983b4d12c94480> /System/Library/PrivateFrameworks/MediaServices.framework/MediaServices
0x1bcf88000 - 0x1bcfc7fff BiometricKit arm64  <e6db96b653b93c1ebfc883ed0eaf8aec> /System/Library/PrivateFrameworks/BiometricKit.framework/BiometricKit
0x1bcfc8000 - 0x1bcff2fff PersistentConnection arm64  <396582b9038d33ecbbaf6270715f2b50> /System/Library/PrivateFrameworks/PersistentConnection.framework/PersistentConnection
0x1bcff3000 - 0x1bd046fff CalendarDaemon arm64  <7f06d2437059300ab555af7cb5998810> /System/Library/PrivateFrameworks/CalendarDaemon.framework/CalendarDaemon
0x1bd047000 - 0x1bd0ddfff CalendarDatabase arm64  <94a758b9924130a9a008623815ebbac9> /System/Library/PrivateFrameworks/CalendarDatabase.framework/CalendarDatabase
0x1bd0de000 - 0x1bd2ccfff MediaRemote arm64  <1a209e28192c390bab18d149f841c17f> /System/Library/PrivateFrameworks/MediaRemote.framework/MediaRemote
0x1bd2cd000 - 0x1bd2d5fff CorePhoneNumbers arm64  <68106cb9cf6d390d8e267e7bbf249c6b> /System/Library/PrivateFrameworks/CorePhoneNumbers.framework/CorePhoneNumbers
0x1bd2e6000 - 0x1bd30cfff DuetActivityScheduler arm64  <13c0f1714e3036779c37852398f0bafa> /System/Library/PrivateFrameworks/DuetActivityScheduler.framework/DuetActivityScheduler
0x1bd411000 - 0x1bd433fff CoreSVG arm64  <73bfc0febb0d31628b9223dc7a5a983f> /System/Library/PrivateFrameworks/CoreSVG.framework/CoreSVG
0x1bd44e000 - 0x1bd46bfff ProactiveEventTracker arm64  <d3f6831ea3103097999b303f03c8719e> /System/Library/PrivateFrameworks/ProactiveEventTracker.framework/ProactiveEventTracker
0x1bd46c000 - 0x1bd477fff MallocStackLogging arm64  <bd95833751b935d8bfaa122f9c6eaafa> /System/Library/PrivateFrameworks/MallocStackLogging.framework/MallocStackLogging
0x1bd478000 - 0x1bd50cfff CoreSuggestions arm64  <5692520a6a6a3fa4a4dabef3347d528b> /System/Library/PrivateFrameworks/CoreSuggestions.framework/CoreSuggestions
0x1bd50d000 - 0x1bd6befff IMCore arm64  <fe16f952a8763d4ba91b2fb929d8ef98> /System/Library/PrivateFrameworks/IMCore.framework/IMCore
0x1bd6bf000 - 0x1bd710fff DeviceManagement arm64  <a2ec1a2c4bdc3d4da47e05f8c0b0810d> /System/Library/PrivateFrameworks/DeviceManagement.framework/DeviceManagement
0x1bdf15000 - 0x1bdf22fff BluetoothManager arm64  <f0706407ab963b31aac5f69d7e70dead> /System/Library/PrivateFrameworks/BluetoothManager.framework/BluetoothManager
0x1bdf23000 - 0x1bdf58fff CoreBluetooth arm64  <bfd3e1ab946c30a4b6a3c86c831f13d2> /System/Library/Frameworks/CoreBluetooth.framework/CoreBluetooth
0x1bdf59000 - 0x1bdf5bfff libsystem_sandbox.dylib arm64  <19bf542aa27f358aaf26c829d92f3995> /usr/lib/system/libsystem_sandbox.dylib
0x1be040000 - 0x1be077fff TextInputUI arm64  <584490afffd630b0a2b86d6045db9880> /System/Library/PrivateFrameworks/TextInputUI.framework/TextInputUI
0x1be086000 - 0x1be092fff ContextKit arm64  <af4e539a51ed31f58501db604920f663> /System/Library/PrivateFrameworks/ContextKit.framework/ContextKit
0x1be0c3000 - 0x1be12ffff Rapport arm64  <0d829a31fed33c2bb4da9a2712178c8c> /System/Library/PrivateFrameworks/Rapport.framework/Rapport
0x1be130000 - 0x1be173fff OSAnalytics arm64  <66d408f799793943ae529a4b12829625> /System/Library/PrivateFrameworks/OSAnalytics.framework/OSAnalytics
0x1be174000 - 0x1be1a2fff MobileInstallation arm64  <82830c2abb583bd5a627995189600504> /System/Library/PrivateFrameworks/MobileInstallation.framework/MobileInstallation
0x1be1a3000 - 0x1be23dfff Metal arm64  <245b6ff0bdfd33a7a34ce4fe57ebc2a2> /System/Library/Frameworks/Metal.framework/Metal
0x1be23e000 - 0x1be244fff IOAccelerator arm64  <3335cc966200367c99e96bb8fd064751> /System/Library/PrivateFrameworks/IOAccelerator.framework/IOAccelerator
0x1be245000 - 0x1be250fff MediaAccessibility arm64  <f8f4cb6f12af349aadc0c2124373d615> /System/Library/Frameworks/MediaAccessibility.framework/MediaAccessibility
0x1be26e000 - 0x1be275fff libsystem_dnssd.dylib arm64  <59b26d826fd335ed998cf5b62e38f910> /usr/lib/system/libsystem_dnssd.dylib
0x1be276000 - 0x1be27cfff PushKit arm64  <634713aced1d38df81cd370674d873ad> /System/Library/Frameworks/PushKit.framework/PushKit
0x1be27d000 - 0x1be382fff FileProvider arm64  <817c33078d9f344bae2e99274886c2de> /System/Library/Frameworks/FileProvider.framework/FileProvider
0x1be397000 - 0x1be398fff BackgroundTaskAgent arm64  <2ba41ad36b8a36088b6f0097d4a014fd> /System/Library/PrivateFrameworks/BackgroundTaskAgent.framework/BackgroundTaskAgent
0x1be399000 - 0x1be39efff LinguisticData arm64  <ee7e5c2f67d63fdb8f294a556494ffa5> /System/Library/PrivateFrameworks/LinguisticData.framework/LinguisticData
0x1be39f000 - 0x1be3b7fff CoreSDB arm64  <3c8d2ae38db03228b83874a7957493c9> /System/Library/PrivateFrameworks/CoreSDB.framework/CoreSDB
0x1be3b8000 - 0x1be3c8fff Categories arm64  <4aee06d32058399082825c91d95b7771> /System/Library/PrivateFrameworks/Categories.framework/Categories
0x1be3e3000 - 0x1be49efff VideoToolbox arm64  <cb7226845bc83f528ef0eb5e3d9e7d06> /System/Library/Frameworks/VideoToolbox.framework/VideoToolbox
0x1be8d4000 - 0x1be933fff PersonalizationPortrait arm64  <c41be57e68c13b2e91365a72b69ae410> /System/Library/PrivateFrameworks/PersonalizationPortrait.framework/PersonalizationPortrait
0x1be9fd000 - 0x1bea05fff SymptomDiagnosticReporter arm64  <7f5611dfa5063e699db9329b22f493de> /System/Library/PrivateFrameworks/SymptomDiagnosticReporter.framework/SymptomDiagnosticReporter
0x1bea06000 - 0x1bea08fff IOSurfaceAccelerator arm64  <4d17d1ca325c350a8cceec8a93550c14> /System/Library/PrivateFrameworks/IOSurfaceAccelerator.framework/IOSurfaceAccelerator
0x1bea09000 - 0x1beab7fff AssetsLibraryServices arm64  <4955c2b198f034fabf1be5e071b1f199> /System/Library/PrivateFrameworks/AssetsLibraryServices.framework/AssetsLibraryServices
0x1beab8000 - 0x1beaeafff DataAccessExpress arm64  <ccd6268a555f36fc823411bece0a960a> /System/Library/PrivateFrameworks/DataAccessExpress.framework/DataAccessExpress
0x1beb5a000 - 0x1beb6ffff CoreFollowUp arm64  <edfbe826475a330eb7062eaf1f013738> /System/Library/PrivateFrameworks/CoreFollowUp.framework/CoreFollowUp
0x1beb70000 - 0x1beb78fff FamilyCircle arm64  <47b6531315713b6fb50aa030a9bc27b9> /System/Library/PrivateFrameworks/FamilyCircle.framework/FamilyCircle
0x1beb79000 - 0x1beb8efff libcoretls.dylib arm64  <e83864eb177533af91d71d6e5bfd6799> /usr/lib/libcoretls.dylib
0x1bebe5000 - 0x1bec76fff libate.dylib arm64  <0dbd4cdb7d493a94a11e8c4b6eb9d303> /usr/lib/libate.dylib
0x1bff01000 - 0x1bff25fff Pasteboard arm64  <e599feae3d8d3929b1afefeaf62018d6> /System/Library/PrivateFrameworks/Pasteboard.framework/Pasteboard
0x1bff26000 - 0x1bff74fff FTServices arm64  <c451d4c6281f34c7880529373e2a84d7> /System/Library/PrivateFrameworks/FTServices.framework/FTServices
0x1c0026000 - 0x1c0090fff SAObjects arm64  <4d72bf5c563e3a9ca016e691ae307b08> /System/Library/PrivateFrameworks/SAObjects.framework/SAObjects
0x1c0091000 - 0x1c009bfff CoreRecents arm64  <e64c1a460cf23b7880679d9bc3521015> /System/Library/PrivateFrameworks/CoreRecents.framework/CoreRecents
0x1c0144000 - 0x1c0151fff DataMigration arm64  <bda78d7eac783fb7ad49253a971577af> /System/Library/PrivateFrameworks/DataMigration.framework/DataMigration
0x1c0305000 - 0x1c0329fff IconServices arm64  <9d0a77437f5e311097babd6a8f94e8a1> /System/Library/PrivateFrameworks/IconServices.framework/IconServices
0x1c032a000 - 0x1c0516fff iTunesCloud arm64  <e806cac9c1f13e80bf88b696c4cdd5e4> /System/Library/PrivateFrameworks/iTunesCloud.framework/iTunesCloud
0x1c0517000 - 0x1c07dcfff MusicLibrary arm64  <c4573d69b57033c8871d37d686109222> /System/Library/PrivateFrameworks/MusicLibrary.framework/MusicLibrary
0x1c07dd000 - 0x1c07defff WatchdogClient arm64  <834e0b823de23ff6b57e7904ce03a445> /System/Library/PrivateFrameworks/WatchdogClient.framework/WatchdogClient
0x1c07df000 - 0x1c07f0fff libprequelite.dylib arm64  <83d923c30f863498843177b257132ca9> /usr/lib/libprequelite.dylib
0x1c0815000 - 0x1c081afff IDSKVStore arm64  <0107cc7a4d5e38619995358ffa0a265d> /System/Library/PrivateFrameworks/IDSKVStore.framework/IDSKVStore
0x1c081b000 - 0x1c082bfff CoreEmoji arm64  <577a37002ad53990bcc8b0c9fd511a74> /System/Library/PrivateFrameworks/CoreEmoji.framework/CoreEmoji
0x1c08c4000 - 0x1c0926fff ClassKit arm64  <a5b8753d353b33adb396bb4c1770589a> /System/Library/Frameworks/ClassKit.framework/ClassKit
0x1c0992000 - 0x1c099ffff CPMS arm64  <df575af01b103cfcb663abf02f06ac80> /System/Library/PrivateFrameworks/CPMS.framework/CPMS
0x1c09a0000 - 0x1c09a8fff RTCReporting arm64  <0a2ce1ac2e2e3ce4a08f6cac1003638f> /System/Library/PrivateFrameworks/RTCReporting.framework/RTCReporting
0x1c0b04000 - 0x1c0b50fff MobileBackup arm64  <c8b58b1f4f1b3c4e90d8a015dc4b8a5d> /System/Library/PrivateFrameworks/MobileBackup.framework/MobileBackup
0x1c0bff000 - 0x1c0c06fff CoreTime arm64  <cf3715716c1635b68d871a966ae17239> /System/Library/PrivateFrameworks/CoreTime.framework/CoreTime
0x1c0c4d000 - 0x1c0d8cfff IMDPersistence arm64  <cd78aa6993ee36f289a9f7f9f382bc4d> /System/Library/PrivateFrameworks/IMDPersistence.framework/IMDPersistence
0x1c1234000 - 0x1c1287fff ToneLibrary arm64  <ae796371fa9c388d875bf9987e816484> /System/Library/PrivateFrameworks/ToneLibrary.framework/ToneLibrary
0x1c1521000 - 0x1c153ffff AppConduit arm64  <154844916f3532859f72c3ab9b95ae87> /System/Library/PrivateFrameworks/AppConduit.framework/AppConduit
0x1c1540000 - 0x1c1558fff IntlPreferences arm64  <19b52e5151793276afea6f0b59e6a97e> /System/Library/PrivateFrameworks/IntlPreferences.framework/IntlPreferences
0x1c18ff000 - 0x1c19edfff CoreBrightness arm64  <df0aac48fa243894800d72a97e6b4943> /System/Library/PrivateFrameworks/CoreBrightness.framework/CoreBrightness
0x1c19ee000 - 0x1c19f5fff libIOReport.dylib arm64  <ab2118f813b933e48f29f6d37d8d976e> /usr/lib/libIOReport.dylib
0x1c1b7e000 - 0x1c1db1fff libBNNS.dylib arm64  <a36340b78a703f8180b712c7759ab043> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libBNNS.dylib
0x1c1db2000 - 0x1c1db9fff StudyLog arm64  <6ba8e4d9754b3e25b97d3084e1646db0> /System/Library/PrivateFrameworks/StudyLog.framework/StudyLog
0x1c1e40000 - 0x1c1ecefff iTunesStore arm64  <b89f93b7ddc33e6993b8701d7e98e765> /System/Library/PrivateFrameworks/iTunesStore.framework/iTunesStore
0x1c2921000 - 0x1c2978fff SafariCore arm64  <0cd7ad921ee937db82a85e9a9252636d> /System/Library/PrivateFrameworks/SafariCore.framework/SafariCore
0x1c2979000 - 0x1c29e0fff ScreenTimeCore arm64  <3a52a67989fb39a98d87749022ce38c6> /System/Library/PrivateFrameworks/ScreenTimeCore.framework/ScreenTimeCore
0x1c2feb000 - 0x1c2ffdfff LocalAuthentication arm64  <b6f98d423e8634dc93182ca70b09cf3b> /System/Library/Frameworks/LocalAuthentication.framework/LocalAuthentication
0x1c2ffe000 - 0x1c3002fff CommunicationsFilter arm64  <b6b1cc145f2a3b199c85ada5af8dfd3e> /System/Library/PrivateFrameworks/CommunicationsFilter.framework/CommunicationsFilter
0x1c3003000 - 0x1c3025fff AddressBook arm64  <437470fa20f039ebbd8f319565a681e7> /System/Library/Frameworks/AddressBook.framework/AddressBook
0x1c3026000 - 0x1c3031fff CaptiveNetwork arm64  <dc9b5ed33e063d7eb9edec10ebd0e665> /System/Library/PrivateFrameworks/CaptiveNetwork.framework/CaptiveNetwork
0x1c3182000 - 0x1c3232fff libBLAS.dylib arm64  <62050c2e28b83071926604f28576b48a> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libBLAS.dylib
0x1c3233000 - 0x1c3241fff CTCarrierSpace arm64  <41d7677ad9313fe891ce68c033bec647> /System/Library/PrivateFrameworks/CTCarrierSpace.framework/CTCarrierSpace
0x1c3a50000 - 0x1c3b1bfff CoreParsec arm64  <cdc62617d5a9365bafacc9546ea06583> /System/Library/PrivateFrameworks/CoreParsec.framework/CoreParsec
0x1c3d09000 - 0x1c3d24fff libtailspin.dylib arm64  <450b7c0ece54385bbdab05395a050bcd> /usr/lib/libtailspin.dylib
0x1c3d81000 - 0x1c3d95fff ContactsDonation arm64  <d9c53579f3753255a0d649fe1f7780dc> /System/Library/PrivateFrameworks/ContactsDonation.framework/ContactsDonation
0x1c3de0000 - 0x1c3de9fff MobileActivation arm64  <ed46d70e41b63f13bf3b17894f6b594d> /System/Library/PrivateFrameworks/MobileActivation.framework/MobileActivation
0x1c3e6a000 - 0x1c3e78fff MobileIcons arm64  <3326557a3286356a87ca1df0d6130151> /System/Library/PrivateFrameworks/MobileIcons.framework/MobileIcons
0x1c3e79000 - 0x1c3f78fff ResponseKit arm64  <f16e781681d434dab63e5b9f5b065347> /System/Library/PrivateFrameworks/ResponseKit.framework/ResponseKit
0x1c403f000 - 0x1c4089fff CoreHaptics arm64  <06db7c401d2d3d9cb266f37874fa0bbb> /System/Library/Frameworks/CoreHaptics.framework/CoreHaptics
0x1c41c3000 - 0x1c4252fff CoreSymbolication arm64  <a57040868d163139acb568011b34123a> /System/Library/PrivateFrameworks/CoreSymbolication.framework/CoreSymbolication
0x1c4253000 - 0x1c4259fff IdleTimerServices arm64  <39c79767aa7034c9a680af46224d4640> /System/Library/PrivateFrameworks/IdleTimerServices.framework/IdleTimerServices
0x1c4352000 - 0x1c440bfff VideoSubscriberAccount arm64  <b9300042738f365c90ca366308d929c9> /System/Library/Frameworks/VideoSubscriberAccount.framework/VideoSubscriberAccount
0x1c4420000 - 0x1c4423fff FTClientServices arm64  <78f0b76870173a47ae1f3024101d4aad> /System/Library/PrivateFrameworks/FTClientServices.framework/FTClientServices
0x1c4424000 - 0x1c4489fff ContactsUICore arm64  <2da1d6849b7b36e3bc95d2be741b2ea9> /System/Library/PrivateFrameworks/ContactsUICore.framework/ContactsUICore
0x1c48e5000 - 0x1c492cfff LoggingSupport arm64  <6b7e370405d33c45967ac8c458928a3f> /System/Library/PrivateFrameworks/LoggingSupport.framework/LoggingSupport
0x1c4a30000 - 0x1c4a89fff ProtectedCloudStorage arm64  <bbc869b2f84b34d6bf61cef9d1fa8fc0> /System/Library/PrivateFrameworks/ProtectedCloudStorage.framework/ProtectedCloudStorage
0x1c4a8a000 - 0x1c4b52fff GLEngine arm64  <1b5a16deb30b3589831851240da1efc8> /System/Library/Frameworks/OpenGLES.framework/GLEngine.bundle/GLEngine
0x1c4b53000 - 0x1c4b6ffff AppleMetalGLRenderer arm64  <5c891a5bc2563d5ab3f6c42856ce154e> /System/Library/Extensions/AppleMetalGLRenderer.bundle/AppleMetalGLRenderer
0x1c4b70000 - 0x1c4b78fff OpenGLES arm64  <287f3b01842d30da9702f5cd4793458e> /System/Library/Frameworks/OpenGLES.framework/OpenGLES
0x1c4b79000 - 0x1c4cd7fff libGLProgrammability.dylib arm64  <0f85f94239203b818fe9f75af9a6782f> /System/Library/Frameworks/OpenGLES.framework/libGLProgrammability.dylib
0x1c4cd8000 - 0x1c4ce0fff libGFXShared.dylib arm64  <2209635c627c36d381f28da5e9019b90> /System/Library/Frameworks/OpenGLES.framework/libGFXShared.dylib
0x1c4ce1000 - 0x1c4d16fff SharedUtils arm64  <f6c64f0f3df3385aab929b5f99acb807> /System/Library/Frameworks/LocalAuthentication.framework/Support/SharedUtils.framework/SharedUtils
0x1c4d17000 - 0x1c4d64fff PhotosFormats arm64  <80f459a667303db0b188f9a6c61eb6cd> /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats
0x1c6371000 - 0x1c63adfff StreamingZip arm64  <80a7602a6d27384abec3ffe12bc0c50f> /System/Library/PrivateFrameworks/StreamingZip.framework/StreamingZip
0x1c6fec000 - 0x1c719ffff SafariShared arm64  <930666655b4937d9a2152c6834d06a0a> /System/Library/PrivateFrameworks/SafariShared.framework/SafariShared
0x1c7225000 - 0x1c7228fff InternationalTextSearch arm64  <d534123f5b233184ac92042f378619cd> /System/Library/PrivateFrameworks/InternationalTextSearch.framework/InternationalTextSearch
0x1c7246000 - 0x1c7262fff AssetCacheServices arm64  <fe2d1f58a37a30459b13dcc1814362e6> /System/Library/PrivateFrameworks/AssetCacheServices.framework/AssetCacheServices
0x1c7bd3000 - 0x1c7bd8fff IncomingCallFilter arm64  <d6b56428a9b634788ecddd75c8420b8e> /System/Library/PrivateFrameworks/IncomingCallFilter.framework/IncomingCallFilter
0x1c7bf4000 - 0x1c7c0cfff NetworkStatistics arm64  <52d0181fe70c385697ef3746d5fe1bb4> /System/Library/PrivateFrameworks/NetworkStatistics.framework/NetworkStatistics
0x1c8078000 - 0x1c807efff Netrb arm64  <53cc7821890f34b380124739cbb90896> /System/Library/PrivateFrameworks/Netrb.framework/Netrb
0x1c8082000 - 0x1c80b2fff EAP8021X arm64  <e8e5622aa64439bdae85b80f604662f1> /System/Library/PrivateFrameworks/EAP8021X.framework/EAP8021X
0x1c80b3000 - 0x1c80b5fff OSAServicesClient arm64  <785aab0a88ed34ba885d7483d3be9ee9> /System/Library/PrivateFrameworks/OSAServicesClient.framework/OSAServicesClient
0x1c8239000 - 0x1c823dfff libgermantok.dylib arm64  <e15d5eee368a3e16b9a11328963ce574> /usr/lib/libgermantok.dylib
0x1c823e000 - 0x1c82f1fff libmecab.dylib arm64  <0bb7b7b678bb3ab887345ee24d6eff43> /usr/lib/libmecab.dylib
0x1c82f2000 - 0x1c832dfff Catalyst arm64  <986bc11a0f5131e191295b9c7a3f7ab2> /System/Library/PrivateFrameworks/Catalyst.framework/Catalyst
0x1c83ea000 - 0x1c8402fff EmojiFoundation arm64  <73ce79d27270382791122516bb308cf8> /System/Library/PrivateFrameworks/EmojiFoundation.framework/EmojiFoundation
0x1c8499000 - 0x1c84d5fff VoiceServices arm64  <e6f4af2654f03125b334ccce6916d07d> /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices
0x1c84d6000 - 0x1c85ecfff Navigation arm64  <16a6a764ab0a3f75bc063f808063cbbf> /System/Library/PrivateFrameworks/Navigation.framework/Navigation
0x1c8905000 - 0x1c8913fff CoreDuetDaemonProtocol arm64  <165d40fd3ad831c19723d85738aabf53> /System/Library/PrivateFrameworks/CoreDuetDaemonProtocol.framework/CoreDuetDaemonProtocol
0x1c8914000 - 0x1c8933fff FTAWD arm64  <51a4c50a1e883595bf4d7195a506fc8c> /System/Library/PrivateFrameworks/FTAWD.framework/FTAWD
0x1c9ee5000 - 0x1c9ee7fff OAuth arm64  <a6900a3c3a9639aca03ab1e00576cede> /System/Library/PrivateFrameworks/OAuth.framework/OAuth
0x1ca182000 - 0x1ca1bdfff DifferentialPrivacy arm64  <b0a6360b231337369dc89715c832eb22> /System/Library/PrivateFrameworks/DifferentialPrivacy.framework/DifferentialPrivacy
0x1ca997000 - 0x1caa05fff libarchive.2.dylib arm64  <f687622c8e6e3452a0d48f7ed993c0d4> /usr/lib/libarchive.2.dylib
0x1caa06000 - 0x1caa36fff C2 arm64  <0d7a3e496f95395c9eae28b0d0b16ba5> /System/Library/PrivateFrameworks/C2.framework/C2
0x1caa37000 - 0x1caa6afff NaturalLanguage arm64  <cfa438750b4032c8b14daf751e0b0df0> /System/Library/Frameworks/NaturalLanguage.framework/NaturalLanguage
0x1caafd000 - 0x1caafefff libsystem_coreservices.dylib arm64  <50693ebd12b43fc8acaad84a8b82a0df> /usr/lib/system/libsystem_coreservices.dylib
0x1cab10000 - 0x1cab22fff libmis.dylib arm64  <70eb0208446d35d1a06035cee66ecf30> /usr/lib/libmis.dylib
0x1cab23000 - 0x1cab78fff WebBookmarks arm64  <999457f8960a3611bf14c3f4619837a5> /System/Library/PrivateFrameworks/WebBookmarks.framework/WebBookmarks
0x1cab79000 - 0x1cab86fff DCIMServices arm64  <2f74408211e2332b8aa91789e71ae562> /System/Library/PrivateFrameworks/DCIMServices.framework/DCIMServices
0x1cab87000 - 0x1cacd7fff CloudPhotoLibrary arm64  <51a836e0dea1366b83a29640fc2648b1> /System/Library/PrivateFrameworks/CloudPhotoLibrary.framework/CloudPhotoLibrary
0x1cad12000 - 0x1cad1afff libcopyfile.dylib arm64  <f5f048c1d258338f96bd94863b7f84e4> /usr/lib/system/libcopyfile.dylib
0x1cad1b000 - 0x1cad3cfff UsageTracking arm64  <81e36061690d39c19eb46f605c1fbcff> /System/Library/PrivateFrameworks/UsageTracking.framework/UsageTracking
0x1cb07e000 - 0x1cb112fff AccountsDaemon arm64  <7abea61a48783baaa76d6ba23b765846> /System/Library/PrivateFrameworks/AccountsDaemon.framework/AccountsDaemon
0x1cb113000 - 0x1cb11efff AppleIDSSOAuthentication arm64  <e4999d56d7673b7b9c1370b23fcbbec5> /System/Library/PrivateFrameworks/AppleIDSSOAuthentication.framework/AppleIDSSOAuthentication
0x1cb11f000 - 0x1cb132fff SettingsFoundation arm64  <d6b7da8b402b3d9c91234c18f5dc7ffb> /System/Library/PrivateFrameworks/SettingsFoundation.framework/SettingsFoundation
0x1cb26b000 - 0x1cb2edfff Symbolication arm64  <31fd30f6ccb13309b25294a1d85326e2> /System/Library/PrivateFrameworks/Symbolication.framework/Symbolication
0x1cb4a2000 - 0x1cb4effff ChunkingLibrary arm64  <6c669fdc362138dd89e33201adb10962> /System/Library/PrivateFrameworks/ChunkingLibrary.framework/ChunkingLibrary
0x1cb4f3000 - 0x1cb4f7fff DAAPKit arm64  <407eb1b504133cf59185bb985c8834bd> /System/Library/PrivateFrameworks/DAAPKit.framework/DAAPKit
0x1cb9cc000 - 0x1cb9cefff CoreDuetDebugLogging arm64  <1fd35a97edf032d68a771db66fc72f52> /System/Library/PrivateFrameworks/CoreDuetDebugLogging.framework/CoreDuetDebugLogging
0x1cc4f3000 - 0x1cc531fff SignpostSupport arm64  <a8ffcfa229463bc087f1dcc98e94864e> /System/Library/PrivateFrameworks/SignpostSupport.framework/SignpostSupport
0x1cc7c6000 - 0x1cc7cffff SignpostCollection arm64  <4f5984b7fa9938779a0e784f4ec5f2e1> /System/Library/PrivateFrameworks/SignpostCollection.framework/SignpostCollection
0x1ccefc000 - 0x1ccf02fff URLFormatting arm64  <fbc08a2be4293492a507ee08d69db0b9> /System/Library/PrivateFrameworks/URLFormatting.framework/URLFormatting
0x1ccf17000 - 0x1ccfbefff MMCS arm64  <a0b62405414f3082832d301e6c98c361> /System/Library/PrivateFrameworks/MMCS.framework/MMCS
0x1cd016000 - 0x1cd242fff MobileSpotlightIndex arm64  <001c3d304f153304b2a50fef0300dae4> /System/Library/PrivateFrameworks/MobileSpotlightIndex.framework/MobileSpotlightIndex
0x1cd665000 - 0x1cd6abfff CoreLocationProtobuf arm64  <354363c3361234f0bde81d06b68951a8> /System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/CoreLocationProtobuf
0x1cd75f000 - 0x1cd7dbfff Quagga arm64  <1e8a7a5cf04239d8b8a9d719c1aeddad> /System/Library/PrivateFrameworks/Quagga.framework/Quagga
0x1cdae6000 - 0x1cdafbfff libEDR arm64  <66ee6000bd2339d1ba5e6b3b10c2470c> /System/Library/PrivateFrameworks/libEDR.framework/libEDR
0x1ce719000 - 0x1ce726fff libperfcheck.dylib arm64  <3ba9a8fd8a773231ab960d7701333c63> /usr/lib/libperfcheck.dylib
0x1ce727000 - 0x1ce732fff libAudioStatistics.dylib arm64  <c74af5a6998431e3b5cf65f2283d2145> /usr/lib/libAudioStatistics.dylib
0x1ce8f6000 - 0x1ce906fff caulk arm64  <eb0f4cd651633b23948a25c8c2ba93c2> /System/Library/PrivateFrameworks/caulk.framework/caulk
0x1ce945000 - 0x1ce94bfff MobileSystemServices arm64  <a1c84260dd6f36be94784291ef6f1c30> /System/Library/PrivateFrameworks/MobileSystemServices.framework/MobileSystemServices
0x1cfa7d000 - 0x1cfa87fff HID arm64  <b07d4f0b24023f4ea0d2ab04d5871a94> /System/Library/PrivateFrameworks/HID.framework/HID
0x1cfab4000 - 0x1cfaedfff libGLImage.dylib arm64  <15ad0d4a18443118ac68cf15538dab9e> /System/Library/Frameworks/OpenGLES.framework/libGLImage.dylib
0x1cfee8000 - 0x1cfef9fff libSparseBLAS.dylib arm64  <1f51189eaa19385c94b7fb0292561c82> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libSparseBLAS.dylib
0x1cfefa000 - 0x1cff0dfff Engram arm64  <6e8e17826af3317f92fb524fa0b85c33> /System/Library/PrivateFrameworks/Engram.framework/Engram
0x1cff84000 - 0x1cffbefff DataDetectorsNaturalLanguage arm64  <fdd18833bb40393cb0b36aa612898268> /System/Library/PrivateFrameworks/DataDetectorsNaturalLanguage.framework/DataDetectorsNaturalLanguage
0x1d02b5000 - 0x1d02bdfff FSEvents arm64  <ff8eb4136ed734ddbba680ce0c3e88be> /System/Library/PrivateFrameworks/FSEvents.framework/FSEvents
0x1d02cd000 - 0x1d034afff CoreDAV arm64  <bc90cfd12bae381e89a63307c80599a5> /System/Library/PrivateFrameworks/CoreDAV.framework/CoreDAV
0x1d0c93000 - 0x1d0ca3fff RemoteTextInput arm64  <76a999dbfd5a363384d1ad23aaadccf6> /System/Library/PrivateFrameworks/RemoteTextInput.framework/RemoteTextInput
0x1d0ccc000 - 0x1d0cfbfff iCalendar arm64  <9df467aa8d1630b69f7d5e1371cf1b12> /System/Library/PrivateFrameworks/iCalendar.framework/iCalendar
0x1d0d18000 - 0x1d0d21fff CloudPhotoServices arm64  <fa48e241fdfe38fe8596c734d100b850> /System/Library/PrivateFrameworks/CloudPhotoServices.framework/CloudPhotoServices
0x1d0d60000 - 0x1d0d74fff libLinearAlgebra.dylib arm64  <83e007597b01399783a65a8f7a6c3208> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libLinearAlgebra.dylib
0x1d0e08000 - 0x1d0f02fff ConfigurationEngineModel arm64  <4577aebeb8fc3bd09d1b030d97373dde> /System/Library/PrivateFrameworks/ConfigurationEngineModel.framework/ConfigurationEngineModel
0x1d0f03000 - 0x1d0f0afff CertUI arm64  <6680caf12d653f11a1df07a43db46053> /System/Library/PrivateFrameworks/CertUI.framework/CertUI
0x1d0fef000 - 0x1d0ffdfff CoreAUC arm64  <0baa16e29c3a372aafd1f0e84f547e5c> /System/Library/PrivateFrameworks/CoreAUC.framework/CoreAUC
0x1d198e000 - 0x1d19d4fff PhysicsKit arm64  <b47ea3ebcfd037bda7b951e1ad5f7f90> /System/Library/PrivateFrameworks/PhysicsKit.framework/PhysicsKit
0x1d19d5000 - 0x1d1a26fff CorePrediction arm64  <e70c69587f633651b1c42a87caa03dc9> /System/Library/PrivateFrameworks/CorePrediction.framework/CorePrediction
0x1d1e18000 - 0x1d1e65fff SafariSafeBrowsing arm64  <76e45ab6253135dbbcc5b9657344c140> /System/Library/PrivateFrameworks/SafariSafeBrowsing.framework/SafariSafeBrowsing
0x1d2213000 - 0x1d2289fff HomeSharing arm64  <f5d31569258d319fa9d6df64a246504d> /System/Library/PrivateFrameworks/HomeSharing.framework/HomeSharing
0x1d2317000 - 0x1d2335fff GenerationalStorage arm64  <05a7c289ff76316bad961b4e87eefbf6> /System/Library/PrivateFrameworks/GenerationalStorage.framework/GenerationalStorage
0x1d2398000 - 0x1d23a3fff PersonaKit arm64  <818ad3bb76b83cf2a5e2abd964da978b> /System/Library/PrivateFrameworks/PersonaKit.framework/PersonaKit
0x1d23a4000 - 0x1d23b0fff PersonaUI arm64  <65aeb7d64ae135f28487092ea21b4344> /System/Library/PrivateFrameworks/PersonaUI.framework/PersonaUI
0x1d27bc000 - 0x1d27c1fff kperf arm64  <4dd4a30e85383405b9959fde4fd003f1> /System/Library/PrivateFrameworks/kperf.framework/kperf
0x1d295e000 - 0x1d296cfff AssetsLibrary arm64  <486139609c8b3b29bf7561f253873e44> /System/Library/Frameworks/AssetsLibrary.framework/AssetsLibrary
0x1d2999000 - 0x1d29ccfff libpcap.A.dylib arm64  <80be39cf99d83d1eb3c6b8d3fd8a838d> /usr/lib/libpcap.A.dylib
0x1d2c8c000 - 0x1d2ca0fff WebUI arm64  <a9cd6647a4913d30ac88fd88bc4c4667> /System/Library/PrivateFrameworks/WebUI.framework/WebUI
0x1d2ca1000 - 0x1d2cb8fff SafariFoundation arm64  <ebcb0a0b83f53be091d8d09e80e2b2ec> /System/Library/PrivateFrameworks/SafariFoundation.framework/SafariFoundation
0x1d2d04000 - 0x1d2d9efff libvDSP.dylib arm64  <76375e092cdb311185ec8ed1d8f4bfc9> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libvDSP.dylib
0x1d2d9f000 - 0x1d2dc9fff vCard arm64  <b0b531acb8d93d96b56ebc95a2d3f347> /System/Library/PrivateFrameworks/vCard.framework/vCard
0x1d2e11000 - 0x1d2e9bfff SampleAnalysis arm64  <b0b83d5c49fc3b3d9737165254abfacb> /System/Library/PrivateFrameworks/SampleAnalysis.framework/SampleAnalysis
0x1d2e9c000 - 0x1d2ea8fff IntentsFoundation arm64  <2090563ffa41300da28ea5bc984ed49b> /System/Library/PrivateFrameworks/IntentsFoundation.framework/IntentsFoundation
0x1d3094000 - 0x1d3096fff ParsecSubscriptionServiceSupport arm64  <a90bc317d0c63803a67dd9fac0e4bc06> /System/Library/PrivateFrameworks/ParsecSubscriptionServiceSupport.framework/ParsecSubscriptionServiceSupport
0x1d3097000 - 0x1d3126fff MediaPlatform arm64  <a7f36f3dd45230f78c0dfd793cf737da> /System/Library/PrivateFrameworks/MediaPlatform.framework/MediaPlatform
0x1d3127000 - 0x1d3437fff MediaLibraryCore arm64  <55b303ee3c563e8ba58e5d3aaa7af419> /System/Library/PrivateFrameworks/MediaLibraryCore.framework/MediaLibraryCore
0x1d349a000 - 0x1d34d2fff PhotosImagingFoundation arm64  <d5ab64a694fc362c8a1af663f04dc142> /System/Library/PrivateFrameworks/PhotosImagingFoundation.framework/PhotosImagingFoundation
0x1d34d3000 - 0x1d34f5fff MediaConversionService arm64  <546cb2add7863f26a98d7269bef43091> /System/Library/PrivateFrameworks/MediaConversionService.framework/MediaConversionService
0x1d34f6000 - 0x1d3513fff MediaStream arm64  <53b300858ffc31d8a6b4c6c007e5e24b> /System/Library/PrivateFrameworks/MediaStream.framework/MediaStream
0x1d3514000 - 0x1d360efff CoreMediaStream arm64  <199d1804e5113baa9df9d57487aeb62a> /System/Library/PrivateFrameworks/CoreMediaStream.framework/CoreMediaStream
0x1d3728000 - 0x1d3728fff Accelerate arm64  <9818869ce13333be8f6636eea59aedc8> /System/Library/Frameworks/Accelerate.framework/Accelerate
0x1d3729000 - 0x1d3a3efff libLAPACK.dylib arm64  <1d4e4b0531313da5b611fb2575e17079> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libLAPACK.dylib
0x1d3a3f000 - 0x1d3a43fff libQuadrature.dylib arm64  <cccd3657551a38ef9e6c240d60dc8df8> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libQuadrature.dylib
0x1d3a44000 - 0x1d3a9dfff libvMisc.dylib arm64  <435399eb7a8f3979b0d139c3f453fd29> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libvMisc.dylib
0x1d3a9e000 - 0x1d3a9efff vecLib arm64  <b52984345da233bb9108b4b63a4b26a6> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/vecLib
0x1d3aa7000 - 0x1d3ab5fff AuthenticationServices arm64  <5af6c2ea423e34cdbe63b7567d256def> /System/Library/Frameworks/AuthenticationServices.framework/AuthenticationServices
0x1d3afa000 - 0x1d3beefff Combine arm64  <25b66e311fbc3bf68cb6df8c27a2152f> /System/Library/Frameworks/Combine.framework/Combine
0x1d3c00000 - 0x1d3c50fff CoreMIDI arm64  <c742c545e39338cfa7a113ee469671dc> /System/Library/Frameworks/CoreMIDI.framework/CoreMIDI
0x1d3e29000 - 0x1d3e4efff GLKit arm64  <04b0e586b6263ee5a348025776314cb2> /System/Library/Frameworks/GLKit.framework/GLKit
0x1d3e4f000 - 0x1d3e7cfff GSS arm64  <a117041e533335ba8e67d0af00477b37> /System/Library/Frameworks/GSS.framework/GSS
0x1d3e8f000 - 0x1d3ec1fff MPSCore arm64  <7f98e0d3952a38c09bc314765766fc86> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSCore.framework/MPSCore
0x1d3ec2000 - 0x1d3f3efff MPSImage arm64  <63f5ffc1702e36ff841abafcd47d0301> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSImage.framework/MPSImage
0x1d3f3f000 - 0x1d3f61fff MPSMatrix arm64  <cb977b3da929362a9a59a85ba312a392> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSMatrix.framework/MPSMatrix
0x1d3f62000 - 0x1d3f76fff MPSNDArray arm64  <8a75d75a84c439e0bdf578136ceb73f1> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNDArray.framework/MPSNDArray
0x1d3f77000 - 0x1d4108fff MPSNeuralNetwork arm64  <4b7b42c84e2538758d2503bcaf4c695d> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNeuralNetwork.framework/MPSNeuralNetwork
0x1d4109000 - 0x1d414dfff MPSRayIntersector arm64  <9d947816460c35e2b072e2d9b809d01b> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSRayIntersector.framework/MPSRayIntersector
0x1d414e000 - 0x1d414efff MetalPerformanceShaders arm64  <7de1dbb3681835558dfb8c6d50de268b> /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders
0x1d415b000 - 0x1d415bfff MobileCoreServices arm64  <d7873825e57d3c4081f1da103c723f89> /System/Library/Frameworks/MobileCoreServices.framework/MobileCoreServices
0x1d4166000 - 0x1d4167fff libCVMSPluginSupport.dylib arm64  <cda51c2ff1b33e6fa71ae3ae6daa7325> /System/Library/Frameworks/OpenGLES.framework/libCVMSPluginSupport.dylib
0x1d4168000 - 0x1d416efff libCoreFSCache.dylib arm64  <84690d5764ad3ee3864e18d4704e08cd> /System/Library/Frameworks/OpenGLES.framework/libCoreFSCache.dylib
0x1d416f000 - 0x1d4174fff libCoreVMClient.dylib arm64  <66daee76addf32a981f2daca6fb6b0fe> /System/Library/Frameworks/OpenGLES.framework/libCoreVMClient.dylib
0x1d41a9000 - 0x1d41e0fff QuickLookThumbnailing arm64  <b2d5c531a95638c695531339b1bbfa52> /System/Library/Frameworks/QuickLookThumbnailing.framework/QuickLookThumbnailing
0x1d4615000 - 0x1d4615fff UIKit arm64  <47a27c57c3aa387fbc3d53d2e7249e16> /System/Library/Frameworks/UIKit.framework/UIKit
0x1d4863000 - 0x1d49b5fff ANECompiler arm64  <931531fa29713983a242fe34c7917616> /System/Library/PrivateFrameworks/ANECompiler.framework/ANECompiler
0x1d49b6000 - 0x1d49c6fff ANEServices arm64  <c2fbaeaf090e35deacb75ae881fb4b14> /System/Library/PrivateFrameworks/ANEServices.framework/ANEServices
0x1d49cf000 - 0x1d4a5ffff APFS arm64  <0d446bc9f2f93ca0b2ee1727925f10ef> /System/Library/PrivateFrameworks/APFS.framework/APFS
0x1d4a60000 - 0x1d4a64fff ASEProcessing arm64  <d4b121b1aabb3f92baafe2a6b70e32de> /System/Library/PrivateFrameworks/ASEProcessing.framework/ASEProcessing
0x1d4c0b000 - 0x1d4c16fff AccountSettings arm64  <d3c47caea6ce393a80e478b9f1266638> /System/Library/PrivateFrameworks/AccountSettings.framework/AccountSettings
0x1d5515000 - 0x1d5523fff AppleFSCompression arm64  <a1d88ec9766332a89edc09ee5ab40182> /System/Library/PrivateFrameworks/AppleFSCompression.framework/AppleFSCompression
0x1d5524000 - 0x1d552efff AppleIDAuthSupport arm64  <fe30c61996483b1887f3cc6c25edf7ce> /System/Library/PrivateFrameworks/AppleIDAuthSupport.framework/AppleIDAuthSupport
0x1d552f000 - 0x1d5570fff AppleJPEG arm64  <14d3a4bcfc0f374297d912b8c85cc5a0> /System/Library/PrivateFrameworks/AppleJPEG.framework/AppleJPEG
0x1d55b9000 - 0x1d55cafff AppleNeuralEngine arm64  <622801b185fe3bfb834d3d44ad9f9187> /System/Library/PrivateFrameworks/AppleNeuralEngine.framework/AppleNeuralEngine
0x1d55d1000 - 0x1d55f4fff AppleSauce arm64  <f5d836a116f13ebba5fc71d3efb4d030> /System/Library/PrivateFrameworks/AppleSauce.framework/AppleSauce
0x1d57ed000 - 0x1d581dfff Bom arm64  <0dfe861e6be13f9eb920584c5b46f646> /System/Library/PrivateFrameworks/Bom.framework/Bom
0x1d6296000 - 0x1d629dfff CommonAuth arm64  <ba671729ef0f30039c1774666fc6592c> /System/Library/PrivateFrameworks/CommonAuth.framework/CommonAuth
0x1d669a000 - 0x1d669efff CoreOptimization arm64  <81a3200ad13730a59e896c36e69ff6fc> /System/Library/PrivateFrameworks/CoreOptimization.framework/CoreOptimization
0x1d67e9000 - 0x1d67f4fff DeviceIdentity arm64  <8e7caf4f24f0322c9947f91c17a715fd> /System/Library/PrivateFrameworks/DeviceIdentity.framework/DeviceIdentity
0x1d6984000 - 0x1d69a0fff DocumentManagerCore arm64  <a077927cd5eb35ce992239758da231b9> /System/Library/PrivateFrameworks/DocumentManagerCore.framework/DocumentManagerCore
0x1d6a57000 - 0x1d70b2fff Espresso arm64  <9df07bcd41c4334fb57ed6ea22476366> /System/Library/PrivateFrameworks/Espresso.framework/Espresso
0x1d7364000 - 0x1d7775fff FaceCore arm64  <4de7d3c4806235d09407711b87b2bae5> /System/Library/PrivateFrameworks/FaceCore.framework/FaceCore
0x1d7846000 - 0x1d785afff libGSFontCache.dylib arm64  <abcdc382bad33a6c9ba10d0cf44c136f> /System/Library/PrivateFrameworks/FontServices.framework/libGSFontCache.dylib
0x1d78be000 - 0x1d78cafff libhvf.dylib arm64  <9563809693d6387db69fea88af4564e3> /System/Library/PrivateFrameworks/FontServices.framework/libhvf.dylib
0x1d78ec000 - 0x1d7900fff Futhark arm64  <07fc0e314de9321fb0f6ff75d012a134> /System/Library/PrivateFrameworks/Futhark.framework/Futhark
0x1d844c000 - 0x1d844cfff libmetal_timestamp.dylib arm64  <114bf199e7e0374d94e385c271b0c8a3> /System/Library/PrivateFrameworks/GPUCompiler.framework/Libraries/libmetal_timestamp.dylib
0x1d85cd000 - 0x1d85d9fff GraphVisualizer arm64  <d5a5d07491713bfd892d31889ec1b6ce> /System/Library/PrivateFrameworks/GraphVisualizer.framework/GraphVisualizer
0x1d8eca000 - 0x1d8f3afff Heimdal arm64  <0a1b601c4d7331c4a37c44d2f5271264> /System/Library/PrivateFrameworks/Heimdal.framework/Heimdal
0x1d9486000 - 0x1d948cfff InternationalSupport arm64  <56238f820e0f3cc4befe347f830ffe44> /System/Library/PrivateFrameworks/InternationalSupport.framework/InternationalSupport
0x1d972c000 - 0x1d972cfff Marco arm64  <d1a138229ac438b586ef4d9bd9f5d5a2> /System/Library/PrivateFrameworks/Marco.framework/Marco
0x1d9be1000 - 0x1d9c0bfff MetricsKit arm64  <6464cc726ac63bd0b755a159e205a73f> /System/Library/PrivateFrameworks/MetricsKit.framework/MetricsKit
0x1d9c1b000 - 0x1d9c2efff MobileDeviceLink arm64  <687959b4e80d3fe08b0cc23ec02a82b2> /System/Library/PrivateFrameworks/MobileDeviceLink.framework/MobileDeviceLink
0x1d9ee2000 - 0x1d9f21fff OTSVG arm64  <4295cc2da66d3905963b70f4ca852533> /System/Library/PrivateFrameworks/OTSVG.framework/OTSVG
0x1da566000 - 0x1da566fff PhoneNumbers arm64  <e23d89e41d5939f5a5def8c70b89efe4> /System/Library/PrivateFrameworks/PhoneNumbers.framework/PhoneNumbers
0x1dbf30000 - 0x1dbf34fff RevealCore arm64  <40fbd11d577e3bbc9d10621400e5f57f> /System/Library/PrivateFrameworks/RevealCore.framework/RevealCore
0x1dc0d0000 - 0x1dc0dcfff SetupAssistantSupport arm64  <12028ece9f6a3995b90d31fed2d46a77> /System/Library/PrivateFrameworks/SetupAssistantSupport.framework/SetupAssistantSupport
0x1dc0fa000 - 0x1dc0fafff SignpostMetrics arm64  <bd8c101a86253fdb87532ccbd64266f7> /System/Library/PrivateFrameworks/SignpostMetrics.framework/SignpostMetrics
0x1dc128000 - 0x1dc158fff SiriInstrumentation arm64  <a08172f898bf358b9e79ac9ced804429> /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation
0x1dc96d000 - 0x1dca88fff TextRecognition arm64  <3f60021f659d3da9b2b470d0b997fc61> /System/Library/PrivateFrameworks/TextRecognition.framework/TextRecognition
0x1dca89000 - 0x1dcb2afff TextureIO arm64  <55a7d4be7c2835d59ed2cbc7db47f880> /System/Library/PrivateFrameworks/TextureIO.framework/TextureIO
0x1ddaa3000 - 0x1de004fff libwebrtc.dylib arm64  <fb6670b5c0093e729bd61ea2e0c710f4> /System/Library/PrivateFrameworks/WebCore.framework/Frameworks/libwebrtc.dylib
0x1de19c000 - 0x1de1a4fff kperfdata arm64  <0280752ec857378482e788bd63ad43ef> /System/Library/PrivateFrameworks/kperfdata.framework/kperfdata
0x1de1a5000 - 0x1de1ecfff ktrace arm64  <fddcc7c6de53358985ed0fe969d61468> /System/Library/PrivateFrameworks/ktrace.framework/ktrace
0x1de205000 - 0x1de211fff perfdata arm64  <d5f09efc1baa33a0b6a7e59d13432cfb> /System/Library/PrivateFrameworks/perfdata.framework/perfdata
0x1de509000 - 0x1de832fff libAWDSupportFramework.dylib arm64  <5079327466f43f86b15028858aa1bb67> /usr/lib/libAWDSupportFramework.dylib
0x1de9dc000 - 0x1de9e6fff libChineseTokenizer.dylib arm64  <5dd82d181e2e32d4a3e755012a2534aa> /usr/lib/libChineseTokenizer.dylib
0x1dea10000 - 0x1debc2fff libFosl_dynamic.dylib arm64  <6692e724c11b3bfb9593a3180f183057> /usr/lib/libFosl_dynamic.dylib
0x1dec3d000 - 0x1dec44fff libMatch.1.dylib arm64  <d0d21782e5c730e59c5059b33b72995c> /usr/lib/libMatch.1.dylib
0x1ded03000 - 0x1ded04fff libSystem.B.dylib arm64  <18687f3a21d73966b82704fc5d4e2188> /usr/lib/libSystem.B.dylib
0x1ded0d000 - 0x1ded0ffff libThaiTokenizer.dylib arm64  <342d2a135b0a37a2969fcb30ef6f5217> /usr/lib/libThaiTokenizer.dylib
0x1dee0e000 - 0x1dee23fff libapple_nghttp2.dylib arm64  <50a1e06796123db8af9bdc15a2c82dfe> /usr/lib/libapple_nghttp2.dylib
0x1dee9c000 - 0x1deeacfff libbsm.0.dylib arm64  <8072366407503038b0e1eccd42c12f23> /usr/lib/libbsm.0.dylib
0x1deead000 - 0x1deeb9fff libbz2.1.0.dylib arm64  <aa92d96b6c6b3c30b868bd327247c281> /usr/lib/libbz2.1.0.dylib
0x1deeba000 - 0x1deebafff libcharset.1.dylib arm64  <3a1952fac60c363fb2720123f782b09c> /usr/lib/libcharset.1.dylib
0x1deebb000 - 0x1deeccfff libcmph.dylib arm64  <3db1a5a10dee3c8cac717ea539ca7ff6> /usr/lib/libcmph.dylib
0x1deecd000 - 0x1deee4fff libcompression.dylib arm64  <d5cd6dc1de683966b5a5a18a6f5eae85> /usr/lib/libcompression.dylib
0x1deee5000 - 0x1deee6fff libcoretls_cfhelpers.dylib arm64  <7940b1e1e9b33782860ac608bfd44fbc> /usr/lib/libcoretls_cfhelpers.dylib
0x1deee7000 - 0x1deeedfff libcupolicy.dylib arm64  <39fd4f3cb58e35ab8095f873beed4007> /usr/lib/libcupolicy.dylib
0x1def2d000 - 0x1def36fff libdscsym.dylib arm64  <0b0f4385a47f3eeb9cc385864a69b909> /usr/lib/libdscsym.dylib
0x1def37000 - 0x1def53fff libedit.3.dylib arm64  <208aef48da0a3872b9cabc520a506e19> /usr/lib/libedit.3.dylib
0x1def7f000 - 0x1def84fff libheimdal-asn1.dylib arm64  <40eb02d5300c3a129e2ad0ed647ac737> /usr/lib/libheimdal-asn1.dylib
0x1def85000 - 0x1df076fff libiconv.2.dylib arm64  <8467990cb00c3b1194ce7feae7e3370a> /usr/lib/libiconv.2.dylib
0x1df08c000 - 0x1df097fff liblockdown.dylib arm64  <63d8b54e30bf3af39b56fc654cabf8ff> /usr/lib/liblockdown.dylib
0x1df098000 - 0x1df0b0fff liblzma.5.dylib arm64  <4074d76ec7a93b8492a262a059d3b837> /usr/lib/liblzma.5.dylib
0x1df42d000 - 0x1df45cfff libncurses.5.4.dylib arm64  <fde38058c2563bb88c96fc717f409d6b> /usr/lib/libncurses.5.4.dylib
0x1df45d000 - 0x1df472fff libnetworkextension.dylib arm64  <6dc4d4e4896a3c5da26ddd4f3528d833> /usr/lib/libnetworkextension.dylib
0x1df7f5000 - 0x1df80cfff libresolv.9.dylib arm64  <7d42c468c5223bcd8764b1706b530a84> /usr/lib/libresolv.9.dylib
0x1df80d000 - 0x1df80ffff libsandbox.1.dylib arm64  <ae76c31a749a355a9d26b8c216681c0f> /usr/lib/libsandbox.1.dylib
0x1df810000 - 0x1df815fff libsysdiagnose.dylib arm64  <8accc334bf85392e96f9800ceeffd6c0> /usr/lib/libsysdiagnose.dylib
0x1df816000 - 0x1df847fff libtidy.A.dylib arm64  <9596a6a694de3e1d80c5a18e8f81366a> /usr/lib/libtidy.A.dylib
0x1df84f000 - 0x1df852fff libutil.dylib arm64  <0520efce5fe43c2fb18ee9d621dd2433> /usr/lib/libutil.dylib
0x1df880000 - 0x1df891fff libz.1.dylib arm64  <58a7ec43dad53a55aa9ed43f7d72639e> /usr/lib/libz.1.dylib
0x1df8b8000 - 0x1df8bafff liblog_network.dylib arm64  <331cc2c0fc3237aea38af49702e318fd> /usr/lib/log/liblog_network.dylib
0x1df8ca000 - 0x1df8d9fff libswiftAVFoundation.dylib arm64  <f6c94e8fc06a3bee900d6e1005f79a79> /usr/lib/swift/libswiftAVFoundation.dylib
0x1df93e000 - 0x1df94afff libswiftCoreAudio.dylib arm64  <b592a969021d36bbacada028a20e50ad> /usr/lib/swift/libswiftCoreAudio.dylib
0x1df953000 - 0x1df957fff libswiftCoreFoundation.dylib arm64  <95f4aa43717e35ed8455f1f98a41d718> /usr/lib/swift/libswiftCoreFoundation.dylib
0x1df958000 - 0x1df966fff libswiftCoreGraphics.dylib arm64  <6a3a6ef138423e4cad5e634184b7ed1c> /usr/lib/swift/libswiftCoreGraphics.dylib
0x1df967000 - 0x1df96bfff libswiftCoreImage.dylib arm64  <5667910aa13f374a8d4b562110880561> /usr/lib/swift/libswiftCoreImage.dylib
0x1df96c000 - 0x1df972fff libswiftCoreLocation.dylib arm64  <3aa2846d79dd33cbaf7f052f26c4670c> /usr/lib/swift/libswiftCoreLocation.dylib
0x1df973000 - 0x1df97cfff libswiftCoreMIDI.dylib arm64  <8a5e058bc53d3c078874697b119441e0> /usr/lib/swift/libswiftCoreMIDI.dylib
0x1df97d000 - 0x1df9b6fff libswiftCoreMedia.dylib arm64  <d34dc3b537293cd585ac046077ee9cda> /usr/lib/swift/libswiftCoreMedia.dylib
0x1df9b7000 - 0x1df9c0fff libswiftDarwin.dylib arm64  <3d54fb1adeda33e4ba691b56bddf23d8> /usr/lib/swift/libswiftDarwin.dylib
0x1df9c1000 - 0x1df9dafff libswiftDispatch.dylib arm64  <96f8dbd7431c38ec9b6436e82a2c3a36> /usr/lib/swift/libswiftDispatch.dylib
0x1df9db000 - 0x1dfb48fff libswiftFoundation.dylib arm64  <8b541f9dd90234288dfaea18559508b2> /usr/lib/swift/libswiftFoundation.dylib
0x1dfb85000 - 0x1dfb8cfff libswiftMetal.dylib arm64  <23a9ea2bb79e33518d47c8ef06b87ca0> /usr/lib/swift/libswiftMetal.dylib
0x1dfbfc000 - 0x1dfc02fff libswiftObjectiveC.dylib arm64  <8433a4b12ec035638806cb4be16007bb> /usr/lib/swift/libswiftObjectiveC.dylib
0x1dfc03000 - 0x1dfc0cfff libswiftPhotos.dylib arm64  <c8ddc687651730e4a3cfdadc5df5e549> /usr/lib/swift/libswiftPhotos.dylib
0x1dfc0d000 - 0x1dfc12fff libswiftQuartzCore.dylib arm64  <c53da33c928a3323ab582b5c59b20fd8> /usr/lib/swift/libswiftQuartzCore.dylib
0x1dfc54000 - 0x1dfc6dfff libswiftUIKit.dylib arm64  <d14e6a0abc373717854e10207c781d7a> /usr/lib/swift/libswiftUIKit.dylib
0x1dfc88000 - 0x1dfca3fff libswiftsimd.dylib arm64  <0fc2969b84e73704b291c6a625f0dc5c> /usr/lib/swift/libswiftsimd.dylib
0x1dfca4000 - 0x1dfca9fff libcache.dylib arm64  <f8f9d9c8fa2c341f9f6ba0fe985552eb> /usr/lib/system/libcache.dylib
0x1dfcaa000 - 0x1dfcb6fff libcommonCrypto.dylib arm64  <367980207814337795ba9d6fd082d14e> /usr/lib/system/libcommonCrypto.dylib
0x1dfcb7000 - 0x1dfcbbfff libcompiler_rt.dylib arm64  <cd83d9e185c43820a03fd018a7321b2a> /usr/lib/system/libcompiler_rt.dylib
0x1dfd89000 - 0x1dfd89fff liblaunch.dylib arm64  <5e9d917f41d23568889a2d74a12446a9> /usr/lib/system/liblaunch.dylib
0x1dfd8a000 - 0x1dfd8ffff libmacho.dylib arm64  <7e4bdcc5830e33feb1141fcd5abe21aa> /usr/lib/system/libmacho.dylib
0x1dfd90000 - 0x1dfd92fff libremovefile.dylib arm64  <4acd11ced3f83562a5ff9d6896b07164> /usr/lib/system/libremovefile.dylib
0x1dfd93000 - 0x1dfd94fff libsystem_featureflags.dylib arm64  <956d43661dea3dd5a7029b8d345289ca> /usr/lib/system/libsystem_featureflags.dylib
0x1dfd95000 - 0x1dfdc2fff libsystem_m.dylib arm64  <adfc3aac75c0342cb72b2d50d29ef28d> /usr/lib/system/libsystem_m.dylib
0x1dfdc3000 - 0x1dfdc8fff libunwind.dylib arm64  <2ad0d47cf0f53a9f8c140cb8dd009c91> /usr/lib/system/libunwind.dylib
0x1e00a8000 - 0x1e010ffff NanoRegistry arm64  <115719fffc0d394a9516e82dd06f219c> /System/Library/PrivateFrameworks/NanoRegistry.framework/NanoRegistry
0x1e0110000 - 0x1e011dfff NanoPreferencesSync arm64  <d48f6b82db873cd99cb3332f0d4a8f48> /System/Library/PrivateFrameworks/NanoPreferencesSync.framework/NanoPreferencesSync
0x1e0aa3000 - 0x1e0b86fff AGXMetalA9 arm64  <c3748a2f9e0c35afbfcdb1dcce479ec2> /System/Library/Extensions/AGXMetalA9.bundle/AGXMetalA9
0x1e0be4000 - 0x1e0c1dfff CryptoTokenKit arm64  <15782f61144b32ffa99852964437ef46> /System/Library/Frameworks/CryptoTokenKit.framework/CryptoTokenKit
0x1e1b37000 - 0x1e1b55fff AppSSO arm64  <218026c5368839a281410c2a703778c8> /System/Library/PrivateFrameworks/AppSSO.framework/AppSSO
0x1e1b56000 - 0x1e1b6afff AppSSOCore arm64  <a8d86f1c336531a0a7144e8c0e059684> /System/Library/PrivateFrameworks/AppSSOCore.framework/AppSSOCore
0x1e1f63000 - 0x1e1f6dfff PointerUIServices arm64  <0df18b83eb173ca9a87fd1391fdeea49> /System/Library/PrivateFrameworks/PointerUIServices.framework/PointerUIServices
0x1e1f6e000 - 0x1e1ff2fff SafariSharedUI arm64  <07a13071a4f2307e8e6ebacd4f692dd3> /System/Library/PrivateFrameworks/SafariSharedUI.framework/SafariSharedUI

EOF
```",Can you confirm that this is the case?,"**Update**
I just found out that my stack view is full of UITransitionView. It looks like it's related with the GMSMarker:

[https://drive.google.com/open?id=1cFU_rDKWvZtmhGlmwsgvAPlQqaYGmS9t](url)"
Source-Python-Dev-Team/Source.Python,https://github.com/Source-Python-Dev-Team/Source.Python/issues/264,Source-Python-Dev-Team_Source.Python_issues_264,"Set Transmit crashes on certain maps

OS: Linux
Game: CS:GO

Example map that crashes: **trikz_advanced_csgo** 
Download: https://gamebanana.com/maps/170864

```
IMPORTANT: Please copy the full output.
--------------------------------------------------------
Checksum      : 5a60a1bae2f27f62a5aa05e68b7c835b
Date          : 2018-11-20 22:24:42.974079
OS            : Linux-4.15.0-38-generic-x86_64-with-debian-buster-sid
Game          : csgo
SP version    : 667
Github commit : 4b4d6a886456e7f59793af7ca0a9d2f098683b78
Server plugins:
   00: Source.Python, (C) 2012-2018, Source.Python Team.
   01: Metamod:Source 1.10.7-dev
SP plugins:
   00: transmit
--------------------------------------------------------

```

Nothing else was loaded with this code, I made a new file called transmit.py with the only following code 
```python
from entities.hooks import EntityCondition
from entities.hooks import EntityPreHook
from messages import SayText2
from players.entity import Player
from entities import CheckTransmitInfo
from entities.entity import BaseEntity
from memory import make_object
from entities.helpers import index_from_edict

@EntityPreHook(EntityCondition.is_not_player, 'set_transmit')
def pre_set_transmit(args):
        entity = make_object(BaseEntity, args[0])
        edict = make_object(CheckTransmitInfo, args[1]).client

        player = Player(index_from_edict(edict))
        # We always transmit the player to himself. If we don't, bad things happen.
        if player.index == entity.index:
            return None
```
It doesn't matter what EntityCondition is or if I use PreHook instead of EntityPreHook AND it does not matter what is inside the transmit function as long as transmit is hooked. This code crashes my server in many maps, a few maps do work, but I think there must be something wrong with PreHook.",What's the output of ``sp info``? Also please include the imports in future. There is no reason to not include them unless you want to bother me. ;-),"from entities.hooks import EntityCondition
from entities.hooks import EntityPreHook
from messages import SayText2
from players.entity import Player
from entities import CheckTransmitInfo
from entities.entity import BaseEntity
from memory import make_object
from entities.helpers import index_from_edict"
ReactiveX/RxCpp,https://github.com/ReactiveX/RxCpp/issues/533,ReactiveX_RxCpp_issues_533,"Segfault when combine publish/repeat/zip

```cpp
auto s = rxcpp::observable<>::just(1).publish();

rxcpp::observable<>::from(1,2,3,4)
	.zip(s.repeat())
	.subscribe([](std::tuple<int, int> const&){});

s.connect();
```
or
```cpp
auto s = rxcpp::observable<>::just(1).publish();

rxcpp::observable<>::from(1,2,3,4)
	.merge(s.repeat().take(4))
	.subscribe([](int){});

s.connect();
```
v4.1.0

Without publish/connect this code works as expected.

In real life i have one shared resource s (as shared_ptr), and zip it with several task contexts. Maybe i doing something wrong, and this is expected behavior?

My environment:
```
▶ uname -a
Darwin macbook-4106 19.3.0 Darwin Kernel Version 19.3.0: Thu Jan  9 20:58:23 PST 2020; root:xnu-6153.81.5~1/RELEASE_X86_64 x86_64
▶ /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ --version
Apple clang version 11.0.0 (clang-1100.0.33.12)
```",Do you have full code example that can be compiled?,"My environment:
```
▶ uname -a
Darwin macbook-4106 19.3.0 Darwin Kernel Version 19.3.0: Thu Jan  9 20:58:23 PST 2020; root:xnu-6153.81.5~1/RELEASE_X86_64 x86_64
▶ /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ --version
Apple clang version 11.0.0 (clang-1100.0.33.12)
```"
msiemens/tinydb,https://github.com/msiemens/tinydb/issues/261,msiemens_tinydb_issues_261,"Can't ""remove"" with a working query

Hello!
Just picked up tinydb recently, but I got some troubles removing some entries.
A query that works for search doesn't work for removing.

```
>>> s.db.search(s.key.network.id == '114')
[{'network': {'id': '114', 'name': 'ok', 'rpc': 'dac', 'ticker': 'mkay'}}]
>>> s.db.remove(s.key.network)
[]
>>> s.db.search(s.key.network.id == '114')
[{'network': {'id': '114', 'name': 'ok', 'rpc': 'dac', 'ticker': 'mkay'}}]
```

-----------

using v. 3.12.2
no special configuration, just a json file storage",What's the content of the `s.key.network.id` and `s.key.networks` variables you use?,"no speci configuration, just a json fi"
strongloop/loopback-connector-postgresql,https://github.com/strongloop/loopback-connector-postgresql/issues/396,strongloop_loopback-connector-postgresql_issues_396,"invalid input syntax for type json when use repository.updateById()

# Description/Steps to reproduce

When the dataType is JSON or JSONB and use repository.updateById() can't add the new array in database, but work normaly if use repository.replaceById()

Model: 
```
@property({
    type: 'array',
    itemType: 'object',
    postgresql: {
      dataType: 'jsonb'
    },
    required: true,
  })
  test: AnyObject[];
```
Controller: 
```
await this.testRepository.updateById(test_id, test);
```
Response:
```
invalid input syntax for type json
```
# Sandbox
https://github.com/zzhenryquezz/bug-update-arrya-jsonb

# Expected result
Update the array jsonb in Postgres Database

# Additional information
Maybe is something related in the parse to JSON of the method updateById()

# Edit: Steps to reproduce

1 - First config a postgres database in json connector

![example-dbconfig](https://user-images.githubusercontent.com/43827016/70124725-2a3e2080-1654-11ea-8414-b476db228486.png)

2 - Create a dummy data for the tests using the POST endpoint

![example-post](https://user-images.githubusercontent.com/43827016/70124764-3f1ab400-1654-11ea-92bc-b2fc49878934.png)

3 - Try update one entity using the PATH endpoint
![example-update](https://user-images.githubusercontent.com/43827016/70124837-5fe30980-1654-11ea-90ea-2993fde76cf7.png)



4 - This will trigger a Internar server error and also a error log in console
![example-console-error](https://user-images.githubusercontent.com/43827016/70124881-77ba8d80-1654-11ea-9fc3-caa5271f99f8.png)",What do you think?,"# Steps to reproduce

1 - First config a postgres database in json connector

![example-dbconfig](https://user-images.githubusercontent.com/43827016/70124725-2a3e2080-1654-11ea-8414-b476db228486.png)

2 - Create a dummy data for the tests using the POST endpoint

![example-post](https://user-images.githubusercontent.com/43827016/70124764-3f1ab400-1654-11ea-92bc-b2fc49878934.png)

3 - Try update one entity using the PATH endpoint
![example-update](https://user-images.githubusercontent.com/43827016/70124837-5fe30980-1654-11ea-90ea-2993fde76cf7.png)



4 - This will trigger a Internar server error and also a error log in console
![example-console-error](https://user-images.githubusercontent.com/43827016/70124881-77ba8d80-1654-11ea-9fc3-caa5271f99f8.png)"
dart-lang/protobuf,https://github.com/dart-lang/protobuf/issues/219,dart-lang_protobuf_issues_219,"Generate `bytes` with `Uint8List`

Ref: https://groups.google.com/a/dartlang.org/forum/#!topic/misc/JpNkRRLI9_w, https://github.com/Daegalus/dart-uuid/issues/35

More and more packages are explicitly switching to Uint8List

Right now, with the folling proto
```proto
message BluetoothCharacteristic {
  bytes value = 6;
}
```

The generated dart code (by `Activated protoc_plugin 16.0.1.`) is 
```dart
import 'dart:core' show int, bool, double, String, List, Map, override;

import 'package:protobuf/protobuf.dart' as $pb;

class BluetoothCharacteristic extends $pb.GeneratedMessage {
  static final $pb.BuilderInfo _i = new $pb.BuilderInfo('BluetoothCharacteristic')
    ..a<List<int>>(6, 'value', $pb.PbFieldType.OY)
    ..hasRequiredFields = false
  ;

  BluetoothCharacteristic() : super();
  BluetoothCharacteristic.fromBuffer(List<int> i, [$pb.ExtensionRegistry r = $pb.ExtensionRegistry.EMPTY]) : super.fromBuffer(i, r);
  BluetoothCharacteristic.fromJson(String i, [$pb.ExtensionRegistry r = $pb.ExtensionRegistry.EMPTY]) : super.fromJson(i, r);
  BluetoothCharacteristic clone() => new BluetoothCharacteristic()..mergeFromMessage(this);
  BluetoothCharacteristic copyWith(void Function(BluetoothCharacteristic) updates) => super.copyWith((message) => updates(message as BluetoothCharacteristic));
  $pb.BuilderInfo get info_ => _i;
  static BluetoothCharacteristic create() => new BluetoothCharacteristic();
  BluetoothCharacteristic createEmptyInstance() => create();
  static $pb.PbList<BluetoothCharacteristic> createRepeated() => new $pb.PbList<BluetoothCharacteristic>();
  static BluetoothCharacteristic getDefault() => _defaultInstance ??= create()..freeze();
  static BluetoothCharacteristic _defaultInstance;

  List<int> get value => $_getN(0);
  set value(List<int> v) { $_setBytes(0, v); }
  bool hasValue() => $_has(0);
  void clearValue() => clearField(6);
}
```

We can see that we still have
```dart
  List<int> get value => $_getN(0);
  set value(List<int> v) { $_setBytes(0, v); }
```

Expected generated code:
```dart
  Uint8List get value => $_getN(0);
  set value(Uint8List v) { $_setBytes(0, v); }
```

One concern might be that this is more or less a breaking change in strong mode.","Can you be more specific?
`GeneratedMessage.writeToBuffer` already returns a `Uint8List`.","Right now, with the folling proto
```
message BluetoothCharacteristic {
  bytes value = 6;
}
```

The generated dart code (by `Activated protoc_plugin 16.0.1.`) is 
```
import 'dart:core' show int, bool, double, String, List, Map, override;

import 'package:protobuf/protobuf.dart' as $pb;

class BluetoothCharacteristic extends $pb.GeneratedMessage {
  static final $pb.BuilderInfo _i = new $pb.BuilderInfo('BluetoothCharacteristic')
    ..a<List<int>>(6, 'value', $pb.PbFieldType.OY)
    ..hasRequiredFields = false
  ;

  BluetoothCharacteristic() : super();
  BluetoothCharacteristic.fromBuffer(List<int> i, [$pb.ExtensionRegistry r = $pb.ExtensionRegistry.EMPTY]) : super.fromBuffer(i, r);
  BluetoothCharacteristic.fromJson(String i, [$pb.ExtensionRegistry r = $pb.ExtensionRegistry.EMPTY]) : super.fromJson(i, r);
  BluetoothCharacteristic clone() => new BluetoothCharacteristic()..mergeFromMessage(this);
  BluetoothCharacteristic copyWith(void Function(BluetoothCharacteristic) updates) => super.copyWith((message) => updates(message as BluetoothCharacteristic));
  $pb.BuilderInfo get info_ => _i;
  static BluetoothCharacteristic create() => new BluetoothCharacteristic();
  BluetoothCharacteristic createEmptyInstance() => create();
  static $pb.PbList<BluetoothCharacteristic> createRepeated() => new $pb.PbList<BluetoothCharacteristic>();
  static BluetoothCharacteristic getDefault() => _defaultInstance ??= create()..freeze();
  static BluetoothCharacteristic _defaultInstance;

  List<int> get value => $_getN(0);
  set value(List<int> v) { $_setBytes(0, v); }
  bool hasValue() => $_has(0);
  void clearValue() => clearField(6);
}
```

We can see that we still have
```
  List<int> get value => $_getN(0);
  set value(List<int> v) { $_setBytes(0, v); }
```"
pa11y/pa11y-dashboard,https://github.com/pa11y/pa11y-dashboard/issues/231,pa11y_pa11y-dashboard_issues_231,"How to view log of pa11y dashboard

How to view log of pa11y dashboard","Could you please describe the problem that you're having?

Thanks.",How to view log of pa11y dashboard
phetsims/ph-scale,https://github.com/phetsims/ph-scale/issues/160,phetsims_ph-scale_issues_160,"home screen buttons don't behave correctly on touch devices

For https://github.com/phetsims/QA/issues/487 Found on Safari 13 iPadOS 13.4, but occurs on any touch screen.
On published sim, when on the home screen you have to tap an icon to make it bigger, then tap again to enter that screen. In this sim, it seems to enter with only one tap and does not make the icon in question bigger.
![pushbutton](https://user-images.githubusercontent.com/41024075/78721099-23fed000-78e4-11ea-9c6c-98c0c0d85527.gif)

Steps:
1. Go to the sim with a touch device
2. Click the second or third screen icon (one of the small ones)","Why do I see frames of the Number Line sim? The GIFs are nice, but steps to reproduce are always appreciated.","Steps:
1. Go to the sim with a touch device
2. Click the second or third screen icon (one of the small ones)"
kwin-scripts/kwin-tiling,https://github.com/kwin-scripts/kwin-tiling/issues/79,kwin-scripts_kwin-tiling_issues_79,"No config options

I'm trying to use this script under plasma 5.9.2. I managed to install it and it seems to be working fine, except for the fact that there is no settings option and I can't get into the GUI. Anyone else having this problem?

Edit by @laloch: The solution is documented in the [Troubleshooting section](https://github.com/kwin-scripts/kwin-tiling#troubleshooting) of the README.",Do you have any other scripts that do show configuration settings? Do you have `/usr/lib/qt/plugins/kwin/effects/configs/kcm_kwin4_genericscripted.so`? Or do you have a similarly named file in another directory?,Edit by @laloch: The solution is documented in the [Troubleshooting section](https://github.com/kwin-scripts/kwin-tiling#troubleshooting) of the README.
kframework/c-semantics,https://github.com/kframework/c-semantics/issues/325,kframework_c-semantics_issues_325,"kcc can't compile FFmpeg

#kcc can't compile ff-mpeg and for the first error:
#XXXXXXXX wrong error rax.c[202:16-23] : syntax error Translation failed (kcc_config dumped).<------
#------>error should be Translation failed. To repeat.....
#I created a minimized input to reproduce it 
wget https://raw.githubusercontent.com/Lycbel/cs510Files/master/report4/report_ffmpeg/report.sh
bash report.sh",What's at `rax.c[202:16-23]`?,"XXXXXXXX wrong error <------
#------>error should be Translation failed. To repeat....."
NREL/OpenStudio-server,https://github.com/NREL/OpenStudio-server/issues/348,NREL_OpenStudio-server_issues_348,"memfix.rb kills download process

Please see https://github.com/NREL/OpenStudio-server/issues/348#issuecomment-396321854 for more details.

The file is being sent using Rail's send_file https://github.com/NREL/OpenStudio-server/blob/pad_nrcan_2.4.3/server/app/controllers/analyses_controller.rb#L732

nginx.conf file: https://github.com/NREL/OpenStudio-server/blob/pad_nrcan_2.4.3/docker/server/nginx.conf

The download file is about 930 MB, and it is being killed after approximately 10 to 12 minutes.

From nginx error log from `var/log/nginx/error.log`
```
App 7073 stdout:
App 6913 stderr: [ 2018-06-08 19:42:44.8914 7073/0x00000002851b30(Worker 1) utils.rb:87 ]: *** Exception IOError (stream closed) (process 7073, thread 0x00000002851b30(Worker 1)):
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler/thread_handler.rb:136:in `accept'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler/thread_handler.rb:136:in `accept_and_process_next_request'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler/thread_handler.rb:113:in `main_loop'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler.rb:416:in `block (3 levels) in start_threads'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/utils.rb:113:in `block in create_thread_and_abort_on_exception'
App 6913 stderr: [ 2018-06-08 19:42:44.8921 7073/0x00000002891460(HTTP helper worker) utils.rb:87 ]: *** Exception IOError (stream closed) (process 7073, thread 0x00000002891460(HTTP helper worker)):
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler/thread_handler.rb:136:in `accept'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler/thread_handler.rb:136:in `accept_and_process_next_request'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler/thread_handler.rb:113:in `main_loop'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/request_handler.rb:431:in `block (2 levels) in start_threads'
App 6913 stderr:        from /usr/local/lib/ruby/gems/2.2.0/gems/passenger-5.0.25/src/ruby_supportlib/phusion_passenger/utils.rb:113:in `block in create_thread_and_abort_on_exception'
[ 2018-06-08 19:42:47.0085 6645/7fd86cedc700 age/Cor/App/Poo/AnalyticsCollection.cpp:105 ]: Process (pid=6939, group=/opt/openstudio/server/public (docker)) no longer exists! Detaching it from the pool.
[ 2018-06-08 19:42:47.0085 6645/7fd86cedc700 age/Cor/App/Poo/AnalyticsCollection.cpp:105 ]: Process (pid=7073, group=/opt/openstudio/server/public (docker)) no longer exists! Detaching it from the pool.
[ 2018-06-08 19:42:47.0086 6645/7fd86cedc700 age/Cor/CoreMain.cpp:794 ]: Checking whether to disconnect long-running connections for process 6939, application /opt/openstudio/server/public (docker)
[ 2018-06-08 19:42:47.0091 6645/7fd86cedc700 age/Cor/CoreMain.cpp:794 ]: Checking whether to disconnect long-running connections for process 7073, application /opt/openstudio/server/public (docker)
App 7390 stdout:
App 7414 stdout:
[ 2018-06-08 19:43:26.7031 6645/7fd864e05700 age/Cor/Con/ForwardResponse.cpp:189 ]: [Client 3-1] Application sent EOF before finishing response body: 292753984 bytes already read, 976077852 bytes expected
[ 2018-06-08 19:43:26.7031 6645/7fd864e05700 Ser/Server.h:937 ]: [Client 3-1] Disconnecting client with error: application did not send a complete response
```


nginx access log from `/var/log/nginx/access.log`
```
10.255.0.2 - - [08/Jun/2018:19:25:57 +0000] ""GET /favicon.ico HTTP/1.1"" 200 0 ""-"" ""Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:46.0) Gecko/20100101 Firefox/46.0""
10.255.0.2 - - [08/Jun/2018:19:30:10 +0000] ""GET /analyses/71cb4da9-4631-4c5a-8226-bc9e3839302c/download_BTAP_results_zip HTTP/1.1"" 200 282753274 ""http://ec2-XX-XXX-XX-XXX.compute-1.amazonaws.com/"" ""Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:46.0) Gecko/20100101 Firefox/46.0""
10.255.0.2 - - [08/Jun/2018:19:30:43 +0000] ""GET /analyses/71cb4da9-4631-4c5a-8226-bc9e3839302c/download_BTAP_results_zip HTTP/1.1"" 200 33050 ""http://ec2-XX-XXX-XX-XXX.compute-1.amazonaws.com/"" ""Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:46.0) Gecko/20100101 Firefox/46.0""
10.255.0.2 - - [08/Jun/2018:19:43:27 +0000] ""GET /analyses/71cb4da9-4631-4c5a-8226-bc9e3839302c/download_BTAP_results_zip HTTP/1.1"" 200 292619770 ""-"" ""Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 Safari/537.36""
10.255.0.2 - - [08/Jun/2018:19:51:54 +0000] ""GET / HTTP/1.1"" 200 11839 ""-"" ""Mozilla/5.0 (Windows NT 6.2;en-US) AppleWebKit/537.32.36 (KHTML, live Gecko) Chrome/57.0.3070.92 Safari/537.32""
`","Did I miss something?

https://github.com/NREL/OpenStudio-server/pull/347 

Nick",Please see https://github.com/NREL/OpenStudio-server/issues/348#issuecomment-396321854 for more details.
pixel-saver/pixel-saver,https://github.com/pixel-saver/pixel-saver/issues/177,pixel-saver_pixel-saver_issues_177,"Update GNOME extensions website's zip

""I see that #174 was merged. Can you publish it to GNOME extensions?""

![pending reviews](https://user-images.githubusercontent.com/7817636/70866178-c1657b00-1f66-11ea-996f-c06ad682c01f.png)

Anyone can help approve the patches [here](https://extensions.gnome.org/review/).
Until published,

| Gnome Shell | Latest recommended version (github)                                          |
|-------------|----------------------------------------------------------------------|
| 3.12        | [1.3](https://github.com/deadalnix/pixel-saver/releases/tag/1.3)     |
| 3.14        | [1.5.1](https://github.com/deadalnix/pixel-saver/releases/tag/1.5.1) |
| 3.15        | [1.10](https://github.com/deadalnix/pixel-saver/releases/tag/1.10)   |
| 3.24        | [1.12](https://github.com/deadalnix/pixel-saver/releases/tag/1.12)   |
| 3.26        | [1.14](https://github.com/deadalnix/pixel-saver/releases/tag/1.14)   |
| 3.30        | [1.18](https://github.com/deadalnix/pixel-saver/releases/tag/1.18)   |
| 3.32        | [1.20](https://github.com/deadalnix/pixel-saver/releases/tag/1.20)   |
| 3.34        | [master](https://github.com/deadalnix/pixel-saver)                   |",Will this still show the title when the app menu is removed in the next gnome release?,"""""

![pending reviews](https://user-images.githubusercontent.com/7817636/70866178-c1657b00-1f66-11ea-996f-c06ad682c01f.png)

Anyone can help approve the patches [here](https://extensions.gnome.org/review/).
Until published,

| Gnome Shell | Latest recommended version (github)                                          |
|-------------|----------------------------------------------------------------------|
| 3.12        | [1.3](https://github.com/deadalnix/pixel-saver/releases/tag/1.3)     |
| 3.14        | [1.5.1](https://github.com/deadalnix/pixel-saver/releases/tag/1.5.1) |
| 3.15        | [1.10](https://github.com/deadalnix/pixel-saver/releases/tag/1.10)   |
| 3.24        | [1.12](https://github.com/deadalnix/pixel-saver/releases/tag/1.12)   |
| 3.26        | [1.14](https://github.com/deadalnix/pixel-saver/releases/tag/1.14)   |
| 3.30        | [1.18](https://github.com/deadalnix/pixel-saver/releases/tag/1.18)   |
| 3.32        | [1.20](https://github.com/deadalnix/pixel-saver/releases/tag/1.20)   |
| 3.34        | [master](https://github.com/deadalnix/pixel-saver)                   |"
atom/language-ruby,https://github.com/atom/language-ruby/issues/245,atom_language-ruby_issues_245,"YARD comments no longer syntax highlighted

<!--

Have you read Atom's Code of Conduct? By filing an Issue, you are expected to comply with it, including treating everyone with respect: https://github.com/atom/atom/blob/master/CODE_OF_CONDUCT.md

Do you want to ask a question? Are you looking for support? The Atom message board is the best place for getting support: https://discuss.atom.io

-->

### Prerequisites

* [ ] Put an X between the brackets on this line if you have done all of the following:
    * Reproduced the problem in Safe Mode: http://flight-manual.atom.io/hacking-atom/sections/debugging/#using-safe-mode
    * Followed all applicable steps in the debugging guide: http://flight-manual.atom.io/hacking-atom/sections/debugging/
    * Checked the FAQs on the message board for common solutions: https://discuss.atom.io/c/faq
    * Checked that your issue isn't already filed: https://github.com/issues?utf8=✓&q=is%3Aissue+user%3Aatom
    * Checked that there is not already an Atom package that provides the described functionality: https://atom.io/packages

### Description

YARD comments no longer syntax highlighted

### Steps to Reproduce

Previously, comments would be highlighted:

```ruby
# @return [String] The result
def foobar
  return ""foobar""
end
```


**Expected behavior:**

`@return` would be highlighted, along with other parts of the structured comment.

**Actual behavior:**

It's not highlighted

**Reproduces how often:** 100%

### Versions

1.32.0",Can you please update this issue to follow the template? Thanks!,"Description

YARD comments no longer syntax highlighted

Steps to Reproduce


Expected behavior:

ctual behavior:

It's not highlighted

Reproduces how o"
8p/EightPointsGuzzleBundle,https://github.com/8p/EightPointsGuzzleBundle/issues/235,8p_EightPointsGuzzleBundle_issues_235,"Error:  ""You have requested a non-existent service \""eight_points_guzzle.middleware.profile.mercury_api\""

| Q                | A
| ---------------- | -----
| Symfony version  | 2.8.46
| Bundle version   | 7.4.0

**config.yml**

```
eight_points_guzzle:
    clients:
        myapi_api:
            base_url: ""https://myurl""
            options:
                headers:
                    Content-Type: ""application/json""
                curl:
                    sslversion: 1 # or !php/const:CURL_HTTP_VERSION_1_0 for symfony >= 3.2
```

**config_dev.yml**

```
eight_points_guzzle:
    logging: true
#    profiling: true
    clients:
        myapi_api:
            base_url: ""https://dev-myurl""
            options:
                debug: true
                http_errors: true
```

```
$client   = $this->get('eight_points_guzzle.client.myapi_api');
```

> {""code"":0,""message"":""You have requested a non-existent service \""eight_points_guzzle.middleware.profile.myapi_api\"". Did you mean one of these: \""eight_points_guzzle.client.myapi_api\"", \""eight_points_guzzle.handler_stack.myapi_api\"", \""eight_points_guzzle.middleware.event_dispatch.myapi_api\"", \""eight_points_guzzle.middleware.log.myapi_api\"", \""eight_points_guzzle.middleware.request_time.myapi_api\"", \""eight_points_guzzle.middleware.symfony_log\""?""}



It works fine, when i downgrade the bundle to 7.3.1 version.

@florianpreusner i saw that you post a fix [here](https://github.com/8p/EightPointsGuzzleBundle/issues/165)

Am i missing something?",Could you provide your yaml configuration of guzzle bundle?,"**config.yml**

`eight_points_guzzle:
    clients:
        myapi_api:
            base_url: ""https://myurl""
            options:
                headers:
                    Content-Type: ""application/json""
                curl:
                    sslversion: 1 # or !php/const:CURL_HTTP_VERSION_1_0 for symfony >= 3.2`

**config_dev.yml**

`eight_points_guzzle:
    logging: true
#    profiling: true
    clients:
        myapi_api:
            base_url: ""https://dev-myurl""
            options:
                debug: true
                http_errors: true`"
h5bp/server-configs-apache,https://github.com/h5bp/server-configs-apache/issues/179,h5bp_server-configs-apache_issues_179,"`Feature-Policy` header

When scanning my site through https://securityheaders.com/ I got flagged because I was missing a `Feature-Policy` header: https://scotthelme.co.uk/a-new-security-header-feature-policy/

Would you be interested in adding it to the template? I can make a PR if that's the case.

---

* Paper: https://w3c.github.io/webappsec-feature-policy/
* MDN: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Feature-Policy
* CanIUse: https://caniuse.com/#feat=feature-policy","Does this header follow a published standard?
What is its browser support?","---

* Paper: https://w3c.github.io/webappsec-feature-policy/
* MDN: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Feature-Policy
* CanIUse: https://caniuse.com/#feat=feature-policy"
s-u/Rserve,https://github.com/s-u/Rserve/issues/110,s-u_Rserve_issues_110,"Unable to install

Unable to install in Alpine linux; output:

```
$ R -e ""install.packages('Rserve', repos = 'https://cloud.r-project.org')""

R version 3.5.0 (2018-04-23) -- ""Joy in Playing""
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> install.packages('Rserve', repos = 'https://cloud.r-project.org')
trying URL 'https://cloud.r-project.org/src/contrib/Rserve_1.7-3.tar.gz'
Content type 'application/x-gzip' length 407390 bytes (397 KB)
==================================================
downloaded 397 KB

* installing *source* package ‘Rserve’ ...
** package ‘Rserve’ successfully unpacked and MD5 sums checked
checking whether to compile the server... yes
configure: error: R was configured without --enable-R-shlib or --enable-R-static-lib

*** Rserve requires R (shared or static) library.                       ***
*** Please install R library or compile R with either --enable-R-shlib  ***
*** or --enable-R-static-lib support                                    ***

 Alternatively use --without-server if you wish to build only Rserve client.


ERROR: configuration failed for package ‘Rserve’
* removing ‘/usr/lib/R/library/Rserve’

The downloaded source packages are in
	‘/tmp/RtmpdjKkLf/downloaded_packages’
Updating HTML index of packages in '.Library'
Warning messages:
1: In install.packages(""Rserve"", repos = ""https://cloud.r-project.org"") :
  installation of package ‘Rserve’ had non-zero exit status
2: In file.create(f.tg) :
  cannot create file '/usr/share/doc/R/html/packages.html', reason 'No such file or directory'
3: In make.packages.html(.Library) : cannot update HTML package index
```

You can reproduce by building this `Dockerfile`:

```
FROM alpine

RUN apk add R
RUN R -e ""install.packages('Rserve', repos = 'https://cloud.r-project.org')""
```
via

```
docker build -t rserve .
```

from the same folder as this dockerfile

===
Original message:

Having trouble installing Rserve in an alpine container; I'm getting enable shlib error. Problem is it is enabled per the package build script: https://git.alpinelinux.org/cgit/aports/tree/community/R/APKBUILD#n42

Installing from source gives same problem. I do see `libR.so` in `/usr/lib/R/lib/libR.so`. Is this possible to resolve with configuration? I tried symlinking it to `/usr/lib/libR.so` already

I have an image to play around: `docker run -ti --rm levkuznetsov/rserve:alpine sh` or omit shell and drop into R","Can you, please, file a proper issue? Exact error output, steps to reproduce, expected vs observed behavior...","Unable to install in Alpine linux; output:

```
$ R -e ""install.packages('Rserve', repos = 'https://cloud.r-project.org')""

R version 3.5.0 (2018-04-23) -- ""Joy in Playing""
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> install.packages('Rserve', repos = 'https://cloud.r-project.org')
trying URL 'https://cloud.r-project.org/src/contrib/Rserve_1.7-3.tar.gz'
Content type 'application/x-gzip' length 407390 bytes (397 KB)
==================================================
downloaded 397 KB

* installing *source* package ‘Rserve’ ...
** package ‘Rserve’ successfully unpacked and MD5 sums checked
checking whether to compile the server... yes
configure: error: R was configured without --enable-R-shlib or --enable-R-static-lib

*** Rserve requires R (shared or static) library.                       ***
*** Please install R library or compile R with either --enable-R-shlib  ***
*** or --enable-R-static-lib support                                    ***

 Alternatively use --without-server if you wish to build only Rserve client.


ERROR: configuration failed for package ‘Rserve’
* removing ‘/usr/lib/R/library/Rserve’

The downloaded source packages are in
	‘/tmp/RtmpdjKkLf/downloaded_packages’
Updating HTML index of packages in '.Library'
Warning messages:
1: In install.packages(""Rserve"", repos = ""https://cloud.r-project.org"") :
  installation of package ‘Rserve’ had non-zero exit status
2: In file.create(f.tg) :
  cannot create file '/usr/share/doc/R/html/packages.html', reason 'No such file or directory'
3: In make.packages.html(.Library) : cannot update HTML package index
```

You can reproduce by building this `Dockerfile`:

```
FROM alpine

RUN apk add R
RUN R -e ""install.packages('Rserve', repos = 'https://cloud.r-project.org')""
```
via

```
docker build -t rserve .
```

from the same folder as this dockerfile

===
Original message:"
atom/whitespace,https://github.com/atom/whitespace/issues/185,atom_whitespace_issues_185,"Whitespace stripped from markdown despite settings, doesn't work with `text.md` scope

*Edit by @rsese to describe the larger issue*

As mentioned in https://github.com/atom/whitespace/issues/185#issuecomment-446533137:

> It's not as much that `language-markdown` doesn't respect the setting, but `whitespace` should now also work within the `text.md` scope.

I believe https://github.com/atom/whitespace/pull/177 was supposed to add this functionality so that the whitespace package worked with the `text.md` scope but as mentioned in https://github.com/atom/whitespace/issues/185#issuecomment-448727955 (the author of #177), it looks like it may not have done what was intended.

The result is that if you use `language-markdown` (as in this report), the whitespace package will still strip trailing whitespace on save in Markdown files even if you have `Keep Markdown Line Break Whitespace` enabled.

---

<!--

Have you read Atom's Code of Conduct? By filing an Issue, you are expected to comply with it, including treating everyone with respect: https://github.com/atom/atom/blob/master/CODE_OF_CONDUCT.md

Do you want to ask a question? Are you looking for support? The Atom message board is the best place for getting support: https://discuss.atom.io

-->

### Prerequisites

* [X] Put an X between the brackets on this line if you have done all of the following:
    * Reproduced the problem in Safe Mode: http://flight-manual.atom.io/hacking-atom/sections/debugging/#using-safe-mode
    * Followed all applicable steps in the debugging guide: http://flight-manual.atom.io/hacking-atom/sections/debugging/
    * Checked the FAQs on the message board for common solutions: https://discuss.atom.io/c/faq
    * Checked that your issue isn't already filed: https://github.com/issues?utf8=✓&q=is%3Aissue+user%3Aatom
    * Checked that there is not already an Atom package that provides the described functionality: https://atom.io/packages

### Description

Whitespace is stripping trailing whitespaces in markdown files despited the settings.

*Edit by @rsese: not reproducible in safe mode because it reproduces when you install and use https://atom.io/packages/language-markdown*

### Steps to Reproduce

1. Edit a README.md for a project
2. Put two whitespaces at end of line to indicate a line break.
3. Save the file.

**Expected behavior:** The whitespace at the end of the line are ignored and and not deleted.

**Actual behavior:** The whitespaces are deleted. (The trailing whitespaces in the current line are ignored.) If the option ""Remove Trailing Whitespace"" or the package Whitespace is deactivated, the whitespaces remain.

**Reproduces how often:** 100.0000000%

### Versions

Atom    : 1.33.0
Electron: 2.0.11
Chrome  : 61.0.3163.100
Node    : 8.9.3

Whitespace: 0.37.7

OS: Mac OS Mohave 10.14.1

### Additional Information

I can **not** reproduce the issue running Atom on Debian (Bunsen Labs).",Can you share your settings for `Ignore Whitespace On Current Line` and `Keep Markdown Line Break Whitespace` as well?,"*Edit by @rsese to describe the larger issue*

As mentioned in https://github.com/atom/whitespace/issues/185#issuecomment-446533137:

> It's not as much that `language-markdown` doesn't respect the setting, but `whitespace` should now also work within the `text.md` scope.

I believe https://github.com/atom/whitespace/pull/177 was supposed to add this functionality so that the whitespace package worked with the `text.md` scope but as mentioned in https://github.com/atom/whitespace/issues/185#issuecomment-448727955 (the author of #177), it looks like it may not have done what was intended.

The result is that if you use `language-markdown` (as in this report), the whitespace package will still strip trailing whitespace on save in Markdown files even if you have `Keep Markdown Line Break Whitespace` enabled.

---"
prometheus/statsd_exporter,https://github.com/prometheus/statsd_exporter/issues/186,prometheus_statsd_exporter_issues_186,"Reject invalid metrics/mappings early instead of breaking `/metrics`

When a user submits an invalid metric (such as mapping a counter and a gauge to the same metric name), we do not log anything, but from that point on (until the exporter is restarted) `/metrics` will return a 500. We ought to not accept the second (then invalid) sample at all, and log a descriptive error message instead. This way users do not lose visibility into their other metrics.


Original issue:
=======================

Statsd exporter results an internal error (Showed in Prometheus) when malformed statsd lines are sent. However, this does not show any error in the log as well.

Steps to recreate:

1. Use the statsd package 'hot-shots' (nodejs)
2. Send an 'increment' without specifying the increment number.

`
import {StatsD} from 'hot-shots';
let client  = new StatsD(this.initConfig);
client.increment('adapter.' + adapter + '.errors'); //note the buggy invocation
`
On Prometheus targets, exporter goes to down state. No logs will be shown.",What is the line that hot-shots sends to the exporter?,"When a user submits an invalid metric (such as mapping a counter and a gauge to the same metric name), we do not log anything, but from that point on (until the exporter is restarted) `/metrics` will return a 500. We ought to not accept the second (then invalid) sample at all, and log a descriptive error message instead. This way users do not lose visibility into their other metrics.


Original issue:
======================="
gsuitedevs/python-samples,https://github.com/gsuitedevs/python-samples/issues/38,gsuitedevs_python-samples_issues_38,"KeyError: '_module' error 

I get the below error when running the script ::


PS C:\Users\nhr\Desktop\Gmail_Api> python quickstart.py
Traceback (most recent call last):
  File ""quickstart.py"", line 32, in <module>
    main()
  File ""quickstart.py"", line 14, in main
    creds = store.get()
  File ""C:\Python27\lib\site-packages\oauth2client\client.py"", line 407, in get
    return self.locked_get()
  File ""C:\Python27\lib\site-packages\oauth2client\file.py"", line 54, in locked_get
    credentials = client.Credentials.new_from_json(content)
  File ""C:\Python27\lib\site-packages\oauth2client\client.py"", line 302, in new_from_json
    module_name = data['_module']
KeyError: '_module'


## Steps to Reproduce the Problem

I have followed the sames procedure described in https://developers.google.com/gmail/api/quickstart/python

1. Install Python , PIP and all related modules
2. Enabled GMAIL API and saved the credentials.json file in project directory
2. Installed Google Client Library
4. Copied and Saved the Quickstart.py file in project directory
5. Run the python command to run quickstart.py

These are the files in my project directory:

09/25/2018  07:45 AM    <DIR>          .
09/25/2018  07:45 AM    <DIR>          ..
09/25/2018  07:46 AM    <DIR>          .idea
09/09/2018  09:03 PM               431 client_secret.json
09/09/2018  08:42 PM               431 credentials.json
09/09/2018  08:33 PM             4,285 index.html
09/09/2018  08:40 PM             3,076 index.js
09/09/2018  08:56 PM             1,001 quickstart.py
09/09/2018  08:47 PM               340 token.json
               6 File(s)          9,564 bytes
              


## Specifications

- Python version (`python --version`) : 2.7
- OS (Mac/Linux/Windows) : Windows 10",Can you fill out the steps to reproduce the problem?,I have followed the sames procedure described in https://developers.google.com/gmail/api/quickstart/python
camlp4/camlp4,https://github.com/camlp4/camlp4/issues/152,camlp4_camlp4_issues_152,"can't install campl4@4.07+1 with esy

OS: windows 10
package manager: [esy](https://esy.sh)

log file: https://gist.github.com/Et7f3/2994b5b63106a264f508f84c87dd220a#file-failed_log-txt
minimal repro: https://gist.github.com/Et7f3/2994b5b63106a264f508f84c87dd220a#file-package-json

step to repdroduce:
- install esy
- download package.json in empty folder
- open cmd.exe
- travel to the folder that contain only package.json
- type `esy`

some note:
you can see the graph of dependencies in esy.lock/index.json
the first time it will build ocaml compiler so it is availabel inside esy: but once it is build: it will be faster.
other port it for windows with old OCaml see https://github.com/esy-ocaml/camlp4 I have tried to reproduce theese commits: don't help. From what I see: it only config path variable so others package can use it.
I use esy because it support native workflow with OCaml on windows.

Hello,
I have a project that use camlp4 and when i try to build I get some error.  I have added some information that might be helpful. If you want more info/test I am here.

Edit: esy build project in sandbox for me it is:
X:\usr\root\.esy\3_\b\opam__s__camlp4-opam__c__4.07+1-09660eb8\_build
because I have changed ESY__PREFIX var: if empty it will be %USERPROFILE%\\.esy",Could you try reporting the issue to the esy people?,"Edit: esy build project in sandbox for me it is:
X:\usr\root\.esy\3_\b\opam__s__camlp4-opam__c__4.07+1-09660eb8\_build
because I have changed ESY__PREFIX var: if empty it will be %USERPROFILE%\.esy"
yegor256/xembly,https://github.com/yegor256/xembly/issues/82,yegor256_xembly_issues_82,"non-thread-safe XPathFactory reused in XpathDirective.FACTORY

I believe this reuse of non-thread-safe object by xembly is causing https://github.com/zerocracy/farm/issues/1167#issuecomment-410485364:

```
java.lang.ArrayIndexOutOfBoundsException: 8
	at java.util.ArrayList.add(ArrayList.java:459)
	at net.sf.saxon.functions.FunctionLibraryList.addFunctionLibrary(FunctionLibraryList.java:44)
	at net.sf.saxon.Configuration.getBuiltInExtensionLibraryList(Configuration.java:1388)
	at net.sf.saxon.sxpath.AbstractStaticContext.setDefaultFunctionLibrary(AbstractStaticContext.java:127)
	at net.sf.saxon.xpath.JAXPXPathStaticContext.<init>(JAXPXPathStaticContext.java:56)
	at net.sf.saxon.xpath.XPathEvaluator.<init>(XPathEvaluator.java:71)
	at net.sf.saxon.xpath.XPathFactoryImpl.newXPath(XPathFactoryImpl.java:203)
	at org.xembly.XpathDirective.traditional(XpathDirective.java:138)
	at org.xembly.XpathDirective.exec(XpathDirective.java:98)
	at org.xembly.Xembler.apply(Xembler.java:155)
	at org.xembly.Xembler.dom(Xembler.java:210)
	at org.xembly.Xembler.xml(Xembler.java:256)
	at org.xembly.Xembler.xmlQuietly(Xembler.java:221)
	at com.zerocracy.claims.ClaimOut.postTo(ClaimOut.java:127)
	at com.zerocracy.pm.FootprintTest.lambda$addsInThreads$0(FootprintTest.java:88)
	at com.zerocracy.RunsInThreads.lambda$matchesSafely$0(RunsInThreads.java:90)
	at com.jcabi.log.VerboseCallable.call(VerboseCallable.java:173)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at com.jcabi.log.VerboseThreads$Wrap.run(VerboseThreads.java:221)
	at java.lang.Thread.run(Thread.java:745)
```
As you can see in XPathFactory documentation (https://docs.oracle.com/javase/8/docs/api/javax/xml/xpath/XPathFactory.html), it is not thread-safe and must never be used by more than one thread concurrently.
Xembly stores in the static final attribute `XpathDirective.FACTORY` an instance of such object and reuses it in many operations. Because of this, any multi-threaded application are subject to suffer misbehavior when using Xembly.
The error above is one example of such misbehavior that may happen when using Xembly in more than one thread. In this case this exception occurs on a race condition when calling Xembler.xmlQuietly on different threads, even with the threads using their own Xembler instance (because xembly internally will reuse the same XPathFactory causing the error).",What is the problematic code and why?,"As you can see in XPathFactory documentation (https://docs.oracle.com/javase/8/docs/api/javax/xml/xpath/XPathFactory.html), it is not thread-safe and must never be used by more than one thread concurrently.
Xembly stores in the static final attribute `XpathDirective.FACTORY` an instance of such object and reuses it in many operations. Because of this, any multi-threaded application are subject to suffer misbehavior when using Xembly.
The error above is one example of such misbehavior that may happen when using Xembly in more than one thread. In this case this exception occurs on a race condition when calling Xembler.xmlQuietly on different threads, even with the threads using their own Xembler instance (because xembly internally will reuse the same XPathFactory causing the error)."
electron/rcedit,https://github.com/electron/rcedit/issues/84,electron_rcedit_issues_84,"What DLLs are reqired to run rcedit ?

I really need to use rcedit under wine but it always ends with error : `0009:fixme:ver:GetCurrentPackageId (0x33fe24 (nil)): stub `
But that's alright. This error means, most of times, problem with dll. I'm not using Wine on daily basis so I have lot of things missing in Wine. Can I please have list of required DLLs so I can put them into Wine and finally make it run ?

Thanks

_Moderator's note: Edited to remove language violating the Electron Code of Conduct._","Which version of Wine is this, and what OS are you running it under?

As far as I know, there are no extra DLLs required to run `rcedit`.",_Moderator's note: Edited to remove language violating the Electron Code of Conduct._
reduxframework/redux-framework-4,https://github.com/reduxframework/redux-framework-4/issues/51,reduxframework_redux-framework-4_issues_51,"Redux 4 Global Argument Error

Hi team redux,

I have found an error on the global argument database ( theme_mods, theme_mods_expanded ).
When I add the database like theme_mods or theme_mods_expended, I have found an error on saving of redux options and error is Ajax: warning.
And here is the errors list by actions.

PHP Warning: Illegal offset type in ReduxCore\framework.php on line 661.
PHP Stack trace:
PHP 1. {main}() wp-admin\admin-ajax.php:0
PHP 2. do_action() wp-admin\admin-ajax.php:173
PHP 3. WP_Hook->do_action() wp-includes\plugin.php:465
PHP 4. WP_Hook->apply_filters() wp-includes\class-wp-hook.php:310
PHP 5. Redux_AJAX_Save->save() wp-includes\class-wp-hook.php:286
PHP 6. Redux_Options->validate_options() ReduxCore\inc\classes\class-redux-ajax-save.php:80
PHP 7. ReduxFramework->set() ReduxCore\inc\classes\class-redux-options.php:923

This error was so hard to find out for me. Because I thought that error is in my PHP code. So, I sorted my PHP code so many times.

And the redux version is **4.0.1.9**.

Regard
Themecat_Info","Can you send a support URL, please?

This may have not been tested in the new version of Redux.  ;)",And the redux version is **4.0.1.9**.
bk138/gromit-mpx,https://github.com/bk138/gromit-mpx/issues/81,bk138_gromit-mpx_issues_81,"Hot Keys not working in MX Linux

If i select toggle painting, i enter into painting mode but unable to toggle back to normal mode, because hot key are not working. 

1. Select Gromit-mpx from application menu
2. Complete the What is it and how to use it screens. Apply
3. Select toggle screen from status bar icon
4. toggle back with F9

**Desktop (please complete the following information):**
Gromix-mpx is already packaged in MX-Linux through debian repository",Might this issue be a duplicate?,"If i select toggle painting, i enter into painting mode but unable to toggle back to normal mode, because hot key are not working. 

1. Select Gromit-mpx from application menu
2. Complete the What is it and how to use it screens. Apply
3. Select toggle screen from status bar icon
4. toggle back with F9

**Desktop (please complete the following information):**"
jackpoz/BotFarm,https://github.com/jackpoz/BotFarm/issues/55,jackpoz_BotFarm_issues_55,"Running BotFarm.exe

Hello!
Sorry if that sounds silly. But how to run this great program?
I downloaded from https://ci.appveyor.com/project/jackpoz/botfarm/build/artifacts. Filled all the settings in BotFarm.dll.config and tried to run the program. But it produced this error
![изображение](https://user-images.githubusercontent.com/24715026/81444186-6c2d3e80-917f-11ea-9c11-ea64ffe88a8a.png)


<bountysource-plugin>

---
Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/91525058-running-botfarm-exe?utm_campaign=plugin&utm_content=tracker%2F457221&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F457221&utm_medium=issues&utm_source=github).
</bountysource-plugin>",do you have .NET Core 3.1 installed ? https://dotnet.microsoft.com/download/dotnet-core/3.1,"<bountysource-plugin>

---
Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/91525058-running-botfarm-exe?utm_campaign=plugin&utm_content=tracker%2F457221&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F457221&utm_medium=issues&utm_source=github).
</bountysource-plugin>"
atom/metrics,https://github.com/atom/metrics/issues/102,atom_metrics_issues_102,"Failed to activate the metrics package

*Edit by @rsese to add more specific repro steps and a link to @gmarton's notes*

### Steps to reproduce

1. Install atom-hg (apm install atom-hg)
2. Clone some Mercurial repository e.g. `hg clone https://selenic.com/repo/bloatwatch` (I installed [TortoiseHG](https://tortoisehg.bitbucket.io/) to do this on Windows)
3. Start Atom with that project or add it as a project folder

Reproduced on Windows 10 with Atom 1.32.1 and as noted by @gmarton, doesn't reproduce in 1.29.

See @gmarton's notes (""Took a quick look at both sources there seem to be a conflict between the atom-hg and mertics"") at https://github.com/atom/metrics/issues/102#issuecomment-420023430.

---

[Enter steps to reproduce:]

1. Auto-update Atom from 1.29.0 to 1.30.0
2. Start Atom

**Atom**: 1.30.0 x64
**Electron**: 2.0.5
**OS**: Windows 7 SP1
**Thrown From**: [metrics](https://github.com/atom/metrics) package 1.6.1


### Stack Trace

Failed to activate the metrics package

```
At repository.getOriginURL is not a function

TypeError: repository.getOriginURL is not a function
    at subscriptions.add.atom.project.observeRepositories (~/AppData/Local/atom/app-1.30.0/resources/app/node_modules/metrics/lib/metrics.js:197:49)
    at Project.observeRepositories (~/AppData/Local/atom/app-1.30.0/resources/app/src/project.js:254:15)
    at Object.watchRepositories (~/AppData/Local/atom/app-1.30.0/resources/app/node_modules/metrics/lib/metrics.js:196:47)
    at Object.begin (~/AppData/Local/atom/app-1.30.0/resources/app/node_modules/metrics/lib/metrics.js:88:16)
    at ensureClientId (~/AppData/Local/atom/app-1.30.0/resources/app/node_modules/metrics/lib/metrics.js:29:42)
    at Object.ensureClientId (~/AppData/Local/atom/app-1.30.0/resources/app/node_modules/metrics/lib/metrics.js:106:13)
    at Object.activate (~/AppData/Local/atom/app-1.30.0/resources/app/node_modules/metrics/lib/metrics.js:29:16)
    at Package.activateNow (~/AppData/Local/atom/app-1.30.0/resources/app/src/package.js:230:33)
    at measure (~/AppData/Local/atom/app-1.30.0/resources/app/src/package.js:206:33)
    at Package.measure (~/AppData/Local/atom/app-1.30.0/resources/app/src/package.js:88:25)
    at activationPromise.Promise (~/AppData/Local/atom/app-1.30.0/resources/app/src/package.js:200:20)
    at new Promise (<anonymous>)
    at Package.activate (~/AppData/Local/atom/app-1.30.0/resources/app/src/package.js:198:38)
    at PackageManager.activatePackage (~/AppData/Local/atom/app-1.30.0/resources/app/src/package-manager.js:695:42)
    at config.transactAsync (~/AppData/Local/atom/app-1.30.0/resources/app/src/package-manager.js:670:36)
    at Config.transactAsync (~/AppData/Local/atom/app-1.30.0/resources/app/src/config.js:866:28)
    at PackageManager.activatePackages (~/AppData/Local/atom/app-1.30.0/resources/app/src/package-manager.js:668:23)
    at PackageManager.activate (~/AppData/Local/atom/app-1.30.0/resources/app/src/package-manager.js:647:50)
    at loadStatePromise.loadState.then (~/AppData/Local/atom/app-1.30.0/resources/app/src/atom-environment.js:875:27)
    at <anonymous>
```

### Commands

```
```

### Non-Core Packages

```
atom-hg 2.0.14 
city-lights-syntax 1.1.8 
city-lights-ui 1.5.3 
highlight-selected 0.14.0 
notepad-plus-plus-syntax 0.2.7 
seti-syntax 1.2.0 
seti-ui 1.11.0 
tortoise-hg 1.2.0 
```",Do you have to be working with a Mercurial repository for the error to show?,"*Edit by @rsese to add more specific repro steps and a link to @gmarton's notes*

### Steps to reproduce

1. Install atom-hg (apm install atom-hg)
2. Clone some Mercurial repository e.g. `hg clone https://selenic.com/repo/bloatwatch` (I installed [TortoiseHG](https://tortoisehg.bitbucket.io/) to do this on Windows)
3. Start Atom with that project or add it as a project folder

Reproduced on Windows 10 with Atom 1.32.1 and as noted by @gmarton, doesn't reproduce in 1.29.

See @gmarton's notes (""Took a quick look at both sources there seem to be a conflict between the atom-hg and mertics"") at https://github.com/atom/metrics/issues/102#issuecomment-420023430.

---"
atom/styleguide,https://github.com/atom/styleguide/issues/73,atom_styleguide_issues_73,"Styleguide consuming extensive CPU power

*edit by @rsese: confirmed with @simurai about his comment in https://github.com/atom/styleguide/issues/73#issuecomment-447718297 that we should not render everything by default.*

---

<!--

Have you read Atom's Code of Conduct? By filing an Issue, you are expected to comply with it, including treating everyone with respect: https://github.com/atom/atom/blob/master/CODE_OF_CONDUCT.md

Do you want to ask a question? Are you looking for support? The Atom message board is the best place for getting support: https://discuss.atom.io

-->

### Prerequisites

* [x] Put an X between the brackets on this line if you have done all of the following:
    * Reproduced the problem in Safe Mode: http://flight-manual.atom.io/hacking-atom/sections/debugging/#using-safe-mode
    * Followed all applicable steps in the debugging guide: http://flight-manual.atom.io/hacking-atom/sections/debugging/
    * Checked the FAQs on the message board for common solutions: https://discuss.atom.io/c/faq
    * Checked that your issue isn't already filed: https://github.com/issues?utf8=✓&q=is%3Aissue+user%3Aatom
    * Checked that there is not already an Atom package that provides the described functionality: https://atom.io/packages

### Description

When I open the styleguide, it causes CPU usage to spike to 100%-200% of available CPU power and the framerate drops to a sluggish 10-15 fps, causing Atom to feel slow while editing a document with the Styleguide being shown in a separate pane. This occurs even if nothing is being changed in the viewport.

### Steps to Reproduce

1. Open the styleguide (Styleguide -> Show)
1. Observe CPU usage to go up until Styleguide view is closed

**Expected behavior:**

Opening the Styleguide should have minimal impact on performance, at the very least while no elements are being changed (ie. no spinners are on screen)

**Actual behavior:**

Performance drops significantly with Styleguide open, regardless of what is being shown in viewport.

**Reproduces how often:** All the time

### Versions

```
Atom    : 1.34.0-beta0
Electron: 2.0.14
Chrome  : 61.0.3163.100
Node    : 8.9.3

```

### Additional Information

[Performance profile for the Inspector](https://github.com/atom/styleguide/files/2679261/styleguide-perf-profile.json.zip)

> I think this is caused by the fact that the whole Styleguide is contained within a single `render()` function, so that when the moving elements in the styleguide change they cause re-render of the whole styleguide instead of just those parts which really changed.

> Separating the Styleguide into small, individual components might help, but I am not a web developer so just throwing ideas here. 🤔","Does it help if you ""Collapse All"" rows?

![screen shot 2018-12-17 at 1 16 06 pm](https://user-images.githubusercontent.com/378023/50066243-004edc80-01fe-11e9-8f7c-c29d1cf11313.png)

Might be better if that _would_ be the default and not render everything.","*edit by @rsese: confirmed with @simurai about his comment in https://github.com/atom/styleguide/issues/73#issuecomment-447718297 that we should not render everything by default.*

---"
gizmag/django-fsm-log,https://github.com/gizmag/django-fsm-log/issues/85,gizmag_django-fsm-log_issues_85,"Deleting user object in multiple database environment, raises exception

**Env:**
- Python 2.7
- Django==1.7.10
- django-fsm==2.6.0
- django-fsm-log==1.3.0

**Scenario:**

- A django project with two Apps (**app1** & **app2**).
- We have two databases(DB1, DB2) configured as well (check below DB router configuration). 
- Tables which are part of **app2**, will be created in the DB2. 
   (`python manage.py migrate app2 --database=DB2`)
- And app1 tables in DB1 database, which is a default database.
  (`python manage.py migrate app1`)
- Both DBs have the user, group, permission and auth tables. 
- Installdjango_fsm_log in 2nd DB only (i.e. DB2). 
 (`python manage.py migrate django_fsm_log --database=DB2`)

Now try to delete a user object in the **app1**, This user object is coming from DB1. you will get an Error saying,
`ProgrammingError: (1146, ""Table 'DB1.django_fsm_log_statelog' doesn't exist"")` which is True. 
we don't have that table in DB1 but in DB2.

After investigating we found that it tries to delete `user.statelog__set` and fail.

**Source code** 
DB router configuration: **database_router.py**
```
class DB2Router(object):
    APP_LABEL_LIST = ['app2, 'django_fsm_log']

    def db_for_read(self, model, **hints):
        if model._meta.app_label in self.APP_LABEL_LIST:
            return DB2
        return None

    def db_for_write(self, model, **hints):
        if model._meta.app_label in self.APP_LABEL_LIST:
            return DB2
        return None

    def allow_relation(self, obj1, obj2, **hints):
        if set(self.APP_LABEL_LIST) & set([obj1._meta.app_label, obj2._meta.app_label]):
            return obj1._meta.app_label == obj2._meta.app_label
        return None

    def allow_migrate(self, db, model):
        if model._meta.app_label in self.APP_LABEL_LIST:
            return db == DB2
        return None
```
And in settings
```
DATABASE_ROUTERS = [
    'database_router.DB2Router',
]
```
Even after having database_router configured, it is happening. 
What can be done here? is there any way in our library to remove this constraint or set ON_DELETE attribute dynamically.

**Error Traceback:**

```
File ""/home/local/lib/python2.7/site-packages/django/db/models/base.py"", line 738, in delete
File ""/home/local/lib/python2.7/site-packages/django/db/models/deletion.py"", line 198, in collect
File ""/home/local/lib/python2.7/site-packages/django/db/models/query.py"", line 145, in __nonzero__
File ""/home/local/lib/python2.7/site-packages/django/db/models/query.py"", line 966, in _fetch_all
File ""/home/local/lib/python2.7/site-packages/django/db/models/query.py"", line 265, in iterator
File ""/home/local/lib/python2.7/site-packages/django/db/models/sql/compiler.py"", line 701, in results_iter
File ""/home/local/lib/python2.7/site-packages/django/db/models/sql/compiler.py"", line 787, in execute_sql
File ""/home/local/lib/python2.7/site-packages/django/db/backends/utils.py"", line 65, in execute
File ""/home/local/lib/python2.7/site-packages/django/db/utils.py"", line 94, in __exit__
File ""/home/local/lib/python2.7/site-packages/django/db/backends/utils.py"", line 65, in execute
File ""/home/local/lib/python2.7/site-packages/django/db/backends/mysql/base.py"", line 129, in execute
File ""/home/local/lib/python2.7/site-packages/MySQLdb/cursors.py"", line 205, in execute
File ""/home/local/lib/python2.7/site-packages/MySQLdb/connections.py"", line 36, in defaulterrorhandler
```",Do you have a traceback for when it fails?,"Below is the DB router configuration
```
class DB2Router(object):
    APP_LABEL_LIST = ['app1', 'django_fsm_log']

    def db_for_read(self, model, **hints):
        if model._meta.app_label in self.APP_LABEL_LIST:
            return DB2
        return None

    def db_for_write(self, model, **hints):
        if model._meta.app_label in self.APP_LABEL_LIST:
            return DB2
        return None

    def allow_relation(self, obj1, obj2, **hints):
        if set(self.APP_LABEL_LIST) & set([obj1._meta.app_label, obj2._meta.app_label]):
            return obj1._meta.app_label == obj2._meta.app_label
        return None

    def allow_migrate(self, db, model):
        if model._meta.app_label in self.APP_LABEL_LIST:
            return db == DB2
        return None
```
And in settings
```
DATABASE_ROUTERS = [
    'main.database_router.DB2Router',
]
```"
sabotage-linux/kernel-headers,https://github.com/sabotage-linux/kernel-headers/issues/17,sabotage-linux_kernel-headers_issues_17,"Standby problem with kernel version 5.0.16


    OS: Ubuntu 18.04.2 LTS x86_64
    Kernel: 4.18.0-51-generic
    Shell: fish

I have a problem when I update it for a version 5.0.16, I have a problem of standby yet it is a stable version, why?",did you use the vanilla kernel config of sabotage?,"OS: Ubuntu 18.04.2 LTS x86_64
    Kernel: 4.18.0-51-generic
    Shell: fish"
sindresorhus/detect-indent,https://github.com/sindresorhus/detect-indent/issues/15,sindresorhus_detect-indent_issues_15,"Mixup with files with equal amount of tabs and spaces

<!-- Issuehunt Badges -->

[<img alt=""Issuehunt badges"" src=""https://issuehunt.io/r/sindresorhus/detect-indent/issues/15/badge.svg"" />](https://issuehunt.io/r/sindresorhus/detect-indent/issues/15)

<!-- /Issuehunt Badges -->

I am using this project to write an [extension](https://github.com/Hirse/brackets-detect-indentation) for Brackets and it is working quite well.

However I have noticed one mixup when the file has equal amount of tabs and spaces.

If I have a file like this[1]

```
This file should not change the indentation setting
    1 tab
    1 tab
    4 spaces
    4 spaces
```

I get `{amount: 1, type: ""space"", indent: "" ""}` which is obviously incorrect.
It should either be 4 spaces or 1 tab (or `null`).

[1]: The GitHub parsing seems to make it all spaces, but if edited shows the original formatting.
<!-- Issuehunt content -->



> [fr6](https://issuehunt.io/u/fr6) earned $60.00 by resolving this issue!
> - Checkout the [Issuehunt explorer](https://issuehunt.io/r/sindresorhus/detect-indent/) to discover more funded issues.
> - Need some help from other developers? [Add your repositories](https://issuehunt.io/r/new) on Issuehunt to raise funds.


<!-- /Issuehunt content-->",Can you provide a failing test or an example file that the issue can be reproduced with?,"<!-- Issuehunt Badges -->

[<img alt=""Issuehunt badges"" src=""https://issuehunt.io/r/sindresorhus/detect-indent/issues/15/badge.svg"" />](https://issuehunt.io/r/sindresorhus/detect-indent/issues/15)

<!-- /Issuehunt Badges -->

<!-- Issuehunt content -->



> [fr6](https://issuehunt.io/u/fr6) earned $60.00 by resolving this issue!
> - Checkout the [Issuehunt explorer](https://issuehunt.io/r/sindresorhus/detect-indent/) to discover more funded issues.
> - Need some help from other developers? [Add your repositories](https://issuehunt.io/r/new) on Issuehunt to raise funds.


<!-- /Issuehunt content-->"
