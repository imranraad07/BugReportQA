\section{Related Work}
To our knowledge, the proposed approach is the first effort towards improving the quality of bug reports by asking follow-up questions. Prior research related to this area can be broadly grouped into three main categories including evaluation of bug reports quality, approaches for improving deficient bug reports, and techniques automatically posing follow-up questions in domains external to software engineering field.

%bug report quality (focus first on measuring, then on improving)
\noindent
{\em Analyzing the quality of bug reports.} The quality of user written bug reports is a topic that several researchers have been interested in. Linstead et al. applied Latent Dirichlet Analysis to a large corpus of bug reports to study their semantic coherence~\cite{linstead09mining}, while Huo et al. investigated how the  content of a bug report changes depending on the level of expertise of its author~\cite{Huo2014AnES}. Di Sorbo et al. observed that issues marked as ``won't fix'' often contains numerous errors in their reports~\cite{Sorbo2019WontWF}, while insufficient amount of information supplied within a bug report can lead to developers not being able to reproduce as bug, as noted by Joorabchi et al.~\cite{erfani2014works}.
%Kavaler et al. examined language tendencies of bug reports among different developer groups and GitHub projects~\cite{kavaler2017language}.
Researchers have been extensively investigating the content of bug reports to determine the most useful information leading to locating and fixing buggy code efficiently.
%To this end, Bettenburg et al. proposed techniques for automatically identifying stack traces, code snippets, and other structures in bug reports~\cite{bettenburg08extracting}.
To this end, Davies et al. manually analyzed a corpus of bug reports from four popular open-source projects finding that observable behavior and expected behavior are among the most consistently encountered parts of a bug report~\cite{davies14whats}. Survey of software developers conducted by Sasso et al. reveled that steps to reproduce, test cases and stack traces are the most helpful types of information, however they were also the hardest for users to supply~\cite{sasso2016satisficing}. These finding were confirmed and further expanded in the study of Laukkanen et al. who indicated the importance of application's configuration~\cite{laukkanen2011survey}. Chaparro et al. developed a technique leveraging language patterns to automatically extract observable behavior, expected behavior, and steps to reproduce from a bug report~\cite{chaparro17detecting}. Liu et al. proposed to improve Chaparro's technique by eschewing predefined patterns, instead relying on pre-trained classifier to identify steps to reproduce~\cite{liu2020automated}. Recently, Yu et al. developed a tool, S2RMiner, that extracts steps to reproduce from a bug report with high accuracy~\cite{yu2019s2rminer}.
%Karim et al. identified test cases, code examples, steps to reproduce, expected behavior, and stack traces as initially missing features which are often requested~\cite{Karim2017UnderstandingKF, karim2019identifying}.

\noindent
{\em Improving inadequate bug reports.} Researchers have approached the problem of improving the quality of bug reports from a few different angels. One line of work, with numerous proposed techniques, is to detect duplicate bug reports~\cite{sun2011towards,nguyen2012duplicate,chaparro19reformulating}. Another research avenue is to classify bug reports into valid vs. invalid or easy vs. difficult bug reports~\cite{fan20chaff,zhou2016combining,hooimeijer07modeling}. Researchers have also attempted to automatically improve specific parts of bug reports. Moran et al. provided auto-completion for the steps to reproduce portion of bug reports by leveraging image processing of screenshots taken from the application's UI~\cite{moran15autocompleting}.  Chaparro et al. explored how bug report quality can be improved based on unexpected vocabularies in the steps to reproduce~\cite{Chaparro2019AssessingTQ}. Recently proposed BEE tool, implemented as a GitHub plugin, extracts observable behavior, expected behavior, and steps to reproduce from a bug report in order to alert bug reporters when this information is not provided~\cite{song2020bee}.

\noindent
{\em Automatically posing follow-up questions.} Research on automatic question generation has been applied within a few different domains and applications. One topic of extensive prior research is on generating questions from an existing document, i.e., questions whose answers can be found within the given text~\cite{vanderwende2008importance,rus2011question,zhou2017neural,heilman2010good,duan2017question,du2017learning}. For instance, such generated questions can be used for educational assessment and automation. More recently, researchers have envisioned a future where a user's information need will be satisfied via dialog with a virtual assistant, i.e., follow-up questions that are automatically posed to clarify the user's intent. To this end, Braslavski et al. analyzed clarification question patterns on question-answering (QA) websites in order to understand users behavior, and the types of clarification questions asked~\cite{10.1145/3020165.3022149}. Trienes et al. focused on detecting when the original questions in community QA sites are unclear and clarification questions are needed~\cite{trienes2019identifying}. Qu et al. curated and published a large dataset of question and answers intended to help develop conversational search systems~\cite{10.1145/3209978.3210124}. In Web search, follow-up questions have been used for improving document retrieval for low-quality queries~\cite{10.1145/3366423.3380126,10.1145/3331184.3331265,stoyanchev2014towards}. Targeting information that is missing from a document, Rao et al. used generative adversarial neural networks to automatically generate questions that seek to augment Amazon product reviews~\cite{rao2019answer}. Asking follow-up questions has been explored in several other contexts such as chatbots~\cite{Hancock2019LearningFD}, open domain question answering systems~\cite{de2005implementing, de2003analysis}, search engines~\cite{Ren2020ConversationsWS}, search within a Q\&A forum~\cite{zhang2020chatbot4qr}, and image content~\cite{Mostafazadeh_2016}.
