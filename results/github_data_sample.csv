aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/2070,"Introduced between 1.11.602 and 1.11.603.
Tested with aws-java-sdk-s3.

If you have Environment variable ""HTTP_PROXY"" or ""HTTPS_PROXY"" set without userInfo part of the URI you get a NullPointerException when library is checking if there is a a proxy password as part of the URI.

```
Caused by: java.lang.NullPointerException
	at com.amazonaws.ClientConfiguration.getProxyPasswordEnvironment(ClientConfiguration.java:950)
	at com.amazonaws.ClientConfiguration.getProxyPassword(ClientConfiguration.java:977)
	at com.amazonaws.ClientConfiguration.<init>(ClientConfiguration.java:377)
	at com.amazonaws.client.builder.AwsClientBuilder.resolveClientConfiguration(AwsClientBuilder.java:169)
	at com.amazonaws.client.builder.AwsClientBuilder.access$000(AwsClientBuilder.java:54)
	at com.amazonaws.client.builder.AwsClientBuilder$SyncBuilderParams.<init>(AwsClientBuilder.java:505)
	at com.amazonaws.client.builder.AwsClientBuilder.getSyncClientParams(AwsClientBuilder.java:441)
	at com.amazonaws.client.builder.AwsSyncClientBuilder.build(AwsSyncClientBuilder.java:46)
```

Previously (1.11.602) this was handled in a catch block when accessing `httpProxy.getUserInfo()` that returned null as proxy password if any exception occurred.
While it now in 1.11.603 results in a NullPointerException since `httpProxy.getUserInfo()`is null.

[Code from 1.11.602](https://github.com/aws/aws-sdk-java/blob/1.11.602/aws-java-sdk-core/src/main/java/com/amazonaws/ClientConfiguration.java#L877)

[Code from 1.11.603](https://github.com/aws/aws-sdk-java/blob/1.11.603/aws-java-sdk-core/src/main/java/com/amazonaws/ClientConfiguration.java#L874)

**Introduced with these changes:**
https://github.com/aws/aws-sdk-java/commit/65cd7e62ed4b304f22dfc06cb383c434df28c26e#diff-f91b7dd5b56ee19883f751e608dc43a8


","Why didn't your test suite blow up in 1.11.603 when this bug was introduced?  I wonder what was the worldwide cost of this little bug was.  

_Please_ TDD the API libs if you're not already.","I referenced a test in the project i experienced the issue so that I don't upgrade to a version with this issue, using [System Rules](https://stefanbirkner.github.io/system-rules/#EnvironmentVariables). So it could be added a test similar to this, quite easy since it crashes on initialization of the client."
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1505,"The [document](https://docs.aws.amazon.com/cognito-user-identity-pools/latest/APIReference/API_CreateUserPoolClient.html#CognitoUserPools-CreateUserPoolClient-request-ClientName) shows that we can use custom name. However, it will throw the error ""clientName must contain a scheme"".

 ```
        String userPoolId = ""ap-northeast-1_XXXXXXXX""; //cens user
        String clientName = ""clientName"";

        AWSCognitoIdentityProvider provider = AWSCognitoIdentityProviderClientBuilder.defaultClient();

        CreateUserPoolClientRequest update = new CreateUserPoolClientRequest()
                .withUserPoolId(userPoolId)
                .withClientName(clientName)
                .withAllowedOAuthFlows(OAuthFlowType.Implicit)
                .withAllowedOAuthScopes(""phone"", ""email"", ""openid"");

        provider.createUserPoolClient(update);
```","Could you raise this question on the AWS forums for cognito, and cross-link the thread here so people can find it?","The  AWS forums for cognito for this issue.  I hope that it could be helpful.
[AWS forums for cognito](https://forums.aws.amazon.com/thread.jspa?threadID=275922)


"
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1458,"DynamoDB.batchGetItem tries to update an unmodifiable map under some conditions and throws an UnsupportedOperationException

the requestItems map is updated, but it can come from spec.getUnprocessedKeys()
BatchGetItemSpec.withUnprocessedKeys makes the map unmodifiable

stacktrace:
```
java.lang.UnsupportedOperationException: null
	at java.base/java.util.Collections$UnmodifiableMap.put(Collections.java:1458)
	at com.amazonaws.services.dynamodbv2.document.internal.BatchGetItemImpl.doBatchGetItem(BatchGetItemImpl.java:92)
	at com.amazonaws.services.dynamodbv2.document.internal.BatchGetItemImpl.batchGetItem(BatchGetItemImpl.java:64)
	at com.amazonaws.services.dynamodbv2.document.DynamoDB.batchGetItem(DynamoDB.java:158)
```","Do you have a reproducible test case? Sample code is helpful.
Did this issue happen in the latest version of the SDK?",it happened with version 1.11.253
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1316,"We are getting this error when we try to send messages using the buffered client.

```
Exception in thread ""main"" com.amazonaws.services.sqs.model.AmazonSQSException: The request must contain the parameter MessageGroupId. (Service: AmazonSQS; Status Code: 400; Error Code: InvalidParameterValue; Request ID: eb0020ee-13e6-5792-aa99-72aad3a2832c)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1638)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1303)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1055)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:743)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:717)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)
	at com.amazonaws.services.sqs.AmazonSQSClient.doInvoke(AmazonSQSClient.java:1740)
	at com.amazonaws.services.sqs.AmazonSQSClient.invoke(AmazonSQSClient.java:1716)
	at com.amazonaws.services.sqs.AmazonSQSClient.executeSendMessageBatch(AmazonSQSClient.java:1607)
	at com.amazonaws.services.sqs.AmazonSQSClient.sendMessageBatch(AmazonSQSClient.java:1583)
	at com.amazonaws.services.sqs.buffered.SendQueueBuffer$SendMessageBatchTask.process(SendQueueBuffer.java:512)
	at com.amazonaws.services.sqs.buffered.SendQueueBuffer$OutboundBatchTask.run(SendQueueBuffer.java:443)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

```

If we change to `AmazonSQSAsync` the message is sent successfully.","Can you provide the code you're using to send via sync vs async? The async client delegates to the sync one internally, so I wouldn't expect them to behave differently.

The call to AmazonSQSAsync won't fail immediately, but the future/async handler should eventually received the same exception if you're using the same request.","Exactly, and I was searching about it and found out that there's a pull
request to fix this, but even when I tried to create my custom Object with
the updates from this pull request which is not in master branch yet, I
also got a failure message regarding message-group-id. Then I tried to
override the Bean AmazonSQSAsync to avoid using batch processing and it
worked, but now the performance declined.

You can try to use AmazonSQSAsyncClient, that works fine, instead of using
AmazonSQSBufferedAsyncClient.
However, there's the performance impact using the one that works.



-- 
<https://www.ebanx.com/>
Angela c. pereira
Web Developer
+55 (41) 99863-1250 <+55+(41)+3044-8471>

<https://www.ebanx.com/br>
Privileged and confidential. If this message has been received in error,
notify the sender and delete it.


On Fri, Sep 29, 2017 at 9:31 AM, Neil Rutherford <notifications@github.com>
wrote:

> I'm experiencing this as well, in my case the culprit is the process()
> method in SendMessageBatchTask when using the AmazonSQSBufferedAsyncClient.
> When it converts my SendMessageRequest to a SendMessageBatchRequestEntry it
> doesn't carry across the MessageGroupId or MessageDeduplicationId.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/aws/aws-sdk-java/issues/1316#issuecomment-333113550>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AeKnu1huzCHnF_WWeSEbOzqE6jY4-cqoks5snOMpgaJpZM4Pk3q2>
> .
>
"
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1314,"com.fasterxml.jackson.databind.JsonMappingException: Conflicting setter definitions for property ""principals"": com.amazonaws.auth.policy.Statement#setPrincipals(1 params) vs com.amazonaws.auth.policy.Statement#setPrincipals(1 params)

I'm getting the Exception above when I try to deserialize the lambda Policy:

GetPolicyRequest getPolicyRequest = new GetPolicyRequest()
                    .withFunctionName(lambdaFunction.getFunctionName());
            GetPolicyResult GetPolicyResult = lambdaClient.getPolicy(getPolicyRequest);
            Policy policy = Policy.fromJson(GetPolicyResult.getPolicy()
",Can you provide a complete code example?,"Thanks @shorea, I'm sorry, after seeing your hint above, I looked closer and realized that I was setting the Policy retrieved the function on a class which goes through some custom jackson parsing, using ObjectMapper.  My fault, but thank you for your quick attention to this."
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1181,"We're getting an issue very much like #427 where a download reset is attempted, which fails. The source of the stream is an upload through dropwizard (which is a DataHead.ReadMultiStream); it is then piped through our encryption code using PipedInputStream/PipedOutputStream, and one of our own streams. At no point do we use a BufferedInputStream, nor do we have any streams that suggest markSupported=true.

It seems that the exception is happening due to the use of SdkFilterInputStream, which ultimately extends from BufferedInputStream, which comes from wrapping it in a ReleaseableInputStream.

```
AmazonS3Client:
            // When input is a FileInputStream, this wrapping enables
            // unlimited mark-and-reset
            if (input != null)
                input = ReleasableInputStream.wrap(input);
```

```
ReleaseableInputStream:
    public static ReleasableInputStream wrap(InputStream is) {
        if (is instanceof ReleasableInputStream)
            return (ReleasableInputStream)is;   // already wrapped
        if (is instanceof FileInputStream)
            return ResettableInputStream.newResettableInputStream((FileInputStream)is);
        return new ReleasableInputStream(is);
    }
```

```
public class ReleasableInputStream extends SdkFilterInputStream implements Releasable {
```

So, I believe this bug is entirely internal to the S3 client.

```
...
Caused by: com.amazonaws.ResetException: Failed to reset the request input stream;  If the request involves an input stream, the maximum stream buffer size can be configured via request.getRequestClientOptions().setReadLimit(int)
        at com.amazonaws.http.AmazonHttpClient.resetRequestInputStream(AmazonHttpClient.java:996)
        at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:822)
        at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:723)
        at com.amazonaws.http.AmazonHttpClient.doExecute(AmazonHttpClient.java:475)
        at com.amazonaws.http.AmazonHttpClient.executeWithTimer(AmazonHttpClient.java:437)
        at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:386)
        at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3996)
        at com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1570)
        at com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1435)
        at our.package.S3.lambda$putFileAsync$1(S3.java:85)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        ... 1 common frames omitted
Caused by: java.io.IOException: Resetting to invalid mark
        at java.io.BufferedInputStream.reset(BufferedInputStream.java:448)
        at com.amazonaws.internal.SdkBufferedInputStream.reset(SdkBufferedInputStream.java:106)
        at com.amazonaws.internal.SdkFilterInputStream.reset(SdkFilterInputStream.java:102)
        at com.amazonaws.event.ProgressInputStream.reset(ProgressInputStream.java:139)
        at com.amazonaws.internal.SdkFilterInputStream.reset(SdkFilterInputStream.java:102)
        at com.amazonaws.http.AmazonHttpClient.resetRequestInputStream(AmazonHttpClient.java:994)
```",What's the expected behavior? From the way it's described it sounds like the SDK is behaving appropriately. I.E. your source input stream does not support mark/reset so the SDK can't reset it on a retry. ,"@shorea 

The resetRequestInputStream method is this: 

```
    private void resetRequestInputStream(final Request<?> request) throws ResetException {
        InputStream requestInputStream = request.getContent();
        if (requestInputStream != null) {
            if (requestInputStream.markSupported()) {
                try {
                    requestInputStream.reset();
                } catch (IOException ex) {
                    throw new ResetException(""Failed to reset the request input stream"", ex);
                }
            }
        }
    }
```

This is called from inside a while loop in executeHelper, which has this block:

```
} catch (IOException ioe) {
               ...
                if (!shouldRetry(request.getOriginalRequest(), execOneParams, ace,
                        executionContext)) {
                    throw lastReset(ace, request);
                }
```

So somehow my InputStream is getting past the check of shouldRetry rather than just exiting early. "
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1175,"Error message:
```
Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: 67D325E721442841
```

How to reproduce:
1- Create a bucket with all permissions enabled.
2- Enable Requester Pays flag for this bucket
3- Try to download a file using `
Download com.amazonaws.services.s3.transfer.TransferManager.download(GetObjectRequest getObjectRequest, File file)`

Here is a sample code to show the problem:
```
import java.io.*;
import com.amazonaws.auth.*;
import com.amazonaws.services.s3.*;
import com.amazonaws.services.s3.model.*;
import com.amazonaws.services.s3.transfer.*;
import com.amazonaws.util.IOUtils;
public class RequesterPaysTest {
    final static AWSCredentials awsCredentials = new BasicAWSCredentials(MY IAMAccessKey,MY IAMSecretKey);
    final static String bucketName = ""Name of requester pays bucket"";
    final static String fileName = ""Name of a file in this bucket "";
    final static AWSCredentialsProvider awsCredentialsProvider =  new AWSStaticCredentialsProvider(awsCredentials);
    final static AmazonS3 s3client = AmazonS3ClientBuilder.standard().withCredentials(awsCredentialsProvider).withRegion(MY bucketRegion).build();
    final static GetObjectRequest getRequest = new GetObjectRequest(bucketName, fileName, true);

    static void testSimpleRequesterPays() {
        try {
        S3Object object = s3client.getObject(getRequest);
        InputStream objectData = object.getObjectContent();
        FileOutputStream out = new FileOutputStream (new File(fileName));
        IOUtils.copy(objectData, out);
        out.close();
        System.out.println("" Simple RequesterPays successful"");
        } catch (Exception e) {
        System.out.println("" Simple RequesterPays unsuccessful: "" + e.getMessage());
        }
    }
    static void testTransferManagerRequesterPays() {
        try {
            TransferManager tx = TransferManagerBuilder.standard().withS3Client(s3client).build();
            Download download = tx.download(getRequest, new File(fileName));
            while (download.isDone() == false)
                Thread.sleep(10);
            System.out.println("" TransferManager RequesterPays successful"");
        } catch (Exception e) {
        System.out.println("" TransferManager RequesterPays unsuccessful: "" + e.getMessage());
        }
    }
public static void main(String[] args) throws IOException {
    testSimpleRequesterPays();
    testTransferManagerRequesterPays();
}
}
```

Output is:
```
 Simple RequesterPays successful
 TransferManager RequesterPays unsuccessful: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: 67D325E721442841)
```","What is the size of the object you are downloading?
Can you enable wire logging and share it? (DO NOT include Sensitive data)","I am going to collect a wire log with wireshark today (if this is what you meant).
Meanwhile, want to double check what permission you have used. Here is my bucket policy:
```
{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Principal"": {
                ""AWS"": ""*""
            },
            ""Action"": ""*"",
            ""Resource"": ""arn:aws:s3:::MY.BUCKET/*""
        },
        {
            ""Effect"": ""Allow"",
            ""Principal"": {
                ""AWS"": ""*""
            },
            ""Action"": ""*"",
            ""Resource"": ""MY.BUCKET""
        }
    ]
}
```
Also, for this test, make sure that you are using AWS credentials of someone other than bucket owner (lets say another account wants to access your bucket and pays himself)."
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1149,"Isn't this deprecated already?
AmazonSQS sqs = new **AmazonSQSClient(credentials)**;",Why do you ask?,Still I see this being used in aws-sdk-java examples!
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1122,"Currently the following error is thrown when trying to read objects from an S3 bucket with public ACLs:

   ```
   SdkClientException: Unable to load AWS credentials from any provider in the chain
   ```

Would it be possible to add the ability for the SDK to work without credentials? 

The CLI does this through the [`--no-sign-request`](https://github.com/aws/aws-cli/commit/64822485f48d2d0f7916d957ae5fd9e4e68cd907) flag and it looks like something similar will be added to the [Ruby SDK](https://github.com/aws/aws-sdk-ruby/issues/1149).

It would be awesome if the SDK could just work :tm: when there are no credentials available without having to pass it some sort of configuration.","Can you try with the latest?
If issue still exists, give me sample code to reproduce the issue and wire log.
","We were on `1.11.106`. Just tried `1.11.121` and had the same problem.

**Code snippet:**

```scala
val s3Client = AmazonS3ClientBuilder.standard().withRegion(Regions.AP_SOUTHEAST_2).build()
s3Client.getObject(bucketName, filename).getObjectContent
```

**Error:**

```
SdkClientException: Unable to load AWS credentials from any provider in the chain
	at com.amazonaws.auth.AWSCredentialsProviderChain.getCredentials(AWSCredentialsProviderChain.java:131)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.getCredentialsFromContext(AmazonHttpClient.java:1119)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.runBeforeRequestHandlers(AmazonHttpClient.java:759)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:723)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:716)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4187)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4134)
	at com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1385)
	at com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1263)
```

**Edited to remove stray information**"
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/1034,"Cannot provide a full testcase yet as I had to quickly revert the code but something makes the cloudsearch server crash with 1.11.95 and the server replies with a 500 hard and a text/plain message, given it works with 1.11.93, it could be related to some json refactoring present in 1.11.94 ?

```
com.amazonaws.protocol.json.JsonContent: Unable to parse HTTP response content
! com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'Internal': was expecting 'null', 'true', 'false' or NaN  
! at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1586)
! at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:521)
! at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3464)
! at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3442)
! at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._matchToken(UTF8StreamJsonParser.java:2766)
! at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2612)
! at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:854)
! at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:748)
! at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3847)
! at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3792)
! at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:2355)
! at com.amazonaws.protocol.json.JsonContent.parseJsonContent(JsonContent.java:72)
! at com.amazonaws.protocol.json.JsonContent.<init>(JsonContent.java:64)
! at com.amazonaws.protocol.json.JsonContent.createJsonContent(JsonContent.java:54)
! at com.amazonaws.http.JsonErrorResponseHandler.handle(JsonErrorResponseHandler.java:61)
! at com.amazonaws.http.JsonErrorResponseHandler.handle(JsonErrorResponseHandler.java:33)
! at com.amazonaws.http.AwsErrorResponseHandler.handleAse(AwsErrorResponseHandler.java:50)
! at com.amazonaws.http.AwsErrorResponseHandler.handle(AwsErrorResponseHandler.java:38)
! at com.amazonaws.http.AwsErrorResponseHandler.handle(AwsErrorResponseHandler.java:24)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1561)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1249)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1030)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:742)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:716)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)
! at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)
! at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)
! at com.amazonaws.services.cloudsearchdomain.AmazonCloudSearchDomainClient.doInvoke(AmazonCloudSearchDomainClient.java:507)
! at com.amazonaws.services.cloudsearchdomain.AmazonCloudSearchDomainClient.invoke(AmazonCloudSearchDomainClient.java:483)
! at com.amazonaws.services.cloudsearchdomain.AmazonCloudSearchDomainClient.uploadDocuments(AmazonCloudSearchDomainClient.java:447)
```

Cannot paste the content of the json being sent but the answer I get is.

```
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""HTTP/1.1 500 Server Error[\r][\n]""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""Content-Type: text/plain[\r][\n]""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""Date: Fri, 24 Feb 2017 21:23:00 GMT[\r][\n]""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""x-amzn-RequestId: 6b0cea86-fad7-11e6-919e-2b1758bca830[\r][\n]""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""Content-Length: 21[\r][\n]""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""Connection: keep-alive[\r][\n]""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""[\r][\n]""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.wire: http-outgoing-7 << ""Internal Server Error""  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.headers: http-outgoing-7 << HTTP/1.1 500 Server Error  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.headers: http-outgoing-7 << Content-Type: text/plain  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.headers: http-outgoing-7 << Date: Fri, 24 Feb 2017 21:23:00 GMT  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.headers: http-outgoing-7 << x-amzn-RequestId: 6b0cea86-fad7-11e6-919e-2b1758bca830  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.headers: http-outgoing-7 << Content-Length: 21  
16:23:01.954   DEBUG [2017-02-24 21:23:00,277] org.apache.http.headers: http-outgoing-7 << Connection: keep-alive  
```",What content type are you setting? Seems we may be blowing it away with the latest refactoring.,"Was just looking at the request log in details, apparently content-type is not set

```
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""POST /2013-01-01/documents/batch?format=sdk HTTP/1.1[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""Host: xxxxxxxxxxx-k4twi2hvwnwandapy4dho4435q.us-east-1.cloudsearch.amazonaws.com[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""Authorization: AWS4-HMAC-SHA256 Credential=XXXXXXX/20170224/us-east-1/cloudsearch/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-retry;content-length;content-type;host;user-agent;x-amz-date, Signature=63423d51d91964992083a329c41c6695cbe1abd293aa0a562942b715c55b4f47[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""X-Amz-Date: 20170224T212300Z[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""User-Agent: aws-sdk-java/1.11.95 Linux/4.4.44-39.55.amzn1.x86_64 Java_HotSpot(TM)_64-Bit_Server_VM/25.111-b14/1.8.0_111 scala/2.11.8[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""amz-sdk-invocation-id: c8fb41ca-d010-2989-4133-31fed4a74f35[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""amz-sdk-retry: 2/35/460[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""Content-Type: [\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""Content-Length: 149792[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""Connection: Keep-Alive[\r][\n]""  
16:23:03.210   DEBUG [2017-02-24 21:23:00,408] org.apache.http.wire: http-outgoing-7 >> ""[\r][\n]""  
```"
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/896,"With the [parallel downloads feature](https://aws.amazon.com/blogs/developer/parallelizing-large-downloads-for-optimal-speed/) in 1.11.x, it's very easy to deadlock the `TransferManager`'s executor's thread pool by simply submitting a lot of download requests.  All of the executor's threads end up in this sort of state:

```
""s3-transfer-manager-worker-10"" #27 prio=5 os_prio=31 tid=0x00007fa0b3bdd000 nid=0x7903 waiting on condition [0x0000000125530000]
   java.lang.Thread.State: WAITING (parking)
    at sun.misc.Unsafe.park(Native Method)
    - parking to wait for  <0x00000006c07a08f0> (a java.util.concurrent.FutureTask)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:429)
    at java.util.concurrent.FutureTask.get(FutureTask.java:191)
    at com.amazonaws.services.s3.transfer.DownloadCallable.combineFiles(DownloadCallable.java:203)
    at com.amazonaws.services.s3.transfer.DownloadCallable.downloadInParallel(DownloadCallable.java:193)
    at com.amazonaws.services.s3.transfer.DownloadCallable.call(DownloadCallable.java:131)
    at com.amazonaws.services.s3.transfer.DownloadCallable.call(DownloadCallable.java:51)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:744)

   Locked ownable synchronizers:
    - <0x00000006c06ae580> (a java.util.concurrent.ThreadPoolExecutor$Worker)
```

...and none of the executor's threads is actually downloading anything.  Presumably the combineFiles task should be a non-blocking future of some sort.
","Can you explain you download scenario like what is size of the file to download, downloading single/multiple files? I am trying to figure out the case where dead lock can happen.
","I tried it both with a custom thread pool (8 threads) and the default one that the SDK provides.

The code I have is trying to download 69 files, totaling to about 16 GiB, with the same `TransferManager`.   My code works just fine under version 1.10.16, but when I try upgrading to 1.11.44 (specifically for the parallel downloads feature!) the program just hangs after downloading a few files.

My code, as it happens, has some metrics around the transfers.  First I get these warnings, which I don't know if they're relevant:

```
18:14:52.551 [Coordinator 2] INFO  c.p.d.automation.s3.BulkS3Download - Bulk S3 download from s3://my-bucket/common/prefix/for/my/objects to /home/myusername/path/to/download/directory (regexp = ^.*\.csv(/part-\d+)$, metrics-uuid=966c0cf1-dfe7-48ac-adac-4f82ee82e5e8)
Oct 18, 2016 6:15:00 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file01.csv/part-000025315321510609134081.part.1 could not be deleted.
Oct 18, 2016 6:15:01 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file01.csv/part-000003552744014039759453.part.1 could not be deleted.
Oct 18, 2016 6:15:01 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file01.csv/part-00000285658510910860522.part.2 could not be deleted.
18:15:03.216 [Coordinator 2] INFO  c.p.d.automation.s3.BulkS3Download - Downloading 69 files from s3://my-bucket/common/prefix/for/my/objects
Oct 18, 2016 6:15:03 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file01.csv/part-000013847210060239851018.part.1 could not be deleted.
Oct 18, 2016 6:15:04 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file01.csv/part-000012084396428992029528.part.2 could not be deleted.
Oct 18, 2016 6:15:05 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file01.csv/part-000027710304967505190617.part.2 could not be deleted.
Oct 18, 2016 6:15:06 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file02.csv/part-000004575248648125704409.part.1 could not be deleted.
Oct 18, 2016 6:15:06 PM com.amazonaws.services.s3.transfer.DownloadCallable combineFiles
WARNING: The file /home/myusername/path/to/download/directory/subdir01/file02.csv/part-000007141841352462430105.part.2 could not be deleted.
```

Then the download proper starts.  It downloads for a few seconds (as seen from the OS X system monitor's network graph), but it hangs very soon thereafer.  So my metrics reporter just repeatedly logs this out, showing the TransferManager stuck after 8 transfers have started (same as the number of threads in the custom executor)  and only 4 have completed.  (I compute these metrics by attaching `ProgressListener`s to the SDK's `Transfer` objects, and observing the `ProgressEvent`s and `ProgressEventType`s.)

```
18:15:37.569 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=GAUGE, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.fraction-bytes-transferred, value=0.05701729361113557
18:15:37.571 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=GAUGE, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.progress, value=5.70%
18:15:37.571 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=COUNTER, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.total-bytes-to-transfer, count=16580360328
18:15:37.571 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=COUNTER, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.transfers-completed, count=4
18:15:37.571 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=COUNTER, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.transfers-failed, count=0
18:15:37.571 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=COUNTER, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.transfers-started, count=8
18:15:37.571 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=COUNTER, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.transfers-total, count=69
18:15:37.571 [metrics-logger-reporter-2-thread-1] INFO  c.p.d.a.metrics.S3TransferMetrics - type=METER, name=S3TransferMetrics.4b4df776-f11c-443e-82f3-fca12d913a47.bytes-transferred, count=945367273, mean_rate=2.1003752701155223E7, m1=3.752772926092549E7, m5=5.581370025628049E7, m15=5.9619597766520604E7, rate_unit=events/second
```

To me it looks like the following is happening, if I understand things right:
1. Each time I initiate a download with the `TransferManager`, it [submits a  `DownloadCallable` task to its executor](https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-s3/src/main/java/com/amazonaws/services/s3/transfer/TransferManager.java#L1101).
2. This task will itself [submit `DownloadPartCallable` tasks to the same executor](https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-s3/src/main/java/com/amazonaws/services/s3/transfer/DownloadCallable.java#L190).
3. The `DownloadCallable` task then [blocks waiting for its submitted `DownloadPartCallable`s to complete](https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-s3/src/main/java/com/amazonaws/services/s3/transfer/DownloadCallable.java#L203).
4. When the parts download tasks complete, the `DownloadCallable` combines the files.

So with 69 downloads and an executor with only 8 (or the default 10) threads, it's just very easy for the program to end up in a state where all of the executor's 8 threads are running `DownloadCallable`s who've all submitted their `DownloadPartCallable`s and are in a blocking wait for them to complete, but there are no more threads available to actually run the latter.

Solutions I might suggest (which may well be all wrong): 
- Submit the `DownloadCallable`s and `DownloadPartCallable`s to two different executors, so that the former never starve the threads available for the latter.  Downside: if the separate executor for the `DownloadCallable` tasks has a fixed number of threads, only that many downloads can be active at the same time.  If it's an unlimited number of threads, then my code would end up launching 69 threads.
- Rework the `DownloadCallable` so that it doesn't block waiting for the parts to download before it combines them.  Rather, the task to combine the files is triggered asynchronously upon completion of all of the part download `Future`s.  This requires some mechanism like [Guava's `ListenableFuture`](https://github.com/google/guava/wiki/ListenableFutureExplained), [Java 8's `CompletionStage`](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletionStage.html) or [the AWS Java SDK's async callbacks feature](https://aws.amazon.com/articles/Java/5496117154196801).  This is perhaps more complex than the two-executors solution, but it's ""righter"" in some sense (that may or may not matter).
"
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/822,"The code looks like:

``` java
// Used to check if the object is modified between pause and resume
long lastModifiedTime = objectMetadata.getLastModified().getTime();
```

where:

``` java
 /**
     * Gets the value of the Last-Modified header, indicating the date
     * and time at which Amazon S3 last recorded a modification to the
     * associated object.
     *
     * @return The date and time at which Amazon S3 last recorded a modification
     *         to the associated object. Returns <code>null</code> if
     *         the Last-Modified header hasn't been set.
     */
    public Date getLastModified() {
        return cloneDate((Date)metadata.get(Headers.LAST_MODIFIED));
    }
```

Pay attention to the note in the JavaDoc:

> Returns `<code>null</code>` if the Last-Modified header hasn't been set.

Therefore the in the `TransferManager` should be protected against NPE and maybe just returns `0` for the `lastModifiedTime` variable.
","How did you come across this issue? Can you give me a case where LAST_MODIFIED is null.
I was wondering if this may be a documentation bug as [Amazon S3 ](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html#object-metadata) docs points this field is the object creation date or the last modified date, whichever is the latest. So once an object is created, I don't see a way for this field to have a null value.
","Well, my case was enough naive with the Mock test:

```
given(amazonS3.getObjectMetadata(any(GetObjectMetadataRequest.class))).willReturn(new ObjectMetadata());
```

That worked for me, just because I used AWS SDK - 1.10.30. Since there the download logic has been changed.

Right, now I just provide `new Date()` for the `LastModified` property of the `ObjectMetadata`.

I won't mind if that will be fixed on the `ObjectMetadata` level. For example asserting that `Last-Modified` header can't be `null` and so on for JavaDocs.

Thanks
"
aws/aws-sdk-java,https://github.com/aws/aws-sdk-java/issues/812,"The following code will produce a NPE if ~/.aws/credentials does not exist

`
try {
    AWSCredentials credentials = new ProfileCredentialsProvider(""test"").getCredentials();
}
catch (Exception e) {
    e.printStackTrace();
}
`

Resulting in this stacktrace:

`java.lang.NullPointerException
    at com.amazonaws.auth.profile.ProfilesConfigFile.<init>(ProfilesConfigFile.java:143)
    at com.amazonaws.auth.profile.ProfilesConfigFile.<init>(ProfilesConfigFile.java:132)
    at com.amazonaws.auth.profile.ProfilesConfigFile.<init>(ProfilesConfigFile.java:99)
    at com.amazonaws.auth.profile.ProfileCredentialsProvider.getCredentials(ProfileCredentialsProvider.java:135)
    at ProfilesConfigBug.main(ProfilesConfigBug.java:16)
`

This is due to the ctor not checking _file_ argument for null before calling .lastModified()
","What is the version of the SDK that you are using ? We have fixed this. Give it a try with the latest version of the SDK and let us know if you still face issues.
","With 1.11.26 it still fails.  1.11.27 doesn't seem to be available from [https://sdk-for-java.amazonwebservices.com/latest/aws-java-sdk.zip]
"
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1299,"<!--- Provide a general summary of the issue in the Title above -->

## Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->

When retrieving `ObjectVersion` - it should use the appropriate data type that can hold the size attribute. 

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- Include full errors, uncaught exceptions, stack traces, and relevant logs -->
<!--- To turn on SDK logging, follow instructions here: http://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/java-dg-logging.html -->
<!--- If service responses are relevant, please include wirelogs -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->

I receive an `ObjectVersion` with a large size I get - ```java.lang.NumberFormatException: For input string: ""2484911842""``` as it is larger than `Integer.MAX_VALUE`

Full stacktrace:
```
Caused by: java.lang.NumberFormatException: For input string: ""2484911842""
    at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
    at java.base/java.lang.Integer.parseInt(Integer.java:652)
    at java.base/java.lang.Integer.parseInt(Integer.java:770)
    at software.amazon.awssdk.protocols.core.StringToValueConverter$SimpleStringToValue.convert(StringToValueConverter.java:58)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlPayloadUnmarshaller$SimpleTypePayloadUnmarshaller.unmarshall(XmlPayloadUnmarshaller.java:118)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlProtocolUnmarshaller.unmarshall(XmlProtocolUnmarshaller.java:86)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlPayloadUnmarshaller.unmarshallSdkPojo(XmlPayloadUnmarshaller.java:55)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlPayloadUnmarshaller.lambda$unmarshallList$0(XmlPayloadUnmarshaller.java:65)
    at java.base/java.util.ArrayList.forEach(ArrayList.java:1540)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlPayloadUnmarshaller.unmarshallList(XmlPayloadUnmarshaller.java:62)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlProtocolUnmarshaller.unmarshall(XmlProtocolUnmarshaller.java:86)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlProtocolUnmarshaller.unmarshall(XmlProtocolUnmarshaller.java:74)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.XmlProtocolUnmarshaller.unmarshall(XmlProtocolUnmarshaller.java:58)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.AwsXmlResponseHandler.unmarshallResponse(AwsXmlResponseHandler.java:82)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.AwsXmlResponseHandler.handle(AwsXmlResponseHandler.java:61)
    at software.amazon.awssdk.protocols.xml.internal.unmarshall.AwsXmlResponseHandler.handle(AwsXmlResponseHandler.java:41)
    at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler$Crc32ValidationResponseHandler.handle(AwsSyncClientHandler.java:88)
    at software.amazon.awssdk.core.client.handler.BaseClientHandler.lambda$interceptorCalling$2(BaseClientHandler.java:151)
    at software.amazon.awssdk.core.client.handler.AttachHttpMetadataResponseHandler.handle(AttachHttpMetadataResponseHandler.java:40)
    at software.amazon.awssdk.core.client.handler.AttachHttpMetadataResponseHandler.handle(AttachHttpMetadataResponseHandler.java:28)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.handleSuccessResponse(HandleResponseStage.java:89)
    ... 64 more
```

## Possible Solution
<!--- Not required, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement the addition or change -->

Seems very similar to #917 - May need to add a customization for the `ObjectVersion` in `services/s3/src/main/resources/codegen-resources/customization.config`

You may want to review all usages of the Shape size in s3 codegen.

## Steps to Reproduce (for bugs)
<!--- Provide a self-contained, concise snippet of code that can be inserted into a -->
<!--- For more complex issues provide a repo with the smallest sample that reproduces the bug -->
<!--- Including business logic or unrelated code makes diagnosis more difficult -->

Create a file larger than `Integer.MAX_VALUE` in an s3 bucket.
Call the `listObjectVersions` method.

```
s3Client.listObjectVersions(ListObjectVersionsRequest.builder().bucket(bucketName).prefix(prefix).versionIdMarker(versionIdMarker).build())
```

## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

Cannot retrieve Object Versions.

## Your Environment
<!--- Include as many relevant details about the environment where the bug was discovered -->
* AWS Java SDK version used: 2.5.29
* JDK version used: 11.0.3
* Operating System and version: macOS 10.13.6
",Can you try with the latest version?  Feel free to reopen if you have further questions.,
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1297,"<!--- Provide a general summary of the issue in the Title above -->
S3 client could not make PUT request if http protocol is used.
## Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->
The PUT api of S3 client should work well for both http and https protocol. But for http protocol, there is a problem in it. 
## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- Include full errors, uncaught exceptions, stack traces, and relevant logs -->
<!--- To turn on SDK logging, follow instructions here: http://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/java-dg-logging.html -->
<!--- If service responses are relevant, please include wirelogs -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->
I use s3 client to upload files to s3. I set a value which is an http url for endpoint. Then when I invoke the API of `s3Client.putObject`, client side is keeping waiting response from server. 
I have checked the source code of s3 API. If http protocol is used, then the whole payload will be signed,including header and body. So during the process of body signing, the whole stream is read. When the client side lauch a PUT request, at first step, the server respond with 100 continue, then client side should send body to the sever, but the stream has been adready consumed. the client is haning until timeout occur.
## Possible Solution
<!--- Not required, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement the addition or change -->
The code of siging the http request body should be modified.
## Steps to Reproduce (for bugs)
<!--- Provide a self-contained, concise snippet of code that can be inserted into a -->
<!--- For more complex issues provide a repo with the smallest sample that reproduces the bug -->
<!--- Including business logic or unrelated code makes diagnosis more difficult -->

## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

## Your Environment
<!--- Include as many relevant details about the environment where the bug was discovered -->
* AWS Java SDK version used: 
* JDK version used:1.8.0_191
* Operating System and version: centos 7
","What Java SDK version are you using?  
What type of the `InputStream` are you using? Does it support resetting?
Can you provide sample code to reproduce the issue?","@zoewangg 
The jdk version is 1.8.0_191. The aws s3 sdk version  is 2.5.31.
The code is very simple:
```
 S3ClientBuilder builder = S3Client.builder().region(Region.of(config.getRegion()))
                .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))
                .httpClientBuilder(ApacheHttpClient.builder().connectionTimeout(Duration.ofSeconds(30))
                       .connectionMaxIdleTime(Duration.ofSeconds(30)).socketTimeout(Duration.ofSeconds(60)));
 builder = builder.endpointOverride(new URI(""http://xxxxxxx""));
putObjectResponse =
                        s3Client.putObject(putObjectRequest, RequestBody.fromBytes(transferContent.getData()));
```
Maybe there are some missunderstandings here.  I have analyzed the source code of aws sdk: the class of `software.amazon.awssdk.auth.signer.AwsS3V4Signer` and `software.amazon.awssdk.auth.signer.internal.AbstractAws4Signer`.
I did not use any `Inputstream`. The inutputstream I mentioned is used in aws s3 sdk, the `Inputstream` represents the stream data of http request.
It's quite easy to reproduce.

"
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1258,"## Following services artifacts are not found in Maven repo on `mvnrepository.com`:
+ alexaforbusiness, autoscalingplans, chime, cloud9, cloudhsmv2, cloudsearchdomain, comprehend, dlm, eks, fms, glue, guardduty, iot1clickdevices, iot1clickprojects, iotanalytics, iotjobsdataplane, kinesisvideoarchivedmedia, kinesisvideomedia, macie, mediaconvert, medialive, mediapackage, mediatailor, migrationhub, mobile, mq, pi, pinpointemail, pinpointsmsvoice, pricing, ram, resourcegroupstaggingapi, route53domains, route53resolver, sagemaker, sagemakerruntime, servicediscovery, signer, transcribe, transcribestreaming, translate, waf, and workmail.
",Can you try to just import the service you need? It's recommended to just import individual models instead to keep jar size smaller.,"... I think not recommend is not equal to not worked. Anyway, this is the most smart patch I have ever seen, and Are Right A Lot and Bias for Action."
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1171,"Hi all, sorry for the long post but i'm trying to give as most relevant informations as i can. 
All calls with **PinpointAsyncClient** are failing systemically but all works with **PinpointClient**.

_pom.xml_
```
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.2.0.M1</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>software.amazon.awssdk</groupId>
                <artifactId>bom</artifactId>
                <version>2.5.11</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
```

_AWS Config_
```
@Configuration
public class AWSConfig {

    private final AwsConfigurationProperties awsConfigurationProperties;

    @Autowired
    public AWSConfig(AwsConfigurationProperties awsConfigurationProperties) {
        this.awsConfigurationProperties = awsConfigurationProperties;
    }

    private AwsBasicCredentials awsCredentials() {
        return AwsBasicCredentials.create(awsConfigurationProperties.getAccessKey(), awsConfigurationProperties.getSecretKey());
    }

    @Bean
    public SnsAsyncClient amazonSNSClient() {
        return SnsAsyncClient.builder()
                .credentialsProvider(StaticCredentialsProvider.create(awsCredentials()))
                .region(Region.EU_WEST_1)
                .build();
    }


    @Bean
    public S3Client amazonS3Client() {
        return S3Client.builder()
                .credentialsProvider(StaticCredentialsProvider.create(awsCredentials()))
                .region(Region.EU_CENTRAL_1)
                .build();
    }

    @Bean
    public PinpointAsyncClient amazonPinpointClient() {
        return PinpointAsyncClient.builder()
                .credentialsProvider(StaticCredentialsProvider.create(awsCredentials()))
                .region(Region.US_EAST_1)
                .build();
    }

}
```
_Async Config_
```
@Configuration
@EnableAsync
public class ExecutorsConfig {
}
```
_Calls_
```
@Override
@Async
public void sendPush() {
       pinpointAsyncClient.sendUsersMessages(sendUsersMessagesRequest)
                .exceptionally(throwable -> {
                    LOGGER.error(""Failed to deliver push notification "");
                    return null;
                });
    }
```
**Current Behavior**

- When i use a call from PinpointAsyncClient an error occurs.

And here is the stacktrace : 
```
2019-03-20 11:41:05.449  INFO 69862 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 10 ms
2019-03-20 11:41:14.532  WARN 69862 --- [tyEventLoop-1-7] .a.h.n.n.i.UnusedChannelExceptionHandler : A non-I/O exception occurred on a channel (df1c7411) that was not in use. The channel has been closed to prevent any ongoing issues.

io.netty.handler.codec.DecoderException: javax.net.ssl.SSLException: Received fatal alert: handshake_failure
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491) [netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905) [netty-common-4.1.33.Final.jar:4.1.33.Final]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_191]
Caused by: javax.net.ssl.SSLException: Received fatal alert: handshake_failure
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208) ~[na:1.8.0_191]
	at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1647) ~[na:1.8.0_191]
	at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1615) ~[na:1.8.0_191]
	at sun.security.ssl.SSLEngineImpl.recvAlert(SSLEngineImpl.java:1781) ~[na:1.8.0_191]
	at sun.security.ssl.SSLEngineImpl.readRecord(SSLEngineImpl.java:1070) ~[na:1.8.0_191]
	at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:896) ~[na:1.8.0_191]
	at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:766) ~[na:1.8.0_191]
	at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624) ~[na:1.8.0_191]
	at io.netty.handler.ssl.SslHandler$SslEngineType$3.unwrap(SslHandler.java:295) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1301) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	... 15 common frames omitted

2019-03-20 11:41:14.978 ERROR 69862 --- [tyEventLoop-1-4] com.dabchy.api.service.PushService       : Failed to deliver push notification

java.util.concurrent.CompletionException: software.amazon.awssdk.core.exception.SdkClientException
	at software.amazon.awssdk.utils.CompletableFutureUtils.errorAsCompletionException(CompletableFutureUtils.java:61) ~[utils-2.5.11.jar:na]
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncExecutionFailureExceptionReportingStage.lambda$execute$0(AsyncExecutionFailureExceptionReportingStage.java:51) ~[sdk-core-2.5.11.jar:na]
	at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:822) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:797) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) ~[na:1.8.0_191]
	at software.amazon.awssdk.utils.CompletableFutureUtils.lambda$forwardExceptionTo$0(CompletableFutureUtils.java:75) ~[utils-2.5.11.jar:na]
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) ~[na:1.8.0_191]
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.retryErrorIfNeeded(AsyncRetryableStage.java:173) ~[sdk-core-2.5.11.jar:na]
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.retryIfNeeded(AsyncRetryableStage.java:124) ~[sdk-core-2.5.11.jar:na]
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.lambda$execute$0(AsyncRetryableStage.java:105) ~[sdk-core-2.5.11.jar:na]
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) ~[na:1.8.0_191]
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) ~[na:1.8.0_191]
	at software.amazon.awssdk.core.internal.http.pipeline.stages.MakeAsyncHttpRequestStage$ResponseHandler.onError(MakeAsyncHttpRequestStage.java:241) ~[sdk-core-2.5.11.jar:na]
	at software.amazon.awssdk.http.nio.netty.internal.NettyRequestExecutor.handleFailure(NettyRequestExecutor.java:237) ~[netty-nio-client-2.5.11.jar:na]
	at software.amazon.awssdk.http.nio.netty.internal.NettyRequestExecutor.lambda$writeRequest$6(NettyRequestExecutor.java:191) ~[netty-nio-client-2.5.11.jar:na]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.internal.PromiseNotificationUtil.tryFailure(PromiseNotificationUtil.java:64) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:57) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:31) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:834) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.wrapAndFlush(SslHandler.java:797) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.flush(SslHandler.java:778) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.flush(CombinedChannelDuplexHandler.java:533) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelOutboundHandlerAdapter.java:115) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.flush(CombinedChannelDuplexHandler.java:358) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:117) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.logging.LoggingHandler.flush(LoggingHandler.java:265) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:802) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at com.typesafe.netty.http.HttpStreamsHandler.completeBody(HttpStreamsHandler.java:298) ~[netty-reactive-streams-http-2.0.0.jar:na]
	at com.typesafe.netty.http.HttpStreamsHandler.access$400(HttpStreamsHandler.java:14) ~[netty-reactive-streams-http-2.0.0.jar:na]
	at com.typesafe.netty.http.HttpStreamsHandler$3$1.run(HttpStreamsHandler.java:276) ~[netty-reactive-streams-http-2.0.0.jar:na]
	at com.typesafe.netty.http.HttpStreamsHandler.executeInEventLoop(HttpStreamsHandler.java:342) ~[netty-reactive-streams-http-2.0.0.jar:na]
	at com.typesafe.netty.http.HttpStreamsHandler.access$300(HttpStreamsHandler.java:14) ~[netty-reactive-streams-http-2.0.0.jar:na]
	at com.typesafe.netty.http.HttpStreamsHandler$3.complete(HttpStreamsHandler.java:273) ~[netty-reactive-streams-http-2.0.0.jar:na]
	at com.typesafe.netty.HandlerSubscriber$3.operationComplete(HandlerSubscriber.java:244) ~[netty-reactive-streams-2.0.0.jar:na]
	at com.typesafe.netty.HandlerSubscriber$3.operationComplete(HandlerSubscriber.java:241) ~[netty-reactive-streams-2.0.0.jar:na]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.internal.PromiseNotificationUtil.tryFailure(PromiseNotificationUtil.java:64) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:57) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:31) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.internal.PromiseNotificationUtil.tryFailure(PromiseNotificationUtil.java:64) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:57) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:31) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:485) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:121) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.internal.PromiseNotificationUtil.tryFailure(PromiseNotificationUtil.java:64) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:57) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:31) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractCoalescingBufferQueue.releaseAndCompleteAll(AbstractCoalescingBufferQueue.java:340) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractCoalescingBufferQueue.releaseAndFailAll(AbstractCoalescingBufferQueue.java:207) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.releaseAndFailAll(SslHandler.java:1591) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.setHandshakeFailure(SslHandler.java:1585) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.handleUnwrapThrowable(SslHandler.java:1239) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1209) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-codec-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1408) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:677) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:612) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:529) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:491) ~[netty-transport-4.1.33.Final.jar:4.1.33.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905) ~[netty-common-4.1.33.Final.jar:4.1.33.Final]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_191]
Caused by: software.amazon.awssdk.core.exception.SdkClientException: null
	at software.amazon.awssdk.core.exception.SdkClientException$BuilderImpl.build(SdkClientException.java:97) ~[sdk-core-2.5.11.jar:na]
	at software.amazon.awssdk.core.internal.util.ThrowableUtils.asSdkException(ThrowableUtils.java:98) ~[sdk-core-2.5.11.jar:na]
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.retryIfNeeded(AsyncRetryableStage.java:123) ~[sdk-core-2.5.11.jar:na]
	... 96 common frames omitted
Caused by: javax.net.ssl.SSLException: SSLEngine closed already
	at io.netty.handler.ssl.SslHandler.wrap(...)(Unknown Source) ~[netty-handler-4.1.33.Final.jar:4.1.33.Final]
```","Can you tell me what your TPS is? I will try to reproduce the issue.

The first WARNING log can be ignored because the channel was unused. Though we should adjust the logging level to debug for `SSLException`.

For second ERROR log, it could happen when service closes the TLS connection and we should retry the request if this happens(current it doesn't look like it gets retried)","Hi @zoewangg, thank you for your response. What do you mean by TPS?"
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1122,"I have code using the Java SDK to download a few hundred photos from an S3 bucket. The first bunch work but things start to fail around photo number 100. It does not always fail on the same file. It seems very similar to #452 though that issue is closed. Note that I'm using `S3AsyncClient` but downloading the file sequentially, never downloading more than one concurrently.

The photos are about 500KB each.

## Expected Behavior

I should be able to download all the objects in my bucket

## Current Behavior

Am able to download many files but after about 100 requests star to fail. The exception is:

```
java.util.concurrent.CompletionException: software.amazon.awssdk.core.exception.SdkClientException
	at software.amazon.awssdk.utils.CompletableFutureUtils.errorAsCompletionException(CompletableFutureUtils.java:61)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncExecutionFailureExceptionReportingStage.lambda$execute$0(AsyncExecutionFailureExceptionReportingStage.java:50)
	at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:822)
	at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:797)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.retryErrorIfNeeded(AsyncRetryableStage.java:167)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.retryIfNeeded(AsyncRetryableStage.java:118)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.lambda$execute$0(AsyncRetryableStage.java:103)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.MakeAsyncHttpRequestStage$ResponseHandler.onError(MakeAsyncHttpRequestStage.java:241)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.lambda$notifyIfResponseNotCompleted$3(ResponseHandler.java:398)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.runAndLogError(ResponseHandler.java:179)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.notifyIfResponseNotCompleted(ResponseHandler.java:398)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.channelInactive(ResponseHandler.java:148)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.handler.logging.LoggingHandler.channelInactive(LoggingHandler.java:167)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelInactive(CombinedChannelDuplexHandler.java:420)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:390)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355)
	at io.netty.handler.codec.http.HttpClientCodec$Decoder.channelInactive(HttpClientCodec.java:282)
	at io.netty.channel.CombinedChannelDuplexHandler.channelInactive(CombinedChannelDuplexHandler.java:223)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:390)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355)
	at io.netty.handler.ssl.SslHandler.channelInactive(SslHandler.java:1054)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1403)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:912)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:826)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:495)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at java.lang.Thread.run(Thread.java:748)
Caused by: software.amazon.awssdk.core.exception.SdkClientException: null
	at software.amazon.awssdk.core.exception.SdkClientException$BuilderImpl.build(SdkClientException.java:97)
	at software.amazon.awssdk.core.internal.util.ThrowableUtils.asSdkException(ThrowableUtils.java:98)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.retryIfNeeded(AsyncRetryableStage.java:117)
	... 63 common frames omitted
Caused by: java.io.IOException: Server failed to send complete response
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.notifyIfResponseNotCompleted(ResponseHandler.java:397)
	... 54 common frames omitted
```

With full debug logs enabled there's a **ton** of output but the response from the Netty network logs from right before things crash is:

```
11:16:18.311 [aws-java-sdk-NettyEventLoop-1-3] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xffce7082, L:/192.168.0.165:59528 - R:com-revl-revlx.s3.us-west-2.amazonaws.com/52.218.224.248:443] READ: DefaultLastHttpContent(data: PooledSlicedByteBuf(ridx: 0, widx: 254, cap: 254/254, unwrapped: PooledUnsafeDirectByteBuf(ridx: 8446, widx: 8446, cap: 8475)), decoderResult: success), 254B
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 5d 52 e1 13 91 3f b5 10 51 7b 34 f6 79 a0 39 aa |]R...?..Q{4.y.9.|
|00000010| 3a 4d fc ce 3c 68 3b 15 b5 ad 02 63 d4 f7 a0 78 |:M..<h;....c...x|
|00000020| 92 29 39 d5 39 01 a9 44 b9 c6 33 2a 8d 7e 91 f3 |.)9.9..D..3*.~..|
|00000030| 28 ea 71 58 a6 09 25 58 2f a8 4e 94 f1 24 02 65 |(.qX..%X/.N..$.e|
|00000040| a7 b5 48 11 7c 6a 95 05 d2 a8 b0 93 a1 02 d8 57 |..H.|j.........W|
|00000050| 11 04 21 ad 32 b4 2d 94 16 99 af 0e f4 00 41 2a |..!.2.-.......A*|
|00000060| 80 04 55 04 32 94 41 38 93 40 01 11 25 02 94 89 |..U.2.A8.@..%...|
|00000070| 1a 39 2a 2d 84 b0 04 12 d7 2a cd 22 60 a7 34 27 |.9*-.....*.""`.4'|
|00000080| 40 94 0f 0d 0d 53 0d 85 38 5d bb 24 ea af 94 32 |@....S..8].$...2|
|00000090| 84 80 24 ad 3a 63 0c e8 f8 77 85 44 8a a0 14 1a |..$.:c...w.D....|
|000000a0| 02 74 27 51 ab e6 25 02 c6 4e a8 ed 4e 64 68 4a |.t'Q..%..N..NdhJ|
|000000b0| 4e 84 09 cf 8c 7a 0e f4 65 4c f8 2b 00 28 14 f1 |N....z..eL.+.(..|
|000000c0| 98 f0 54 0a a2 a0 24 9b 48 42 2e ed 20 ad ae 53 |..T...$.HB.. ..S|
|000000d0| a8 f0 12 a9 80 9a 05 11 a3 53 2a 72 4f 3d 70 ae |.........S*rO=p.|
|000000e0| 07 9a 61 20 27 e7 8c 27 27 2d 6a a3 ff d9 f2 d3 |..a '..''-j.....|
|000000f0| 22 9e 33 37 d2 2e 06 03 e0 06 a6 fc 72 02       |"".37........r.  |
+--------+-------------------------------------------------+----------------+
11:16:18.312 [aws-java-sdk-NettyEventLoop-1-3] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xffce7082, L:/192.168.0.165:59528 ! R:com-revl-revlx.s3.us-west-2.amazonaws.com/52.218.224.248:443] READ COMPLETE
11:16:18.312 [aws-java-sdk-NettyEventLoop-1-3] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xffce7082, L:/192.168.0.165:59528 ! R:com-revl-revlx.s3.us-west-2.amazonaws.com/52.218.224.248:443] INACTIVE
11:16:18.316 [aws-java-sdk-NettyEventLoop-1-3] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xffce7082, L:/192.168.0.165:59528 ! R:com-revl-revlx.s3.us-west-2.amazonaws.com/52.218.224.248:443] CLOSE
11:16:18.316 [aws-java-sdk-NettyEventLoop-1-3] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xffce7082, L:/192.168.0.165:59528 ! R:com-revl-revlx.s3.us-west-2.amazonaws.com/52.218.224.248:443] UNREGISTERED
```

## Steps to Reproduce (for bugs)

Here is a slightly modified version of the Kotlin code that produces the above (modified to remove company sensitive stuff):

```
object Main {
    val log = getLogger { }

    val s3AsyncClient = S3AsyncClient.builder()
        .credentialsProvider(DefaultCredentialsProvider.create())
        .region(Region.US_WEST_2)
        // retries disable here because we can't retry in our situation - the real use case is to stream
        // data from a server to a customer. Note that you get the same failures even with retries -- it
        // just takes longer
        .overrideConfiguration { config ->
            config.retryPolicy(RetryPolicy.none()).build()
        }
        .build()

    val daBucket = ""com-revl-revlx""

    fun doDownload(key: String) {
        val outFile = Paths.get(""/tmp/experiment/"").resolve(key)
        outFile.parent.toFile().mkdirs()
        if (outFile.toFile().exists()) {
            outFile.toFile().delete()
        }
        log.info(""Downloading via toFile: {}"", key)
        val request = GetObjectRequest.builder()
            .bucket(daBucket)
            .key(key)
            .build()

        val future = s3AsyncClient.getObject(request, AsyncResponseTransformer.toFile(outFile))

        try {
            future.join()
            log.info(""Download of {} succeeded"", key)
        } catch (t: Throwable) {
            log.error(""Download of {} failed with:"", key, t)
            throw t
        }
    }

    @JvmStatic
    fun main(argv: Array<String>) {
        ThreadUtils.setLoggingDefaultExceptionHandler()
        val keys = (1..240).toList()

        var numDone = 1
        for (i in keys) {
            log.info(""Process file number {}"", numDone)
            ++numDone
            val key = String.format(""path/to/photo_%05d.jpg"", i)
            doDownload(key)
        }
    }
}
```


## Context

We provide photos to our customers and are trying to provide a ""download all"" function. To do this we need to stream the data from S3 through some code that incrementally adds it to a zip file which is provided to the customer. Since there's so much data we can't hold it all in RAM so we need to do this async-streaming processing. We have our own `AsyncResponseTransformer` which does this but wanted to provide an example with as little of our code as possible. `AsyncResponseTransformer.toFile` and our code experience the same error.

## Your Environment

* AWS Java SDK version used: 2.5.4
* JDK version used: Kotlin 1.2.71 running on Java 8 JVM
* Operating System and version: have reproduced on Debian Linux Stretch and OSX
","Would v2 sync clients work for you? 

I think this exception would get retried and should succeed in the next attempt, is it not the case for you?

","> Would v2 sync clients work for you?

We could spawn threads and use sync clients. A bit less efficient but would be OK.

> I think this exception would get retried and should succeed in the next attempt, is it not the case for you?

What we see is that with retries enabled this bug is less common but still appears quite often (e.g. every 250 files instead of every 100).

Even if retries did work we can't use them though. Our use case is to create a zip file containing all the data from all of these photos in a streaming way without holding it all in RAM  so retries aren't an option for us; they'd cause a corrupt file because the zip archive would contain part of the file (the part that failed part way through) and then on retry that part of the file would be repeated."
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1109,"<!--- Provide a general summary of the issue in the Title above -->

When killing my Spring WebFlux on Netty app that uses S3AsyncClient the app hangs for 16 seconds.

## Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->

Expect the server to be killed faster than 16 seconds.

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- Include full errors, uncaught exceptions, stack traces, and relevant logs -->
<!--- To turn on SDK logging, follow instructions here: http://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/java-dg-logging.html -->
<!--- If service responses are relevant, please include wirelogs -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->

After timing out the following stack trace is given:


```
02:05:04.281 [Thread-19] ERROR s.a.a.h.n.n.NettyNioAsyncHttpClient - Unable to shutdown event loop
java.lang.RuntimeException: Shutting down Netty EventLoopGroup did not complete within 16 seconds
	at software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient.closeEventLoopUninterruptibly(NettyNioAsyncHttpClient.java:235)
	at software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient.lambda$close$2(NettyNioAsyncHttpClient.java:222)
	at software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient$$Lambda$1600/736839034.run(Unknown Source)
	at software.amazon.awssdk.utils.FunctionalUtils.runAndLogError(FunctionalUtils.java:40)
	at software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient.close(NettyNioAsyncHttpClient.java:221)
	at software.amazon.awssdk.utils.IoUtils.closeQuietly(IoUtils.java:73)
	at software.amazon.awssdk.utils.IoUtils.closeIfCloseable(IoUtils.java:90)
	at software.amazon.awssdk.utils.AttributeMap.lambda$close$0(AttributeMap.java:86)
	at software.amazon.awssdk.utils.AttributeMap$$Lambda$1596/1964394254.accept(Unknown Source)
	at java.util.HashMap$Values.forEach(HashMap.java:972)
	at software.amazon.awssdk.utils.AttributeMap.close(AttributeMap.java:86)
	at software.amazon.awssdk.core.client.config.SdkClientConfiguration.close(SdkClientConfiguration.java:79)
	at software.amazon.awssdk.core.internal.http.HttpClientDependencies.close(HttpClientDependencies.java:88)
	at software.amazon.awssdk.core.internal.http.AmazonAsyncHttpClient.close(AmazonAsyncHttpClient.java:78)
	at software.amazon.awssdk.core.client.handler.BaseAsyncClientHandler.close(BaseAsyncClientHandler.java:138)
	at software.amazon.awssdk.services.s3.DefaultS3AsyncClient.close(DefaultS3AsyncClient.java:3942)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.invokeCustomDestroyMethod(DisposableBeanAdapter.java:337)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:271)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:954)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:961)
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1041)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1017)
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:937)
```

## Steps to Reproduce (for bugs)
<!--- Provide a self-contained, concise snippet of code that can be inserted into a -->
<!--- For more complex issues provide a repo with the smallest sample that reproduces the bug -->
<!--- Including business logic or unrelated code makes diagnosis more difficult -->

* Deploy any Spring WebFlux 2.0.4.RELEASE app locally
* Make a request that uses the S3AsyncClient to populate the response
* Kill the server via control + c

## Your Environment
<!--- Include as many relevant details about the environment where the bug was discovered -->
* AWS Java SDK version used: 2.5.1
* JDK version used: 1.8.0_51
* Operating System and version: MacOS High Sierra 10.13.6
* Spring version: 2.0.4.RELEASE
",Does it happen every time you try to close the client or just occasionally?,Every time.
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1076,"<!--- Provide a general summary of the issue in the Title above -->

## Expected Behavior
When querying for `S3AsyncClient.headBucket` without specifying the region for a bucket that relies somewhere else than us-east-1, I'm expecting to get the proper 400 exception (was working up to 2.3.9)

## Current Behavior
We're getting an `SdkClientException` that is not the result of the http 400 failed response but rather:
```Caused by: java.io.IOException: Server failed to send complete response```

## Steps to Reproduce (for bugs)
```java
HeadBucketResponse response = S3AsyncClient.builder()
    .credentialsProvider(credentialsProvider)
    .build()
    .headBucket(HeadBucketRequest.builder().bucket(""sentinel-inventory"").build())
    .get();
```
Should throw a `S3Exception` and not an `SdkClientException`

<details><summary>Complete Stacktrace</summary>

```
java.util.concurrent.ExecutionException: software.amazon.awssdk.core.exception.SdkClientException

	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
	at com.dd.logs.archive_reloader.planner.client.TestS3Head.test(TestS3Head.java:41)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: software.amazon.awssdk.core.exception.SdkClientException
	at software.amazon.awssdk.core.exception.SdkClientException$BuilderImpl.build(SdkClientException.java:97)
	at software.amazon.awssdk.core.internal.util.ThrowableUtils.asSdkException(ThrowableUtils.java:98)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.retryIfNeeded(AsyncRetryableStage.java:118)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.lambda$execute$0(AsyncRetryableStage.java:104)
	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859)
	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at software.amazon.awssdk.core.internal.http.pipeline.stages.MakeAsyncHttpRequestStage$ResponseHandler.onError(MakeAsyncHttpRequestStage.java:236)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.channelInactive(ResponseHandler.java:139)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.handler.logging.LoggingHandler.channelInactive(LoggingHandler.java:167)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelInactive(CombinedChannelDuplexHandler.java:420)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:390)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355)
	at io.netty.handler.codec.http.HttpClientCodec$Decoder.channelInactive(HttpClientCodec.java:282)
	at io.netty.channel.CombinedChannelDuplexHandler.channelInactive(CombinedChannelDuplexHandler.java:223)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:390)
	at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355)
	at io.netty.handler.ssl.SslHandler.channelInactive(SslHandler.java:1054)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:75)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1429)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:947)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:826)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute$$$capture(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:474)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.io.IOException: Server failed to send complete response
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.channelInactive(ResponseHandler.java:138)
	... 54 more
```
</details>","What is the region for ""sentinel-inventory"" bucket? I will test with a bucket in same region.

* This is an IOException and it interesting that you are seeing it every time. Can you try running the same program in a different machine?
* Are you using a proxy or does you network have policies restricting traffic to certain regions? To eliminate if its a network policy issue, you can try using a different network.","I don't think this is a network issue: it's running fine with version 2.3.9. I don't have a particular network setup.

`sentinel-inventory` is in `eu-central-1` (https://registry.opendata.aws/sentinel-2/ 😉)"
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/1023,"<!--- Provide a general summary of the issue in the Title above -->
When using amazon-kinesis-client, I'm getting
```
Unexpected exception was thrown. This could probably be an issue or a bug. Please search for the exception/error online to check what is going on. If the issue persists or is a recurring problem, feel free to open an issue on, https://github.com/awslabs/amazon-kinesis-client.
```

## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
The `ShardRecordProcessor` fails when reading records from Kinesis stream with
```
java.lang.NumberFormatException: For input string: ""1.547993531819E9""
```

### Stack trace
```
java.lang.NumberFormatException: For input string: ""1.547993531819E9""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ~[?:1.8.0_181]
	at java.lang.Long.parseLong(Long.java:589) ~[?:1.8.0_181]
	at java.lang.Long.parseLong(Long.java:631) ~[?:1.8.0_181]
	at software.amazon.awssdk.utils.DateUtils.parseUnixTimestampMillisInstant(DateUtils.java:146) ~[utils-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.core.StringToInstant.lambda$safeParseDate$0(StringToInstant.java:72) ~[protocol-core-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.core.StringToInstant.convert(StringToInstant.java:56) ~[protocol-core-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.core.StringToInstant.convert(StringToInstant.java:32) ~[protocol-core-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller$SimpleTypeJsonUnmarshaller.unmarshall(JsonProtocolUnmarshaller.java:160) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller.unmarshallStructured(JsonProtocolUnmarshaller.java:210) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller.unmarshallStructured(JsonProtocolUnmarshaller.java:114) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller.lambda$unmarshallList$2(JsonProtocolUnmarshaller.java:143) ~[aws-json-protocol-2.3.2.jar:?]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_181]
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ~[?:1.8.0_181]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[?:1.8.0_181]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[?:1.8.0_181]
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[?:1.8.0_181]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_181]
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[?:1.8.0_181]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller.unmarshallList(JsonProtocolUnmarshaller.java:145) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller.unmarshallStructured(JsonProtocolUnmarshaller.java:210) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller.unmarshall(JsonProtocolUnmarshaller.java:197) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonProtocolUnmarshaller.unmarshall(JsonProtocolUnmarshaller.java:168) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonResponseHandler.handle(JsonResponseHandler.java:79) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.JsonResponseHandler.handle(JsonResponseHandler.java:36) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.protocols.json.internal.unmarshall.AwsJsonResponseHandler.handle(AwsJsonResponseHandler.java:43) ~[aws-json-protocol-2.3.2.jar:?]
	at software.amazon.awssdk.core.client.handler.BaseClientHandler.lambda$interceptorCalling$2(BaseClientHandler.java:133) ~[sdk-core-2.3.2.jar:?]
	at software.amazon.awssdk.core.client.handler.AttachHttpMetadataResponseHandler.handle(AttachHttpMetadataResponseHandler.java:40) ~[sdk-core-2.3.2.jar:?]
	at software.amazon.awssdk.core.client.handler.AttachHttpMetadataResponseHandler.handle(AttachHttpMetadataResponseHandler.java:28) ~[sdk-core-2.3.2.jar:?]
	at software.amazon.awssdk.core.internal.http.async.SyncResponseHandlerAdapter.lambda$prepare$0(SyncResponseHandlerAdapter.java:85) ~[sdk-core-2.3.2.jar:?]
	at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:952) ~[?:1.8.0_181]
	at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:926) ~[?:1.8.0_181]
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) ~[?:1.8.0_181]
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962) ~[?:1.8.0_181]
	at software.amazon.awssdk.core.internal.http.async.SyncResponseHandlerAdapter$BaosSubscriber.onComplete(SyncResponseHandlerAdapter.java:127) ~[sdk-core-2.3.2.jar:?]
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.runAndLogError(ResponseHandler.java:158) ~[netty-nio-client-2.3.2.jar:?]
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.access$700(ResponseHandler.java:64) ~[netty-nio-client-2.3.2.jar:?]
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler$PublisherAdapter$1.onComplete(ResponseHandler.java:268) ~[netty-nio-client-2.3.2.jar:?]
	at com.typesafe.netty.HandlerPublisher.complete(HandlerPublisher.java:408) ~[netty-reactive-streams-2.0.0.jar:?]
	at com.typesafe.netty.HandlerPublisher.handlerRemoved(HandlerPublisher.java:395) ~[netty-reactive-streams-2.0.0.jar:?]
	at io.netty.channel.DefaultChannelPipeline.callHandlerRemoved0(DefaultChannelPipeline.java:670) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline.remove(DefaultChannelPipeline.java:505) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline.remove(DefaultChannelPipeline.java:451) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at com.typesafe.netty.http.HttpStreamsHandler.removeHandlerIfActive(HttpStreamsHandler.java:328) ~[netty-reactive-streams-http-2.0.0.jar:?]
	at com.typesafe.netty.http.HttpStreamsHandler.handleReadHttpContent(HttpStreamsHandler.java:189) ~[netty-reactive-streams-http-2.0.0.jar:?]
	at com.typesafe.netty.http.HttpStreamsHandler.channelRead(HttpStreamsHandler.java:165) ~[netty-reactive-streams-http-2.0.0.jar:?]
	at com.typesafe.netty.http.HttpStreamsClientHandler.channelRead(HttpStreamsClientHandler.java:148) ~[netty-reactive-streams-http-2.0.0.jar:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at software.amazon.awssdk.http.nio.netty.internal.FutureCancelHandler.channelRead0(FutureCancelHandler.java:35) ~[netty-nio-client-2.3.2.jar:?]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:323) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:297) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:591) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:508) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) ~[netty-common-4.1.32.Final.jar:4.1.32.Final]
```
<!--- Include full errors, uncaught exceptions, stack traces, and relevant logs -->
<!--- To turn on SDK logging, follow instructions here: http://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/java-dg-logging.html -->
<!--- If service responses are relevant, please include wirelogs -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->

## Possible Solution
<!--- Not required, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement the addition or change -->
No possible solution

## Steps to Reproduce (for bugs)
<!--- Provide a self-contained, concise snippet of code that can be inserted into a -->
<!--- For more complex issues provide a repo with the smallest sample that reproduces the bug -->
<!--- Including business logic or unrelated code makes diagnosis more difficult -->

## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
This issue may be related: https://github.com/aws/aws-sdk-java-v2/issues/970
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

## Your Environment
<!--- Include as many relevant details about the environment where the bug was discovered -->
* AWS Java SDK version used:
  * amazon-kinesis-client:2.1.0
  * kinesis:2.3.2
  * dynamodb:2.3.2
  * cloudwatch:2.3.2
* JDK version used: 1.8
* Operating System and version: Alpine
",Maybe it's related to the bug I reported in #1021 ? What do you think ?,"@aesteve it might be the case, since we also disabled CBOR for localstack."
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/958,"<!--- Provide a general summary of the issue in the Title above -->

## Expected Behavior
Creating a new multi-part upload should work ok.
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->

## Current Behavior
Creating a new multi-part upload fails signature check
```
software.amazon.awssdk.services.s3.model.S3Exception: The request signature we calculated does not match the signature you provided. Check your key and signing method.
```
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- Include full errors, uncaught exceptions, stack traces, and relevant logs -->
<!--- To turn on SDK logging, follow instructions here: http://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/java-dg-logging.html -->
<!--- If service responses are relevant, please include wirelogs -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->

## Possible Solution
It seems that `uploads` query parameter is missing from the HTTP request. This might explain why the signature does not match.
```
Sending Request: DefaultSdkHttpFullRequest(httpMethod=POST, protocol=https, host=bucketname.s3.us-east-2.amazonaws.com, port=443, encodedPath=/2d12b1d999734ab9fcbeba621ccc3efce62c5ef4, headers=[amz-sdk-invocation-id, Cache-Control, Content-Length, Content-MD5, Content-Type, User-Agent], queryParameters=[])
```
<!--- Not required, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement the addition or change -->

## Steps to Reproduce (for bugs)
<!--- Provide a self-contained, concise snippet of code that can be inserted into a -->
<!--- For more complex issues provide a repo with the smallest sample that reproduces the bug -->
<!--- Including business logic or unrelated code makes diagnosis more difficult -->

## Context
Regular get and put object requests work just fine in the same setup, only the multi-part uploads fail.
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->

## Your Environment
<!--- Include as many relevant details about the environment where the bug was discovered -->
* AWS Java SDK version used: 2.1.4
* JDK version used: JDK8
* Operating System and version:  Win10
",Could you provide the sample code?,"Here's a simplified version that fails with invalid signature:

```scala
import software.amazon.awssdk.services.s3.S3AsyncClient
import software.amazon.awssdk.services.s3.model._

import scala.compat.java8.FutureConverters._
import scala.concurrent.Await
import scala.concurrent.duration.Duration

val bucketName  = ""your-bucket-here""
val path        = ""123456test""
val contentType = ""application/octet-stream""

val s3Client = S3AsyncClient.builder().build()

try {
  val req = CreateMultipartUploadRequest
    .builder()
    .bucket(bucketName)
    .key(path)
    .contentType(contentType)
    .cacheControl(s""max-age=3600,s-maxage=3600"")

  val result   = Await.result(s3Client.createMultipartUpload(req.build).toScala, Duration.Inf)
  val uploadId = result.uploadId()

  val req2 = AbortMultipartUploadRequest
    .builder()
    .bucket(bucketName)
    .key(path)
    .uploadId(uploadId)
    .build

  val abortResult = Await.result(s3Client.abortMultipartUpload(req2).toScala, Duration.Inf)
} catch {
  case e: Throwable => println(e)
}
```

Log:
```
11:39:59.850 DEBUG [software.amazon.awssdk.core.interceptor.ExecutionInterceptorChain:84] Creating an interceptor chain that will apply interceptors in the following order: [software.amazon.awssdk.services.s3.internal.handlers.EndpointAddressInterceptor@2c5711ad, software.amazon.awssdk.services.s3.internal.handlers.CreateBucketInterceptor@1848aa31, software.amazon.awssdk.services.s3.internal.handlers.PutObjectInterceptor@4948a8b7, software.amazon.awssdk.services.s3.internal.handlers.CreateMultipartUploadRequestInterceptor@79f9a15b, software.amazon.awssdk.services.s3.internal.handlers.EnableChunkedEncodingInterceptor@6db70db0, software.amazon.awssdk.services.s3.internal.handlers.DisableDoubleUrlEncodingInterceptor@30f32b15, software.amazon.awssdk.services.s3.internal.handlers.DecodeUrlEncodedResponseInterceptor@3c7220ac, software.amazon.awssdk.services.s3.internal.handlers.AddContentMd5HeaderInterceptor@835ad00, software.amazon.awssdk.services.s3.internal.handlers.GetBucketPolicyInterceptor@5dbaeb3b, software.amazon.awssdk.services.s3.internal.handlers.AsyncChecksumValidationInterceptor@7438d81a, software.amazon.awssdk.services.s3.internal.handlers.SyncChecksumValidationInterceptor@59e2f171, software.amazon.awssdk.services.s3.internal.handlers.EnableTrailingChecksumInterceptor@7c9a0ae0, software.amazon.awssdk.services.s3.internal.handlers.ExceptionTranslationInterceptor@7673d57b]
11:39:59.852 DEBUG [software.amazon.awssdk.core.interceptor.ExecutionInterceptorChain:84] Interceptor 'software.amazon.awssdk.services.s3.internal.handlers.EndpointAddressInterceptor@2c5711ad' modified the message with its modifyHttpRequest method.
11:39:59.852 DEBUG [software.amazon.awssdk.core.interceptor.ExecutionInterceptorChain:84] Interceptor 'software.amazon.awssdk.services.s3.internal.handlers.CreateMultipartUploadRequestInterceptor@79f9a15b' modified the message with its modifyHttpRequest method.
11:39:59.853 DEBUG [software.amazon.awssdk.core.interceptor.ExecutionInterceptorChain:84] Interceptor 'software.amazon.awssdk.services.s3.internal.handlers.AddContentMd5HeaderInterceptor@835ad00' modified the message with its modifyHttpRequest method.
11:39:59.854 DEBUG [software.amazon.awssdk.request:84] Sending Request: DefaultSdkHttpFullRequest(httpMethod=POST, protocol=https, host=bucket-name-elided.s3.us-east-2.amazonaws.com, port=443, encodedPath=/123456test, headers=[amz-sdk-invocation-id, Content-Length, Content-MD5, Content-Type, User-Agent], queryParameters=[])
11:39:59.855 DEBUG [software.amazon.awssdk.auth.signer.Aws4Signer:84] AWS4 String to sign: AWS4-HMAC-SHA256
20190102T094001Z
20190102/us-east-2/s3/aws4_request
c68e6b46940f6791064e343c5c18d130db2744010d32a1aeea1b13f65514a078
java.util.concurrent.CompletionException: software.amazon.awssdk.services.s3.model.S3Exception: The request signature we calculated does not match the signature you provided. Check your key and signing method. (Service: S3, Status Code: 403, Request ID: 99CA2CB97F48182D)
res0: Unit = ()
```
"
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/485,"I have seen this similar issue at https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2813. Perhaps the solution there can inform the solution for this issue as well. I have a Play framework project (version 2.5.9).

I append the following in its build.sbt's libraryDependencies:
`""software.amazon.awssdk""          % ""s3""       % ""2.0.0-preview-9""`

Then I run `sbt clean && sbt ""project frontend"" run`. Instead of the app starting, it errors with the following:

--- (Running the application, auto-reloading is enabled) ---

java.lang.NoSuchFieldError: DEFAULT_MAX_PENDING_TASKS
	at io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:141)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:127)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:36)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)
	at io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:49)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:77)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:72)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:59)
	at play.core.server.NettyServer.<init>(NettyServer.scala:77)
	at play.core.server.NettyServerProvider.createServer(NettyServer.scala:279)
	at play.core.server.NettyServerProvider.createServer(NettyServer.scala:278)
	at play.core.server.DevServerStart$$anonfun$mainDev$1.apply(DevServerStart.scala:235)
	at play.core.server.DevServerStart$$anonfun$mainDev$1.apply(DevServerStart.scala:65)
	at play.utils.Threads$.withContextClassLoader(Threads.scala:21)
	at play.core.server.DevServerStart$.mainDev(DevServerStart.scala:64)
	at play.core.server.DevServerStart$.mainDevHttpMode(DevServerStart.scala:54)
	at play.core.server.DevServerStart.mainDevHttpMode(DevServerStart.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at play.runsupport.Reloader$.startDevMode(Reloader.scala:234)
	at play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.devModeServer$lzycompute$1(PlayRun.scala:74)
	at play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.play$sbt$run$PlayRun$$anonfun$$anonfun$$anonfun$$devModeServer$1(PlayRun.scala:74)
	at play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.apply(PlayRun.scala:100)
	at play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.apply(PlayRun.scala:53)
	at scala.Function1$$anonfun$compose$1.apply(Function1.scala:47)",Will this work for you? @playtowork @stkeky ,
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/202,"I'm creating many short-lived requests concurrently using the `*AsyncClient`, and this fails with:

```
java.util.concurrent.CompletionException: java.util.NoSuchElementException: HttpStreamsClientHandler#0-body-publisher

	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
	at software.amazon.awssdk.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.handle(AsyncRetryableStage.java:160)
	at software.amazon.awssdk.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.lambda$execute$0(AsyncRetryableStage.java:143)
	at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:822)
	at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:797)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
	at software.amazon.awssdk.http.pipeline.stages.MakeAsyncHttpRequestStage$ResponseHandler.exceptionOccurred(MakeAsyncHttpRequestStage.java:185)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.lambda$exceptionCaught$1(ResponseHandler.java:120)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.runAndLogError(ResponseHandler.java:132)
	at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.exceptionCaught(ResponseHandler.java:119)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at com.typesafe.netty.HandlerSubscriber.exceptionCaught(HandlerSubscriber.java:157)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:264)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:256)
	at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:285)
	at io.netty.channel.AbstractChannelHandlerContext.notifyHandlerException(AbstractChannelHandlerContext.java:850)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:364)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1273)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1084)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.NoSuchElementException: HttpStreamsClientHandler#0-body-publisher
	at io.netty.channel.DefaultChannelPipeline.getContextOrDie(DefaultChannelPipeline.java:1080)
	at io.netty.channel.DefaultChannelPipeline.remove(DefaultChannelPipeline.java:434)
	at com.typesafe.netty.http.HttpStreamsHandler.removeHandlerIfActive(HttpStreamsHandler.java:328)
	at com.typesafe.netty.http.HttpStreamsHandler.handleReadHttpContent(HttpStreamsHandler.java:189)
	at com.typesafe.netty.http.HttpStreamsHandler.channelRead(HttpStreamsHandler.java:165)
	at com.typesafe.netty.http.HttpStreamsClientHandler.channelRead(HttpStreamsClientHandler.java:148)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	... 28 more
```

This can be reproduced by creating a do-nothing lambda function called ""test"" in your AWS account, and then running this JUnit test a couple of times:
```java
package repro.bug;

import java.lang.reflect.Array;
import java.nio.ByteBuffer;
import java.util.concurrent.CompletableFuture;
import java.util.stream.Collectors;
import java.util.stream.IntStream;
import org.junit.Test;
import software.amazon.awssdk.services.lambda.LambdaAsyncClient;
import software.amazon.awssdk.services.lambda.model.InvocationType;
import software.amazon.awssdk.services.lambda.model.InvokeRequest;
import software.amazon.awssdk.services.lambda.model.InvokeResponse;

public class CallLambdaLots {

  public static final int CONCURRENCY = 1000;
  LambdaAsyncClient lambda = LambdaAsyncClient.create();

  @Test
  @SuppressWarnings(""unchecked"")
  public void joinAllAtOnce() {
    CompletableFuture.allOf(
            IntStream.range(1, CONCURRENCY)
                .mapToObj(this::callLambda)
                .toArray(
                    size ->
                        (CompletableFuture<InvokeResponse>[])
                            Array.newInstance(CompletableFuture.class, size)))
        .join();
  }

  @Test
  public void joinOneAtATime() {
    IntStream.range(1, CONCURRENCY)
        .mapToObj(this::callLambda)
        .collect(Collectors.toList())
        .forEach(CompletableFuture::join);
  }

  private CompletableFuture<InvokeResponse> callLambda(int payload) {
    return lambda.invoke(
        InvokeRequest.builder()
            .functionName(""test"")
            .invocationType(InvocationType.Event)
            .payload(ByteBuffer.wrap(Integer.toString(payload).getBytes()))
            .build());
  }
}
```

On machines with lots of cores, you have to crank `CONCURRENCY` up quite a lot to hit the race condition, but from a small lambda function with 1-2 cores I hit this even with 50-100 concurrent requests.",Can you tell me what version of the SDK you used?,"Ah, of course, should have included that. Here's the `build.gradle` I used:

```groovy
plugins {
    id ""io.spring.dependency-management"" version ""1.0.3.RELEASE""
    id ""java""
}

group 'repro.bug'
version '1.0-SNAPSHOT'

sourceCompatibility = 1.8

dependencyManagement {
    imports {
        mavenBom 'software.amazon.awssdk:bom:2.0.0-preview-4'
    }
}

repositories {
    mavenCentral()
}

dependencies {
    compile 'software.amazon.awssdk:lambda'
    testCompile group: 'junit', name: 'junit', version: '4.12'
}
```

And here's the exact set of dependencies used:

```
testRuntimeClasspath - Runtime classpath of source set 'test'.
+--- software.amazon.awssdk:lambda: -> 2.0.0-preview-4
|    +--- org.slf4j:slf4j-api:1.7.25
|    +--- software.amazon.awssdk:core:2.0.0-preview-4
|    |    +--- org.slf4j:slf4j-api:1.7.25
|    |    +--- software.amazon.ion:ion-java:1.0.2
|    |    +--- com.fasterxml.jackson.core:jackson-databind:2.8.8
|    |    |    +--- com.fasterxml.jackson.core:jackson-annotations:2.8.0 -> 2.8.8
|    |    |    \--- com.fasterxml.jackson.core:jackson-core:2.8.8
|    |    +--- com.fasterxml.jackson.jr:jackson-jr-objects:2.9.0.pr4
|    |    |    \--- com.fasterxml.jackson.core:jackson-core:2.9.0.pr4 -> 2.8.8
|    |    +--- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:2.8.8
|    |    |    \--- com.fasterxml.jackson.core:jackson-core:2.8.8
|    |    +--- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:2.8.8
|    |    |    +--- com.fasterxml.jackson.core:jackson-core:2.8.8
|    |    |    \--- com.fasterxml.jackson.core:jackson-databind:2.8.8 (*)
|    |    +--- com.fasterxml.jackson.datatype:jackson-datatype-jsr310:2.8.8
|    |    |    +--- com.fasterxml.jackson.core:jackson-annotations:2.8.0 -> 2.8.8
|    |    |    +--- com.fasterxml.jackson.core:jackson-core:2.8.8
|    |    |    \--- com.fasterxml.jackson.core:jackson-databind:2.8.8 (*)
|    |    +--- software.amazon.awssdk:http-client-spi:2.0.0-preview-4
|    |    |    +--- software.amazon.awssdk:annotations:2.0.0-preview-4
|    |    |    +--- software.amazon.awssdk:utils:2.0.0-preview-4
|    |    |    |    +--- org.slf4j:slf4j-api:1.7.25
|    |    |    |    \--- software.amazon.awssdk:annotations:2.0.0-preview-4
|    |    |    \--- org.reactivestreams:reactive-streams:1.0.0.final -> 1.0.0
|    |    \--- software.amazon.awssdk:utils:2.0.0-preview-4 (*)
|    +--- software.amazon.awssdk:apache-client:2.0.0-preview-4
|    |    +--- software.amazon.awssdk:http-client-spi:2.0.0-preview-4 (*)
|    |    +--- org.slf4j:slf4j-api:1.7.25
|    |    +--- software.amazon.awssdk:utils:2.0.0-preview-4 (*)
|    |    +--- software.amazon.awssdk:annotations:2.0.0-preview-4
|    |    \--- org.apache.httpcomponents:httpclient:4.5.2
|    |         +--- org.apache.httpcomponents:httpcore:4.4.4
|    |         +--- commons-logging:commons-logging:1.2
|    |         \--- commons-codec:commons-codec:1.9
|    +--- software.amazon.awssdk:netty-nio-client:2.0.0-preview-4
|    |    +--- software.amazon.awssdk:http-client-spi:2.0.0-preview-4 (*)
|    |    +--- software.amazon.awssdk:utils:2.0.0-preview-4 (*)
|    |    +--- io.netty:netty-codec-http:4.1.13.Final
|    |    |    \--- io.netty:netty-codec:4.1.13.Final
|    |    |         \--- io.netty:netty-transport:4.1.13.Final
|    |    |              +--- io.netty:netty-buffer:4.1.13.Final
|    |    |              |    \--- io.netty:netty-common:4.1.13.Final
|    |    |              \--- io.netty:netty-resolver:4.1.13.Final
|    |    |                   \--- io.netty:netty-common:4.1.13.Final
|    |    +--- io.netty:netty-handler:4.1.13.Final
|    |    |    +--- io.netty:netty-buffer:4.1.13.Final (*)
|    |    |    +--- io.netty:netty-transport:4.1.13.Final (*)
|    |    |    \--- io.netty:netty-codec:4.1.13.Final (*)
|    |    +--- io.netty:netty-transport-native-epoll:4.1.13.Final
|    |    |    +--- io.netty:netty-common:4.1.13.Final
|    |    |    +--- io.netty:netty-buffer:4.1.13.Final (*)
|    |    |    +--- io.netty:netty-transport-native-unix-common:4.1.13.Final
|    |    |    |    +--- io.netty:netty-common:4.1.13.Final
|    |    |    |    \--- io.netty:netty-transport:4.1.13.Final (*)
|    |    |    \--- io.netty:netty-transport:4.1.13.Final (*)
|    |    +--- com.typesafe.netty:netty-reactive-streams-http:2.0.0
|    |    |    +--- com.typesafe.netty:netty-reactive-streams:2.0.0
|    |    |    |    +--- io.netty:netty-handler:4.1.13.Final (*)
|    |    |    |    \--- org.reactivestreams:reactive-streams:1.0.0
|    |    |    \--- io.netty:netty-codec-http:4.1.13.Final (*)
|    |    \--- org.slf4j:slf4j-api:1.7.25
|    \--- io.burt:jmespath-jackson:0.2.0
|         +--- io.burt:jmespath-core:0.2.0
|         \--- com.fasterxml.jackson.core:jackson-databind:2.7.0 -> 2.8.8 (*)
\--- junit:junit:4.12
     \--- org.hamcrest:hamcrest-core:1.3
```"
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/146,"It appears the async S3 client is corrupting files.  I uploaded a zip file to an S3 bucket with the CLI tools.  I then downloaded the file from S3 using the CLI tools and verified that the downloaded file had the same SHA256 as the original file.

I then downloaded the file using the v2 SDK async S3 client using:
```scala
    val future = client.getObject(
      GetObjectRequest.builder().bucket(s3Bucket).key(s3Key).build(),
      AsyncResponseHandler.toFile(tmpPathname)
    )
```

The file that results has the same length as the original file (133,822), but it no longer has the same SHA256.  `cmp  file.zip file.zip2` says `file.zip file.zip2 differ: char 85628, line 279`.  In fact, all bytes after and including 85628 are incorrect.

",Which version (or commit if you built locally) did you use for testing?,@dagnir I used the 2.0.0-preview-2 s3 artifact from Maven.
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/94,"So I have this snippet (in kotlin, but it shouldnt matter)

```
val s3Client : S3Client = S3Client.builder()
          .endpointOverride(URI(""http://localhost:12345"")).region(Region.US_EAST_1)
          .advancedConfiguration(S3AdvancedConfiguration.builder().pathStyleAccessEnabled(true).build())
          .build()
```

The exception is the following

```
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:80 [localhost/127.0.0.1] failed: Connection refused (Connection refused)
```

As you can see here, the port is suddenly set to 80 instead of 12345, seems to get lost when going through all the stages at some point but hadnt had time to debug further.",Which version of the SDK are you using?,"So this also fails in java for me (created a fresh gradle project with this in a main method):

```
    public static void main(String[] args) throws Exception {
        System.setProperty(""aws.accessKeyId"", ""foo"");
        System.setProperty(""aws.secretAccessKey"", ""bar"");

        S3Client s3Client = S3Client.builder()
                .endpointOverride(new URI(""http://localhost:12345"")).region(Region.US_EAST_1)
                .advancedConfiguration(S3AdvancedConfiguration.builder().pathStyleAccessEnabled(true).build())
                .build();
        CreateBucketResponse response = s3Client.createBucket(CreateBucketRequest.builder().bucket(""foo"").build());
    }
```

I am using `2.0.0-preview-2`

**Update**: Your list buckets call actually works and goes to the correct port! Mine however fails."
aws/aws-sdk-java-v2,https://github.com/aws/aws-sdk-java-v2/issues/81,"Most async calls to S3 API emit stack traces to the console, despite still performing the intended function:

Failed to parse the endpoint https://`<bucket name>`.s3.amazonaws.com, and skip re-assigning the signer region
java.lang.StringIndexOutOfBoundsException: String index out of range: -1
        at java.lang.String.substring(String.java:1931)
        at software.amazon.awssdk.util.AwsHostNameUtils.parseStandardRegionName(AwsHostNameUtils.java:157)
        at software.amazon.awssdk.util.AwsHostNameUtils.parseRegion(AwsHostNameUtils.java:82)
        at software.amazon.awssdk.util.AwsHostNameUtils.parseRegionName(AwsHostNameUtils.java:57)
        at software.amazon.awssdk.services.s3.auth.S3SignerProvider.getSigner(S3SignerProvider.java:47)
        at software.amazon.awssdk.http.pipeline.stages.SigningStage.newSigner(SigningStage.java:75)
        at software.amazon.awssdk.http.pipeline.stages.SigningStage.signRequest(SigningStage.java:55)
        at software.amazon.awssdk.http.pipeline.stages.SigningStage.execute(SigningStage.java:47)
        at software.amazon.awssdk.http.pipeline.stages.SigningStage.execute(SigningStage.java:34)
        at software.amazon.awssdk.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:203)
        at software.amazon.awssdk.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.doExecute(AsyncRetryableStage.java:222)
        at software.amazon.awssdk.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.execute(AsyncRetryableStage.java:151)
        at software.amazon.awssdk.http.pipeline.stages.AsyncRetryableStage$RetryExecutor.execute(AsyncRetryableStage.java:145)
        at software.amazon.awssdk.http.pipeline.stages.AsyncRetryableStage.execute(AsyncRetryableStage.java:81)
        at software.amazon.awssdk.http.pipeline.stages.AsyncRetryableStage.execute(AsyncRetryableStage.java:55)
        at software.amazon.awssdk.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:203)
        at software.amazon.awssdk.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:203)
        at software.amazon.awssdk.http.AmazonAsyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonAsyncHttpClient.java:301)
        at software.amazon.awssdk.client.AsyncClientHandlerImpl.doInvoke(AsyncClientHandlerImpl.java:301)
        at software.amazon.awssdk.client.AsyncClientHandlerImpl.invoke(AsyncClientHandlerImpl.java:280)
        at software.amazon.awssdk.client.AsyncClientHandlerImpl.execute(AsyncClientHandlerImpl.java:127)
        at software.amazon.awssdk.client.SdkAsyncClientHandler.execute(SdkAsyncClientHandler.java:42)
        at software.amazon.awssdk.services.s3.DefaultS3AsyncClient.headObject(DefaultS3AsyncClient.java:1355)
",When will this fix be available as SDK ? Or do you have nightly build I can use ?,
ReactiveX/RxNetty,https://github.com/ReactiveX/RxNetty/issues/552,"The check for SSE content type in `HttpClientResponseImpl` does not take into account that a charset may also be present in the header.  A content type of `text/event-stream;charset=UTF-8` results in an `IllegalStateException`.

https://github.com/ReactiveX/RxNetty/blob/1d6eb41994b70098fe0c2ec68b5ce1e650951e69/rxnetty-http/src/main/java/io/reactivex/netty/protocol/http/client/internal/HttpClientResponseImpl.java#L258
","Do you want to send a PR?
","Yeah, sure 👍 
"
ReactiveX/RxNetty,https://github.com/ReactiveX/RxNetty/issues/105,"```
    HttpClient<ByteBuf, ByteBuf> client = new HttpClientBuilder<ByteBuf, ByteBuf>('localhost', 8080)
            .//withNoIdleConnectionCleanup()
            .withMaxConnections(DEFAULT_MAX_CONNECTIONS)
            .build()

        println client.submit(HttpClientRequest.createPost('/api/profile/login')
           // [...]
          .toBlockingObservable().last()

        client.shutdown()
```

Without `withNoIdleConnectionCleanup`, a static 1-thread scheduler is created and prevents application from closing.

=> Why it is shared ? Could it just be instanciated per client, since each client aslo schedules its own cleanup task and delay ? Ansi since each client can handle a lot of connections, there shouldn't be so much client instances within an app ?

Thank you ;-)
","Could it just be instanciated per client, since each client aslo schedules its own cleanup task and delay ?

Default is a shared cleanup scheduler, one can use a different scheduler per client using this method:

```
new ClientBuilder(""localhost"", 8080).withPoolIdleCleanupScheduler(Executors.newScheduledThreadPool(1));
```

> > > since each client can handle a lot of connections, there shouldn't be so much client instances within an app ?

An RxClient is dedicated to a host+port combination (the interface supports one RxClient dedicated to a pool of homogeneous servers) so an application will have as many clients as the number of hosts it connects to. All the resources used by an RxClient like eventloops, cleanup threads, etc. can be shared and hence an RxClient does not have any overhead per se, so there isn't an issue creating multiple clients.
","Ok! Thank you for the very fast answers :-) I will wait for the new version.
"
ReactiveX/RxNetty,https://github.com/ReactiveX/RxNetty/issues/100,"In the code of IdleConnectionsCleanupTask:

```
    PooledConnection<I, O> idleConnection = iterator.next(); // 1
    if (!idleConnection.isUsable()) { // 2
           iterator.remove(); 
           discardConnection(idleConnection); 
    }
```

Follow the sequence below:
1. clean up thread gets an idle connection from `iterator.next()` at mark 1
2. clean up thread gets suspended
3. another thread acquires the same connection via `idleConnections.poll()`
4. clean up thread resumes, and at mark 2 `idleConnection.isUsable()` may return false since some time has elapsed 
5. clean up thread closes the connection, which is already in use in another thread

Possibly make sense to use an AtomicBoolean to indicate that a PooledConnection has been owned by a thread?
","Will the system behave any differently in these two scenarios? I believe no.

Now, can we avoid this scenario?

Let us take your possible fix. If we do have a flag ""isUsed"" in the connection, then the above code will convert to:

```
PooledConnection<I, O> idleConnection = iterator.next(); // 1
    if (!idleConnection.isUsable() && !idleConnection.isInUse()) { // 2
           iterator.remove(); 
           discardConnection(idleConnection); 
    }
```

(The isInUse() check can be inside isUsable() but this is just for discussion purpose)

Is the above fix any different than what is there currently? I think no because the threads can be interleaved so that the connection acquire is between isInUse() check and iterator.remove()/discard call. So it is essentially the same situation.

I think the only way we can ensure that it is not used while in the iterator loop is that instead of having an iterator, we do a drain() from the queue and then add back the connections which are usable. Considering normal usage pattern of highly used pools, I guess if this concurrency situation is to be considered, we should assume that the pool is in frequent use and hence most of the connections are _not_ idle. Hence, we should optimize for connections that are not idle for long (i.e. not expired) than the situation in which they are. The completely safe situation optimizes for the situation when most of the connections are about to be expired. The current one hopes that there are less such occurrences.
","Would this fix the problem, assuming `owned` is an AtomicBoolean:

For cleaning thread:

``` java
PooledConnection<I, O> idleConnection = iterator.next(); // 1
    if (!idleConnection.isUsable() && !idleConnection.owned.compareAndSet(false, true)) { // 2
           iterator.remove(); 
           discardConnection(idleConnection); 
    }
```

For acquiring thread:

``` java
PooledConnection<I, O> idleConnection = idleConnections.poll();
        while (null != idleConnection)) {
                if (!idleConnection.isUsable()) {
                    discardConnection(idleConnection);
                    idleConnection = idleConnections.poll();
                } else if (!idleConnection.owned.compareAndSet(false, true)) {
                    // this should only happen if clean up thread has set the ownership of the connection
                    idleConnection = idleConnections.poll();
                } else {
                    break;
                }
       }
```

Any other race condition problems that are not solved after this?
"
ReactiveX/RxJava,https://github.com/ReactiveX/RxJava/issues/6418,"> org.junit.runners.model.TestTimedOutException: test timed out after 2000 milliseconds

	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
	at io.reactivex.observers.BaseTestConsumer.await(BaseTestConsumer.java:213)
	at io.reactivex.observers.BaseTestConsumer.awaitTerminalEvent(BaseTestConsumer.java:702)
	at io.reactivex.flowable.FlowableBackpressureTests.testOnBackpressureBuffer(FlowableBackpressureTests.java:658)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)

> java.lang.AssertionError: 8,414,032 -> 108,340,920

	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at io.reactivex.internal.operators.observable.ObservableRefCountTest.publishNoLeak(ObservableRefCountTest.java:726)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:114)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:57)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:66)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy1.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:108)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:146)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:128)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:404)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)
	at java.lang.Thread.run(Thread.java:745)","How, when, what's the context, why were you running our unit tests on what machine? Why 2.2.0 when we are at 2.2.6?","> How, when, what's the context, why were you running our unit tests on what machine? Why 2.2.0 when we are at 2.2.6?

I just follow the recommended steps .
`$ git clone git@github.com:ReactiveX/RxJava.git`
`$ cd RxJava/`
`$ ./gradlew build`
and it generated three .jar files under /build/libs
build/libs/rxjava-2.2.0-SNAPSHOT.jar
build/libs/rxjava-2.2.0-SNAPSHOT-javadoc.jar
build/libs/rxjava-2.2.0-SNAPSHOT-sources.jar
but 2 tests failed"
ReactiveX/RxJava,https://github.com/ReactiveX/RxJava/issues/6360,"When I use the following code with RxJava2 version 2.2.4:

               onBackpressureBuffer(Integer.MAX_VALUE,
                        ()->{Logger.error(""Buffer has overflowed. "" +
                                ""This means we are experiencing a data loss event!"");});

I get the following error:

va.lang.NegativeArraySizeException
	at io.reactivex.plugins.RxJavaPlugins.onError(RxJavaPlugins.java:367)
	at io.reactivex.Flowable.subscribe(Flowable.java:14643)
	at io.reactivex.Flowable.subscribe(Flowable.java:14583)
	at io.reactivex.internal.operators.flowable.FlowableZip$ZipCoordinator.subscribe(FlowableZip.java:126)
	at io.reactivex.internal.operators.flowable.FlowableZip.subscribeActual(FlowableZip.java:79)
	at io.reactivex.Flowable.subscribe(Flowable.java:14636)
	at io.reactivex.internal.operators.flowable.FlowableFilter.subscribeActual(FlowableFilter.java:37)
	at io.reactivex.Flowable.subscribe(Flowable.java:14636)
	at io.reactivex.internal.operators.flowable.FlowableFlatMap.subscribeActual(FlowableFlatMap.java:53)
	at io.reactivex.Flowable.subscribe(Flowable.java:14636)
Caused by: java.lang.NegativeArraySizeException: null
	at java.util.concurrent.atomic.AtomicReferenceArray.<init>(AtomicReferenceArray.java:94)
	at io.reactivex.internal.queue.SpscArrayQueue.<init>(SpscArrayQueue.java:51)
	at io.reactivex.internal.operators.flowable.FlowableOnBackpressureBuffer$BackpressureBufferSubscriber.<init>(FlowableOnBackpressureBuffer.java:80)
	at io.reactivex.internal.operators.flowable.FlowableOnBackpressureBuffer.subscribeActual(FlowableOnBackpressureBuffer.java:46)
	at io.reactivex.Flowable.subscribe(Flowable.java:14636)
	at io.reactivex.Flowable.subscribe(Flowable.java:14583)
	at io.reactivex.internal.operators.flowable.FlowableZip$ZipCoordinator.subscribe(FlowableZip.java:126)
	at io.reactivex.internal.operators.flowable.FlowableZip.subscribeActual(FlowableZip.java:79)
	at io.reactivex.Flowable.subscribe(Flowable.java:14636)
	at io.reactivex.internal.operators.flowable.FlowableFilter.subscribeActual(FlowableFilter.java:37)
[error] a.a.OneForOneStrategy - Actually not, but can't throw other exceptions due to RS
java.lang.NullPointerException: Actually not, but can't throw other exceptions due to RS
	at io.reactivex.Flowable.subscribe(Flowable.java:14645)",Do you want to buffer everything or drop some items beyond some capacity?,@akarnokd Thank you. This was a test to make sure we buffer a lot of data and thought of informing the team. We want to buffer in case of back pressure and not lose data. Would the default onBackpressureBuffer() do that? The documentation doesn't mentioning about dropping beyond capacity but in the code it looks like the capacity is 128 and will drop after that.
ReactiveX/RxJava,https://github.com/ReactiveX/RxJava/issues/6213,"In our case , 
We have a use case of fetching remote Ad from an API (Single)  and map it to observable .
We wait for 5 seconds , and then timeout the source

SingleEmitter on Error here tries to do post error to downstream using ""tryOnError"".
Even the observable is terminated due to timeout , we still get the ""UndeliverableException""

```
Fatal Exception: io.reactivex.exceptions.UndeliverableException: java.lang.Exception: Native Ad Failed to load. i: 3
       at io.reactivex.plugins.RxJavaPlugins.onError(RxJavaPlugins.java:367)
       at io.reactivex.internal.operators.observable.ObservableTimeoutTimed$TimeoutObserver.onError(ObservableTimeoutTimed.java:112)
       at io.reactivex.internal.observers.DeferredScalarDisposable.error(DeferredScalarDisposable.java:100)
       at io.reactivex.internal.operators.single.SingleToObservable$SingleToObservableObserver.onError(SingleToObservable.java:77)
       at io.reactivex.internal.operators.single.SingleCreate$Emitter.tryOnError(SingleCreate.java:94)
       at in.startv.hotstar.rocky.ads.nativeads.RxNativeAdsFetcher.onAdFailedToLoad(RxNativeAdsFetcher.java:92)
       at com.google.android.gms.internal.zzjg.onAdClosed(Unknown Source)
```

**Code** : 

```java
rxNativeAdsFetcher
                .fetch(AdUtils.getNativeAdUnitId(adConfig, placementId), placementId, null)
                .toObservable()
                .timeout(5, TimeUnit.SECONDS);
```



**Single Creation :** 

```java
public Single<Ad> fetch(String id, String pId, Map<String, String> params) {
        return Single.create(this);
    }

 @Override
    public void onAdFailedToLoad(int i) {
        Timber.d(""native_ad on error placement id = %s"", placementId);

        super.onAdFailedToLoad(i);
        emitter.tryOnError(e);
    }

@Override
    public void subscribe(SingleEmitter<NativeAd> emitter) throws Exception {
      this.emitter = emitter;
   }

```
   
Can any one please let me know why this is happening , although I call tryonError?
Is it a race condition by time the dispose state is propagated to the upstream , upstream tried to deliver the event to downstream and error happened ?","What is the version you are using?

> Is it a race condition by time the dispose state is propagated to the upstream , upstream tried to deliver the event to downstream and error happened ?

Operators, such as `timeout` will route undeliverable errors even if you used `tryOnError` somewhere upstream. This may happen with races between emission and cancellation by timeout, but the window for it is pretty narrow. Does this happen if you timeout with 4 or 6 seconds?

In general, it is always recommended to install a global error handler to avoid crashes on Android: https://github.com/ReactiveX/RxJava/wiki/What's-different-in-2.0#error-handling","@akarnokd 
Version used is 2.2.1
Yes In our case  timeout is at 5 seconds 
"
ReactiveX/RxJava,https://github.com/ReactiveX/RxJava/issues/4543,"I'm using Jersey2 to handle my REST calls so, that gives me the option to handle them async.
Those requests calls are translated in commands placed on a command bus and eventually, a result needs to come back and returned through Jersey. The command bus is constructed with a PublishSubject and so is the result bus where I'm posting the results.

Regularly, I'm seeing timeouts happening in my logs and I narrowed the problem down in the following simple test case. 

``` java
public class TestPublishSubjectBehaviour {

    public static void main(String[] args) {
        Service service = new Service();

        Task task = new Task(1);

        int result = service.publishAndWaitForReply(task)
                .timeout(5, TimeUnit.SECONDS)
                .doOnNext(id -> log(""received "" + id))
                .doOnError(id -> error(""timed out "" + task.id))
                .onErrorReturn(e -> 0)
                .doOnSubscribe(() -> log(""subscribed results "" + task.id))
                .doOnUnsubscribe(() -> log(""unsubscribed results "" + task.id))
                .toBlocking().first();

        assert result == task.id;
    }

    private static final class Service {

        private final Subject<Integer, Integer> taskResults;

        Service() {
            this.taskResults = PublishSubject.create();
        }

        private static int process(Task task) {
            log(""process task "" + task.id);
            return task.id;
        }

        Observable<Integer> publishAndWaitForReply(Task task) {
            return this.taskResults
                    .filter(x -> x == task.id)
                    .take(1)
                    .doOnSubscribe(() -> this.taskResults.onNext(
                            process(task)
                    ));
        }
    }

    private static class Task {

        final int id;

        Task(int id) {
            this.id = id;
        }

        @Override
        public boolean equals(Object o) {
            return this == o || !(o == null || getClass() != o.getClass()) && id == ((Task) o).id;

        }

        @Override
        public int hashCode() {
            return id;
        }
    }

    private static void log(String message) {
        System.out.println(LocalDateTime.now() + "" - "" + Thread.currentThread().getName() + "" - "" + message);
    }

    private static void error(String message) {
        System.err.println(LocalDateTime.now() + "" - "" + Thread.currentThread().getName() + "" - "" + message);
    }
}
```

As you can see, I tried to only publish to the result subject when a subscribe happened, but it looks like the hook happens just before the subscribe instead of after. I think this is a conflict with the documentation. From http://reactivex.io/RxJava/javadoc/rx/Observable.html#doOnSubscribe(rx.functions.Action0) <pre>Modifies the source Observable so that it invokes the given action when it is <strong>subscribed</strong> from its subscribers.</pre>

The expected output of this should be 

```
2016-09-13T15:03:26.767 - main - publish and wait 1
2016-09-13T15:03:27.032 - main - subscribed results 1
2016-09-13T15:03:27.087 - main - process task 1
2016-09-13T15:03:27.088 - main - published result 1
2016-09-13T15:03:27.091 - main - received 1
2016-09-13T15:03:27.093 - main - unsubscribed results 1
```

However, I get

```
2016-09-13T15:37:42.667 - main - subscribed results 1
2016-09-13T15:37:42.691 - main - process task 1
2016-09-13T15:37:47.696 - RxComputationScheduler-1 - timed out 1
```

First question, am I doing it wrong? Is PublishSubject not suited for this? It works if multiple tasks are published though until it gets unsubscribed. 
Alternatively, what are my options? Looking at the other subjects, I think they don't do what I want. I don't want them to hold state for a while. It should just receive and pass on. 

I noticed there's an internal class created to solve a same problem with GroupedObservables, being `BufferUntilSubscriber`

Any help would be much appreciated.
","Why are you using such a convoluted approach? You could just easily use `fromCallable` to compute a result on demand for incoming subscribers?

``` java
Observable<Integer> publishAndWaitForReply(Task task) {
   return Observable.fromCallable(() -> process(task));
}
```
","About the lost item, I noticed, hence my question ;)

well.. fromCallable is marked Beta and wasn't in the core when I wrote that code ~20 months ago. I'll check if it works for me as the above example has a very simplified stripped down version of what's going on in the process method.

I would suggest to change the doc line on doOnSubscribe into _is subscribing_ instead of _is subscribed_ as it might be misleading. It was for me.

Also, the solution I came up with isn't _that_ weird, is it? There is one general result stream, subscribe to it with a filter for your id, take 1 and the subscription will get unsubscribed after receiving it because of onCompleted. But too bad one can not postpone putting items on the subject until a subscribe happened.

Thanks for the fast reply.
"
google/conscrypt,https://github.com/google/conscrypt/issues/711,"Hi,
It seems that between version 1.0.1 and 1.1.0 something has changed in conscrypt such that it now appears to leak memory when used as the SSL library with the jetty web server. The **latest** version of conscrypt also appears to leak memory.

To reproduce it start jetty with conscrypt then send http 1.0 requests, this can be done with curl.

**Limit the cipher**
When only one of the following ciphers exist:
* TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
* TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
the memory leak still appears.

**Number of java classes**
I does not look to ever be garbage collected, I made the JVM allocate a bunch of `byte[]` held on to by a weak reference and call `System.gc` a bunch but that did not reduce the RSS of the JVM.

running jmap gives:
```
 num     #instances         #bytes  class name
----------------------------------------------
 510:           111           5328  org.conscrypt.NativeSslSession$Impl
 692:           111           2664  org.conscrypt.ByteArray
 693:           111           2664  org.conscrypt.NativeRef$SSL_SESSION
1577:             5            400  org.conscrypt.SSLParametersImpl
1751:            13            312  org.conscrypt.HostProperties$Architecture
1805:             3            288  org.conscrypt.ConscryptEngine
1806:            12            288  org.conscrypt.HostProperties$Architecture
...
10127:             1             16  org.conscrypt.PeerInfoProvider$1
```
It doesn't look like an insane amount of classes are created.

**Compile with debug**
I have a memory profiler (jemalloc), however it only shows that something in the conscrypt shared library is allocating. I would like to try conscrypt with `-g` and `-O0` so I can hopefully get some line numbers on the allocations. I couldn't find pre-compiled boringSSL with debug symbols. I attempted to compile it myself, however after tinkering 
```
CMakeLists.txt
-  set(C_CXX_FLAGS ""-Werror -Wformat=2 -Wsign-compare -Wmissing-field-initializers -Wwrite-strings"")
+  set(C_CXX_FLAGS ""-Wformat=2 -Wsign-compare -Wmissing-field-initializers -Wwrite-strings"")
```
I ran:
```
$ cmake -DCMAKE_POSITION_INDEPENDENT_CODE=TRUE -DCMAKE_ASM_FLAGS=-Wa,--noexecstack -GNinja ..
...
-- Configuring done
-- Generating done
-- Build files have been written to: /home/luke/code/third_party/boringssl/build64
```
After I ran:
```
$ ninja
[444/444] Linking CXX executable ssl/ssl_test
```

I set: `BORINGSSL_HOME=/home/luke/code/third_party/boringssl/`
I then attempted to build conscrypt, with some minor modifications I replaced all `-O3` with `-O0` and `-g`.
```
./gradlew install
./gradlew build
```
This resulted in building a linux conscrypt I included that and started jetty web server with that along with jemalloc, however the resulting pdf:
[jemalloc.pdf](https://github.com/google/conscrypt/files/3544767/jemalloc.pdf)
doesn't show anything interesting about conscrypt or boringSSL.

It is not clear what to do next, to help identify why conscrypt is leaking memory.",Does that not work?  Running under something like jemalloc might also be helpful.  Or if you can find a reproducible case we'd be happy to take a look as well.,"If it is of interest I think I have it replicated in a smaller way that you could try it out,
the repo is over at: https://github.com/LukeButters/conscrypt-jetty
basically you need to start that web server send non stop http 1.0 requests to it and very very very slowly the memory just keeps growing. @flooey this is the best reproducible case I have so far, I don't know how to make it leak faster sorry.

Here is a graph of it growing over ten days 
![leak](https://user-images.githubusercontent.com/7076477/65667175-81d37500-e082-11e9-86ae-c0892f870b80.png)

I also mentioned this to the jetty users mailing list over at https://www.eclipse.org/lists/jetty-users/msg09100.html
"
google/guava,https://github.com/google/guava/issues/2994,"Hi all,

I am facing something I'm calling a bug with the method parse from the class MediaType.
The method raises an exception if I parse the string ""application/toto"" what is correct.
The method don't raise any exception if I parse the string ""application/pdf"" what is also correct.
However, the method don't raise any exception if I parse the string ""application/p"" what is not a mime type.

Did I miss something?

Yours sincerely,
Julien BAUMGARTEN","What version of Guava are you using? This test passes at head:

```
  public void testIssue2994() {
    assertThat(MediaType.parse(""application/pdf"")).isNotNull();
    assertThat(MediaType.parse(""application/p"")).isNotNull();
    assertThat(MediaType.parse(""application/toto"")).isNotNull();
  }
```","I am using version 23.4-jre

<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0""
xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0
http://maven.apache.org/maven-v4_0_0.xsd"">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <artifactId>spring-boot-starter-parent</artifactId>
        <groupId>org.springframework.boot</groupId>
        <version>1.5.7.RELEASE</version>
        <relativePath/>
    </parent>

    <groupId>com.viadialog.repository.media</groupId>
    <artifactId>mediarepository</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <packaging>war</packaging>
    <name>Mediarepository</name>

    <properties>
        <argLine>-Djava.security.egd=file:/dev/./urandom -Xmx256m</argLine>
        <assertj.version>3.6.2</assertj.version>
        <awaitility.version>2.0.0</awaitility.version>
        <commons-io.version>2.5</commons-io.version>
        <commons-lang.version>3.5</commons-lang.version>
        <dockerfile-maven-plugin.version>1.3.4</dockerfile-maven-plugin.version>
        <!-- Overridden to get metrics-jcache -->
        <dropwizard-metrics.version>3.2.2</dropwizard-metrics.version>
        <gatling.version>2.2.5</gatling.version>
        <gatling-maven-plugin.version>2.2.4</gatling-maven-plugin.version>
        <hazelcast-hibernate52.version>1.2</hazelcast-hibernate52.version>
        <hibernate.version>5.2.10.Final</hibernate.version>
        <hikaricp.version>2.6.0</hikaricp.version>
        <jacoco-maven-plugin.version>0.7.9</jacoco-maven-plugin.version>
        <java.version>1.8</java.version>
        <jcache.version>1.0.0</jcache.version>
        <jzlib.version>1.1.3</jzlib.version>
        <jhipster.server.version>1.1.13</jhipster.server.version>
        <liquibase-hibernate5.version>3.6</liquibase-hibernate5.version>
        <liquibase-slf4j.version>2.0.0</liquibase-slf4j.version>
        <logstash-logback-encoder.version>4.11</logstash-logback-encoder.version>
        <m2e.apt.activation>jdt_apt</m2e.apt.activation>
        <mapstruct.version>1.1.0.Final</mapstruct.version>
        <maven-compiler-plugin.version>3.7.0</maven-compiler-plugin.version>
        <maven-enforcer-plugin.version>3.0.0-M1</maven-enforcer-plugin.version>
        <maven-resources-plugin.version>3.0.1</maven-resources-plugin.version>
        <maven.build.timestamp.format>yyyyMMddHHmmss</maven.build.timestamp.format>
        <maven.compiler.source>${java.version}</maven.compiler.source>
        <maven.compiler.target>${java.version}</maven.compiler.target>
        <maven.version>3.0.0</maven.version>
        <metrics-spring.version>3.1.3</metrics-spring.version>
        <node.version>v6.11.3</node.version>
        <problem-spring-web.version>0.21.0</problem-spring-web.version>
        <!-- These remain empty unless the corresponding profile is active -->
        <profile.no-liquibase />
        <profile.swagger />
        <prometheus-simpleclient.version>0.0.20</prometheus-simpleclient.version>
        <!-- Sonar properties -->
        <project.testresult.directory>${project.build.directory}/test-results</project.testresult.directory>
        <run.addResources>false</run.addResources>
        <scala-maven-plugin.version>3.2.2</scala-maven-plugin.version>
        <scala.version>2.12.1</scala.version>
        <sonar-maven-plugin.version>3.2</sonar-maven-plugin.version>

        <sonar.exclusions>src/main/webapp/content/**/*.*,
src/main/webapp/i18n/*.js, target/www/**/*.*,
src/main/webapp/app/app.main-aot.ts</sonar.exclusions>

        <sonar.issue.ignore.multicriteria>S3437,UndocumentedApi,BoldAndItalicTagsCheck</sonar.issue.ignore.multicriteria>

        <!-- Rule
https://sonarqube.com/coding_rules#rule_key=Web%3ABoldAndItalicTagsCheck
is ignored. Even if we agree that using the ""i"" tag is an awful
practice, this is what is recommended by
http://fontawesome.io/examples/ -->
        <sonar.issue.ignore.multicriteria.BoldAndItalicTagsCheck.resourceKey>src/main/webapp/app/**/*.*</sonar.issue.ignore.multicriteria.BoldAndItalicTagsCheck.resourceKey>
        <sonar.issue.ignore.multicriteria.BoldAndItalicTagsCheck.ruleKey>Web:BoldAndItalicTagsCheck</sonar.issue.ignore.multicriteria.BoldAndItalicTagsCheck.ruleKey>
        <!-- Rule
https://sonarqube.com/coding_rules#rule_key=squid%3AS3437 is ignored,
as a JPA-managed field cannot be transient -->
        <sonar.issue.ignore.multicriteria.S3437.resourceKey>src/main/java/**/*</sonar.issue.ignore.multicriteria.S3437.resourceKey>
        <sonar.issue.ignore.multicriteria.S3437.ruleKey>squid:S3437</sonar.issue.ignore.multicriteria.S3437.ruleKey>
        <!-- Rule
http://sonarqube.com/coding_rules#rule_key=squid%3AUndocumentedApi is
ignored, as we want to follow ""clean code"" guidelines and classes,
methods and arguments names should be self-explanatory -->
        <sonar.issue.ignore.multicriteria.UndocumentedApi.resourceKey>src/main/java/**/*</sonar.issue.ignore.multicriteria.UndocumentedApi.resourceKey>
        <sonar.issue.ignore.multicriteria.UndocumentedApi.ruleKey>squid:UndocumentedApi</sonar.issue.ignore.multicriteria.UndocumentedApi.ruleKey>

        <sonar.jacoco.itReportPath>${project.testresult.directory}/coverage/jacoco/jacoco-it.exec</sonar.jacoco.itReportPath>
        <sonar.jacoco.reportPath>${project.testresult.directory}/coverage/jacoco/jacoco.exec</sonar.jacoco.reportPath>
        <sonar.java.codeCoveragePlugin>jacoco</sonar.java.codeCoveragePlugin>

        <sonar.javascript.jstestdriver.reportsPath>${project.testresult.directory}/karma</sonar.javascript.jstestdriver.reportsPath>

        <sonar.typescript.lcov.reportPaths>${project.testresult.directory}/coverage/report-lcov/lcov.info</sonar.typescript.lcov.reportPaths>

        <sonar.sources>${project.basedir}/src/main/</sonar.sources>
        <sonar.surefire.reportsPath>${project.testresult.directory}/surefire-reports</sonar.surefire.reportsPath>
        <sonar.tests>${project.basedir}/src/test/</sonar.tests>

        <!-- Spring properties -->
        <spring-cloud.version>Dalston.SR4</spring-cloud.version>
        <spring-security-oauth.version>2.0.12.RELEASE</spring-security-oauth.version>
        <springfox.version>2.7.0</springfox.version>
        <validation-api.version>1.1.0.Final</validation-api.version>
        <yarn.version>v1.1.0</yarn.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-dependencies</artifactId>
                <version>${spring-cloud.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <dependencies>
        <dependency>
            <groupId>io.github.jhipster</groupId>
            <artifactId>jhipster</artifactId>
            <version>${jhipster.server.version}</version>
        </dependency>
        <dependency>
            <groupId>io.dropwizard.metrics</groupId>
            <artifactId>metrics-core</artifactId>
        </dependency>
        <dependency>
            <groupId>io.dropwizard.metrics</groupId>
            <artifactId>metrics-annotation</artifactId>
            <version>${dropwizard-metrics.version}</version>
        </dependency>
        <dependency>
            <groupId>io.dropwizard.metrics</groupId>
            <artifactId>metrics-json</artifactId>
            <version>${dropwizard-metrics.version}</version>
        </dependency>
        <dependency>
            <groupId>io.dropwizard.metrics</groupId>
            <artifactId>metrics-jvm</artifactId>
            <version>${dropwizard-metrics.version}</version>
        </dependency>
        <dependency>
            <groupId>io.dropwizard.metrics</groupId>
            <artifactId>metrics-servlet</artifactId>
            <version>${dropwizard-metrics.version}</version>
        </dependency>
        <dependency>
            <groupId>io.dropwizard.metrics</groupId>
            <artifactId>metrics-servlets</artifactId>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.datatype</groupId>
            <artifactId>jackson-datatype-hibernate5</artifactId>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.datatype</groupId>
            <artifactId>jackson-datatype-hppc</artifactId>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.datatype</groupId>
            <artifactId>jackson-datatype-jsr310</artifactId>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.datatype</groupId>
            <artifactId>jackson-datatype-json-org</artifactId>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.module</groupId>
            <artifactId>jackson-module-afterburner</artifactId>
        </dependency>
        <dependency>
            <groupId>com.h2database</groupId>
            <artifactId>h2</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.hazelcast</groupId>
            <artifactId>hazelcast</artifactId>
        </dependency>
        <dependency>
            <groupId>com.hazelcast</groupId>
            <artifactId>hazelcast-hibernate52</artifactId>
            <version>${hazelcast-hibernate52.version}</version>
        </dependency>
        <dependency>
            <groupId>com.hazelcast</groupId>
            <artifactId>hazelcast-spring</artifactId>
        </dependency>
        <dependency>
            <groupId>org.awaitility</groupId>
            <artifactId>awaitility</artifactId>
            <version>${awaitility.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.jayway.jsonpath</groupId>
            <artifactId>json-path</artifactId>
            <scope>test</scope>
            <!-- parent POM declares this dependency in default
(compile) scope -->
        </dependency>
        <dependency>
            <groupId>io.springfox</groupId>
            <artifactId>springfox-swagger2</artifactId>
            <version>${springfox.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>org.mapstruct</groupId>
                    <artifactId>mapstruct</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>io.springfox</groupId>
            <artifactId>springfox-bean-validators</artifactId>
            <version>${springfox.version}</version>
        </dependency>
        <dependency>
            <groupId>com.mattbertolini</groupId>
            <artifactId>liquibase-slf4j</artifactId>
            <version>${liquibase-slf4j.version}</version>
        </dependency>
        <dependency>
            <groupId>com.ryantenney.metrics</groupId>
            <artifactId>metrics-spring</artifactId>
            <version>${metrics-spring.version}</version>
        </dependency>
        <dependency>
            <groupId>com.zaxxer</groupId>
            <artifactId>HikariCP</artifactId>
        </dependency>

        <dependency>
            <groupId>commons-io</groupId>
            <artifactId>commons-io</artifactId>
            <version>${commons-io.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
            <version>${commons-lang.version}</version>
        </dependency>
        <dependency>
            <groupId>io.gatling.highcharts</groupId>
            <artifactId>gatling-charts-highcharts</artifactId>
            <version>${gatling.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.jcraft</groupId>
            <artifactId>jzlib</artifactId>
            <version>${jzlib.version}</version>
        </dependency>
        <dependency>
            <groupId>javax.cache</groupId>
            <artifactId>cache-api</artifactId>
        </dependency>
        <dependency>
            <groupId>org.mariadb.jdbc</groupId>
            <artifactId>mariadb-java-client</artifactId>
        </dependency>
        <dependency>
            <groupId>org.assertj</groupId>
            <artifactId>assertj-core</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.hibernate</groupId>
            <artifactId>hibernate-envers</artifactId>
        </dependency>
        <dependency>
            <groupId>org.hibernate</groupId>
            <artifactId>hibernate-validator</artifactId>
        </dependency>
        <dependency>
            <groupId>org.liquibase</groupId>
            <artifactId>liquibase-core</artifactId>
        </dependency>
        <dependency>
            <groupId>org.mapstruct</groupId>
            <artifactId>mapstruct-jdk8</artifactId>
            <version>${mapstruct.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-context-support</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-actuator</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-autoconfigure</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-configuration-processor</artifactId>
            <optional>true</optional>
            <exclusions>
                <exclusion>
                    <groupId>com.vaadin.external.google</groupId>
                    <artifactId>android-json</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-loader-tools</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-aop</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-elasticsearch</artifactId>
        </dependency>
        <dependency>
            <groupId>net.java.dev.jna</groupId>
            <artifactId>jna</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-logging</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-mail</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-security</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
            <exclusions>
                <exclusion>
                    <groupId>com.vaadin.external.google</groupId>
                    <artifactId>android-json</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.security</groupId>
            <artifactId>spring-security-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-thymeleaf</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
            <exclusions>
                <exclusion>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-starter-tomcat</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.zalando</groupId>
            <artifactId>problem-spring-web</artifactId>
            <version>${problem-spring-web.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.security.oauth</groupId>
            <artifactId>spring-security-oauth2</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.security</groupId>
            <artifactId>spring-security-jwt</artifactId>
        </dependency>
        <!-- Spring Cloud -->
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-ribbon</artifactId>
            <!-- netty's native is pulled, but is useless unless you
explicitly add the native binary dependency.
                 Having it in the classpath without the binary can
cause warnings -->
            <exclusions>
                <exclusion>
                    <groupId>io.netty</groupId>
                    <artifactId>netty-transport-native-epoll</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-hystrix</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-spectator</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.retry</groupId>
            <artifactId>spring-retry</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-eureka</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-config</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-security</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-feign</artifactId>
        </dependency>
        <dependency>
            <groupId>net.logstash.logback</groupId>
            <artifactId>logstash-logback-encoder</artifactId>
            <version>${logstash-logback-encoder.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-cloud-connectors</artifactId>
        </dependency>
        <!-- security -->
        <dependency>
            <groupId>org.springframework.security</groupId>
            <artifactId>spring-security-data</artifactId>
        </dependency>
        <!-- jhipster-needle-maven-add-dependency -->
        <dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
            <version>23.4-jre</version>
        </dependency>
    </dependencies>
    <build>
        <defaultGoal>spring-boot:run</defaultGoal>
        <plugins>
            <plugin>
                <groupId>io.gatling</groupId>
                <artifactId>gatling-maven-plugin</artifactId>
                <version>${gatling-maven-plugin.version}</version>
                <configuration>
                    <configFolder>src/test/gatling/conf</configFolder>
                    <dataFolder>src/test/gatling/user-files/data</dataFolder>

<resultsFolder>target/gatling/results/${maven.build.timestamp}/</resultsFolder>

<bodiesFolder>src/test/gatling/user-files/bodies</bodiesFolder>

<simulationsFolder>src/test/gatling/user-files/simulations</simulationsFolder>
                    <!-- If uncommented, these arguments below will be
applied to all your gatling tests -->
                    <!--<jvmArgs>
                        <jvmArg>-Dusers=100</jvmArg>
                        <jvmArg>-Dramp=1</jvmArg>
                    </jvmArgs>-->
                    <!--
                    This will run multiple simulations one by one.
Useful when doing Gatling
                    tests in CI.
                    -->
                    <runMultipleSimulations>true</runMultipleSimulations>
                    <!--
                    To run only one simulation, you need to disable
the ""runMultipleSimulations""
                    above, and write the name of your simulation below.
                    -->

<!--<simulationClass>WriteTheNameOfYourGatlingSimulation</simulationClass>-->
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>${maven-compiler-plugin.version}</version>
                <configuration>
                    <annotationProcessorPaths>
                        <path>
                            <groupId>org.mapstruct</groupId>
                            <artifactId>mapstruct-processor</artifactId>
                            <version>${mapstruct.version}</version>
                        </path>
                        <!-- For JPA static metamodel generation -->
                        <path>
                            <groupId>org.hibernate</groupId>
                            <artifactId>hibernate-jpamodelgen</artifactId>
                            <version>${hibernate.version}</version>
                        </path>

                    </annotationProcessorPaths>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-eclipse-plugin</artifactId>
                <configuration>
                    <downloadSources>true</downloadSources>
                    <downloadJavadocs>true</downloadJavadocs>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-enforcer-plugin</artifactId>
                <version>${maven-enforcer-plugin.version}</version>
                <executions>
                    <execution>
                        <id>enforce-versions</id>
                        <goals>
                            <goal>enforce</goal>
                        </goals>
                    </execution>
                </executions>
                <configuration>
                    <rules>
                        <requireMavenVersion>
                            <message>You are running an older version
of Maven. JHipster requires at least Maven ${maven.version}</message>
                            <version>[${maven.version},)</version>
                        </requireMavenVersion>
                        <requireJavaVersion>
                            <message>You are running an older version
of Java. JHipster requires at least JDK ${java.version}</message>
                            <version>[${java.version}.0,)</version>
                        </requireJavaVersion>
                    </rules>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-resources-plugin</artifactId>
                <version>${maven-resources-plugin.version}</version>
                <executions>
                    <execution>
                        <id>default-resources</id>
                        <phase>validate</phase>
                        <goals>
                            <goal>copy-resources</goal>
                        </goals>
                        <configuration>
                            <outputDirectory>target/classes</outputDirectory>
                            <useDefaultDelimiters>false</useDefaultDelimiters>
                            <delimiters>
                                <delimiter>#</delimiter>
                            </delimiters>
                            <resources>
                                <resource>
                                    <directory>src/main/resources/</directory>
                                    <filtering>true</filtering>
                                    <includes>
                                        <include>**/*.xml</include>
                                        <include>**/*.yml</include>
                                    </includes>
                                </resource>
                                <resource>
                                    <directory>src/main/resources/</directory>
                                    <filtering>false</filtering>
                                    <excludes>
                                        <exclude>**/*.xml</exclude>
                                        <exclude>**/*.yml</exclude>
                                    </excludes>
                                </resource>
                            </resources>
                        </configuration>
                    </execution>
                    <execution>
                        <id>docker-resources</id>
                        <phase>validate</phase>
                        <goals>
                            <goal>copy-resources</goal>
                        </goals>
                        <configuration>
                            <outputDirectory>target/</outputDirectory>
                            <resources>
                                <resource>
                                    <directory>src/main/docker/</directory>
                                    <filtering>false</filtering>
                                    <excludes>
                                        <exclude>**/*.yml</exclude>
                                    </excludes>
                                </resource>
                            </resources>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <!-- Force alphabetical order to have a
reproducible build -->
                    <runOrder>alphabetical</runOrder>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.jacoco</groupId>
                <artifactId>jacoco-maven-plugin</artifactId>
                <version>${jacoco-maven-plugin.version}</version>
                <executions>
                    <execution>
                        <id>pre-unit-tests</id>
                        <goals>
                            <goal>prepare-agent</goal>
                        </goals>
                        <configuration>
                            <!-- Sets the path to the file which
contains the execution data. -->

<destFile>${project.testresult.directory}/coverage/jacoco/jacoco.exec</destFile>
                        </configuration>
                    </execution>
                    <!-- Ensures that the code coverage report for
unit tests is created after unit tests have been run -->
                    <execution>
                        <id>post-unit-test</id>
                        <phase>test</phase>
                        <goals>
                            <goal>report</goal>
                        </goals>
                        <configuration>

<dataFile>${project.testresult.directory}/coverage/jacoco/jacoco.exec</dataFile>

<outputDirectory>${project.testresult.directory}/coverage/jacoco</outputDirectory>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.sonarsource.scanner.maven</groupId>
                <artifactId>sonar-maven-plugin</artifactId>
                <version>${sonar-maven-plugin.version}</version>
            </plugin>
            <plugin>
                <groupId>org.liquibase</groupId>
                <artifactId>liquibase-maven-plugin</artifactId>
                <version>${liquibase.version}</version>
                <configuration>

<changeLogFile>src/main/resources/config/liquibase/master.xml</changeLogFile>

<diffChangeLogFile>src/main/resources/config/liquibase/changelog/${maven.build.timestamp}_changelog.xml</diffChangeLogFile>
                    <driver>org.mariadb.jdbc.Driver</driver>
                    <url>jdbc:mariadb://localhost:3307/mediarepository</url>
                    <defaultSchemaName></defaultSchemaName>
                    <username></username>
                    <password></password>

<referenceUrl>hibernate:spring:com.viadialog.repository.media.domain?dialect=org.hibernate.dialect.MySQL5InnoDBDialect&amp;hibernate.physical_naming_strategy=org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy&amp;hibernate.implicit_naming_strategy=org.springframework.boot.orm.jpa.hibernate.SpringImplicitNamingStrategy</referenceUrl>
                    <verbose>true</verbose>
                    <logging>debug</logging>
                </configuration>
                <dependencies>
                    <dependency>
                        <groupId>org.javassist</groupId>
                        <artifactId>javassist</artifactId>
                        <version>${javassist.version}</version>
                    </dependency>
                    <dependency>
                        <groupId>org.liquibase.ext</groupId>
                        <artifactId>liquibase-hibernate5</artifactId>
                        <version>${liquibase-hibernate5.version}</version>
                    </dependency>
                    <dependency>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-starter-data-jpa</artifactId>
                        <version>${project.parent.version}</version>
                    </dependency>
                    <dependency>
                        <groupId>javax.validation</groupId>
                        <artifactId>validation-api</artifactId>
                        <version>${validation-api.version}</version>
                    </dependency>
                </dependencies>
            </plugin>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <configuration>
                    <executable>true</executable>
                    <fork>true</fork>
                    <!--
                    Enable the line below to have remote debugging of
your application on port 5005

<jvmArguments>-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005</jvmArguments>
                    -->
                </configuration>
            </plugin>
            <plugin>
                <groupId>com.spotify</groupId>
                <artifactId>dockerfile-maven-plugin</artifactId>
                <version>${dockerfile-maven-plugin.version}</version>
                <!--
                Uncomment the section below to build the docker image
with mvn package and and push it with mvn deploy
                <executions>
                    <execution>
                    <id>default</id>
                    <goals>
                        <goal>build</goal>
                        <goal>push</goal>
                    </goals>
                    </execution>
                </executions>
                -->
                <configuration>
                    <repository>mediarepository</repository>
                    <tag>latest</tag>

<contextDirectory>${project.build.directory}</contextDirectory>
                </configuration>
            </plugin>
            <!-- jhipster-needle-maven-add-plugin -->
        </plugins>
        <pluginManagement>
            <plugins>
                <!--
                    This plugin's configuration is used to store
Eclipse m2e settings only.
                    It has no influence on the Maven build itself.
                    Remove when the m2e plugin can correctly bind to
Maven lifecycle
                -->
                <plugin>
                    <groupId>org.eclipse.m2e</groupId>
                    <artifactId>lifecycle-mapping</artifactId>
                    <version>1.0.0</version>
                    <configuration>
                        <lifecycleMappingMetadata>
                            <pluginExecutions>
                                <pluginExecution>
                                    <pluginExecutionFilter>
                                        <groupId>org.jacoco</groupId>
                                        <artifactId>
                                            jacoco-maven-plugin
                                        </artifactId>
                                        <versionRange>
                                            ${jacoco-maven-plugin.version}
                                        </versionRange>
                                        <goals>
                                            <goal>prepare-agent</goal>
                                        </goals>
                                    </pluginExecutionFilter>
                                    <action>
                                        <ignore/>
                                    </action>
                                </pluginExecution>
                            </pluginExecutions>
                        </lifecycleMappingMetadata>
                    </configuration>
                </plugin>
            </plugins>
        </pluginManagement>
    </build>
    <profiles>
        <profile>
            <id>no-liquibase</id>
            <properties>
                <profile.no-liquibase>,no-liquibase</profile.no-liquibase>
            </properties>
        </profile>
        <profile>
            <id>swagger</id>
            <properties>
                <profile.swagger>,swagger</profile.swagger>
            </properties>
        </profile>
        <profile>
            <id>dev</id>
            <activation>
                <activeByDefault>true</activeByDefault>
            </activation>
            <dependencies>
                <dependency>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-starter-undertow</artifactId>
                </dependency>
                <dependency>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-devtools</artifactId>
                    <optional>true</optional>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-war-plugin</artifactId>
                        <configuration>
                        </configuration>
                    </plugin>
                </plugins>
            </build>
            <properties>
                <!-- log configuration -->
                <logback.loglevel>DEBUG</logback.loglevel>
                <!-- default Spring profiles -->

<spring.profiles.active>dev${profile.no-liquibase}</spring.profiles.active>
            </properties>
        </profile>
        <profile>
            <id>prod</id>
            <dependencies>
                <dependency>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-starter-undertow</artifactId>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                        <artifactId>maven-clean-plugin</artifactId>
                        <configuration>
                            <filesets>
                                <fileset>
                                    <directory>target/www/</directory>
                                </fileset>
                            </filesets>
                        </configuration>
                    </plugin>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-war-plugin</artifactId>
                        <configuration>
                        </configuration>
                    </plugin>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <configuration>
                            <executable>true</executable>
                        </configuration>
                        <executions>
                            <execution>
                                <goals>
                                    <goal>build-info</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
            <properties>
                <!-- log configuration -->
                <logback.loglevel>INFO</logback.loglevel>
                <!-- default Spring profiles -->

<spring.profiles.active>prod${profile.swagger}${profile.no-liquibase}</spring.profiles.active>
            </properties>
        </profile>
        <profile>
            <!--
                Profile for doing ""continuous compilation"" with the
Scala Maven plugin.
                It allows automatic compilation of Java classes as
soon as they are saved.
                To use it, run in 3 terminals:
                - './mvnw -Pcc scala:cc' for continuous compilation of
your classes
                - './mvnw -Pcc' for hot reload of Spring boot
                - 'npm start/yarn start' for hot reload of the
HTML/JavaScript asset
                Everything should hot reload automatically!
            -->
            <id>cc</id>
            <dependencies>
                <dependency>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-starter-undertow</artifactId>
                </dependency>
                <dependency>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-devtools</artifactId>
                    <optional>true</optional>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-war-plugin</artifactId>
                        <configuration>

<warSourceDirectory>src/main/webapp/</warSourceDirectory>
                        </configuration>
                    </plugin>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <configuration>
                            <executable>true</executable>
                            <fork>true</fork>
                            <addResources>true</addResources>
                            <!--
                            Enable the line below to have remote
debugging of your application on port 5005

<jvmArguments>-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005</jvmArguments>
                            -->
                        </configuration>
                    </plugin>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-compiler-plugin</artifactId>
                        <executions>
                            <execution>
                                <id>default-compile</id>
                                <phase>none</phase>
                            </execution>
                            <execution>
                                <id>default-testCompile</id>
                                <phase>none</phase>
                            </execution>
                        </executions>
                    </plugin>
                    <plugin>
                        <groupId>net.alchim31.maven</groupId>
                        <artifactId>scala-maven-plugin</artifactId>
                        <version>${scala-maven-plugin.version}</version>
                        <executions>
                            <execution>
                                <id>compile</id>
                                <phase>compile</phase>
                                <goals>
                                    <goal>add-source</goal>
                                    <goal>compile</goal>
                                </goals>
                            </execution>
                            <execution>
                                <id>test-compile</id>
                                <phase>test-compile</phase>
                                <goals>
                                    <goal>add-source</goal>
                                    <goal>testCompile</goal>
                                </goals>
                            </execution>
                        </executions>
                        <configuration>
                            <recompileMode>incremental</recompileMode>
                            <verbose>true</verbose>
                            <scalaVersion>${scala.version}</scalaVersion>
                        </configuration>
                    </plugin>
                </plugins>
            </build>
            <properties>
                <!-- log configuration -->
                <logback.loglevel>DEBUG</logback.loglevel>
                <!-- default Spring profiles -->
                <spring.profiles.active>dev,swagger</spring.profiles.active>
            </properties>
        </profile>
        <profile>
            <!--
                Profile for monitoring the application with Graphite.
            -->
            <id>graphite</id>
            <dependencies>
                <dependency>
                    <groupId>io.dropwizard.metrics</groupId>
                    <artifactId>metrics-graphite</artifactId>
                </dependency>
            </dependencies>
        </profile>
        <profile>
            <!--
                Profile for monitoring the application with Prometheus.
            -->
            <id>prometheus</id>
            <dependencies>
                <dependency>
                    <groupId>io.prometheus</groupId>
                    <artifactId>simpleclient</artifactId>
                    <version>${prometheus-simpleclient.version}</version>
                </dependency>
                <dependency>
                    <groupId>io.prometheus</groupId>
                    <artifactId>simpleclient_servlet</artifactId>
                    <version>${prometheus-simpleclient.version}</version>
                </dependency>
                <dependency>
                    <groupId>io.prometheus</groupId>
                    <artifactId>simpleclient_dropwizard</artifactId>
                    <version>${prometheus-simpleclient.version}</version>
                </dependency>
            </dependencies>
        </profile>
        <profile>
            <!--
                Profile for tracing requests with Zipkin.
            -->
            <id>zipkin</id>
            <dependencies>
                <dependency>
                    <groupId>org.springframework.cloud</groupId>
                    <artifactId>spring-cloud-starter-zipkin</artifactId>
                </dependency>
            </dependencies>
        </profile>
        <profile>
            <!--
                Profile for applying IDE-specific configuration.
                At the moment it only configures MapStruct, which you
need when working
                with DTOs.
            -->
            <id>IDE</id>
            <dependencies>
                <dependency>
                    <groupId>org.mapstruct</groupId>
                    <artifactId>mapstruct-processor</artifactId>
                    <version>${mapstruct.version}</version>
                </dependency>
            </dependencies>
        </profile>
    </profiles>
</project>


2017-11-15 16:37 GMT+01:00 Kurt Alfred Kluever <notifications@github.com>:

> What version of Guava are you using? This test passes at head:
>
>   public void testIssue2994() {
>     assertThat(MediaType.parse(""application/pdf"")).isNotNull();
>     assertThat(MediaType.parse(""application/p"")).isNotNull();
>     assertThat(MediaType.parse(""application/toto"")).isNotNull();
>   }
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/google/guava/issues/2994#issuecomment-344630269>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AJnjA63ETunFaMOovxBsaSE3oTzmllZpks5s2wUggaJpZM4Qepjv>
> .
>
"
google/guava,https://github.com/google/guava/issues/2779,"After serializing / deserializing Absent instances won't be the same (e.g. in an Apache Spark context with Kryo serialization).

Therefore the implementation below contains a bug. Why not just check if the two instances have the same class definition?

```
@Override public boolean equals(@Nullable Object object) {
  return object == this;
}
```","Does ""Kryo serialization"" circumvent Java serialization and not invoke readResolve?",
google/guava,https://github.com/google/guava/issues/2659,"Hi, guys! I have some problem with method construct in ImmutableSortedSet class, cause I've received every time n-1 elements after build ImmutableSortedSet.

I found that this part of code can include a bug:
```
for (int i = 1; i < n; i++) {
      E cur = contents[i];
      E prev = contents[uniques - 1];
      if (comparator.compare(cur, prev) != 0) {
        contents[uniques++] = cur;
      }
    }
```
Why you not process the last one element? I mean this:
`for (int i = 1; i < n; i++)`",Could you provide a reproduction test case for returning n-1 elements?,"![1](https://cloud.githubusercontent.com/assets/11968111/20677455/71fcaaa6-b593-11e6-9ee6-b8513a88dc59.png)
![2](https://cloud.githubusercontent.com/assets/11968111/20677467/7b6c4b0a-b593-11e6-96f7-2f2ff97a71a8.png)
"
google/dagger,https://github.com/google/dagger/issues/1700,"It looks like Dagger 2.25.3 has introduced a dependency on something from google.common.collect in a breaking fashion. In my app, I upgraded only from Dagger 2.25.2 to Dagger 2.25.3, and started seeing the following compilation failure:

```
e: [kapt] An exception occurred: java.lang.NoSuchMethodError: com.google.common.collect.ImmutableList.toImmutableList()Ljava/util/stream/Collector;
        at dagger.internal.codegen.binding.InjectionAnnotations.getQualifiers(InjectionAnnotations.java:95)
        at dagger.internal.codegen.validation.DependencyRequestValidator.checkQualifiers(DependencyRequestValidator.java:90)
        at dagger.internal.codegen.validation.DependencyRequestValidator.validateDependencyRequest(DependencyRequestValidator.java:68)
        at dagger.internal.codegen.validation.InjectValidator.validateDependencyRequest(InjectValidator.java:244)
        at dagger.internal.codegen.validation.InjectValidator.validateField(InjectValidator.java:205)
        at dagger.internal.codegen.validation.InjectValidator.validateMembersInjectionType(InjectValidator.java:256)
        at dagger.internal.codegen.validation.InjectBindingRegistryImpl.tryRegisterMembersInjectedType(InjectBindingRegistryImpl.java:280)
        at dagger.internal.codegen.validation.InjectBindingRegistryImpl.tryRegisterMembersInjectedType(InjectBindingRegistryImpl.java:264)
        at dagger.internal.codegen.InjectProcessingStep$1.visitVariableAsField(InjectProcessingStep.java:54)
        at dagger.internal.codegen.InjectProcessingStep$1.visitVariableAsField(InjectProcessingStep.java:44)
        at javax.lang.model.util.ElementKindVisitor6.visitVariable(ElementKindVisitor6.java:229)
        at com.sun.tools.javac.code.Symbol$VarSymbol.accept(Symbol.java:1237)
        at dagger.internal.codegen.InjectProcessingStep.process(InjectProcessingStep.java:76)
        at dagger.internal.codegen.validation.TypeCheckingProcessingStep.lambda$process$0(TypeCheckingProcessingStep.java:51)
        at java.util.Map.forEach(Map.java:630)
        at dagger.internal.codegen.validation.TypeCheckingProcessingStep.process(TypeCheckingProcessingStep.java:48)
        at dagger.internal.codegen.validation.TypeCheckingProcessingStep.process(TypeCheckingProcessingStep.java:34)
        at dagger.internal.codegen.statistics.DaggerStatisticsCollectingProcessingStep.process(DaggerStatisticsCollectingProcessingStep.java:52)
        at dagger.shaded.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:330)
        at dagger.shaded.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:181)
        at org.jetbrains.kotlin.kapt3.base.incremental.IncrementalProcessor.process(incrementalProcessors.kt)
        at org.jetbrains.kotlin.kapt3.base.ProcessorWrapper.process(annotationProcessing.kt:147)
        at com.sun.tools.javac.processing.JavacProcessingEnvironment.callProcessor(JavacProcessingEnvironment.java:802)
        at com.sun.tools.javac.processing.JavacProcessingEnvironment.discoverAndRunProcs(JavacProcessingEnvironment.java:713)
        at com.sun.tools.javac.processing.JavacProcessingEnvironment.access$1800(JavacProcessingEnvironment.java:91)
        at com.sun.tools.javac.processing.JavacProcessingEnvironment$Round.run(JavacProcessingEnvironment.java:1043)
        at com.sun.tools.javac.processing.JavacProcessingEnvironment.doProcessing(JavacProcessingEnvironment.java:1184)
        at com.sun.tools.javac.main.JavaCompiler.processAnnotations(JavaCompiler.java:1170)
        at com.sun.tools.javac.main.JavaCompiler.processAnnotations(JavaCompiler.java:1068)
        at org.jetbrains.kotlin.kapt3.base.AnnotationProcessingKt.doAnnotationProcessing(annotationProcessing.kt:79)
        at org.jetbrains.kotlin.kapt3.base.AnnotationProcessingKt.doAnnotationProcessing$default(annotationProcessing.kt:35)
        at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.runAnnotationProcessing(Kapt3Extension.kt:224)
        at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.analysisCompleted(Kapt3Extension.kt:187)
        at org.jetbrains.kotlin.kapt3.ClasspathBasedKapt3Extension.analysisCompleted(Kapt3Extension.kt:98)
        at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM$analyzeFilesWithJavaIntegration$2.invoke(TopDownAnalyzerFacadeForJVM.kt:97)
        at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration(TopDownAnalyzerFacadeForJVM.kt:107)
        at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$default(TopDownAnalyzerFacadeForJVM.kt:82)
        at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:557)
        at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:82)
        at org.jetbrains.kotlin.cli.common.messages.AnalyzerWithCompilerReport.analyzeAndReport(AnalyzerWithCompilerReport.kt:107)
        at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.analyze(KotlinToJVMBytecodeCompiler.kt:548)
        at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli(KotlinToJVMBytecodeCompiler.kt:177)
        at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:165)
        at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:55)
        at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:84)
        at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:42)
        at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:104)
        at org.jetbrains.kotlin.daemon.CompileServiceImpl.compile(CompileServiceImpl.kt:1558)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
        at sun.rmi.transport.Transport$1.run(Transport.java:200)
        at sun.rmi.transport.Transport$1.run(Transport.java:197)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
```

Is this intentional? If so, is there a suggested change that developers are supposed to make to their build setup in order to bring these required classes in correctly?",Do you have any Guava conflict resolution in your setup? As a transitive dependency which version of Guava is it being pulled in your project? In Gradle you can find some of this information via a command like `gradlew app:dependencies`.,"Hmm - we don't pull Guava into our project directly at all, but we also don't have any specific conflict resolution in our build. In our `kapt` output from `dependencies`, I can see that dagger-compiler seems to be getting guava 28.1-android, which seems like it should be good enough?

```
+--- com.google.dagger:dagger-compiler:2.25.3
|    +--- com.google.dagger:dagger:2.25.3
|    |    \--- javax.inject:javax.inject:1
|    +--- com.google.dagger:dagger-producers:2.25.3
|    |    +--- com.google.dagger:dagger:2.25.3 (*)
|    |    +--- com.google.guava:failureaccess:1.0.1
|    |    +--- com.google.guava:guava:27.1-jre -> 28.1-android (*)
|    |    +--- javax.inject:javax.inject:1
|    |    \--- org.checkerframework:checker-compat-qual:2.5.3 -> 2.5.5
```

Is there something about using the Android variant of guava that could cause a problem? It seems very weird that this was introduced in a very small set of seemingly innocent changes.

In case it's relevant, we are currently compiling against SDK 28. Is it possible that somehow, there's something about the switch of dagger to compile against 29 that causes this?"
google/dagger,https://github.com/google/dagger/issues/1308,"**Base class**
```
abstract class BaseGameActivity<PresenterType : Presenter<*>> : NucleusAppCompatActivity<PresenterType>(),
        HasSupportFragmentInjector {

    @Inject
    internal lateinit var supportFragmentInjector: DispatchingAndroidInjector<Fragment>

    @Inject
    internal lateinit var mPresenterInjector: MembersInjector<PresenterType>

    override fun onCreate(savedInstanceState: Bundle?) {
        AndroidInjection.inject(this)
        val superFactory = super.getPresenterFactory()
        setPresenterFactory {
            val presenter = superFactory!!.createPresenter()
            mPresenterInjector.injectMembers(presenter)
            presenter
        }
        super.onCreate(savedInstanceState)
    }
}
```

**Actual class:**
```
class StartActivity : BaseGameActivity<StartPresenter>() {
    ...
    @Inject
    internal lateinit var mGoogleApiAvailability: GoogleApiAvailability
    ...
}

class StartPresenter : RxPresenter<StartActivity>() {
    ...
    @Inject
    ...
}
```

**ActivityBindingModule:**
```
@Module
abstract class ActivityBindingModule {

    @ActivityScope
    @ContributesAndroidInjector(modules = [StartActivityModule::class])
    internal abstract fun startActivity(): StartActivity
}
```

**StartActivityModule:**
```
@Module
class StartActivityModule {

    @Module
    companion object {

        @JvmStatic
        @Provides
        @ActivityScope
        fun provideGoogleApiAvailability() = GoogleApiAvailability.getInstance()
    }
}
```


**Error message:**

> error:  Cannot inject members into PresenterType

2.16, however, compiles and runs successfully.
I think it somehow relates to https://github.com/google/dagger/commit/3be3073f4b9a2c0216a30c71ff75b55d9d759db1","Can you provide a more full example?

Do you have a members injection method for BaseGameActivity, or for StartActivity?",Updated!
google/dagger,https://github.com/google/dagger/issues/1158,"FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':app:transformClassesWithMultidexlistForProductDebug'.
> java.lang.UnsupportedOperationException (no error message)

* Try:
Run with --info or --debug option to get more log output.

* Exception is:
org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':app:transformClassesWithMultidexlistForProductDebug'.
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46)
        at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35)
        at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:66)
        at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)
        at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52)
        at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)
        at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53)
        at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)
        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:203)
        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:185)
        at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:66)
        at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:50)
        at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
        at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
Caused by: java.lang.UnsupportedOperationException
        at com.android.ide.common.process.ProcessInfoBuilder$JavaProcessInfoImpl.getExecutable(ProcessInfoBuilder.java:349)
        at com.android.build.gradle.internal.process.GradleProcessResult.buildProcessException(GradleProcessResult.java:74)
        at com.android.build.gradle.internal.process.GradleProcessResult.assertNormalExitValue(GradleProcessResult.java:49)
        at com.android.builder.core.AndroidBuilder.createMainDexList(AndroidBuilder.java:1426)
        at com.android.build.gradle.internal.transforms.MultiDexTransform.callDx(MultiDexTransform.java:309)
        at com.android.build.gradle.internal.transforms.MultiDexTransform.computeList(MultiDexTransform.java:265)
        at com.android.build.gradle.internal.transforms.MultiDexTransform.transform(MultiDexTransform.java:186)
        at com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:178)
        at com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:174)
        at com.android.builder.profile.ThreadRecorder.record(ThreadRecorder.java:156)
        at com.android.build.gradle.internal.pipeline.TransformTask.transform(TransformTask.java:173)
        at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:75)
        at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$IncrementalTaskAction.doExecute(AnnotationProcessingTaskFactory.java:245)
        at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:221)
        at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$IncrementalTaskAction.execute(AnnotationProcessingTaskFactory.java:232)
        at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:210)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:80)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:61)
",What leads you to believe that Dagger somehow caused this?,
google/dagger,https://github.com/google/dagger/issues/611,It looks like at least some of the artifacts of Dagger 2.10RC2 are built without debug info for variables. When I did some debugging today I had no variable information available when debugging into some of the Android-related Dagger artifact classes.,"Can you give an example? 

```sh
wget https://oss.sonatype.org/content/repositories/public/com/google/dagger/dagger-android/2.10-rc2/dagger-android-2.10-rc2.aar
unzip dagger-android-2.10-rc2.aar
javap -v -c -cp classes.jar dagger.android.DaggerActivity
```

Gives me this output: https://gist.github.com/ronshapiro/ca611bb4bb710c785f5f1a43a83508cc

Here's a Fieldref that looks to be as intended: https://gist.github.com/ronshapiro/ca611bb4bb710c785f5f1a43a83508cc#file-daggeractivity-javap-L13","Is the intention to enable debugging into the Dagger artifacts with local variable information available? This needs the appropriate `-g` option to `javac` - https://docs.oracle.com/javase/8/docs/technotes/tools/windows/javac.html

Right now I don't see local variables/parameters when debugging in Android Studio. For example, in `DaggerActivity.onCreate(Bundle savedInstanceState)` I don't see the value of `savedInstanceState`. Same with `Preconditions.checkNotNull(T reference, String errorMessage)`."
google/dagger,https://github.com/google/dagger/issues/458,"I tried updating my Android project from version 2.0 to 2.6.1 and saw the following error message:

```
* What went wrong:
Execution failed for task ':app:compileDebugJavaWithJavac'.
> java.lang.StackOverflowError
```

I then tried various version of Dagger2 to see which version caused the problem. 2.0.1 works fine, but 2.0.2 exhibits it for me.

When I run the task with the `--stacktrace` flag, I see the following ad infinitum:

```
at dagger.internal.codegen.ModuleDescriptor$Factory.collectIncludedModules(ModuleDescriptor.java:116)
at dagger.internal.codegen.ModuleDescriptor$Factory.create(ModuleDescriptor.java:89)
at dagger.internal.codegen.ModuleDescriptor$Factory.collectIncludedModules(ModuleDescriptor.java:116)
at dagger.internal.codegen.ModuleDescriptor$Factory.create(ModuleDescriptor.java:89)
```

Any ideas? Let me know what I can provide that might help with diagnosis. Much obliged.
","Did you
mean ThreeMvp.Presenter as the return type?

This is a bug which should be fixed in 2.7 (I'm releasing tomorrow) and
then a follow-on fix in the next release by @gk5885 which should be even
better.

On Wed, Sep 7, 2016, 5:53 PM Tony Robalik notifications@github.com wrote:

> With that hint, I was able to track down a circular dependency among my
> modules. I removed them and successfully upgraded to Dagger 2.6.1. (Thank
> you!)
> 
> However, my next step was to replace some of my @Provides methods with
> @Binds methods. I did so (example below), and ran into another
> StackOverflowError. Sample output below the code example.
> 
> @Module(includes = { ... })
> public abstract class PresenterModule {
> 
> ```
> @Binds
> public abstract OneMvp.Presenter bindSplashHeadlessPresenter(OnePresenter presenter);
> 
> @Binds
> public abstract TwoMvp.Presenter bindLoginPresenter(TwoPresenter presenter);
> 
> @Binds
> public abstract ThreePresenter bindNowPlayingPresenter(ThreePresenter presenter);
> ```
> 
> Note there are no typos, there. We're doing some incremental refactoring
> and replacing our presenter references with interfaces. The first two
> return the concrete implementation as its interface. The third returns it
> as the implementation. Not sure if that's relevant.
> 
> at dagger.shaded.auto.common.MoreTypes$1.doHash(MoreTypes.java:71)
> at com.google.common.base.Equivalence.hash(Equivalence.java:106)
> at com.google.common.base.Equivalence$Wrapper.hashCode(Equivalence.java:220)
> at dagger.internal.codegen.AutoValue_Key.hashCode(AutoValue_Key.java:70)
> at com.google.common.collect.RegularImmutableMap.get(RegularImmutableMap.java:119)
> at com.google.common.collect.RegularImmutableMap.get(RegularImmutableMap.java:111)
> at com.google.common.collect.ImmutableSetMultimap.get(ImmutableSetMultimap.java:362)
> at dagger.internal.codegen.BindingGraph$Factory$Resolver.getExplicitBindings(BindingGraph.java:673)
> at dagger.internal.codegen.BindingGraph$Factory$Resolver.lookUpBindings(BindingGraph.java:357)
> at dagger.internal.codegen.BindingGraph$Factory$Resolver.createDelegateBinding(BindingGraph.java:541)
> at dagger.internal.codegen.BindingGraph$Factory$Resolver.createDelegateBindings(BindingGraph.java:528)
> at dagger.internal.codegen.BindingGraph$Factory$Resolver.getExplicitBindings(BindingGraph.java:675)
> 
> Once again, any ideas are much appreciated.
> 
> —
> You are receiving this because you commented.
> 
> Reply to this email directly, view it on GitHub
> https://github.com/google/dagger/issues/458#issuecomment-245431481, or mute
> the thread
> https://github.com/notifications/unsubscribe-auth/AAwY3aLmCxOqKYGGtNgrx4a9WUf94N9cks5qnzJegaJpZM4J3Pc_
> .
","Yeah, that wasn't a typo, as I pointed out in my brief paragraph between the two code samples :)

I want to switch to `@Binds` to avoid having to update my `@Provides` methods every time I change the constructor params. In some cases, we're injecting our presenters as interfaces, whereas in other cases we're injecting them as the implementations. This is a temporary situation while we do incremental refactoring. Does binding to the same thing simply not work? Is there a better way to do that? Or do I just wait for 2.7 and use that?

Thanks again.
"
google/dagger,https://github.com/google/dagger/issues/446,"This build error is created when compiling with 2.6, but not 2.2. 
Execution failed for task ':cnn:compileDevelopmentDebugJavaWithJavac'.

> java.lang.NoSuchMethodError: com.google.common.collect.FluentIterable.append(Ljava/lang/Iterable;)Lcom/google/common/collect/FluentIterable;

This issue seems similar to https://github.com/google/dagger/issues/356 and the same solution works for this error too. Include guava explicitly with the apt plugin.

The other annotation processor in the project in this case is realm 2.1.3.
","Did you check to make sure the gradle versions are up to date with what's referenced there?

There's not much we can do here, guava has a stable API, and the other annotation processors should make sure to update.
","Yes. I'm using grade plugin 2.1.3, realm 1.2.0, gradle 2.14.1. So I'll check realm's repo to see what guava version they're using then.
"
google/dagger,https://github.com/google/dagger/issues/406,"Basically, something I've noticed, if you have a android-library module with base classes for your activities or w.e. you wish. There will be an issue in compiling when you subclass those base classes. 

So what appears to be happening... is that to be safe, the processor puts the providers in the module's namespace to be able to access package private fields and expose them publicly for the dagger components to be able to inject in their own dependency's modules (in cases of package private @inject declarations) Is there a reason for this? It looks to me as you could easily write this to generate the provider factories in the dagger compiler's module if it knows that all provider methods are public...

https://github.com/PatryksPlaygrounds/DaggerBehaviour

logs:

```
Executing tasks: [clean, :app:generateDebugSources, :app:generateDebugAndroidTestSources, :app:mockableAndroidJar, :app:prepareDebugUnitTestDependencies, :app:compileDebugSources, :app:compileDebugAndroidTestSources, :app:compileDebugUnitTestSources, :othermodule:generateDebugSources, :othermodule:generateDebugAndroidTestSources, :othermodule:mockableAndroidJar, :othermodule:prepareDebugUnitTestDependencies, :othermodule:compileDebugSources, :othermodule:compileDebugAndroidTestSources, :othermodule:compileDebugUnitTestSources]

Configuration on demand is an incubating feature.
Incremental java compilation is an incubating feature.
:clean
:app:clean
:othermodule:clean
:app:preBuild UP-TO-DATE
:app:preDebugBuild UP-TO-DATE
:app:checkDebugManifest
:app:preReleaseBuild UP-TO-DATE
:othermodule:preBuild UP-TO-DATE
:othermodule:preReleaseBuild UP-TO-DATE
:othermodule:checkReleaseManifest
:othermodule:preDebugAndroidTestBuild UP-TO-DATE
:othermodule:preDebugBuild UP-TO-DATE
:othermodule:preDebugUnitTestBuild UP-TO-DATE
:othermodule:preReleaseUnitTestBuild UP-TO-DATE
:othermodule:prepareComAndroidSupportAnimatedVectorDrawable2400Library
:othermodule:prepareComAndroidSupportAppcompatV72400Library
:othermodule:prepareComAndroidSupportSupportV42400Library
:othermodule:prepareComAndroidSupportSupportVectorDrawable2400Library
:othermodule:prepareReleaseDependencies
:othermodule:compileReleaseAidl
:othermodule:compileReleaseNdk UP-TO-DATE
:othermodule:compileLint
:othermodule:copyReleaseLint UP-TO-DATE
:othermodule:compileReleaseRenderscript
:othermodule:generateReleaseBuildConfig
:othermodule:generateReleaseResValues
:othermodule:generateReleaseResources
:othermodule:mergeReleaseResources
:othermodule:processReleaseManifest
:othermodule:processReleaseResources
:othermodule:generateReleaseSources
:othermodule:incrementalReleaseJavaCompilationSafeguard
:othermodule:compileReleaseJavaWithJavac
:othermodule:compileReleaseJavaWithJavac - is not incremental (e.g. outputs have changed, no previous execution, etc.).

Note: /Users/patrykpoborca/Documents/consulting/plagrounds/othermodule/src/main/java/patrykpoborca/io/othermodule/BaseClassTwo.java uses unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.

:othermodule:extractReleaseAnnotations
:othermodule:mergeReleaseShaders
:othermodule:compileReleaseShaders
:othermodule:generateReleaseAssets
:othermodule:mergeReleaseAssets
:othermodule:mergeReleaseProguardFiles UP-TO-DATE
:othermodule:packageReleaseRenderscript UP-TO-DATE
:othermodule:packageReleaseResources
:othermodule:processReleaseJavaRes UP-TO-DATE
:othermodule:transformResourcesWithMergeJavaResForRelease
:othermodule:transformClassesAndResourcesWithSyncLibJarsForRelease
:othermodule:mergeReleaseJniLibFolders
:othermodule:transformNative_libsWithMergeJniLibsForRelease
:othermodule:transformNative_libsWithSyncJniLibsForRelease
:othermodule:bundleRelease
:app:prepareComAndroidSupportAnimatedVectorDrawable2400Library
:app:prepareComAndroidSupportAppcompatV72400Library
:app:prepareComAndroidSupportConstraintConstraintLayout100Alpha3Library
:app:prepareComAndroidSupportSupportV42400Library
:app:prepareComAndroidSupportSupportVectorDrawable2400Library
:app:preparePlagroundsOthermoduleUnspecifiedLibrary
:app:prepareDebugDependencies
:app:compileDebugAidl
:app:compileDebugRenderscript
:app:generateDebugBuildConfig
:app:generateDebugResValues
:app:generateDebugResources
:app:mergeDebugResources
:app:processDebugManifest
:app:processDebugResources
:app:generateDebugSources
:app:preDebugAndroidTestBuild UP-TO-DATE
:app:prepareComAndroidSupportTestEspressoEspressoCore222Library
:app:prepareComAndroidSupportTestEspressoEspressoIdlingResource222Library
:app:prepareComAndroidSupportTestExposedInstrumentationApiPublish05Library
:app:prepareComAndroidSupportTestRules05Library
:app:prepareComAndroidSupportTestRunner05Library
:app:prepareDebugAndroidTestDependencies
:app:compileDebugAndroidTestAidl
:app:processDebugAndroidTestManifest
:app:compileDebugAndroidTestRenderscript
:app:generateDebugAndroidTestBuildConfig
:app:generateDebugAndroidTestResValues
:app:generateDebugAndroidTestResources
:app:mergeDebugAndroidTestResources
:app:processDebugAndroidTestResources
:app:generateDebugAndroidTestSources
:app:mockableAndroidJar
:app:preDebugUnitTestBuild UP-TO-DATE
:app:prepareDebugUnitTestDependencies
:app:incrementalDebugJavaCompilationSafeguard
:app:compileDebugJavaWithJavac
Note: Generating a MembersInjector for patrykpoborca.io.othermodule.BaseActivity. Prefer to run the dagger processor over that class instead.
/Users/patrykpoborca/Documents/consulting/plagrounds/app/build/generated/source/apt/debug/patrykpoborca/io/plagrounds/DaggerActivityComponent.java:13: error: cannot find symbol
import patrykpoborca.io.othermodule.activitylevel.ActivityModule_ProvidesBaseActivityFactory;
                                                 ^
  symbol:   class ActivityModule_ProvidesBaseActivityFactory
  location: package patrykpoborca.io.othermodule.activitylevel
1 error

 FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':app:compileDebugJavaWithJavac'.
> Compilation failed; see the compiler error output for details.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

```

Thanks!
","Shouldn't Proguard run only on the whole APK?
","Here is [`--debug`](https://gist.githubusercontent.com/patrykpoborca/0917881a92bb77957b3bdf03b681e4c2/raw/4222523a1145994e3a0809535c3e4bad56c8a7b9/log.txt) and here is the [`--stacktrace`](https://gist.github.com/patrykpoborca/30fa5c53f0cbe760e576509d5fbfb68f) and here is [`--info`](https://gist.github.com/patrykpoborca/eacc30253038ea4ae4c09835431afe73)

Can APT write into the generated files of a library module that doesn't have that APT running though? And if not, is there a way to get around it?
"
google/dagger,https://github.com/google/dagger/issues/290,"I don't have much more info than this stack trace but I'm suddenly seeing this error in Eclipse (4.5.1) in conjunction with Dagger 2.1-SNAPSHOT.

My best guess is that it has something to do with differences in how Eclipse's `org.eclipse.jdt.internal.compiler.apt.model.TypesImpl` is implemented vs. javac.

```
org.eclipse.jdt.internal.compiler.apt.model.TypesImpl.asMemberOf(TypesImpl.java:129)
    at dagger.internal.codegen.MembersInjectionBinding$Factory.injectionSiteForInjectMethod(MembersInjectionBinding.java:154)
```

```
!ENTRY org.eclipse.jdt.apt.pluggable.core 4 1 2016-01-05 14:52:27.388
!MESSAGE Exception thrown by Java annotation processor dagger.internal.codegen.ComponentProcessor@6a740d75
!STACK 0
java.lang.IllegalArgumentException: element protected abstract void initChannel(C) throws java.lang.Exception is not a member of the containing type io.netty.channel.ChannelInitializer<io.netty.channel.socket.SocketChannel> nor any of its superclasses
    at org.eclipse.jdt.internal.compiler.apt.model.TypesImpl.asMemberOf(TypesImpl.java:129)
    at dagger.internal.codegen.MembersInjectionBinding$Factory.injectionSiteForInjectMethod(MembersInjectionBinding.java:154)
    at dagger.internal.codegen.MembersInjectionBinding$Factory.access$100(MembersInjectionBinding.java:136)
    at dagger.internal.codegen.MembersInjectionBinding$Factory$4.visitExecutableAsMethod(MembersInjectionBinding.java:318)
    at dagger.internal.codegen.MembersInjectionBinding$Factory$4.visitExecutableAsMethod(MembersInjectionBinding.java:314)
    at javax.lang.model.util.ElementKindVisitor6.visitExecutable(ElementKindVisitor6.java:340)
    at org.eclipse.jdt.internal.compiler.apt.model.ExecutableElementImpl.accept(ExecutableElementImpl.java:59)
    at javax.lang.model.util.AbstractElementVisitor6.visit(AbstractElementVisitor6.java:97)
    at dagger.internal.codegen.MembersInjectionBinding$Factory.getInjectionSites(MembersInjectionBinding.java:248)
    at dagger.internal.codegen.MembersInjectionBinding$Factory.hasInjectedMembers(MembersInjectionBinding.java:179)
    at dagger.internal.codegen.InjectBindingRegistry.tryRegisterConstructor(InjectBindingRegistry.java:236)
    at dagger.internal.codegen.InjectBindingRegistry.tryRegisterConstructor(InjectBindingRegistry.java:215)
    at dagger.internal.codegen.InjectProcessingStep$1.visitExecutableAsConstructor(InjectProcessingStep.java:64)
    at dagger.internal.codegen.InjectProcessingStep$1.visitExecutableAsConstructor(InjectProcessingStep.java:60)
    at javax.lang.model.util.ElementKindVisitor6.visitExecutable(ElementKindVisitor6.java:334)
    at org.eclipse.jdt.internal.compiler.apt.model.ExecutableElementImpl.accept(ExecutableElementImpl.java:59)
    at dagger.internal.codegen.InjectProcessingStep.process(InjectProcessingStep.java:59)
    at dagger.shaded.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:318)
    at dagger.shaded.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:171)
    at org.eclipse.jdt.internal.compiler.apt.dispatch.RoundDispatcher.handleProcessor(RoundDispatcher.java:139)
    at org.eclipse.jdt.internal.compiler.apt.dispatch.RoundDispatcher.round(RoundDispatcher.java:121)
    at org.eclipse.jdt.internal.compiler.apt.dispatch.BaseAnnotationProcessorManager.processAnnotations(BaseAnnotationProcessorManager.java:159)
    at org.eclipse.jdt.internal.apt.pluggable.core.dispatch.IdeAnnotationProcessorManager.processAnnotations(IdeAnnotationProcessorManager.java:134)
    at org.eclipse.jdt.internal.compiler.Compiler.processAnnotations(Compiler.java:909)
    at org.eclipse.jdt.internal.compiler.Compiler.compile(Compiler.java:434)
    at org.eclipse.jdt.internal.core.builder.AbstractImageBuilder.compile(AbstractImageBuilder.java:367)
    at org.eclipse.jdt.internal.core.builder.BatchImageBuilder.compile(BatchImageBuilder.java:179)
    at org.eclipse.jdt.internal.core.builder.AbstractImageBuilder.compile(AbstractImageBuilder.java:304)
    at org.eclipse.jdt.internal.core.builder.BatchImageBuilder.build(BatchImageBuilder.java:61)
    at org.eclipse.jdt.internal.core.builder.JavaBuilder.buildAll(JavaBuilder.java:256)
    at org.eclipse.jdt.internal.core.builder.JavaBuilder.build(JavaBuilder.java:175)
    at org.eclipse.core.internal.events.BuildManager$2.run(BuildManager.java:734)
    at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)
    at org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:205)
    at org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:245)
    at org.eclipse.core.internal.events.BuildManager$1.run(BuildManager.java:300)
    at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)
    at org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:303)
    at org.eclipse.core.internal.events.BuildManager.basicBuildLoop(BuildManager.java:359)
    at org.eclipse.core.internal.events.BuildManager.build(BuildManager.java:382)
    at org.eclipse.core.internal.events.AutoBuildJob.doBuild(AutoBuildJob.java:144)
    at org.eclipse.core.internal.events.AutoBuildJob.run(AutoBuildJob.java:235)
    at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)
```
","Does this work with `javac`?
","Yes, no problems with javac
"
google/dagger,https://github.com/google/dagger/issues/214,"So I have an abstract base class, BaseDialogFragment that does injection and then subclasses of that also do injection. I am seeing the component that is generated (in my case actually a subcomponent) such that it creates the MembersInjector for subclasses before it creates the MembersInjector for the base class. Because it needs the injector for the base class in order to create the injector for the subclass, it ends up passing a null for the superTypeInjector parameter and when you try to inject the subclass you get a null pointer exception.

There doesn't seem to be any dependency analysis done to determine what order the injectors need to be created in. The only way I have found to enforce the ordering is to explicitly define an inject method for the base class in the component and make sure that it comes BEFORE the subclass injection methods.

The code needs to analyze the dependencies to make sure they are created before being referenced.
","What do you mean by ""that does injection""? Do you explicitly call `component.inject(this)` in your base class? If so I made the experience that explicit injection in base classes should be avoided since the dependencies specified in the base class(es) are injected twice, once when the injection is performed in the base class and second when it's performed in the concrete class. Therefor in my Android projects I avoid calling the dependency injection explicitly in base classes.

If you look at my [Android example project](https://github.com/svenjacobs/dagger2-android-template) this case is exactly the reason why I've created the [onPostComponentCreated()](https://github.com/svenjacobs/dagger2-android-template/blob/master/android-template/src/main/java/com/svenjacobs/dagger/inject/ComponentLifecycle.java) lifecycle method. This method can be used by base classes to access and configure injected dependencies once the injection has been performed in the concrete class.
","It has nothing to do with when inject is called. The issue is in the actual class that Dagger generates. So I have my BaseDialogFragment that has something like:

```
public abstract class BaseDialogFragment extends DialogFragment
{
     @Inject Bus bus;
```

and I have 

```
public class ForgotPasswordDialogFragment extends BaseDialogFragment
{
    @Inject NetworkService networkService;
```

and with all lines unrelated to these 2 classes removed this is what Dagger generates:

```
private final class ActivityComponentImpl implements ActivityComponent {
  private MembersInjector<ForgotPasswordDialogFragment> 
  private MembersInjector<BaseDialogFragment> baseDialogFragmentMembersInjector;

  private ActivityComponentImpl(ActivityModule activityModule) {  
    initialize();
    initialize1();
  }

  private void initialize() {  
   this.forgotPasswordDialogFragmentMembersInjector =
       ForgotPasswordDialogFragment_MembersInjector.create(
             baseDialogFragmentMembersInjector,
             DaggerAppComponent.this.provideNetworkServiceProvider,
             DaggerAppComponent.this.provideEmailObservablePreferenceProvider);
 }

  private void initialize1() {  
    this.baseDialogFragmentMembersInjector =
        BaseDialogFragment_MembersInjector.create(
             (MembersInjector) MembersInjectors.noOp(),
             DaggerAppComponent.this.provideBusProvider);
  }
}
```

Notice that in the `initialize()` method that `baseDialogFragmentMembersInjector` is passed to `ForgotPasswordDialogFragment_MembersInjector.create()`, **BUT** it is still null at this point because it isn't initialized until later when `initialize1()` is called. So when you try to inject `ForgotPasswordDialogFragment` you get an NPE when it tries to use the null pointer it was given.

Luckily for our app the injection in the base class wasn't actually being used so I was able to rip it out and sidestep the problem, but this is a bug.
"
google/dagger,https://github.com/google/dagger/issues/198,"The most recent 2.1-SNAPSHOT of dagger-producers has a dependency on dagger-parent 2.0.1 which doesn't exist and breaks everything on my end.

https://oss.sonatype.org/content/repositories/snapshots/com/google/dagger/dagger-producers/2.1-SNAPSHOT/dagger-producers-2.1-20150528.211922-7.pom

```
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">
<modelVersion>4.0.0</modelVersion>
<parent>
<groupId>com.google.dagger</groupId>
<artifactId>dagger-parent</artifactId>
<version>2.0.1</version>
</parent>
<artifactId>dagger-producers</artifactId>
<version>2.1-SNAPSHOT</version>
<name>Dagger Production Graphs</name>
<description>
An asynchronous dependency injection system that extends JSR-330.
</description>
<dependencies>
<dependency>
<groupId>${project.groupId}</groupId>
<artifactId>dagger</artifactId>
<version>${project.version}</version>
</dependency>
<dependency>
<groupId>com.google.guava</groupId>
<artifactId>guava</artifactId>
</dependency>
<dependency>
<groupId>junit</groupId>
<artifactId>junit</artifactId>
<scope>test</scope>
</dependency>
<dependency>
<groupId>com.google.truth</groupId>
<artifactId>truth</artifactId>
<scope>test</scope>
</dependency>
</dependencies>
</project>
```
","Can you please test against the current snapshot and see if the issue is still present?
","Things are working again. Thanks!
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6954,"I have problem on the 2.11.1 release right now.
Sometimes, when switching different files, with different codecs, with codec cache enabled, onAudioSessionId events do not work at all! At this time mMediaPlayer.getAudioSessionId() produces 0.
Most often it happens when you switch from 4k movie to mp3 track.
Music is playing, but no audio session and no onAudioSessionId events.
Fix it, please.
What details are you interested in?","What is the type of mMediaPlayer? Did it work with a previous version of ExoPlayer? Could you please provide steps to reproduce the issue, together with the test contents, as described [here](https://github.com/google/ExoPlayer/blob/release-v2/.github/ISSUE_TEMPLATE/bug.md)?","Thank you for the answer. This bug is available if you call stop after a track with mMediaPlayer.setForegroundMode(true);
It took me a long time to figure out what was going on, but then I found an instruction in the depths of the code explaining that I don't need to call a stop in this case.
Now it works correctly."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6951,"Getting stacktrace below when trying to play DRM video on Android TV api ver 28

Version of ExoPlayer being used: 2.11.1

Stacktrace:
```
E/ExoPlayerImplInternal: Internal runtime error.
    java.lang.NullPointerException
        at com.google.android.exoplayer2.util.Assertions.checkNotNull(Assertions.java:147)
        at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.createNewDefaultSession(DefaultDrmSessionManager.java:563)
        at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.acquireSession(DefaultDrmSessionManager.java:530)
        at com.google.android.exoplayer2.BaseRenderer.getUpdatedSourceDrmSession(BaseRenderer.java:322)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:1235)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:755)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.readToFlagsOnlyBuffer(MediaCodecRenderer.java:801)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:700)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:599)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:329)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:193)
        at android.os.HandlerThread.run(HandlerThread.java:65)`

`E/EventLogger: playerFailed [eventTime=1.15, mediaPos=0.00, window=0, period=0]
    com.google.android.exoplayer2.ExoPlaybackException: java.lang.NullPointerException
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:401)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:193)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: java.lang.NullPointerException
        at com.google.android.exoplayer2.util.Assertions.checkNotNull(Assertions.java:147)
        at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.createNewDefaultSession(DefaultDrmSessionManager.java:563)
        at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.acquireSession(DefaultDrmSessionManager.java:530)
        at com.google.android.exoplayer2.BaseRenderer.getUpdatedSourceDrmSession(BaseRenderer.java:322)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:1235)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:755)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.readToFlagsOnlyBuffer(MediaCodecRenderer.java:801)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:700)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:599)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:329)
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:193) 
        at android.os.HandlerThread.run(HandlerThread.java:65)
```

Seems like some parameter excepted as not-null in Kotlin is null, but i can't see which exactly",Can you provide repro steps for this in the demo app? ,
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6944,"I am trying to remove PlayerNotificationManager notification on activity destroy but it's not removing notification after app killed

```
private fun killPlayer() {
         playerNotificationManager.setPlayer(null)
        if (exoPlayer != null) {
            exoPlayer.release()
            mediaSource = null
        }
    }
```

can anyone suggest me why notification is not removed programmatically ","May I ask you to check whether this is the case for you? I change the type of this issue to 'question'. I'll put it back to 'bug' in case we can rule out the foreground service reason. LMK.



","I am using this code to show notification in main activity

```
playerNotificationManager = PlayerNotificationManager.createWithNotificationChannel(
            this,""channel_id"",R.string.channelName,R.string.channelDescription,11,
            object : PlayerNotificationManager.MediaDescriptionAdapter{
                override fun createCurrentContentIntent(player: Player): PendingIntent? {
                    val intent = Intent(this@MainActivity, MainActivity::class.java)
                    return PendingIntent.getActivity(this@MainActivity,0,intent, PendingIntent.FLAG_UPDATE_CURRENT)
                }

                override fun getCurrentContentText(player: Player): String? {
                    return mSongList[player.currentWindowIndex].descripation // descrption
                }

                override fun getCurrentContentTitle(player: Player): String {
                    return mSongList[player.currentWindowIndex].name // title
                }

                override fun getCurrentLargeIcon(
                    player: Player,
                    callback: PlayerNotificationManager.BitmapCallback
                ): Bitmap? {
                    return this@MainActivity.getBitmap(R.drawable.bg)
                }

            } ,null
        )

        playerNotificationManager.setUseStopAction(false)  //stop song
        playerNotificationManager.setRewindIncrementMs(0)   //hide rewind button
        playerNotificationManager.setFastForwardIncrementMs(0)  //hide fast forward button
        playerNotificationManager.setPlayer(exoPlayer)
```

I am not using any foreground service to show notification"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6785,"### Issue description
The following crash is being seen in Crashlytics

```
Fatal Exception: java.lang.IllegalStateException
       at com.google.android.exoplayer2.util.Assertions.checkState(Assertions.java:81)
       at com.google.android.exoplayer2.offline.Download.<init>(Download.java:133)
       at com.google.android.exoplayer2.offline.DefaultDownloadIndex.getDownloadForCurrentRow(DefaultDownloadIndex.java:359)
       at com.google.android.exoplayer2.offline.DefaultDownloadIndex.access$100(DefaultDownloadIndex.java:35)
       at com.google.android.exoplayer2.offline.DefaultDownloadIndex$DownloadCursorImpl.getDownload(DefaultDownloadIndex.java:409)
       at com.google.android.exoplayer2.offline.DownloadManager$InternalHandler.initialize(DownloadManager.java:697)
       at com.google.android.exoplayer2.offline.DownloadManager$InternalHandler.handleMessage(DownloadManager.java:630)
       at android.os.Handler.dispatchMessage(Handler.java:106)
       at android.os.Looper.loop(Looper.java:216)
       at android.os.HandlerThread.run(HandlerThread.java:65)
```
It appears that the download progress is `null` which is failing the assertion.  From what I can see this progress is returned from the database.

Over the last 90 days: This issue has 1070 crashes affecting 110 users.

### Reproduction steps
We have not been able to reproduce this issue ourselves, but it is currently our biggest crash in Crashlytics and has recently generated a velocity alert.

### Link to test content
If required please let us know and we can try to provide access to a test user account

###  A full bug report captured from the device
As above this is an issue from Crashlytics so unable to capture a bug report ourselves

### Version of ExoPlayer being used
v2.10.4

### Device(s) and version(s) of Android being used
80% Samsung (Galaxy S8, S9, S8+)
5% Huawei (p20 lite, Y7 Prime 2019, P smart 2019)
4% OnePlus (A6000, 7T Pro, 5T)
4% OPPO (CPH1725)
56% Other

65% Android 9
23& Android 8
6% Android 7
3% Android 5
3% Other

25% In background
0% Rooted
93% Proximity On","Does your app happen to call `DownloadService.sendRemoveAllDownloads`, `DownloadService.buildRemoveAllDownloadsIntent` or `DownloadManager.removeAllDownloads`? I think I see a possible bug along those code paths that might explain this.","I believe we do yes.

On Fri, 20 Dec 2019, 13:40 Oliver Woodman, <notifications@github.com> wrote:

> Thanks for the report. Does your app happen to call
> DownloadService.sendRemoveAllDownloads,
> DownloadService.buildRemoveAllDownloadsIntent or
> DownloadManager.removeAllDownloads? I think I see a possible bug along
> those code paths that might explain this.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/google/ExoPlayer/issues/6785?email_source=notifications&email_token=AAGP2RRMUI2AHOVUCZOLNXDQZS4NPA5CNFSM4J4766QKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHM2LCA#issuecomment-567911816>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAGP2RQ4LOW3GPFI4X3GW73QZS4NPANCNFSM4J4766QA>
> .
>
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6774,"### [REQUIRED] Issue description
com.google.android.exoplayer2.extractor.mp4.Sniffer cannot recognize the stream (see a link to torrent containing m4b files below).
ExoPlayer can play a file when media source is created with Mp4Extractor factory:
`MediaSource mediaSource = new ProgressiveMediaSource.Factory(dataSourceFactory, Mp4Extractor.FACTORY)`

However, exception is thrown when media source should recognize format:
`MediaSource mediaSource = new ProgressiveMediaSource.Factory(dataSourceFactory)`

### [REQUIRED] Reproduction steps
Download m4b files from torrent. Put any of them to test device/emulator. Define PATH_TO_FILE. Use the simplest code to play it by ExoPlayer:
```
mp = new SimpleExoPlayer.Builder(context)
	.setTrackSelector(new DefaultTrackSelector(context))
	.build();
mp.setAudioAttributes(new AudioAttributes.Builder()
	.setContentType(C.CONTENT_TYPE_MUSIC)
	.setUsage(C.USAGE_MEDIA).build());
DefaultDataSourceFactory dataSourceFactory = new DefaultDataSourceFactory(context, ""none"");
MediaSource mediaSource = new ProgressiveMediaSource.Factory(dataSourceFactory)
	.createMediaSource(Uri.fromFile(new File(PATH_TO_FILE)));
mp.prepare(mediaSource);
mp.setPlayWhenReady(true);
```

### [REQUIRED] Link to test content
[Torrent file](https://rutracker.org/forum/dl.php?t=5781821)

### [REQUIRED] A full bug report captured from the device
```
2019-12-17 17:21:03.783 25627-25627/mindmine.audiobook I/ExoPlayerImpl: Init 64ad1d2 [ExoPlayerLib/2.11.0] [blueline, Pixel 3, Google, 29]
2019-12-17 17:21:03.874 25627-25756/mindmine.audiobook E/ExoPlayerImplInternal: Source error.
    com.google.android.exoplayer2.source.UnrecognizedInputFormatException: None of the available extractors (MatroskaExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, Ac3Extractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor, AmrExtractor, Ac4Extractor) could read the stream.
        at com.google.android.exoplayer2.source.ProgressiveMediaPeriod$ExtractorHolder.selectExtractor(ProgressiveMediaPeriod.java:1095)
        at com.google.android.exoplayer2.source.ProgressiveMediaPeriod$ExtractingLoadable.load(ProgressiveMediaPeriod.java:974)
        at com.google.android.exoplayer2.upstream.Loader$LoadTask.run(Loader.java:391)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
        at java.lang.Thread.run(Thread.java:919)
```

### [REQUIRED] Version of ExoPlayer being used
2.9.6 , 2.11.0

### [REQUIRED] Device(s) and version(s) of Android being used
Pixel 3, Android 10
","Would it be possible for you to put the file on to a server and provide a URI accessible by http? 

Sorry for the inconvenience. ","Hi,
Could you please let me know on which server I can upload the file (~700Mb) so you can access it?"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6771,"### [REQUIRED] Issue description
I cannot generate signed apk/bundle. Whenever I do it, I get the following messages on failure:

`com.google.android.exoplayer2.text.ssa.SsaDecoder: can't find referenced class com.google.android.exoplayer2.text.ssa.SsaStyle$SsaAlignment`

`com.google.android.exoplayer2.text.ssa.SsaStyle$Overrides: can't find referenced class com.google.android.exoplayer2.text.ssa.SsaStyle$SsaAlignment`

### [REQUIRED] Reproduction steps
Attempt to generate a signed apk/bundle. I am using **ProGuard**.

### [REQUIRED] Link to test content

### [REQUIRED] A full bug report captured from the device

### [REQUIRED] Version of ExoPlayer being used
Latest (v2.11.0).

### [REQUIRED] Device(s) and version(s) of Android being used
","Can you provide more detailed repro instructions, including information about how you're depending on the ExoPlayer library?

","Hello @icbaker and thanks for the help. I am upgrading from 2.10.4 -> 2.11.0. I did not have any issues creating signed APKs before, so those messages are new to me. I am only adding the ui and core to my project:

`implementation 'com.google.android.exoplayer:exoplayer-core:2.11.0'`
`implementation 'com.google.android.exoplayer:exoplayer-ui:2.11.0'`

I have just tried enabling R8 instead of ProGuard, and I was able to create a signed APK without issues. Though, I favor ProGuard because it handles one aspect better. Note that I am only playing offline files on my app.

Does the demo app use R8 or ProGuard?"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6739,"I've just updated the lastest Exo and extension/flac libs. But I met the problem with Android 5.1. Sometimes, Player can't play the flac file. Sometimes, noise when playing FLAC content. 

Do you any suggestion to fix these issues ? Thank you so much.

","Can you please share your content so that we can test locally? You can send it via email to dev.exoplayer@gmail.com with subject ""Issue #6739"". Also, is this happening on a specific device?","Issue #6739 <https://github.com/google/ExoPlayer/issues/6739>

 TuTam-NguyenTranTrungQuan-6131334.flac
<https://drive.google.com/file/d/101DXS8GNQzx2VO5Kk20H-95OwjzeYM8q/view?usp=drive_web>
 XieuLong-PhamQuynhAnh-6132140.flac
<https://drive.google.com/file/d/1W6CfPFj-Bvih1CedM3nVJ6ueIbDDE4Aw/view?usp=drive_web>


On Mon, Dec 9, 2019 at 10:26 PM christosts <notifications@github.com> wrote:

> Can you please share your content so that we can test locally? You can
> send it via email to dev.exoplayer@gmail.com with subject ""Issue #6739
> <https://github.com/google/ExoPlayer/issues/6739>"". Also, is this
> happening on a specific device?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/google/ExoPlayer/issues/6739?email_source=notifications&email_token=ADIQB27LDOGZ4WLQ2RGUOMDQXZPRNA5CNFSM4JYF7KZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGJSHJY#issuecomment-563291047>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADIQB24JW3MVCMXQR53G6CDQXZPRNANCNFSM4JYF7KZQ>
> .
>
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6730,"### [REQUIRED] Issue description
We are seeing potential ANR in the application. It is coming when we are calling `openSession()` 

### [REQUIRED] Reproduction steps
When we are calling mediaDrm.openSession() then in `FrameworkMediaDrm` class, following method looks like waiting for the response from jni.

```
@Override
  public byte[] openSession() throws MediaDrmException {
    return mediaDrm.openSession();
  }
```

### [REQUIRED] A full bug report captured from the device
```
""main"" prio=5 tid=1 Native
  | group=""main"" sCount=1 dsCount=0 obj=0x754a5650 self=0xb3004400
  | sysTid=3300 nice=0 cgrp=bg_non_interactive sched=0/0 handle=0xb5c2c534
  | state=S schedstat=( 157239541 61332131 169 ) utm=10 stm=5 core=5 HZ=100
  | stack=0xbe26e000-0xbe270000 stackSize=8MB
  | held mutexes=
  #00  pc 0000000000048598  /system/lib/libc.so (__ioctl+8)
  #01  pc 000000000001ad03  /system/lib/libc.so (ioctl+38)
  #02  pc 000000000003cc55  /system/lib/libbinder.so (_ZN7android14IPCThreadState14talkWithDriverEb+168)
  #03  pc 000000000003d62f  /system/lib/libbinder.so (_ZN7android14IPCThreadState15waitForResponseEPNS_6ParcelEPi+238)
  #04  pc 000000000003655d  /system/lib/libbinder.so (_ZN7android8BpBinder8transactEjRKNS_6ParcelEPS1_j+36)
  #05  pc 0000000000086e83  /system/lib/libmedia.so (???)
  #06  pc 0000000000025731  /system/lib/libmedia_jni.so (_ZN7android4JDrm7MakeDrmEv+76)
  #07  pc 0000000000025435  /system/lib/libmedia_jni.so (_ZN7android4JDrm7MakeDrmEPKh+20)
  #08  pc 000000000002550f  /system/lib/libmedia_jni.so (_ZN7android4JDrmC1EP7_JNIEnvP8_jobjectPKh+134)
  #09  pc 00000000000263d3  /system/lib/libmedia_jni.so (???)
  #10  pc 00000000004766a1  /system/framework/arm/boot-framework.oat (Java_android_media_MediaDrm_native_1setup__Ljava_lang_Object_2_3B+116)
  at android.media.MediaDrm.native_setup (Native method)
  at android.media.MediaDrm.<init> (MediaDrm.java:215)
  at com.google.android.exoplayer2.drm.FrameworkMediaDrm.<init> (FrameworkMediaDrm.java:73)
  at com.google.android.exoplayer2.drm.FrameworkMediaDrm.newInstance (FrameworkMediaDrm.java:61)
  at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.newFrameworkInstance (DefaultDrmSessionManager.java:221)
  at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.newWidevineInstance (DefaultDrmSessionManager.java:143)
```

### [REQUIRED] Version of ExoPlayer being used
ExoPlayer version: 2.10.6

### [REQUIRED] Device(s) and version(s) of Android being used
Affected Android OS : 9, 8.1, 10, 5.1 etc
Device name: Redmi Note 7 Pro(violet), Mi A1(tissot_sprout), Redmi 5A(riva), Realme 2 Pro(RMX1801)
",Can you provide the media file and the necessary information to play it as described [here](https://github.com/google/ExoPlayer/blob/release-v2/.github/ISSUE_TEMPLATE/question.md#link-to-test-content)?,"Hi @kim-vde , I have replied you privately over the email."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6700,"When I try to play an AAC File under 30 seconds ExoPlayer throws java.io.EOFException if ""FLAG_ENABLE_CONSTANT_BITRATE_SEEKING"" is set.

Currently I use version 2.9.3. I tried also with 2.10.8 and it still reproduces

Device(s) and version(s) of Android being used
Samsung Galaxy s8+ Android 8
Lg Q6 Android 8.1

I sent the report and AAC File on email at dev.exoplayer@gmail.com
","How was this file produced? It seems it might have been sliced from a larger file using e.g. Unix `split`?

We probably shouldn't completely fail playback in this case though (given we successfully play the file when not using constant bitrate seeking) - I'll send a change that makes this slightly more robust.","I record files from online streams, I slice the file when I stop the recording. I don't check if the frame is complete or not."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6694,"Hello Exoplayer team.

i used Exoplayer in my app.
i have a problem.
when i play video format .mkv or Matroska on mobile device and android box 
video can't support Audio ac3 some device

i used Ffmpeg extension in my project, for decode audio renderer
video can play and audio support, but i have a problem

some device android box, CPU usage allwinner h6. example Android box Tx6, Android box X96H
when play video picture not smooth and freezes

could I ask for your advice about fix it.","What version of ExoPlayer are you using?
1. Did you build the FFmpeg extension with ac3 support enabled? https://exoplayer.dev/supported-formats.html#ffmpeg-extension
1. Does the issue reproduce in the ExoPlayer demo app? If so please attach a bug report showing the repro - or send it to dev.exoplayer@gmail.com if you don't want to attach it publicly.
1. Can you provide sample media that demonstrates the problem? Send it to dev.exoplayer@gmail.com if you don't want to attach it publicly.
    * If you can't provide the sample media, and it's a video-related problem, we at least need to know the video codec used inside the MKV container.
1. Can you more precisely describe the problem? You mention that AC3 audio isn't supported, but also say that the video isn't smooth - these don't sound like the same problem.
",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6654,"Using the exoplayer demo application for version 2.10.4 in a concrete mobile phone I'm not able to play DASH+widevine video.

The information of the device it's the following:
Device name: Galaxy J7
Model number: SM-J700H
Android version: 6.0.1
Kernel version: 3.10.61-13202935
Build number: MMB29K_J700HXWU3BRC1

This it's the concrete asset used from exoplayer demo:
```
{
        ""name"": ""Exoplayer test asset WV: Secure SD (MP4,H265)"",
        ""uri"": ""https://storage.googleapis.com/wvmedia/cenc/hevc/tears/tears_sd.mpd"",
        ""drm_scheme"": ""widevine"",
        ""drm_license_url"": ""https://proxy.uat.widevine.com/proxy?provider=widevine_test""
 }
```

The error given by exoplayer it's:
```
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: Playback error.
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: com.google.android.exoplayer2.ExoPlaybackException: android.media.MediaCodec$CryptoException: Unknown Error
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:1122)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:654)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:575)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:326)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at android.os.Handler.dispatchMessage(Handler.java:98)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at android.os.Looper.loop(Looper.java:148)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at android.os.HandlerThread.run(HandlerThread.java:61)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: Caused by: android.media.MediaCodec$CryptoException: Unknown Error
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at android.media.MediaCodec.native_queueSecureInputBuffer(Native Method)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at android.media.MediaCodec.queueSecureInputBuffer(MediaCodec.java:2292)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:1113)
11-14 20:13:49.282 17940 27651 E ExoPlayerImplInternal: 	... 6 more
```

Attached a file with the logs of the device whem the error it's reproduced:
[error_logs.txt](https://github.com/google/ExoPlayer/files/3847178/error_logs.txt)

With this mobile phone using the DASH-IF reference player this video can be played.

","Did you test with this the device with the most recent OS available for that device? If you tested, can you confirm this does fix the problem?

",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6590,"hi , we have this error while running local video  on android api 17,but on another android api 17 no problem. how can we fix it ?
thanks!

MediaCodec: Codec reported an error. (omx error 0x80001001, internalError -2147483648)
01-01 02:11:31.868 1494-1632/com.hdl.m3u8demo E/ExoPlayerImplInternal: Internal runtime error.
    java.lang.IllegalStateException
        at android.media.MediaCodec.queueInputBuffer(Native Method)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:773)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:583)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:518)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:301)
        at android.os.Handler.dispatchMessage(Handler.java:95)
        at android.os.Looper.loop(Looper.java:138)
        at android.os.HandlerThread.run(HandlerThread.java:60)
[video.txt](https://github.com/google/ExoPlayer/files/3777989/video.txt)
","Does it happen on a specific device only, or also on other devices running API 17?",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6582,"### Use case description
When switching from ExoPlayer to CastPlayer, I have an UI inconstancy on the Shuffle state when ExoPlayer was shuffle enabled.
The UI is still reporting that CastPlayer queue is shuffled.

### Proposed solution
in CastPlayer::updateInternalState() add something like
`notificationsBatch.add(new ListenerNotificationTask(listener -> listener.onShuffleModeEnabledChanged(false));`

",Can you state exactly what's going on? Perhaps provide a set of minimal changes to reproduce in the demo app?,"maybe I should have added that I'm using the mediasession extension.
My UI is observing the MediaController shuffleMode.

When i switch from ExoPlayer (with shuffle enabled) to CastPlayer, the shuffleMode of the MediaController is not set to false, because CastPlayer doesn't report it through the onShuffleModeEnabledChanged() method"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6560,"I have implemented exoplayer with exoplayer cast extension in july 2019 and everything worked fine in august 2019 for my clients :
https://github.com/google/ExoPlayer/tree/release-v2
https://github.com/google/ExoPlayer/tree/release-v2/extensions/

    dependencies {
      implementation 'com.google.android.exoplayer:exoplayer-dash:2.9.6'
      implementation 'com.google.android.exoplayer:extension-cast:2.9.6'
    }
But suddenly, I have tested it this month (october 2019) on my chromecast and it doesn't work anymore.
Exoplayer still play video but it doesn't detect any chromecast.
My chromecast still works with Youtube cast or Netflix cast.

My code hasn't changed since august.
Someone has experience the same thing or has a clue of what is going on ?",Can you check which receiver app id you are using?,
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6530,"I am unable to resolve this bug from 4 days so I need to post it here. I have two devices OPPO F11 Pro and Honor 6X. I am getting black screen problem after playing videos. My app is in beta in app store, just play some video around 8-12 videos then back to previous videos. Once black screen come no single video will start playing.

Beta Version:- https://play.google.com/store/apps/details?id=coders.hub.daily_status

Logcat:-
```java
10-11 13:01:35.047 678-28268/? E/OMXNodeInstance: getConfig(0xf0234ec0:google.aac.decoder, ConfigAndroidVendorExtension(0x6f100004)) ERROR: Undefined(0x80001001)
2019-10-11 13:01:35.105 678-28259/? E/osal_utils: Returns insufficientResource
2019-10-11 13:01:35.105 678-28259/? E/media.codec: Failed to allocate omx component 'OMX.MTK.VIDEO.DECODER.AVC'  err=InsufficientResources(0x80001000)
2019-10-11 13:01:35.106 13075-17958/coders.hub.daily_status E/ACodec: Unable to instantiate codec 'OMX.MTK.VIDEO.DECODER.AVC' with err 0xfffffff4.
2019-10-11 13:01:35.106 13075-17958/coders.hub.daily_status E/ACodec: signalError(omxError 0xfffffff4, internalError -12)
2019-10-11 13:01:35.106 13075-17957/coders.hub.daily_status E/MediaCodec: Codec reported err 0xfffffff4, actionCode 0, while in state 1
2019-10-11 13:01:35.108 666-666/? E/ResourceManagerService: getLowestPriorityBiggestClient_l: lowest priority 0 vs caller priority 0
2019-10-11 13:01:35.119 13075-17952/coders.hub.daily_status E/ExoPlayerImplInternal: Renderer error.
    com.google.android.gms.ads.exoplayer3.b
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.x(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:41)
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.b(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:8)
        at com.google.android.gms.ads.exoplayer3.video.f.b(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:5)
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.a(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:7)
        at com.google.android.gms.ads.exoplayer3.k.handleMessage(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:135)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:226)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: com.google.android.gms.ads.exoplayer3.mediacodec.b: Decoder init failed: OMX.MTK.VIDEO.DECODER.AVC, Format(1, null, video/avc, -1, null, [640, 360, -1.0], [-1, -1])
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.x(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:40)
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.b(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:8) 
        at com.google.android.gms.ads.exoplayer3.video.f.b(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:5) 
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.a(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:7) 
        at com.google.android.gms.ads.exoplayer3.k.handleMessage(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:135) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:226) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
     Caused by: android.media.MediaCodec$CodecException: Failed to initialize OMX.MTK.VIDEO.DECODER.AVC, error 0xfffffff4
        at android.media.MediaCodec.native_setup(Native Method)
        at android.media.MediaCodec.<init>(MediaCodec.java:1811)
        at android.media.MediaCodec.createByCodecName(MediaCodec.java:1792)
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.x(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:23)
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.b(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:8) 
        at com.google.android.gms.ads.exoplayer3.video.f.b(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:5) 
        at com.google.android.gms.ads.exoplayer3.mediacodec.c.a(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:7) 
        at com.google.android.gms.ads.exoplayer3.k.handleMessage(:com.google.android.gms.policy_ads_fdr_dynamite@20461004@20461004.264725060.264725060:135) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:226) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
```

**Second one**

```java
2019-10-11 13:01:36.131 678-1789/? E/OMXNodeInstance: setParameter(0xd5de5004:MTK.DECODER.AVC, OMX.google.android.index.allocateNativeHandle(0x7f20040e): Output:1 en=0) ERROR: BadParameter(0x80001005)
2019-10-11 13:01:36.132 678-1789/? E/OMXNodeInstance: getConfig(0xd5de5004:MTK.DECODER.AVC, ConfigAndroidVendorExtension(0x6f100004)) ERROR: UnsupportedIndex(0x8000101a)
2019-10-11 13:01:36.133 678-1789/? E/OMXNodeInstance: getConfig(0xd5de5004:MTK.DECODER.AVC, ConfigCommonOutputCrop(0x700000f)) ERROR: BadParameter(0x80001005)
2019-10-11 13:01:36.140 678-28259/? E/OMXNodeInstance: setParameter(0xd5de5004:MTK.DECODER.AVC, ParamPortDefinition(0x2000001)) ERROR: BadParameter(0x80001005)
2019-10-11 13:01:36.140 678-1789/? E/OMXNodeInstance: setParameter(0xd5de5004:MTK.DECODER.AVC, ParamPortDefinition(0x2000001)) ERROR: BadParameter(0x80001005)
2019-10-11 13:01:36.157 678-28268/? E/OMXNodeInstance: getConfig(0xf0234ec0:google.aac.decoder, ConfigAndroidVendorExtension(0x6f100004)) ERROR: Undefined(0x80001001)
2019-10-11 13:01:36.160 678-28268/? E/OMXNodeInstance: setParameter(0xd5de5004:MTK.DECODER.AVC, ParamPortDefinition(0x2000001)) ERROR: BadParameter(0x80001005)
2019-10-11 13:01:36.160 678-1789/? E/OMXNodeInstance: setParameter(0xd5de5004:MTK.DECODER.AVC, ParamPortDefinition(0x2000001)) ERROR: BadParameter(0x80001005)
2019-10-11 13:01:36.173 522-30601/? E/AudioParamParser-vnd: utilNativeGetParam(), categoryType is NULL
2019-10-11 13:01:36.173 522-30601/? E/AudioParamParser-vnd: utilNativeGetParam(), paramUnit is NULL
2019-10-11 13:01:36.177 678-28268/? E/OMXNodeInstance: setParameter(0xd5de5004:MTK.DECODER.AVC, ??(0x7f00002b)) ERROR: IncorrectStateOperation(0x80001018)
2019-10-11 13:01:36.198 560-2040/? E/AudioFlinger: TrackBase####alloc memory 0xe0cf4d20
2019-10-11 13:01:36.202 13075-17963/coders.hub.daily_status E/AudioTrack: start(): 0x76acdfdc00, mState = 1
2019-10-11 13:01:36.207 522-962/? E/AudioParamParser-vnd: utilNativeGetParam(), categoryType is NULL
2019-10-11 13:01:36.207 522-962/? E/AudioParamParser-vnd: utilNativeGetParam(), paramUnit is NULL
2019-10-11 13:01:36.210 522-12305/? E/se.dirac.effect: first processing
2019-10-11 13:01:36.428 1282-1420/? E/WifiVendorHal: getWifiLinkLayerStats(l.946) failed {.code = ERROR_NOT_SUPPORTED, .description = }
2019-10-11 13:01:37.688 678-1789/? E/osal_utils: Returns insufficientResource
2019-10-11 13:01:37.688 678-1789/? E/media.codec: Failed to allocate omx component 'OMX.MTK.VIDEO.DECODER.AVC'  err=InsufficientResources(0x80001000)
2019-10-11 13:01:37.689 13075-17981/coders.hub.daily_status E/ACodec: Unable to instantiate codec 'OMX.MTK.VIDEO.DECODER.AVC' with err 0xfffffff4.
2019-10-11 13:01:37.689 13075-17981/coders.hub.daily_status E/ACodec: signalError(omxError 0xfffffff4, internalError -12)
2019-10-11 13:01:37.690 13075-17980/coders.hub.daily_status E/MediaCodec: Codec reported err 0xfffffff4, actionCode 0, while in state 1
2019-10-11 13:01:37.692 666-2141/? E/ResourceManagerService: getLowestPriorityBiggestClient_l: lowest priority 0 vs caller priority 0
2019-10-11 13:01:37.696 13075-17978/coders.hub.daily_status E/ExoPlayerImplInternal: Renderer error.
    com.google.android.exoplayer2.ExoPlaybackException
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.throwDecoderInitError(MediaCodecRenderer.java:395)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodec(MediaCodecRenderer.java:382)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:814)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:435)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:513)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:574)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:350)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:226)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: com.google.android.exoplayer2.mediacodec.MediaCodecRenderer$DecoderInitializationException: Decoder init failed: OMX.MTK.VIDEO.DECODER.AVC, Format(1, null, video/avc, -1, null, [480, 640, -1.0], [-1, -1])
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodec(MediaCodecRenderer.java:382) 
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:814) 
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:435) 
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:513) 
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:574) 
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:350) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:226) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
     Caused by: android.media.MediaCodec$CodecException: Failed to initialize OMX.MTK.VIDEO.DECODER.AVC, error 0xfffffff4
        at android.media.MediaCodec.native_setup(Native Method)
        at android.media.MediaCodec.<init>(MediaCodec.java:1811)
        at android.media.MediaCodec.createByCodecName(MediaCodec.java:1792)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodec(MediaCodecRenderer.java:368)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:814) 
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:435) 
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:513) 
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:574) 
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:350) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:226) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
```

Found some same issue here but no solution. Does it not have any solution yet? I am waiting approx one week to publish my app.","Can you please take a look at the ExoPlayer's [demo app](https://github.com/google/ExoPlayer/blob/35e030f56b4e3312e863e44a1e8fe27aef4310b7/demos/main/src/main/java/com/google/android/exoplayer2/demo/PlayerActivity.java) how to properly release the player, covering all possible Android versions?","This is my Full screen activity, small player activity have above onPause and onStop:-

```java
public class FullscreenActivity extends AppCompatActivity {
    private SimpleExoPlayerView simpleExoPlayerView;
    private SimpleExoPlayer player;

    private Timeline.Window window;
    private DataSource.Factory mediaDataSourceFactory;
    private DefaultTrackSelector trackSelector;
    private boolean shouldAutoPlay;
    private BandwidthMeter bandwidthMeter;

    private ImageView ivHideControllerButton;
    private String URL;
    private String duration;
    private SimpleArcLoader simple_arc_loader_exo;
    private String local;
    private ImageView exo_pause;
    private PrefManager prefManager;


    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        requestWindowFeature(Window.FEATURE_NO_TITLE);
        getWindow().setFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN,
                WindowManager.LayoutParams.FLAG_FULLSCREEN);

        setContentView(R.layout.activity_video);
        Bundle bundle = getIntent().getExtras() ;
        this.URL =  bundle.getString(""video"");
        this.local =  bundle.getString(""local"");
        this.duration =  bundle.getString(""duration"");

        setContentView(R.layout.activity_fullscreen);
        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);

        shouldAutoPlay = true;
        bandwidthMeter = new DefaultBandwidthMeter();
        mediaDataSourceFactory = new DefaultDataSourceFactory(this, Util.getUserAgent(this, ""Daily Status""), (TransferListener<? super DataSource>) bandwidthMeter);
        window = new Timeline.Window();
        ivHideControllerButton = (ImageView) findViewById(R.id.exo_controller);
        ivHideControllerButton.setImageDrawable(getResources().getDrawable(R.drawable.ic_fullscreen_exit));
        simple_arc_loader_exo = (SimpleArcLoader) findViewById(R.id.simple_arc_loader_exo);
        exo_pause = (ImageView) findViewById(R.id.exo_pause);

        prefManager = new PrefManager(FullscreenActivity.this);

    }


    private void initializePlayer() {

        simpleExoPlayerView = (SimpleExoPlayerView) findViewById(R.id.video_view);
        simpleExoPlayerView.requestFocus();

        TrackSelection.Factory videoTrackSelectionFactory =
                new AdaptiveTrackSelection.Factory(bandwidthMeter);

        trackSelector = new DefaultTrackSelector(videoTrackSelectionFactory);

        player = ExoPlayerFactory.newSimpleInstance(this, trackSelector);
        simpleExoPlayerView.setControllerShowTimeoutMs(4000);
        simpleExoPlayerView.setPlayer(player);
        player.setPlayWhenReady(shouldAutoPlay);
/*        MediaSource mediaSource = new HlsMediaSource(Uri.parse(""https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8""),
                mediaDataSourceFactory, mainHandler, null);*/
        Log.v(""MY ONE"",URL);
        DefaultExtractorsFactory extractorsFactory = new DefaultExtractorsFactory();

        MediaSource mediaSource;
        if (prefManager.getString(""video_cache"").equals(""false""))
            mediaSource = new ExtractorMediaSource(Uri.parse(URL),
                    mediaDataSourceFactory, extractorsFactory, null, null);
        else
         mediaSource =new ExtractorMediaSource(Uri.parse(URL),
                new CacheDataSourceFactory(FullscreenActivity.this), extractorsFactory, null, null);

        if (local!=null){
            Log.v(""this is path"",local);
            Uri imageUri = FileProvider.getUriForFile(FullscreenActivity.this, FullscreenActivity.this.getApplicationContext().getPackageName() + "".provider"", new File(local));
            mediaSource = new ExtractorMediaSource(imageUri,
                    mediaDataSourceFactory, extractorsFactory, null, null);
        }

        player.prepare(mediaSource);
        player.seekTo(Integer.parseInt(duration));

        ivHideControllerButton.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                finish();
            }
        });
        player.addListener(new Player.EventListener() {
            @Override
            public void onTimelineChanged(Timeline timeline, Object manifest) {

            }

            @Override
            public void onTracksChanged(TrackGroupArray trackGroups, TrackSelectionArray trackSelections) {

            }

            @Override
            public void onLoadingChanged(boolean isLoading) {

            }

            @Override
            public void onPlayerStateChanged(boolean playWhenReady, int playbackState) {
                if (playbackState == ExoPlayer.STATE_READY){
                    simple_arc_loader_exo.setVisibility(View.GONE);
                    simpleExoPlayerView.setControllerShowTimeoutMs(1500);
                }
                else if (playbackState == ExoPlayer.STATE_BUFFERING){
                    simple_arc_loader_exo.setVisibility(View.VISIBLE);
                    exo_pause.setVisibility(View.GONE);
                    simpleExoPlayerView.setControllerShowTimeoutMs(3000);
                }
                else if (playbackState == ExoPlayer.STATE_ENDED){
                    player.seekTo(0);
                    simpleExoPlayerView.setControllerShowTimeoutMs(1);
                }
            }

            @Override
            public void onRepeatModeChanged(int repeatMode) {

            }

            @Override
            public void onPlayerError(ExoPlaybackException error) {

            }

            @Override
            public void onPositionDiscontinuity() {

            }

            @Override
            public void onPlaybackParametersChanged(PlaybackParameters playbackParameters) {

            }
        });
    }

    private void releasePlayer() {
        if (player != null) {
            player.seekTo(Integer.parseInt(duration));
            shouldAutoPlay = player.getPlayWhenReady();
            player.release();
            player = null;
            trackSelector = null;

        }
    }

    @Override
    public void onStart() {
        super.onStart();
        if (Util.SDK_INT > 23) {
            initializePlayer();
        }
    }

    @Override
    public void onResume() {
        super.onResume();
        if ((Util.SDK_INT <= 23 || player == null)) {
            initializePlayer();
        }
    }

    @Override
    public void onPause() {
        super.onPause();
        if (Util.SDK_INT <= 23) {
            releasePlayer();
        }
    }

    @Override
    public void onStop() {
        super.onStop();
        if (Util.SDK_INT > 23) {
            releasePlayer();
        }
    }

}
```"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6503,"**Content description**

On many old devices that use OMX.MTK.VIDEO.DECODER.AVC decoder when try to play a MPEG-DASH stream on Akamai CDN with DRM  we receive this error:
I think this issue is linked to others that are marked in your code inside the `MediaCodecVideoRenderer.class` class (e.g # 3835, # 3236, # 3355, # 3439 etc ..).
Inside the switch of method `protected boolean codecNeedsSetOutputSurfaceWorkaround(String name)` of class `MediaCodecVideoRenderer.class` adding, for example, the code of the wiko fever the media is playing correctly.
We encounter the same error on many devices of our users
(see attachment [reportErrorDrmWithDevice.pdf](https://github.com/google/ExoPlayer/files/3686369/reportErrorDrmWithDevice.pdf)), which clearly we have no chance to test. 
We wanted to know if you can test them and / or add them to the switch in the code

```
com.google.android.exoplayer2.ExoPlaybackException: com.google.android.exoplayer2.mediacodec.MediaCodecRenderer$DecoderInitializationException: Decoder init failed: OMX.MTK.VIDEO.DECODER.AVC, Format(1_0, null, null, video/avc, avc1.640028, 511750, null, [512, 288, -1.0], [-1, -1])
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodec(MediaCodecRenderer.java:479)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.reinitializeCodec(MediaCodecRenderer.java:1261)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:1111)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:552)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:647)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:529)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:300)
        at android.os.Handler.dispatchMessage(Handler.java:107)
        at android.os.Looper.loop(Looper.java:207)
```

**Version of ExoPlayer being used**

2.9.2

**Device(s) and version(s) of Android being used**

Wiko Fever - l5460 - Android 6 and many others
","Can you please provide a bug report as described [here](https://github.com/google/ExoPlayer/blob/release-v2/.github/ISSUE_TEMPLATE/bug.md)?

About the other devices, do you have a stack trace? Do you have access to the device names (see 3rd column of https://support.google.com/googleplay/answer/1727131?hl=en-GB)? ","I sent an email with the two required files like attachements. I don't have full stacktrace access, I only have the information in the file (now there is also device name)"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6473,"### [REQUIRED] Issue description
I use ExoPlayer in Android app to record and play video files. Since I don't want to pause playback when app goes to background, when I play video and move app to the background sound is still heard. When I am going back to my app, and bind player to new playerView sound is heard, but image in video is stopped at this moment, which I move app to the background. After usage of seekBar image in video works well again. 

### [REQUIRED] Reproduction steps
-record video file
-play video
-while video is playing go to background
-go back to app
-sound is heard but image in video stops

### [REQUIRED] Link to test content
--

### [REQUIRED] A full bug report captured from the device
--

### [REQUIRED] Version of ExoPlayer being used
I use ExoPlayer v2.10.0.

### [REQUIRED] Device(s) and version(s) of Android being used
It happens on multiple devices with Android 10 version only. On other devices with lower OS version everything works fine. 

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","Can you provide more details on how your background playback is working?

In particular:
- Are you using a foreground service?
- Are you making any changes to the `DefaultTrackSelector` (e.g. disable the video track)?
- Are you unbinding the player from the previous `PlayerView`? 
- What kind of view are you using? (SurfaceView, TextureView, ..)
- Also, what kind of `MediaSource` are you using? And can you provide an example stream in case it's media related?",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6401,"**[REQUIRED] Issue description**
The recent update in MI TV 4a pro 32 inch with android Pie, having issues with the aspectrationframelayout.resize_mode_fit, resize_mode_zoom.  Until previous version, it was working fine. The latest update given and now its not functioning at all.

**[REQUIRED] Reproduction steps**
On MI tv 4a pro use the exoplayer demo app with simple exoplayerview and aspectratio fame layout.
make a button to resize the screen to zoom or fit  using playerView.setResizeMode(AspectRatioFrameLayout.RESIZE_MODE_ZOOM); or
playerView.setResizeMode(AspectRatioFrameLayout.RESIZE_MODE_FIT);

The screen is on same size on PIE.

**[REQUIRED] Link to test content**
[
  {
    ""name"": ""Widevine DASH Policy Tests (GTS)"",
    ""samples"": [
      {
     ""name"": ""Apple 4x3 basic stream"",
        ""uri"": ""https://devstreaming-cdn.apple.com/videos/streaming/examples/bipbop_4x3/bipbop_4x3_variant.m3u8""
      }
    ]
  }
]

**[REQUIRED] Version of ExoPlayer being used**
v2.9.3

**[REQUIRED] Device(s) and version(s) of Android being used**

MI TV 4A PRO

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
",Can you reproduce this on any other devices? Is only DRM playback affected?,all streams are affected. Only this happening with MI tv with pie edition. There is no effect on playback but that view AspectRatioFrameLayout resize modes are not working at all.
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6397,"### [REQUIRED] Content description
FLAC in mp4 using DASH does not seem to work. 
The same track in regular flac container works as it should.
I'm of course using the Mp4Extractor, and playing AAC in the same setup works flawlessly. I have tested with various configuration in regards to renderer, explained in the bug report section below.

### [REQUIRED] Link to test content
I can probably provide if needed. Do you have any test content that should work? I tried our .mpd file in VLC on my computer, and that played as it should.

### [REQUIRED] Version of ExoPlayer being used
2.10.4 forked with [this](https://github.com/google/ExoPlayer/issues/6396) change included.

### [REQUIRED] Device(s) and version(s) of Android being used
Pixel 3 Android 9 and 10.

### [REQUIRED] A full bug report captured from the device
Full bug report can be provided if needed.
Here are some logs from my different tries:

Using LibflacAudioRenderer: It is not fetching the dash segments, but plays without sound(time is passing, can pause, play etc) and gives me no error message.

Using default MediaCodecAudioRenderer(afaik understood from https://github.com/google/ExoPlayer/issues/6392 this should work because of platform decoder on Android 8.1 and above) it is fetching dash segments, but does not play like above, and I'm getting the following error:

```
D/CCodec: allocate(c2.android.flac.decoder)
I/Codec2Client: Available Codec2 services: ""default"" ""software""
I/Codec2Client: Creating a Codec2 client to service ""default""
I/Codec2Client: Client to Codec2 service ""default"" created
I/CCodec: setting up 'default' as default (vendor) store
I/Codec2Client: Creating a Codec2 client to service ""default""
I/Codec2Client: Client to Codec2 service ""default"" created
E/Codec2Client: createComponent(c2.android.flac.decoder) -- call failed: NOT_FOUND.
I/Codec2Client: Creating a Codec2 client to service ""software""
I/Codec2Client: Client to Codec2 service ""software"" created
I/CCodec: Created component [c2.android.flac.decoder]
D/CCodecConfig: read media type: audio/flac
D/ReflectedParamUpdater: extent() != 1 for single value type: algo.buffers.max-count.values
D/ReflectedParamUpdater: extent() != 1 for single value type: output.subscribed-indices.values
D/ReflectedParamUpdater: extent() != 1 for single value type: input.buffers.allocator-ids.values
D/ReflectedParamUpdater: extent() != 1 for single value type: output.buffers.allocator-ids.values
D/ReflectedParamUpdater: extent() != 1 for single value type: algo.buffers.allocator-ids.values
D/ReflectedParamUpdater: extent() != 1 for single value type: output.buffers.pool-ids.values
D/ReflectedParamUpdater: extent() != 1 for single value type: algo.buffers.pool-ids.values
I/CCodecConfig: query failed after returning 8 values (BAD_INDEX)
D/CCodecConfig: c2 config is Dict {
      c2::u32 coded.bitrate.value = 768000
      c2::u32 input.buffers.max-size.value = 32768
      c2::u32 input.delay.value = 0
      string input.media-type.value = ""audio/flac""
      string output.media-type.value = ""audio/raw""
      c2::u32 raw.channel-count.value = 1
      c2::u32 raw.pcm-encoding.value = 0
      c2::u32 raw.sample-rate.value = 44100
    }
D/CCodecConfig: c2 config is Dict {
      c2::u32 coded.bitrate.value = 768000
      c2::u32 input.buffers.max-size.value = 32768
      c2::u32 input.delay.value = 0
      string input.media-type.value = ""audio/flac""
      string output.media-type.value = ""audio/raw""
      c2::u32 raw.channel-count.value = 2
      c2::u32 raw.pcm-encoding.value = 0
      c2::u32 raw.sample-rate.value = 44100
    }
W/Codec2Client: query -- param skipped: index = 1107298332.
D/CCodec: setup formats input: AMessage(what = 0x00000000) = {
      int32_t channel-count = 2
      int32_t max-input-size = 32768
      string mime = ""audio/flac""
      int32_t pcm-encoding = 2
      int32_t sample-rate = 44100
    } and output: AMessage(what = 0x00000000) = {
      int32_t channel-count = 2
      string mime = ""audio/raw""
      int32_t pcm-encoding = 2
      int32_t sample-rate = 44100
    }
W/Codec2Client: query -- param skipped: index = 1342179345.
W/Codec2Client: query -- param skipped: index = 2415921170.
D/CCodecBufferChannel: [c2.android.flac.decoder#18] Created input block pool with allocatorID 16 => poolID 17 - OK (0)
I/CCodecBufferChannel: [c2.android.flac.decoder#18] Created output block pool with allocatorID 16 => poolID 116 - OK
D/CCodecBufferChannel: [c2.android.flac.decoder#18] Configured output block pool ids 116 => OK
E/ion: ioctl c0044901 failed with code -1: Invalid argument
D/CCodecBufferChannel: [c2.android.flac.decoder#18] work failed to complete: 14
E/MediaCodec: Codec reported err 0xe, actionCode 0, while in state 6
D/CCodecBufferChannel: [c2.android.flac.decoder#18] work failed to complete: 22
E/MediaCodec: Codec reported err 0x16, actionCode 0, while in state 0
E/ExoPlayerImplInternal: Internal runtime error.
    java.lang.IllegalStateException
        at android.media.MediaCodec.native_dequeueOutputBuffer(Native Method)
        at android.media.MediaCodec.dequeueOutputBuffer(MediaCodec.java:2789)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1437)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:653)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:575)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:326)
        at android.os.Handler.dispatchMessage(Handler.java:103)
        at android.os.Looper.loop(Looper.java:214)
        at android.os.HandlerThread.run(HandlerThread.java:67)
W/System.err: com.google.android.exoplayer2.ExoPlaybackException: java.lang.IllegalStateException
W/System.err:     at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:397)
W/System.err:     at android.os.Handler.dispatchMessage(Handler.java:103)
W/System.err:     at android.os.Looper.loop(Looper.java:214)
W/System.err:     at android.os.HandlerThread.run(HandlerThread.java:67)
W/System.err: Caused by: java.lang.IllegalStateException
E/ExoPlayerImplInternal: Disable failed.
    java.lang.IllegalStateException
        at android.media.MediaCodec.native_flush(Native Method)
        at android.media.MediaCodec.flush(MediaCodec.java:2194)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.flushOrReleaseCodec(MediaCodecRenderer.java:702)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onDisabled(MediaCodecRenderer.java:580)
        at com.google.android.exoplayer2.audio.MediaCodecAudioRenderer.onDisabled(MediaCodecAudioRenderer.java:625)
        at com.google.android.exoplayer2.BaseRenderer.disable(BaseRenderer.java:158)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.disableRenderer(ExoPlayerImplInternal.java:1088)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.resetInternal(ExoPlayerImplInternal.java:851)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.stopInternal(ExoPlayerImplInternal.java:813)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:399)
        at android.os.Handler.dispatchMessage(Handler.java:103)
        at android.os.Looper.loop(Looper.java:214)
        at android.os.HandlerThread.run(HandlerThread.java:67)
W/System.err:     at android.media.MediaCodec.native_dequeueOutputBuffer(Native Method)
W/System.err:     at android.media.MediaCodec.dequeueOutputBuffer(MediaCodec.java:2789)
W/System.err:     at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1437)
W/System.err:     at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:653)
W/System.err:     at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:575)
W/System.err:     at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:326)
W/System.err: 	... 3 more
E/ExoPlayerImplInternal: Reset failed.
    java.lang.IllegalStateException
        at android.media.MediaCodec.native_stop(Native Method)
        at android.media.MediaCodec.stop(MediaCodec.java:2147)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.releaseCodec(MediaCodecRenderer.java:609)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onReset(MediaCodecRenderer.java:587)
        at com.google.android.exoplayer2.audio.MediaCodecAudioRenderer.onReset(MediaCodecAudioRenderer.java:635)
        at com.google.android.exoplayer2.BaseRenderer.reset(BaseRenderer.java:164)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.resetInternal(ExoPlayerImplInternal.java:860)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.stopInternal(ExoPlayerImplInternal.java:813)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:399)
        at android.os.Handler.dispatchMessage(Handler.java:103)
        at android.os.Looper.loop(Looper.java:214)
        at android.os.HandlerThread.run(HandlerThread.java:67)
I/ExoPlayerImpl: Release 5e5c6b5 [ExoPlayerLib/2.10.4] [blueline, Pixel 3, Google, 29] [goog.exo.core, goog.exo.dash, goog.exo.okhttp]
```

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/content_not_playing.md
-->
","Do you really *need* to use it? Doing what nearly everyone else does (i.e. AAC) is definitely the path of least resistance, unless that's a non-started from a product perspective.",[Here](https://quc-test-source.s3.amazonaws.com/flac.mpd) is an example of a FLAC in mp4/DASH.
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6381,"Searches:
-----------------------

1. [q=MediaCodec.CodecException](https://github.com/google/ExoPlayer/issues?utf8=%E2%9C%93&q=MediaCodec.CodecException) - No result

2. [q=0xffffffe0](https://github.com/google/ExoPlayer/issues?utf8=✓&q=0xffffffe0)

Issue #5649 - Not related
Issue #3896 - Stale
Issue #1036 & Issue #978 - Outdated


### [REQUIRED] Issue description

Facing MediaCodec.CodecException.ERROR_RECLAIMED after 2-3 minutes of video playback on DRM protected content

**Exception Log:**
```
E ExoPlayerImplInternal: Internal runtime error.
E ExoPlayerImplInternal: android.media.MediaCodec$CodecException: Error 0xffffffe0
E ExoPlayerImplInternal: 	at android.media.MediaCodec.native_queueSecureInputBuffer(Native Method)
E ExoPlayerImplInternal: 	at android.media.MediaCodec.queueSecureInputBuffer(MediaCodec.java:2608)
E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:1113)
E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:654)
E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:575)
E ExoPlayerImplInternal: 	at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:326)
E ExoPlayerImplInternal: 	at android.os.Handler.dispatchMessage(Handler.java:102)
E ExoPlayerImplInternal: 	at android.os.Looper.loop(Looper.java:224)
E ExoPlayerImplInternal: 	at android.os.HandlerThread.run(HandlerThread.java:65)
I MediaCodec: kWhatStop or kWhatRelease
E EventLogger: playerFailed [209.88, 176.18, window=0, period=0]
E EventLogger: com.google.android.exoplayer2.ExoPlaybackException: android.media.MediaCodec$CodecException: Error 0xffffffe0
E EventLogger: 	at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:397)
E EventLogger: 	at android.os.Handler.dispatchMessage(Handler.java:102)
E EventLogger: 	at android.os.Looper.loop(Looper.java:224)
E EventLogger: 	at android.os.HandlerThread.run(HandlerThread.java:65)
E EventLogger: Caused by: android.media.MediaCodec$CodecException: Error 0xffffffe0
E EventLogger: 	at android.media.MediaCodec.native_queueSecureInputBuffer(Native Method)
E EventLogger: 	at android.media.MediaCodec.queueSecureInputBuffer(MediaCodec.java:2608)
E EventLogger: 	at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:1113)
E EventLogger: 	at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:654)
E EventLogger: 	at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:575)
E EventLogger: 	at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:326)
E EventLogger: 	... 3 more
```
### [REQUIRED] Reproduction steps
1. Build sample demo app from v2.10.4 Exo or [download this apk](https://github.com/sharish/BugReferences/blob/master/ExoplayerIssue_6381/Exo_2.10.4.demo-noExtensions-debug.apk?raw=true)
2. Expand `Widevine DASH Policy Test (GTS)`
3. Open `WV: HDCP not specified`
4. Play the video for a while approx 3 minutes

### [REQUIRED] Link to test content
```json
[
  {
    ""name"": ""Widevine DASH Policy Tests (GTS)"",
    ""samples"": [
      {
        ""name"": ""WV: HDCP not specified"",
        ""uri"": ""https://storage.googleapis.com/wvmedia/cenc/h264/tears/tears.mpd"",
        ""drm_scheme"": ""widevine"",
        ""drm_license_url"": ""https://proxy.uat.widevine.com/proxy?video_id=d286538032258a1c&provider=widevine_test""
      }
    ]
  }
]
```

### [REQUIRED] A full bug report captured from the device
1. [Bug report](https://github.com/sharish/BugReferences/blob/master/ExoplayerIssue_6381/Vivo-bugreport-1951-PKQ1.181030.001-2019-09-04-13-38-07.zip?raw=true)
2. [Logcat logs](https://raw.githubusercontent.com/sharish/BugReferences/master/ExoplayerIssue_6381/vivo_logcat.txt)

### [REQUIRED] Version of ExoPlayer being used
v2.10.4

### [REQUIRED] Device(s) and version(s) of Android being used
Personally reproduced: 
Vivo Z1 Pro - Android 9 - **100% reproducible**
User reports  :
Samsung Galaxy Tab A 8.0 - Android 7.1.1
Samsung SM-J415F - Android 8.1.0
Vivo 1806 - Android 9



<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","Does factory resetting the device and installing only your app make the problem go away? Do other apps such as Netflix and Play Movies, both of which also play DRM protected content, work correctly on this device?
* Is it possible that your application is doing something that could be causing this issue?

Note that we've not received any significant volume of this issue from other uses, so it seems most likely to be specific to your device (possibly sporadic across other devices but with a low occurrence rate), or specific to your application.","@ojw28 Thanks for your input.

1. _Is it possible that there's an app that's behaving very badly on your Vivo Z1 Pro test device. Does factory resetting the device and installing only your app make the problem go away?_

    No. This was a newly bought device with no apps (expect system and default apps). We bought this device purely based on crashlytics non-fatals.

2. _Does factory resetting the device and installing only your app make the problem go away?_

   No. Tried factory reset and installed **only** exoplayer demo application and was still facing the same. 

3. _Do other apps such as Netflix and Play Movies, both of which also play DRM protected content, work correctly on this device?_

- Netflix plays smoothly. Tried to play few videos for more than an hour without a single interruption
- Play Movies - able to replicate the issue. However, I could notice that player gets reset and re-initialized once this error is encountered and continue streaming from where it left.

   - [Play movies bugreport](https://github.com/sharish/BugReferences/blob/master/ExoplayerIssue_6381/Vivo-PlayMovies-bugreport-1951-PKQ1.181030.001-2019-09-12-11-51-58.zip?raw=true)
  - [Play movies logcat](https://raw.githubusercontent.com/sharish/BugReferences/master/ExoplayerIssue_6381/play-movies-logcat.txt)

4. _Is it possible that your application is doing something that could be causing this issue?_

   No. Btw, the application reference I'm mentioning is **exo player demo application** which is based on commit https://github.com/google/ExoPlayer/commit/85c10b02567b66ecfaaaacfd0ba9389b41bf919e. This is not version-specific issue as I'm able to replicate on `v2.9.6` as well.

Few points to add,

1. Based on crashlytics non-fatal reports, 77% of users encountered this issue came from devices manufactured by `Vivo` and among those, 95% of them came from `Vivo Z1 Pro`. This matches what you said in note section.

2. We are fixing this issue like the workaround done by `Play Movies` - Kill and re-initialize the player. However there is an experience lag as this re-initialization takes some time and buffers are also destroyed. Also, license cost overhead is also to be considered as we are nearly hitting 30license calls for an hour video through this workaround(Offline licensing is another workaround to solve this which is a problem for another time)

Questions:

> I would expect ERROR_RECLAIMED to occur something else requires the same resource

Would like to know what resource the player is abusing as I tried looking into memory patterns which were totally fine. I'm clueless what happens at the native DRM level where this problem likely to take place




"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6362,"### Issue description
Black flash happens on switching from lower bitrate on 30fps to higher bitrate on 60fps.

### Reproduction steps
1. Start playback with good bandwidth and a playlist with 30fps as lowest bitrate and 60fps highest streams. 
2. Wait for few seconds to switch to highest bitrate.
Result: Black screen during the transition during bitrate switch

Link to test content - **Widevine-DRM-DASH-Live**
mpd file -> https://gist.github.com/juechemparathy/c891e565e89e6f12c4a98ac6e17188a4
Stream url -> emailed to dev.exoplayer@gmail.com
Let me know if you guys need more info.Thanks.

### A full bug report captured from the device

From EventLogger

2019-08-29 17:54:45.535 8958-8958/com.yahoo.mobile.client.android.example.yvideosdkdemo D/EventLogger: decoderInputFormatChanged [11.10, 4.10, window=0, video, id=C, mimeType=video/avc, **bitrate=1069178,** codecs=avc1.4d001e, res=640x360, **fps=30.0]**

2019-08-29 17:54:53.910 8958-8958/com.yahoo.mobile.client.android.example.yvideosdkdemo D/EventLogger: decoderInputFormatChanged [19.47, 11.71, window=0, video, id=G, mimeType=video/avc, **bitrate=5949747,** codecs=avc1.640020, res=1280x720, **fps=60.0]`**

 -------   Black screen appears after above log -------

### Version of ExoPlayer being used
2.9.5

### Device(s) and version(s) of Android being used
S8 

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
",Do you observe similar behavior on HLS ? can you confirm on that?,@mikulbhatt - I don't have an HLS test stream with same setup. Stream url has been emailed to dev.exoplayer@gmail.com
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6346,"### Issue description
Getting a playback error randomly and in very rare occasions. It happens right after our app finishes encoding a new video, and a new ExoPlayer instance is created to play it. There are no problem with the videos themselves, as trying a playback again will not produce any error.

In our flow we encode a video using the MediaCodec API. Then ensure the video is fully saved to file. Release the MediaCodec and MediaMuxer resources. And finally open a new ExoPlayer instance to play it.

The only thing I can think of, and I’m only guessing, is that maybe there is some type of OS lock when the system is in the process of releasing the MediaCodec used for encoding, making ExoPlayer to fail. Although, besides the fact that I don’t know how long does the OS take to release the codec resources, I don’t see why ExoPlayer would need a video codec which was used only for encoding, and not decoding.

### Reproduction steps
To play a video right after has been created/encoded. The problem happens in very rare occasions.

### A full bug report captured from the device

```
019-08-27 15:31:01.807 789-3756/? E/VDEC: [set_parameter] : [5399] Allocate native buffer failed, invalid port index 1
2019-08-27 15:31:01.807 789-3756/? E/OMXNodeInstance: setParameter(0xead79de0:hisi.decoder.avc, OMX.google.android.index.allocateNativeHandle(0x7f000008): Output:1 en=0) ERROR: BadPortIndex(0x8000101b)
2019-08-27 15:31:01.807 789-3756/? E/OMXNodeInstance: getExtensionIndex(0xead79de0:hisi.decoder.avc, OMX.google.android.index.storeMetaDataInBuffers) ERROR: NotImplemented(0x80001006)
2019-08-27 15:31:01.807 25784-27450/com.production.test E/ACodec: [OMX.hisi.video.decoder.avc] setPortMode on output to DynamicANWBuffer failed w/ err -2147483648
2019-08-27 15:31:01.807 789-3756/? E/VDEC: [set_parameter] : [5399] Allocate native buffer failed, invalid port index 1
2019-08-27 15:31:01.807 789-3756/? E/OMXNodeInstance: setParameter(0xead79de0:hisi.decoder.avc, OMX.google.android.index.allocateNativeHandle(0x7f000008): Output:1 en=0) ERROR: BadPortIndex(0x8000101b)
2019-08-27 15:31:01.807 789-3756/? E/OMXNodeInstance: getExtensionIndex(0xead79de0:hisi.decoder.avc, OMX.google.android.index.storeMetaDataInBuffers) ERROR: NotImplemented(0x80001006)
2019-08-27 15:31:01.809 25784-27450/com.production.test E/HwExtendedCodec: mime: video/avc matching compontent failed!
2019-08-27 15:31:01.813 789-3756/? E/OMXNodeInstance: setConfig(0xead79de0:hisi.decoder.avc, ConfigPriority(0x6f800002)) ERROR: BadParameter(0x80001005)
2019-08-27 15:31:01.828 3406-27458/? E/NfcNci:HwCustNfcService: applyRouting -1.1
2019-08-27 15:31:01.904 636-1184/? E/BufferQueueProducer: [SurfaceView - com.production.test/app.application.activities.PlayerVideoActivity$Internal#0] setMaxDequeuedBufferCount: requested buffer count 1 is less than minimum 2
2019-08-27 15:31:01.904 25784-27450/com.production.test E/Surface: IGraphicBufferProducer::setBufferCount(1) returned Invalid argument
2019-08-27 15:31:01.904 25784-27450/com.production.test E/ACodec: native_window_set_buffer_count failed: Invalid argument (22)
2019-08-27 15:31:01.906 25784-27446/com.production.test E/ExoPlayerImplInternal: Internal runtime error.
    java.lang.IllegalArgumentException
        at android.media.MediaCodec.native_setSurface(Native Method)
        at android.media.MediaCodec.setOutputSurface(MediaCodec.java:1986)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.setOutputSurfaceV23(MediaCodecVideoRenderer.java:1103)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.setSurface(MediaCodecVideoRenderer.java:509)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.handleMessage(MediaCodecVideoRenderer.java:475)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.deliverMessage(ExoPlayerImplInternal.java:973)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.sendMessageToTarget(ExoPlayerImplInternal.java:944)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.sendMessageInternal(ExoPlayerImplInternal.java:926)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:363)
        at android.os.Handler.dispatchMessage(Handler.java:108)
        at android.os.Looper.loop(Looper.java:216)
        at android.os.HandlerThread.run(HandlerThread.java:65)
2019-08-27 15:31:01.910 789-789/? E/VDEC: [check_port_param] : [5001] set_parameter: invalid buffer count 15, should not be bigger than max count 14
2019-08-27 15:31:01.910 789-789/? E/OMXNodeInstance: setParameter(0xead79de0:hisi.decoder.avc, ParamPortDefinition(0x2000001)) ERROR: Undefined(0x80001001)
2019-08-27 15:31:01.932 787-1260/? E/IppAlgoSmartAE: [b378326_64E] onUnloadLibrary() mSmartAESoState is unloaded ,so we not Uninit it!
2019-08-27 15:31:01.943 25784-25784/com.production.test E/main#1.VideoPlayerModule.onPlayerError: Unexpected video player error.content://media/external/video/media/37281
    com.google.android.exoplayer2.ExoPlaybackException: java.lang.IllegalArgumentException
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:397)
        at android.os.Handler.dispatchMessage(Handler.java:108)
        at android.os.Looper.loop(Looper.java:216)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: java.lang.IllegalArgumentException
        at android.media.MediaCodec.native_setSurface(Native Method)
        at android.media.MediaCodec.setOutputSurface(MediaCodec.java:1986)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.setOutputSurfaceV23(MediaCodecVideoRenderer.java:1103)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.setSurface(MediaCodecVideoRenderer.java:509)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.handleMessage(MediaCodecVideoRenderer.java:475)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.deliverMessage(ExoPlayerImplInternal.java:973)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.sendMessageToTarget(ExoPlayerImplInternal.java:944)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.sendMessageInternal(ExoPlayerImplInternal.java:926)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:363)
        at android.os.Handler.dispatchMessage(Handler.java:108) 
        at android.os.Looper.loop(Looper.java:216) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
```


### Version of ExoPlayer being used
 2.10.4

### Device(s) and version(s) of Android being used
Android PIE. 
Huawei P20Lite

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","Does this happen on any device or did you observer this only on the device you stated above?

Can you please create a full bug report so we can look into this?","I've sent a full bug report to dev.exoplayer@gmail.com
I could also see the issue in a Nexus 6 with 7.1, but only once, haven't been able to reproduce it anymore in such device.
In a Huawei P20-Lite with Pie seems to be more common.

Doing some test, if I delay the video playback to start around a couple of seconds after releasing the codec, then the problem doesn't seem to occur anymore. But, I can't confirm at all if placing such delay may be related or just pure chance, since the issue happens rarely and I need to perform several times the video encoding followed by the ExoPlayer playback before the error happens again.

"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6345,"I attach a patch that allows to reproduce the problem using the official demo of exoplayer 2.9.5.

I added a sample HDR content. When playing on Huawei P30 pro, wait 10 seconds so that the surfaceView is added. Only one frame will be displayed then the video playback freezes while audio goes on.

If you try to go back in the previous screen the app may become unresponsive and occasionally crash.

May be related to #6331 ?

[hdrhuawei.patch.zip](https://github.com/google/ExoPlayer/files/3545174/hdrhuawei.patch.zip)
",Can you please provide us with a full bug report taken right after the video freezes? With this we can check some more closely.,@marcbaechinger it does not freeze just the video. The entire app becomes unresponsive and after a while it crashes. Next week I see if I can get my hands on the device and create a report
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6344,"<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/content_not_playing.md
-->

Our application uses two instances of SimpleExoPlayer to support crossfading effect. While one player is playing a track, the other prepares the next so crossfade is available when the first track is finishing. However, we noticed some brief audio interruptions when player one starts to play and player two prepares. This is not a consistent behaviour among all devices, it only happens in certain Huawei and Xiaomi devices; it only happens when playing dash content (MP3 content plays without errors using the same 2-player architecture); and it only happens when the first player is prepared and starts to play while a second instance of ExoPlayer is created and prepared at the same time.

EDIT: The audio interruption also happens during a license download using OfflineLicenseHelper, so I guess this issue is related to DRM session.

EDIT 2: After debugging the application, I noticed that one of the audio interruptions is caused when native MediaDrm.provideKeyResponse is called. I'd like to know if there's an explanation for this and how to avoid it.

We're using ExoPlayer 2.9.1.

This is how we setup each player: 

```
public MediaSource getMediaSource(@NonNull Uri uri) throws MalformedURLException {
	
		DataSource.Factory dataSourceFactory = DataSourceUtil.buildCacheDataSourceFactory(mContext);

		DashMediaSource.Factory dashFactory = new DashMediaSource.Factory(dataSourceFactory);
		if (serializedDownloadAction != null) {
			InputStream inputStream = new ByteArrayInputStream(serializedDownloadAction);
			try {
				DownloadAction downloadAction = DownloadAction.deserializeFromStream(DownloadAction.getDefaultDeserializers(), inputStream);
				dashFactory.setManifestParser(new FilteringManifestParser<>(new DashManifestParser(), downloadAction.getKeys()));
			} catch (IOException e) {
				GeneralLog.e(e);
			}
		}
		return dashFactory.createMediaSource(uri);
	}
```

```
private void getPlayer(String url, Boolean playWhenReady) {
		release();
		Utils.trustEveryone();
		TrackSelection.Factory trackSelection = new AdaptiveTrackSelection.Factory();
		DefaultTrackSelector trackSelector = new DefaultTrackSelector(trackSelection);
		try {
			exoPlayer = ExoPlayerFactory.newSimpleInstance(mContext, getRender(url), trackSelector, buildDrmSessionManager(url));
			exoPlayer.addListener(listener);
			exoPlayer.setVolume(volume);
			exoPlayer.setPlayWhenReady(playWhenReady);
			exoPlayer.prepare(getMediaSource(url));
		} catch (Exception e) {
			GeneralLog.e(e);
			onError(e);
		}
	}
```

And this is a recording where the audio interruptions are noticeable: 

[Evidence](https://i0001.clarodrive.com/s/X9QXsKf5Cydy267)
","Can you please do a bug report right after the interruptions? This is kind of hard to reproduce on our side so any information we can get is useful. The bugreport may help us.

I think your thoughts around DRM license make sense. Can you confirm that this does not happen with MP3 because there is no DRM involved? Also, do you have the chance to get the dash stream without DRM so you can test whether this does happen with DASH without DRM?","> Can you please do a bug report right after the interruptions? This is kind of hard to reproduce on our side so any information we can get is useful. The bugreport may help us.
> 
> I think your thoughts around DRM license makes sense. Can you confirm that this does not happen with MP3 because there is no DRM involved? Also, do you have the chance to get the dash stream without DRM so you can test whether this does happen with DASH without DRM?

- MP3 content plays without interruptions.
- Non licensed Dash content plays without interruptions aswell.

So I guess the problem is caused by how DRM keys are handled internally by Android. Even if I download a license with a different MediaDrmCallback, audio interruptions still happen."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6340,"### Issue description
In our app we do not use a player controller and disable it this way: 
```
view.setUseController(false)
```
However, the touch event is consumed by the view.

### Reproduction steps
I'm not allowed to share the app code.
Please see the code snippet `com.google.android.exoplayer2.ui.PlayerView` (ExoPlayer ver. 2.10.2) below that demonstrate the touches are consumed by the view in any cases:
```
  @Override
  public boolean onTouchEvent(MotionEvent event) {
    switch (event.getAction()) {
      case MotionEvent.ACTION_DOWN:
        isTouching = true;
        return true;
      case MotionEvent.ACTION_UP:
        if (isTouching) {
          isTouching = false;
          performClick();
          return true;
        }
        return false;
      default:
        return false;
    }
  }
``` 

### Link to test content
The issue is reproduced with any test assets.

### A full bug report captured from the device
A bug report has been sent by email.

### Version of ExoPlayer being used
The current ver is 2.10.2.
The issue is not seen with ExoPlayer 2.9.3.

### Device(s) and version(s) of Android being used
- Pixel 2 XL + Android 9 (test device)

The issue is reproduced on any Android devices.

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","Can you please trying to reproduce with the most recent version of the release-v2 branch? It appears to me that this has been fixed already in [PlayerView](https://github.com/google/ExoPlayer/blob/release-v2/library/ui/src/main/java/com/google/android/exoplayer2/ui/PlayerView.java#L1056):

```
public boolean onTouchEvent(MotionEvent event) {
    if (!useController || player == null) {
      return false;
    }
    switch (event.getAction()) {
       // ...
```

Please let us know whether this solves your problem or we need to take a look.",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6335,"We have 2 dash DRM streams with audio tracks.
As far as we know the default language that should be picked in dash is the first audio adaptation set.
In the following streams 1,2 we can see that the dash has Hindi as the first language in manifest
But in the first we can see in Charles that the Language that is playing in the demo app  is Hindi and in the second the language that is playing is Telugu by default.
Could you please explain when the first audio is selected and when other one is selected in dash please?

We have sent an email on dev.exoplayer@gmail.com by Subject Name:  ""Dash Audio track selection inconsistent"".

We can see the same in 'release-v2' version.

-Thanks

",Can you verify if that's the case here?,"No, The device language is English."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6307,"I've managed to use SimpleExoPlayer to play HLS streams successfully and implemented a working way of selecting different playback speeds (1.25x, 1.5x, etc) by setting PlaybackParameters on the player. But in sometime, the sound scratch like a noise.
It's work fine with version r-2.8.3","Could you please provide all the information requested in the [issue template](https://github.com/google/ExoPlayer/blob/release-v2/.github/ISSUE_TEMPLATE/bug.md)? Specifically, it would be very helpful to have an example stream and the device you tested on so that it's more likely that we can reproduce the issue.",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6243,"### [REQUIRED] Issue description
For SMPTE-TT subtitles subtitles are getting displayed but from the two lines which are displayed the second line at the bottom is half visible.

### [REQUIRED] Reproduction steps
It can be easily reproducible with 2.10.3  version of Exoplayer in demo app.

### [REQUIRED] Link to test content

### [REQUIRED] A full bug report captured from the device

### [REQUIRED] Version of ExoPlayer being used
2.10.3 

### [REQUIRED] Device(s) and version(s) of Android being used
**Tested on SAMSUNG LED TV, Model No: LT24E310AR/XL / 2018, Screen size: 60 cm. Attached the image which contains the device details on which this is tested and issue is happened and android version of the setup box is 7.1.1.** 

**This issue is not seen in other model of SAMSUNG TV - 'SAMSUNG Screensize:80cm Model No:UA32M5570AULXL / 2018**

**This issue is not seen in Android 1ft device - Samsung galaxy S8.**


<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","May I ask you to look into the file you attached here and check whether that's what you expect?

Another thought is that the positioning of the text within the bitmap can't really be adjusted by the SubtitleView. The bitmap is 1080x1920. The subtitle view may need to scale accordingly but the position of the text within that bitmap is probably fixed. The screenshot you attached shows that the text is centered properly so it does not appear to be a scaling issue. I wonder how the overscan of that TV is an issue and the positioning needs to be adjusted in the bitmap for TVs?

Can you please check the subtitle file to see if it contains what you expect?",Hi @marcbaechinger any update on this issue?
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6229,"Hi,

I keep getting this error when trying to prepare the SilcenceMediaSource in the player, it simply fails to play.

```
2019-07-26 12:03:45.884 4663-5805/com.yiqqi.android.yiqqi.development E/ExoPlayerImplInternal: Internal runtime error.
    java.lang.IndexOutOfBoundsException: off=0, len=-741232 out of bounds (size=4096)
        at java.nio.Buffer.checkBounds(Buffer.java:587)
        at java.nio.DirectByteBuffer.put(DirectByteBuffer.java:285)
        at com.google.android.exoplayer2.source.SilenceMediaSource$SilenceSampleStream.readData(SilenceMediaSource.java:219)
        at com.google.android.exoplayer2.BaseRenderer.readSource(BaseRenderer.java:308)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:1024)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:654)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:575)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:326)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:214)
        at android.os.HandlerThread.run(HandlerThread.java:65)
```

This class was created under our request and we deeply appreciate it, but it seems to have this error which makes it unusable, could you please look into it? Thank you.",Could you provide some more information on how to reproduce this error? Does it occur after seeking? I just tried playing a concatenation of some media with a `SilenceMediaSource` in the demo app and it worked as expected.,"Yes, here's the situation, I have a timeline, which has multiple songs and with empty gaps between them, these gaps can be at the start and end as well. for that, I use ConcatenatingMediaSoruce with ClippingMediaSource for songs and SilenceMediaSource for gaps. Here's a representation of a simple timeline:

**-song-song-song-**
**-**: SilenceMediaSource
**song**: ClippingMediaSource with ProgressiveMediaSource

The issue is when readData happens, the byteRemaining is a negative value which shouldn't be the case, here's a debug screenshot up until the hightlighted line that produces the error:
![image](https://user-images.githubusercontent.com/10184170/61947147-bc4a6400-afa4-11e9-84f8-b4ef567cf3d5.png)

This issue is that everytime I recreate the ConcatenatingMediaSoruce, even with the same values, with the same SilenceMediaSource durations and start positions for SilenceMediaSource and ClippingMediaSource. I sometimes get the error and sometime not. I tested with fixed constant values and recreated the ConcatenatingMediaSoruce again and again, it's like a hit and miss, works a couple of times, then error, then works again, then error again...

I'm sorry as it's hard to explain because I ran a couple of tests already and I can't seem to track down the exact source of the issue.


"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6203,"### Issue description
I'm trying to get AudioFocus behavior: duck (lower volume) on notifications and pause on incoming call (and play after call end). When i look at the code https://github.com/google/ExoPlayer/blob/release-v2/library/core/src/main/java/com/google/android/exoplayer2/audio/AudioFocusManager.java#L419 default ExoPlayer implementation should be working like this (or maybe i don't understand it well). But unfortunetely - on incoming call volume is down to 0, but playback doesn't stop.

Interestingly enough. `CONTENT_TYPE_SPEECH` is not working either. Playback isn't stopped on both - notifications and incoming call.

### Reproduction steps
I set audio attributes like this
```kotlin
setAudioAttributes(AudioAttributes.Builder()
    .setContentType(C.CONTENT_TYPE_MUSIC)
    .setUsage(C.USAGE_MEDIA)
    .build(), true)
```

In logs i can see that `AUDIOFOCUS_LOSS_TRANSIENT` was dispatched. It seems like `PLAYER_COMMAND_WAIT_FOR_CALLBACK` wasn't handled properly.
```
D/AudioManager: dispatching onAudioFocusChange(-2) to android.media.AudioManager@1420c8com.google.android.exoplayer2.audio.AudioFocusManager$AudioFocusListener@d3f1561
D/AudioManager: dispatching onAudioFocusChange(1) to android.media.AudioManager@1420c8com.google.android.exoplayer2.audio.AudioFocusManager$AudioFocusListener@d3f1561
```

EDIT: when i digged deeper i found that on `SimpleExoPlayer` `ComponentListener` to `PlayerCommand` is ignoring `PLAYER_COMMAND_WAIT_FOR_CALLBACK` completely
```java
private void updatePlayWhenReady(
      boolean playWhenReady, @AudioFocusManager.PlayerCommand int playerCommand) {
    player.setPlayWhenReady(
        playWhenReady && playerCommand != AudioFocusManager.PLAYER_COMMAND_DO_NOT_PLAY,
        playerCommand != AudioFocusManager.PLAYER_COMMAND_PLAY_WHEN_READY);
  }
```

### Version of ExoPlayer being used
2.10.3

### Device(s) and version(s) of Android being used
Samsung Galaxy S7 Edge, Android 8.0; Huawei Mate 20 lite, Android 8.1; Samsung Galaxy A7 (2018), Android 9

Also emulators of Pixel 2 devices using Android 8, 9 and Q (9+)

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
",Could you add some logging in that method to check what parameters are passed to `setPlayWhenReady` when audio focus is lost transiently and gained again?,"Hi. Thanks for taking interest in this issue. Maybe the issue is bound to some other functionality (MediaSessionConnector or any other additional ExoPlayer classes i'm using). I managed to create simple reproduce project, that have this behavior (tested on API 28 Emulator and Nokia 8 device). In this project i'm using only ExoPlayer classes to play one online hls track. On call - playback doesn't get paused (you can see that on state textview and on notification). Let me know if i can assist you more
[AudioFocus.zip](https://github.com/google/ExoPlayer/files/3434725/AudioFocus.zip)
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6165,"I am using the latest version 2.10.2. But we encountered a new bug that only occurred in Android 8.0 and 8.1. 
I never found this stackoverflow using exoplayer 2.9.6.

![1562825302126](https://user-images.githubusercontent.com/16443498/61026218-5dea8680-a3e5-11e9-8e9b-d061dc5a1b51.jpg)
![1562825401994](https://user-images.githubusercontent.com/16443498/61026337-9f7b3180-a3e5-11e9-825e-c3a4a2b8e5e6.jpg)

","Can you please provide something more complete than a heavily clipped screenshot? That doesn't look like a stack overflow to me. It looks like some number of recursive calls to `read`, which exit fine into `RandomAccessFile`.","> Can you please provide something more complete than a heavily clipped screenshot? That doesn't look like a stack overflow to me. It looks like some number of recursive calls to `read`, which exit fine into `RandomAccessFile`.

start from RandomAccessFile, and then many number of recursive calls to read.

```
1 libcore.io.Linux.fstat(Native Method)
--
2 libcore.io.BlockGuardOs.fstat(BlockGuardOs.java:154)
3 libcore.io.IoBridge.open(IoBridge.java:501)
4 java.io.RandomAccessFile.<init>(RandomAccessFile.java:274)
5 java.io.RandomAccessFile.<init>(RandomAccessFile.java:141)
6 com.google.android.exoplayer2.upstream.FileDataSource.open(FileDataSource.java:65)
7 com.google.android.exoplayer2.upstream.cache.CacheDataSource.openNextSource(CacheDataSource.java:455)
8 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:317)
9 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
10 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
11 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
12 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
13 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
14 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
15 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
16 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
17 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
18 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
19 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
20 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
21 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
22 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
23 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
24 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
25 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
26 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
27 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
28 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
29 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
30 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
31 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
32 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
33 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
34 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
35 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
36 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
37 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
38 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
39 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
40 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
41 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
42 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
43 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
44 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
45 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
46 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
47 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
48 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
49 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
50 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
51 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
52 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
53 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
54 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
55 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
56 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
57 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
58 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
59 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
60 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
61 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
62 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
63 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
64 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
65 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
66 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
67 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
68 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
69 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
70 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
71 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
72 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
73 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
74 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
75 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
76 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
77 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
78 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
79 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
80 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
81 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
82 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
83 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
84 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
85 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
86 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
87 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
88 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
89 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
90 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
91 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
92 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
93 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
94 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
95 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
96 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
97 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
98 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
99 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
100 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
101 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
102 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
103 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
104 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
105 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
106 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
107 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
108 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
109 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
110 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
111 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
112 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
113 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
114 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
115 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
116 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
117 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
118 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
119 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
120 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
121 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
122 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
123 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
124 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
125 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
126 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
127 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
128 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
129 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
130 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
131 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
132 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
133 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
134 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
135 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
136 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
137 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
138 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
139 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
140 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
141 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
142 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
143 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
144 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
145 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
146 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
147 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
148 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
149 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
150 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
151 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
152 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
153 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
154 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
155 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
156 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
157 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
158 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
159 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
160 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
161 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
162 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
163 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
164 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
165 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
166 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
167 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
168 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
169 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
170 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
171 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
172 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
173 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
174 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
175 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
176 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
177 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
178 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
179 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
180 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
181 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
182 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
183 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
184 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
185 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
186 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
187 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
188 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
189 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
190 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
191 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
192 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
193 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
194 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
195 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
196 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
197 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
198 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
199 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
200 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
201 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
202 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
203 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
204 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
205 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
206 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
207 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
208 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
209 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
210 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
211 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
212 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
213 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
214 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
215 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
216 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
217 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
218 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
219 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
220 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
221 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
222 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
223 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
224 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSource.java:318)
225 com.google.android.exoplayer2.upstream.cache.CacheDataSource.read(CacheDataSou...too long be cutted!
```
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6155,"### [REQUIRED] Issue description
Calling `seekTo` when playing from an HLS playlist does not always seek to the exact location. After calling `seekTo`, playback appears to begin at the beginning of the playlist chunk containing the requested location. From the docs, it appears that exact seeking should be supported.

### [REQUIRED] Reproduction steps
1. Load the playlist into the sample player
1. Seek from the beginning to (e.g.) `270757ms` (I accomplished this by hardcoding the seek location into `PlayerControlView.seekToTimeBarPosition`)
1. Playback resumes at approximately `240047ms`
1. Once the playhead is within the current chunk, seeking to that location behaves as expected.

### [REQUIRED] Link to test content
Sample playlist has been sent to the dev.exoplayer email.

### [REQUIRED] A full bug report captured from the device
Bug report has been sent with the sample playlist.

### [REQUIRED] Version of ExoPlayer being used
I have reproduced this on 2.9.4 and 2.10

### [REQUIRED] Device(s) and version(s) of Android being used
I am currently using a Pixel 3 running Android 9. We've had a couple instances of it happening on a Pixel 1 running 9 as well, but less frequently. I've been thus far unable to reproduce it on an emulator.

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
",What are you looking at to determine (3)?,"In the demo application, I'm seeing that the seekbar goes to ~4:30 (270757ms) when I drop it (I hardcoded the seekbar to use that number - this is replicating a seek based on chapter metadata), but then it jumps back to ~4:00 (240047ms) when playback resumes.

In my own app, I've verified the location where playback resumes by polling the current state of the player."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6146,"### [REQUIRED] Issue description
When I try to run ExoPlayer library core test cases keep failing

### [REQUIRED] Reproduction steps
When try to Run `DownloadHelperTest.java` is keep failing 

### [REQUIRED] Link to test content
N/A

### [REQUIRED] A full bug report captured from the device
```
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackSelections_afterReplaceTrackSelections_returnsNewSelections: sdk=28; resources=BINARY
Exception in thread ""DownloadHelper"" java.lang.NullPointerException
	at com.google.android.exoplayer2.offline.DownloadHelper$MediaPreparer.onSourceInfoRefreshed(DownloadHelper.java:918)
	at com.google.android.exoplayer2.source.BaseMediaSource.refreshSourceInfo(BaseMediaSource.java:74)
	at com.google.android.exoplayer2.testutil.FakeMediaSource.finishSourcePreparation(FakeMediaSource.java:215)
	at com.google.android.exoplayer2.testutil.FakeMediaSource.prepareSourceInternal(FakeMediaSource.java:105)
	at com.google.android.exoplayer2.source.BaseMediaSource.prepareSource(BaseMediaSource.java:140)
	at com.google.android.exoplayer2.offline.DownloadHelper$MediaPreparer.handleMessage(DownloadHelper.java:858)
	at android.os.Handler.dispatchMessage(Handler.java:102)
	at com.google.android.exoplayer2.testutil.RobolectricUtil$CustomLooper.doLoop(RobolectricUtil.java:129)
	at com.google.android.exoplayer2.testutil.RobolectricUtil$CustomLooper.loop(RobolectricUtil.java:67)
	at android.os.Looper.loop(Looper.java)
	at android.os.HandlerThread.run(HandlerThread.java:65)
```

### [REQUIRED] Version of ExoPlayer being used
### 2.10.2 ###

### [REQUIRED] Device(s) and version(s) of Android being used
N/A

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","Could you share a bit more detail about how you're able to reproduce this?

Also, it looks impossible to me that [this line would throw a NPE](https://github.com/google/ExoPlayer/blob/r2.10.2/library/core/src/main/java/com/google/android/exoplayer2/offline/DownloadHelper.java#L918). I think that would mean `mediaPeriods` is null, but it's assigned right above. Can you see any way that a NPE can happen?

```
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackSelections_afterAddAudioLanguagesToSelection_returnsCombinedSelections: sdk=28; resources=BINARY
Called loadFromPath(/system/framework/framework-res.apk, true); mode=binary sdk=28
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackSelections_afterReplaceTrackSelections_returnsNewSelections: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackGroups_returnsTrackGroups: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getMappedTrackInfo_returnsMappedTrackInfo: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getDownloadRequest_createsDownloadRequest_withAllSelectedTracks: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackSelections_afterAddTrackSelections_returnsCombinedSelections: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackSelections_afterClearTrackSelections_isEmpty: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getPeriodCount_returnsPeriodCount: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getManifest_returnsManifest: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackSelections_returnsInitialSelection: sdk=28; resources=BINARY
[Robolectric] com.google.android.exoplayer2.offline.DownloadHelperTest.getTrackSelections_afterAddTextLanguagesToSelection_returnsCombinedSelections: sdk=28; resources=BINARY

Process finished with exit code 0
```","It actually in the code base locally NPE is in the next line of code `pendingMediaPeriods.add(mediaPeriod);`


1) If I run the test cases one by one, all the test cases are passing successfully.

2) If I put `TimeUnit.SECONDS.sleep(5);` after the `prepareDownloadHelper(downloadHelper);` in each test suit, all test cases passes successfully."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6109,"### [REQUIRED] Searched documentation and issues
There was no mention of why click handling is being overridden by the `PlayerView` via `onTouchEvent`

### [REQUIRED] Question
We recently upgraded from exoplayer **2.8** to **2.10.2** and noticed not all of our Views hosting an exoplayer were clickable. Looking at the source shows that in **2.10.2** PlayerView consumes all touch events upon it's surface:
```
  @Override
  public boolean onTouchEvent(MotionEvent event) {
    switch (event.getAction()) {
      case MotionEvent.ACTION_DOWN:
        isTouching = true;
        return true;
      case MotionEvent.ACTION_UP:
        if (isTouching) {
          isTouching = false;
          performClick();
          return true;
        }
        return false;
      default:
        return false;
    }
  }
```
Whereas in **2.8** it would still allow touch/click events to be propagated to it's parent container unless the controller was present:
```
  @Override
  public boolean onTouchEvent(MotionEvent ev) {
    if (!useController || player == null || ev.getActionMasked() != MotionEvent.ACTION_DOWN) {
      return false;
    }
    if (!controller.isVisible()) {
      maybeShowController(true);
    } else if (controllerHideOnTouch) {
      controller.hide();
    }
    return true;
  }
```
Is this intended behavior? It seems like a bug since it prevents any parent view from performing a click event if the tapped surface is within a PlayerView's bounds.
### A full bug report captured from the device
n/a

### Link to test content
n/a
<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/question.md
-->
",Can you check whether we also consume the click to which `performClick()` delegate the touch event? ,
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/6107,"We are receiving a bug, where Exoplayer does not load our MP4 files in the ViewPager after 5th attempt(it is predictable and occurs always). Here is crash log from ExoPlayer:

```
2019-06-28 14:11:03.758 30021-31428/com.idenfy.app.new E/ExoPlayerImplInternal: Playback error.
    com.google.android.exoplayer2.ExoPlaybackException
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.throwDecoderInitError(MediaCodecRenderer.java:450)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodec(MediaCodecRenderer.java:437)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:929)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:506)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:566)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:518)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:301)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:193)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: com.google.android.exoplayer2.mediacodec.MediaCodecRenderer$DecoderInitializationException: Decoder init failed: OMX.qcom.video.decoder.avc, Format(1, null, video/avc, -1, null, [500, 500, -1.0], [-1, -1])
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodec(MediaCodecRenderer.java:437) 
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:929) 
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:506) 
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:566) 
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:518) 
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:301) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:193) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
```","How many ExoPlayer instances are hold by the view pager code after the 5th attempt? 

Background of that queston is that, the app code needs to make sure that you don't have more ExoPlayer instances than instances of media codecs a device provides. 

Can you please take a [bug report](https://developer.android.com/studio/debug/bug-report) right after the crash and upload it? You can also send it to dev.exoplayer@gmail.com if you don't want to upload here in public.

You can also look into the logs yoursefl and watch out for [the log statements indicating initialization and release of instances](https://exoplayer.dev/listening-to-player-events.html#player-information).  There are statements similar to these:

```
ExoPlayerImpl: Init 2e5194c [ExoPlayerLib/2.9.6] [marlin, Pixel XL, Google, 26]
...
ExoPlayerImpl: Release 2cd6e65 [ExoPlayerLib/2.9.6] [marlin, Pixel XL, Google, 26] [goog.exo.core, goog.exo.ui, goog.exo.dash]
```

If you find 5 init statements not resolved by a release statement, I'd interpret that that your device is running out of mp4 decoders which produces the exception you are reporting. It happens when no more codecs can be instantiated because all codecs in use.",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5971,"**Issue:** Playback fails when we try to select all the tracks available in an audio group.

**Media:** https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8 

**Crash Log:**

```
2019-05-30 14:15:49.249 12743-12743/com.google.android.exoplayer2.demo E/EventLogger: playerFailed [14.12, 16.62, window=0, period=0]
    com.google.android.exoplayer2.ExoPlaybackException: java.lang.ArrayIndexOutOfBoundsException: length=4; index=4
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:397)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:193)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: java.lang.ArrayIndexOutOfBoundsException: length=4; index=4
        at com.google.android.exoplayer2.trackselection.AdaptiveTrackSelection.setCheckpointValues(AdaptiveTrackSelection.java:810)
        at com.google.android.exoplayer2.trackselection.AdaptiveTrackSelection.getAllocationCheckpoints(AdaptiveTrackSelection.java:745)
        at com.google.android.exoplayer2.trackselection.AdaptiveTrackSelection.access$000(AdaptiveTrackSelection.java:37)
        at com.google.android.exoplayer2.trackselection.AdaptiveTrackSelection$Factory.createTrackSelections(AdaptiveTrackSelection.java:275)
        at com.google.android.exoplayer2.trackselection.DefaultTrackSelector.selectTracks(DefaultTrackSelector.java:1451)
        at com.google.android.exoplayer2.trackselection.MappingTrackSelector.selectTracks(MappingTrackSelector.java:400)
        at com.google.android.exoplayer2.MediaPeriodHolder.selectTracks(MediaPeriodHolder.java:209)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.reselectTracksInternal(ExoPlayerImplInternal.java:1100)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:357)
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:193) 
        at android.os.HandlerThread.run(HandlerThread.java:65)
```

**My Assumption:** I am assuming that when I select all the tracks available from an audio group it will behave like adaptive (track Index = -1).

**Question:**
If I check the stream it has the following audio track group,

```
#EXT-X-MEDIA:TYPE=AUDIO,GROUP-ID=""stereo"",LANGUAGE=""en"",NAME=""English"",DEFAULT=YES,AUTOSELECT=YES,URI=""audio/stereo/en/128kbit.m3u8""
#EXT-X-MEDIA:TYPE=AUDIO,GROUP-ID=""stereo"",LANGUAGE=""dubbing"",NAME=""Dubbing"",DEFAULT=NO,AUTOSELECT=YES,URI=""audio/stereo/none/128kbit.m3u8""

#EXT-X-MEDIA:TYPE=AUDIO,GROUP-ID=""surround"",LANGUAGE=""en"",NAME=""English"",DEFAULT=YES,AUTOSELECT=YES,URI=""audio/surround/en/320kbit.m3u8""
#EXT-X-MEDIA:TYPE=AUDIO,GROUP-ID=""surround"",LANGUAGE=""dubbing"",NAME=""Dubbing"",DEFAULT=NO,AUTOSELECT=YES,URI=""audio/stereo/none/128kbit.m3u8""
```
If I check the tracks in code then audio groups will be

1. English(stereo)/English(surround)   Unique Id:  1,0,0 /  1,0,1
2. dubbing(stereo)/dubbing(surround)    Unique Id:  1,1,0 /  1,1,1

How can we select auto for Audio ? 

There could be following an option to select auto from English group (1,0,-1) or dubbing group (1,1,-1). Can we do this ? I tried but the app crashed.

How ExoPlayer is selecting the audio in case if I select auto ?




",Can you rephrase it or open a new issue/question if unrelated?,
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5927,"**[REQUIRED] Searched documentation and issues**
I am using ExoPlayer version 2.9.6 to stream video content in one of my project. Recently I added download video feature to my app using ExoPlayer's in built download manager. The problem with download is that it consumes more data while downloading. For a 18 MB video (the size is determined by checking the size of ExoPlayer's download folder after download) , it takes about 140 MB (this is variable in each try) of network data. I am using DASH to stream videos.  I checked the same with Demo App provided and the results are almost same.

**[REQUIRED] Question**
Any one know why this is happening.? Is there any improvements needed in my code ?

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/question.md
-->
","How do you measure the used network data?
Could you share the measurement you did using the ExoPlayer demo app?","> How do you measure the used network data?
> Could you share the measurement you did using the ExoPlayer demo app?

I noticed this issue only after some of our users started reporting. I measured the network data using GlassWire network monitor app. I have downloaded a 37 MB video using ExoPlayer Demo app and here I am attaching the screenshot from data monitor app

![Screenshot_20190522-203711](https://user-images.githubusercontent.com/25474982/58186234-19d6e180-7cd2-11e9-9155-419989c71878.png)
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5876,"Hello,

I have been waiting for 2.10.0 release for a long time. Finally it has been released. Thanks for your effort.

I tried to fetch ICY metadata from radio streams, but it seems ExoPlayer fails on some streams. Here is some examples:

[http://voyagesc.radyotvonline.com/](http://voyagesc.radyotvonline.com/)
ExoPlayer fails in fetching ICY metadata on this radio stream while 'Current Song' section is not empty when you open link on browser (Chrome in my case). Also, ExoPlayer logs this issue as 

> W/IcyDecoder: Unrecognized ICY tag: null

I would like to also give a working example:
[http://stream.radyoalaturka.com.tr:9100/](http://stream.radyoalaturka.com.tr:9100/)
ExoPlayer successfuly fetches ICY metadata from this stream and invokes `MetadataOutput` listener.

The only difference between two streams is SHOUTcast Server version; failing stream version is 1.9.8 while working stream version is 2.5.5.733

I used an API level 28 Android 9 Emulator
I fetch ICY Metadata as follows:

```
player.addMetadataOutput(metadata -> {
            if ((metadata != null)) {
                final int length = metadata.length();
                if (length > 0) {
                    for (int i = 0; i < length; i++) {
                        final Metadata.Entry entry = metadata.get(i);
                        if (entry instanceof IcyInfo) {
                            final IcyInfo icyInfo = ((IcyInfo) entry);
                            Log.d(""IcyInfo"", icyInfo.title);
                        } else if (entry instanceof IcyHeaders) {
                            final IcyHeaders icyHeaders = ((IcyHeaders) entry);
                            Log.d(""IcyHeaders"", icyHeaders.name);
                            Log.d(""IcyHeaders"", icyHeaders.genre);
                        }
                    }
                }
            }
        });
```

I hope these examples help for finding the issue. If you think I miss something to fetch the metadata, please inform me.

Thank you.

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","Does playback of the stream work at all? Does using the OkHttp extension rather than the default network stack resolve the problem? You should probably be using the OkHttp extension anyway if you're playing ICY streams, since on some devices the default network stack will not handle not-strictly-http status responses, and will fail playback with ""Unexpected status line: ICY 200 OK"" for some ICY streams. We should add an entry to our troubleshooting page about this!","Update

Using OkHttp extension resolves the problem in `Sony E5553 Android 6.0, API 23`. I only changed my code from this:

```
public HttpDataSource.Factory buildHttpDataSourceFactory() {
    return new DefaultHttpDataSourceFactory(userAgent);
}
```

to this:

```
public HttpDataSource.Factory buildHttpDataSourceFactory() {
        return new OkHttpDataSourceFactory(new OkHttpClient(), userAgent);
 }
```

We appreciate when other easy-to-fix bugs are resolved.

Thank you."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5865,"exo version:2.9.6
MediaPlayer:
![MediaPlayer](https://user-images.githubusercontent.com/16698336/57502603-01081c80-731f-11e9-81bc-4bdf43e29d34.png)
ExoPlayer:
![ExoPlayer](https://user-images.githubusercontent.com/16698336/57502618-0b2a1b00-731f-11e9-82a6-ac58b109e99c.png)
",Can you please provide us with some steps on how to reproduce this? ,"Android 4.4  SOC: Allwinner Quad-core H3

The same problem with using this project：
https://github.com/roxlu/2018-016-android-exoplayer-with-gltexture

video resource:
https://drive.google.com/open?id=1l0XuEfyrPsE-jg98kndVlpfzcqkKSmFH
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5845,"**Details:**
This error occur when the security level of the device is L1 with exoplayer ver 2.8.4
Content: HEVC +DASH
Android 7
If full adb logcat is needed:
https://drive.google.com/open?id=1QG4d6VOr_UPCoYLojjJJkTmmqRWlc2Dp

I am using our tv app that using the exoplayer 2.8.4 implemented so I can't use the
special log request, I attached above the full log in a link.

Happens when zapping to others channels, I can get handreds of this error that also effect the video that doesn't work from time to time.
***********************************************************************************************************

Log:
```
E MediaDrm-JNI: Illegal state exception: Failed to handle key response: DRM vendor-defined error: -2965 (-2965)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: Renderer error.
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: com.google.android.exoplayer2.ExoPlaybackException
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.shouldWaitForKeys(MediaCodecRenderer.java:775)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.feedInputBuffer(MediaCodecRenderer.java:716)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:551)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:578)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:350)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at android.os.Handler.dispatchMessage(Handler.java:98)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at android.os.Looper.loop(Looper.java:154)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at android.os.HandlerThread.run(HandlerThread.java:61)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: Caused by: com.google.android.exoplayer2.drm.DrmSession$DrmSessionException: android.media.MediaDrm$MediaDrmStateException: Failed to handle key response: DRM vendor-defined error: -2965
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.onError(DefaultDrmSessionManager.java:610)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.onKeysError(DefaultDrmSessionManager.java:605)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.onKeyResponse(DefaultDrmSessionManager.java:597)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.access$900(DefaultDrmSessionManager.java:51)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.drm.DefaultDrmSessionManager$PostResponseHandler.handleMessage(DefaultDrmSessionManager.java:685)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at android.os.Handler.dispatchMessage(Handler.java:102)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: ... 2 more
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: Caused by: android.media.MediaDrm$MediaDrmStateException: Failed to handle key response: DRM vendor-defined error: -2965
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at android.media.MediaDrm.provideKeyResponse(Native Method)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.drm.FrameworkMediaDrm.provideKeyResponse(FrameworkMediaDrm.java:106)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: at com.google.android.exoplayer2.drm.DefaultDrmSessionManager.onKeyResponse(DefaultDrmSessionManager.java:581)
05-06 15:09:32.675 20625 10275 E ExoPlayerImplInternal: ... 5 more
05-06 15:09:32.677 208 5936 D BerlinOmxComponentImpl: setState() line 903: OMX.Marvell.video_decoder.hevc.secure, state change, OMX_StateExecuting(3) -> OMX_StateIdle(2)
05-06 15:09:32.677 208 5936 D BerlinOmxAmpVideoDecoder: Function stop(), Line 1742, Function Enter
05-06 15:09:32.678 20625 20625 D MetricManager: Destroying player state manager
05-06 15:09:32.679 20625 20625 D MetricManager: Player is stopped
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: �[0;34m[�[0;34m(main)IFSExoPlayer2Pipe.java:2129->onPlayerError]�[0;32m[android]�[0;0m �[1;31mIFS_ERROR: onPlayerError rendererIndex:0 type: 1 log:com.google.android.exoplayer2.ExoPlaybackException
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: IFSExoPlayer2Pipe.java:2129->onPlayerError
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: ExoPlayerImpl.java:504->handleEvent
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: ExoPlayerImpl.java:103->handleMessage
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: Handler.java:102->dispatchMessage
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: Looper.java:154->loop
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: ActivityThread.java:6077->main
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: Method.java:-2->invoke
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: ZygoteInit.java:865->run
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: ZygoteInit.java:755->main
05-06 15:09:32.679 20625 20625 E IFSExoPlayer2Pipe: �[0;0m
05-06 15:09:32.680 20625 20625 W IFSExoPlayer2Pipe: �[0;34m[�[0;34m(main)IFSExoPlayer2Pipe.java:2162->onPlayerError]�[0;32m[android]�[0;0m �[1;33munknown error exception�[0;0m
```",Did you manage to make this work on any devices or is this happening on a specific device only?,
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5831,"### [REQUIRED] Issue description
Our app just recently released and we found in the Firebase Crashalytics an increasing number of crashes which I included below 
we are using an HlsMediaSource for the content then adding the AdsMediaSourceand for the ads and 
here is the code of how we are initializing the player:

   ```
 ImaAdsLoader.Builder builder = new ImaAdsLoader.Builder(this);
    
  imaAdsLoader=builder.setImaSdkSettings(ImaSdkFactory.getInstance().createImaSdkSettings()).buildForAdTag(Uri.parse(adVMAP));

 DefaultDataSourceFactory defaultDataSourceFactory = new DefaultDataSourceFactory(this, Util.getUserAgent(this, getResources().getString(R.string.app_name)));

    MediaSource mediaSource = new 
    HlsMediaSource.Factory(defaultDataSourceFactory).createMediaSource(Uri.parse(episodeLink));

        AdsMediaSource adsMediaSource = new AdsMediaSource(mediaSource, defaultDataSourceFactory, imaAdsLoader, playerView.getOverlayFrameLayout());

        player.addListener(this);

        boolean haveStartPosition = startPosition != C.INDEX_UNSET;
        if (haveStartPosition) {
            player.seekTo(startPosition);
        }

        player.prepare(adsMediaSource,!haveStartPosition,false);
        player.setPlayWhenReady(true);

```
### [REQUIRED] Reproduction steps
we couldn't reproduce the issue , we only see the crashes on the crashlytics console.

### [REQUIRED] Link to test content

### [REQUIRED] A full bug report captured from the device
```
Fatal Exception: java.lang.IllegalArgumentException
       at com.google.android.exoplayer2.util.Assertions.checkArgument(Assertions.java:39)
       at com.google.android.exoplayer2.ext.ima.ImaAdsLoader.onTimelineChanged(ImaAdsLoader.java:912)
       at com.google.android.exoplayer2.ExoPlayerImpl$PlaybackInfoUpdate.notifyListeners(ExoPlayerImpl.java:780)
       at com.google.android.exoplayer2.ExoPlayerImpl.updatePlaybackInfo(ExoPlayerImpl.java:717)
       at com.google.android.exoplayer2.ExoPlayerImpl.handlePlaybackInfo(ExoPlayerImpl.java:648)
       at com.google.android.exoplayer2.ExoPlayerImpl.handleEvent(ExoPlayerImpl.java:593)
       at com.google.android.exoplayer2.ExoPlayerImpl$1.handleMessage(ExoPlayerImpl.java:125)
       at android.os.Handler.dispatchMessage(Handler.java:105)
       at android.os.Looper.loop(Looper.java:156)
       at android.app.ActivityThread.main(ActivityThread.java:6577)
       at java.lang.reflect.Method.invoke(Method.java)
       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:986)
       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:876)
```
### [REQUIRED] Version of ExoPlayer being used
2.9.4

### [REQUIRED] Device(s) and version(s) of Android being used
Samsung galaxy S6 
HTC Desire 820s 
HUAWEI MediaPad T3 7

android 6, 7 and 8 
<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
",Could you confirm that you are always just playing an `HlsMediaSource` (and never a concatenation)?,"Thank you for replying 
yes we are always playing HlsMediaSource "
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5821,"### [REQUIRED] Content description

I found that there is a specific device that cannot play 48000Hz sampling rate contents.

`AXON7 mini ZTE B2017G` always throws an error ""DecoderInitializationException"" every time it tries to play 48000Hz sampling-rate contents.

This device uses decoder ""OMX.google.aac.decoder"" for audio, and its `CodecCapabilities#getAudioCapabilities#.getSupportedSampleRateRanges()` contains `48000`.

Also, it only plays fine when the audio decoder is disabled. (Only video plays.)

My questions are

 - Why does this device fail with ""DecoderInitializationException"", even though the decoder is ""OMX.google.aac.decoder"", which is used on other devices.

As far as I understand, ""OMX.google.aac.decoder"" is a software decoder and all the devices with ""OMX.google.aac.decoder"" decoder should fail to decode 48000Hz contents (like Nexus5, which also uses ""OMX.google.aac.decoder"" for audio) because there are no differences on the decoder aspect. 

 - Could you think of any other possible reasons why only this device fails to decode 48000Hz contents or what can I do to find other devices that cause the same issue?

### [REQUIRED] Link to test content

Sample URL

44100Hz sample (works on AXON7 mini ZTE B2017G): https://mock-stream-2.firebaseapp.com/44100hz/playlist.m3u8

48000Hz sample (not works on AXON7 mini ZTE B2017G): https://mock-stream-2.firebaseapp.com/48000hz/playlist.m3u8



### [REQUIRED] Version of ExoPlayer being used
ExoPlayer Version: v2.9.6

### [REQUIRED] Device(s) and version(s) of Android being used
Device: AXON7 mini ZTE B2017G
Android OS: 6.0.1
","Can you tell us the Build.DEVICE and Build.MODEL values for your device? It might help us to see if there is any variation in these for better workaround targeting. When using ExoPlayer, you'll see a log line containing ""ExoPlayerLib/2."" which includes these values.",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5806,"### [REQUIRED] Issue description

**While playing video content, we are getting below given exception randomly:**
```
_PlayerEventListener onPlayerError e : com.google.android.exoplayer2.ExoPlaybackException: java.lang.IllegalStateException
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:359)
        at android.os.Handler.dispatchMessage(Handler.java:98)
        at android.os.Looper.loop(Looper.java:148)
        at android.os.HandlerThread.run(HandlerThread.java:61)
     Caused by: java.lang.IllegalStateException
        at android.media.MediaCodec.native_dequeueOutputBuffer(Native Method)
        at android.media.MediaCodec.dequeueOutputBuffer(MediaCodec.java:2379)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1273)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:649)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:530)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:303)
        at android.os.Handler.dispatchMessage(Handler.java:98) 
        at android.os.Looper.loop(Looper.java:148) 
        at android.os.HandlerThread.run(HandlerThread.java:61) 
     VideoPlayerFragment{84a84a1 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}__
```
### [REQUIRED] Reproduction steps
We are playing videos one by one i.e right after end of one video, another video starts. These videos keep playing in loop.

### [REQUIRED] Link to test content
I have tried playing 3 videos one after another. Please find them at below given google drive link:
**https://drive.google.com/drive/folders/108kjPUW0RQreyixFh_xAHg1LU5ZKxTD_?usp=sharing**

### [REQUIRED] A full bug report captured from the device
```
_**PlayerEventListener onPlayerError e : com.google.android.exoplayer2.ExoPlaybackException: java.lang.IllegalStateException
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:359)
        at android.os.Handler.dispatchMessage(Handler.java:98)
        at android.os.Looper.loop(Looper.java:148)
        at android.os.HandlerThread.run(HandlerThread.java:61)
     Caused by: java.lang.IllegalStateException
        at android.media.MediaCodec.native_dequeueOutputBuffer(Native Method)
        at android.media.MediaCodec.dequeueOutputBuffer(MediaCodec.java:2379)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1273)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:649)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:530)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:303)
        at android.os.Handler.dispatchMessage(Handler.java:98) 
        at android.os.Looper.loop(Looper.java:148) 
        at android.os.HandlerThread.run(HandlerThread.java:61) 
     VideoPlayerFragment{84a84a1 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}__**
```
### [REQUIRED] Version of ExoPlayer being used
Exoplayer 2.9.6

### [REQUIRED] Device(s) and version(s) of Android being used
Brand name : Realtek
Model name: X5
OS: Marshmallow 6.0.1

<!-- DO NOT DELETE
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
","Does this occur only on the specified device? Also, please provide a proper bug report (the issue template clearly says ""a log snippet is NOT sufficient""). Thanks.","Yes, we are facing this issue on this particular device only. Please find detailed bug report below:
```
04-29 19:55:37.374 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:55:37.378] run on Thread: Timer-2
04-29 19:55:37.377 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:55:37.381] run Panel Status Polling
04-29 19:55:37.380 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.384] setAllPanelsPolling
04-29 19:55:37.383 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:55:37.387] run on Thread: Timer-1
04-29 19:55:37.387 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.390] panelHelperRX panelId: null commands: [QPW, QAM]
04-29 19:55:37.390 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:55:37.394] run Device Status Polling
04-29 19:55:37.393 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:55:37.397] run Device Status Polling
04-29 19:55:37.396 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.400] sendCommandsForAllPanels All commands[QPW, QAM] Thread: pool-5-thread-4
04-29 19:55:37.399 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:55:37.403] saveDeviceOnLastCheckTime timeStamp: 1556547937391
04-29 19:55:37.402 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:55:37.406] saveDeviceOnLastCheckTime timeStamp: 1556547937394
04-29 19:55:37.405 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.InMemoryStorageImpl: [2019-04-29 19:55:37.409] getAllPanelsInfo mAllPanels : [{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null}]
04-29 19:55:37.411 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:55:37.415] getAllPanels panels :[{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null}]
04-29 19:55:37.414 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.418] sendCommandsForAllPanels priority || non-projector RZ660 cmds send to individual panel
04-29 19:55:37.417 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.421] sendCommandsForIndividualPanel panelId: 2308 commands: [QPW, QAM] Thread: pool-5-thread-4
04-29 19:55:37.420 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.InMemoryStorageImpl: [2019-04-29 19:55:37.425] getPanelInfoOfPanelId panelId : 2308
04-29 19:55:37.424 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:55:37.428] getPanelInfoOfPanelId panel :{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null}
04-29 19:55:37.427 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.432] addCommandsToQueue panel : {{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null} isPriorityCmds = false pushId = null msgId = null processingStartTimeStamp : -1 timeStamp : 1556547937425 commands = [QPW, QAM]} isPriorityCommands : false
04-29 19:55:37.431 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.435] addCommandsToQueue polling
04-29 19:55:37.434 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.438] addCommandsToQueue sendCmdForExecute
04-29 19:55:37.436 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.441] sendNextCommandForExecution 
04-29 19:55:37.439 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.443] sendNextCommandForExecution processPanelCommand 
04-29 19:55:37.443 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:37.447] processPanelCommand panelCommandModel: {{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null} isPriorityCmds = false pushId = null msgId = null processingStartTimeStamp : -1 timeStamp : 1556547937425 commands = [QPW, QAM]}
04-29 19:55:37.446 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:37.450] RS232PanelConnection panelId : 2308 messageId : null pushId : null panelControl : RS232_RM_HDMI_ONLY
04-29 19:55:37.450 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:37.454] checkForSerialPort DeviceList :1
04-29 19:55:37.453 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:37.457] checkForSerialPort device.getDeviceName :/dev/bus/usb/005/002
04-29 19:55:37.457 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.461] Entered isVendorSpecificUsbDevice for device :UsbDevice[mName=/dev/bus/usb/005/002,mVendorId=1133,mProductId=50484,mClass=0,mSubclass=0,mProtocol=0,mManufacturerName=Logitech,mProductName=USB Receiver,mVersion=2.0,mSerialNumber=null,mConfigurations=[
    UsbConfiguration[mId=1,mName=RQR29.00_B0015,mAttributes=160,mMaxPower=49,mInterfaces=[
    UsbInterface[mId=0,mAlternateSetting=0,mName=null,mClass=3,mSubclass=1,mProtocol=1,mEndpoints=[
    UsbEndpoint[mAddress=129,mAttributes=3,mMaxPacketSize=8,mInterval=8]]
    UsbInterface[mId=1,mAlternateSetting=0,mName=null,mClass=3,mSubclass=1,mProtocol=2,mEndpoints=[
    UsbEndpoint[mAddress=130,mAttributes=3,mMaxPacketSize=20,mInterval=2]]]]
04-29 19:55:37.460 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.464] isVendorSpecificUsbDevice ManufacturerName : Logitech
04-29 19:55:37.463 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.467] isVendorSpecificUsbDevice ProductName : USB Receiver
04-29 19:55:37.466 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.470] isVendorSpecificUsbDevice SerialNumber : null
04-29 19:55:37.470 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.474] isVendorSpecificUsbDevice DeviceId : 5002
04-29 19:55:37.472 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.476] isVendorSpecificUsbDevice ProductId : 50484
04-29 19:55:37.475 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.479] isVendorSpecificUsbDevice VendorId : 1133
04-29 19:55:37.478 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.482] isVendorSpecificUsbDevice deviceClass As Per Interface
04-29 19:55:37.481 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.485] isVendorSpecificUsbDevice intF ManufacturerName : null
04-29 19:55:37.484 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.488] isVendorSpecificUsbDevice intF ManufacturerName : 0
04-29 19:55:37.487 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.491] isVendorSpecificUsbDevice intF InterfaceClass : 3
04-29 19:55:37.490 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.494] isVendorSpecificUsbDevice intF ManufacturerName : null
04-29 19:55:37.493 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.497] isVendorSpecificUsbDevice intF ManufacturerName : 1
04-29 19:55:37.496 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.500] isVendorSpecificUsbDevice intF InterfaceClass : 3
04-29 19:55:37.499 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:55:37.503] Exited isVendorSpecificUsbDevice isVendorSpecificDevice :false
04-29 19:55:37.502 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:37.506] registerListener
04-29 19:55:37.505 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:37.509] sendCommandsToPanel isPriorityCommands : false commands :[QPW, QAM]
04-29 19:55:37.508 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:37.513] sendResponseForDisconnectedMode
04-29 19:55:37.512 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.DeviceUtils: [2019-04-29 19:55:37.516] isHDMIConnected HDMI file Path : /sys/devices/virtual/switch/hdmi/state
04-29 19:55:38.000 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.DeviceUtils: [2019-04-29 19:55:38.005] isHDMIConnected switchValue : 1
04-29 19:55:38.002 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.DeviceUtils: [2019-04-29 19:55:38.006] isHDMIConnected finally try
04-29 19:55:38.004 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:38.008] sendResponse
04-29 19:55:38.005 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:38.010] sendResponse returning response.
04-29 19:55:38.007 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.012] onGettingPanelStatusModel panelStatusModel panelStatus : {panelControl = RS232_RM_HDMI_ONLY shutterState = -1 isPriorityCmd = false panelStatus = DISCONNECTED_HDMI_CONNECTED isAudioEnable : false}
04-29 19:55:38.009 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:55:38.013] unRegisterListener
04-29 19:55:38.011 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.015] removeCommandFromQueue panelId: 2308 isPriorityCommand : false
04-29 19:55:38.012 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.017] removeCommandFromQueue from pollingQueue panelId: 2308
04-29 19:55:38.013 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.018] sendNextCommandForExecution 
04-29 19:55:38.015 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.020] sendNextCommandForExecution no cmd for execution
04-29 19:55:38.017 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:55:38.022] saveIsPanelAudioOn isPanelAudioOn : false
04-29 19:55:38.018 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:55:38.023] getTimeOffsetFromLocalServer :5
04-29 19:55:38.019 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.024] writePanelStatusDataToDBAndSendToServer PanelId: 2308 isResponseFromPanelPolling: true
04-29 19:55:38.020 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:55:38.025] getPanelStatusReportingStartTime :-1
04-29 19:55:38.021 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.026] writePanelStatusDataToDBAndSendToServer panelStatusReportingStartTime: -1
04-29 19:55:38.022 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.026] writePanelStatusDataToDBAndSendToServer no need to send panel info to server 
04-29 19:55:38.026 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:55:38.031] panelHelperRX onSuccess
04-29 19:56:04.999 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:05.003] getTimeOffsetFromLocalServer :5
04-29 19:56:05.006 15200-15493/panasonic.digital.signage.piqa1 D/RegionContentChangeTimerTask: [2019-04-29 19:56:05.010] run currentTime : 1556547965002
04-29 19:56:05.010 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:05.014] getTimeOffsetFromLocalServer :5
04-29 19:56:05.013 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:05.017] playNextItem position : 1 currentTime :1556547965013 contentType : VIDEO thread : Thread[Timer-10,5,main]
04-29 19:56:05.017 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:05.021] getTimeOffsetFromLocalServer :5
04-29 19:56:05.020 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:05.024] showFragment  position : 1 ContentId : 5779 currentTimestamp : 1556547965020 StartTimeStamp : 1556547965000 isForRefreshView : false isAnimationEnable : true thread : Thread[Timer-10,5,main] com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:05.023 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:05.027] showFragment ContentId new fragment will be created com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:05.027 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:05.031] showFragment ContentType.VIDEO :com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:05.031 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.035] updateVideo --->VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.034 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:05.038] showFragment mFragmentManager = null || mFragment = null || fragmentTag empty com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:05.038 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.042] stopPlayer isReset : false mExoPlayer : com.google.android.exoplayer2.SimpleExoPlayer@b0b9b78
04-29 19:56:05.041 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:05.045] getTimeOffsetFromLocalServer :5
04-29 19:56:05.045 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:05.049] showFragment mRegionTimeLineManager currentTimeStamp : 1556547965041 com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:05.050 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:05.054] setContentPlaylist position : 1
04-29 19:56:05.053 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:05.057] setContentPlaylist remove old Timertask reference
04-29 19:56:05.058 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:05.062] setContentPlaylist next position : 2
04-29 19:56:05.061 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:05.065] setContentPlaylist endTimeStamp : 1556547975000 Thread[Timer-10,5,main]
04-29 19:56:05.067 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:05.071] getTimeOffsetFromLocalServer :5
04-29 19:56:05.072 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:05.076] getTimeOffsetFromLocalServer :5
04-29 19:56:05.078 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.082] startPlayer uri from filePath : /storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5779.mp4
04-29 19:56:05.081 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.085] logContentPlayBackModel
04-29 19:56:05.085 15200-15200/panasonic.digital.signage.piqa1 D/basic.framework.ui.CommonBaseActivity: [2019-04-29 19:56:05.089] getContentPlayBackUIModel mContentPlayBackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null}
04-29 19:56:05.089 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:05.093] logContentPlayBackEvent with parameter contentPlayBackUIModel: ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null} contentId: 5779 playBackStatus: YES reasonForFailure: null regionId: 5075
04-29 19:56:05.092 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:05.097] getTimeOffsetFromLocalServer :5
04-29 19:56:05.096 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:05.100] insertOrUpdateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5779widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547965096, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:05.101 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:05.105] insertOrUpdateContentPlayBackDetail performDbTask
04-29 19:56:05.106 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.110] startPlayer displayMode : STRETCH-TO-FIT
04-29 19:56:05.111 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.115] initializeExoPlayer Video
04-29 19:56:05.114 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:05.118] data = ContentPlaybackUIModel{layoutId=3037contentId=5779widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556546457230, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:05.118 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.122] initializeExoPlayer Video same video player is being used mPlayer :com.google.android.exoplayer2.SimpleExoPlayer@b0b9b78
04-29 19:56:05.121 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:05.125] insertOrUpdateContentPlayBackDetail onDbDataReceived contentId :5779layoutID :3037
04-29 19:56:05.124 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.128] playVideoByExoplayer uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5779.mp4
04-29 19:56:05.128 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:05.132] updateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5779widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547965096, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:05.131 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.135] muteUnMuteExoplayer VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment} isMute :true
04-29 19:56:05.134 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:05.138] updateContentPlayBackDetail performDbTask 
04-29 19:56:05.138 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.142] buildMediaSource uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5779.mp4
04-29 19:56:05.141 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:05.145] data = 0
04-29 19:56:05.144 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.148] buildMediaSource TYPE_OTHER
04-29 19:56:05.147 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:05.151] updateContentPlayBackDetail onDbDataReceived success at rowNo :0
04-29 19:56:05.150 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.155] buildDataSourceFactory build DataSourceFactory
04-29 19:56:05.154 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.158] buildDataSourceFactory encryption type: 1
04-29 19:56:05.157 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.161] buildDataSourceFactory returned already created data source factory
04-29 19:56:05.170 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.174] PlayerEventListener onTracksChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.177 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.180] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 2 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.180 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.184] playVideoByExoplayer player is prepared
04-29 19:56:05.184 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.188] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.187 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.192] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.292 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:05.293 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:05.298 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.302] PlayerEventListener onTracksChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.304 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.308] PlayerMediaSourceEventListener onReadingStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.307 15200-19852/panasonic.digital.signage.piqa1 I/OMXClient: Using client-side OMX mux.
04-29 19:56:05.308 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.313] PlayerMediaSourceEventListener onDownstreamFormatChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.316 15200-19851/panasonic.digital.signage.piqa1 I/MediaCodec: [OMX.realtek.video.dec.avc] setting surface generation to 15564851
04-29 19:56:05.322 15200-19852/panasonic.digital.signage.piqa1 I/ACodec: codec does not support config priority (err -1010)
04-29 19:56:05.327 15200-19852/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.video.dec.avc] Allocating 3 buffers of size 3774873/3774873 (from 3774873 using Invalid) on input port
04-29 19:56:05.338 15200-19852/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea54b08 for 32x32, color 0x52, rotation 0, usage 0x2002b00
04-29 19:56:05.370 15200-19852/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 7 totalAllocBufferCount:7 ----
04-29 19:56:05.375 15200-19852/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:05.378 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.382] onDecoderInitialized track type: 2 Decoder name: OMX.realtek.video.dec.avc initializationDurationMs: 75
04-29 19:56:05.380 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.385] onDecoderInitialized VIDEO ID: 5779 RESOLUTION: 3840x2160
04-29 19:56:05.383 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.387] onDecoderInitialized actual VIDEO BITRATE : 12415316
04-29 19:56:05.385 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.DeviceCodecInfoImpl: [2019-04-29 19:56:05.389] getCodecModelMap
04-29 19:56:05.387 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.391] onDecoderInitialized CodecModelKey : OMX.realtek.video.dec.avc
04-29 19:56:05.389 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.393] onDecoderInitialized IMediaCodecModel BITRATE RANGE: null MAX RESOLUTION:4096x2208
04-29 19:56:05.391 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.395] onDecoderInitialized Video is within capabilities of codec to play
04-29 19:56:05.642 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.646] PlayerMediaSourceEventListener onLoadCompleted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.645 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.649] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.646 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:05.651] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:05.695 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:05.696 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:05.871 15200-19852/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea54b08 for 3840x2160, color 0x53, rotation 0, usage 0x2002b00
04-29 19:56:05.894 15200-19852/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 9 totalAllocBufferCount:9 ----
04-29 19:56:05.909 15200-19852/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:06.085 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.090] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 3 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.087 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:06.092] getTimeOffsetFromLocalServer :5
04-29 19:56:06.089 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.093] PlayerEventListener onPlayerStateChanged playbackPosition : 1091 duration : 10443
04-29 19:56:06.091 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.095] PlayerEventListener onPositionDiscontinuity reason : 1 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.094 15200-15200/panasonic.digital.signage.piqa1 E/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.098] PlayerMediaSourceEventListener onLoadCanceled VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.097 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.101] PlayerMediaSourceEventListener onMediaPeriodReleased VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.140 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.145] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 2 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.142 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.146] PlayerEventListener onSeekProcessed VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.143 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.148] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.145 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.150] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:06.192 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:06.193 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:06.384 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:06.389] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 3 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:07.381 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:56:07.386] run on Thread: Timer-1
04-29 19:56:07.383 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:56:07.388] run Device Status Polling
04-29 19:56:07.385 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:07.389] saveDeviceOnLastCheckTime timeStamp: 1556547967384
04-29 19:56:11.136 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:11.140] PlayerMediaSourceEventListener onLoadCompleted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:11.145 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:11.148] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:11.152 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:11.156] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:11.280 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:11.281 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:15.001 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:15.005] getTimeOffsetFromLocalServer :5
04-29 19:56:15.005 15200-15493/panasonic.digital.signage.piqa1 D/RegionContentChangeTimerTask: [2019-04-29 19:56:15.009] run currentTime : 1556547975004
04-29 19:56:15.009 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:15.013] getTimeOffsetFromLocalServer :5
04-29 19:56:15.013 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:15.017] playNextItem position : 2 currentTime :1556547975013 contentType : VIDEO thread : Thread[Timer-10,5,main]
04-29 19:56:15.016 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:15.020] getTimeOffsetFromLocalServer :5
04-29 19:56:15.020 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:15.024] showFragment  position : 2 ContentId : 5778 currentTimestamp : 1556547975019 StartTimeStamp : 1556547975000 isForRefreshView : false isAnimationEnable : true thread : Thread[Timer-10,5,main] com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:15.024 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:15.028] showFragment ContentId new fragment will be created com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:15.028 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:15.032] showFragment ContentType.VIDEO :com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:15.033 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.037] updateVideo --->VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.037 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:15.041] showFragment mFragmentManager = null || mFragment = null || fragmentTag empty com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:15.041 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.045] stopPlayer isReset : false mExoPlayer : com.google.android.exoplayer2.SimpleExoPlayer@b0b9b78
04-29 19:56:15.045 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:15.049] getTimeOffsetFromLocalServer :5
04-29 19:56:15.049 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.052] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 1 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.052 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:15.056] showFragment mRegionTimeLineManager currentTimeStamp : 1556547975045 com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:15.055 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.059] startPlayer uri from filePath : /storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5778.mp4
04-29 19:56:15.059 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:15.063] setContentPlaylist position : 2
04-29 19:56:15.063 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.067] logContentPlayBackModel
04-29 19:56:15.068 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:15.072] setContentPlaylist remove old Timertask reference
04-29 19:56:15.072 15200-15200/panasonic.digital.signage.piqa1 D/basic.framework.ui.CommonBaseActivity: [2019-04-29 19:56:15.076] getContentPlayBackUIModel mContentPlayBackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null}
04-29 19:56:15.075 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:15.079] setContentPlaylist next position : 3
04-29 19:56:15.079 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:15.083] logContentPlayBackEvent with parameter contentPlayBackUIModel: ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null} contentId: 5778 playBackStatus: YES reasonForFailure: null regionId: 5075
04-29 19:56:15.082 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:15.086] setContentPlaylist endTimeStamp : 1556547985000 Thread[Timer-10,5,main]
04-29 19:56:15.085 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:15.089] getTimeOffsetFromLocalServer :5
04-29 19:56:15.090 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:15.094] insertOrUpdateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5778widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547975086, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:15.094 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:15.098] getTimeOffsetFromLocalServer :5
04-29 19:56:15.100 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.102] startPlayer displayMode : STRETCH-TO-FIT
04-29 19:56:15.104 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.108] initializeExoPlayer Video
04-29 19:56:15.108 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.112] initializeExoPlayer Video same video player is being used mPlayer :com.google.android.exoplayer2.SimpleExoPlayer@b0b9b78
04-29 19:56:15.111 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:15.115] insertOrUpdateContentPlayBackDetail performDbTask
04-29 19:56:15.117 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:15.120] getTimeOffsetFromLocalServer :5
04-29 19:56:15.119 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:15.124] data = ContentPlaybackUIModel{layoutId=3037contentId=5778widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556546467039, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:15.122 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.126] playVideoByExoplayer uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5778.mp4
04-29 19:56:15.124 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:15.128] insertOrUpdateContentPlayBackDetail onDbDataReceived contentId :5778layoutID :3037
04-29 19:56:15.126 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.131] muteUnMuteExoplayer VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment} isMute :true
04-29 19:56:15.129 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:15.133] updateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5778widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547975086, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:15.131 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.135] buildMediaSource uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5778.mp4
04-29 19:56:15.134 15200-15411/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:15.138] updateContentPlayBackDetail performDbTask 
04-29 19:56:15.136 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.140] buildMediaSource TYPE_OTHER
04-29 19:56:15.139 15200-15411/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:15.143] data = 0
04-29 19:56:15.142 15200-15411/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:15.146] updateContentPlayBackDetail onDbDataReceived success at rowNo :0
04-29 19:56:15.144 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.148] buildDataSourceFactory build DataSourceFactory
04-29 19:56:15.147 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.151] buildDataSourceFactory encryption type: 1
04-29 19:56:15.157 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.160] buildDataSourceFactory returned already created data source factory
04-29 19:56:15.163 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.167] PlayerEventListener onTracksChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.168 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.172] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 2 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.173 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.177] playVideoByExoplayer player is prepared
04-29 19:56:15.357 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.362] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.360 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.365] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.441 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:15.442 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:15.446 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.450] PlayerEventListener onTracksChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.449 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.454] PlayerMediaSourceEventListener onReadingStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.456 15200-19875/panasonic.digital.signage.piqa1 I/OMXClient: Using client-side OMX mux.
04-29 19:56:15.463 15200-19874/panasonic.digital.signage.piqa1 I/MediaCodec: [OMX.realtek.video.dec.avc] setting surface generation to 15564852
04-29 19:56:15.463 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.468] PlayerMediaSourceEventListener onDownstreamFormatChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:15.471 15200-19875/panasonic.digital.signage.piqa1 I/ACodec: codec does not support config priority (err -1010)
04-29 19:56:15.475 15200-19875/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.video.dec.avc] Allocating 3 buffers of size 3774873/3774873 (from 3774873 using Invalid) on input port
04-29 19:56:15.483 15200-19875/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea54b08 for 32x32, color 0x52, rotation 0, usage 0x2002b00
04-29 19:56:15.522 15200-19875/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 7 totalAllocBufferCount:7 ----
04-29 19:56:15.529 15200-19875/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:15.533 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.538] onDecoderInitialized track type: 2 Decoder name: OMX.realtek.video.dec.avc initializationDurationMs: 86
04-29 19:56:15.537 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.541] onDecoderInitialized VIDEO ID: 5778 RESOLUTION: 3840x2160
04-29 19:56:15.541 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.545] onDecoderInitialized actual VIDEO BITRATE : 42757516
04-29 19:56:15.543 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.DeviceCodecInfoImpl: [2019-04-29 19:56:15.548] getCodecModelMap
04-29 19:56:15.545 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.550] onDecoderInitialized CodecModelKey : OMX.realtek.video.dec.avc
04-29 19:56:15.548 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.552] onDecoderInitialized IMediaCodecModel BITRATE RANGE: null MAX RESOLUTION:4096x2208
04-29 19:56:15.551 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:15.555] onDecoderInitialized Video is within capabilities of codec to play
04-29 19:56:15.619 15200-19875/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea54b08 for 3840x2160, color 0x53, rotation 0, usage 0x2002b00
04-29 19:56:15.684 15200-19875/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 9 totalAllocBufferCount:9 ----
04-29 19:56:15.717 15200-15212/panasonic.digital.signage.piqa1 I/art: Background partial concurrent mark sweep GC freed 15806(1205KB) AllocSpace objects, 394(25MB) LOS objects, 27% free, 41MB/57MB, paused 2.974ms total 102.184ms
04-29 19:56:16.240 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:16.244] PlayerMediaSourceEventListener onLoadCompleted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:16.250 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:16.255] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:16.252 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:16.256] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:16.311 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:16.311 15200-18327/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:16.680 15200-19875/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:16.680 15200-19875/panasonic.digital.signage.piqa1 E/ACodec: Failed to allocate output port buffers after port reconfiguration: (-12)
04-29 19:56:16.681 15200-19875/panasonic.digital.signage.piqa1 E/ACodec: signalError(omxError 0x80001001, internalError -12)
04-29 19:56:16.681 15200-19874/panasonic.digital.signage.piqa1 E/MediaCodec: Codec reported err 0xfffffff4, actionCode 0, while in state 6
04-29 19:56:16.687 15200-18327/panasonic.digital.signage.piqa1 E/ExoPlayerImplInternal: Internal runtime error.
    java.lang.IllegalStateException
        at android.media.MediaCodec.native_dequeueOutputBuffer(Native Method)
        at android.media.MediaCodec.dequeueOutputBuffer(MediaCodec.java:2379)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1273)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:649)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:530)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:303)
        at android.os.Handler.dispatchMessage(Handler.java:98)
        at android.os.Looper.loop(Looper.java:148)
        at android.os.HandlerThread.run(HandlerThread.java:61)
04-29 19:56:16.970 15200-19875/panasonic.digital.signage.piqa1 I/ACodec: ignoring message as already freed component: AMessage(what = 'omxL', target = 235) = {
      int32_t node = 155
      RefBase *messages = 0xdf911a28
    }
04-29 19:56:17.014 15200-18327/panasonic.digital.signage.piqa1 E/ExoPlayerImplInternal: Stop failed.
    java.lang.IllegalStateException
        at android.media.MediaCodec.native_stop(Native Method)
        at android.media.MediaCodec.stop(MediaCodec.java:1901)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.releaseCodec(MediaCodecRenderer.java:594)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.releaseCodec(MediaCodecVideoRenderer.java:508)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onDisabled(MediaCodecRenderer.java:548)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onDisabled(MediaCodecVideoRenderer.java:377)
        at com.google.android.exoplayer2.BaseRenderer.disable(BaseRenderer.java:153)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.disableRenderer(ExoPlayerImplInternal.java:983)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.resetInternal(ExoPlayerImplInternal.java:774)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.stopInternal(ExoPlayerImplInternal.java:734)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:358)
        at android.os.Handler.dispatchMessage(Handler.java:98)
        at android.os.Looper.loop(Looper.java:148)
        at android.os.HandlerThread.run(HandlerThread.java:61)
04-29 19:56:17.018 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:17.022] PlayerMediaSourceEventListener onMediaPeriodReleased VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:17.019 15200-15200/panasonic.digital.signage.piqa1 E/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:17.024] PlayerMediaSourceEventListener onLoadCanceled VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:17.024 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:17.029] PlayerMediaSourceEventListener onMediaPeriodReleased VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:17.026 15200-15200/panasonic.digital.signage.piqa1 E/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:17.030] PlayerEventListener onPlayerError e : com.google.android.exoplayer2.ExoPlaybackException: java.lang.IllegalStateException
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:359)
        at android.os.Handler.dispatchMessage(Handler.java:98)
        at android.os.Looper.loop(Looper.java:148)
        at android.os.HandlerThread.run(HandlerThread.java:61)
     Caused by: java.lang.IllegalStateException
        at android.media.MediaCodec.native_dequeueOutputBuffer(Native Method)
        at android.media.MediaCodec.dequeueOutputBuffer(MediaCodec.java:2379)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1273)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:649)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:530)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:303)
        at android.os.Handler.dispatchMessage(Handler.java:98) 
        at android.os.Looper.loop(Looper.java:148) 
        at android.os.HandlerThread.run(HandlerThread.java:61) 
     VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:17.076 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:17.081] releasePlayer mExoPlayer : com.google.android.exoplayer2.SimpleExoPlayer@b0b9b78
04-29 19:56:25.018 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.022] getTimeOffsetFromLocalServer :5
04-29 19:56:25.021 15200-15493/panasonic.digital.signage.piqa1 D/RegionContentChangeTimerTask: [2019-04-29 19:56:25.025] run currentTime : 1556547985021
04-29 19:56:25.024 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.028] getTimeOffsetFromLocalServer :5
04-29 19:56:25.027 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:25.031] playNextItem position : 3 currentTime :1556547985028 contentType : VIDEO thread : Thread[Timer-10,5,main]
04-29 19:56:25.030 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.034] getTimeOffsetFromLocalServer :5
04-29 19:56:25.033 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:25.037] showFragment  position : 3 ContentId : 5777 currentTimestamp : 1556547985034 StartTimeStamp : 1556547985000 isForRefreshView : false isAnimationEnable : true thread : Thread[Timer-10,5,main] com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:25.037 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:25.040] showFragment ContentId new fragment will be created com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:25.040 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:25.044] showFragment ContentType.VIDEO :com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:25.043 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.047] updateVideo --->VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.046 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:25.050] showFragment mFragmentManager = null || mFragment = null || fragmentTag empty com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:25.049 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.053] stopPlayer isReset : false mExoPlayer : null
04-29 19:56:25.052 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.056] getTimeOffsetFromLocalServer :5
04-29 19:56:25.056 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:25.060] showFragment mRegionTimeLineManager currentTimeStamp : 1556547985053 com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:25.059 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:25.063] setContentPlaylist position : 3
04-29 19:56:25.063 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:25.067] setContentPlaylist remove old Timertask reference
04-29 19:56:25.066 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:25.070] setContentPlaylist next position : 4
04-29 19:56:25.069 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:25.073] setContentPlaylist endTimeStamp : 1556547994000 Thread[Timer-10,5,main]
04-29 19:56:25.073 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.077] startPlayer uri from filePath : /storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5777.mp4
04-29 19:56:25.076 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.080] getTimeOffsetFromLocalServer :5
04-29 19:56:25.080 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.084] logContentPlayBackModel
04-29 19:56:25.084 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.088] getTimeOffsetFromLocalServer :5
04-29 19:56:25.088 15200-15200/panasonic.digital.signage.piqa1 D/basic.framework.ui.CommonBaseActivity: [2019-04-29 19:56:25.092] getContentPlayBackUIModel mContentPlayBackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null}
04-29 19:56:25.091 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:25.096] logContentPlayBackEvent with parameter contentPlayBackUIModel: ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null} contentId: 5777 playBackStatus: YES reasonForFailure: null regionId: 5075
04-29 19:56:25.095 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.099] getTimeOffsetFromLocalServer :5
04-29 19:56:25.100 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:25.104] insertOrUpdateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5777widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547985098, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:25.104 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.108] startPlayer displayMode : STRETCH-TO-FIT
04-29 19:56:25.107 15200-15488/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:25.111] insertOrUpdateContentPlayBackDetail performDbTask
04-29 19:56:25.111 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.115] initializeExoPlayer Video
04-29 19:56:25.114 15200-15488/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:25.118] data = ContentPlaybackUIModel{layoutId=3037contentId=5777widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556546477075, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:25.117 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.exoplayer.ExoPlayerInstanceManagerImpl: [2019-04-29 19:56:25.122] getFreeInstanceOfExoPlayer !userInstances.isEmpty() size is 2
04-29 19:56:25.120 15200-15488/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:25.125] insertOrUpdateContentPlayBackDetail onDbDataReceived contentId :5777layoutID :3037
04-29 19:56:25.123 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.exoplayer.ExoPlayerInstanceManagerImpl: [2019-04-29 19:56:25.127] newInstance
04-29 19:56:25.126 15200-15488/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:25.130] updateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5777widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547985098, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:25.128 15200-15200/panasonic.digital.signage.piqa1 I/ExoPlayerImpl: Init c23a844 [ExoPlayerLib/2.9.0] [kylin32, X5, realtek, 23]
04-29 19:56:25.131 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:25.135] updateContentPlayBackDetail performDbTask 
04-29 19:56:25.135 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.exoplayer.ExoPlayerInstanceManagerImpl: [2019-04-29 19:56:25.139] getFreeInstanceOfExoPlayer player : com.google.android.exoplayer2.SimpleExoPlayer@10b8d2d
04-29 19:56:25.138 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:25.142] data = 0
04-29 19:56:25.141 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.145] initializeExoPlayer Video mPlayer :com.google.android.exoplayer2.SimpleExoPlayer@10b8d2d
04-29 19:56:25.144 15200-15461/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:25.148] updateContentPlayBackDetail onDbDataReceived success at rowNo :0
04-29 19:56:25.148 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.152] playVideoByExoplayer uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5777.mp4
04-29 19:56:25.151 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.155] muteUnMuteExoplayer VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment} isMute :true
04-29 19:56:25.155 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.159] buildMediaSource uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5777.mp4
04-29 19:56:25.159 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.163] buildMediaSource TYPE_OTHER
04-29 19:56:25.161 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.166] buildDataSourceFactory build DataSourceFactory
04-29 19:56:25.164 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.168] buildDataSourceFactory encryption type: 1
04-29 19:56:25.167 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.171] buildDataSourceFactory returned already created data source factory
04-29 19:56:25.172 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.176] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 1 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.182 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.187] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 2 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.187 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.191] playVideoByExoplayer player is prepared
04-29 19:56:25.195 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.199] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.200 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.204] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.298 15200-19892/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:25.299 15200-19892/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:25.303 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.308] PlayerEventListener onTracksChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.308 15200-19895/panasonic.digital.signage.piqa1 I/OMXClient: Using client-side OMX mux.
04-29 19:56:25.310 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.313] PlayerMediaSourceEventListener onReadingStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.316 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.320] PlayerMediaSourceEventListener onDownstreamFormatChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.318 15200-19894/panasonic.digital.signage.piqa1 I/MediaCodec: [OMX.realtek.video.dec.avc] setting surface generation to 15564853
04-29 19:56:25.324 15200-19895/panasonic.digital.signage.piqa1 I/ACodec: codec does not support config priority (err -1010)
04-29 19:56:25.331 15200-19895/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.video.dec.avc] Allocating 3 buffers of size 3774873/3774873 (from 3774873 using Invalid) on input port
04-29 19:56:25.345 15200-19895/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea48108 for 32x32, color 0x52, rotation 0, usage 0x2002b00
04-29 19:56:25.378 15200-19895/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 7 totalAllocBufferCount:7 ----
04-29 19:56:25.383 15200-19895/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:25.387 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.391] onDecoderInitialized track type: 2 Decoder name: OMX.realtek.video.dec.avc initializationDurationMs: 81
04-29 19:56:25.390 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.394] onDecoderInitialized VIDEO ID: 5777 RESOLUTION: 3840x2160
04-29 19:56:25.393 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.397] onDecoderInitialized actual VIDEO BITRATE : 42906611
04-29 19:56:25.395 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.DeviceCodecInfoImpl: [2019-04-29 19:56:25.399] getCodecModelMap
04-29 19:56:25.397 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.401] onDecoderInitialized CodecModelKey : OMX.realtek.video.dec.avc
04-29 19:56:25.400 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.404] onDecoderInitialized IMediaCodecModel BITRATE RANGE: null MAX RESOLUTION:4096x2208
04-29 19:56:25.402 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.407] onDecoderInitialized Video is within capabilities of codec to play
04-29 19:56:25.484 15200-19895/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea48108 for 3840x2160, color 0x53, rotation 0, usage 0x2002b00
04-29 19:56:25.529 15200-19895/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 9 totalAllocBufferCount:9 ----
04-29 19:56:25.555 15200-19895/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:25.796 15200-15212/panasonic.digital.signage.piqa1 I/art: Background partial concurrent mark sweep GC freed 3305(276KB) AllocSpace objects, 1265(86MB) LOS objects, 24% free, 48MB/64MB, paused 2.917ms total 159.253ms
04-29 19:56:25.800 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.804] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 3 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.801 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:25.806] getTimeOffsetFromLocalServer :5
04-29 19:56:25.803 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.807] PlayerEventListener onPlayerStateChanged playbackPosition : 805 duration : 9275
04-29 19:56:25.805 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.810] PlayerEventListener onPositionDiscontinuity reason : 1 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.811 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.815] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 2 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:25.821 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:25.825] PlayerEventListener onSeekProcessed VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:26.217 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:26.221] PlayerMediaSourceEventListener onLoadCompleted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:26.222 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:26.227] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:26.224 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:26.229] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:26.294 15200-19892/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:26.294 15200-19892/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:26.741 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:26.745] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 3 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:29.503 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:29.507] PlayerMediaSourceEventListener onLoadCompleted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:29.517 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:29.519] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:29.528 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:29.532] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:29.693 15200-19892/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:29.694 15200-19892/panasonic.digital.signage.piqa1 D/MediaCodecInfo: NoSupport [sizeAndRate.support, 3840x2160x-1.0] [OMX.realtek.video.dec.avc, video/avc] [kylin32, X5, realtek, 23]
04-29 19:56:34.005 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.009] getTimeOffsetFromLocalServer :5
04-29 19:56:34.010 15200-15493/panasonic.digital.signage.piqa1 D/RegionContentChangeTimerTask: [2019-04-29 19:56:34.013] run currentTime : 1556547994008
04-29 19:56:34.014 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.018] getTimeOffsetFromLocalServer :5
04-29 19:56:34.019 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:34.023] playNextItem position : 4 currentTime :1556547994017 contentType : VIDEO thread : Thread[Timer-10,5,main]
04-29 19:56:34.023 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.027] getTimeOffsetFromLocalServer :5
04-29 19:56:34.027 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:34.031] showFragment  position : 4 ContentId : 5774 currentTimestamp : 1556547994026 StartTimeStamp : 1556547994000 isForRefreshView : false isAnimationEnable : true thread : Thread[Timer-10,5,main] com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:34.032 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:34.035] showFragment ContentId new fragment will be created com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:34.035 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:34.039] showFragment ContentType.VIDEO :com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:34.040 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.044] updateVideo --->VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.043 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:34.047] showFragment mFragmentManager = null || mFragment = null || fragmentTag empty com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:34.047 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.050] stopPlayer isReset : false mExoPlayer : com.google.android.exoplayer2.SimpleExoPlayer@10b8d2d
04-29 19:56:34.052 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.055] getTimeOffsetFromLocalServer :5
04-29 19:56:34.056 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.RegionHolder: [2019-04-29 19:56:34.060] showFragment mRegionTimeLineManager currentTimeStamp : 1556547994050 com.panasonic.android_app.fragments.RegionHolder@ab20d30
04-29 19:56:34.060 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.064] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 1 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.064 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:34.067] setContentPlaylist position : 4
04-29 19:56:34.069 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:34.073] setContentPlaylist remove old Timertask reference
04-29 19:56:34.072 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.076] startPlayer uri from filePath : /storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5774.mp4
04-29 19:56:34.076 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:34.080] setContentPlaylist next position : 5
04-29 19:56:34.080 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.084] logContentPlayBackModel
04-29 19:56:34.085 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.managers.impls.RegionTimeLineManager3Impl: [2019-04-29 19:56:34.089] setContentPlaylist endTimeStamp : 1556548171000 Thread[Timer-10,5,main]
04-29 19:56:34.091 15200-15200/panasonic.digital.signage.piqa1 D/basic.framework.ui.CommonBaseActivity: [2019-04-29 19:56:34.095] getContentPlayBackUIModel mContentPlayBackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null}
04-29 19:56:34.095 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.099] getTimeOffsetFromLocalServer :5
04-29 19:56:34.099 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:34.103] logContentPlayBackEvent with parameter contentPlayBackUIModel: ContentPlaybackUIModel{layoutId=3037contentId=0widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=null, contentLastPlayed=0, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=null} contentId: 5774 playBackStatus: YES reasonForFailure: null regionId: 5075
04-29 19:56:34.103 15200-15493/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.107] getTimeOffsetFromLocalServer :5
04-29 19:56:34.106 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.110] getTimeOffsetFromLocalServer :5
04-29 19:56:34.110 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:34.114] insertOrUpdateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5774widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547994106, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:34.115 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.119] startPlayer displayMode : STRETCH-TO-FIT
04-29 19:56:34.119 15200-15410/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:34.123] insertOrUpdateContentPlayBackDetail performDbTask
04-29 19:56:34.122 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.126] initializeExoPlayer Video
04-29 19:56:34.126 15200-15410/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:34.130] data = ContentPlaybackUIModel{layoutId=3037contentId=5774widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556546486188, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:34.129 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.133] initializeExoPlayer Video same video player is being used mPlayer :com.google.android.exoplayer2.SimpleExoPlayer@10b8d2d
04-29 19:56:34.133 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.137] playVideoByExoplayer uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5774.mp4
04-29 19:56:34.138 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.142] muteUnMuteExoplayer VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment} isMute :true
04-29 19:56:34.142 15200-15410/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:34.146] insertOrUpdateContentPlayBackDetail onDbDataReceived contentId :5774layoutID :3037
04-29 19:56:34.147 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.150] buildMediaSource uri : file:///storage/emulated/0/Android/data/panasonic.digital.signage.piqa1/files/Download/5774.mp4
04-29 19:56:34.151 15200-15410/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:34.155] updateContentPlayBackDetail contentPlaybackUIModel : ContentPlaybackUIModel{layoutId=3037contentId=5774widgetType=null, startTime=1556546017992, endTime=0, playbackStatus=YES, contentLastPlayed=1556547994106, contentEndTime=0, layoutLastPlayedStartTime=0, reasonForFailure=}
04-29 19:56:34.156 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.159] buildMediaSource TYPE_OTHER
04-29 19:56:34.160 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.164] buildDataSourceFactory build DataSourceFactory
04-29 19:56:34.163 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.DbPresenter: [2019-04-29 19:56:34.167] updateContentPlayBackDetail performDbTask 
04-29 19:56:34.166 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.170] buildDataSourceFactory encryption type: 1
04-29 19:56:34.172 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.177] buildDataSourceFactory returned already created data source factory
04-29 19:56:34.175 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.db.utils.AsyncDb: [2019-04-29 19:56:34.179] data = 0
04-29 19:56:34.180 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.184] PlayerEventListener onTracksChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.184 15200-15275/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.ContentPlayBackImpl: [2019-04-29 19:56:34.188] updateContentPlayBackDetail onDbDataReceived success at rowNo :0
04-29 19:56:34.188 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.191] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 2 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.193 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.197] playVideoByExoplayer player is prepared
04-29 19:56:34.355 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.359] PlayerMediaSourceEventListener onMediaPeriodCreated VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.358 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.362] PlayerMediaSourceEventListener onLoadStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.498 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.502] PlayerEventListener onTracksChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.503 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.508] PlayerMediaSourceEventListener onReadingStarted VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.505 15200-19914/panasonic.digital.signage.piqa1 I/OMXClient: Using client-side OMX mux.
04-29 19:56:34.511 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.516] PlayerMediaSourceEventListener onDownstreamFormatChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.513 15200-19913/panasonic.digital.signage.piqa1 I/MediaCodec: [OMX.realtek.video.dec.avc] setting surface generation to 15564854
04-29 19:56:34.519 15200-19914/panasonic.digital.signage.piqa1 I/ACodec: codec does not support config priority (err -1010)
04-29 19:56:34.522 15200-19914/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.video.dec.avc] Allocating 3 buffers of size 3774873/3774873 (from 3774873 using Invalid) on input port
04-29 19:56:34.527 15200-19914/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea48108 for 32x32, color 0x52, rotation 0, usage 0x2002b00
04-29 19:56:34.556 15200-19914/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 7 totalAllocBufferCount:7 ----
04-29 19:56:34.560 15200-19914/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:34.564 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.568] onDecoderInitialized track type: 2 Decoder name: OMX.realtek.video.dec.avc initializationDurationMs: 60
04-29 19:56:34.566 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.570] onDecoderInitialized VIDEO ID: 5774 RESOLUTION: 1920x1080
04-29 19:56:34.569 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.573] onDecoderInitialized actual VIDEO BITRATE : 9974312
04-29 19:56:34.569 15200-19918/panasonic.digital.signage.piqa1 I/OMXClient: Using client-side OMX mux.
04-29 19:56:34.570 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.DeviceCodecInfoImpl: [2019-04-29 19:56:34.575] getCodecModelMap
04-29 19:56:34.572 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.577] onDecoderInitialized CodecModelKey : OMX.realtek.video.dec.avc
04-29 19:56:34.574 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.578] onDecoderInitialized IMediaCodecModel BITRATE RANGE: null MAX RESOLUTION:4096x2208
04-29 19:56:34.577 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.582] onDecoderInitialized Video is within capabilities of codec to play
04-29 19:56:34.580 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.585] PlayerMediaSourceEventListener onDownstreamFormatChanged VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.585 15200-19918/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.audio.dec] Allocating 4 buffers of size 32768/32768 (from 32768 using Invalid) on input port
04-29 19:56:34.589 15200-19918/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.audio.dec] Allocating 4 buffers of size 32768/32768 (from 32768 using Invalid) on output port
04-29 19:56:34.593 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.598] onDecoderInitialized track type: 1 Decoder name: OMX.realtek.audio.dec initializationDurationMs: 26
04-29 19:56:34.595 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.600] onDecoderInitialized trackType != VIDEO
04-29 19:56:34.647 15200-19918/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.audio.dec] Allocating 4 buffers of size 32768/32768 (from 32768 using Invalid) on output port
04-29 19:56:34.661 15200-19914/panasonic.digital.signage.piqa1 D/SurfaceUtils: set up nativeWindow 0xdea48108 for 1920x1080, color 0x55, rotation 0, usage 0x2002b00
04-29 19:56:34.725 15200-19914/panasonic.digital.signage.piqa1 D/ACodec: --- In allocateOutputMetadataBuffers:1427 send back buffer count : 10 totalAllocBufferCount:10 ----
04-29 19:56:34.735 15200-19914/panasonic.digital.signage.piqa1 D/ACodec: In allocateOutputMetadataBuffers:1437 notifyBufferAllocDone index :0x7fff0100 and send notify done 
04-29 19:56:34.868 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.872] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 3 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.870 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:34.874] getTimeOffsetFromLocalServer :5
04-29 19:56:34.872 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.876] PlayerEventListener onPlayerStateChanged playbackPosition : 874 duration : 177177
04-29 19:56:34.881 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.886] PlayerEventListener onPositionDiscontinuity reason : 1 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.899 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.904] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 2 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.909 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:34.913] PlayerEventListener onSeekProcessed VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:34.936 15200-19918/panasonic.digital.signage.piqa1 D/ACodec: [OMX.realtek.audio.dec] Allocating 4 buffers of size 32768/32768 (from 32768 using Invalid) on output port
04-29 19:56:35.143 15200-15212/panasonic.digital.signage.piqa1 I/art: Background partial concurrent mark sweep GC freed 5585(477KB) AllocSpace objects, 1128(74MB) LOS objects, 24% free, 50MB/66MB, paused 2.117ms total 110.657ms
04-29 19:56:35.260 15200-15200/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.fragments.VideoPlayerFragment: [2019-04-29 19:56:35.265] PlayerEventListener onPlayerStateChanged playWhenReady : true playbackState : 3 VideoPlayerFragment{8fd3b65 #0 id=0x13d3 com.panasonic.android_app.fragments.VideoPlayerFragment}
04-29 19:56:37.373 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:56:37.377] run on Thread: Timer-2
04-29 19:56:37.375 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:56:37.380] run Panel Status Polling
04-29 19:56:37.377 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.382] setAllPanelsPolling
04-29 19:56:37.380 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.384] panelHelperRX panelId: null commands: [QPW, QAM]
04-29 19:56:37.382 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:56:37.386] run on Thread: Timer-1
04-29 19:56:37.384 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:56:37.388] run Device Status Polling
04-29 19:56:37.386 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.390] sendCommandsForAllPanels All commands[QPW, QAM] Thread: pool-5-thread-6
04-29 19:56:37.388 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:56:37.393] run Device Status Polling
04-29 19:56:37.391 15200-15459/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:37.395] saveDeviceOnLastCheckTime timeStamp: 1556547997385
04-29 19:56:37.393 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.InMemoryStorageImpl: [2019-04-29 19:56:37.397] getAllPanelsInfo mAllPanels : [{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null}]
04-29 19:56:37.395 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:37.400] saveDeviceOnLastCheckTime timeStamp: 1556547997389
04-29 19:56:37.399 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:37.403] getAllPanels panels :[{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null}]
04-29 19:56:37.401 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.405] sendCommandsForAllPanels priority || non-projector RZ660 cmds send to individual panel
04-29 19:56:37.404 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.408] sendCommandsForIndividualPanel panelId: 2308 commands: [QPW, QAM] Thread: pool-5-thread-6
04-29 19:56:37.407 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.InMemoryStorageImpl: [2019-04-29 19:56:37.411] getPanelInfoOfPanelId panelId : 2308
04-29 19:56:37.410 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:37.414] getPanelInfoOfPanelId panel :{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null}
04-29 19:56:37.413 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.417] addCommandsToQueue panel : {{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null} isPriorityCmds = false pushId = null msgId = null processingStartTimeStamp : -1 timeStamp : 1556547997411 commands = [QPW, QAM]} isPriorityCommands : false
04-29 19:56:37.416 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.420] addCommandsToQueue polling
04-29 19:56:37.420 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.425] addCommandsToQueue sendCmdForExecute
04-29 19:56:37.422 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.427] sendNextCommandForExecution 
04-29 19:56:37.424 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.428] sendNextCommandForExecution processPanelCommand 
04-29 19:56:37.426 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.430] processPanelCommand panelCommandModel: {{panelId = 2308 panelControl = RS232_RM_HDMI_ONLY panelIp = null} isPriorityCmds = false pushId = null msgId = null processingStartTimeStamp : -1 timeStamp : 1556547997411 commands = [QPW, QAM]}
04-29 19:56:37.428 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.433] RS232PanelConnection panelId : 2308 messageId : null pushId : null panelControl : RS232_RM_HDMI_ONLY
04-29 19:56:37.431 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.436] checkForSerialPort DeviceList :1
04-29 19:56:37.433 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.438] checkForSerialPort device.getDeviceName :/dev/bus/usb/005/002
04-29 19:56:37.435 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.440] Entered isVendorSpecificUsbDevice for device :UsbDevice[mName=/dev/bus/usb/005/002,mVendorId=1133,mProductId=50484,mClass=0,mSubclass=0,mProtocol=0,mManufacturerName=Logitech,mProductName=USB Receiver,mVersion=2.0,mSerialNumber=null,mConfigurations=[
    UsbConfiguration[mId=1,mName=RQR29.00_B0015,mAttributes=160,mMaxPower=49,mInterfaces=[
    UsbInterface[mId=0,mAlternateSetting=0,mName=null,mClass=3,mSubclass=1,mProtocol=1,mEndpoints=[
    UsbEndpoint[mAddress=129,mAttributes=3,mMaxPacketSize=8,mInterval=8]]
    UsbInterface[mId=1,mAlternateSetting=0,mName=null,mClass=3,mSubclass=1,mProtocol=2,mEndpoints=[
    UsbEndpoint[mAddress=130,mAttributes=3,mMaxPacketSize=20,mInterval=2]]]]
04-29 19:56:37.438 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.442] isVendorSpecificUsbDevice ManufacturerName : Logitech
04-29 19:56:37.443 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.447] isVendorSpecificUsbDevice ProductName : USB Receiver
04-29 19:56:37.445 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.449] isVendorSpecificUsbDevice SerialNumber : null
04-29 19:56:37.456 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.460] isVendorSpecificUsbDevice DeviceId : 5002
04-29 19:56:37.458 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.462] isVendorSpecificUsbDevice ProductId : 50484
04-29 19:56:37.460 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.464] isVendorSpecificUsbDevice VendorId : 1133
04-29 19:56:37.462 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.467] isVendorSpecificUsbDevice deviceClass As Per Interface
04-29 19:56:37.464 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.469] isVendorSpecificUsbDevice intF ManufacturerName : null
04-29 19:56:37.466 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.471] isVendorSpecificUsbDevice intF ManufacturerName : 0
04-29 19:56:37.468 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.472] isVendorSpecificUsbDevice intF InterfaceClass : 3
04-29 19:56:37.470 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.475] isVendorSpecificUsbDevice intF ManufacturerName : null
04-29 19:56:37.473 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.477] isVendorSpecificUsbDevice intF ManufacturerName : 1
04-29 19:56:37.474 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.479] isVendorSpecificUsbDevice intF InterfaceClass : 3
04-29 19:56:37.476 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.AppUtils: [2019-04-29 19:56:37.481] Exited isVendorSpecificUsbDevice isVendorSpecificDevice :false
04-29 19:56:37.478 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.483] registerListener
04-29 19:56:37.481 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.485] sendCommandsToPanel isPriorityCommands : false commands :[QPW, QAM]
04-29 19:56:37.483 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.488] sendResponseForDisconnectedMode
04-29 19:56:37.485 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.DeviceUtils: [2019-04-29 19:56:37.490] isHDMIConnected HDMI file Path : /sys/devices/virtual/switch/hdmi/state
04-29 19:56:37.882 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.DeviceUtils: [2019-04-29 19:56:37.886] isHDMIConnected switchValue : 1
04-29 19:56:37.883 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.utils.DeviceUtils: [2019-04-29 19:56:37.888] isHDMIConnected finally try
04-29 19:56:37.885 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.889] sendResponse
04-29 19:56:37.887 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.891] sendResponse returning response.
04-29 19:56:37.888 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.893] onGettingPanelStatusModel panelStatusModel panelStatus : {panelControl = RS232_RM_HDMI_ONLY shutterState = -1 isPriorityCmd = false panelStatus = DISCONNECTED_HDMI_CONNECTED isAudioEnable : false}
04-29 19:56:37.890 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.RS232PanelConnection: [2019-04-29 19:56:37.894] unRegisterListener
04-29 19:56:37.893 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.897] removeCommandFromQueue panelId: 2308 isPriorityCommand : false
04-29 19:56:37.894 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.899] removeCommandFromQueue from pollingQueue panelId: 2308
04-29 19:56:37.896 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.900] sendNextCommandForExecution 
04-29 19:56:37.897 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.902] sendNextCommandForExecution no cmd for execution
04-29 19:56:37.899 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:37.904] saveIsPanelAudioOn isPanelAudioOn : false
04-29 19:56:37.901 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:37.906] getTimeOffsetFromLocalServer :5
04-29 19:56:37.903 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.908] writePanelStatusDataToDBAndSendToServer PanelId: 2308 isResponseFromPanelPolling: true
04-29 19:56:37.905 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:56:37.909] getPanelStatusReportingStartTime :-1
04-29 19:56:37.907 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.911] writePanelStatusDataToDBAndSendToServer panelStatusReportingStartTime: -1
04-29 19:56:37.909 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.913] writePanelStatusDataToDBAndSendToServer no need to send panel info to server 
04-29 19:56:37.915 15200-15494/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.panelCommunication.PanelHelper: [2019-04-29 19:56:37.920] panelHelperRX onSuccess
04-29 19:57:07.383 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:57:07.387] run on Thread: Timer-1
04-29 19:57:07.386 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.timers.PollingTimerTask: [2019-04-29 19:57:07.390] run Device Status Polling
04-29 19:57:07.390 15200-15458/panasonic.digital.signage.piqa1 D/com.panasonic.android_app.localstorage.StorageImpl: [2019-04-29 19:57:07.394] saveDeviceOnLastCheckTime timeStamp: 1556548027388
```"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5676,"This the log：
```
2019-03-25 16:59:56.709 1559-1693/? I/ActivityManager: Displayed com.zhangmen.kids.apad/.guidein.ui.activity.GuidanceActivity: +777ms
2019-03-25 16:59:56.712 681-681/? I/OMX-VDEC-1080P: component_init: OMX.qcom.video.decoder.avc : fd=19
2019-03-25 16:59:56.718 681-681/? I/OMX-VDEC-1080P: omx_vdec::component_init() success : fd=19
2019-03-25 16:59:56.718 14054-14169/com.zhangmen.kids.apad I/ACodec: In onAllocateComponent create compenent, codec name: OMX.qcom.video.decoder.avc
2019-03-25 16:59:56.721 14054-14168/com.zhangmen.kids.apad I/MediaCodec: [OMX.qcom.video.decoder.avc] setting surface generation to 14391297
2019-03-25 16:59:56.722 681-2275/? E/OMX-VDEC-1080P: Extension: OMX.google.android.index.storeANWBufferInMetadata not implemented
2019-03-25 16:59:56.722 14054-14169/com.zhangmen.kids.apad I/HwExtendedCodec: mime is [video/avc] at setVideoFormat
2019-03-25 16:59:56.726 681-2275/? E/OMX-VDEC-1080P: Extension: OMX.google.android.index.storeANWBufferInMetadata not implemented
2019-03-25 16:59:56.726 681-2275/? E/OMX-VDEC-1080P: Extension: OMX.google.android.index.configureVideoTunnelMode not implemented
2019-03-25 16:59:56.726 681-2275/? E/OMX-VDEC-1080P: Extension: OMX.google.android.index.useAndroidNativeBuffer is supported
2019-03-25 16:59:56.727 681-2277/? E/OMX-VDEC-1080P: Extension: OMX.google.android.index.describeHDRStaticInfo not implemented
2019-03-25 16:59:56.729 681-2277/? E/OMX-VDEC-1080P: Does not handle dataspace request
2019-03-25 16:59:56.729 681-2277/? E/OMXNodeInstance: getConfig(2a902f4:qcom.decoder.avc, ??(0x7f000062)) ERROR: UnsupportedSetting(0x80001019)
2019-03-25 16:59:56.730 1559-19538/? W/System.err: java.lang.SecurityException: uid 10190 does not have android.permission.UPDATE_DEVICE_STATS.
2019-03-25 16:59:56.730 1559-19538/? W/System.err:     at android.app.ContextImpl.enforce(ContextImpl.java:1760)
2019-03-25 16:59:56.730 1559-19538/? W/System.err:     at android.app.ContextImpl.enforcePermission(ContextImpl.java:1773)
2019-03-25 16:59:56.730 1559-19538/? W/System.err:     at com.android.server.am.BatteryStatsService.enforceCallingPermission(BatteryStatsService.java:1204)
2019-03-25 16:59:56.730 1559-19538/? W/System.err:     at com.android.server.am.BatteryStatsService.noteStartVideo(BatteryStatsService.java:760)
2019-03-25 16:59:56.730 1559-19538/? W/System.err:     at com.android.internal.app.IBatteryStats$Stub.onTransact(IBatteryStats.java:72)
2019-03-25 16:59:56.731 1559-19538/? W/System.err:     at android.os.Binder.execTransact(Binder.java:565)
2019-03-25 16:59:56.740 681-2275/? E/OMX-VDEC-1080P: Extension: OMX.img.index.scalingdown not implemented
2019-03-25 16:59:56.752 681-31517/? I/MediaPlayerService: MediaPlayerService::getOMX
2019-03-25 16:59:56.752 681-14184/? E/OMX-VDEC-1080P: OMX_COMPONENT_GENERATE_HARDWARE_ERROR
2019-03-25 16:59:56.752 681-14184/? E/OMX-VDEC-1080P: ERROR: Sending OMX_ErrorHardware to Client
2019-03-25 16:59:56.753 14054-14186/com.zhangmen.kids.apad I/OMXClient: MuxOMX ctor
2019-03-25 16:59:56.754 14054-14169/com.zhangmen.kids.apad E/ACodec: [OMX.qcom.video.decoder.avc] ERROR(0x80001009)
2019-03-25 16:59:56.754 14054-14169/com.zhangmen.kids.apad E/ACodec: signalError(omxError 0x80001009, internalError -2147483648)
2019-03-25 16:59:56.755 14054-14168/com.zhangmen.kids.apad E/MediaCodec: Codec reported err 0x80001009, actionCode 0, while in state 6
2019-03-25 16:59:56.756 681-14183/? E/OMX-VDEC-1080P: Dropping message 11 since client expected to be in error state
2019-03-25 16:59:56.756 1559-9365/? W/System.err: java.lang.SecurityException: uid 10190 does not have android.permission.UPDATE_DEVICE_STATS.
2019-03-25 16:59:56.756 1559-9365/? W/System.err:     at android.app.ContextImpl.enforce(ContextImpl.java:1760)
2019-03-25 16:59:56.756 1559-9365/? W/System.err:     at android.app.ContextImpl.enforcePermission(ContextImpl.java:1773)
2019-03-25 16:59:56.757 1559-9365/? W/System.err:     at com.android.server.am.BatteryStatsService.enforceCallingPermission(BatteryStatsService.java:1204)
2019-03-25 16:59:56.757 1559-9365/? W/System.err:     at com.android.server.am.BatteryStatsService.noteStopVideo(BatteryStatsService.java:771)
2019-03-25 16:59:56.757 1559-9365/? W/System.err:     at com.android.internal.app.IBatteryStats$Stub.onTransact(IBatteryStats.java:81)
2019-03-25 16:59:56.757 1559-9365/? W/System.err:     at android.os.Binder.execTransact(Binder.java:565)
2019-03-25 16:59:56.758 14054-14186/com.zhangmen.kids.apad I/OMXMaster: makeComponentInstance(OMX.google.aac.decoder) in ngmen.kids.apad process
2019-03-25 16:59:56.767 14054-14186/com.zhangmen.kids.apad I/ACodec: In onAllocateComponent create compenent, codec name: OMX.google.aac.decoder
2019-03-25 16:59:56.768 14054-14186/com.zhangmen.kids.apad E/OMXNodeInstance: setConfig(36e60001:google.aac.decoder, ConfigPriority(0x6f800002)) ERROR: Undefined(0x80001001)
2019-03-25 16:59:56.768 14054-14186/com.zhangmen.kids.apad I/ACodec: codec does not support config priority (err -2147483648)
2019-03-25 16:59:56.768 14054-14186/com.zhangmen.kids.apad E/OMXNodeInstance: setConfig(36e60001:google.aac.decoder, ConfigOperatingRate(0x6f800003)) ERROR: Undefined(0x80001001)
2019-03-25 16:59:56.768 14054-14186/com.zhangmen.kids.apad I/ACodec: codec does not support config operating rate (err -2147483648)
2019-03-25 16:59:56.768 14054-14187/com.zhangmen.kids.apad W/SimpleSoftOMXComponent: checkTransitions port is not populate
2019-03-25 16:59:56.768 14054-14186/com.zhangmen.kids.apad W/SimpleSoftOMXComponent: checkTransitions port is not populate
2019-03-25 16:59:56.770 14054-14187/com.zhangmen.kids.apad I/SoftAAC2: Reconfiguring decoder: 0->48000 Hz, 0->1 channels
2019-03-25 16:59:56.772 14054-14165/com.zhangmen.kids.apad E/ExoPlayerImplInternal: Internal runtime error.
    java.lang.IllegalStateException
        at android.media.MediaCodec.native_dequeueOutputBuffer(Native Method)
        at android.media.MediaCodec.dequeueOutputBuffer(MediaCodec.java:2595)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1287)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:663)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:529)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:300)
        at android.os.Handler.dispatchMessage(Handler.java:101)
        at android.os.Looper.loop(Looper.java:156)
        at android.os.HandlerThread.run(HandlerThread.java:61)
2019-03-25 16:59:56.776 14054-14169/com.zhangmen.kids.apad E/Surface: getSlotFromBufferLocked: unknown buffer: 0xc50a10c0
2019-03-25 16:59:56.776 14054-14169/com.zhangmen.kids.apad W/ACodec: [OMX.qcom.video.decoder.avc] can not return buffer 14 to native window
2019-03-25 16:59:56.777 14054-14169/com.zhangmen.kids.apad E/Surface: getSlotFromBufferLocked: unknown buffer: 0xc50a1180
2019-03-25 16:59:56.777 14054-14169/com.zhangmen.kids.apad W/ACodec: [OMX.qcom.video.decoder.avc] can not return buffer 13 to native window
2019-03-25 16:59:56.777 14054-14169/com.zhangmen.kids.apad E/Surface: getSlotFromBufferLocked: unknown buffer: 0xc50a11e0
2019-03-25 16:59:56.777 14054-14169/com.zhangmen.kids.apad W/ACodec: [OMX.qcom.video.decoder.avc] can not return buffer 12 to native window
2019-03-25 16:59:56.777 14054-14108/com.zhangmen.kids.apad I/CrashReport: rom:HuaWei/EMOTION/EmotionUI_5.1.3
2019-03-25 16:59:56.778 14054-14169/com.zhangmen.kids.apad E/Surface: getSlotFromBufferLocked: unknown buffer: 0xc50a12a0
2019-03-25 16:59:56.778 14054-14169/com.zhangmen.kids.apad W/ACodec: [OMX.qcom.video.decoder.avc] can not return buffer 11 to native window
2019-03-25 16:59:56.781 681-2275/? I/OMX-VDEC-1080P: omx_vdec::component_deinit() complete
2019-03-25 16:59:56.784 681-2275/? I/OMX-VDEC-1080P: Exit OMX vdec Destructor: fd=19
2019-03-25 16:59:56.784 681-2275/? I/OMX-VDEC-1080P: Video slvp perflock released
2019-03-25 16:59:56.787 14054-14165/com.zhangmen.kids.apad E/ExoPlayerImplInternal: Stop failed.
    java.lang.IllegalStateException
        at android.media.MediaCodec.native_stop(Native Method)
        at android.media.MediaCodec.stop(MediaCodec.java:2032)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.releaseCodec(MediaCodecRenderer.java:608)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.releaseCodec(MediaCodecVideoRenderer.java:508)
        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onDisabled(MediaCodecRenderer.java:562)
        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onDisabled(MediaCodecVideoRenderer.java:377)
        at com.google.android.exoplayer2.BaseRenderer.disable(BaseRenderer.java:153)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.disableRenderer(ExoPlayerImplInternal.java:976)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.resetInternal(ExoPlayerImplInternal.java:764)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.stopInternal(ExoPlayerImplInternal.java:735)
        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:355)
        at android.os.Handler.dispatchMessage(Handler.java:101)
        at android.os.Looper.loop(Looper.java:156)
        at android.os.HandlerThread.run(HandlerThread.java:61)
```
Help me plase.","Can you please provide the information request by the issue template? We can't help you without the information asked for in the issue template.

You can find the issue template here: https://github.com/google/ExoPlayer/blob/release-v2/.github/ISSUE_TEMPLATE/content_not_playing.md","[REQUIRED] Content description
Play sound, but no video.

[REQUIRED] Link to test content
Send email to dev.exoplayer@gmail.com.

[REQUIRED] Version of ExoPlayer being used
Version is 2.9.6.

[REQUIRED] Device(s) and version(s) of Android being used
Huawei M3青春版. android version 7.0.
 
thank you."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5671,"hello,

I am building application for IPTV and I was able to add subtitles to my tracks, and it is working with no problem on tv box, the problem only happen when I run the application on mag box, it start to show the name of subtitle as Und

can anyone please advice on this problem ?","Can you please provide us with a bit more of information of what you actually did? 

The issue template which has been removed does outline what information we need to be able to help you. The issue template can be found here: https://github.com/google/ExoPlayer/blob/release-v2/.github/ISSUE_TEMPLATE/bug.md

Please describe what you did and how it can be reproduced with the content links you provide. Specifically if this happens on a given device only we need a bug report from that device which has been taken right after the problem occured.","This is my method

```
private MediaSource buildMediaSourceWithSubtitle(Uri uri, @Nullable String overrideExtension, ArrayList<Subtitle> subtitles) {
ArrayList<MediaSource> allSources = new ArrayList<>();

    // add list of subtitles if found
    if (subtitles != null && subtitles.size() > 0) {
        for (int i = 0; i < subtitles.size(); i++) {
            Format textFormat = Format.createTextSampleFormat(null, MimeTypes.APPLICATION_SUBRIP, C.SELECTION_FLAG_FORCED, subtitles.get(i).getName());
            allSources.add(new SingleSampleMediaSource(subtitles.get(i).getUri(), dataSourceFactory, textFormat, C.TIME_UNSET));
        }
    }

    MediaSource mediaSource = null;
    MediaSource[] allSourcesArray = null;

    @ContentType int type = Util.inferContentType(uri, overrideExtension);
    switch (type) {
        case C.TYPE_DASH:
            mediaSource = new DashMediaSource.Factory(dataSourceFactory)
                    .setManifestParser(
                            new FilteringManifestParser<>(new DashManifestParser(), getOfflineStreamKeys(uri)))
                    .createMediaSource(uri);
            allSources.add(0, mediaSource);
            allSourcesArray = allSources.toArray(new MediaSource[allSources.size()]);

            return new MergingMediaSource(allSourcesArray);
        case C.TYPE_SS:
            mediaSource = new SsMediaSource.Factory(dataSourceFactory)
                    .setManifestParser(
                            new FilteringManifestParser<>(new SsManifestParser(), getOfflineStreamKeys(uri)))
                    .createMediaSource(uri);
            allSources.add(0, mediaSource);
            allSourcesArray = allSources.toArray(new MediaSource[allSources.size()]);

            return new MergingMediaSource(allSourcesArray);
        case C.TYPE_HLS:
            mediaSource = new HlsMediaSource.Factory(dataSourceFactory)
                    .setPlaylistParserFactory(
                            new DefaultHlsPlaylistParserFactory(getOfflineStreamKeys(uri)))
                    .createMediaSource(uri);
            allSources.add(0, mediaSource);
            allSourcesArray = allSources.toArray(new MediaSource[allSources.size()]);

            return new MergingMediaSource(allSourcesArray);
        case C.TYPE_OTHER:
            mediaSource = new ExtractorMediaSource.Factory(dataSourceFactory).createMediaSource(uri);
            allSources.add(0, mediaSource);
            allSourcesArray = allSources.toArray(new MediaSource[allSources.size()]);

            return new MergingMediaSource(allSourcesArray);
        default: {
            throw new IllegalStateException(""Unsupported type: "" + type);
        }
    }
}
```

you can see that I set the subtitle name here ""subtitles.get(i).getName()"" , it works pefect but on this device ""MAG260"" the subtitle name appear as ""Und""

can you please help ?"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5658,"Hi , 
this stream is working fine .
 **Radio Company Italyamo**
https://ice03.fluidstream.net/companyitalia.mp3
when you start it ,it plays the audio ads from the station and then stops
when you tap again it starts playing fine.
why the stream won't play after the ads.
Regards","Do you control the content? If so, it may be worth removing it, as I don't think this stream is intended to be seekable at all.","Thanks so much for taking time to explain and fix the issue
Best regards"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5564,"exoplaer version  2.9.3

android 5.1.1

````
02-25 14:46:57.266 3101-5096/? E/art: Throwing OutOfMemoryError ""Failed to allocate a 28 byte allocation with 0 free bytes and 3GB until OOM"" (recursive case)
02-25 14:46:57.266 3101-5143/? I/art: WaitForGcToComplete blocked for 106.160ms for cause Alloc
02-25 14:46:57.267 3101-5096/? E/art: ""ExoPlayerImplInternal:Handler"" prio=5 tid=48 Runnable
02-25 14:46:57.267 3101-5096/? E/art:   | group=""main"" sCount=0 dsCount=0 obj=0x13084f90 self=0xb9338240
02-25 14:46:57.267 3101-5096/? E/art:   | sysTid=5096 nice=-16 cgrp=default sched=0/0 handle=0xb94d8c68
02-25 14:46:57.267 3101-5096/? E/art:   | state=R schedstat=( 223438971 588924 108 ) utm=21 stm=1 core=3 HZ=100
02-25 14:46:57.267 3101-5096/? E/art:   | stack=0x9b430000-0x9b432000 stackSize=1036KB
02-25 14:46:57.267 3101-5096/? E/art:   | held mutexes= ""mutator lock""(shared held)
02-25 14:46:57.267 3101-5096/? E/art:     at android.util.Pair.create(Pair.java:75)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.source.AbstractConcatenatedTimeline.getConcatenatedUid(AbstractConcatenatedTimeline.java:60)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.source.AbstractConcatenatedTimeline.getPeriod(AbstractConcatenatedTimeline.java:223)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.MediaPeriodQueue.getFollowingMediaPeriodInfo(MediaPeriodQueue.java:552)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.MediaPeriodQueue.getNextMediaPeriodInfo(MediaPeriodQueue.java:126)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.ExoPlayerImplInternal.maybeUpdateLoadingPeriod(ExoPlayerImplInternal.java:1525)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.ExoPlayerImplInternal.updatePeriods(ExoPlayerImplInternal.java:1399)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:513)
02-25 14:46:57.267 3101-5096/? E/art:     at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:303)
02-25 14:46:57.267 3101-5096/? E/art:     at android.os.Handler.dispatchMessage(Handler.java:98)
02-25 14:46:57.267 3101-5096/? E/art:     at android.os.Looper.loop(Looper.java:135)
02-25 14:46:57.267 3101-5096/? E/art:     at android.os.HandlerThread.run(HandlerThread.java:61)
`````
My native language is Chinese, please forgive me if my English is not good
I suspect it's a matter of switching mediasource frequently. I wonder if I can switch frequently
````
   /**
     * 切换mediaSource
     */
    public void next(int nextWindowIndex) {
        if (mInternalPlayer == null) {
            return;
        }
        Timeline timeline = mInternalPlayer.getCurrentTimeline();
        if (timeline.isEmpty()) {
            return;
        }
        int windowIndex = mInternalPlayer.getCurrentWindowIndex();
        if (nextWindowIndex != C.INDEX_UNSET) {
            mInternalPlayer.seekTo(nextWindowIndex, C.TIME_UNSET);
        } else if (timeline.getWindow(windowIndex, window, false).isDynamic) {
            mInternalPlayer.seekTo(windowIndex, C.TIME_UNSET);
        }
    }
````
",Can you provide steps to reproduce the issue in the demo app? If it requires some minor changes in the code you may point me to a github fork for me to look at.,"I'm really sorry that I can't demo this problem again, it just happened by accident"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5547,"
### Issue description
In our particular device which has media tunneling support, ExoPlayer is unable to list and select the tunneling decoder properly. For example, the device advertises these two components supporting avc, one without and one with tunneling support:

omx.oem.avc.decoder
and
omx.oem.avc.decoder.tunneled

ExoPlayer isn't able to select the tunneled version of the decoder but can only detect the non-tunneled version.

We believe there are two issues with the current selection logic in ExoPlayer:

1) ExoPlayer lists by default the codecs using the 'REGULAR_CODECS' filter and tunneled decoders have to be queried with 'ALL_CODECS' filter. See this in ""frameworks/base/media/java/android/media/MediaCodecList.java""

/**
     * Use in {@link #MediaCodecList} to enumerate all codecs, even ones that are
     * not suitable for regular (buffer-to-buffer) decoding or encoding.  These
     * include codecs, for example, that only work with special input or output
     * surfaces, such as secure-only or tunneled-only codecs.
     * /
    public static final int ALL_CODECS = 1;

2) When more than one decoder supporting the given mime-type is returned in the media codec list, ExoPlayer needs to iterate through the list and pick the one with the tunneling feature enabled. In our devices, the non-tunneled version decoder will be listed first so additional logic needs to be added to pick the tunneled version.

I guess another problem with the existing implementation is that there doesn't seem to be a way to tell ExoPlayer that the app prefers a tunneling decoder if the platform supports it. Having this ability would make it easier for ExoPlayer to adjust the codec selection logic as suggested above.

### Reproduction steps
Play any stream with demo app on ExoPlayer v2.9.x 

### Link to test content
Any content, including the sample streams in the demo app

## Version of ExoPlayer being used
ExoPlayer v2.9.x

### Device(s) and version(s) of Android being used
Android-P on broadcom reference designs

### A full bug report captured from the device
N/A  ?
",Could you elaborate a bit on what is needed? Thanks.,"Thanks for the quick response.

>> if you set a tunneling audio session id on the track selector we should prefer using a tunneling decoder

Yes, you're right. I should rephrase that, the statement was referring to point 1). Currently ExoPlayer decides to list the platform codecs with 'REGULAR_CODECS' or 'ALL_CODECS' filter depending on whether the app needs a secure decoder or not. 

In file: library/core/src/main/java/com/google/android/exoplayer2/mediacodec/MediaCodecUtil.java
codecKind = includeSecure ? MediaCodecList.ALL_CODECS : MediaCodecList.REGULAR_CODECS;

I guess if the utility class knew whether the app preferred a tunneled decoder it could select the right filter.

Anyway, I figure these are implementation details so you guys should know better how to address it. Looking forward to try out your changes when they're ready.

Thanks,
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5520,"### Issue description
When trying to switch an ExoPlayer instance between a Dash and an MP4 stream (or MP4 to Dash) while trying to resume at the same playback position an IndexOutOfBoundsException occurs.

Specifically, calling prepare with resetPosition set to false while changing MediaSource types will cause the exception.
`player.prepare(mediaSource, false, true);`

### Reproduction steps
1. Load and begin playing an MP4 stream.
2. Try and load a Dash stream, keeping playback position (`player.prepare(mediaSource, false, true);`).
3. Application crash.

### Link to test content
[SampleExoPlayerVideoSwitchCrash.zip](https://github.com/google/ExoPlayer/files/2868976/SampleExoPlayerVideoSwitchCrash.zip)

To reproduce the steps in the sample app:
1. Build and launch the app.
2. Tap on either the ""Play MP4"" or ""Play Dash"" buttons.
3. Once the video starts playing, tap on the other button,
4. The application will crash.

Replacing the currently playing MP4 with a new MP4 stream (pressing the ""Play MP4"" button a second time) switches playback as expected, likewise loading a new Dash stream while a current Dash stream is playing also switches correctly. 

### Version of ExoPlayer being used
2.9.5

### Device(s) and version(s) of Android being used
Google Pixel 3 XL","Can you describe your use case in more detail to understand why you want to keep a position of an apparently unrelated piece of media? 

I guess we could support such a case by converting the current position to an initial seek if needed, but that depends on whether we think that we should support the `player.prepare(mediaSource, false, true)` option at all.","Our case that triggered this issue is:

We have multiple video streams that can represent what we'd consider to be the same content across different languages and qualities. We recently started rolling out adaptive videos for some of our content, and so we have some cases where our users can watch and switch between videos that are available across two languages; where one language might be available in a progressive only format (MP4 - 1080p, 720p, etc.) and the other language may be available in an adaptive format like Dash to handle auto quality switching.

As the user is switching between different instances of the same content, we wanted to resume playback at the same position in the video.

Otherwise it looks like we can do something like this:
`…`
`long currentPosition = player.getCurrentPosition();`
`player.prepare(mediaSource, true, true);`
`player.seekTo(currentPosition);`
`…`


It was only something we started to see reports of after updating from 2.7.3 to 2.9.4+ (we were previously releasing the previous MediaSource and setting the seek to position before calling prepare with the new MediaSource without issue)."
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5502,"from the error stack:

```
.videoplayer.player.PlayErrorException:play https://qiniu.yunjilink.com/7sVsQSyLqgl8tJY8qgJBa_DKh44=/lpKV7HFasjjp4ZMUhWkiT1LO7f9X error,
......
--
Caused by:
java.lang.IllegalStateException:
android.media.MediaCodec.releaseOutputBuffer(Native Method)
android.media.MediaCodec.releaseOutputBuffer(MediaCodec.java:2752)
com.google.android.exoplayer2.audio.MediaCodecAudioRenderer.processOutputBuffer(MediaCodecAudioRenderer.java:641)
com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.drainOutputBuffer(MediaCodecRenderer.java:1355)
```
The audio https://qiniu.yunjilink.com/7sVsQSyLqgl8tJY8qgJBa_DKh44=/lpKV7HFasjjp4ZMUhWkiT1LO7f9X can be played at any position but not at 22 secs. 

Btw, **the issue can only reproduced in one device** in my hand,
![image](https://user-images.githubusercontent.com/2981114/52692776-d3216f00-2f9f-11e9-9b98-17b80cbf5bc1.png)

","Can you take a bug report right after the error occurred? 

You can do in the console with a

```
adb bugreport
```

Here is some detailed information on how you can capture a bug report: https://developer.android.com/studio/debug/bug-report
",
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5397,"Hello,

### Issue description
Weird simultaneous play/pause state In tunnelled mode after preparing the player. 
Using the same code in non tunnelled mode works correctly.

### Reproduction steps
As always, when I want to play a media I use these classic exoplayer methods:
```
playWhenReady(true)
prepare(mediaSource)
```
(works correctly in tunnelling)

And when I want to just prepare and not start playing, Instead of the previous code I usually just do :
```
prepare(mediaSource)
```
(ExoPlayerImpl's playWhenReady default value is ""false"" I don't need to set it)

* In non tunnelled mode: the behaviour is correct: my media is loaded and is in a paused state.
* In tunnelled mode: my media is loaded, but is in a weird state: the player looks like it is in between paused and playing: it plays a few frames then pauses and keeps going on repeating this weird play/pause (approximately 1second cycles).
Also happens if I seekTo(mPosition) before or just after prepare(mediaSource)

According to logs, all values are the same in tunnelled and non-tunnelled, however I don't have the same behaviours. (The debugger shows the same information: playWhenReady:false, playbackState:ready)

Even if I try to use any of the methods of the EventListener I can't do anything because the onPlayerStateChanged gives me the same result then when I am paused in non-tunelled mode.

Also, I noticed after the bug if I press play, it plays correctly, then I wait a few seconds and manually pause, my player will be correctly paused. it only happens when I prepare the media and not setPlayWhenReady(true)

Do you have any idea what is causing this?
Thanks.

### Version of ExoPlayer being used
2.9.3

### Device(s) and version(s) of Android being used
Custom Sagemcom STB
Android 7.1.1","Can you reproduce this on any other devices that support video tunneling? If not, it's likely to be a device-specific bug and should be reported to the manufacturer of the ""Custom Sagemcom STB"" you're using.","@andrewlewis 
I just reproduced it on another device.
Device: AMINO Amigo7 
Android: 8.0.0
Detailed Specs: https://www.aminocom.com/products/amino-vu/client-devices/amigo-7x

Also, I was able to reproduce the bug on exoplayer2.demo from the release-v2 branch, using the default sources (for example all Youtube DASH)

Here is how to reproduce it:

com.google.android.exoplayer2.demo.PlayerActivity

- Enable tunneling
line 202
```
-      trackSelectorParameters = new DefaultTrackSelector.ParametersBuilder().build();
+      trackSelectorParameters = new DefaultTrackSelector
+              .ParametersBuilder()
+              .setTunnelingAudioSessionId(C.generateAudioSessionIdV21(getApplicationContext()))
+              .build();
```

- Cancel playWhenReady
line 435
```
-      player.setPlayWhenReady(startAutoPlay);
+    //  player.setPlayWhenReady(startAutoPlay);
```
"
google/ExoPlayer,https://github.com/google/ExoPlayer/issues/5290,"Hello I am using exoplayer 2.7.2 and currently facing some issues in android box AlfawiseA8   oreo 8.1
Screen coming blue layer on playing but its gone while the control view is open. I cant figure out the issue can anyone help? I am using default exoplayer demoapp code. 
https://tinypng.com/web/output/mtacqwc0j33p5abzjtjxgekyvg6jh6h6/bluescreen.jpg","Do you mean video appears normal when the control view is visible? 
Does the problem occurs on all streams? If not please specify the stream name.
Also please provide a bug report:
### A full bug report captured from the device
Capture a full bug report using ""adb bugreport"". Output from ""adb logcat"" or a
log snippet is NOT sufficient. Please attach the captured bug report as a file.
If you don't wish to post it publicly, please submit the issue, then email the
bug report to dev.exoplayer@gmail.com using a subject in the format
""Issue #1234"".",Its happening to every streams on that device. Sample video: https://www.youtube.com/watch?v=lsYJD0CLx-w   but other app having no issues.
springfox/springfox,https://github.com/springfox/springfox/issues/3075,"SpringDataRest Pageable resuorce page and size parameter is generated with String type

Maybe the following snipet in springfox.documentation.spring.data.rest.SpecificationBuilder generates:

```java
case PAGEABLE_RESOURCE:
          RepositoryRestConfiguration configuration = context.getConfiguration();
          TypeResolver typeResolver = context.getTypeResolver();

          //noinspection unchecked
          withParameter(new ResolvedMethodParameter(
              0,
              configuration.getPageParamName(),
              Collections.EMPTY_LIST,
              typeResolver.resolve(String.class)));
          //noinspection unchecked
          withParameter(new ResolvedMethodParameter(
              1,
              configuration.getLimitParamName(),
              Collections.EMPTY_LIST,
              typeResolver.resolve(String.class)));
          //noinspection unchecked
          withParameter(new ResolvedMethodParameter(
              2,
              configuration.getSortParamName(),
              Collections.EMPTY_LIST,
              typeResolver.resolve(String.class)));
```
",Would you be up to submitting a PR to fix?,PR: #3076 
springfox/springfox,https://github.com/springfox/springfox/issues/2622,"Hi

When use X-Forwarded-Prefix (Over a zuul/cloud-gateway proxy) and ForwardedHeaderFilter, what remove the header an put on context path of ServletRequest the json the base path is not updated, the path provider extension is use only on startup, not runtime 

Can I do same workaround to solve this problem? or send a PR with a new feature?
","Could you please explain your problem with an example urls, headers etc?",
springfox/springfox,https://github.com/springfox/springfox/issues/2322,"I have an api gateway built with Spring Cloud Gateway (Finchley.M9) and when I try to hit the api to get the JSON for the documentation, swagger cant parse the ""forwarded"" header when the node ""host"" and ""for"" are double quoted because of the port number being added. I spoke with the developer of Spring Cloud Gateway 

<blockquote class=""twitter-tweet"" data-lang=""en""><p lang=""en"" dir=""ltr""><a href=""https://twitter.com/spencerbgibb?ref_src=twsrc%5Etfw"">@spencerbgibb</a> hey Spencer, ForwardedHeadersFilter is including extra quotes in some of the fields. Is this according to the specs? It breaks on my downstream system. Thank you <a href=""https://t.co/Q0TO6aNE5L"">pic.twitter.com/Q0TO6aNE5L</a></p>&mdash; Thiago Locatelli (@thiagolocatelli) <a href=""https://twitter.com/thiagolocatelli/status/977238493297602561?ref_src=twsrc%5Etfw"">March 23, 2018</a></blockquote> 

 and he mentioned that according to the specs, when there is a colon, it needs to be double quoted.


Header: forward
Value: proto=http; host=""127.0.0.1:8081""; for=""127.0.0.1:50518""

Headers being sent to the docs api: 
![headers](https://pbs.twimg.com/media/DY_ZD6DV4AEK_tA.jpg)

Specs: https://tools.ietf.org/html/rfc7239, end of page 7: It is important to note that an IPv6 address and any node name with node-port specified MUST be quoted, since "":"" is not an allowed character in ""token"".

Swagger version: 2.4.0

Stacktrace:

<pre><code>
java.lang.NumberFormatException: For input string: ""8081""""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at springfox.documentation.swagger2.web.HostNameProvider.componentsFrom(HostNameProvider.java:62)
	at springfox.documentation.swagger2.web.Swagger2Controller.hostName(Swagger2Controller.java:90)
	at springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(Swagger2Controller.java:83)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:220)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:134)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:105)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:107)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:108)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:784)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:802)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1410)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:745)
</pre></code>",Can you share the stack trace please?,I have updated my question with the stacktrace and the swagger version.
springfox/springfox,https://github.com/springfox/springfox/issues/2182," release 2.7.0 fixed the JsonUnwrapped  problem ,but prefix still didn't show.

`
@Data
public class ProductVO {
private String name;
@JsonUnwrapped(prefix = ""specification_"")
private Specification specification;
}
`

`
@Data
public class Specification {
private String name;
}
`

what i got in swagger-ui is something like

`
ProductVO {
 name(string,optional);
}
`
","Could you let me know how to well coding it and I can have a look ?

",
springfox/springfox,https://github.com/springfox/springfox/issues/2012,"version `2.7.0` (also tested with `2.6.1`)

Swagger configuration

```java
@Configuration
@EnableSwagger2
public class SwaggerConfiguration {
    @Bean
    public Docket revenueModelerApi() {

        return new Docket(DocumentationType.SWAGGER_2)
                .select()
                .apis(RequestHandlerSelectors.basePackage(""com.###""))
                .paths(PathSelectors.any())
                .build();
    }
}
```
When doing a GET to `/v2/api-docs` I get two identical JSON documents one after the other:

```
{
   ""swagger"":""2.0"",
   ""info"": {...},
   ""paths"": {...}
}{
   ""swagger"":""2.0"",
   ""info"": {...},
   ""paths"": {...}
}
```
If I cut the file in half I get a valid Swagger.json file. But what could trigger the duplication in the response?",Could you create a sample project that demonstrates this bug? surprised by this,
springfox/springfox,https://github.com/springfox/springfox/issues/1937,"@ModelAttribute param name depends on setter method, eg.

```java
class MyPojo{
 private String testProperty;
 public void setBoomProperty(String testProperty){
   this.testProperty = testProperty;
 }
}
```
for  @ModelAttribute  MyPojo myPojo Springfox will generate *testProperty* attrubute, but boomProperty will be used by Spring

see for more info org.springframework.beans.BeanWrapperImpl.BeanPropertyHandler#setValue",What version are you using of springfox? This is fixed in 2.7.0,"@dilipkrish thanks for updating title, here the part of my build.gradle
 springBootVersion = '1.5.4.RELEASE'
```groovy
    compile('io.springfox:springfox-swagger2:2.7.0')
    compile('io.springfox:springfox-bean-validators:2.7.0')
    compile('io.springfox:springfox-swagger-ui:2.7.0')
```"
springfox/springfox,https://github.com/springfox/springfox/issues/1932,"Please take the time to search the repository, if your question has already been asked or answered.

- [2.7.0] What version of the library are you using? Is it the latest version? The latest released version is [ ![Download](https://api.bintray.com/packages/springfox/maven-repo/springfox/images/download.svg) ](https://bintray.com/springfox/maven-repo/springfox/_latestVersion)

What kind of issue is this?

 - [ ] Question. Is this a question about how to do a certain thing? 

 - [ ] Bug report. If you’ve found a bug, spend the time to write a failing test. Bugs with tests or 
       steps to reproduce get fixed faster. Here’s an example: https://gist.github.com/swankjesse/6608b4713ad80988cdc9
    - [ ] spring xml/java config that is relevant
    - [ ] springfox specific configuration if it makes sense
    - [ ] include any output you've received; logs, json snippets etc.; and what the expected output should be
    - [ ] if you have a repo that demonstrates the issue for bonus points! See [this example](https://github.com/springfox/springfox/issues/494) 

 - [x] Feature Request. Start by telling us what problem you’re trying to solve. Often a solution
       already exists! Don’t send pull requests to implement new features without first getting our
       support. Sometimes we leave features out on purpose to keep the project small.

Please do consider ***starring*** this repository if you do like this project and find it useful. 

I have a project which uses both spring data rest and custom controllers for overrides. To keep the base path spring configuration aware, I use the `@BasePathAwareController` annotation:

```
@RestController
@BasePathAwareController
@Api(tags = ""banana"", description = ""Banana Controller"")
public class BananaController {

    @PostMapping(""/banana"")
    public Banana create(@RequestBody Resource<Banana> entity) throws Exception {
        return null;
    }

    @PutMapping(""/banana/{id}"")
    public Banana update(@PathVariable Long id, @RequestBody Resource<Banana> entity) throws Exception {
        return null;
    }

    @DeleteMapping(""/banana/{id}"") // Define mappings at method levels only
    public void delete(@PathVariable Long id) throws Exception {
    }
}
```

Meanwhile i have the spring rest prefix set to `/api` so this will expose the resources over `/api/banana/*` and the repository resources with your wonderful `SpringDataRestConfiguration` class detects this fine, but these custom controllers do not, and instead are registered in the documentation relative to `/`.

Also the spring data rest configuration does not seem to honour the `@RestResource(exported = false)` annotation and continues to document it even though export of all duplicate resources has been disabled.",Do you know if there are bugs opened for this issue? Thanks,I think this issue *is* the opened bug.
springfox/springfox,https://github.com/springfox/springfox/issues/1876,"I'm using springfox-swagger2, springfox-swagger-ui and springfox-data-rest versione 2.7.0 to document Spring Data Rest repositories.

I created my configuration class:

```java
@Configuration
@EnableSwagger2
@Import({ springfox.documentation.spring.data.rest.configuration.SpringDataRestConfiguration.class })
public class SwaggerConfig {
	@Bean
	public Docket api() {
		return new Docket(DocumentationType.SWAGGER_2).select().apis(RequestHandlerSelectors.basePackage(""com.test.rest""))
				.paths(PathSelectors.any()).build();
	}
```

Unfortunately I've a NullPointerException:

```stacktrace 
org.springframework.context.ApplicationContextException: Failed to start bean 'documentationPluginsBootstrapper'; nested exception is java.lang.NullPointerException
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:50) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:348) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:151) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:114) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:880) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) ~[spring-boot-1.5.4.RELEASE.jar:1.5.4.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.4.RELEASE.jar:1.5.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.4.RELEASE.jar:1.5.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.4.RELEASE.jar:1.5.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.4.RELEASE.jar:1.5.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.4.RELEASE.jar:1.5.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.4.RELEASE.jar:1.5.4.RELEASE]
	at com.test.rest.BusletApplication.main(BusletApplication.java:12) [classes/:na]
Caused by: java.lang.NullPointerException: null
	at springfox.documentation.builders.RequestHandlerSelectors$4.apply(RequestHandlerSelectors.java:97) ~[springfox-core-2.7.0.jar:2.7.0]
	at springfox.documentation.builders.RequestHandlerSelectors$4.apply(RequestHandlerSelectors.java:94) ~[springfox-core-2.7.0.jar:2.7.0]
	at com.google.common.base.Present.transform(Present.java:71) ~[guava-18.0.jar:na]
	at springfox.documentation.builders.RequestHandlerSelectors$5.apply(RequestHandlerSelectors.java:113) ~[springfox-core-2.7.0.jar:2.7.0]
	at springfox.documentation.builders.RequestHandlerSelectors$5.apply(RequestHandlerSelectors.java:110) ~[springfox-core-2.7.0.jar:2.7.0]
	at com.google.common.base.Predicates$AndPredicate.apply(Predicates.java:359) ~[guava-18.0.jar:na]
	at com.google.common.base.Predicates$AndPredicate.apply(Predicates.java:359) ~[guava-18.0.jar:na]
	at com.google.common.collect.Iterators$7.computeNext(Iterators.java:652) ~[guava-18.0.jar:na]
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) ~[guava-18.0.jar:na]
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138) ~[guava-18.0.jar:na]
	at springfox.documentation.spring.web.scanners.ApiListingReferenceScanner.scan(ApiListingReferenceScanner.java:48) ~[springfox-spring-web-2.7.0.jar:2.7.0]
	at springfox.documentation.spring.web.scanners.ApiDocumentationScanner.scan(ApiDocumentationScanner.java:67) ~[springfox-spring-web-2.7.0.jar:2.7.0]
	at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.scanDocumentation(DocumentationPluginsBootstrapper.java:95) ~[springfox-spring-web-2.7.0.jar:2.7.0]
	at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.start(DocumentationPluginsBootstrapper.java:154) ~[springfox-spring-web-2.7.0.jar:2.7.0]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:175) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE]
	... 14 common frames omitted`
```

Removing the inclusion of SpringDataRestConfiguration.class Swagger starts correctly (but of course it doesn't display resourses of Spring data rest repositories).

I tried to debug the point where the exception happens and I found the input variable is a proxy: springfox.documentation.builders.RequestHandlerSelectors$4@7210f559 class com.sun.proxy.$Proxy167


and the call to getPackage() return an error.

Is this a bug? Should this exception be handled? How could I fix the problem meanwhile?

Thanks",Do you have a controller perhaps that doesnt belong to a package?,
springfox/springfox,https://github.com/springfox/springfox/issues/1839,"After upgrading to 2.7.0  from 2.6.2-SNAPSHOT, 
Springfox adds  primary keys as path parameters in Post requests for Spring Data Rest Entities.
Swagger Editor throws
""Semantic error at paths./api/EntityNames.post.parameters[0]
Path parameter id was defined but never used""

Is there a way to get rid of the primary key from the path params?
 - name: id
          in: path
          description: id
          required: true
          type: integer
          format: int32",Would you mind providing a breaking scenario using [one of these repositories](https://github.com/springfox/springfox/tree/master/swagger-contract-tests/src/main/java/springfox/test/contract/swagger/data/rest) as an example?,"Hi,
I am getting the primary keys in input for all the entities . Consider an Test entity 
```java
FunctionToRole{
@EmbeddedId
	private FunctionToRoleId functionToRole;

..getter,setter
}
```
where,
```java
public class FunctionToRoleId implements Serializable  {
	@Column(name = ""FUNCTION_ID"")
	private long fkUserFunctionId;
	
	@Column(name = ""ROLE_ID"")
	private long fkUserRoleId;
...getter setter
}
```
I get in the YAMLfor post:

```yaml
post:
      tags:
        - FunctionToRole Entity
      summary: saveFunctionToRole
      operationId: saveFunctionToRoleUsingPOST
      consumes:
        - application/json
      produces:
        - '*/*'
      parameters:
        - name: fkUserFunctionId
          in: query
          required: false
          type: integer
          format: int64
        - name: fkUserRoleId
          in: query
          required: false
          type: integer
          format: int64
        - in: body
          name: body
          description: body
          required: true
          schema:
            $ref: '#/definitions/FunctionToRole'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/Resource«FunctionToRole»'
        '201':
          description: Created
        '401':
          description: Unauthorized
        '403':
          description: Forbidden
        '404':
          description: Not Found
```
I tested post method in swagger ui by providing values in body only, it works fine.But when the entity does not have embedded id, the path parameter id is required=true.
So the documentation is incorrect in that case.

As 2.7.0 is listing the associations nicely as separate apis, wanted to upgrade to this version.
Let me know if I can help with anything else.

"
springfox/springfox,https://github.com/springfox/springfox/issues/1827,"
This error causes the stack to overflow in the ModelAttributeParameterExpander class：



![qbj 2eso wr344td igf0](https://cloud.githubusercontent.com/assets/28040861/26306123/c22c119a-3f24-11e7-9511-1c721cecc1c7.png)

I tried to fix it in my code：
`if (Types.isBaseType(itemType) || itemType.getErasedType().isEnum()) {
        parameters.add(simpleFields(context.getParentName(), context.getDocumentationContext(), each));
      } else {
        parameters.addAll(
            expand(
                    context.childContext(
                            nestedParentName(context.getParentName(), each.getField()),
                            each.getFieldType(),
                            context.getDocumentationContext())));
      }
    }`

In addition, because of the large number of my project interface, the project started very slow, compared to 2.5.0 version of a slow slow for a whole minute","Would be able to create a minimal reproducible scenario? I don't understand what your implying by the highlighted code and your fix. Perhaps create a PR with a breaking test and your fix that solves the problem. 

That said. This tool isn't really meant for documenting controller methods with model attributes. It's for documenting http APIs. ","`class A {
  List<B> bList;
}`
`class B{
  List<A> aList;
}`"
springfox/springfox,https://github.com/springfox/springfox/issues/1708,"Hello, I'm trying to integrate swagger2 with a spring mvc project (no spring boot) and am running into a configuration related issue that is causing build failure whenever I use the @EnableSwagger2 annotation. 


pom.xml

```
	    <dependency>
		    <groupId>io.springfox</groupId>
		    <artifactId>springfox-swagger2</artifactId>
		    <version>2.6.1</version>
		    <exclusions>
		        <exclusion>
		            <groupId>com.google.guava</groupId>
		            <artifactId>guava</artifactId>
		        </exclusion>
		    </exclusions>
	    </dependency>
	    <dependency>
		    <groupId>io.springfox</groupId>
		    <artifactId>springfox-swagger-ui</artifactId>
		    <version>2.6.1</version>
	    </dependency>
```


SwaggerConfig

```
@EnableSwagger2
public class SwaggerConfig {
    
    List<Parameter> listParameter = new ArrayList<>();
    
    @Bean
    public Docket api() {
        return new Docket(DocumentationType.SWAGGER_2)
                .select()
                .apis(RequestHandlerSelectors.any())
                .paths(PathSelectors.any())
                .build()
                .globalOperationParameters(listParameter)
                .apiInfo(apiInfo());
    }
    
    private ApiInfo apiInfo() {
        return new ApiInfoBuilder()
                .title(""some service"")
                .description(""description"")
                .build();
    } 
}
```


AppConfig.java (relevant parts)

```
@EnableWebMvc
@EnableTransactionManagement
@Configuration
@Import(<package goes here>SwaggerConfig.class)
@ComponentScan(basePackages = { ""com.company.package1""})

@MapperScan(""com.company.model.mappers"")
public class AppConfig extends WebMvcConfigurerAdapter {


...
...
...

    @Override
    public void addResourceHandlers(ResourceHandlerRegistry registry) {
        registry.addResourceHandler(""swagger-ui.html"").addResourceLocations(""classpath:/META-INF/resources/"");
        registry.addResourceHandler(""/webjars/**"").addResourceLocations(""classpath:/META-INF/resources/webjars/"");
    }


```


When I attempt to mvn clean install, I get the following error


```
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.company.KmsClient]: Factory method 'kmsClient' threw exception; nested exception is java.lang.RuntimeException: java.net.MalformedURLException: no protocol: NotConfigured
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)
	... 105 more
Caused by: java.lang.RuntimeException: java.net.MalformedURLException: no protocol: NotConfigured
	at com.company.AppConfig.kmsClient(AppConfig.java:269)
	at com.company.AppConfig$$EnhancerBySpringCGLIB$$f5c52e6a.CGLIB$kmsClient$17(<generated>)
	at com.company.AppConfig$$EnhancerBySpringCGLIB$$f5c52e6a$$FastClassBySpringCGLIB$$6b97ed1f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:318)
	at com.company.AppConfig$$EnhancerBySpringCGLIB$$f5c52e6a.kmsClient(<generated>)
	at sun.reflect.GeneratedMethodAccessor96.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162)
	... 106 more
Caused by: java.net.MalformedURLException: no protocol: NotConfigured
	at java.net.URL.<init>(URL.java:593)
	at java.net.URL.<init>(URL.java:490)
	at java.net.URL.<init>(URL.java:439)
	at com.company.KmsClient.<init>(KmsClient.java:125)
	at com.company.AppConfig.kmsClient(AppConfig.java:266)
	... 115 more
```

I've been able to track the issue to a particular property value that seems to be missing whenever the @EnableSwagger2 annotation is used, which in turn is causing the above exception. If I remove the @EnableSwagger2 annotation from SwagerConfig.java, the property in question is correctly injected into the appropriate @Bean method and everything builds fine. 

Again, this is a spring mvc application (i.e. no Spring boot). Following the lead of another issue I found in this repo, I elected to remove the @Configuration annotation from SwaggerConfig.java with no success. 

Any help would be greatly appreciated
 
",Whats in `com.company.AppConfig.kmsClient(AppConfig.java:266)`?,"Thanks for the response. It's a home grown kms client that expects a configuration object. The configuration object is constructed from values that are read in from a .properties file and injected as parameters into the enclosing @Bean method. The issue is arising from the fact that one of the injected parameters is somehow null when @EnableSwagger2 is used, but non null when it's commented out. The code runs and builds fine in the absence of swagger."
springfox/springfox,https://github.com/springfox/springfox/issues/1615,"Hi this is a question on configuration. I was reading for hours today but did not get my mistake.

**Symptom:**

http://localhost:8080/sabi/api/v2/api-docs/
shows me that the annotations have been scanned and assembled.  I get a detailed json containing my content.

However when calling the swagger-ui
http://localhost:8080/sabi/swagger-ui.html
The ui renders, but I can see non of my API. Even by pasting the api-docs url from above and pressing enter did not lead to any result.

**Here's my setup:**

Im using:
```
           <dependency>
                <groupId>io.springfox</groupId>
                <artifactId>springfox-swagger-ui</artifactId>
                <version>2.6.1</version>
                <scope>compile</scope>
            </dependency>

            <dependency>
                <groupId>io.springfox</groupId>
                <artifactId>springfox-swagger2</artifactId>
                <version>2.6.1</version>
                <scope>compile</scope>
            </dependency>
```

with spring-webmvc (4.2.1-RELEASE) and using xml-free annotation based config:

```
@Configuration
@EnableWebMvc
@EnableSwagger2
@ComponentScan(basePackages = ""de.bluewhale.sabi"")
@PropertySource(""classpath:server.properties"")
public class AppConfig {

    @Autowired
    Environment env;

    @Bean
    public EncryptionService encryptionService() {
        return new EncryptionService(env.getProperty(""accessToken.salt""), env.getProperty(""accessToken.password""));
    }

    @Bean
    public static PropertySourcesPlaceholderConfigurer properties() {
        return new PropertySourcesPlaceholderConfigurer();
    }
}
```

and 
```

@Configuration
public class ApiDocumentationConfiguration {

    @Bean
    public Docket documentation() {
        return new Docket(DocumentationType.SWAGGER_2)
                .select()
                    .apis(RequestHandlerSelectors.any())
                    .paths(PathSelectors.any())
                    // .paths(regex(""/api/*""))
                    .build()
                .pathMapping(""/api"")
                .apiInfo(metadata());
    }

    private ApiInfo metadata() {
        return new ApiInfoBuilder()
                .title(""sabi's REST API documentation"")
                .description(""see https://github.com/StefanSchubert/sabi"")
                .version(""1.0"")
                .license(""MIT Licence (MIT)"")
                .licenseUrl(""https://github.com/StefanSchubert/sabi/blob/master/LICENSE"")
                .contact(""Stefan.Schubert@bluewhale.de"")
                .build();
    }
}
```

What am I doing wrong?",Could you try seeing the javascript console to see why its not loading the UI?,"When hitting enter I can see an HTTP-404 on the developer console of firefox:
http://localhost:8080/sabi/swagger-resources/configuration/ui

with this information I found: https://github.com/springfox/springfox/issues/983 

and tried to access: http://localhost:8080/sabi/api/swagger-resources/configuration/ui
which results in some JSON and a HTTP-200.
"
springfox/springfox,https://github.com/springfox/springfox/issues/1597,"my code is annotation on parameter `@ApiParam(value = ""example"")` .
Swagger shows:
![image](https://cloud.githubusercontent.com/assets/6240704/20919989/9aedbe6c-bb9e-11e6-8fe8-9b037c2406c4.png)
so the second `sort` should be `example` but is not.

Im using springfox swagger
compile(""io.springfox:springfox-swagger2:2.6.1"")
compile(""io.springfox:springfox-swagger-ui:2.6.1"")

With version 2.5.1 everything was working. Nothing was changed in configuration, just version upgrade.",Could you share what you're endpoint method signature looks like?,"```
public Object getSmth(
@ApiParam(value = ""example"", name = ""sort"")
@RequestParam(name = ""sort"", required = false, defaultValue = """") final Sort sort) {}

public class Sort {
    private String fieldName;
    private Direction direction = Direction.ASC;
    // getters, setters, constructors,....
}
```"
springfox/springfox,https://github.com/springfox/springfox/issues/1528,"After using Swagger 2.6, when registering with the registration module, the registered instance name becomes ""Unknown"", which causes the corresponding service can not be found correctly when the service is found by the service name.

Ask for help!
","Could you verify that 2.6.1-SNAPSHOT fixes it? 
","I try, the results and then feedback
"
springfox/springfox,https://github.com/springfox/springfox/issues/1508,"The 2.6.0 update seems to automatically configure a default for the whole application. This code works perfectly fine with 2.5.0 but crashes in 2.6.0 if spring.horse is undefined.

This is caused by a change in SwaggerCommonConfiguration when PropertySourcesPlaceholderConfigurer was replaced with PropertyPlaceholderConfigurer

I think that the new behavior is actually the default that spring boot had, I just wanted to log a side effect that I received by updating the library.

```
@SpringBootApplication
@RestController
@EnableSwagger2
public class Swagger2SpringBoot {

    @Value(""${spring.horse}"")
    private String horse;

    public static void main(String[] args) throws Exception {
        new SpringApplication(Swagger2SpringBoot.class).run(args);
    }

    @RequestMapping(value = ""/dummy"")
    String meGet() {
        return null;
    }


}
```
","Maybe fixed by https://github.com/springfox/springfox/commit/d3c18b9969648958811d3fcdff9b9fd5ff25a2e9 ?
","No, however that's a good thing. The new behavior is the correct behavior, it was actually wrong in 2.5.0.
I mainly created this issue to track the change in case someone else comes across this behavior.

That commit does however fix https://github.com/springfox/springfox/issues/1525
"
springfox/springfox,https://github.com/springfox/springfox/issues/1321,"> What version of the library are you using? 

```
compile 'io.springfox:springfox-swagger2:2.4.0'
compile 'io.springfox:springfox-swagger-ui:2.4.0'
```

> What kind of issue is this?
- Feature Request. 

I want to fully change documentation url like http://127.0.0.1:8080/aaa/v3/public/swagger-ui.html for further simplyfy nginx configuration i want to use ""/public"" subpath:

```
http://127.0.0.1:8080/aaa/v3/public
http://127.0.0.1:8080/aaa/v3/secured
```

I add property source:

```
@Configuration
@EnableSwagger2
@PropertySource(""classpath:/config/swagger.properties"")
public class SwaggerConfig {
...
```

I set path in swagger.properties:

```
springfox.documentation.swagger.v2.path=/public
```

And I tested GET http://127.0.0.1:8080/aaa/v3/public, json are present in response:

```
{
""swagger"": ""2.0"",
""info"":{
""description"": ""Some custom description of API."",
""version"": ""API TOS"",
""title"": ""AAA REST API"",
""termsOfService"": ""Terms of service"",
""contact"":{
...
```

Further, i changed webjar's path in my Spring Boot WebMvcConfigurerAdapter:
WebConfig.java

```
@Configuration
public class WebConfig extends WebMvcConfigurerAdapter{
    private static final String[] CLASSPATH_RESOURCE_LOCATIONS = {
            ""classpath:/META-INF/resources/"",
            ""classpath:/static/"", ""classpath:/public/"" };

    @Override
    public void addResourceHandlers(ResourceHandlerRegistry registry) {
        if (!registry.hasMappingForPattern(""/webjars/**"")) {
            registry.addResourceHandler(""/webjars/**"").addResourceLocations(""classpath:/META-INF/resources/webjars/"");
        }
        if (!registry.hasMappingForPattern(""/public/**"")) {
            registry.addResourceHandler(""/public/**"").addResourceLocations(CLASSPATH_RESOURCE_LOCATIONS);
        }
    }
}
```

Now i open http://127.0.0.1:8080/aaa/v3/public/swagger-ui.html in Firefox, but load nothing [PNG image](http://i.imgur.com/kfhFLCR.png) because javascripts attempt to call http://127.0.0.1:8080/aaa/v3/public/configuration/ui.

I found In ApiResourceController.java hard-coded paths - it is root cause.

Please consider to parametrize hard-coded paths.
It does swagger more flexible.

Something like

```
@RequestMapping(value = ""${springfox.documentation.swagger.v2.path}/configuration/security"")
...
@RequestMapping(value = ""${springfox.documentation.swagger.v2.path}/configuration/ui"")
...
```
","Would you like to take a shot at a PR since you're right in there?
","Ok, probably you right, it' s not easy as I want =(
I simple write it here -- nginx locations for swagger2 and swagger ui:
   #http://127.0.0.1/aaa/v3/swagger-ui.html
   #http://127.0.0.1/aaa/v3/webjars/springfox-swagger-ui/
   #http://127.0.0.1/aaa/v3/swagger-resources/
   #http://127.0.0.1/aaa/v3/v2/api-docs
   #http://127.0.0.1/aaa/v3/configuration/ui
   #http://127.0.0.1/aaa/v3/configuration/security

```
location ~* ^/(\w+)/v3/swagger-ui.html {
    proxy_pass  http://$1:8080;
}
location ~* ^/(\w+)/v3/webjars/springfox-swagger-ui/ {
    proxy_pass  http://$1:8080;
}
location ~* ^/(\w+)/v3/swagger-resources {
    proxy_pass  http://$1:8080;
}
location ~* ^/(\w+)/v3/v2/api-docs {
    proxy_pass  http://$1:8080;
}
location ~* ^/(\w+)/v3/configuration/ui {
    proxy_pass  http://$1:8080;
}
location ~* ^/(\w+)/v3/configuration/security {
    proxy_pass  http://$1:8080;
}
```
"
springfox/springfox,https://github.com/springfox/springfox/issues/1285,"This @ApiImplicitParam(dataType = ""file"", name = ""image1"", required = true, paramType = ""form"") is working in version 2.2.2, but if I migrate to the last version (2.4.0) , it doesn't recognize the parameter image1 like a file.
","Could you share your request mapping? Also try removing the `ApiImplicitParam` annotation
","Here you are my request mapping, I am using spring annotations

@RequestMapping(value = ""/{userId}/exchange"", method = RequestMethod.POST,
consumes = MediaType.MULTIPART_FORM_DATA_VALUE)

and I am using

@ApiImplicitParams (value = {

```
   @ApiImplicitParam(dataType = ""file"", name = ""image2"", required = true,
```

paramType = ""form"")

}

2016-04-25 22:47 GMT+02:00 Dilip Krishnan notifications@github.com:

> Could you share your request mapping? Also try removing the
> ApiImplicitParam annotation
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly or view it on GitHub
> https://github.com/springfox/springfox/issues/1285#issuecomment-214516360
"
springfox/springfox,https://github.com/springfox/springfox/issues/1282,"i'm using 2.4.0 version

```
compile (""io.springfox:springfox-swagger2:2.4.0"") {
    exclude group: ""org.springframework""
}
compile ('io.springfox:springfox-swagger-ui:2.4.0') {
    exclude group: ""org.springframework""
}
```

when Controller method return array 

```
@RequestMapping(value = ""/apis/roles"", method = RequestMethod.GET)
@ResponseBody
public Role[] getRoleTestStatus() {
    ...
}
```

responses json is correct.

```
responses: {
    200: {
        description: ""OK"",
        schema: {
            type: ""array"",
            items: {
                $ref: ""#/definitions/Roles""
            }
        }
    },
    401: {
        description: ""Unauthorized""
    },
    403: {
        description: ""Forbidden""
    },
    404: {
        description: ""Not Found""
    }
}
```

but definitions json node don't contain 'Roles' model property. 
How can i represent array type model?
thanks for your help.
","What does `Role` look like? is it an enum?
","hi dilipkrish
`Role` is just POJO class. 

```
@Controller
public class WorldController {

    @RequestMapping(value = ""/test1"", method = RequestMethod.GET)
    @ResponseBody
    public Role[] test() {
        return null;
    }

    static class Role {
        private String id;
        private String name;
    }
}
```

change the return type `Role[]` to `List<Role>`. then result json is correct. only array return type is allways missing model Role.
"
springfox/springfox,https://github.com/springfox/springfox/issues/1280,"I'm using Springfox `2.4.0` but the output does not respect the @ApiModelProperty position field.
Instead the fields in the resource are ordered alphabetically.
","Could you perhaps create a breaking test?
","@dilipkrish What can we expect? 

When I have class like:

```
public class HotelResource {

@ApiModelProperty(value = ""The unique id of the hotel"", required = true)
private String id;

@ApiModelProperty(value = ""The name of the hotel"", required = true)
private String name;

@ApiModelProperty(value = ""The unique alpha2 code of the hotel"", required = true)
private String countryAlpha2Code;

// getters and setters omitted
..
```

Now the Springfox generated swagger.json contains a `HotelResource` definition containing these properties but ordered like: `country_alpha2_code`, `id`, `name`.

Is that expected? Should it not keep the order of the properties in the class?
"
springfox/springfox,https://github.com/springfox/springfox/issues/1129,"In 2.2.2 version it's OK, but when upgrade to 2.3.1(or 2.3.0), i got a IndexOutOfBoundsException.
I finally find in my rest API request DTO, if exist a filed ""JSONObject"", it will happen.
If delete it, it's OK. Why? Is there some change about this?
","Could you provide a stacktrace?
","2016-01-07 18:47:16,073 ERROR [http-nio-8080-exec-13#101] <com.huawei.iom.component.base.exception.ExceptionHandler.resolveException,117> - java.lang.IndexOutOfBoundsException: Index: 1
         at java.util.Collections$EmptyList.get(Collections.java:4454)
         at springfox.documentation.swagger2.mappers.ModelMapper.typeOfValue(ModelMapper.java:109)
         at springfox.documentation.swagger2.mappers.ModelMapper.mapProperties(ModelMapper.java:91)
         at springfox.documentation.swagger2.mappers.ModelMapper.mapModels(ModelMapper.java:65)
         at springfox.documentation.swagger2.mappers.ModelMapper.modelsFromApiListings(ModelMapper.java:190)
         at springfox.documentation.swagger2.mappers.ServiceModelToSwagger2MapperImpl.mapDocumentation(ServiceModelToSwagger2MapperImpl.java:50)
         at springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(Swagger2Controller.java:76)
         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
         at java.lang.reflect.Method.invoke(Method.java:497)
         at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)
         at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)
         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)
         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:776)
         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:705)
         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
         at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959)
         at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893)
         at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)
         at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)
         at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)
         at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
         at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
         at com.huawei.m2m.nscl.security.filter.HttpHeaderFilter.doFilter(HttpHeaderFilter.java:79)
         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
         at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:207)
         at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176)
         at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:344)
         at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:261)
         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
         at com.huawei.iccp.monitor.thread.filter.ThreadFilter.doFilter(ThreadFilter.java:86)
         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
         at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
         at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:85)
         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
         at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219)
         at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
         at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502)
         at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)
         at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
         at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:617)
         at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
         at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
         at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
         at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:668)
         at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1527)
         at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1484)
         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
         at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
         at java.lang.Thread.run(Thread.java:745)

发件人: Dilip Krishnan [mailto:notifications@github.com]
发送时间: 2016年1月7日 20:40
收件人: springfox/springfox
抄送: Zhanyongqiang
主题: Re: [springfox] Swagger2Controller.getDocumentation get IndexOutOfBoundsException (#1129)

Could you provide a stacktrace?

—
Reply to this email directly or view it on GitHubhttps://github.com/springfox/springfox/issues/1129#issuecomment-169652831.
"
springfox/springfox,https://github.com/springfox/springfox/issues/1055,"I've just updated my spring-boot 1.3.0.RC1 ( also 1.3.0.RELEASE ) app to Spring 4.2.3, and having

```
<dependency>
          <groupId>io.springfox</groupId>
          <artifactId>springfox-swagger2</artifactId>
          <version>2.2.2</version>
      </dependency>
      <dependency>
          <groupId>io.springfox</groupId>
          <artifactId>springfox-swagger-ui</artifactId>
          <version>2.2.2</version>
          <scope>runtime</scope>
      </dependency>
```

in my pom.xml, used in a class

```
@Configuration
@EnableSwagger2
public class SwaggerConfig {
```

makes the application do not boot.

See error log attached :

```
2015-11-16 11:56:18,050 ERROR o.s.b.SpringApplication | Application startup failed 
java.lang.IllegalArgumentException: interface org.springframework.core.annotation.SynthesizedAnnotation is not visible from class loader
        at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:581) ~[na:1.8.0_66]
        at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:557) ~[na:1.8.0_66]
        at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:230) ~[na:1.8.0_66]
        at java.lang.reflect.WeakCache.get(WeakCache.java:127) ~[na:1.8.0_66]
        at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:419) ~[na:1.8.0_66]
        at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:719) ~[na:1.8.0_66]
        at org.springframework.core.annotation.AnnotationUtils.synthesizeAnnotation(AnnotationUtils.java:1404) ~[spring-core-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.core.annotation.AnnotatedElementUtils.findMergedAnnotation(AnnotatedElementUtils.java:405) ~[spring-core-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.web.method.HandlerMethod.getMethodAnnotation(HandlerMethod.java:234) ~[spring-web-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at springfox.documentation.spring.web.readers.operation.OperationDeprecatedReader.apply(OperationDeprecatedReader.java:34) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.plugins.DocumentationPluginsManager.operation(DocumentationPluginsManager.java:113) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.readers.operation.ApiOperationReader.read(ApiOperationReader.java:79) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.readers.operation.ApiOperationReader$$FastClassBySpringCGLIB$$7c030d50.invoke(<generated>) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:718) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:85) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at springfox.documentation.spring.web.caching.CachingAspect.cachedValue(CachingAspect.java:86) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.caching.CachingAspect.operationsAndProperties(CachingAspect.java:69) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source) ~[na:na]
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_66]
        at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_66]
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:68) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:654) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at springfox.documentation.spring.web.readers.operation.ApiOperationReader$$EnhancerBySpringCGLIB$$c04784f2.read(<generated>) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.scanners.ApiDescriptionReader.read(ApiDescriptionReader.java:67) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.scanners.ApiListingScanner.scan(ApiListingScanner.java:92) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.scanners.ApiDocumentationScanner.scan(ApiDocumentationScanner.java:62) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.scanDocumentation(DocumentationPluginsBootstrapper.java:101) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.onApplicationEvent(DocumentationPluginsBootstrapper.java:87) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.onApplicationEvent(DocumentationPluginsBootstrapper.java:50) ~[springfox-spring-web-2.2.2.jar:2.2.2]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:163) ~[spring-context-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:136) ~[spring-context-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:380) ~[spring-context-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:334) ~[spring-context-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:854) ~[spring-context-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:140) ~[spring-boot-1.3.0.RC1.jar:1.3.0.RC1]
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:540) ~[spring-context-4.2.3.RELEASE.jar:4.2.3.RELEASE]
        at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.3.0.RC1.jar:1.3.0.RC1]
        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:761) [spring-boot-1.3.0.RC1.jar:1.3.0.RC1]
        at org.springframework.boot.SpringApplication.doRun(SpringApplication.java:356) [spring-boot-1.3.0.RC1.jar:1.3.0.RC1]
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:295) [spring-boot-1.3.0.RC1.jar:1.3.0.RC1]
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1085) [spring-boot-1.3.0.RC1.jar:1.3.0.RC1]
```
","Would you be able to try it and report back?
","I'm using 

```
2787 [INFO] |  \- org.aspectj:aspectjweaver:jar:1.8.7:compile
2788 [INFO] \- org.aspectj:aspectjrt:jar:1.8.7:compile
```

Are they the right versions ?
"
springfox/springfox,https://github.com/springfox/springfox/issues/1054,"With Swagger2 enabled, I get the below class cast exception when running the application in Eclipse.

Strange enough, this exception does not occur when running the application from Gradle.

I'm running SpringFox 2.2.2 and Jackson 2.6.3.
See [`build.gradle`](https://github.com/yonadev/yona-server/blob/master/appservice/build.gradle)
Your help is appreciated!

```
java.lang.ClassCastException: com.fasterxml.classmate.members.ResolvedConstructor cannot be cast to com.fasterxml.classmate.members.ResolvedParameterizedMember
    at springfox.documentation.schema.property.FactoryMethodProvider$1.apply(FactoryMethodProvider.java:56)
    at com.google.common.collect.Iterators$7.computeNext(Iterators.java:652)
    at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
    at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
    at com.google.common.collect.Iterators.tryFind(Iterators.java:752)
    at com.google.common.collect.Iterables.tryFind(Iterables.java:675)
    at com.google.common.collect.FluentIterable.firstMatch(FluentIterable.java:236)
    at springfox.documentation.schema.property.FactoryMethodProvider.in(FactoryMethodProvider.java:52)
    at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.fromFactoryMethod(OptimizedModelPropertiesProvider.java:302)
    at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.candidateProperties(OptimizedModelPropertiesProvider.java:191)
    at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.propertiesFor(OptimizedModelPropertiesProvider.java:125)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
    at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:85)
    at springfox.documentation.spring.web.caching.CachingAspect.cachedValue(CachingAspect.java:86)
    at springfox.documentation.spring.web.caching.CachingAspect.operationsAndProperties(CachingAspect.java:69)
    at sun.reflect.GeneratedMethodAccessor37.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621)
    at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610)
    at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:68)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168)
    at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
    at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
    at com.sun.proxy.$Proxy77.propertiesFor(Unknown Source)
    at springfox.documentation.schema.DefaultModelProvider.properties(DefaultModelProvider.java:151)
    at springfox.documentation.schema.DefaultModelProvider.modelFor(DefaultModelProvider.java:85)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
    at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:85)
    at springfox.documentation.spring.web.caching.CachingAspect.cachedValue(CachingAspect.java:86)
    at springfox.documentation.spring.web.caching.CachingAspect.modelsAndDependencies(CachingAspect.java:80)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621)
    at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610)
    at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:68)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168)
    at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92)
    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
    at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
    at com.sun.proxy.$Proxy78.modelFor(Unknown Source)
    at springfox.documentation.spring.web.scanners.ApiModelReader.read(ApiModelReader.java:66)
    at springfox.documentation.spring.web.scanners.ApiListingScanner.scan(ApiListingScanner.java:91)
    at springfox.documentation.spring.web.scanners.ApiDocumentationScanner.scan(ApiDocumentationScanner.java:62)
    at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.scanDocumentation(DocumentationPluginsBootstrapper.java:101)
    at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.onApplicationEvent(DocumentationPluginsBootstrapper.java:87)
    at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.onApplicationEvent(DocumentationPluginsBootstrapper.java:50)
    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)
    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)
    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:331)
    at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:775)
    at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:139)
    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:483)
    at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:117)
    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:689)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:969)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:958)
    at nu.yona.server.AppServiceApplication.main(AppServiceApplication.java:36)
```
","Would you mind giving 2.2.3-SNAPSHOT a whirl and see if the problem is fixed?
","With 2.2.3-SNAPSHOT, the stacktrace is different but the issue still exists:

```
com.google.common.util.concurrent.UncheckedExecutionException: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.ClassCastException: com.fasterxml.classmate.members.ResolvedConstructor cannot be cast to com.fasterxml.classmate.members.ResolvedParameterizedMember
    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2203)
    at com.google.common.cache.LocalCache.get(LocalCache.java:3937)
    at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3941)
    at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4824)
    at com.google.common.cache.LocalCache$LocalLoadingCache.getUnchecked(LocalCache.java:4830)
    at springfox.documentation.schema.CachingModelProvider.modelFor(CachingModelProvider.java:56)
    at springfox.documentation.spring.web.scanners.ApiModelReader.read(ApiModelReader.java:67)
    at springfox.documentation.spring.web.scanners.ApiListingScanner.scan(ApiListingScanner.java:88)
    at springfox.documentation.spring.web.scanners.ApiDocumentationScanner.scan(ApiDocumentationScanner.java:69)
    at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.scanDocumentation(DocumentationPluginsBootstrapper.java:101)
    at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.onApplicationEvent(DocumentationPluginsBootstrapper.java:87)
    at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.onApplicationEvent(DocumentationPluginsBootstrapper.java:50)
    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)
    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)
    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:331)
    at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:775)
    at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:139)
    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:483)
    at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:117)
    at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:689)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:969)
    at org.springframework.boot.SpringApplication.run(SpringApplication.java:958)
    at nu.yona.server.AppServiceApplication.main(AppServiceApplication.java:36)
Caused by: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.ClassCastException: com.fasterxml.classmate.members.ResolvedConstructor cannot be cast to com.fasterxml.classmate.members.ResolvedParameterizedMember
    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2203)
    at com.google.common.cache.LocalCache.get(LocalCache.java:3937)
    at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3941)
    at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4824)
    at com.google.common.cache.LocalCache$LocalLoadingCache.getUnchecked(LocalCache.java:4830)
    at springfox.documentation.schema.property.CachingModelPropertiesProvider.propertiesFor(CachingModelPropertiesProvider.java:59)
    at springfox.documentation.schema.DefaultModelProvider.properties(DefaultModelProvider.java:151)
    at springfox.documentation.schema.DefaultModelProvider.modelFor(DefaultModelProvider.java:84)
    at springfox.documentation.schema.CachingModelProvider$1.load(CachingModelProvider.java:49)
    at springfox.documentation.schema.CachingModelProvider$1.load(CachingModelProvider.java:47)
    at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3527)
    at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2319)
    at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2282)
    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2197)
    ... 23 common frames omitted
Caused by: java.lang.ClassCastException: com.fasterxml.classmate.members.ResolvedConstructor cannot be cast to com.fasterxml.classmate.members.ResolvedParameterizedMember
    at springfox.documentation.schema.property.FactoryMethodProvider$1.apply(FactoryMethodProvider.java:56)
    at com.google.common.collect.Iterators$7.computeNext(Iterators.java:652)
    at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
    at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
    at com.google.common.collect.Iterators.tryFind(Iterators.java:752)
    at com.google.common.collect.Iterables.tryFind(Iterables.java:675)
    at com.google.common.collect.FluentIterable.firstMatch(FluentIterable.java:236)
    at springfox.documentation.schema.property.FactoryMethodProvider.in(FactoryMethodProvider.java:52)
    at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.fromFactoryMethod(OptimizedModelPropertiesProvider.java:300)
    at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.candidateProperties(OptimizedModelPropertiesProvider.java:189)
    at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.propertiesFor(OptimizedModelPropertiesProvider.java:123)
    at springfox.documentation.schema.property.CachingModelPropertiesProvider$1.load(CachingModelPropertiesProvider.java:52)
    at springfox.documentation.schema.property.CachingModelPropertiesProvider$1.load(CachingModelPropertiesProvider.java:50)
    at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3527)
    at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2319)
    at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2282)
    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2197)
    ... 36 common frames omitted
```
"
springfox/springfox,https://github.com/springfox/springfox/issues/951,"The solution for the issue described in #796 does no longer work. In 690c126e704879d10001fb8c4b918068924673ba (2.1.2) you decided to move the `validatorUrl` out the constructor and it seems that this broke the option to change the `validatorUrl`.

Right now, whatever value I use within the `UiConfiguration` bean, the validator keeps using the online version. I can no longer set it to `null` (for example). Downgrading to the latest version using the constructor (2.1.1) solves the issue.
","Would you be able to submit a patch?
","I'll see if I can do that. Didn't have much time lately though.
"
springfox/springfox,https://github.com/springfox/springfox/issues/897,"I have a Scala/Spring Boot application.
JSon de/serialization is handled by an ObjectMapper configured with DefaultScalaModule along with JodaModule and some application specific customizations.
I defined an ApplicationListener for the ObjectMapperConfigured that configures the supplied ObjectMapper.

Springfox Swagger finds the controller methods but has an empty `{}` model schema for the requests and responses.

Suggestions?
","Would you be able to share a repo I can take a look at perhaps? If not would you mind sharing how you're configuring your `Docket`? If you've given it an explicit group name then you might be hitting the wrong endpoint.
","I updated one of public examples: wip-swagger-support branch https://github.com/cer/microservices-examples/commits/wip-swagger-integration

This is the commit showing the changes: https://github.com/cer/microservices-examples/commit/03e5c931758239fb69ce60b3bba3287f7e8e0d24
"
springfox/springfox,https://github.com/springfox/springfox/issues/870,"I'm trying to configure OAuth with springfox (followup on #834). The button appears but is not clickable.

There is a small error icon next to the button: 

``` html
<div class=""auth"">
      <span class=""api-ic ic-error""></span>
         <div id=""api_information_panel"" style=""top: 526px; left: 776px; display: none;"">
         <div title=""read and write"">write</div>
     </div>
</div>
```

There is no error message, and the information panel appears somewhere else on the page. 

``` java
public Docket swaggerSpringMvcPlugin()
{
     return new Docket( DocumentationType.SWAGGER_2 )
        .groupName( ""test"" )
        .select()
            .apis( not( withMethodAnnotation( PrivateAPI.class )))
            .paths( regex( "".*/rest/.*"" ) )
            .build().apiInfo( new ApiInfoBuilder()
                .title( ""test"" )
                .description( ""test"" )
                .version( ""0.1"" )
                .build())
        .securitySchemes(securitySchemes())
        .securityContexts(securityContext()); 

    private class PasswordTokenRequestEndpoint extends TokenRequestEndpoint {

        private final String _username;
        private final String _password;

        public PasswordTokenRequestEndpoint(String url, String clientIdName,
                String clientSecretName, String username, String password) {

            super(url, clientIdName, clientSecretName);
            this._username = username;
            this._password = password;
        }

        @SuppressWarnings(""unused"")
        public String getUsername() {
            return _username;
        }

        @SuppressWarnings(""unused"")
        public String getPassword() {
            return _password;
        }
    }

    /**
     * Class used for Oauth2 password grant type
     */
    private class OAuth2PasswordCredentialsGrantType extends GrantType {

        @SuppressWarnings(""unused"")
        private final PasswordTokenRequestEndpoint _tokenRequestEndpoint;

        public OAuth2PasswordCredentialsGrantType(
                PasswordTokenRequestEndpoint tokenRequestEndpoint) {
            super(""password"");
            this._tokenRequestEndpoint = tokenRequestEndpoint;
        }
    }

    private List<SecurityContext> securityContext() {
        return Arrays.asList(SecurityContext.builder()
        .securityReferences(SecurityReferences())
        .build());
    }

    private List<SecurityScheme> securitySchemes() {
        ArrayList<SecurityScheme> authorizationTypes = new ArrayList<>();

        /* not sure why scopes are used for both authorization and authorization
         * type
         * API is not using the scopes for now
         */
        List<AuthorizationScope> authorizationScopeList = new ArrayList<>();
        authorizationScopeList.add(new AuthorizationScope(""read"", ""read only""));
        authorizationScopeList.add(new AuthorizationScope(""write"", ""read and write""));

        List<GrantType> grantTypes = new ArrayList<>();

        TokenRequestEndpoint tokenRequestEndpoint = new TokenRequestEndpoint(""/oauth/token"", ""client_Id "", ""client_secret"" );
        TokenEndpoint tokenEndpoint = new TokenEndpoint(""/oauth/token"", ""theToken"");

        PasswordTokenRequestEndpoint passwordTokenRequestEndpoint = new PasswordTokenRequestEndpoint(
                ""/oauth/token"", ""client_Id "", ""client_secret"", ""user"", ""password"");
        grantTypes.add(new OAuth2PasswordCredentialsGrantType(
                passwordTokenRequestEndpoint));

        grantTypes.add(new AuthorizationCodeGrant(tokenRequestEndpoint, tokenEndpoint));

        /* OAuth authorization type with client credentials and password grant
         * types.
         */
        authorizationTypes.add(new OAuth(""oauth2"", authorizationScopeList,
                grantTypes));

         authorizationTypes.add(oAuth);

        return authorizationTypes;
    }

    private List<SecurityReference> SecurityReferences() {

        List<SecurityReference> authorizations = new ArrayList<>();

        /* use same scopes as above */
        AuthorizationScope[] authorizationScopes = {
                new AuthorizationScope(""read"", ""read only""),
                new AuthorizationScope(""write"", ""read and write"") };

        /* Currently we have 2 roles - user and client */
        authorizations.add(new SecurityReference(""USER"", authorizationScopes));
        authorizations
                .add(new SecurityReference(""CLIENT"", authorizationScopes));

        return authorizations;

    }
```

An example controller method we use is:

```
    @RequestMapping (value=""/apiCallExample"", method = RequestMethod.GET)
    @ApiOperation   (value = ""Get event"", response = RestAPI.class,
                    authorizations = {
                            @Authorization(value = ""oauth2"", scopes = {
                                    @AuthorizationScope(scope = ""write"", description = ""read and write"")
                            })})
```

I am still unable to find out why this is failing, mainly because there are no error messages showing.  Am I missing something?  
","What version are you using? Could you try with 2.1.2?
","I am using version 2.1.1, I'll try with 2.1.2.
"
springfox/springfox,https://github.com/springfox/springfox/issues/858,"Externalized caches like ehcache need models to be serializable. 
Caches need to be easier to opt-in rather than be thrust on consumers.
","maybe by default springfox could use its own cacheManager which uses the concurrentMap based cache so as to not impact existing cacheManagers, and the end user would have the ability to override to use their cacheManager if they so choose? I believe spring caching abstraction supports that right?
","@cabbonizio, @rkaltreider Couple of issues that I did not foresee
- The models cached are designed to be used in-memory and not across clusters. The models are not serializable. That's the error that @rkaltreider is seeing.
- Secondly, they were introduced to improve performance of operations and models rendering. But it is not cool that its being thrust upon library consumers, whether they want to use it or not.

I went down the path of creating a cache manager thats isolated to springfox, but it seems like thats not possible with spring 4.0.x (1 version behind the latest released version). From what I could find, it seems like only one cache manager is allowed per app. I know there have been quite a few caching improvements in spring 4.1.x, but can't use those features yet.

ideas?
"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7670,"Documentation for `HttpSecurity oauth2ResourceServer(Customizer<OAuth2ResourceServerConfigurer<HttpSecurity>> oauth2ResourceServerCustomizer)` method is wrong : 

```java
protected void configure(HttpSecurity http) throws Exception {
	http
		.authorizeRequests(authorizeRequests ->
			authorizeRequests
				.anyRequest().authenticated()
		)
		.oauth2ResourceServer(oauth2ResourceServer ->
			oauth2ResourceServer
				.jwt(jwt ->
					jwt
						.jwtAuthenticationConverter(jwtDecoder())
				)
		);
}

@Bean
public JwtDecoder jwtDecoder() {
	return JwtDecoders.fromOidcIssuerLocation(issuerUri);
}
```

`jwtAuthenticationConverter` methd expects a converter, not a decoder.",Would you be interested in submitting a PR to fix the Javadoc?,
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7640,"Hi Spring security team,

I'm using the brand new SAML 2 support with Spring Boot 2.2.1 and Spring Security 5.2.1 and I have an issue using it with Microsoft ADFS.

The ADFS doesn't like having an empty `RelayState` parameter in the redirect url. A `RelayState=` or removing `RelayState` from the url make the process works.

This behavior is coming from this method :
```
private String createSamlRequestRedirectUrl(HttpServletRequest request, RelyingPartyRegistration relyingParty) {
		Saml2AuthenticationRequest authNRequest = createAuthenticationRequest(relyingParty, request);
		String xml = this.authenticationRequestFactory.createAuthenticationRequest(authNRequest);
		String encoded = encode(deflate(xml));
		String relayState = request.getParameter(""RelayState"");
		String redirect = UriComponentsBuilder
				.fromUriString(relyingParty.getIdpWebSsoUrl())
				.queryParam(""SAMLRequest"", UriUtils.encode(encoded, StandardCharsets.ISO_8859_1))
				.queryParam(""RelayState"", UriUtils.encode(relayState, StandardCharsets.ISO_8859_1))
				.build(true)
				.toUriString();
		return redirect;
	}
```

While this is probably a weird behavior from the ADFS, I think it would be better to avoid including the `RelayState` when there is no value.

What do you think about that ?

Have a nice day :)",Would you be able to submit a PR for this?,@rwinch Yes I'll try to do that tomorrow :)
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7514,"<!--
For Security Vulnerabilities, please use https://pivotal.io/security#reporting
-->

### Summary

When validating the assertion, if the IdP has provided a `SubjectConfirmation` which matches the `Bearer` method, the validation will fail.  This is due to the fact that the `OpenSamlAuthenticationProvider` does not set the necessary parameter 
```java
SAML2AssertionValidationParameters.SC_VALID_ADDRESSES
```
This parameter is used to obtain valid address and compare it to what has been provided in the assertion.  But as this parameter is not set this [code block](https://github.com/maximusfloydus/java-opensaml/blob/master/opensaml-saml-impl/src/main/java/org/opensaml/saml/saml2/assertion/impl/AbstractSubjectConfirmationValidator.java#L275-L280) fails.

### Actual Behavior

SubjectConfirmation validation fails.

### Expected Behavior

SubjectConfirmation validation should succeed.

### Configuration

<!--
Please provide any configuration you have.
-->

### Version

spring-security-5.2.0
spring-boot-2.2.0-RC1

### Sample

<!--
Providing a complete sample (i.e. link to a github repository) will give this issue higher
priority than issues that do not have a complete sample
-->

@fhanik FYI.","However, we shouldn't be failing, so what are our options? Do we provide an option to validate or disable that check? ","I agree that address validation isn't necessarily useful, but if you view the source code for `AbstractSubjectConfirmationValidator` (super class of `BearerSubjectConfirmationValidator`) you'll see that it is responsible for validating addresses.  Its implementation uses `InetAddress.getAllByName(...)` which seems to imply that it would support name resolution lookups to compare to the SP's whitelist.

The `AbstractSubjectConfirmationValidator.validateAddress` method will return `ValidationResult.INDETERMINATE` if the whitelist isn't populated by the SP and the IdP included an address in the message, but unfortunately the validator is specifically requiring that the `validateAddress` method returns a `VALID`
```java
result = validateAddress(confirmation, assertion, context);
if (result != ValidationResult.VALID) {
    return result;
}
```
From there, [OpenSamlAuthenticationProvider](https://github.com/spring-projects/spring-security/blob/master/saml2/saml2-service-provider/src/main/java/org/springframework/security/saml2/provider/service/authentication/OpenSamlAuthenticationProvider.java#L335-L340) will throw a `Saml2ErrorCodes.INVALID_ASSERTION` as the validator returned `ValidationResult.INDETERMINATE` instead of `ValidationResult.VALID`.

In summary, I think the provider should support validation of the address (which may be a hostname or IP) as well as the ability to disable (or ignore) specific `ValidationResult.INDETERMINATE` results.

#7517 Provides a solution to validate the address"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7327,"When #6215 was fixed only the adding of new `OAuth2AuthorizationRequest`s was fixed, not the removal of those. With a distributed session store we observed an increase in session size for users having long running sessions.

A dump of the keys of the session attributes revealed a huge `HashMap` of `OAuth2AuthorizationRequest`. This is due to `org.springframework.security.oauth2.client.web.server.WebSessionOAuth2ServerAuthorizationRequestRepository#removeAuthorizationRequest` only removing the `OAuth2AuthorizationRequest` from the `HashMap` and not updating the session attributes leaving no clue to the session repository that the session was amended.

The expected behaviour would be that the **stateToAuthzRequest** `HashMap` should not grow without limit and `OAuth2AuthorizationRequest` should be removed after it was used to create a new session.

Used version: spring-security-oauth2-client-5.1.6.RELEASE.jar
however the issue exists on master: https://github.com/spring-projects/spring-security/blob/master/oauth2/oauth2-client/src/main/java/org/springframework/security/oauth2/client/web/server/WebSessionOAuth2ServerAuthorizationRequestRepository.java#L85



",Would you be interested in submitting a PR for this fix?,"@jgrandja Would be happy to provide the PR.

Do you think it is of any value, if I also provide a PR with an optional facility that allows to limit the amount of `OAuth2AuthorizationRequest`s for a single session. This could be an additional session attribute backed by a size limited `LinkedHashMap` containing the `state` values as keys and an empty object as value (this would have the benefit that existing sessions can be de-serialized).

Something like:

```java
  void limitSizeOfAuthorizationRequest(
      OAuth2AuthorizationRequest oAuth2AuthorizationRequest, WebSession webSession) {
    requireNonNull(oAuth2AuthorizationRequest, ""oAuth2AuthorizationRequest must not be null"");
    requireNonNull(webSession, ""webSession must not be null"");

    removeOldAuthorizationRequest(
        storeMostRecentAuthorizationRequests(oAuth2AuthorizationRequest, webSession), webSession);
  }

  private Map<String, String> storeMostRecentAuthorizationRequests(
      OAuth2AuthorizationRequest oAuth2AuthorizationRequest, WebSession webSession) {

    SizeLimitedHashMap<String, String> workingSet =
        webSession.getAttribute(DEFAULT_AUTHORIZATION_REQUEST_LIMIT_ATTR_NAME);
    if (workingSet == null) {
      workingSet = new SizeLimitedHashMap<>(limit);
    }

    workingSet.put(oAuth2AuthorizationRequest.getState(), SOME_VALUE);

    if (LOG.isDebugEnabled()) {
      LOG.debug(""The current active auth request states are: {}"", workingSet.keySet());
    }

    webSession.getAttributes().put(DEFAULT_AUTHORIZATION_REQUEST_LIMIT_ATTR_NAME, workingSet);
    return workingSet;
  }

  private void removeOldAuthorizationRequest(
      Map<String, String> workingSet, WebSession webSession) {
    Map<String, OAuth2AuthorizationRequest> oAuth2AuthorizationRequests =
        webSession.getAttribute(DEFAULT_AUTHORIZATION_REQUEST_ATTR_NAME);

    if (oAuth2AuthorizationRequests == null) {
      return;
    }

    if (LOG.isDebugEnabled()) {
      LOG.debug(
          ""Auth request state keys before cleanup: {}"", oAuth2AuthorizationRequests.keySet());
    }

    oAuth2AuthorizationRequests.keySet().retainAll(workingSet.keySet());

    if (LOG.isDebugEnabled()) {
      LOG.debug(""Auth request state keys after cleanup: {}"", oAuth2AuthorizationRequests.keySet());
    }

    webSession
        .getAttributes()
        .put(DEFAULT_AUTHORIZATION_REQUEST_ATTR_NAME, oAuth2AuthorizationRequests);
  }
```
```java
public class SizeLimitedHashMap<TKey extends Serializable, TValue extends Serializable>
    extends LinkedHashMap<TKey, TValue> implements Serializable {

  private static final long serialVersionUID = -4358903105100110082L;

  private final int limit;

  SizeLimitedHashMap(int limit) {
    this.limit = limit;
  }

  @Override
  protected boolean removeEldestEntry(Entry<TKey, TValue> eldest) {
    return this.size() > limit;
  }
}
```"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7290,"### Summary

The NimbusJwtDecoderJwkSupport is not able to retrieve the JWK Set because it gets a HTTP 406 (Not Accepted). It tries to retrieve it from an endpoint that only produces the media-type application/jwk-set+json. This media-type is the proper media-type for this kind of endpoint as specified in https://tools.ietf.org/html/rfc7517. This new behaviour is introduced around the release of version 5.1.


### Actual Behavior

The NimbusJwtDecoderJwkSupport gets a HTTP 406 when trying to retrieve a JWK Set from an endpoint that only produces the media-type application/jwk-set+json.


### Expected Behavior

The NimbusJwtDecoderJwkSupport gets a HTTP 200 when trying to retrieve a JWK Set from an endpoint that only produces the media-type 'application/jwk-set+json'. 


### Configuration

The endpoint produces only the media-type application/jwk-set+json. This looks like this in the code: 
`@GetMapping(value = ""/jwk"", produces = com.nimbusds.jose.jwk.JWKSet.MIME_TYPE)`

### Version

It seems the change in behaviour is introduced here:

https://github.com/spring-projects/spring-security/commit/16fe1c5b52633399ff51ed022d23024ab65d0a70 (line 183)

In this commit the RestOperationsResourceRetriever is introduced in the NimbusJwtDecoderJwkSupport class. Before this commit a DefaultResourceRetriever was used. The latter uses an HttpURLConnection to retrieve the JWK Set (WITHOUT an Accept request header). The former uses a RestOperations (WITH an Accept request header with the value 'application/json;charset=UTF-8').

### Sample

I tried to find a public endpoint that only produces the media-type application/jwk-set+json. I was not able able to find one and therefore I cannot provide a working sample to demonstrate this problem.

### Proposed solution

Add the media-type 'application/jwk-set+json' to the Accept request header in the RestOperationsResourceRetriever.
",Would you be interested in submitting a PR?,I am interested in submitting a PR. I will try this today.
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7261,"**Component:** spring-security-web-5.1.3.RELEASE.jar (also with latest 5.1.6)

**TL;DR:** Filters relying on OnCommittedResponseWrapper do not work when a response length  is announced with `ServletResponse.setContentLengthLong` before it is written.

Hey guys. I've noticed, that my HeaderWriters are not triggered for responses served by Tomcats 8.5's default servlet. I've found that the `OnCommittedResponseWrapper.onResponseCommitted` is never triggered. Debugging through the filter chain I've noticed that tomcats `org.apache.catalina.servlets.DefaultServlet` uses `ServletResponse.setContentLengthLong` (see https://github.com/apache/tomcat/blob/8.5.45/java/org/apache/catalina/servlets/DefaultServlet.java#L1063) instead of `ServletResponse.setContentLength`, which is not covered by `OnCommittedResponseWrapper` (see https://github.com/spring-projects/spring-security/blob/f3cdd44350156ffd84b73612f4aab90492054699/web/src/main/java/org/springframework/security/web/util/OnCommittedResponseWrapper.java#L67). Is there any reason why this method is not covered by committed-detection or is it simply an overlooked method during migration to servlet 3.1? 

Keep up the good work!



",Can you please put together a minimal sample to reproduce the issue?,"Here comes the reproducer (sort of, not necessarily tomcat specific): https://gist.github.com/danielwegener/6fe53c3f4625c1761de4507a3dbefe2b
Note that the underscores in filenames are directory separators.

When calling `GET http://localhost:8080/test.html` (served by tomcats DefaultServlet, important: call it without a cached version!) or `GET http://localhost:8080/resourcelike/sucks` you won't see any CSP response header."
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7166,"I am not good at English. So, please forgive my grammatical mistakes.

I have a problem while config `HttpSecurity.sessionManagement().maximumSessions(1)`. I hope a user only have one valid session at the same time.

 If I login at browser A，and then login at browser B. It's run perfect and session in browser A will invalid.

But if I login at browser A,  then login at browser A(
In other words, I'm called the `/login` interface twice in the same browser.), then login at browser B. I found both browsers can access the restricted interfaces.

---

I viewed source code, found there have three `SessionAuthenticationStrategy`: `ConcurrentSessionControlAuthenticationStrategy`, `ChangeSessionIdAuthenticationStrategy`, `RegisterSessionAuthenticationStrategy`. I tried to debug with source code and the following happened:

While the second time login at browser A, `ConcurrentSessionControlAuthenticationStrategy` find the same sessionId, so it do noting. But `ChangeSessionIdAuthenticationStrategy` change sessionId into a new sessionId, and `RegisterSessionAuthenticationStrategy` think it's a new session and store. so there is two session in session registry.

Did I miss some configuration to resolve this problem?

My spring security version is 5.1.5.RELEASE. Think you very much!
",Can you explain by what you mean by this? How do you login A browser and login A browser again?,Thank you for taking the time to look at my issue.I tried to complete my question.
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/7035,"### Summary

_spring-security_ allows to define hierarchical roles to offer a convenient means of simplifying the access-control configuration data. When you provide hierarchy definition with cycle that does not include currently resolved role, resolving process will fall into infinite loop.

### Actual Behavior

Resolving of role hierarchy is not able to correctly detect cycle when currently resolved role is not included in the cycle. Resolving process falls into infinite loop.

### Expected Behavior

`CycleInRoleHierarchyException` should be thrown.

### Version

5.2.0.M3, 5.1.5.RELEASE

### Sample

Add provided test fragment into `RoleHierarchyImplTests#testCyclesInRoleHierarchy` [1].

```
try {
    roleHierarchyImpl.setHierarchy(""ROLE_C > ROLE_B\nROLE_B > ROLE_A\nROLE_A > ROLE_B"");
    fail(""Cycle in role hierarchy was not detected!"");
} catch (CycleInRoleHierarchyException e) {
}
```
I am probably able to resolve the issue and submit pull request. But i have to say that current implementation of role hierarchy resolving looks little strange. For example this condition [2] is completely useless?. 

[1] https://github.com/spring-projects/spring-security/blob/5.1.5.RELEASE/core/src/test/java/org/springframework/security/access/hierarchicalroles/RoleHierarchyImplTests.java#L139
[2] https://github.com/spring-projects/spring-security/blob/5.1.5.RELEASE/core/src/main/java/org/springframework/security/access/hierarchicalroles/RoleHierarchyImpl.java#L220","Can we use lambdas, new collection methods and other goodies from Java 8 (not that we will necessarily use them, but want to know the limits)?",We have created pull request #7106 that resolves the original issue. The pull request to resolve appendix issue has not been created yet. Maybe it should be processed in dedicated issue?.
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6890,"Use case:

We have a system A use OAuth2Login to implement user login(Code flow). And another system B works as OAuth2 provider.

Step 1: A supervisor login system A. Everything works well.
Step 2: Supervisor close browser without logout. System A session is still available.
Step 3: A non-privilege user login system B to do something, Everything works well. Session of system B is reset to non-privilege user.
Step 4: The non-privilege user **login system A from login page**, but found that the login user is actually supervisor. (Reuse the previous supervisor session)

Expected: At step 4, since non-privilege user start a new login process from login page, we expected non-privilege user login finally.

After debug, we found that at step 4, the login process of system A have got the oauth2 code (Code flow) and redirected to the redirect url, but the redirect url is not processed correctly and skipped since the following code.

https://github.com/spring-projects/spring-security/blob/b1195e7789521845752b91677285f9ff5eeeb6b0/config/src/main/java/org/springframework/security/config/web/server/ServerHttpSecurity.java#L851-L855

Since the existence of the previous session, the process of redirect url is skipped. And the previous session is reused incorrectly.

AFAIK the process of redirect url is used to validate oauth2 code and retrieve user/token info and cannot be skipped. So it looks a security issue.

And since the process of redirect url is skipped, the saved authentication request cannot be removed from (in memory) session and potential run out server memory.
 ","Can you please test your scenario using a different browser (or new session window) and let me know your results?

FYI, we also introduced support (in 5.2.0.M2) for RP (Client) initiated logout via #5350, which would allow you to configure the application to logout at the provider whenever the user logs out of the application.

","@jgrandja 

Thanks for your reply. I'm aware that two different sessions exist for application and provider.

At Step 3, a non-privilege user login system B (Provider), so the session of provider is for non-privilege user.

> a non-privilege user attempts to authenticate via the application than authentication will automatically happen given that there is an existing session cookie (in the browser) with the provider.

Yes, it is expected. 

But finally application shows that the login user is supervisor.

The reason is that since the session of system A (application) for supervisor still available during login process, the login process is aborted due to following code.

https://github.com/spring-projects/spring-security/blob/b1195e7789521845752b91677285f9ff5eeeb6b0/config/src/main/java/org/springframework/security/config/web/server/ServerHttpSecurity.java#L851-L855

Since at step 4, the non-privilege user start a new login process to application, the login process should not be aborted no matter a previous session exists or not."
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6812,"This issue is related to #6638.
I use single OpenIDC IdP (google) from [OAuth2Login Sample](https://github.com/spring-projects/spring-security/tree/5.1.3.RELEASE/samples/boot/oauth2login). Added a rest endpoint that use the same security configuration. When an ajax request to the rest endpoint with an expired JSESSIONID or no JESSIONID at all, the response is a redirect to google IdP. The redirect will be blocked by the browser since cross domain redirect is not allowed in CORS policy.

After tracing the code a little bit, and found the request matcher logic in `OAuth2LoginConfigurer` might contribute to this behavior:
https://github.com/spring-projects/spring-security/blob/5aacd0c9550e87360fde3ddd71f02c6d0029ff4f/config/src/main/java/org/springframework/security/config/annotation/web/configurers/oauth2/client/OAuth2LoginConfigurer.java#L450

https://github.com/spring-projects/spring-security/blob/5aacd0c9550e87360fde3ddd71f02c6d0029ff4f/config/src/main/java/org/springframework/security/config/annotation/web/configurers/oauth2/client/OAuth2LoginConfigurer.java#L619-L634

The `defaultEntryPointMatcher` will filter out XMLHttpRequest. Should the `entryPoints` be something like
```
entryPoints.put(new OrRequestMatcher(new NegatedRequestMatcher(defaultLoginPageMatcher), defaultEntryPointMatcher),
				new LoginUrlAuthenticationEntryPoint(providerLoginPage));
```
Then the AJAX call to data will simply got 401 instead of a redirect, which the browser will block since it will be a cross domain redirect.

_Originally posted by @simpleway in https://github.com/spring-projects/spring-security/issues/6638#issuecomment-483814974_",Would you be interested in submitting a PR?,"@rwinch Sure, I can work on a PR.
In the meanwhile, I found a workaround for this issue.
Add the following in customized `WebSecurityConfigurerAdapter.configure(HttpSecurity)` method
```
LinkedHashMap<RequestMatcher, AuthenticationEntryPoint> entryPoints = new LinkedHashMap<>();
entryPoints.put(new RequestHeaderRequestMatcher(""X-Requested-With"", ""XMLHttpRequest""), new HttpStatusEntryPoint(HttpStatus.UNAUTHORIZED));

DelegatingAuthenticationEntryPoint nonAjaxLoginEntryPoint = new DelegatingAuthenticationEntryPoint(entryPoints);
nonAjaxLoginEntryPoint.setDefaultEntryPoint(new LoginUrlAuthenticationEntryPoint(""/oauth2/authorization/google""));

http.authorizeRequests()
       .anyRequest().fullyAuthenticated()
       .and()
       .oauth2Login()
       .and()
       .exceptionHandling().authenticationEntryPoint(nonAjaxLoginEntryPoint)
```
Not ideal, since hardcoded OpenID Connect provider login page, but good enough to overwrite the default behavior."
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6809,"### Summary
In Spring Security documentation in the hello-web example here:
   https://docs.spring.io/spring-security/site/docs/5.1.5.RELEASE/reference/htmlsingle/#hello-web-security-java-configuration
the code is:
```
@EnableWebSecurity
public class WebSecurityConfig implements WebMvcConfigurer {
``` 
This suggests that custom implementation of `WebMvcConfigurer` interface is the standard way of Spring Security configuration.

Further down in the documentation usage of `WebSecurityConfigurerAdapter` is mentioned and multiple examples of `void configure(HttpSecurity http)` customization are given. 

This raises confusion about the role of `WebMvcConfigurer` in Spring Security and the use cases for `WebMvcConfigurer` vs `WebSecurityConfigurerAdapter`.

Most likely the intention in the example was:
```
@EnableWebSecurity
public class WebSecurityConfig implements WebSecurityConfigurerAdapter {
```
instead of
```
@EnableWebSecurity
public class WebSecurityConfig implements WebMvcConfigurer {
```

### Version
5.1.5

### Sample

Not only I got confused, Stackoverflow discussing the same:
https://stackoverflow.com/questions/53894649/difference-between-webmvcconfigurer-and-websecurityconfigureradapter",Would you be able to submit a PR with the needed change?,
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6773,"I guess there is a bug in org.springframework.security.core.authority.AuthorityUtils.java
```
public static Set<String> authorityListToSet(
		Collection<? extends GrantedAuthority> userAuthorities) {

/* No test parameters  userAuthorities, it may be null and led to NullPointException */

		Set<String> set = new HashSet<>(userAuthorities.size());
		for (GrantedAuthority authority : userAuthorities) {
		set.add(authority.getAuthority());
	}
	return set;
}
```",Would you like to contribute a PR that adds an `Assert` to the beginning of this method?,"@jzheaux Well,i will fix this bug and contribute a PR later, thanks for your supporting."
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6503,"### Summary

When a WebClient (configured with ServletOAuth2AuthorizedClientExchangeFilterFunction) automatically refresh an access token using an available refresh token, the refresh token may be lost, preventing any further refresh. 
This happen when the authorization server doesn't return the refresh token on the Token Endpoint response (Which is the case of Google)

This issue seems to be the same than this one on the old Spring Security Oauth module : https://github.com/spring-projects/spring-security-oauth/issues/712

### Actual Behavior

On a Spring Boot Application using Spring Security 5, OAuth2 AuthorizedClient feature (with authorization code grant type)
And with a custom OAuth2AuthorizedClientService implementation that can persist AuthorizedClient durably (in a file for me)

When a user authorizes the application to access its Google resources : an AuthorizedClient with an access_token and a refresh_token is stored in OAuth2AuthorizedClientService.
After that the application can access theses Google resources correctly with a webClient configured with ServletOAuth2AuthorizedClientExchangeFilterFunction.

Later (more than 1 hour), another access to its Google resources triggers a token refresh : this works but Google doesn't send another refresh_token (the old one is still valid). Consequently, the new persisted AuthorizedClient  in OAuth2AuthorizedClientService doesn't have any refresh token. 

More than another hour later : another access to the user's Google resources fails because the WebClient doesn't have any refresh token anymore to refresh the old access token.

( Note : with Google, it's should be necessary to use the param access_type=offline to get a durable refresh_token. So https://github.com/spring-projects/spring-security/issues/5760 is necessary)

### Expected Behavior

Expected Behavior is that when refreshing the access token for the first time, the old refresh_token is saved (if no new refresh_token is provided), so that it is possible to refresh the access_token more than once after ( and as long as the refresh_token is still valid )

### Version

Spring Security 5.2.0.M1
",Would you be interested in submitting a PR for this fix?,"Hi @jgrandja
I tried to submit a PR. Hope the test I add is enough

FYI : it does fix my issue on my project"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6423,"### Summary

We use multiple XML configuration for different realms. If CSRF is not disabled, the application startup fails beause of multiple registrations of requestDataValueProcessor bean.

### Actual Behavior

see org.springframework.security.config.http.CsrfBeanDefinitionParser.parse()
```

		boolean webmvcPresent = ClassUtils.isPresent(DISPATCHER_SERVLET_CLASS_NAME,
				getClass().getClassLoader());
		if (webmvcPresent) {
			RootBeanDefinition beanDefinition = new RootBeanDefinition(
					CsrfRequestDataValueProcessor.class);
			BeanComponentDefinition componentDefinition = new BeanComponentDefinition(
					beanDefinition, REQUEST_DATA_VALUE_PROCESSOR);
			pc.registerBeanComponent(componentDefinition);
		}

```

unconditionally registers bean

### Expected Behavior

CsrfBeanDefinitionParser should check presence?

### Version

version 5.1.3

### Sample

This will not start

```
	<bean id=""errorAuthenticationEntryPoint""
		class=""org.springframework.security.web.authentication.Http403ForbiddenEntryPoint"" />
 	<security:http name=""securityRealmControl"" pattern=""/api/v1/control/**"" entry-point-ref=""errorAuthenticationEntryPoint"">
		<security:intercept-url pattern=""/**"" access=""hasRole('OPERATOR')"" />
	</security:http>
 	<security:http name=""securityRealmFlow"" pattern=""/api/v1/flow/**"" entry-point-ref=""errorAuthenticationEntryPoint"">
		<security:intercept-url pattern=""/api/v1/flow/*/create"" access=""hasRole('USER')"" />
	</security:http>

```
",Can you please provide a minimal and complete sample to reproduce the problem?,[Here](https://github.com/mtraut/SpringIssue6423) you are....
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6417,"### Summary
Invalid html in spring-security/web/src/main/java/org/springframework/security/web/authentication/defaultLoginPageGeneratingFilter.java::generateLoginPageHtml.

### Actual Behavior
div class=""container"" at line 237 is not closed.  Closing div required around line 291 before ""</body>"".

Page does not validate, but Chrome gracioiusly display the page correctly.

### Expected Behavior
Pass validation test.

### Configuration
n/a

### Version
org.spring.framework.boot,l artifactID spring-boot-starter-security version 2.1.0.RELEASE

### Sample
",Would you be interested in submitting a PR for this?,"What’s a PR?  (Pull Request + submission with fix?)

 

From: Rob Winch [mailto:notifications@github.com] 
Sent: Tuesday, January 15, 2019 4:37 AM
To: spring-projects/spring-security
Cc: bestwmm; Mention
Subject: Re: [spring-projects/spring-security] Invalid html in default login page (#6417)

 

Thanks for the report @bestwmm <https://github.com/bestwmm> ! Would you be interested in submitting a PR for this?

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub <https://github.com/spring-projects/spring-security/issues/6417#issuecomment-454133604> , or mute the thread <https://github.com/notifications/unsubscribe-auth/AGOuSq5lr-tO_ceRccidZgl9AX5L2nj5ks5vDNxygaJpZM4Z8bRV> .  <https://github.com/notifications/beacon/AGOuSsafOFPzynhoQ0M2HsgqX9IqJm2Jks5vDNxygaJpZM4Z8bRV.gif> 

"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6341,"### Summary
When configuring a WebFlux application as an OAuth2 Client using an authentication_code grant type and without implementing the OAuth2Login feature, the application redirects to the ""/"" path after authenticating in the Authentication Server instead of redirecting back to the original request

### Actual Behavior

1-Calling an endpoint in an OAuth2 Client application (without using OAuth2 login) using Auth code Grant type
2- Authenticate in the Authorization Server
3- Get redirected to the /authorize/oauth2/code/[myclient] endpoint
4- Get redirected to the root (""/"") URL

### Expected Behavior

1-Calling an endpoint in an OAuth2 Client application (without using OAuth2 login) using Auth code Grant type
2- Authenticate in the Authorization Server
3- Get redirected to the /authorize/oauth2/code/[myclient] endpoint
**4- Get redirected to the endpoint we called in the first place**

### Configuration

1- Set up an application with the following using the following ServerHttpSecurity configuration:
```
@Bean
public SecurityWebFilterChain springSecurityFilterChain(ServerHttpSecurity http) {
    http.authorizeExchange()
        .anyExchange()
        .permitAll()
        .and()
        .oauth2Client();
    return http.build();
}
```
2- A client registration:
```
spring.security.oauth2.client.registration.myclient.client-name=myclient
spring.security.oauth2.client.registration.myclient.client-id=myclient-client-id
spring.security.oauth2.client.registration.myclient.client-secret=myclient-secret
spring.security.oauth2.client.registration.myclient.authorization-grant-type=authorization_code
spring.security.oauth2.client.registration.myclient.redirect-uri-template=http://localhost:8080/authorize/oauth2/code/myclient

spring.security.oauth2.client.provider.myclient.token-uri=http://localhost:8085/oauth/token
spring.security.oauth2.client.provider.myclient.authorization-uri=http://localhost:8085/oauth/authorize
```
Note: In my case, I set up the Client registration using Spring Boot 2.x. The client is registered in a custom Authentication Provider that I configured using Spring Security Oauth, but the issue should be present for well-known providers as well.

3- Configure the WebClient:
```
@Bean
    WebClient webClient(ReactiveClientRegistrationRepository clientRegistrations, ServerOAuth2AuthorizedClientRepository authorizedClients) {
        ServerOAuth2AuthorizedClientExchangeFilterFunction oauth = new ServerOAuth2AuthorizedClientExchangeFilterFunction(clientRegistrations, authorizedClients);
        oauth.setDefaultClientRegistrationId(""myclient"");
        return WebClient.builder()
            .filter(oauth)
            .build();
    }
```
4-And the endpoint that I'm using:
```
@RestController
public class ClientRestController {

    private static final String RESOURCE_URI = ""http://localhost:8084/retrieve-resource"";

    @Autowired
    WebClient webClient;

    @GetMapping(""/auth-code-oauth"")
    Mono<String> useOauthWithAuthCode(@RegisteredOAuth2AuthorizedClient(""myclient"") OAuth2AuthorizedClient authorizedClient) {
        Mono<String> retrievedResource = webClient.get()
            .uri(RESOURCE_URI)
            .attributes(oauth2AuthorizedClient(authorizedClient))
            .retrieve()
            .bodyToMono(String.class);
        return retrievedResource.map(string -> ""We retrieved the following resource using Oauth: "" + string);
    }
}
```
5- Now call the `/auth-code-oauth` endpoint. We get redirected to the Authentication login form, approve the required scopes, and after being redirected to the specified redirect-uri (/authorize/oauth2/code/myclient) the application retrieves the token, and we are redirected to the root (""/"") url, instead of the endpoint that I actually called in the first place. If I make the call to the `/auth-code-oauth` endpoint again afterwards, the retrieved response is the expected, since no authentication process is carried out at this point.

Included a link to the sample by the end of the description

### Version

Spring Boot 2.1.1.RELEASE
Spring Security: 5.1.2.RELEASE

### Sample

https://github.com/rozagerardo/samples
",Would you be interested in submitting a PR for this?,"Thanks for the quick response @rwinch 
Sure, I'll be glad to work on this :)
This will be my first contribution to the project, so it might take me a little bit longer than expected, to get familiarized with the contributor's guidelines
I'll come back as soon as I have the PR ready"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6215,"I got the following error message and after the whole day debug, I found that oauth2 client failed to save `AuthorizationRequest` to session in some case.

```
Resolved [OAuth2AuthorizationException: [authorization_request_not_found] ]
```

To trigger the issue, you have to:
1. With reactor server
2. Configure redis session. (or hazelcast session)
3. Some errors happened before and one or more legacy `AuthorizationRequest` leaved in the session

Result:
Oauth2 client will continue failing with error `authorization_request_not_found`

Root cause:

in ReactiveRedisOperationsSessionRepository.java

```
	@Override
	public Mono<Void> save(RedisSession session) {
		Mono<Void> result = session.saveChangeSessionId().and(session.saveDelta())
				.and((s) -> {
					session.isNew = false;
					s.onComplete();
				});
		if (session.isNew) {
			return result;
		}
		else {
			String sessionKey = getSessionKey(
					session.hasChangedSessionId() ? session.originalSessionId
							: session.getId());
			return this.sessionRedisOperations.hasKey(sessionKey)
					.flatMap((exists) -> exists ? result
							: Mono.error(new IllegalStateException(
									""Session was invalidated"")));
		}
	}
```

Only the delta data `session.saveDelta()` will be update in redis session.

And the delta is captured by `WebSession::getAttributes::setAttribute`

```
	@Override
	public void setAttribute(String attributeName, Object attributeValue) {
		this.cached.setAttribute(attributeName, attributeValue);
		putAndFlush(getAttributeKey(attributeName), attributeValue);
	}

	private void putAndFlush(String a, Object v) {
		this.delta.put(a, v);
		flushImmediateIfNecessary();
	}
``` 


But In WebSessionOAuth2ServerAuthorizationRequestRepository.java

It get state to AuthorizationRequest map from session's attribute and update its value, And does not put the map back to session's attribute again by calling `setAttribute`. So redis session will not capture such change and fail to update the modification.

```
	@Override
	public Mono<Void> saveAuthorizationRequest(
			OAuth2AuthorizationRequest authorizationRequest, ServerWebExchange exchange) {
		Assert.notNull(authorizationRequest, ""authorizationRequest cannot be null"");
		return getStateToAuthorizationRequest(exchange, true)
				.doOnNext(stateToAuthorizationRequest -> stateToAuthorizationRequest.put(authorizationRequest.getState(), authorizationRequest))
				.then();
	}

	private Mono<Map<String, OAuth2AuthorizationRequest>> getStateToAuthorizationRequest(ServerWebExchange exchange, boolean create) {
		Assert.notNull(exchange, ""exchange cannot be null"");

		return getSessionAttributes(exchange)
			.doOnNext(sessionAttrs -> {
				if (create) {
					sessionAttrs.putIfAbsent(this.sessionAttributeName, new HashMap<String, OAuth2AuthorizationRequest>());
				}
			})
			.flatMap(sessionAttrs -> Mono.justOrEmpty(this.sessionAttrsMapStateToAuthorizationRequest(sessionAttrs)));
	}

	private Map<String, OAuth2AuthorizationRequest> sessionAttrsMapStateToAuthorizationRequest(Map<String, Object> sessionAttrs) {
		return (Map<String, OAuth2AuthorizationRequest>) sessionAttrs.get(this.sessionAttributeName);
	}
```

And then `authorization_request_not_found` will be raised since `AuthorizationRequest` is not in session.


",Can you provide a complete sample?,"Distributed session implementation such as redis and hazelcast, only update the modified part of session data to session storage.

And the session modification is captured by calling `WebSession::setAttribute`. Only modify session data's value without calling `setAttribute`, session data will not be updated anyway.

For example:

The following code will NOT add (""key"", ""value"") to session key`A_DICT_TYPE_SESSION_KEY`'s value, if use redis or hazelcast based distributed session.

```
WebSession session = ...
Map<String, String> data = (Map<String, String>)session.getAttribute(""A_DICT_TYPE_SESSION_KEY"");
data.put(""key"", ""value"");
```

You have to add `setAttribute` to the end like this.

```
WebSession session = ...
Map<String, String> data = (Map<String, String>)session.getAttribute(""A_DICT_TYPE_SESSION_KEY"");
data.put(""key"", ""value"");

// The following line looks redundant but is important for redis or hazelcast based distributed session.
// It is used to tell redis or hazelcast that session data with key ""A_DICT_TYPE_SESSION_KEY"" has been updated.
session.setAttribute(""A_DICT_TYPE_SESSION_KEY"", data);
```

`setAttribute` is overwrite by redis or hazelcast based distributed session to capture session data's modification.

For the above reason, we finally got ""authorization_request_not_found"" in some case since the code failed to update session's data.
"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/6089,"<!--
For Security Vulnerabilities, please use https://pivotal.io/security#reporting
-->

### Summary

If anything but a 2xx status is returned (i.e. a redirect) when trying to get the token, we should fail


See #6071","maybe something like this? 🤔

`.filterWhen(response -> Mono.just(response.statusCode().is2xxSuccessful()))`

```java
return this.webClient.post()
					.uri(tokenUri)
					.accept(MediaType.APPLICATION_JSON)
					.headers(headers(clientRegistration))
					.body(body)
					.exchange()
					.filterWhen(response -> Mono.just(response.statusCode().is2xxSuccessful()))
					.flatMap(response -> response.body(oauth2AccessTokenResponse()))
					.map(response -> {
						if (response.getAccessToken().getScopes().isEmpty()) {
							response = OAuth2AccessTokenResponse.withResponse(response)
								.scopes(authorizationGrantRequest.getClientRegistration().getScopes())
								.build();
						}
						return response;
					});
		});
´´´","Thanks for the comment!

* You can simplify it using .filter which does not require a `Mono`
* We should `switchIfEmpty` with a `Mono.error` that contains a message stating that the attempt to get the token returned an unsuccessful status along with the status code.

Would you like to take this one @raphaelDL?"
spring-projects/spring-security,https://github.com/spring-projects/spring-security/issues/5770,"https://github.com/spring-projects/spring-security/blob/master/web/src/main/java/org/springframework/security/web/authentication/preauth/x509/SubjectDnX509PrincipalExtractor.java#L39

In the source from above and **also** in the documentation this example is mentioned:

`emailAddress=(.?),`

I believe this wont work, because an valid E-Mail consists of more than one character.

I propose to change it to

`emailAddress=(.*?),`

which works in my use case.",Would you be interested in submitting a PR to fix this?,I'll have a look at it. May take some time.
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1515,"I have found that RedisSessionExpirationPolicy class method onDelete can not delete.
My version is 2.1.8 and the code is 
this.redis.boundSetOps(expireKey).remove(session.getId())
is the key wrong?  shoud be ""expires:"" + session.getId().
","Could you clarify what exactly is the problem, and how to reproduce it?",
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1514,"I recently upgrade one of our projects to use latest version 2.1.8 from 2.0.7 and we faced following issue:

in previous version it used to format the expiry date as GMT without time offset regardless of the server timezone. but last version will format the expiry in time offset representation (+HHMM) if the server time zone  is not GMT.

It's like Browsers (IE, Chrome) they don't like to see anything beside GMT. in our case the are expiring the cookie unexpectedly. 

for workaround we changed server time zone to GMT.

basically following line is responsible to format the time:

sb.append(""; Expires="").append(expires.format(DateTimeFormatter.RFC_1123_DATE_TIME));

and browsers suppose to support RFC_1123 I guess, but it seems they don't like anything but GMT.

  ",Could you provide concrete cookies exactly how they appear for you in Spring Session 2.0 vs 2.1? Can you also provide some example that reproduces this problem?,
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1489,Related to https://github.com/spring-projects/spring-security/issues/7261,"Did you consider backporting this to `2.1.x`? From the description, it sounds more like a bug than an enhancement to me.","Going point, @vpavic, I'll make sure it gets backported. I'll also reclassify this as a bug."
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1399,"While working on a Spring WebFlux application secured via OAuth2 (Spring Boot 2, Spring Cloud Gateway, Spring Security, Spring Session Redis) I observed users receiving a 500 status code caused by an IllegalStateEx raised by `ReactiveRedisOperationsSessionRepository#save`.

Imho for `spring-data-redis-2.2.0.M2` the issue is that `ReactiveRedisOperationsSessionRepository#saveDelta` is called two times (WebSessionServerCsrfTokenRepository and WebSessionServerSecurityContextRepository) and both receive a reference to `this.delta` with entries at creation time, on execution time when the first finishes `this.delta` is cleared and the second call fails due to an empty map. 

### Simple sample:
https://github.com/AndreasKl/issue-in-spring-session-redis/tree/master

When I bump the version to *Spring Boot 2.1.3* a slightly different behaviour with an additional exception occurs.

### Steps to reproduce:
* Start the application
* Navigate to http://localhost:8080/login
* Login with user: user pw: 123456
* Navigate to http://localhost:8080/logout
* Press ""Log Out""
* Observe the error page and the following stacktrace in your log:

```
java.lang.IllegalStateException: Session was invalidated
	at org.springframework.session.data.redis.ReactiveRedisOperationsSessionRepository.lambda$save$2(ReactiveRedisOperationsSessionRepository.java:159) ~[spring-session-data-redis-2.1.3.RELEASE.jar:2.1.3.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:118) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:76) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:123) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:121) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:76) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:73) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onNext(MonoFlatMapMany.java:238) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:275) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:849) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:121) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:121) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:353) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:76) ~[reactor-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]
	at io.lettuce.core.RedisPublisher$RedisSubscription.onNext(RedisPublisher.java:270) ~[lettuce-core-5.1.3.RELEASE.jar:na]
	at io.lettuce.core.RedisPublisher$SubscriptionCommand.complete(RedisPublisher.java:754) ~[lettuce-core-5.1.3.RELEASE.jar:na]
	at io.lettuce.core.protocol.CommandHandler.complete(CommandHandler.java:646) ~[lettuce-core-5.1.3.RELEASE.jar:na]
	at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:604) ~[lettuce-core-5.1.3.RELEASE.jar:na]
	at io.lettuce.core.protocol.CommandHandler.channelRead(CommandHandler.java:556) ~[lettuce-core-5.1.3.RELEASE.jar:na]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799) ~[netty-transport-native-epoll-4.1.31.Final-linux-x86_64.jar:4.1.31.Final]
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:433) ~[netty-transport-native-epoll-4.1.31.Final-linux-x86_64.jar:4.1.31.Final]
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:330) ~[netty-transport-native-epoll-4.1.31.Final-linux-x86_64.jar:4.1.31.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) ~[netty-common-4.1.31.Final.jar:4.1.31.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.31.Final.jar:4.1.31.Final]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Assembly trace from producer [reactor.core.publisher.MonoFlatMap] :
	reactor.core.publisher.Mono.flatMap(Mono.java:2491)
	org.springframework.session.data.redis.ReactiveRedisOperationsSessionRepository.save(ReactiveRedisOperationsSessionRepository.java:159)
Error has been observed by the following operator(s):
	|_	Mono.flatMap ⇢ org.springframework.session.data.redis.ReactiveRedisOperationsSessionRepository.save(ReactiveRedisOperationsSessionRepository.java:159)
	|_	Flux.concat ⇢ org.springframework.http.server.reactive.AbstractServerHttpResponse.doCommit(AbstractServerHttpResponse.java:234)
	|_	Flux.then ⇢ org.springframework.http.server.reactive.AbstractServerHttpResponse.doCommit(AbstractServerHttpResponse.java:234)
	|_	Mono.doOnError ⇢ org.springframework.http.server.reactive.AbstractServerHttpResponse.writeWith(AbstractServerHttpResponse.java:179)
	|_	Mono.flatMap ⇢ org.springframework.http.codec.EncoderHttpMessageWriter.write(EncoderHttpMessageWriter.java:126)
	|_	Mono.flatMap ⇢ org.springframework.boot.autoconfigure.web.reactive.error.AbstractErrorWebExceptionHandler.handle(AbstractErrorWebExceptionHandler.java:247)
	|_	Mono.onErrorResume ⇢ org.springframework.web.server.handler.ExceptionHandlingWebHandler.handle(ExceptionHandlingWebHandler.java:68)
	|_	Mono.error ⇢ org.springframework.web.server.handler.ResponseStatusExceptionHandler.handle(ResponseStatusExceptionHandler.java:67)
	|_	Mono.onErrorResume ⇢ org.springframework.web.server.handler.ExceptionHandlingWebHandler.handle(ExceptionHandlingWebHandler.java:68)
	|_	Mono.doOnSuccess ⇢ org.springframework.web.server.adapter.HttpWebHandlerAdapter.handle(HttpWebHandlerAdapter.java:247)
```","Can you confirm this?

/cc @rwinch","Hi, @vpavic thanks for looking into this issue. 

I can't reproduce the issue on spring-security-core 5.0.12, however the 5.0.x release does not contain a CSRF-filter for Webflux; therefore only one saveDelta call is executed.

I'll try to create an unit test to reproduce the issue in an isolated environment.

"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1308,"### Summary

Spring Security throws the exception when Spring-session is in use and CSRF token has not been provided.

### Actual Behavior

When Spring security and Spring-session is used in application, when CSRF token is not provided, Spring security throws following exception:

```
java.lang.IllegalStateException: Cannot invoke saveContext on response org.springframework.security.web.firewall.FirewalledResponse@10d467dc. You must use the HttpRequestResponseHolder.response after invoking loadContext
	at org.springframework.security.web.context.HttpSessionSecurityContextRepository.saveContext(HttpSessionSecurityContextRepository.java:144) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:115) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.access.channel.ChannelProcessingFilter.doFilter(ChannelProcessingFilter.java:157) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:75) ~[spring-session-core-2.1.2.RELEASE.jar:2.1.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:566) ~[jetty-security-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.Dispatcher.forward(Dispatcher.java:203) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.Dispatcher.error(Dispatcher.java:81) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ErrorHandler.doError(ErrorHandler.java:119) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ErrorHandler.handle(ErrorHandler.java:78) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.springframework.boot.web.embedded.jetty.JettyEmbeddedErrorHandler.handle(JettyEmbeddedErrorHandler.java:55) ~[spring-boot-2.1.1.RELEASE.jar:2.1.1.RELEASE]
	at org.eclipse.jetty.server.Response.sendError(Response.java:655) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at javax.servlet.http.HttpServletResponseWrapper.sendError(HttpServletResponseWrapper.java:123) ~[javax.servlet-api-4.0.1.jar:4.0.1]
	at org.springframework.session.web.http.OnCommittedResponseWrapper.sendError(OnCommittedResponseWrapper.java:117) ~[spring-session-core-2.1.2.RELEASE.jar:2.1.2.RELEASE]
	at javax.servlet.http.HttpServletResponseWrapper.sendError(HttpServletResponseWrapper.java:123) ~[javax.servlet-api-4.0.1.jar:4.0.1]
	at javax.servlet.http.HttpServletResponseWrapper.sendError(HttpServletResponseWrapper.java:123) ~[javax.servlet-api-4.0.1.jar:4.0.1]
	at org.springframework.security.web.util.OnCommittedResponseWrapper.sendError(OnCommittedResponseWrapper.java:119) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at javax.servlet.http.HttpServletResponseWrapper.sendError(HttpServletResponseWrapper.java:123) ~[javax.servlet-api-4.0.1.jar:4.0.1]
	at org.springframework.security.web.util.OnCommittedResponseWrapper.sendError(OnCommittedResponseWrapper.java:119) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.access.AccessDeniedHandlerImpl.handle(AccessDeniedHandlerImpl.java:76) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:118) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:74) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.access.channel.ChannelProcessingFilter.doFilter(ChannelProcessingFilter.java:157) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) ~[spring-security-web-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:151) ~[spring-session-core-2.1.2.RELEASE.jar:2.1.2.RELEASE]
	at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81) ~[spring-session-core-2.1.2.RELEASE.jar:2.1.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.3.RELEASE.jar:5.1.3.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548) ~[jetty-security-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473) ~[jetty-servlet-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.Server.handle(Server.java:503) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364) ~[jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260) [jetty-server-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305) [jetty-io-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103) [jetty-io-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:411) [jetty-io-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:305) [jetty-io-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:159) [jetty-io-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103) [jetty-io-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118) [jetty-io-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333) [jetty-util-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310) [jetty-util-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168) [jetty-util-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126) [jetty-util-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366) [jetty-util-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765) [jetty-util-9.4.12.v20180830.jar:9.4.12.v20180830]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683) [jetty-util-9.4.12.v20180830.jar:9.4.12.v20180830]
	at java.base/java.lang.Thread.run(Thread.java:844) [na:na]
```

Thist stacktrace is also printed on web page instead of standard Whitelabel error page or JSON message.

### Expected Behavior

Exception is not throwing. User see Whitelabel page or JSON message with status code 403 instead of page with stacktrace and status code 500

### Configuration

Spring security Java config:

```
@EnableWebSecurity
@Configuration
public class DefaultSecurityConfig extends WebSecurityConfigurerAdapter {
@Override
protected void configure(final HttpSecurity http) throws Exception {
        http
                .requiresChannel()
                    .requestMatchers(request -> request.getHeader(""X-Forwarded-Proto"") != null)
                        .requiresSecure()
                    .and()
                .cors()
                    .and()
                .headers()
                    .frameOptions()
                    .sameOrigin()
                    .and()
                .csrf()
                    .ignoringAntMatchers(""/api/v1/auth/local/user/login"", ""/api/v1/auth/local/user/registrations"")
                    .and()
                .logout()
                    .logoutUrl(""/api/v1/auth/logout"")
                    .logoutSuccessHandler(new RestLogoutHandler())
                    .clearAuthentication(true)
                    .invalidateHttpSession(true)
                    .deleteCookies(""JSESSIONID"")
                    .and()
                .exceptionHandling()
                    .authenticationEntryPoint(new HttpStatusEntryPoint(HttpStatus.UNAUTHORIZED))
                    .and()
                .authorizeRequests()
                    .antMatchers(""/api/v1/auth/social/**"")
                        .permitAll()
                    .antMatchers(""/api/v1/auth/local/**"")
                        .permitAll()
                    .antMatchers(""/static/**"")
                        .permitAll()
                    .antMatchers(""/web/**"")
                        .permitAll()
                    .anyRequest()
                        .authenticated();
    }
}
```
Session or Spring security related properties:

```
server.servlet.session.timeout=604800
server.servlet.session.cookie.max-age=604800
server.servlet.session.cookie.http-only=true
server.servlet.session.cookie.secure=true
spring.session.store-type=redis
spring.session.redis.flush-mode=on-save
spring.session.redis.namespace=spring:session
```

### Version

Version: 5.1.2.RELEASE
Problem exists also in: 5.0.8.RELEASE

### Sample
",Can you please provide a complete sample?,"I have prepared example app: https://github.com/PawelJ-PL/spring-security-csrf-error
How to reproduce error:

1) Build and run app (because of spring-session, it requires Redis listening on localhost. I've used Redis docker image)
2) In web browser go to endpoint `/do/something` (`GET` request)
3) You will be redirected to login page. Enter username: `user` and password printed in console
4) You will be redirected to page with content `QWERTY`. Copy SESSION cookie
5) Using curl (or similar tool) send `POST` request to endpoint `/do/something` (and use cookie from previous step)
6) You will see stacktrace in response (because CSRF token has not been provided)."
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1177,Backport of #1137.,Can you confirm?,"Are you still experiencing this problem @adchilds or is your feedback based on something else?

Stacktrace from #1137 includes this line:

```
at org.springframework.session.data.redis.RedisOperationsSessionRepository$RedisSession.saveChangeSessionId(RedisOperationsSessionRepository.java:815)
```

The issue was reported against `2.0.4.RELEASE` which handles the rename of `expiredKey` on line 815:

https://github.com/spring-projects/spring-session/blob/2.0.4.RELEASE/spring-session-data-redis/src/main/java/org/springframework/session/data/redis/RedisOperationsSessionRepository.java#L815-L816

I believe you're considering the current state of `RedisOperationsSessionRepository` and not the one from the release against which #1137 was raised."
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1137,"Hi,

I'm using following versions: 
compile group: ""org.springframework.session"", name: ""spring-session-core"", version: ""2.0.4.RELEASE""
compile group: ""org.springframework.session"", name: ""spring-session-data-redis"", version: ""2.0.4.RELEASE""

Got this exception during integration testing:

```
org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR no such key
at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:54)
at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:52)\
at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:41)
at org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44)
at org.springframework.data.redis.FallbackExceptionTranslationStrategy.translate(FallbackExceptionTranslationStrategy.java:42)
at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:257)
at org.springframework.data.redis.connection.lettuce.LettuceKeyCommands.convertLettuceAccessException(LettuceKeyCommands.java:650)
at org.springframework.data.redis.connection.lettuce.LettuceKeyCommands.rename(LettuceKeyCommands.java:249)
at org.springframework.data.redis.connection.lettuce.LettuceClusterKeyCommands.rename(LettuceClusterKeyCommands.java:119)
at org.springframework.data.redis.connection.DefaultedRedisConnection.rename(DefaultedRedisConnection.java:96)
at org.springframework.data.redis.core.RedisTemplate.lambda$rename$13(RedisTemplate.java:889)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:224)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:184)
at org.springframework.data.redis.core.RedisTemplate.rename(RedisTemplate.java:888)
at org.springframework.session.data.redis.RedisOperationsSessionRepository$RedisSession.saveChangeSessionId(RedisOperationsSessionRepository.java:815)
at org.springframework.session.data.redis.RedisOperationsSessionRepository$RedisSession.saveDelta(RedisOperationsSessionRepository.java:772)
at org.springframework.session.data.redis.RedisOperationsSessionRepository$RedisSession.access$000(RedisOperationsSessionRepository.java:649)
at org.springframework.session.data.redis.RedisOperationsSessionRepository.save(RedisOperationsSessionRepository.java:384)
at org.springframework.session.data.redis.RedisOperationsSessionRepository.save(RedisOperationsSessionRepository.java:245)
at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.commitSession(SessionRepositoryFilter.java:234)
at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.access$100(SessionRepositoryFilter.java:197)
at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryResponseWrapper.onResponseCommitted(SessionRepositoryFilter.java:185)
at org.springframework.session.web.http.OnCommittedResponseWrapper.doOnResponseCommitted(OnCommittedResponseWrapper.java:227)
at org.springframework.session.web.http.OnCommittedResponseWrapper.access$000(OnCommittedResponseWrapper.java:38)
at org.springframework.session.web.http.OnCommittedResponseWrapper$SaveContextServletOutputStream.flush(OnCommittedResponseWrapper.java:494)
at org.springframework.security.web.util.OnCommittedResponseWrapper$SaveContextServletOutputStream.flush(OnCommittedResponseWrapper.java:514)
at com.fasterxml.jackson.core.json.UTF8JsonGenerator.flush(UTF8JsonGenerator.java:1100)
at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:915)
at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.writeInternal(AbstractJackson2HttpMessageConverter.java:286)
at org.springframework.http.converter.AbstractGenericHttpMessageConverter.write(AbstractGenericHttpMessageConverter.java:102)
at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:271)
at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:218)
at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82)
at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:119)
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:870)
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:776)
at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
at ....
```
",Can you provide a sample that can be used to reproduce this? Does your integration test include concurrent requests?,Unfortunately it can't be reproduced reliably - there are no concurrent requests in those tests but the issue is intermittent. 
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1042,"Hello,

We are using Spring Session project widely in our projects, but we encountered a strange situation when we traced lifecycle of our requests.

```
org.springframework.session.jdbc.JdbcOperationsSessionRepository.SessionResultSetExtractor
```

When sessions are fetched from database, this extractor creates sessions.  At first that is okay, but  setAttribute method is making sessions default dirty. (I mean differences in delta)

So, even there is no update on session attributes, there are always SQL operations for writing them to spring_session_attributes table. We think it causes a performance problem.

In the other hand; if security context or principal name index name, or both of them, exist in attributes, it also marks session as changed, and there comes a new query for update session.

Correct me if I am wrong, If we imagine a logged in user in simple website, there will be minimum 3 update queries for each request even there is no operation on session.

What are the motivations, or applied best practices for this implementations and api designs? ","What do you think?
",
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/1031,"Hi everyone,

I'm using spring-session 1.3.2.RELEASE with postgresql, I got this following error on my production environment. When I tried to login into the system, the session was created in the database normally, but somehow this exception occurred, I haven't found how to replicate this. does anyone know how to fix it ?

```
Oops! Appears that an error has occured. Please refresh the page and try again.. Exception message: PreparedStatementCallback; SQL [INSERT INTO SPRING_SESSION_ATTRIBUTES(SESSION_ID, ATTRIBUTE_NAME, ATTRIBUTE_BYTES) VALUES (?, ?, ?)]; ERROR: insert or update on table ""spring_session_attributes"" violates foreign key constraint ""spring_session_attributes_fk""
  Detail: Key (session_id)=(3483b536-25b7-4206-89b7-2323626ba198) is not present in table ""spring_session"".; nested exception is org.postgresql.util.PSQLException: ERROR: insert or update on table ""spring_session_attributes"" violates foreign key constraint ""spring_session_attributes_fk""
  Detail: Key (session_id)=(3483b536-25b7-4206-89b7-2323626ba198) is not present in table ""spring_session"".
org.springframework.dao.DataIntegrityViolationException: PreparedStatementCallback; SQL [INSERT INTO SPRING_SESSION_ATTRIBUTES(SESSION_ID, ATTRIBUTE_NAME, ATTRIBUTE_BYTES) VALUES (?, ?, ?)]; ERROR: insert or update on table ""spring_session_attributes"" violates foreign key constraint ""spring_session_attributes_fk""
  Detail: Key (session_id)=(3483b536-25b7-4206-89b7-2323626ba198) is not present in table ""spring_session"".; nested exception is org.postgresql.util.PSQLException: ERROR: insert or update on table ""spring_session_attributes"" violates foreign key constraint ""spring_session_attributes_fk""
  Detail: Key (session_id)=(3483b536-25b7-4206-89b7-2323626ba198) is not present in table ""spring_session"".
    at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:243)
    at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:73)
    at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:657)
    at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:906)
    at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:967)
    at org.springframework.session.jdbc.JdbcOperationsSessionRepository$2.doInTransactionWithoutResult(JdbcOperationsSessionRepository.java:464)
    at org.springframework.transaction.support.TransactionCallbackWithoutResult.doInTransaction(TransactionCallbackWithoutResult.java:34)
    at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:133)
    at org.springframework.session.jdbc.JdbcOperationsSessionRepository.save(JdbcOperationsSessionRepository.java:418)
    at org.springframework.session.jdbc.JdbcOperationsSessionRepository.save(JdbcOperationsSessionRepository.java:130)
    at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.commitSession(SessionRepositoryFilter.java:245)
    at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.access$100(SessionRepositoryFilter.java:217)
    at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:170)
    at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:80)
    at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:344)
    at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:261)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219)
    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)
    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:615)
    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)
    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
    at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:962)
    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)
    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1115)
    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)
    at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    at java.lang.Thread.run(Thread.java:745)
Caused by: org.postgresql.util.PSQLException: ERROR: insert or update on table ""spring_session_attributes"" violates foreign key constraint ""spring_session_attributes_fk""
  Detail: Key (session_id)=(3483b536-25b7-4206-89b7-2323626ba198) is not present in table ""spring_session"".
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2182)
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1911)
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:173)
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:622)
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:472)
    at org.postgresql.jdbc.PgStatement.executeUpdate(PgStatement.java:429)
    at org.springframework.jdbc.core.JdbcTemplate$2.doInPreparedStatement(JdbcTemplate.java:913)
    at org.springframework.jdbc.core.JdbcTemplate$2.doInPreparedStatement(JdbcTemplate.java:906)
    at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:641)
    ... 30 more
```

The configuration

```
<?xml version=""1.0"" encoding=""UTF-8""?>
<beans xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
       xmlns:context=""http://www.springframework.org/schema/context""
       xmlns=""http://www.springframework.org/schema/beans""
       xsi:schemaLocation=""http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/context
        http://www.springframework.org/schema/context/spring-context.xsd"">

    <context:annotation-config/>
    <bean class=""org.springframework.session.jdbc.config.annotation.web.http.JdbcHttpSessionConfiguration""/>

    <bean id=""dataSource""
          class=""org.springframework.jdbc.datasource.DriverManagerDataSource"">
        <property name=""driverClassName"" value=""${driverClassName}"" />
        <property name=""url"" value=""${database.url}"" />
        <property name=""username"" value=""${database.username}"" />
        <property name=""password"" value=""${database.password}"" />
    </bean>


    <bean class=""org.springframework.jdbc.datasource.DataSourceTransactionManager"">
        <constructor-arg ref=""dataSource""/>
    </bean>

    <bean class=""org.springframework.session.web.http.DefaultCookieSerializer"">
        <property name=""cookieName"" value=""MYCOOKIE"" />
    </bean>
</beans>
```
","Can you show us your Spring Session related tables? With psql you can execute these commands to obtain the required information:

```
> \dS+ spring_session
> \dS+ spring_session_attributes
```

Also it would be useful to know which sequence of actions has led to this error.",
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/978,"Hi, I'm in Spring Session 1.2.2 and I'm trying to move up to 2.x
I noticed CookeSerializer.CookieValue changed visibility from public to package.

sorry if this is super basic, but in new version how could I update the CookieValue from the already configured CookieSerializer.CookieValue?

in 1.2.2 I was doing
myCookieSerializer.writeCookieValue(new CookieSerializer.CookieValue(request, response, ""some value""));

thank you in advance.

",Can you clarify how this works for you in `1.2.2.RELEASE`?,"hello, yeah I noticed this when I moved up to 2.x   so do you think we are making this back to public ?"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/958,"SessionRepositoryRequestWrapper.commitSession (line 236):

			HttpSessionWrapper wrappedSession = getCurrentSession();

For example, my previous requests was with _s=1, then I decided to get some CSS file using _s=0 (using another session), above method will returns HttpSessionWrapper for _s=1 but must for _s=0, why? because application doesn't call SessionRepositoryRequestWrapper.setCurrentSession for new parameter _s=0. It's really impossible to switch b/w sessions.",Could you provide a sample application that could be used to reproduce the issue?,
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/885,"Hi

i to run the ""users"" sample app (samples/javaconfig/users/) with 'gradle tomcatRun' and encountered problems with the navbar. It's not visible for me running Chromium Version 60.0.3112.113 or Firefox 55.0.2.

I removed the 'collapse' class from https://github.com/spring-projects/spring-session/blob/master/samples/javaconfig/users/src/main/webapp/index.jsp#L23

and 

https://github.com/spring-projects/spring-session/blob/master/samples/javaconfig/users/src/main/webapp/link.jsp#L23

So the navbar is visible for me and everthing works. 
Bootstrap version used is 2.3.2 in my case.

Thanks,
Kristian

",Would you be interested in submitting a PR to address this?,
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/396,"Gradle task `:spring-session:integrationTest` is failing for me due to 3 failed test in `GemFireHttpSessionJavaConfigurationTests`, with `assertCacheAndRegion` appearing to be the cause.

Here are more details:

``` bash
$ ./gradlew :spring-session:integrationTest
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0
The 'sonar-runner' plugin has been deprecated and is scheduled to be removed in Gradle 3.0. please use the official plugin from SonarQube (http://docs.sonarqube.org/display/SONAR/Analyzing+with+Gradle).
:spring-session:compileJava UP-TO-DATE
:spring-session:compileGroovy UP-TO-DATE
:spring-session:processResources UP-TO-DATE
:spring-session:classes UP-TO-DATE
:spring-session:compileTestJava UP-TO-DATE
:spring-session:compileTestGroovy UP-TO-DATE
:spring-session:processTestResources UP-TO-DATE
:spring-session:testClasses UP-TO-DATE
:spring-session:compileIntegrationTestJava
warning: [options] bootstrap class path not set in conjunction with -source 1.5
warning: [options] source value 1.5 is obsolete and will be removed in a future release
warning: [options] target value 1.5 is obsolete and will be removed in a future release
warning: [options] To suppress warnings about obsolete options, use -Xlint:-options.
:spring-session:compileIntegrationTestGroovy UP-TO-DATE
:spring-session:processIntegrationTestResources UP-TO-DATE
:spring-session:integrationTestClasses
:spring-session:jar UP-TO-DATE
:spring-session:integrationTest

org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests > gemfireCacheConfigurationIsValid FAILED
    org.junit.ComparisonFailure at GemFireHttpSessionJavaConfigurationTests.java:64

org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests > verifyGemFireExampleCacheRegionSessionAttributesIndexWasNotCreated FAILED
    org.junit.ComparisonFailure at GemFireHttpSessionJavaConfigurationTests.java:64

org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests > verifyGemFireExampleCacheRegionPrincipalNameIndexWasCreatedSuccessfully FAILED
    org.junit.ComparisonFailure at GemFireHttpSessionJavaConfigurationTests.java:64

70 tests completed, 3 failed
:spring-session:integrationTest FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':spring-session:integrationTest'.
> There were failing tests. See the report at: file:///home/vedran/dev/projects/spring-session/spring-session/build/reports/integration-tests/index.html

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 49.151 secs
```

Stacktrace (same for all 3 tests with the exception of 6th line):

``` stacktrace
org.junit.ComparisonFailure: expected:<[REPLICATE]> but was:<[NORMAL]>
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at org.springframework.session.data.gemfire.AbstractGemFireIntegrationTests.assertRegion(AbstractGemFireIntegrationTests.java:319)
    at org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests.assertCacheAndRegion(GemFireHttpSessionJavaConfigurationTests.java:64)
    at org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests.gemfireCacheConfigurationIsValid(GemFireHttpSessionJavaConfigurationTests.java:71)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
    at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)
    at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)
    at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)
    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:224)
    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)
    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
    at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
    at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)
    at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
    at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)
    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:105)
    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:56)
    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
    at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
    at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
```
","Can you provide information about your OS? Can you try a fresh clone and see if it still happens?

cc @jxblum 
","@rwinch @jxblum of course this is on clean master with no modifications, I surely would've noticed otherwise. Here's one more time:

``` bash
$ git status 
On branch master
Your branch is up-to-date with 'origin/master'.
nothing to commit, working directory clean
```

``` bash
$ git log -1
commit 5d1c60711f1f31d2a8f128704807b518dfc30be2
Merge: d3139b0 32cf8ad
Author: Rob Winch <rwinch@users.noreply.github.com>
Date:   Mon Feb 29 12:59:41 2016 -0600

    Merge pull request #397 from vpavic/update-docs

    Fix minor documentation errors
```

``` bash
$ ./gradlew clean build
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0
The 'sonar-runner' plugin has been deprecated and is scheduled to be removed in Gradle 3.0. please use the official plugin from SonarQube (http://docs.sonarqube.org/display/SONAR/Analyzing+with+Gradle).
:clean
:docs:clean
:spring-session:clean
:spring-session-data-gemfire:clean UP-TO-DATE
:spring-session-data-redis:clean UP-TO-DATE
:samples:boot:clean UP-TO-DATE
:samples:custom-cookie:clean UP-TO-DATE
:samples:findbyusername:clean UP-TO-DATE
:samples:hazelcast:clean UP-TO-DATE
:samples:hazelcast-spring:clean UP-TO-DATE
:samples:httpsession:clean UP-TO-DATE
:samples:httpsession-gemfire-clientserver:clean UP-TO-DATE
:samples:httpsession-gemfire-clientserver-xml:clean UP-TO-DATE
:samples:httpsession-gemfire-p2p:clean UP-TO-DATE
:samples:httpsession-gemfire-p2p-xml:clean UP-TO-DATE
:samples:httpsession-xml:clean UP-TO-DATE
:samples:rest:clean UP-TO-DATE
:samples:security:clean UP-TO-DATE
:samples:users:clean UP-TO-DATE
:samples:websocket:clean UP-TO-DATE
:docs:asciidoctor
:spring-session:compileJava
warning: [options] bootstrap class path not set in conjunction with -source 1.5
warning: [options] source value 1.5 is obsolete and will be removed in a future release
warning: [options] target value 1.5 is obsolete and will be removed in a future release
warning: [options] To suppress warnings about obsolete options, use -Xlint:-options.
Note: /home/vedran/dev/projects/spring-session/spring-session/src/main/java/org/springframework/session/web/http/ExpiringSessionHttpSession.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
Note: /home/vedran/dev/projects/spring-session/spring-session/src/main/java/org/springframework/session/data/redis/RedisOperationsSessionRepository.java uses unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
:spring-session:compileGroovy UP-TO-DATE
:spring-session:processResources UP-TO-DATE
:spring-session:classes
:spring-session:javadoc
:configDocsZip
:docsZip
:assemble
:check UP-TO-DATE
:build
:docs:compileJava UP-TO-DATE
:docs:compileGroovy UP-TO-DATE
:docs:processResources UP-TO-DATE
:docs:classes UP-TO-DATE
:docs:jar
:docs:assemble
:spring-session:jar
:docs:compileTestJava
warning: [options] bootstrap class path not set in conjunction with -source 1.5
warning: [options] source value 1.5 is obsolete and will be removed in a future release
warning: [options] target value 1.5 is obsolete and will be removed in a future release
warning: [options] To suppress warnings about obsolete options, use -Xlint:-options.
:docs:compileTestGroovy UP-TO-DATE
:docs:processTestResources
:docs:testClasses
:docs:compileIntegrationTestJava
warning: [options] bootstrap class path not set in conjunction with -source 1.5
warning: [options] source value 1.5 is obsolete and will be removed in a future release
warning: [options] target value 1.5 is obsolete and will be removed in a future release
warning: [options] To suppress warnings about obsolete options, use -Xlint:-options.
:docs:compileIntegrationTestGroovy UP-TO-DATE
:docs:processIntegrationTestResources UP-TO-DATE
:docs:integrationTestClasses
:docs:integrationTest
:docs:test
:docs:check
:docs:build
:spring-session:javadocJar
:spring-session:sourcesJar
:spring-session:assemble
:spring-session:compileTestJava
warning: [options] bootstrap class path not set in conjunction with -source 1.5
warning: [options] source value 1.5 is obsolete and will be removed in a future release
warning: [options] target value 1.5 is obsolete and will be removed in a future release
warning: [options] To suppress warnings about obsolete options, use -Xlint:-options.
Note: /home/vedran/dev/projects/spring-session/spring-session/src/test/java/org/springframework/session/web/http/SessionRepositoryFilterTests.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
:spring-session:compileTestGroovy UP-TO-DATE
:spring-session:processTestResources
:spring-session:testClasses
:spring-session:compileIntegrationTestJava
warning: [options] bootstrap class path not set in conjunction with -source 1.5
warning: [options] source value 1.5 is obsolete and will be removed in a future release
warning: [options] target value 1.5 is obsolete and will be removed in a future release
warning: [options] To suppress warnings about obsolete options, use -Xlint:-options.
:spring-session:compileIntegrationTestGroovy UP-TO-DATE
:spring-session:processIntegrationTestResources UP-TO-DATE
:spring-session:integrationTestClasses
:spring-session:integrationTest

org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests > gemfireCacheConfigurationIsValid FAILED
    org.junit.ComparisonFailure at GemFireHttpSessionJavaConfigurationTests.java:64

org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests > verifyGemFireExampleCacheRegionSessionAttributesIndexWasNotCreated FAILED
    org.junit.ComparisonFailure at GemFireHttpSessionJavaConfigurationTests.java:64

org.springframework.session.data.gemfire.config.annotation.web.http.GemFireHttpSessionJavaConfigurationTests > verifyGemFireExampleCacheRegionPrincipalNameIndexWasCreatedSuccessfully FAILED
    org.junit.ComparisonFailure at GemFireHttpSessionJavaConfigurationTests.java:64

52 tests completed, 3 failed
:spring-session:integrationTest FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':spring-session:integrationTest'.
> There were failing tests. See the report at: file:///home/vedran/dev/projects/spring-session/spring-session/build/reports/integration-tests/index.html

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 1 mins 28.187 secs
```

Here are the relevant environment details:

``` bash
$ cat /etc/os-release 
NAME=""Ubuntu""
VERSION=""15.10 (Wily Werewolf)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 15.10""
VERSION_ID=""15.10""
HOME_URL=""http://www.ubuntu.com/""
SUPPORT_URL=""http://help.ubuntu.com/""
BUG_REPORT_URL=""http://bugs.launchpad.net/ubuntu/""
```

``` bash
$ uname -a
Linux vedran-ws 4.2.0-30-generic #36-Ubuntu SMP Fri Feb 26 00:58:07 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
```

``` bash
$ java -version
java version ""1.8.0_72""
Java(TM) SE Runtime Environment (build 1.8.0_72-b15)
Java HotSpot(TM) 64-Bit Server VM (build 25.72-b15, mixed mode)
```
"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/392,"Was testing the latest release 1.1.0.RELEASE, I was trying to logout, it throws the following exception. And also i have noticed that upon logout there is another cookie called JSESSIONID getting created.

```
Exception handling request to /myapp/logout: java.lang.NullPointerException
    at java.util.StringTokenizer.<init>(StringTokenizer.java:199)
    at java.util.StringTokenizer.<init>(StringTokenizer.java:221)
    at org.springframework.session.web.http.CookieHttpSessionStrategy.getSessionIds(CookieHttpSessionStrategy.java:308)
    at org.springframework.session.web.http.CookieHttpSessionStrategy.onInvalidateSession(CookieHttpSessionStrategy.java:260)
    at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.commitSession(SessionRepositoryFilter.java:190)
    at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.access$100(SessionRepositoryFilter.java:170)
    at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:128)
    at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:65)
```

Environment : Ubuntu 14.04, Wildfly 9.0.2.Final, Chrome/Firefox
","Does this still happen if you clear out your cookies before authenticating? Can you help identify the first version of Spring Session this happens in (does it happen in 1.1.0.RC1, 1.1.0.M1, 1.0.2.RELEASE, etc)?
","@rwinch Yes it is, i have cleared all the cookie then i have logged in then while tried to logout its giving NPE. I was using 1.0.2.RELEASE and was overriding **CookieHttpSessionStrategy** to solve setting custom cookie path  as per your input and i have experienced the same NPE but i thought it may be due to the change i've made so i have fixed in **getSessionIds** method as follows

```
String sessionCookieValue = session == null ? """" : StringUtils.defaultIfBlank(session.getValue(), """");
```

Since setting custom cookie path is fixed in latest release, i have removed my custom **CookieHttpSessionStrategy** implementation and used the config as follows

```
@Configuration
@EnableRedisHttpSession
public class RedisHttpSessionConfiguration {

    @Bean
    public CookieSerializer cookieSerializer() {
        final DefaultCookieSerializer serializer = new DefaultCookieSerializer();
        serializer.setCookieName(""JSESSIONID"");
        serializer.setCookiePath(""/"");
        serializer.setDomainNamePattern(""^.+?\\.(\\w+\\.[a-z]+)$"");
        return serializer;
    }
}
```

But this config didn't work for me since was not able to do SSO, at the same time i was facing the NPE while logout. Then i have add **CookieHttpSessionStrategy** bean definition back to my config as follows 

```
 @Bean
    public CookieHttpSessionStrategy cookieHttpSessionStrategy(CookieSerializer cookieSerializer) {
        final CookieHttpSessionStrategy cookieHttpSession = new CookieHttpSessionStrategy();
        cookieHttpSession.setCookieSerializer(cookieSerializer);
        return cookieHttpSession;
    }
```

After this change, SSO started working but facing the same NPE on logout, that leads me to file this issue. Later i have added custom implementation for **CookieHttpSessionStrategy** and override **getSessionIds** method to solve the NPE as follows.

```
String sessionCookieValue = StringUtils.defaultIfBlank(cookieValues.isEmpty() ? """" : cookieValues.iterator().next(),
                """");
```

the problem was `cookieValues.iterator().next()` was returning null on logout.
"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/373,"I'm trying to setup a simple Spring security session sharing using spring-session and Gemfire.
I've added following dependencies to my webapp project:

```
        compile('org.springframework.session:spring-session-data-gemfire:1.1.0.RC1')
        compile('org.springframework.session:spring-session:1.1.0.RC1')
        compile('org.springframework.security:spring-security-web')
        compile('org.springframework.security:spring-security-config')
```

and almost succeeded to setup session sharing. 
I had to add several Spring dependencies to the Gemfire classpath because the spring-session-data-gemfire doesn't use PDX and thus some classes need to be present on the server side as well:
`spring-session-1.1.0.RC1.jar`,`spring-expression-4.2.4.RELEASE.jar`, `spring-security-web-4.0.3.RELEASE.jar`, `spring-security-core-4.0.3.RELEASE.jar`
The session gets stored in my Gemfire cluster and I don't get server side ClassNotFoundExceptions any more.
I also get a simple authentication prompt asking to login to my application:

```
@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {

    @Autowired
    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception {
        auth
            .inMemoryAuthentication()
                .withUser(""user"").password(""password"").roles(""USER"");
    }
}
```

On the application side after I try to login with the those credentials I get the following exception:

```
[error 2016/02/22 02:29:59.823 CET <http-nio-8080-exec-2> tid=0x31] Exception occurred in CacheListener
java.lang.ClassCastException: com.gemstone.gemfire.internal.cache.Token$Tombstone cannot be cast to org.springframework.session.ExpiringSession
    at org.springframework.session.data.gemfire.AbstractGemFireOperationsSessionRepository.afterCreate(AbstractGemFireOperationsSessionRepository.java:212)
    at com.gemstone.gemfire.internal.cache.EnumListenerEvent$AFTER_CREATE.dispatchEvent(EnumListenerEvent.java:97)
    at com.gemstone.gemfire.internal.cache.LocalRegion.dispatchEvent(LocalRegion.java:8820)
    at com.gemstone.gemfire.internal.cache.LocalRegion.dispatchListenerEvent(LocalRegion.java:7311)
    at com.gemstone.gemfire.internal.cache.LocalRegion.invokePutCallbacks(LocalRegion.java:6133)
    at com.gemstone.gemfire.internal.cache.EntryEventImpl.invokeCallbacks(EntryEventImpl.java:1919)
    at com.gemstone.gemfire.internal.cache.ProxyRegionMap$ProxyRegionEntry.dispatchListenerEvents(ProxyRegionMap.java:544)
    at com.gemstone.gemfire.internal.cache.LocalRegion.basicPutPart2(LocalRegion.java:5987)
    at com.gemstone.gemfire.internal.cache.ProxyRegionMap.basicPut(ProxyRegionMap.java:228)
    at com.gemstone.gemfire.internal.cache.LocalRegion.basicPutEntry(LocalRegion.java:5919)
    at com.gemstone.gemfire.internal.cache.LocalRegion.findObjectInSystem(LocalRegion.java:2808)
    at com.gemstone.gemfire.internal.cache.LocalRegion.nonTxnFindObject(LocalRegion.java:1464)
    at com.gemstone.gemfire.internal.cache.LocalRegionDataView.findObject(LocalRegionDataView.java:133)
    at com.gemstone.gemfire.internal.cache.LocalRegion.get(LocalRegion.java:1348)
    at com.gemstone.gemfire.internal.cache.LocalRegion.get(LocalRegion.java:1311)
    at com.gemstone.gemfire.internal.cache.LocalRegion.get(LocalRegion.java:1298)
    at com.gemstone.gemfire.internal.cache.AbstractRegion.get(AbstractRegion.java:321)
    at org.springframework.data.gemfire.GemfireTemplate.get(GemfireTemplate.java:161)
    at org.springframework.session.data.gemfire.GemFireOperationsSessionRepository.getSession(GemFireOperationsSessionRepository.java:117)
    at org.springframework.session.data.gemfire.GemFireOperationsSessionRepository.getSession(GemFireOperationsSessionRepository.java:38)
    at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:270)
    at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:286)
    at org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper.getSession(SessionRepositoryFilter.java:170)
    at javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:231)
    at javax.servlet.http.HttpServletRequestWrapper.getSession(HttpServletRequestWrapper.java:231)
    at org.springframework.security.web.csrf.HttpSessionCsrfTokenRepository.loadToken(HttpSessionCsrfTokenRepository.java:77)
    at org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:85)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)
    at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)
    at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:91)
    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)
    at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:53)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)
    at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:213)
    at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176)
    at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)
    at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:126)
    at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:65)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:103)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:212)
    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502)
    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:141)
    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:521)
    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1096)
    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:674)
    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    at java.lang.Thread.run(Thread.java:745)
```

The session is not being recognized after that and app's page says after that

```
There was an unexpected error (type=Forbidden, status=403).
Expected CSRF token not found. Has your session expired?
```

That looks like something unexpected for the spring-session code.
Am I missing anything, or this is a spring-session issue indeed?
","What are your thoughts John?
",
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/339,"I could be missing something, but here's what I'm seeing.  I'm not sure if this can really be fixed, or if it just needs to be documented better that HazelcastHttpSessionConfiguration does not work for out of process Hazelcast server.

I enabled HazelcastHttpSessionConfiguration, and it works fine in a local profile that uses an embedded Hazelcast Instance.  However, when I switch to a profile that connects to a standalone Hazelcast instance, I get an exception thrown.

I'm setting up my hazelcast instance with this api:

```
    public static HazelcastInstance newHazelcastClient(ClientConfig config);
```

The first line in HazelcastHttpSessionConfiguration.configureSessionMap()  is 

```
        MapConfig sessionMapConfig = hazelcastInstance.getConfig().getMapConfig(sessionMapName);
```

then getConfig() throws this exception:

```
Caused by: java.lang.UnsupportedOperationException: Client cannot access cluster config!
          at com.hazelcast.client.impl.HazelcastClientInstanceImpl.getConfig(HazelcastClientInstanceImpl.java:278) ~[hazelcast-client-3.5.4.jar:3.5.4]
        at com.hazelcast.client.impl.HazelcastClientProxy.getConfig(HazelcastClientProxy.java:78) ~[hazelcast-client-3.5.4.jar:3.5.4]
        at org.springframework.session.hazelcast.config.annotation.web.http.HazelcastHttpSessionConfiguration.configureSessionMap(HazelcastHttpSessionConfiguration.java:98) ~[spring-session-1.1.0.M1.jar:na]
        at org.springframework.session.hazelcast.config.annotation.web.http.HazelcastHttpSessionConfiguration.sessionRepository(HazelcastHttpSessionConfiguration.java:70) ~[spring-session-1.1.0.M1.jar:na]
```
","Can you post your entire Spring Session Configuration?

cc @shakuzen @manderson23 
",
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/229,"# Updated Description

After further feedback from @tsachev the issue is reproduced:
- Initially there is no session created on the server and no session cookies in the browser.
- The controller/servlet creates a new session and sets an attribute. then throw an exception
- The error is handled and the SessionRepositoryFilter is invoked on the ERROR dispatch

This happens because the wrapped request that is caching the current session is not there anymore. It is a new HttpServletRequest object that is no longer wrapped. Instead, we should save the `HttpSessionWrapper currentSession` in a `HttpServletRequest` attribute.
# Original Description

If a request creates a new session and then forwards (`requestDispatcher.forward()`) to another servlet/view which tries to update the session - two session are created.

if SessionRepositoryFilter is registered for `DisptcherType.FORWARD` - two spring sessions are created.
if SessionRepositoryFilter is not registered for `DisptcherType.FORWARD` - one spring session is created and one tomcat session.

I can see that two `Set-Cooke` headers are sent to the browser.

```
HTTP/1.1 500 Internal Server Error
Server: Apache-Coyote/1.1
Set-Cookie: SESSION=8aa5f36e-820c-43bf-ba68-3797fd70b20f; Path=/storefront/; Secure; HttpOnly
Set-Cookie: SESSION=acc2a3df-ab9a-4080-afa3-c740fee75f5b; Path=/storefront/; Secure; HttpOnly
Content-Type: text/html;charset=UTF-8
Content-Language: en-US
Content-Length: 0
Date: Thu, 25 Jun 2015 14:56:10 GMT
Connection: close
```
","Can you try and provide more details on how to reproduce this issue? Perhaps a sample?

Thanks!
Rob
","I will try to make up a simple project that reproduces the problem.

But generally I think the flow goes like this.
- Initially there is no session created on the server and no session cookies in the browser.
- The controller/servlet creates a new session and sets an attribute. then throw an exception (thus the error in the response above).
- A custom exception handler forwards request to an error page (a jsp without `<%@ page session=""false"" %>`)
"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/188,"``` java
        private boolean isInvalidateClientSession() {
            return currentSession == null && isRequestedSessionIdValid();
        }
```

I believe this is missing a `!`  in front of `isRequestedSessionIdValid()`
","What makes you think that? The method is suppose to represent if a client requested a valid session id and the session is no longer valid (i.e. was the session valid when the client requested it but it was invalidated at some point).
","The issue I'm seeing is that valid sessions are getting erroneously invalidated.

`currentSession` can be `null` if `Request.getSession()` was never called by application code during the lifetime of the request (which is a perfectly valid scenario).  In this case, `isRequestedSessionIdValid()` still returns true because the sessionId is still valid.  However, this triggers Spring session to invalidate the session, thereby removing the cookie.

Why would we want to invalidate the client session if the sessionId _is_ valid?
"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/174,"I was cloned the spring-session samples in Win7 - JDK8. If I change 'springSessionVersion' to  '1.0.1.BUILD-SNAPSHOT'  in 'samples/spring-websocket-chat/build.gradle' then, the error also got...

I think this is a blocked issue, because the whole application not works because of it.
","Can you help out on https://github.com/kstyrc/embedded-redis/issues/23 to provide feedback on the fix?
","Sure,

But, If I use redis server on my win7, the problem was the same, so that code does not work with not embedded redis server.
"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/159,"Right now, if the user accesses the webapp with an invalid Session cookie (e.g. by tampering, using an expired cookie or because of a wrong path in the cookie), the webserver redirects to the expired session url (when using Spring Security). 

Additionally to redirecting, the offending cookie should also be deleted, because if not, a redirect loop similar to #142 occurs.

I'll try to make a PR for this.
","Can you provide a sample of this?
","Hmm.. I'm not sure, as I've got assigned a new work item.. steps to reproduce where
1. start redis instance
2. log in to the application
3. kill redis instance
4. reload web-page
   -> session-cookie is valid, but session is not found in redis, instead of deleting the cookie, it redirects to login page, which instead of deleting the old cookie again redirects and so on.. 
"
spring-projects/spring-session,https://github.com/spring-projects/spring-session/issues/142,"I have the project with servlet 2.5, spring security (cookie strategy JSESSIONID) an session (also with cookie strategy).  
First time it runs (without cookies) the authentication works fine and I can access to the application. Looking at redis the session is stored with SPRING_CONTEXT key all right.
The problem is when I restart the browser and It has the previous cookies setted ( JSESSIONID and SESSION), the login form are continuosly showed, and the spring-session create new session redis variables each time I insert the user/password, and one of this variables has sessionAttr:SPRING_SECURITY_CONTEXT empty.
To break the loop and enter I need to remove the cookies.. ;o(

I think that maybe this strange behavior are due to the  `SessionFixationProtectionStrategy` since it creates a new session for the newly authenticated user if they already have a session (as a defence against session-fixation protection attacks).

Disable session management seems to solve the problem: 

```
<http>
    <session-management session-fixation-protection=""none""/>
</http>
```
","What container are you using? Are you able to provide a sample that reproduces the issue?
","Thanks for your quick answer, I will try to clarify the maximum of your requirements to to locate this issue and fix if finally it exist.
We have only the next cookies at localhost (develop enviroment), the request sends:
`Cookie:SESSION=9d1995b6-2831-4de4-a8c3-de41ef9ac970; JSESSIONID=76E7B5DD151E565C48B4CE398463FFCA`
- _JSESSIONID_ has domain=localhost and  path=""/context-root""
- _SESSION_ has domain=localhost and path=""/context-root/"" (notice the end slash **/**)

The container is **Tomcat 6.0.36 (servlet 2.5)**
The configuration is xml based as you suggest at #101:
_web.xml_

```
(defined before springSecurityFilterChain)
        <filter>
        <filter-name>springSessionRepositoryFilter</filter-name>
        <filter-class>org.springframework.web.filter.DelegatingFilterProxy</filter-class>
    </filter>
    <filter-mapping>
        <filter-name>springSessionRepositoryFilter</filter-name>
        <url-pattern>/*</url-pattern>
    </filter-mapping>   
```

_applicationContext-session.xml_ (class with @EnableRedisHttpSession)
`<bean class=""org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfig""/>`
 Finally the  _SessionRepositoryFilter_ has some changes to fix the #111:
`currentSession = new HttpSessionWrapper(session, getServletContext());`
changed to:
`ServletContext context = super.getSession(true).getServletContext();`
 `currentSession = new HttpSessionWrapper(session, context);`
at lines near 193 and 202.
"
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/20150,"<!--
Thanks for raising a Spring Boot issue. Please take the time to review the following
categories as some of them do not apply here.

🙅 ""Please DO NOT Raise an Issue"" Cases
- Question
STOP!! Please ask questions about how to use something, or to understand why something isn't
working as you expect it to, on Stack Overflow using the spring-boot tag.
- Security Vulnerability
STOP!! Please don't raise security vulnerabilities here. Head over to https://pivotal.io/security to learn how to disclose them responsibly.
- Managed Dependency Upgrade
You DO NOT need to raise an issue for a managed dependency version upgrade as there's a semi-automatic process for checking managed dependencies for new versions before a release. BUT pull requests for upgrades that are more involved than just a version property change are still most welcome.
- With an Immediate Pull Request
An issue will be closed as a duplicate of the immediate pull request, so you don't have to raise an issue if you plan to create a pull request immediately.

🐞 Bug report (please don't include this emoji/text, just add your details)
Please provide details of the problem, including the version of Spring Boot that you
are using. If possible, please provide a test case or sample application that reproduces
the problem. This makes it much easier for us to diagnose the problem and to verify that
we have fixed it.

🎁 Enhancement (please don't include this emoji/text, just add your details)
Please start by describing the problem that you are trying to solve. There may already
be a solution, or there may be a way to solve it that you hadn't considered.


TIP: You can always edit your issue if it isn't formatted correctly.
     See https://guides.github.com/features/mastering-markdown 
-->

Due to the optimization of `ProducesRequestCondition`, HandlerMapping caches MediaTypesAttribute.
However, `WebFluxEndpointHandlerMapping` and `CloudFoundryWebFluxEndpointHandlerMapping` do not delete the cached MediaTypesAttribute and affect the resolution of MediaTypes of other HandlerMappings. ( On the other hand, the class that inherits `RequestMappingHandlerMapping` deletes the cache.)

These issues are occurring not only in Spring Webflux's HandlerMapping but also in Spring MVC's HandlerMapping.

To solve this problem, I think you need one of the following measures:
Add a process to delete the cache at the end of HandlerMapping to `AbstractWebFluxEndpointHandlerMapping` and `AbstractWebMvcEndpointHandlerMapping`.
Move the process of deleting the cache at the end of HandlerMapping from `RequestMappingHandlerMapping` to `RequestMappingInfoHandlerMapping` of the parent class.

If my proposed solution is correct, I am ready to create a PR.

### Related URL

- https://github.com/spring-projects/spring-framework/issues/23091
- https://github.com/spring-projects/spring-framework/commit/0757eaee9deab3c75229c91cf0a6999b9bb563e9
","Did your application fail because of this problem? What was the problem, what were you trying to do and what was the expected behavior?

We need this type of information to properly triage this issue and assign the fix to a milestone.","Helllo @bclozel, thank you for the reaction.

In our team, we provided our own custom `RequestedContentTypeResolver` for `RequestMappingHandlerMapping` to convert our own accept header and content-type header. (This is because the accept header controls versioning.)

Usually, HandlerMapping is executed in the following order.

1. `WebFluxEndpointHandlerMapping` (`HeaderContentTypeResolver`)
2. `ControllerEndpointHandlerMapping` (`HeaderContentTypeResolver`)
3. `RequestMappingHandlerMapping` (CustomRequestedContentTypeResolver)

The value of MediaTypesAttribute cached by `HeaderContentTypeResolver` of `WebFluxEndpointHandlerMapping` is cleared when `ControllerEndpointHandlerMapping` ends.

However, for some reason, our team executed HandlerMapping in the following order. (I am aware that this is a rare case.)

1. `WebFluxEndpointHandlerMapping` (`HeaderContentTypeResolver`)
2. `RequestMappingHandlerMapping` (CustomRequestedContentTypeResolver)
3. `ControllerEndpointHandlerMapping` (`HeaderContentTypeResolver`)

In this case, the MediaTypesAttribute value cached by the `HeaderContentTypeResolver` of `WebFluxEndpointHandlerMapping` is inherited by `RequestMappingHandlerMapping` without being cleared. Therefore, we can no longer resolve the MediaTypesAttribute with the CustomRequestedContentTypeResolver.

Manipulating the HandlerMapping order can solve the above problem. However, if  `WebFluxEndpointHandlerMapping` alone can clear the value of MediaTypesAttribute, can the value of MediaTypesAttribute be handled without depending on the order of HandlerMapping? 
What do you think?



"
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/20128,"springboot 2.2.4-RELEASE
* pom.xml
```
<dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <!-- database start -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-jdbc</artifactId>
        </dependency>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
        </dependency>
        <!-- database end -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

    </dependencies>
```
* application.yml
```
spring:
  datasource:
    url: jdbc:mysql://127.0.0.1:3306/auth8?useUnicode=true&characterEncoding=utf-8&autoReconnect=true&useSSL=false&serverTimezone=Asia/Shanghai
    username: root
    password: 123456
````
* bootstrap.java
```
@SpringBootApplication
public class SessionBootstrap {

    public static void main(String[] args) {
        SpringApplication.run(SessionBootstrap.class, args);
    }
}
```
* But why ???
```
2020-02-12 00:54:42.986  INFO 95047 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-02-12 00:54:43.359  INFO 95047 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
```

",Can you please turn this text into an actual project (zip or github repo url) we can use to reproduce the issue?,"> @cubita-io thanks for the report. Can you please turn this text into an actual project (zip or github repo url) we can use to reproduce the issue?


https://github.com/cubita-io/springboot-issue.git"
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/19626,"### Problem:
The actuator `configprops` and `env` endpoints show `RabbitProperties#addresses` in un-sanitized form. 

### Workaround:
These endpoints expose the `keys-to-sanitize` property and I could set that property to the current defaults plus `addresses`. However, this is not desirable as 

1. we have many applications that will use this and will have to do this in every app (or write a starter that does it). 
2. copying the current default values in the endpoint code is a risk of getting out of sync w/ that code (defaults in the endpoint).

It feels like this is something that should be handled out-of-box. 

#### Couple of options:

1. Update default keys-to-sanitize to include an expression for `addresses`.

2. Add an `additional-keys-to-sanitize` to allow adds to the defaults and set that property in my applications.

3.  Add an annotation that can be set on a `@ConfigurationProperties` field (such as `@Sensitive`) that would automatically get that field excluded from the endpoint reports.

4. Do nothing. Use the existing `keys-to-sanitize` property w/ the current coded defaults and add `addresses` to it. Repeat this in each application. Update each application when/if the defaults happen to change in the endpoint code.

I am happy to submit a merge request for any of these options. ",Could you tell us why this doesn't work for you?,I will take a look this evening @mbhave 
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/19392,"A Spring WebFlux application that uses Spring HATEOAS and has properly excluded Spring MVC will blow up due to `HypermediaAutoConfiguration` pulling in `WebMvcAutoConfiguration`.

Can we somehow further constrain this autoconfiguration to not kick in the there is no Spring MVC on the classpath?

Right now, I have to set `spring.hateoas.use-hal-as-default-json-media-type=false` to manually turn off `HateosConfiguration`.",What error are you actually seeing? Have you got a sample application we can run?,"Okay, I tracked it down to `HypermediaHttpMessageConverterConfiguration`, which is activated by that property.

Working on a sample."
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18936,"As of 2.2.0 the shutdown of a spring-boot application is broken and results in a Build Failure when executed.

I ran ```mvnw clean install package spring-boot:run``` as a command.

In attachment the executable file of a boot from https://start.spring.io/ and the resulted build fail. I ran with Java 8, and the Maven wrapper included in the project. 

[output.txt](https://github.com/spring-projects/spring-boot/files/3822172/output.txt)
","Can you please clarify? The best way to do so would be with a small sample, zipped up and attached to this issue, that reproduces the problem, and the exact commands that we need to run to do so.","Steps I did for the creation of this zip.:

- Download a demo application from start.spring.io (Spring Boot V2.2.1, Java 8, Dependencies: Web)
- Extract the demo application
- Ran command mvnw clean install spring-boot:run in the demo application
- Waited for Boot
- After boot -> Stop with ctrl+C 

Result: A Build failure

[demo.zip](https://github.com/spring-projects/spring-boot/files/3823451/demo.zip)
[output.txt](https://github.com/spring-projects/spring-boot/files/3823453/output.txt)


"
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18910,"when ServletComponentRegisteringPostProcessor add @WebServlet, it requires an ScannedGenericBeanDefinition from an ClassPathScanningCandidateComponentProvider.

it works fine without Context-Indexer but wrong with Context-Indexer.
ClassPathScanningCandidateComponentProvider will return an AnnotatedGenericBeanDefinition, when their is an spring.components file.

",Can you please create a small sample that reproduces the problem and share it with us by zipping it up and attaching it to this issue?,
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18810,"```java
@ConstructorBinding
@ConfigurationProperties(""test"")
static class NestedConstructorProperties {

  private final String name;

  private final Nested nested;

  NestedConstructorProperties(String name, Nested nested) {
    this.name = name;
    this.nested = nested;
  }

  String getName() {
    return this.name;
  }

  Nested getNested() {
    return this.nested;
  }

  static class Nested { 

    private int age;

    @ConstructorBinding
    Nested(int age) {
      this.age = age;
    }

    Nested() {

    }

    int getAge() {
      return this.age;
    }

  }

}
```",Which package has this note?,@giovannilima262 Sorry but I don't think I understood the question.
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18805,"The reactive always returns the http status code 200, even if the health check is down. The response body contains the correct status code.

Response
```
< 200 OK OK
< Date: [Tue, 29 Oct 2019 16:42:00 GMT]
< Content-Type: [application/json]

{""body"":{""status"":""DOWN""},""status"":503}
```
",Do you have a sample application that shows the problem?,"Thanks for the quick reply.

Okay the problem is a little bit more complicated.
We use the WebFlux API with Mono and Flux, but run in a servlet context. With the latest update (2.2.0.RELEASE), the reactive health check classes are no longer registered because the entire structure has changed.
What i have tried now is to create the auto-config. I think i miss a bean. I am currently working on a project.

```
@Configuration( proxyBeanMethods = false )
@ConditionalOnAvailableEndpoint( endpoint = HealthEndpoint.class )
@EnableConfigurationProperties( { HealthEndpointProperties.class, HealthIndicatorProperties.class } )
@Import( { LegacyHealthEndpointAdaptersConfiguration.class, LegacyHealthEndpointCompatibilityConfiguration.class,
               HealthEndpointConfiguration.class, ReactiveHealthEndpointConfiguration.class } )
@EnableAutoConfiguration( exclude = { HealthEndpointAutoConfiguration.class } )
public class ServletReactiveHealthEndpointConfiguration {

   public ServletReactiveHealthEndpointConfiguration(
         final HealthEndpointProperties healthEndpointProperties,
         final HealthIndicatorProperties healthIndicatorProperties ) {
      healthEndpointProperties.getStatus().getOrder().addAll( healthIndicatorProperties.getOrder() );
      healthEndpointProperties.getStatus().getHttpMapping().putAll( healthIndicatorProperties.getHttpMapping() );
   }

   @Bean
   @ConditionalOnMissingBean
   ReactiveHealthEndpointWebExtension reactiveHealthEndpointWebExtension(
         final ReactiveHealthContributorRegistry reactiveHealthContributorRegistry,
         final HealthEndpointGroups groups ) {
      return new ReactiveHealthEndpointWebExtension( reactiveHealthContributorRegistry, groups );
   }
```"
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18674,"Hello,

We were trying to migrate from 2.1.9 to 2.2.0 for our applications last week and encountered a startup failure due to a configuration validation failure. In short, if we are using `@EnableConfigurationProperties` combined with `@ConditionalOnProperty` for some beans, the new version is not respecting the conditional on the config part.

**Here is a tiny example:**

If we add this component to any Spring Boot application, it will fail to start with 2.2.0.

```
@Component
@ConditionalOnProperty(prefix = ""foo"", name = ""enabled"")
@EnableConfigurationProperties(FooBarConfig.class)
public class FooBar {

    public FooBar() {
        Logger.getGlobal().info(""Starting FooBar..."");
    }

    @ConfigurationProperties(prefix = ""foo"")
    @Validated
    static class FooBarConfig {

        @NotNull
        String bar;

        public void setBar(String bar) {
            this.bar = bar;
        }

    }

}
```

**Expected behavior:**
The bean initialization of `FooBar` and `FooBarConfig` should be skipped because `@ConditionalOnProperty` doesn't match.

**Actual behavior:**
`FooBar` is skipped but the `FooBarConfig` keeps initializing thus failed startup.",Does that make sense?,"@snicoll Thanks for the quick explanations. I see what you meant and I just noticed this on the upgrade instructions:

> Classes annotated with @ConfigurationProperties can now be found via classpath scanning as an alternative to using @EnableConfigurationProperties or @Component. If you use @SpringBootApplication, scanning is enabled by default for the package that contains the @SpringBootApplication-annotated class.

We wanted to put the our service bean together with its configuration, and use `@EnableConfigurationProperties` to conditional switch on/off the bean initialization in a consistent way."
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18670,"There are cases that configuration property binding does not work when integrating 3rd party configuration class and it deploy to the application server as war file(= When JndiPropertySource is enabled).

## Versions

* 2.2.0.RELEASE(2.2.0.M5+) ※2.2.0.M4 work fine

## Details
For example, following properties class does not work.  (As actually, MyBatis's configuration class matches this pattern...)

```java
package com.example;

import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.boot.context.properties.NestedConfigurationProperty;

@ConfigurationProperties(prefix = ""my"")
public class MyProperties {

  private String name;

  @NestedConfigurationProperty
  private ThirdPartyConfiguration configuration; // ### Third party class

  public void setName(String name) {
    this.name = name;
  }

  public String getName() {
    return name;
  }

  public void setConfiguration(ThirdPartyConfiguration configuration) {
    this.configuration = configuration;
  }

  public ThirdPartyConfiguration getConfiguration() {
    return configuration;
  }

}
```

```java
package com.example;

public class ThirdPartyConfiguration {

  private String encoding;

  private boolean enabled;

  private final List<ResultMap> resultMaps = new ArrayList<>(); // ### Collection

  public void setEncoding(String encoding) {
    this.encoding = encoding;
  }

  public String getEncoding() {
    return encoding;
  }

  public void setEnabled(boolean enabled) {
    this.enabled = enabled;
  }

  public boolean isEnabled() {
    return enabled;
  }

  public Collection<ResultMap> getResultMaps() {
    return resultMaps;
  }

  public void addResultMap(ResultMap rm) {
    resultMaps.add(rm);
  }

}
```

```java
package com.example;

public class ResultMap {
  private String name;
  private String option;

  private ResultMap() { // ### Define private (If define public, this issue does not occurred)
  }

  public String getName() {
    return name;
  }

  public String getOption() {
    return option;
  }

  public static class Builder { // ### Builder class
    private final ResultMap resultMap;

    public Builder(String name) {
      resultMap = new ResultMap();
      resultMap.name = name;
    }

    public Builder option(String option) {
      resultMap.option = option;
      return this;
    }

    public ResultMap build() {
      return resultMap;
    }
  }
}
```

## StackTrace

```
...
[INFO] [talledLocalContainer] Caused by: org.springframework.boot.context.properties.bind.BindException: Failed to bind properties under 'my.configuration.result-maps[0]' to com.example.ResultMap
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.handleBindError(Binder.java:337)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:297)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$null$1(Binder.java:385)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withSource(Binder.java:519)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.access$1000(Binder.java:486)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$bindAggregate$2(Binder.java:386)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.IndexedElementsBinder.bindIndexed(IndexedElementsBinder.java:106)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.IndexedElementsBinder.bindIndexed(IndexedElementsBinder.java:86)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.IndexedElementsBinder.bindIndexed(IndexedElementsBinder.java:71)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.CollectionBinder.bindAggregate(CollectionBinder.java:49)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.AggregateBinder.bind(AggregateBinder.java:56)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$bindAggregate$3(Binder.java:388)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withIncreasedDepth(Binder.java:543)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.access$200(Binder.java:486)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindAggregate(Binder.java:388)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindObject(Binder.java:349)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:293)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$bindDataObject$4(Binder.java:421)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:88)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:77)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:54)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$bindDataObject$5(Binder.java:425)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withIncreasedDepth(Binder.java:543)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withDataObject(Binder.java:529)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.access$500(Binder.java:486)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindDataObject(Binder.java:423)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindObject(Binder.java:364)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:293)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$bindDataObject$4(Binder.java:421)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:88)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:77)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.JavaBeanBinder.bind(JavaBeanBinder.java:54)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$bindDataObject$5(Binder.java:425)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withIncreasedDepth(Binder.java:543)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withDataObject(Binder.java:529)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.access$500(Binder.java:486)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindDataObject(Binder.java:423)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindObject(Binder.java:364)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:293)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:281)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:211)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:198)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.ConfigurationPropertiesBinder.bind(ConfigurationPropertiesBinder.java:89)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.bind(ConfigurationPropertiesBindingPostProcessor.java:107)
[INFO] [talledLocalContainer]   ... 60 more
[INFO] [talledLocalContainer] Caused by: java.lang.IllegalStateException: Failed to extract parameter names for com.example.ResultMap(com.example.ResultMap$1)
[INFO] [talledLocalContainer]   at org.springframework.util.Assert.state(Assert.java:94)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.ValueObjectBinder$DefaultValueObject.parseConstructorParameters(ValueObjectBinder.java:178)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.ValueObjectBinder$DefaultValueObject.<init>(ValueObjectBinder.java:173)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.ValueObjectBinder$DefaultValueObject.get(ValueObjectBinder.java:218)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.ValueObjectBinder$DefaultValueObject.get(ValueObjectBinder.java:206)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.ValueObjectBinder$ValueObject.get(ValueObjectBinder.java:112)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.ValueObjectBinder.bind(ValueObjectBinder.java:51)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.lambda$bindDataObject$5(Binder.java:425)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withIncreasedDepth(Binder.java:543)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.withDataObject(Binder.java:529)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder$Context.access$500(Binder.java:486)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindDataObject(Binder.java:423)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bindObject(Binder.java:364)
[INFO] [talledLocalContainer]   at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:293)

```

## Related Issue

* #17098


## Reproduce project

* [spring-boot-gh-18670.zip](https://github.com/spring-projects/spring-boot/files/3750219/spring-boot-gh-18670.zip)

### How to reproduce

```
$ ./mvnw package corgo:run
```
",Does someone have a workaround ? ,"@slavus 

If you does not use the JDNI feature, probably you can prevent this issue by disabled the Spring's JNDI feature.
How to disabled, See https://github.com/mybatis/spring-boot-starter/issues/350#issuecomment-500480499."
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18653,"After upgrade to Spring Boot v2.2 the test configuration class which is annotated with `@TestConfiguration` is not proxied by CGLIB anymore, thus calling `@Bean` methods return new instances every time.

After quick search in Spring Framework cores [changes](https://github.com/spring-projects/spring-framework/wiki/Upgrading-to-Spring-Framework-5.x#core-container) gives a hint:

> [...]  or not finding annotations anymore where they have previously been found accidentally. 

The corresponding [commit](https://github.com/spring-projects/spring-framework/commit/fd8fa301a69e9ce586769c12b7572255d0f83f3c) in Spring Framework.
",does this needs to be fixed ?,
spring-projects/spring-boot,https://github.com/spring-projects/spring-boot/issues/18365,"Class `A` has member of Type `A`，if `A` is annotated with `@ConfigurationProperties` and `lombok.Data` together a `java.lang.StackOverflowError` will happen.

For example:

```java
@ConfigurationProperties(""prefix"")
@Data
public class A {

   A m;

}
```",Does it even support this?  Is that why it is stack overflowing because it is trying to generate it?,"@philwebb 
```
Caused by: java.lang.StackOverflowError
        at com.sun.tools.javac.tree.TreeScanner.visitSelect(TreeScanner.java:264)
        at com.sun.tools.javac.tree.JCTree$JCFieldAccess.accept(JCTree.java:1897)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.scan(TreeInfo.java:658)
        at com.sun.tools.javac.tree.TreeScanner.visitApply(TreeScanner.java:199)
        at com.sun.tools.javac.tree.JCTree$JCMethodInvocation.accept(JCTree.java:1465)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.scan(TreeInfo.java:658)
        at com.sun.tools.javac.tree.TreeScanner.visitBinary(TreeScanner.java:244)
        at com.sun.tools.javac.tree.JCTree$JCBinary.accept(JCTree.java:1785)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.scan(TreeInfo.java:658)
        at com.sun.tools.javac.tree.TreeScanner.visitAssign(TreeScanner.java:231)
        at com.sun.tools.javac.tree.JCTree$JCAssign.accept(JCTree.java:1686)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.scan(TreeInfo.java:658)
        at com.sun.tools.javac.tree.TreeScanner.visitExec(TreeScanner.java:175)
        at com.sun.tools.javac.tree.JCTree$JCExpressionStatement.accept(JCTree.java:1296)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.scan(TreeInfo.java:658)
        at com.sun.tools.javac.tree.TreeScanner.scan(TreeScanner.java:57)
        at com.sun.tools.javac.tree.TreeScanner.visitBlock(TreeScanner.java:105)
        at com.sun.tools.javac.tree.JCTree$JCBlock.accept(JCTree.java:909)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.scan(TreeInfo.java:658)
        at com.sun.tools.javac.tree.TreeScanner.visitMethodDef(TreeScanner.java:91)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.visitMethodDef(TreeInfo.java:670)
        at com.sun.tools.javac.tree.JCTree$JCMethodDecl.accept(JCTree.java:778)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.scan(TreeInfo.java:658)
        at com.sun.tools.javac.tree.TreeScanner.scan(TreeScanner.java:57)
        at com.sun.tools.javac.tree.TreeScanner.visitClassDef(TreeScanner.java:80)
        at com.sun.tools.javac.tree.TreeInfo$1DeclScanner.visitClassDef(TreeInfo.java:666)
        at com.sun.tools.javac.tree.JCTree$JCClassDecl.accept(JCTree.java:693)
        at com.sun.tools.javac.tree.TreeInfo.declarationFor(TreeInfo.java:682)
        at com.sun.tools.javac.model.JavacElements.getTreeAndTopLevel(JavacElements.java:547)
        at com.sun.tools.javac.model.JavacElements.getDocComment(JavacElements.java:321)
        at org.springframework.boot.configurationprocessor.TypeUtils.getJavaDoc(TypeUtils.java:144)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processSimpleLombokTypes$1(ConfigurationMetadataAnnotationProcessor.java:340)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processSimpleLombokTypes(ConfigurationMetadataAnnotationProcessor.java:326)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:277)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedTypes(ConfigurationMetadataAnnotationProcessor.java:352)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processTypeElement(ConfigurationMetadataAnnotationProcessor.java:278)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.processNestedType(ConfigurationMetadataAnnotationProcessor.java:423)
        at org.springframework.boot.configurationprocessor.ConfigurationMetadataAnnotationProcessor.lambda$processNestedTypes$2(ConfigurationMetadataAnnotationProcessor.java:354)
```"
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/24491,"Starting from version 5.2.0 `spring-orm` is no longer an optional dependency of spring-aspects.
https://search.maven.org/artifact/org.springframework/spring-aspects/5.2.0.RELEASE/jar

This causes the below conditional to match which will then try to auto configure a data source.
https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/DataSourceAutoConfiguration.java#L52

Was this intentional?

<!--
!!! For Security Vulnerabilities, please go to https://pivotal.io/security !!!
-->
**Affects:** 5.2.x

---
<!--
Thanks for taking the time to create an issue. Please read the following:

- Questions should be asked on Stack Overflow.
- For bugs, specify affected versions and explain what you are trying to do.
- For enhancements, provide context and describe the problem.

Issue or Pull Request? Create only one, not both. GitHub treats them as the same.
If unsure, start with an issue, and if you submit a pull request later, the
issue will be closed as superseded.
-->","Do you know if we can change the ""aspect"" configuration so that it does not leak as a transitive dependency for that module? I know how to remove the node from our published POM, but that won't solve the issue once we're publishing Gradle metadata.

Thanks!",
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/24475,"- Spring Boot 2.2.4.RELEASE + webflux

From the server log I quite often see this nasty exception. We are mixing Weblux + Websockets

```
java.lang.IllegalStateException: Status and headers already sent
	at reactor.netty.http.server.HttpServerOperations.addHeader(HttpServerOperations.java:192) ~[reactor-netty-0.9.4.RELEASE.jar:0.9.4.RELEASE]
	at org.springframework.http.server.reactive.ReactorServerHttpResponse.applyCookies(ReactorServerHttpResponse.java:97) ~[spring-web-5.2.3.RELEASE.jar:5.2.3.RELEASE]
	at org.springframework.http.server.reactive.AbstractServerHttpResponse.lambda$doCommit$11(AbstractServerHttpResponse.java:238) ~[spring-web-5.2.3.RELEASE.jar:5.2.3.RELEASE]
	at reactor.core.publisher.MonoRunnable.subscribe(MonoRunnable.java:49) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.Mono.subscribe(Mono.java:4105) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxConcatArray$ConcatArraySubscriber.onComplete(FluxConcatArray.java:207) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxConcatArray.subscribe(FluxConcatArray.java:80) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFromFluxOperator.subscribe(MonoFromFluxOperator.java:72) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:153) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.ignoreDone(MonoIgnoreThen.java:190) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreInner.onComplete(MonoIgnoreThen.java:240) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:1871) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onComplete(MonoPeekTerminal.java:292) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:1871) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:1871) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:1871) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:1871) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondComplete(MonoFlatMap.java:189) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapInner.onComplete(MonoFlatMap.java:260) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxContextStart$ContextStartSubscriber.onComplete(FluxContextStart.java:122) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxContextStart$ContextStartSubscriber.onComplete(FluxContextStart.java:122) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onComplete(MonoFlatMap.java:174) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:78) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:144) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.ignoreDone(MonoIgnoreThen.java:190) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreInner.onComplete(MonoIgnoreThen.java:240) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondComplete(MonoFlatMap.java:189) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapInner.onComplete(MonoFlatMap.java:260) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxContextStart$ContextStartSubscriber.onComplete(FluxContextStart.java:122) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondComplete(MonoFlatMap.java:189) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapInner.onComplete(MonoFlatMap.java:260) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onComplete(MonoFlatMap.java:174) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onComplete(MonoFlatMap.java:174) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:136) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:78) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:144) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.ignoreDone(MonoIgnoreThen.java:190) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreInner.onComplete(MonoIgnoreThen.java:240) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:1871) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onComplete(FluxOnAssembly.java:395) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onComplete(FluxSwitchIfEmpty.java:78) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onComplete(MonoFlatMap.java:174) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondComplete(MonoFlatMap.java:189) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoFlatMap$FlatMapInner.onComplete(MonoFlatMap.java:260) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:144) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.ignoreDone(MonoIgnoreThen.java:190) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreInner.onComplete(MonoIgnoreThen.java:240) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxHide$SuppressFuseableSubscriber.onComplete(FluxHide.java:137) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.core.publisher.FluxDoOnEach$DoOnEachSubscriber.onComplete(FluxDoOnEach.java:209) ~[reactor-core-3.3.2.RELEASE.jar:3.3.2.RELEASE]
	at reactor.netty.FutureMono$FutureSubscription.operationComplete(FutureMono.java:188) ~[reactor-netty-0.9.4.RELEASE.jar:0.9.4.RELEASE]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:96) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:78) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:73) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.handler.codec.http.websocketx.WebSocketServerHandshaker$1.operationComplete(WebSocketServerHandshaker.java:227) ~[netty-codec-http-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.handler.codec.http.websocketx.WebSocketServerHandshaker$1.operationComplete(WebSocketServerHandshaker.java:221) ~[netty-codec-http-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.internal.PromiseNotificationUtil.trySuccess(PromiseNotificationUtil.java:48) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.ChannelOutboundBuffer.safeSuccess(ChannelOutboundBuffer.java:717) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.ChannelOutboundBuffer.remove(ChannelOutboundBuffer.java:272) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.ChannelOutboundBuffer.removeBytes(ChannelOutboundBuffer.java:352) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.epoll.AbstractEpollChannel.doWriteBytes(AbstractEpollChannel.java:363) ~[netty-transport-native-epoll-4.1.45.Final-linux-x86_64.jar:4.1.45.Final]
	at io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytes(AbstractEpollStreamChannel.java:260) ~[netty-transport-native-epoll-4.1.45.Final-linux-x86_64.jar:4.1.45.Final]
	at io.netty.channel.epoll.AbstractEpollStreamChannel.doWriteSingle(AbstractEpollStreamChannel.java:471) ~[netty-transport-native-epoll-4.1.45.Final-linux-x86_64.jar:4.1.45.Final]
	at io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(AbstractEpollStreamChannel.java:429) ~[netty-transport-native-epoll-4.1.45.Final-linux-x86_64.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:930) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.flush0(AbstractEpollChannel.java:519) ~[netty-transport-native-epoll-4.1.45.Final-linux-x86_64.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:897) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:748) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:740) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:726) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.flush(CombinedChannelDuplexHandler.java:531) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelOutboundHandlerAdapter.java:125) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.flush(CombinedChannelDuplexHandler.java:356) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:748) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:763) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1089) ~[netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:384) ~[netty-transport-native-epoll-4.1.45.Final-linux-x86_64.jar:4.1.45.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.45.Final.jar:4.1.45.Final]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]```
```


My websocket configuration:
```java
@Configuration
public class ReactiveWebSocketConfiguration {

    private final WebSocketHandler webSocketHandler;

    public ReactiveWebSocketConfiguration(@Qualifier(""ReactiveWebSocketHandler"") WebSocketHandler webSocketHandler) {
        this.webSocketHandler = webSocketHandler;
    }

    @Bean
    public HandlerMapping webSocketHandlerMapping() {
        Map<String, WebSocketHandler> map = new HashMap<>();
        map.put(""/event-emitter"", webSocketHandler);

        SimpleUrlHandlerMapping handlerMapping = new SimpleUrlHandlerMapping();
        handlerMapping.setOrder(1);
        handlerMapping.setUrlMap(map);
        return handlerMapping;
    }

    @Bean
    public WebSocketHandlerAdapter handlerAdapter() {
        return new WebSocketHandlerAdapter();
    }
}
```

```java
@Component(""ReactiveWebSocketHandler"")
public class ReactiveWebSocketHandler implements WebSocketHandler {

    final DataService dataService;

    public ReactiveWebSocketHandler(DataService dataService) {
        this.dataService = dataService;
    }

    @Override
    public Mono<Void> handle(WebSocketSession webSocketSession) {
        return webSocketSession.send(dataService.getEventFlux()
          .map(webSocketSession::textMessage))
          .and(webSocketSession.receive()
            .map(WebSocketMessage::getPayloadAsText).log());
    }
}
```
DataService is providing text String.

Browser side:
```javascript
function connectEvents() {

    function createWebSocket(path) {
        var protocolPrefix = (window.location.protocol === 'https:') ? 'wss:' : 'ws:';
        return new WebSocket(protocolPrefix + '//' + location.host + path);
    }

    var clientWebSocket = createWebSocket(location.pathname + 'event-emitter');

    clientWebSocket.onopen = function () {
        console.log(""clientWebSocket.onopen"", clientWebSocket);
        console.log(""clientWebSocket.readyState"", ""websocketstatus"");
        clientWebSocket.send(""event-me-from-browser"");
    };
    clientWebSocket.onclose = function (event) {
        console.log(""clientWebSocket.onclose"", clientWebSocket, event);

        console.log('Socket is closed. Reconnect will be attempted in 10 seconds.', event ? event.reason: '');
        setTimeout(function() {
            console.log('10s websocket reconnecting');
            connectEvents();
        }, 10000);
    };
    clientWebSocket.onerror = function (event) {
        console.log(""clientWebSocket.onerror"", clientWebSocket, event);
    };
    clientWebSocket.onmessage = function (event) {
        console.log(""clientWebSocket.onmessage"", clientWebSocket, event);
        processEvents(JSON.parse(event.data));
    };

}

$(function () {
    connectEvents();
});
```

It's difficult to debug - maybe it's related to cookies somehow(last 2 methods in the exception).
Let me know If I can provide more information.","Do you have filters or other pieces of infrastructure trying to write to the response?

Starting from a blank app from start.spring.io and adding pieces to it until this is reproducing the problem is I think the best course of action here.","I forgot to mention we are using Spring Security. 
According to the stacktrace it's going through the `WebSocketServerHandshaker` - so I suppose it has something to do with the websockets.
I was not able to reproduce it locally, I just see the problem from the server logs. App is is deployed on K8S cluster behind proxies...

 I know this kind of problem is pretty hard to solve. I wanted to report it  and to get some hint.
I will try to disable the security layer. 

Eg. this similar one had to do with Chrome requests:
https://github.com/spring-cloud/spring-cloud-gateway/issues/242
Yet another https://github.com/spring-cloud/spring-cloud-gateway/issues/340

It would be nice to have better logging support for these exceptions.
"
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/24441,"Previously, in spring 5.1, `org.springframework.core.codec.Encoder` and `Decoder` implementations could take advantage of the reactor subscriber `Context`, since all methods returned a `Mono` or `Flux`.

In spring 5.2, the following synchronous methods were added (as part of #22782):
* in `Encoder`... `DataBuffer encodeValue(T value, DataBufferFactory bufferFactory, ResolvableType valueType, MimeType mimeType, Map<String, Object> hints)`
* in `Decoder`... `T decode(DataBuffer buffer, ResolvableType targetType, MimeType mimeType, Map<String, Object> hints)`

These new methods are called instead of the older methods in various places.  E.g. `EncoderHttpMessageWriter.write` calls `encoder.encodeValue` in spring 5.2, where it previously called `encoder.encode` in spring 5.1.  See also [this comment](https://github.com/spring-projects/spring-framework/issues/22782#issuecomment-562706054).

These new methods do not provide access to the subscriber `Context` (since they don't return a `Mono`/`Flux`).  And there is also no way to force all callers to go back to the previous behavior of calling the old methods which do provide access to the `Context`.

Therefore, previous Encoder/Decoder implementations that utilized the subscriber `Context` are now broken in spring 5.2.

I'd like for the subscriber Context to be available in all of the encode*/decode* methods in an Encoder/Decoder.

Perhaps the Context could be added as a hint?  Or another default method added that provides the Context as an additional argument?
",What do you think?,"Yes, this is for a custom `Encoder`/`Decoder`.

As a temporary workaround (until this issue is addressed), I was thinking about extending `EncoderHttpMessageWriter` to make it work like it did in spring 5.1 if the inputStream was a Mono (i.e. call `encode` rather than `encodeValue`).

I haven't actually looked to see all the places where the new methods are used.  If it is limited to `EncoderHttpMessageWriter`, then I guess one of two fixes could be made there:
1. have something that made `EncoderHttpMessageWriter` always call encode, rather than encodeValue (i.e. revert to spring 5.1 behavior), OR
2. have something that made `EncoderHttpMessageWriter` pass the context as a hint to encodeValue

The more I think about it, however, the more I think that having the context as a hint seems hacky. 

And neither of these implementations handle _all_ the possible locations that the new synchronous methods _could_ be used.  So, this would limit any Encoder that uses the context to only be able to be used from the newly patched `EncoderHttpMessageWriter`.  I.e. it couldn't be used in any other location that called encodeValue that doesn't put the context in a hint.

What if the new synchronous `encodeValue` and `decode` methods were revisited, to instead take/return Mono?  This would allow implementations to access the context normally (via `Mono.subscriberContext()`). And it also seems more inline with the fact that the Encoder/Decoder are _reactive_ Encoder/Decoders.  i.e. It seems odd for a synchronous encode/decode method to exist in reactive Encoder/Decoders.

e.g.:
* In `Encoder`...  `default Mono<DataBuffer> encodeValue(Mono<T> value, DataBufferFactory bufferFactory,
			ResolvableType valueType, @Nullable MimeType mimeType, @Nullable Map<String, Object> hints)`
* In `Decoder`... `default Mono<T> decode(Mono<DataBuffer> buffer, ResolvableType targetType, @Nullable MimeType mimeType, @Nullable Map<String, Object> hints)`

I know this would mean immediately deprecating the newly added synchronous methods, and adding another default reactive method in their place.  But, it does seem ""cleaner"" to have only reactive encode/decode methods in Encoder/Decoder, and to allow implementations to access the context ""normally"".  Also, the default implementation of the new methods _might_ be able to delegate to the other existing methods, rather than throw an exception.  (I haven't completely thought that through though)

"
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/24389,"With Spring 5.2.3 I'm experiencing a Bug when reading server sent events with the web client. I've managed to write this minimal sample to reproduce the bug:

This code works perfectly fine on Spring 5.2.2 
```java
public static void main(String[] args) {
	ServerSentEventHttpMessageReader reader = new ServerSentEventHttpMessageReader();
	DataBufferFactory factory = new DefaultDataBufferFactory();

	ReactiveHttpInputMessage message = new ReactiveHttpInputMessage() {
		@Override
		public Flux<DataBuffer> getBody() {
			return Flux.just(
				factory.wrap("":ping\n"".getBytes(StandardCharsets.UTF_8)),
				factory.wrap(""\n"".getBytes(StandardCharsets.UTF_8))
			);
		}

		@Override
		public HttpHeaders getHeaders() {
			return new HttpHeaders();
		}
	};

	Flux<Object> flux = reader.read(ResolvableType.forType(String.class), message, emptyMap());
	flux.collectList().block().forEach(System.out::println);
}
```

But on Spring 5.2.3 an exception is thrown. This also happens when the comment `:ping` is missing and just a newline is received.

```
Exception in thread ""main"" java.lang.NullPointerException: The mapper returned a null value.
	at java.util.Objects.requireNonNull(Objects.java:228)
	at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:100)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.emit(FluxBufferPredicate.java:295)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.onNextNewBuffer(FluxBufferPredicate.java:260)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.tryOnNext(FluxBufferPredicate.java:214)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.onNext(FluxBufferPredicate.java:186)
	at reactor.core.publisher.FluxPeekFuseable$PeekConditionalSubscriber.onNext(FluxPeekFuseable.java:845)
	at reactor.core.publisher.FluxMap$MapConditionalSubscriber.onNext(FluxMap.java:213)
	at reactor.core.publisher.FluxContextStart$ContextStartSubscriber.onNext(FluxContextStart.java:103)
	at reactor.core.publisher.FluxMap$MapConditionalSubscriber.onNext(FluxMap.java:213)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.emit(FluxBufferPredicate.java:295)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.onNextNewBuffer(FluxBufferPredicate.java:260)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.tryOnNext(FluxBufferPredicate.java:214)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.onNext(FluxBufferPredicate.java:186)
	at reactor.core.publisher.FluxFlattenIterable$FlattenIterableSubscriber.drainSync(FluxFlattenIterable.java:576)
	at reactor.core.publisher.FluxFlattenIterable$FlattenIterableSubscriber.drain(FluxFlattenIterable.java:646)
	at reactor.core.publisher.FluxFlattenIterable$FlattenIterableSubscriber.request(FluxFlattenIterable.java:273)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.request(FluxBufferPredicate.java:149)
	at reactor.core.publisher.FluxMap$MapConditionalSubscriber.request(FluxMap.java:281)
	at reactor.core.publisher.FluxContextStart$ContextStartSubscriber.request(FluxContextStart.java:132)
	at reactor.core.publisher.FluxMap$MapConditionalSubscriber.request(FluxMap.java:281)
	at reactor.core.publisher.FluxPeekFuseable$PeekConditionalSubscriber.request(FluxPeekFuseable.java:775)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.request(FluxBufferPredicate.java:149)
	at reactor.core.publisher.FluxMap$MapSubscriber.request(FluxMap.java:155)
	at reactor.core.publisher.MonoCollectList$MonoCollectListSubscriber.onSubscribe(MonoCollectList.java:72)
	at reactor.core.publisher.FluxMap$MapSubscriber.onSubscribe(FluxMap.java:86)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.onSubscribe(FluxBufferPredicate.java:180)
	at reactor.core.publisher.FluxPeekFuseable$PeekConditionalSubscriber.onSubscribe(FluxPeekFuseable.java:808)
	at reactor.core.publisher.FluxMap$MapConditionalSubscriber.onSubscribe(FluxMap.java:185)
	at reactor.core.publisher.FluxContextStart$ContextStartSubscriber.onSubscribe(FluxContextStart.java:97)
	at reactor.core.publisher.FluxMap$MapConditionalSubscriber.onSubscribe(FluxMap.java:185)
	at reactor.core.publisher.FluxBufferPredicate$BufferPredicateSubscriber.onSubscribe(FluxBufferPredicate.java:180)
	at reactor.core.publisher.FluxFlattenIterable$FlattenIterableSubscriber.onSubscribe(FluxFlattenIterable.java:215)
	at reactor.core.publisher.FluxArray.subscribe(FluxArray.java:53)
	at reactor.core.publisher.FluxArray.subscribe(FluxArray.java:59)
	at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:53)
	at reactor.core.publisher.FluxDefer.subscribe(FluxDefer.java:54)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4105)
	at reactor.core.publisher.Mono.block(Mono.java:1662)
	at de.codecentric.boot.admin.server.web.InstancesControllerIntegrationTest.main(InstancesControllerIntegrationTest.java:243)
	Suppressed: java.lang.Exception: #block terminated with an error
		at reactor.core.publisher.BlockingSingleSubscriber.blockingGet(BlockingSingleSubscriber.java:99)
		at reactor.core.publisher.Mono.block(Mono.java:1663)
		... 1 more
```",Could you provide minimal demo to reproduce the problem?,"> Could you provide minimal demo to reproduce the problem?

There is already code in the issue description to reproduce the problem..."
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/24077,"## Overview

After migration to spring boot 2.2 we noticed that behavior of the annotations scan has been changed. In our case we define `@SpringBootApplication` in the base abstract class 

```java
@SpringBootApplication
public abstract class BaseApplication {

    protected abstract BaseApplication getApp();

    public void start(String[] args) {
        SpringApplication.run(getApp().getClass(), args);
    }
}
```

and then multiple concrete applications extend this class

```java
public class DemoApplication extends BaseApplication {
	public static void main(String[] args) {
		new DemoApplication().start(args);
	}

	@Override
	protected BaseApplication getApp() {
		return this;
	}
}
```

It works fine in the v 2.1.x, but in 2.2 attempt to run the app causes the error:""

> java.lang.IllegalArgumentException: No auto-configuration attributes found. Is com.xxx.Application annotated with EnableAutoConfiguration

```
2019-11-13 09:52:58.571 ERROR 97155 --- [           main] o.s.boot.SpringApplication               : Application run failed

java.lang.IllegalArgumentException: No auto-configuration attributes found. Is com.example.demo.DemoApplication annotated with EnableAutoConfiguration?
	at org.springframework.util.Assert.notNull(Assert.java:215) ~[spring-core-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.boot.autoconfigure.AutoConfigurationImportSelector.getAttributes(AutoConfigurationImportSelector.java:148) ~[spring-boot-autoconfigure-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at org.springframework.boot.autoconfigure.AutoConfigurationImportSelector.getAutoConfigurationEntry(AutoConfigurationImportSelector.java:115) ~[spring-boot-autoconfigure-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at org.springframework.boot.autoconfigure.AutoConfigurationImportSelector$AutoConfigurationGroup.process(AutoConfigurationImportSelector.java:396) ~[spring-boot-autoconfigure-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser$DeferredImportSelectorGrouping.getImports(ConfigurationClassParser.java:874) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser$DeferredImportSelectorGroupingHandler.processGroupImports(ConfigurationClassParser.java:801) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser$DeferredImportSelectorHandler.process(ConfigurationClassParser.java:771) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:188) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:325) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:242) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:275) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:95) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:706) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:532) ~[spring-context-5.2.1.RELEASE.jar:5.2.1.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) ~[spring-boot-2.2.1.RELEASE.jar:2.2.1.RELEASE]
	at com.example.demo.BaseApplication.start(BaseApplication.java:12) ~[classes/:na]
	at com.example.demo.DemoApplication.main(DemoApplication.java:8) ~[classes/:na]
```

## Steps to reproduce

- use attached demo project to reproduce the issue
[demo.zip](https://github.com/spring-projects/spring-boot/files/3842778/demo.zip)
- change spring-boot version to 2.1.8.RELEASE and run app again - everything works as expected
",Could you move it there if you agree?,
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23991,"**Affects:** 5.2.1.RELEASE

Calling `MethodParameter.isOptional()` for a `kotlin.coroutines.Continuation` parameter of a `suspend fun` fails when introspecting a Coroutines method.

```
java.lang.IndexOutOfBoundsException: Index: 1, Size: 1

	at java.util.ArrayList.rangeCheck(ArrayList.java:657)
	at java.util.ArrayList.get(ArrayList.java:433)
	at org.springframework.core.MethodParameter$KotlinDelegate.isOptional(MethodParameter.java:899)
	at org.springframework.core.MethodParameter.isOptional(MethodParameter.java:408)
```

The backing collection of `KParameter`s does not contain the parameter and therefore optionality checks fail.

","Could you share a little bit more about the context where this code path is reached? I am asking that because in current Coroutines support this kind of code path is not reached because we use upfront Kotlin reflection to identify the parameters that the user see, not the parameters at bytecode level that does not really make sense from a programming model perspective.","Sure, we're introspecting in Spring Data `MethodParameter`s to determine whether they are nullable or not (optional vs. required). 

Here's some context of how it is used:

```
interface CoCrudRepository<T, ID> {
	suspend fun save(entity: T): T
}

Method method = CoCrudRepository.class.getDeclaredMethod(…);

for (int i = 0; i < method.getParameterCount(); i++) {

	MethodParameter parameter = new MethodParameter(method, i);
	parameter.isOptional();
}
```"
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23852,"```
@Controller
public class ServerController {

    @MessageMapping(value = ""market"")
    public MarketResponse getMarket(Market market) {
        return new MarketResponse(market.getName());
    }
}
```
```
@RestController
public class ConsumerController {

    private final RSocketRequester rSocketRequester;

    public ConsumerController(RSocketRequester rSocketRequester) {
        this.rSocketRequester = rSocketRequester;
    }

    @GetMapping(path = ""/market/{name}"")
    public Publisher<MarketResponse> getMarket(@PathVariable String name) {
        return rSocketRequester.route(""market"").data(new Market(name)).retrieveMono(MarketResponse.class);
    }
}
```

```
java.lang.IllegalArgumentException: No decoder for com.example.rsocketclient.MarketResponse
	at org.springframework.messaging.rsocket.RSocketStrategies.decoder(RSocketStrategies.java:92) ~[spring-messaging-5.2.0.RELEASE.jar:5.2.0.RELEASE]
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Error has been observed at the following site(s):
	|_ checkpoint ⇢ HTTP GET ""/market/test"" [ExceptionHandlingWebHandler]
```",Why do you consider it a bug? It is most likely a configuration issue.,"```
@Configuration
public class ConsumerConfig {

    @Bean
    RSocket rSocket() {
        return RSocketFactory
                .connect()
                .dataMimeType(MimeTypeUtils.APPLICATION_JSON_VALUE)
                .frameDecoder(PayloadDecoder.ZERO_COPY)
                .transport(TcpClientTransport.create(7000))
                .start()
                .block();
    }

    @Bean
    RSocketRequester rSocketRequester() {
        return RSocketRequester.wrap(this.rSocket(), MimeTypeUtils.APPLICATION_JSON, MimeTypeUtils.APPLICATION_JSON, RSocketStrategies.builder().build());
    }
}
```
@rstoyanchev   what do you mean ?this is my configuration   is`s not error"
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23542,"## Exception
![image](https://user-images.githubusercontent.com/11484269/63922943-3d9b8780-ca78-11e9-8e88-4919741b2632.png)

## Code 
```java
String beanName = ...;
BeanDefinitionRegistry registry = ((BeanDefinitionRegistry) context.getAutowireCapableBeanFactory());
        registry.removeBeanDefinition(beanName);
```

Any help is thanks!","What version of Spring Framework are you using?

Where is the example code executing?

And more importantly, please provide the full stack trace **as text**, not as a partial screenshot.

Thanks","1. `Spring Boot` -> 2.1.4.RELEASE, `Spring Framework` -> 5.1.6.RELEASE.
2. Production.
3. The other stack trace is our company code like the code above.And the full stack begin with NPE.
The parameter is beanName，we assert that is not null. And The method `removeBeanDefinition` has an assertion of it."
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23438,"**Affects:** 5.0.12 (sure) and probably 5.1.9 since we tried to upgrade and this is the same code.

---
There is a deadlock at JVM shutdown if a thread tries to close the spring context at the same time.

The issue is a lock in `AbstractApplicationContext`

```java
	@Override
	public void registerShutdownHook() {
		if (this.shutdownHook == null) {
			// No shutdown hook registered yet.
			this.shutdownHook = new Thread() {
				@Override
				public void run() {
					synchronized (startupShutdownMonitor) {
						doClose();
					}
				}
			};
			Runtime.getRuntime().addShutdownHook(this.shutdownHook);
		}
	}
```

```java
	@Override
	public void close() {
		synchronized (this.startupShutdownMonitor) {
			doClose();
			// If we registered a JVM shutdown hook, we don't need it anymore now:
			// We've already explicitly closed the context.
			if (this.shutdownHook != null) {
				try {
					Runtime.getRuntime().removeShutdownHook(this.shutdownHook);
				}
				catch (IllegalStateException ex) {
					// ignore - VM is already shutting down
				}
			}
		}
	}
```

Here is an extract of the thread dump:

```
""SIGTERM handler"" #354 daemon prio=9 os_prio=0 tid=0x00007f5d38004800 nid=0x2bb4c waiting for monitor entry [0x00007f5ae66e5000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at java.lang.Shutdown.exit(Shutdown.java:212)
    - waiting to lock <0x00000005cc3bde18> (a java.lang.Class for java.lang.Shutdown)
    at java.lang.Terminator$1.handle(Terminator.java:52)
    at sun.misc.Signal$1.run(Signal.java:212)
    at java.lang.Thread.run(Thread.java:748)

""Thread-33"" #215 prio=5 os_prio=0 tid=0x00007f5a20002800 nid=0x2bb20 in Object.wait() [0x00007f5ccbbf9000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    at java.lang.Object.wait(Object.java:460)
    at com.tc.object.InFlightMessage.timedWait(InFlightMessage.java:294)
    - locked <0x00000007534e0638> (a com.tc.object.InFlightMessage)
    at com.tc.object.InFlightMessage.waitForAcks(InFlightMessage.java:239)
    at com.tc.object.InFlightMessage.waitForAcks(InFlightMessage.java:222)
    at com.tc.object.ClientEntityManagerImpl.queueInFlightMessage(ClientEntityManagerImpl.java:566)
    at com.tc.object.ClientEntityManagerImpl.sendMessageWhileBusy(ClientEntityManagerImpl.java:525)
    at com.tc.object.ClientEntityManagerImpl.internalRelease(ClientEntityManagerImpl.java:505)
    at com.tc.object.ClientEntityManagerImpl.access$600(ClientEntityManagerImpl.java:82)
    at com.tc.object.ClientEntityManagerImpl$1.run(ClientEntityManagerImpl.java:467)
    at com.tc.object.EntityClientEndpointImpl.close(EntityClientEndpointImpl.java:296)
    at org.terracotta.voltron.proxy.client.VoltronProxyInvocationHandler.invoke(VoltronProxyInvocationHandler.java:124)
    at com.sun.proxy.$Proxy128.close(Unknown Source)
    at org.terracotta.management.entity.nms.client.DefaultNmsService.close(DefaultNmsService.java:112)
    at com.terracottatech.management.voltron.AggregateNmsService.lambda$close$0(AggregateNmsService.java:126)
    at com.terracottatech.management.voltron.AggregateNmsService$$Lambda$1269/551340504.accept(Unknown Source)
    at java.util.concurrent.ConcurrentHashMap$KeySetView.forEach(ConcurrentHashMap.java:4649)
    at com.terracottatech.management.voltron.AggregateNmsService.close(AggregateNmsService.java:123)
    at com.terracottatech.management.voltron.VoltronTmsConnection.doClose(VoltronTmsConnection.java:181)
    at com.terracottatech.management.cluster.api.AbstractTmsConnection.close(AbstractTmsConnection.java:88)
    at com.terracottatech.management.cluster.api.AbstractTmsConnectionFactoryService.close(AbstractTmsConnectionFactoryService.java:42)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.springframework.beans.factory.support.DisposableBeanAdapter.invokeCustomDestroyMethod(DisposableBeanAdapter.java:337)
    at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:271)
    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571)
    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543)
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:954)
    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504)
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:961)
    at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1039)
    at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1015)
    at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:935)
    - locked <0x00000005cc513e08> (a java.lang.Object)

""SIGTERM handler"" #350 daemon prio=9 os_prio=0 tid=0x00007f5d38001000 nid=0x2bb08 in Object.wait() [0x00007f5ccbdfc000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00000005cd116528> (a org.springframework.context.support.AbstractApplicationContext$1)
    at java.lang.Thread.join(Thread.java:1252)
    - locked <0x00000005cd116528> (a org.springframework.context.support.AbstractApplicationContext$1)
    at java.lang.Thread.join(Thread.java:1326)
    at java.lang.ApplicationShutdownHooks.runHooks(ApplicationShutdownHooks.java:107)
    at java.lang.ApplicationShutdownHooks$1.run(ApplicationShutdownHooks.java:46)
    at java.lang.Shutdown.runHooks(Shutdown.java:123)
    at java.lang.Shutdown.sequence(Shutdown.java:167)
    at java.lang.Shutdown.exit(Shutdown.java:212)
    - locked <0x00000005cc3bde18> (a java.lang.Class for java.lang.Shutdown)
    at java.lang.Terminator$1.handle(Terminator.java:52)
    at sun.misc.Signal$1.run(Signal.java:212)
    at java.lang.Thread.run(Thread.java:748)
```",Could you give more information about it? ,"`InFlightMessage` has nothing to do with this. This class is part of another library we use (this is a comm. stack).
Basically what happens is that `Thread-33` tries to close Spring application context. While on the other hand the JVM `SIGTERM handler` thread is running the shutdown hook to exist the JVM.

There is no issue in thread Thread-33. The issue is on lock `0x00000005cc3bde18` caused by the `synchronized` blocks.

The `close()` method in `AbstractApplicationContext` could be called at the same time the JVM shutdown hook is triggered. "
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23352,"```java
	@Override
	public int hashCode() {
		return (getExecutable().hashCode() * 31 + this.parameterIndex);
	}
```

`HandlerMethodArgumentResolverComposite` uses `MethodParameter` as a cache key for `HandlerMethodArgumentResolver`.

Consider:

```java
@FunctionalInterface
public interface GenericHandler<P> {

	Object handle(P payload, MessageHeaders headers);

}
```

```java
		public static class MapHandler implements GenericHandler<Map<String, String>> {

			@Override
			public String handle(Map<String, String> mapPayload, MessageHeaders messageHeaders) {
				return ""Hello "" + mapPayload.get(""key"");
			}

		}

		public static class StringHandler implements GenericHandler<String> {

			@Override
			public String handle(String stringPayload, MessageHeaders messageHeaders) {
				return stringPayload + "" World!"";
			}

		}
```

`MethodParameter.executable` in both cases is the interface `Method`:

>`public abstract java.lang.Object org.springframework.integration.handler.GenericHandler.handle(java.lang.Object,org.springframework.messaging.MessageHeaders)`

When invoking the second method, we get a cache hit and fail with a class cast exception because the wrong argument resolver is returned.

Spring Integration recently changed to use a shared `DefaultMessageHandlerMethodFactory` `@Bean`, and hence a shared  `HandlerMethodArgumentResolverComposite`.

We can work around this by changing the bean scope to prototype, but I think the `hashCode()` and `equals()` should include at least the `containingClass` and/or `parameterType` field.

See https://github.com/spring-projects/spring-integration/issues/3004

","Could you give that one a try for your purposes, ideally against 5.1.9 snapshot?",">Could you give that one a try for your purposes, ideally against 5.1.9 snapshot?

@jhoeller I already [reverted the workaround on master yesterday](https://github.com/spring-projects/spring-integration/commit/fc827e1f929e3a5a77738e42f246c9c298f8a78b) and all is fine; thanks!

I am building our 5.1.x against 5.1.9 snapshots and don't see any problems there either (although we only had the problem on master, when we went to a shared handler factory across multiple components)."
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23241,"Spring version: 5.1.8.RELEASE

Send a http request with header like this, containing `, ` at the end.

```http
Accept: application/json, 
```

`HeaderContentNegotiationStrategy` will produce a `HttpMediaTypeNotAcceptableException`.

```
org.springframework.web.HttpMediaTypeNotAcceptableException: Could not parse 'Accept' header [application/json,]: Invalid mime type """": 'mimeType' must not be empty
	at org.springframework.web.accept.HeaderContentNegotiationStrategy.resolveMediaTypes(HeaderContentNegotiationStrategy.java:59) ~[spring-web-5.1.8.RELEASE.jar!/:5.1.8.RELEASE]
	at org.springframework.web.accept.ContentNegotiationManager.resolveMediaTypes(ContentNegotiationManager.java:124) ~[spring-web-5.1.8.RELEASE.jar!/:5.1.8.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.getAcceptableMediaTypes(AbstractMessageConverterMethodProcessor.java:391) ~[spring-webmvc-5.1.8.RELEASE.jar!/:5.1.8.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:229) ~[spring-webmvc-5.1.8.RELEASE.jar!/:5.1.8.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:225) ~[spring-webmvc-5.1.8.RELEASE.jar!/:5.1.8.RELEASE]
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) ~[spring-web-5.1.8.RELEASE.jar!/:5.1.8.RELEASE]
```

That http request works before 5.1.2.RELEASE.

Maybe the cause of this is the parsing method refactoring in this commit [f4b05dc](https://github.com/spring-projects/spring-framework/commit/f4b05dc2e730ca667daf8861c6eb2d9a6b83d534#diff-47ef64129825b0e047375d409c7d95a9L260).

`StringUtils.tokenizeToStringArray(mimeTypes, "","")` will trim tokens and ignore empty tokens by default, but now, the replacement method not support that anymore.","What is your use case for that?

What client is sending the Accept request header with a trailing comma?
","I'm using an HTTP client named Paw. It sends that request from its built in oauth2 client.

Although it seems to be an invalid header, it did work before."
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23219,"I wrote simple controller:

```java
@RestController
public class TestController {

    @GetMapping(""/api"")
    public Map<String, String> simpleTest() {
        // here is the text with special characters, all in UTF-8
        return Collections.singletonMap(""test"", ""Příliš žluťoučký kůň úpěl ďábelské ódy"");
    }
}
```

Also very simple tutorial-like test:

```java
    @Before
    public void setup() {
        this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).build();
    }

    @Test
    public void test() throws Exception {
        this.mockMvc.perform(get(""/api""))
                .andDo(print())
                .andExpect(jsonPath(""$.test"").value(""Příliš žluťoučký kůň úpěl ďábelské ódy""));
    }
```

The test fails in version 5.2.0.M3 now. Test passes in the previous milestone version 5.2.0.M2 and earlier versions.

The issue is somehow related to deprecation of `org.springframework.http.MediaType#APPLICATION_JSON_UTF8_VALUE`.

Of course it is possible to fix the test by adding _accept_ but I rather do not do that, because `APPLICATION_JSON_UTF8_VALUE` is deprecated now.

```java
.accept(MediaType.APPLICATION_JSON_UTF8_VALUE)
```

I have also prepared simple maven project to simulate the problem.
[springutf8.zip](https://github.com/spring-projects/spring-framework/files/3345177/springutf8.zip)

It seems to me, that `MockMvc` client does not handle UTF-8 characters well, like other modern browsers.
",Do you have time to look into this?,
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/23196,"After the change to `OncePerRequestFilter` in #22989, when using a `RequestContextFilter`, the request context will no longer be available after `sendError(...)` completes in Jetty. This means that the usage of any `@Scope(""request"")` beans in places like the *afterCompletion* in interceptors or on the return path of filters will not work, nor will more general usage of `RequestContextHolder.getRequestAttributes()` work.

The problem is that the change in `OncePerRequestFilter` causes the filter to be processed *again*, even though it is a *Once*PerRequestFilter. And the `RequestContextFilter` is not designed to be nested. The `finally` block clears all request attributes, even when attributes were set before the filter started.

I'm not really sure what the best solution would be. Maybe introduce a `OncePerRequestFilter.shouldNotFilterOnNestedErrorDispatch()` or something. Or maybe make `RequestContextFilter` restore the previous request context, instead of clearing everything (it seems like `FrameworkServlet` does this too)? Or both.

**Affected version**: 5.1.8",Can you take a look at it?,"As far as I can tell it was to mirror the change in spring-projects/spring-session#1308. The problem there was that they use a `OncePerRequestFilter` to wrap the request object and set a request attribute. Later code, when it saw the request attribute assumed the request was wrapped, but it wasn't, since an ERROR dispatch needs to be done with the original request and response objects. In this way an ERROR dispatch differs most significantly from a FORWARD dispatch."
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/22696,"Calling `AnnotatedElementUtils.getAllAnnotationAttributes(…, ""javax.annotation.Nonnull"")` with version `5.2.0.BUILD-SNAPSHOT` for `org.springframework.lang.NonNullApi.class` and `javax.annotation.ParametersAreNonnullByDefault.class` annotation types returns `null`. 

Previously (5.1 and earlier), the method returned `MultiValueMap` containing annotation attributes.",Couldn't you simply use the standard reflection API for annotation introspection purposes there? I'm surprised that standard javax annotations are introspected as attribute value maps...,"In Spring Data we support annotations and meta-annotations that are annotated with JSR305 annotations to discover whether a package, class or method has opted-in for non-nullability. We do not express a limit on meta-annotation nesting, so one can use either directly JSR305 annotations, Spring Framework annotations (that are annotated with JSR305) or further, composed annotations. 

That's, why we are using `AnnotatedElementUtils`. `@Nonnull`'s `when` attribute expresses non-nullability or allows opting out to express that a particular argument or return value may be null."
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/22663,"<!--
!!! For Security Vulnerabilities, please go to https://pivotal.io/security !!!
-->
**Affects:** 5.2.0.BUILD-SNAPSHOT

---
<!--
Thanks for taking the time to create an issue. Please read the following:

- Questions should be asked on Stack Overflow.
- For bugs, specify affected versions and explain what you are trying to do.
- For enhancements, provide context and describe the problem.

Issue or Pull Request? Create only one, not both. GitHub treats them as the same.
If unsure, start with an issue, and if you submit a pull request later, the
issue will be closed as superseded.
-->
After changes introduced in #22586, `AnnotationsScanner.getDeclaredAnnotation(source, annotationType)` method can't find `org.springframework.lang.Nullable` anymore because it gets filtered out by this filter:
```
static final AnnotationFilter PLAIN = packages(""java.lang"",
			""org.springframework.lang"");
```
from `org.springframework.core.annotation.AnnotationFilter`

Is that intentional? If so, what should be used instead?

Jus to clarify, we use `AnnotatedElementUtils.findMergedAnnotation`, but internally it relies on `AnnotationsScanner.getDeclaredAnnotation`",Why not simply look it up through regular JDK `getAnnotation` calls? Are you possibly not repeating the nullability declarations on interface implementations and subclasses?,
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/22547,"in ServletWebRequest class -> getHeaderValues() method:

getRequest().getHeaders(headerName) may return null .. and so, StringUtils.tostringArray() throws Null Pointer Exception.

",Can you please share the stack trace of the exception? `ServletWebRequest` is part of Spring Framework so the problem may need to be fixed there rather than in Spring Boot.,"Hi,
Sorry for the delay !

Here's the stacktrace:


```
java.lang.NullPointerException
java.util.Collections.list(Collections.java:5239)
org.springframework.util.StringUtils.toStringArray(StringUtils.java:980)
org.springframework.web.context.request.ServletWebRequest.getHeaderValues(ServletWebRequest.java:143)
org.springframework.web.accept.HeaderContentNegotiationStrategy.resolveMediaTypes(HeaderContentNegotiationStrategy.java:46)
org.springframework.web.accept.ContentNegotiationManager.resolveMediaTypes(ContentNegotiationManager.java:124)
org.springframework.web.servlet.mvc.condition.ProducesRequestCondition.getAcceptedMediaTypes(ProducesRequestCondition.java:262)
org.springframework.web.servlet.mvc.condition.ProducesRequestCondition.getMatchingCondition(ProducesRequestCondition.java:199)
org.springframework.web.servlet.mvc.method.RequestMappingInfo.getMatchingCondition(RequestMappingInfo.java:223)
org.springframework.web.servlet.mvc.method.RequestMappingInfoHandlerMapping.getMatchingMapping(RequestMappingInfoHandlerMapping.java:93)
org.springframework.web.servlet.mvc.method.RequestMappingInfoHandlerMapping.getMatchingMapping(RequestMappingInfoHandlerMapping.java:57)
org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.addMatchingMappings(AbstractHandlerMethodMapping.java:428)
org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.lookupHandlerMethod(AbstractHandlerMethodMapping.java:390)
org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.getHandlerInternal(AbstractHandlerMethodMapping.java:368)
org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.getHandlerInternal(AbstractHandlerMethodMapping.java:65)
org.springframework.web.servlet.handler.AbstractHandlerMapping.getHandler(AbstractHandlerMapping.java:401)
org.springframework.web.servlet.DispatcherServlet.getHandler(DispatcherServlet.java:1231)
org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1014)
org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)
org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005)
org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897)
javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
```"
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/22416,"**Affects:** 5.1.5

---

In Java 11 [`ReflectUtils.defineClass()`](https://github.com/spring-projects/spring-framework/blob/v5.1.5.RELEASE/spring-core/src/main/java/org/springframework/cglib/core/ReflectUtils.java#L489) uses the new `MethodHandles.Lookup.defineClass()`, this method uses the `contextClass`'s classloader, instead of the `loader` argument.

This difference in behaviour in Java 8 and Java 11 sometimes produces unexpected errors (eg. java.lang.LinkageError: attempted duplicate class definition)

Related issue #22310","Could we potentially identify them through a few standard rules, not having to reconfigure the entire mechanism for common upgrade scenarios (which requires understand of the underlying mechanisms to begin with)?

In any case, all we can do is to choose `ClassLoader.defineClass` even on JDK 9+ through a few further checks and assumptions, accepting the warnings that the JVM will log then. It's a fine line though; after all, `ClassLoader.defineClass` remains effectively deprecated for external calls on JDK 9+, with no equally powerful replacement API.",
spring-projects/spring-framework,https://github.com/spring-projects/spring-framework/issues/22272,"![image](https://user-images.githubusercontent.com/12087354/51299309-0507ea00-1a63-11e9-95d7-87b78bbbd96b.png)
![image](https://user-images.githubusercontent.com/12087354/51299322-105b1580-1a63-11e9-9b2d-7448eb9ddcce.png)
I configed `spring.http.encoding.charset=UTF-8` and `spring.http.encoding.enabled=true` and `spring.http.encoding.force=true,` but webflux does't decoding the filename , so response me 404; PS: spring webmvc works fine",Can you provide an isolated sample?,"@rstoyanchev I know webflux uses the `PathContainer`, you get the path value in this way: `String path = processPath(pathWithinHandler.value());`, the `PathContainer.value()` just return the non-decoded path `@Override
	public String value() {
		return this.path;
	}` 
the `processPath()` method does't decode the path too.
this is the simple demo: https://github.com/BiLuoHen/demo,
visit the `http://localhost:8080/pic.png` will get the pic resource, 
vist the `http://localhost:8080/图片.png` or `http://localhost:8080/%E5%9B%BE%E7%89%87.png` will get 404 response"
square/moshi,https://github.com/square/moshi/issues/1008,"The following model class definition fails with Moshi 1.9.0 and above:

```kotlin
@JsonClass(generateAdapter = true)
data class Model(@Json(name = ""id"") val id: String) {
    inline fun <reified T> inlineMethod(named: String): T? = null
}
```

The fields on the class & the body of its inline function are irrelevant - instead, it seems like the presence of the `reified` keyword will cause Moshi's codegen to fail with the following message:

```
e: [kapt] An exception occurred: java.util.NoSuchElementException: Key 0 is missing in the map.
	at kotlin.collections.MapsKt__MapWithDefaultKt.getOrImplicitDefaultNullable(MapWithDefault.kt:24)
	at kotlin.collections.MapsKt__MapsKt.getValue(Maps.kt:294)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toFunSpec(KotlinPoetMetadataSpecs.kt:543)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.access$toFunSpec(KotlinPoetMetadataSpecs.kt:1)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs$toTypeSpec$26.invoke(KotlinPoetMetadataSpecs.kt:429)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs$toTypeSpec$26.invoke(KotlinPoetMetadataSpecs.kt)
	at kotlin.sequences.TransformingSequence$iterator$1.next(Sequences.kt:172)
	at com.squareup.kotlinpoet.TypeSpec$Builder.addFunctions(TypeSpec.kt:786)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec(KotlinPoetMetadataSpecs.kt:403)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec(KotlinPoetMetadataSpecs.kt:173)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec$default(KotlinPoetMetadataSpecs.kt:171)
	at com.squareup.moshi.kotlin.codegen.MetadataKt.targetType(metadata.kt:153)
	at com.squareup.moshi.kotlin.codegen.JsonClassCodegenProcessor.adapterGenerator(JsonClassCodegenProcessor.kt:133)
	at com.squareup.moshi.kotlin.codegen.JsonClassCodegenProcessor.process(JsonClassCodegenProcessor.kt:107)
	at org.jetbrains.kotlin.kapt3.base.incremental.IncrementalProcessor.process(incrementalProcessors.kt)
(More kapt stuff below this line...)
```

On 1.8.0, code generation and compilation are successful.

As a workaround, the `reified inline fun` can be defined outside of the model class, as an extension function:

```kotlin
@JsonClass(generateAdapter = true)
data class Model(@Json(name = ""id"") val id: String)

// This works
inline fun <reified T> Model.inlineMethod(named: String): T? = null
```","Can you try the master snapshot and 1.9.1? We fixed an issue around type
variables last week.

On Wed, Nov 6, 2019 at 4:03 AM Marcel Schnelle <notifications@github.com>
wrote:

> The following model class definition fails with Moshi 1.9.0 and above:
>
> @JsonClass(generateAdapter = true)data class Model(@Json(name = ""id"") val id: String) {
>     inline fun <reified T> inlineMethod(named: String): T? = null
> }
>
> The fields on the class & the body of its inline function are irrelevant -
> instead, it seems like the presence of the reified keyword will cause
> Moshi's codegen to fail with the following message:
>
> e: [kapt] An exception occurred: java.util.NoSuchElementException: Key 0 is missing in the map.
> 	at kotlin.collections.MapsKt__MapWithDefaultKt.getOrImplicitDefaultNullable(MapWithDefault.kt:24)
> 	at kotlin.collections.MapsKt__MapsKt.getValue(Maps.kt:294)
> 	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toFunSpec(KotlinPoetMetadataSpecs.kt:543)
> 	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.access$toFunSpec(KotlinPoetMetadataSpecs.kt:1)
> 	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs$toTypeSpec$26.invoke(KotlinPoetMetadataSpecs.kt:429)
> 	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs$toTypeSpec$26.invoke(KotlinPoetMetadataSpecs.kt)
> 	at kotlin.sequences.TransformingSequence$iterator$1.next(Sequences.kt:172)
> 	at com.squareup.kotlinpoet.TypeSpec$Builder.addFunctions(TypeSpec.kt:786)
> 	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec(KotlinPoetMetadataSpecs.kt:403)
> 	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec(KotlinPoetMetadataSpecs.kt:173)
> 	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec$default(KotlinPoetMetadataSpecs.kt:171)
> 	at com.squareup.moshi.kotlin.codegen.MetadataKt.targetType(metadata.kt:153)
> 	at com.squareup.moshi.kotlin.codegen.JsonClassCodegenProcessor.adapterGenerator(JsonClassCodegenProcessor.kt:133)
> 	at com.squareup.moshi.kotlin.codegen.JsonClassCodegenProcessor.process(JsonClassCodegenProcessor.kt:107)
> 	at org.jetbrains.kotlin.kapt3.base.incremental.IncrementalProcessor.process(incrementalProcessors.kt)
> (More kapt stuff below this line...)
>
> On 1.8.0, code generation and compilation are successful.
>
> As a workaround, the reified inline fun can be defined outside of the
> model class, as an extension function:
>
> @JsonClass(generateAdapter = true)data class Model(@Json(name = ""id"") val id: String)
> // This worksinline fun <reified T> Model.inlineMethod(named: String): T? = null
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/square/moshi/issues/1008?email_source=notifications&email_token=AAKMJPXSTBM3DKJVYXEQZX3QSKXA7A5CNFSM4JJT5EK2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HXGS22A>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAKMJPSCATPIK33GHAVXEHDQSKXA7ANCNFSM4JJT5EKQ>
> .
>
","Neither `1.9.1` nor the latest `1.10.0-SNAPSHOT` seem to change anything about the failure, unfortunately. The stack trace is unchanged compared to the error using `1.9.0` as well."
square/moshi,https://github.com/square/moshi/issues/995,"I found another use case involving typealiases that fails to compile after upgrading to 1.9.1

```kotlin
typealias GeoJsonCoordinates = List<GeoJsonCoordinate>

typealias GeoJsonCoordinate = List<Double>

@JsonClass(generateAdapter = true)
data class GeoJsonDto(
    val type: String,
    val coordinates: GeoJsonCoordinates
)
```

This generates

```kotlin
private val listOfGeoJsonCoordinateAdapter: JsonAdapter<List<GeoJsonCoordinate>> =
      moshi.adapter(Types.newParameterizedType(List::class.java, GeoJsonCoordinate::class.java),
      emptySet(), ""coordinates"")
```

when it should generate

```kotlin
  private val listOfGeoJsonCoordinateAdapter: JsonAdapter<List<GeoJsonCoordinate>> =
      moshi.adapter(Types.newParameterizedType(List::class.java, Types.newParameterizedType(List::class.java, java.lang.Double::class.java)),
      emptySet(), ""coordinates"")
```",Would you mind trying a snapshot build of current master to verify the fix works for you?,Everything works correctly using 1.10.0-SNAPSHOT.
square/moshi,https://github.com/square/moshi/issues/990,"Hi,

First of all, tanks for the fantastic work on the 1.9.x release! I'm not sure if this is an issue or if I've simply misunderstood what the expected behavior is.

I have a data class with a `List<String>?` which would produce the following line in the code-gen generated adapter on 1.8.0:
`14 -> genres = nullableListOfStringAdapter.fromJson(reader)`

With 1.9.1 code-gen produces this:

`        14 -> genres = listOfStringAdapter.fromJson(reader) ?: throw Util.unexpectedNull(""genres"",
            ""genres"", reader)`

This results in `com.squareup.moshi.JsonDataException: Required value 'genres' missing at $.programs[0].event`.

Have I missed something in the 1.9.X release for marking lists as optional?",Can you share a code snippet? Otherwise I can probably piece together one,
square/moshi,https://github.com/square/moshi/issues/974,"I know this is *very* early, but... in case it helps. 🙂

Using `com.squareup.moshi:moshi:1.9.0` and `com.squareup.moshi:moshi-kotlin-codegen:1.9.0`, I get this error at build time. Works fine with 1.8.0.

```

> Task :common:kaptFrDebugKotlin FAILED
e: [kapt] An exception occurred: java.lang.IllegalArgumentException: abstract function internalReadFromProfile cannot have code
	at com.squareup.kotlinpoet.FunSpec.<init>(FunSpec.kt:55)
	at com.squareup.kotlinpoet.FunSpec.<init>(FunSpec.kt:37)
	at com.squareup.kotlinpoet.FunSpec$Builder.build(FunSpec.kt:486)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toFunSpec(KotlinPoetMetadataSpecs.kt:582)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.access$toFunSpec(KotlinPoetMetadataSpecs.kt:1)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs$toTypeSpec$26.invoke(KotlinPoetMetadataSpecs.kt:429)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs$toTypeSpec$26.invoke(KotlinPoetMetadataSpecs.kt)
	at kotlin.sequences.TransformingSequence$iterator$1.next(Sequences.kt:172)
	at com.squareup.kotlinpoet.TypeSpec$Builder.addFunctions(TypeSpec.kt:786)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec(KotlinPoetMetadataSpecs.kt:403)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec(KotlinPoetMetadataSpecs.kt:173)
	at com.squareup.moshi.kotlinpoet.metadata.specs.KotlinPoetMetadataSpecs.toTypeSpec(KotlinPoetMetadataSpecs.kt:144)
	at com.squareup.moshi.kotlin.codegen.MetadataKt.declaredProperties$default(metadata.kt:209)
	at com.squareup.moshi.kotlin.codegen.MetadataKt.targetType(metadata.kt:187)
	at com.squareup.moshi.kotlin.codegen.JsonClassCodegenProcessor.adapterGenerator(JsonClassCodegenProcessor.kt:133)
	at com.squareup.moshi.kotlin.codegen.JsonClassCodegenProcessor.process(JsonClassCodegenProcessor.kt:107)
	at org.jetbrains.kotlin.kapt3.base.incremental.IncrementalProcessor.process(incrementalProcessors.kt)
	at org.jetbrains.kotlin.kapt3.base.ProcessorWrapper.process(annotationProcessing.kt:147)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.callProcessor(JavacProcessingEnvironment.java:794)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.discoverAndRunProcs(JavacProcessingEnvironment.java:705)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.access$1800(JavacProcessingEnvironment.java:91)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment$Round.run(JavacProcessingEnvironment.java:1035)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.doProcessing(JavacProcessingEnvironment.java:1176)
	at com.sun.tools.javac.main.JavaCompiler.processAnnotations(JavaCompiler.java:1170)
	at com.sun.tools.javac.main.JavaCompiler.processAnnotations(JavaCompiler.java:1068)
	at org.jetbrains.kotlin.kapt3.base.AnnotationProcessingKt.doAnnotationProcessing(annotationProcessing.kt:79)
	at org.jetbrains.kotlin.kapt3.base.AnnotationProcessingKt.doAnnotationProcessing$default(annotationProcessing.kt:35)
	at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.runAnnotationProcessing(Kapt3Extension.kt:230)
	at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.analysisCompleted(Kapt3Extension.kt:188)
	at org.jetbrains.kotlin.kapt3.ClasspathBasedKapt3Extension.analysisCompleted(Kapt3Extension.kt:99)
	at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM$analyzeFilesWithJavaIntegration$2.invoke(TopDownAnalyzerFacadeForJVM.kt:96)
	at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration(TopDownAnalyzerFacadeForJVM.kt:106)
	at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$default(TopDownAnalyzerFacadeForJVM.kt:81)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:555)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:82)
	at org.jetbrains.kotlin.cli.common.messages.AnalyzerWithCompilerReport.analyzeAndReport(AnalyzerWithCompilerReport.kt:107)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.analyze(KotlinToJVMBytecodeCompiler.kt:546)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli(KotlinToJVMBytecodeCompiler.kt:177)
	at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:164)
	at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:54)
	at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:84)
	at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:42)
	at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:104)
	at org.jetbrains.kotlin.daemon.CompileServiceImpl.compile(CompileServiceImpl.kt:1558)
	at sun.reflect.GeneratedMethodAccessor108.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
	at sun.rmi.transport.Transport$1.run(Transport.java:200)
	at sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


> Task :xxxxxxxxxxxx:generateFrDebugRFile

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':common:kaptFrDebugKotlin'.
> Compilation error. See log for more details

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 22s
```",Can you share a code snippet? This should have been fixed with #972 ,@ZacSweers This is on a fairly big project and the stack trace doesn't mention any of our namespaces so I'm not sure how to reproduce it from scratch. I'll try to investigate tomorrow. Do you have an idea where I should start looking?
square/moshi,https://github.com/square/moshi/issues/922,"The generated adapter for this class behaves differently than the reflection version. When using the `KotlinJsonAdapterFactory` and not the generated adapter the result is an empty json-object, but the generated adapter still serializes the `foo` property.
```kotlin
@JsonClass(generateAdapter = true)
class DelegateTest {
	@delegate:Transient
	var foo: Int by Delegates.observable(5) { _, o, n -> println(""$o -> $n"")}
}
val test = DelegateTest()
test.foo = 10
val moshi = Moshi.Builder().build()
val adapter = moshi.adapter(DelegateTest::class.java)
val json = adapter.toJson(test)  // json contains property foo, but shouldn't
val result = adapter.fromJson(json) // result.foo is 10, but I would expect it to be 5
```
I'm willing to look into a fix for this if you accept PRs.","What happens if you just use `@Transient`? In either case happy to accept a PR, just not sure why the delegate site target is necessary in that case",You can't use `@Transient` because the property has no backing field. The backing field is provided by the delegate instead.
square/moshi,https://github.com/square/moshi/issues/857,"## Issue description

`val` can't have _**synchronized**_ as variable identifier because deserialization will fail at runtime for that specific field:

```
com.squareup.moshi.JsonDataException: Required property 'synchronized' missing at $.Channel.Items[0]
        at co.arkbox.msg.model.ItemJsonAdapter.fromJson(ItemJsonAdapter.kt:94)
        at co.arkbox.msg.model.ItemJsonAdapter.fromJson(ItemJsonAdapter.kt:16)
        at com.squareup.moshi.JsonAdapter$2.fromJson(JsonAdapter.java:137)
        at com.squareup.moshi.CollectionJsonAdapter.fromJson(CollectionJsonAdapter.java:76)
        at com.squareup.moshi.CollectionJsonAdapter$2.fromJson(CollectionJsonAdapter.java:53)
        at com.squareup.moshi.JsonAdapter$2.fromJson(JsonAdapter.java:137)
        at co.arkbox.msg.model.ChannelJsonAdapter.fromJson(ChannelJsonAdapter.kt:70)
        at co.arkbox.msg.model.ChannelJsonAdapter.fromJson(ChannelJsonAdapter.kt:16)
        at com.squareup.moshi.JsonAdapter$2.fromJson(JsonAdapter.java:137)
        at co.arkbox.msg.model.MessageJsonAdapter.fromJson(MessageJsonAdapter.kt:40)
        at co.arkbox.msg.model.MessageJsonAdapter.fromJson(MessageJsonAdapter.kt:13)
        at com.squareup.moshi.JsonAdapter$2.fromJson(JsonAdapter.java:137)
        at retrofit2.converter.moshi.MoshiResponseBodyConverter.convert(MoshiResponseBodyConverter.java:45)
        at retrofit2.converter.moshi.MoshiResponseBodyConverter.convert(MoshiResponseBodyConverter.java:27)
        at retrofit2.OkHttpCall.parseResponse(OkHttpCall.java:223)
        at retrofit2.OkHttpCall$1.onResponse(OkHttpCall.java:121)
        at okhttp3.RealCall$AsyncCall.execute(RealCall.java:174)
        at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
        at java.lang.Thread.run(Thread.java:764)
```

**Kotlin**

```
@JsonClass(generateAdapter = true)
data class Message(
    @field:Json(name = ""Title"") val title: String,
    @field:Json(name = ""Channel"") val channel: Channel
)

@JsonClass(generateAdapter = true)
data class Channel(
    @field:Json(name = ""ChannelId"") val channelId: Int,
    @field:Json(name = ""Items"") val itemList: List<Item>
)

@JsonClass(generateAdapter = true)
data class Item(
    @field:Json(name = ""Id"") val id: Int,
    @field:Json(name = ""Description"") val description: String,
    @field:Json(name = ""Order"") val order: Int,
    // Failure: This won't work >>
    @field:Json(name = ""Synchronized"") val synchronized: Boolean
)

```

**Json**

```
{
  ""Title"": ""Container 1"",
  ""Channel"": {
    ""ChannelId"": 192,
    ""Items"": [
      {
        ""ItemId"": 5960,
        ""Description"": ""Item 5960"",
        ""Order"": 1,
        ""Synchronized"": false
      }
    ]
  }
}
```

Once the variable _**synchronized**_ has been renamed to something else, the deserialization works correctly

```
   ...
    // OK: This works correctly >>
    @field:Json(name = ""Synchronized"") val newNonConflictingName: Boolean
   ...
```

On the other hand, if the variable _**synchronized**_ is `Nullable` (in this case `Boolean?`) the deserialization won't fail, nevertheless _**synchronized**_ would be set to `null` even though there is an existent value `true/false` in the Json property

```
   ...
    // false/true deserialized as null >>
    @field:Json(name = ""Synchronized"") val synchronized: Boolean?
   ...
```

## Integration method

**Gradle 5.1.1**

```
implementation ""com.squareup.moshi:moshi:1.8.0""
kapt ""com.squareup.moshi:moshi-kotlin-codegen:1.8.0""
```

## Moshi version

1.8.0

## Kotlin version

1.3.31

## System Information

Android Studio 3.4
Build #AI-183.5429.30.34.5452501, built on April 10, 2019
JRE: 1.8.0_152-release-1343-b01 x86_64
JVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o
macOS 10.14.5","can you post the generated adapter here, if you have it handy?",
square/moshi,https://github.com/square/moshi/issues/800,"Test data class:
```kotlin
package com.company.package

import com.squareup.moshi.Json
import com.squareup.moshi.JsonClass

@JsonClass(generateAdapter = true)
data class Test(
        @Json(name = ""json_property_name"")
        val kotlinPropertyName: String
)
```

Resulting in the generated adapter:
```kotlin
// Code generated by moshi-kotlin-codegen. Do not edit.
package com.company.package

import com.squareup.moshi.JsonAdapter
import com.squareup.moshi.JsonDataException
import com.squareup.moshi.JsonReader
import com.squareup.moshi.JsonWriter
import com.squareup.moshi.Moshi
import java.lang.NullPointerException
import kotlin.String

class TestJsonAdapter(moshi: Moshi) : JsonAdapter<Test>() {
    private val options: JsonReader.Options = JsonReader.Options.of(""json_property_name"")

    private val stringAdapter: JsonAdapter<String> =
            moshi.adapter<String>(String::class.java, kotlin.collections.emptySet(), ""kotlinPropertyName"")

    override fun toString(): String = ""GeneratedJsonAdapter(Test)""

    override fun fromJson(reader: JsonReader): Test {
        var kotlinPropertyName: String? = null
        reader.beginObject()
        while (reader.hasNext()) {
            when (reader.selectName(options)) {
                0 -> kotlinPropertyName = stringAdapter.fromJson(reader) ?: throw JsonDataException(""Non-null value 'kotlinPropertyName' was null at ${reader.path}"")
                -1 -> {
                    // Unknown name, skip it.
                    reader.skipName()
                    reader.skipValue()
                }
            }
        }
        reader.endObject()
        var result = Test(
                kotlinPropertyName = kotlinPropertyName ?: throw JsonDataException(""Required property 'kotlinPropertyName' missing at ${reader.path}""))
        return result
    }

    override fun toJson(writer: JsonWriter, value: Test?) {
        if (value == null) {
            throw NullPointerException(""value was null! Wrap in .nullSafe() to write nullable values."")
        }
        writer.beginObject()
        writer.name(""json_property_name"")
        stringAdapter.toJson(writer, value.kotlinPropertyName)
        writer.endObject()
    }
}
```

Wrong part:
```kotlin
throw JsonDataException(""Required property 'kotlinPropertyName' missing at ${reader.path}"")
```

The exception message should state the property name used in the JSON data (`json_property_name`) instead of the name in the kotlin class (`kotlinPropertyName`). Because it mentions the JSON path, it's more consistent to also use the JSON property name.

I think it should generate:
```kotlin
throw JsonDataException(""Required property 'json_property_name' missing at ${reader.path}"")
```

It could be fixed by changing `property.localName` to `property.jsonName` in the [AdapterGenerator](https://github.com/square/moshi/blob/ded3bccc6089c8a39ca1ebf7227fcee122572512/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/AdapterGenerator.kt#L234). I'm not sure if you agree, but IMO it would make more sense to use the JSON property name instead of the local property name in the message. I will create a pull request.",Should we just include both when they're different? That's easy.,
square/moshi,https://github.com/square/moshi/issues/624,"https://github.com/square/moshi/blob/bb2705128c6062520c83432bd3073ffb333d6d94/moshi/src/main/java/com/squareup/moshi/ClassJsonAdapter.java#L101

I was taking a quick peek at the source to try to satisfy my curiosity regarding whether there was or not any relevant difference between using private or package-private fields and I thought there wouldn't be a reason to call setAccessible on non-private fields, but it's called anyway. I'm not sure if this call should be wrapped on a field.isAccessible check?",what's the drawback?,"Based on what I think is the openjdk 7 implementation it seems there is an assignment going on no matter what unless you try to set accessible the constructor of Class (see L143 in http://www.docjar.com/html/api/java/lang/reflect/AccessibleObject.java.html).
Whether at runtime that assignment is meaningless if obj.override is equal to flag (true in our case) or not I don't know, but if it is, then what's the point of isAccessible() existing, or rather, less philosophically, why does this code have the isAccessible wrap? https://github.com/square/moshi/blob/ee75000c94d20b9b23a98b0d09940ae820635d99/moshi/src/main/java/com/squareup/moshi/Types.java#L230
I understand it could easily be because it's code written by different people, but I'm not confident enough with reflection to assume so."
square/moshi,https://github.com/square/moshi/issues/563,"I have to deal with a broken API that can return strings or arrays for fields ....

I'm using custom annotations https://github.com/square/moshi/issues/295 to manage that.

Now I want to convert those classes to Kotlin and waited for the codegen to avoid kotlin-reflect but it seems the custom annotations are not taken in account in that case :(

Is there a solution to have both without reflection?


",Could you isolate this into a test case?,"I'll try start of next week, but Kotlin annotation seems to require kotlin-reflect in all cases so even if they were retained they would still require the kotlinfactory."
square/moshi,https://github.com/square/moshi/issues/308,"I have the following datastructures:

```kotlin
internal data class AccountInfo(
  @Json(name = ""User"") val user: User,
  @Json(name = ""Rules"") val rules: Map<String, Boolean>
)

data class User(
  @Json(name = ""ID"") val id: Int,
  @Json(name = ""FirstName"") val firstName: String? = null,
  @Json(name = ""LastName"") val lastName: String? = null
)

val jsonStr = """"""{""User"":{""FirstName"":""Josh"",""LastName"":""Friend"",""ID"":10000000},""Rules"":{""Example"":true}}""""""

val moshi = Moshi.Builder().build()
val adapter = moshi.adapter(AccountInfo::class.java)
```

With Moshi 1.4.0 things are OK:

```kotlin
val account = adapter.fromJson(json)
// AccountInfo(user=User(id=10000000, firstName=Josh, lastName=Friend), rules={Example=true})
```

With Moshi 1.5.0, the nested object fields are all `null`:

```kotlin
val account = adapter.fromJson(json)
// AccountInfo(user=null, rules=null)
```

I converted the above classes to Java and the nested objects were no longer null. I'm not using the new kotlin specific Moshi adapter.",Do we need to add a new ProGuard rule?,
square/okhttp,https://github.com/square/okhttp/issues/5770,"Okhttp version: 4.3.1

When using okhttp request an URL `https://>`, it crashes:

```
Fatal Exception: java.lang.IllegalArgumentException: protocol = https host = null
       at sun.net.spi.DefaultProxySelector.select + 183(DefaultProxySelector.java:183)
       at okhttp3.internal.connection.RouteSelector.resetNextProxy + 103(RouteSelector.java:103)
       at okhttp3.internal.connection.RouteSelector.<init> + 53(RouteSelector.java:53)
       at okhttp3.internal.connection.ExchangeFinder.<init> + 61(ExchangeFinder.java:61)
       at okhttp3.internal.connection.Transmitter.prepareToConnect + 134(Transmitter.java:134)
       at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept + 62(RetryAndFollowUpInterceptor.java:62)
       at okhttp3.internal.http.RealInterceptorChain.proceed + 112(RealInterceptorChain.java:112)
       at okhttp3.internal.http.RealInterceptorChain.proceed + 87(RealInterceptorChain.java:87)
       at okhttp3.RealCall.getResponseWithInterceptorChain + 194(RealCall.java:194)
       at okhttp3.RealCall$AsyncCall.run + 138(RealCall.java:138)
       at java.util.concurrent.ThreadPoolExecutor.runWorker + 1167(ThreadPoolExecutor.java:1167)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run + 641(ThreadPoolExecutor.java:641)
       at java.lang.Thread.run + 764(Thread.java:764)
```",Does it contain `_` or any other special characters?,"@swankjesse the full URL is just `https://>`. I have created a quickfix by [SdkEditor](https://github.com/iwhys/sdk-editor-plugin):

![image](https://user-images.githubusercontent.com/5214214/74396915-60670000-4e4e-11ea-9f30-833789109c5f.png)

It works, and if it is acceptable, I can create a PR for this our Okhttp."
square/okhttp,https://github.com/square/okhttp/issues/5731,"Based on this [issue](https://github.com/gildor/kotlin-coroutines-retrofit/issues/34). If we're throwing exceptions inside interceptor, they should inherit IOException to be properly handled without crashing the app. But there's some situations in which you don't want to inherit IOException.
One of this cases: we are handling errors of API. Not HTTP errors. API returns some templated entities with status-code which can be checked to detect some errors like invalid parameters that was passed. 
And one of error handling solutions is to create interceptor that checks all of requests' responses and throwing domain exceptions if status code indicates error.
I suggest to add some parameter to OkHttpClient.Builder that will allow us to disable canceling requests if some Non-IOException was thrown inside interceptor.",What would it do instead? Somebody needs to close the response and release resources.,"Sorry, I put it wrong. My idea is not to crash the app when Non-IOException occurred inside interceptor. "
square/okhttp,https://github.com/square/okhttp/issues/5730,"We use okhttp3.12.1 version in our android code.
And the server use http2.0 protocols.

we build about 3 or 4 okhttpclient instance and make a common connectPool and use OkhttpClient.Builder.connectionPool api to set it.

but when debug, I found the connectPool has 3 connect and they have the same host, I want to know why not reuse in one connect....

I also found one issue but it's not my situation because  ProxySelector.getDefault return not null  in my code.
https://github.com/square/okhttp/pull/5524",Could you try isolating this into a test case? Also please upgrade to the latest 3.12.x release; there have been many updates there.,"> Hmmm, that's odd. Could you try isolating this into a test case? Also please upgrade to the latest 3.12.x release; there have been many updates there.

I write a test demo,here is all the code when I click a button to excute. pls see the `testOkhttp()` 
method
here is the test code:

```gradle
implementation ""com.squareup.okhttp3:okhttp:3.12.7""
```
```kotlin
   val url = ""https://id-app.akulaku.com/figd/api/json/public/item/detail.do?countryCode=ID&id=65886&languageCode=EN&selectedAreaId=1&deviceId=ffff-aaa""
    val connectionPool = ConnectionPool()

    private fun testOkhttp() = Thread(Runnable {

        var okHttpClient = buildOkHttpClient(connectionPool)
        val request = makeRequest(url)
        val resp = okHttpClient.newCall(request).execute()
        resp.body()!!.string()
        //now we have a tcp connection in connection pool
        printConnectionPoolInfo()
        for (i in 0 until 3) {
            okHttpClient = buildOkHttpClient(connectionPool)
            val url2Request = makeRequest(url)
            okHttpClient.newCall(url2Request).enqueue(object : Callback {
                override fun onFailure(call: Call, e: IOException) {
                }

                override fun onResponse(call: Call, response: Response) {
                    response.body()!!.string()
                }
            })
        }
        Thread.sleep(5 * 1000)
        printConnectionPoolInfo()

    }).start()

    private fun makeRequest(url:String): Request {
        return Request.Builder()
            .url(url)
            .build()
    }

    private fun printConnectionPoolInfo() {
        //we print conection pool info
        val field = ConnectionPool::class.java.getDeclaredField(""connections"")
        field.isAccessible = true
        val deque = field.get(connectionPool) as Deque<RealConnection>
        if (connectionPool.connectionCount() > 0) {
            Log.i(""lxw"", ""connectionPool size is ${connectionPool.connectionCount()}"")
        }
        for (con in deque) {
            val protocol = con.protocol().toString()
            val url = con.route().address().url().toString()
            Log.i(""lxw"", ""${con.hashCode()} protocol is $protocol and url is $url"")
        }
    }

    private fun buildOkHttpClient(pool: ConnectionPool): OkHttpClient {
        return OkHttpClient.Builder().connectionPool(pool).build();
    }
```
#### the logcat output is:
```
01-16 03:16:45.066 10122 10181 I lxw     : connectionPool size is 4
01-16 03:16:45.066 10122 10181 I lxw     : 174763262 protocol is h2 and url is https://id-app.akulaku.com/
01-16 03:16:45.066 10122 10181 I lxw     : 254679820 protocol is h2 and url is https://id-app.akulaku.com/
01-16 03:16:45.066 10122 10181 I lxw     : 170351701 protocol is h2 and url is https://id-app.akulaku.com/
01-16 03:16:45.066 10122 10181 I lxw     : 262301290 protocol is h2 and url is https://id-app.akulaku.com/
```

the protocol is http2.0,so I want to know why the connectionPool is not work?"
square/okhttp,https://github.com/square/okhttp/issues/5713,"Hello, 

Since we have updated our Android app DAVx⁵ from okhttp 3.12.5 to 3.12.7, we start receiving these exceptions: 

```
java.util.concurrent.RejectedExecutionException: 
  at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution (ThreadPoolExecutor.java:2104)
  at java.util.concurrent.ThreadPoolExecutor.reject (ThreadPoolExecutor.java:848)
  at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute (ScheduledThreadPoolExecutor.java:334)
  at java.util.concurrent.ScheduledThreadPoolExecutor.schedule (ScheduledThreadPoolExecutor.java:562)
  at java.util.concurrent.ScheduledThreadPoolExecutor.execute (ScheduledThreadPoolExecutor.java:654)
  at okhttp3.internal.http2.Http2Connection.sendDegradedPingLater (Http2Connection.java:598)
  at okhttp3.internal.http2.Http2Stream$StreamTimeout.timedOut (Http2Stream.java:668)
  at okio.AsyncTimeout$Watchdog.run (AsyncTimeout.kt:198)
```

It's not that often, but this exception was not there before. I think it occurs when
* a thread with okhttp I/O is `interrupt()`ed (because the user cancels the action), and
* okhttp tries to send a delayed HTTP/2 ping on such an interrupted channel later.

Unfortunately, I can't provide reliable steps to reproduce yet. Is this however a problem you can imagine to happen or do you need more information?",When can we expect a release for 3.12.x branch?,
square/okhttp,https://github.com/square/okhttp/issues/5700,"I pushed a new version of my app to production and started to get bunch of complains from users.
Turns out with okhttp 4.3.0 there is SSLHandshakeException happening only on Android 5 for some reason. I'm getting this exception for all my requests including requests from 3th party SDKs. It's reproducible on API 21 Emulator.

```
javax.net.ssl.SSLHandshakeException: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found.
        at com.android.org.conscrypt.OpenSSLSocketImpl.startHandshake(OpenSSLSocketImpl.java:306)
        at com.android.okhttp.Connection.upgradeToTls(Connection.java:197)
        at com.android.okhttp.Connection.connect(Connection.java:151)
        at com.android.okhttp.internal.http.HttpEngine.connect(HttpEngine.java:276)
        at com.android.okhttp.internal.http.HttpEngine.sendRequest(HttpEngine.java:211)
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:373)
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:323)
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponseCode(HttpURLConnectionImpl.java:491)
        at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getResponseCode(DelegatingHttpsURLConnection.java:105)
        at com.android.okhttp.internal.http.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:25)
...
     Caused by: java.security.cert.CertificateException: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found.
        at com.android.org.conscrypt.TrustManagerImpl.checkTrusted(TrustManagerImpl.java:318)
        at com.android.org.conscrypt.TrustManagerImpl.checkServerTrusted(TrustManagerImpl.java:219)
        at com.android.org.conscrypt.Platform.checkServerTrusted(Platform.java:113)
        at com.android.org.conscrypt.OpenSSLSocketImpl.verifyCertificateChain(OpenSSLSocketImpl.java:525)
        at com.android.org.conscrypt.NativeCrypto.SSL_do_handshake(Native Method)
        at com.android.org.conscrypt.OpenSSLSocketImpl.startHandshake(OpenSSLSocketImpl.java:302)
        at com.android.okhttp.Connection.upgradeToTls(Connection.java:197) 
        at com.android.okhttp.Connection.connect(Connection.java:151) 
        at com.android.okhttp.internal.http.HttpEngine.connect(HttpEngine.java:276) 
        at com.android.okhttp.internal.http.HttpEngine.sendRequest(HttpEngine.java:211) 
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:373) 
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:323) 
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponseCode(HttpURLConnectionImpl.java:491) 
        at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getResponseCode(DelegatingHttpsURLConnection.java:105) 
        at com.android.okhttp.internal.http.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:25) 
...
     Caused by: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found.
        at com.android.org.conscrypt.TrustManagerImpl.checkTrusted(TrustManagerImpl.java:318) 
        at com.android.org.conscrypt.TrustManagerImpl.checkServerTrusted(TrustManagerImpl.java:219) 
        at com.android.org.conscrypt.Platform.checkServerTrusted(Platform.java:113) 
        at com.android.org.conscrypt.OpenSSLSocketImpl.verifyCertificateChain(OpenSSLSocketImpl.java:525) 
        at com.android.org.conscrypt.NativeCrypto.SSL_do_handshake(Native Method) 
        at com.android.org.conscrypt.OpenSSLSocketImpl.startHandshake(OpenSSLSocketImpl.java:302) 
        at com.android.okhttp.Connection.upgradeToTls(Connection.java:197) 
        at com.android.okhttp.Connection.connect(Connection.java:151) 
        at com.android.okhttp.internal.http.HttpEngine.connect(HttpEngine.java:276) 
        at com.android.okhttp.internal.http.HttpEngine.sendRequest(HttpEngine.java:211) 
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:373) 
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:323) 
        at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponseCode(HttpURLConnectionImpl.java:491) 
        at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getResponseCode(DelegatingHttpsURLConnection.java:105) 
        at com.android.okhttp.internal.http.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:25) 
...
```",What version did you upgrade from 4.2?,"Hi, I was using 4.2.2 before.
It happens with almost every HTTPS request I believe on API 21, maybe with some exception as github pages worked fine.

Will try to make a test now."
square/okhttp,https://github.com/square/okhttp/issues/5666,"Hello
I use EventListener to record network detail.But I find that if the request is a 302 request ,the EventListener has a bug like this:

1. the first 302 step ,EventListener will record the detail from callStart method to callEnd method;
2. but the second 200 step,EventListener only record the detail to responseBodyStart,not record call end.

So I don't know when the time a 302 request is end. I fell that is a bug. I hope get a solution to resolve this case.
Thank you !
the log as follows:
```
2019-12-26 14:22:25.702 11816-11816/com.qunar.qapm.moudle I/qapm: HttpEventListener callStart start time = 1577341345702
2019-12-26 14:22:25.712 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener dns start time = 1577341345712
2019-12-26 14:22:25.738 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener dns end time = 1577341345738
2019-12-26 14:22:25.739 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect start time = 1577341345739
2019-12-26 14:22:25.747 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener secureConnect start time = 1577341345747
2019-12-26 14:22:25.785 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener secureConnect end time = 1577341345785
2019-12-26 14:22:25.787 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect end time = 1577341345787
2019-12-26 14:22:25.787 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect Acquired  time = 1577341345787
2019-12-26 14:22:25.788 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener request header start  time = 1577341345788
2019-12-26 14:22:25.789 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener request header end  time = 1577341345789
2019-12-26 14:22:25.789 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener response header start  time = 1577341345789
2019-12-26 14:22:25.799 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener response header end  time = 1577341345799,code = 302,isRedirect = true
2019-12-26 14:22:25.799 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener response body start  time = 1577341345799
2019-12-26 14:22:25.800 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener response body end  time = 1577341345800
2019-12-26 14:22:25.800 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect release  time = 1577341345800
2019-12-26 14:22:25.800 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener call  end  time = 1577341345800
2019-12-26 14:22:25.801 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect Acquired  time = 1577341345801
2019-12-26 14:22:25.801 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener request header start  time = 1577341345801
2019-12-26 14:22:25.802 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect release  time = 1577341345802
2019-12-26 14:22:25.802 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener dns start time = 1577341345802
2019-12-26 14:22:25.809 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener dns end time = 1577341345809
2019-12-26 14:22:25.810 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect start time = 1577341345810
2019-12-26 14:22:25.813 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener secureConnect start time = 1577341345813
2019-12-26 14:22:25.836 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener secureConnect end time = 1577341345836
2019-12-26 14:22:25.838 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect end time = 1577341345838
2019-12-26 14:22:25.838 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener connect Acquired  time = 1577341345838
2019-12-26 14:22:25.838 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener request header start  time = 1577341345838
2019-12-26 14:22:25.840 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener request header end  time = 1577341345840
2019-12-26 14:22:25.841 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener response header start  time = 1577341345841
2019-12-26 14:22:25.935 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener response header end  time = 1577341345935,code = 200,isRedirect = false
2019-12-26 14:22:25.935 11816-12738/com.qunar.qapm.moudle I/qapm: HttpEventListener response body start  time = 1577341345935
```
","Can you provide a reproducible test case with bug reports in future? Or ask on stackoverflow.

Works for me

```
package okhttp3.logging

import okhttp3.OkHttpClient
import okhttp3.Request

fun main() {
  val client = OkHttpClient.Builder()
      .eventListenerFactory(LoggingEventListener.Factory())
      .build()

  val call = client.newCall(
      Request.Builder().url(
          ""https://httpbin.org/redirect-to?url=https%3A%2F%2Fapi.twitter.com%2Frobots.txt&status_code=302""
      ).build()
  )

  call.execute()
      .use {
        println(""Completed"")
      }
}
```

```
Dec 26, 2019 7:34:15 AM okhttp3.internal.platform.Platform log
INFO: [0 ms] callStart: Request{method=GET, url=https://httpbin.org/redirect-to?url=https%3A%2F%2Fapi.twitter.com%2Frobots.txt&status_code=302}
Dec 26, 2019 7:34:15 AM okhttp3.internal.platform.Platform log
INFO: [50 ms] proxySelectStart: https://httpbin.org/
Dec 26, 2019 7:34:15 AM okhttp3.internal.platform.Platform log
INFO: [51 ms] proxySelectEnd: [DIRECT]
Dec 26, 2019 7:34:15 AM okhttp3.internal.platform.Platform log
INFO: [55 ms] dnsStart: httpbin.org
Dec 26, 2019 7:34:15 AM okhttp3.internal.platform.Platform log
INFO: [113 ms] dnsEnd: [httpbin.org/54.172.95.6, httpbin.org/34.193.212.251]
Dec 26, 2019 7:34:15 AM okhttp3.internal.platform.Platform log
INFO: [118 ms] connectStart: httpbin.org/54.172.95.6:443 DIRECT
Dec 26, 2019 7:34:15 AM okhttp3.internal.platform.Platform log
INFO: [244 ms] secureConnectStart
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [770 ms] secureConnectEnd: Handshake{tlsVersion=TLS_1_2 cipherSuite=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 peerCertificates=[CN=httpbin.org, CN=Amazon, OU=Server CA 1B, O=Amazon, C=US, CN=Amazon Root CA 1, O=Amazon, C=US, CN=Starfield Services Root Certificate Authority - G2, O=""Starfield Technologies, Inc."", L=Scottsdale, ST=Arizona, C=US] localCertificates=[]}
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [770 ms] connectEnd: http/1.1
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [772 ms] connectionAcquired: Connection{httpbin.org:443, proxy=DIRECT hostAddress=httpbin.org/54.172.95.6:443 cipherSuite=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 protocol=http/1.1}
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [775 ms] requestHeadersStart
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [776 ms] requestHeadersEnd
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [777 ms] responseHeadersStart
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [888 ms] responseHeadersEnd: Response{protocol=http/1.1, code=302, message=FOUND, url=https://httpbin.org/redirect-to?url=https%3A%2F%2Fapi.twitter.com%2Frobots.txt&status_code=302}
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [889 ms] responseBodyStart
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [891 ms] responseBodyEnd: byteCount=0
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [892 ms] connectionReleased
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [893 ms] proxySelectStart: https://api.twitter.com/
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [893 ms] proxySelectEnd: [DIRECT]
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [893 ms] dnsStart: api.twitter.com
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [947 ms] dnsEnd: [api.twitter.com/104.244.42.66, api.twitter.com/104.244.42.194, api.twitter.com/104.244.42.130, api.twitter.com/104.244.42.2]
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [948 ms] connectStart: api.twitter.com/104.244.42.66:443 DIRECT
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [975 ms] secureConnectStart
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [1087 ms] secureConnectEnd: Handshake{tlsVersion=TLS_1_2 cipherSuite=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 peerCertificates=[CN=api.twitter.com, OU=lon3, O=""Twitter, Inc."", L=San Francisco, ST=California, C=US, CN=DigiCert SHA2 High Assurance Server CA, OU=www.digicert.com, O=DigiCert Inc, C=US, CN=DigiCert High Assurance EV Root CA, OU=www.digicert.com, O=DigiCert Inc, C=US] localCertificates=[]}
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [1106 ms] connectEnd: h2
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [1107 ms] connectionAcquired: Connection{api.twitter.com:443, proxy=DIRECT hostAddress=api.twitter.com/104.244.42.66:443 cipherSuite=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 protocol=h2}
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [1109 ms] requestHeadersStart
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [1116 ms] requestHeadersEnd
Dec 26, 2019 7:34:16 AM okhttp3.internal.platform.Platform log
INFO: [1116 ms] responseHeadersStart
Dec 26, 2019 7:34:17 AM okhttp3.internal.platform.Platform log
INFO: [1278 ms] responseHeadersEnd: Response{protocol=h2, code=200, message=, url=https://api.twitter.com/robots.txt}
Dec 26, 2019 7:34:17 AM okhttp3.internal.platform.Platform log
INFO: [1279 ms] responseBodyStart
Dec 26, 2019 7:34:17 AM okhttp3.internal.platform.Platform log
INFO: [1285 ms] responseBodyEnd: byteCount=0
Dec 26, 2019 7:34:17 AM okhttp3.internal.platform.Platform log
INFO: [1285 ms] connectionReleased
Dec 26, 2019 7:34:17 AM okhttp3.internal.platform.Platform log
INFO: [1285 ms] callEnd
Completed
```","hello 
this is my test case and my compile version is
""com.squareup.okhttp3:okhttp:3.12.6"" and ""com.squareup.okio:okio:1.15.0""
your can use my url to try.
Perhaps because of my okhttp version is not new?



`  private OkHttpClient client;

    private void request(String url) {
        if (client == null) {
            OkHttpClient.Builder builder = new OkHttpClient.Builder();
            builder.eventListenerFactory(HttpEventListener.FACTORY);
            client = builder.build();
        }
        Request.Builder requestBuilder = new Request.Builder();
        requestBuilder.url(url);
        Call call = client.newCall(requestBuilder.build());
        call.enqueue(new Callback() {
            @Override
            public void onFailure(Call call, IOException e) {
                Log.i(""NetWorkActivity"", ""onFailure"");
            }

            @Override
            public void onResponse(Call call, Response response) throws IOException {
                Log.i(""NetWorkActivity"", ""onResponse"");
            }
        });

    }
    private void test(){
        request(""http://www.baidu.com/link?url=ByBJLpHsj5nXx6DESXbmMjIrU5W4Eh0yg5wCQpe3kCQMlJK_RJBmdEYGm0DDTCoTDGaz7rH80gxjvtvoqJuYxK"");
    }`"
square/okhttp,https://github.com/square/okhttp/issues/5660,"RFC: https://tools.ietf.org/html/rfc7578#appendix-A

Related Comment and issue: https://github.com/django/channels/issues/1386#issuecomment-568215439
https://twistedmatrix.com/trac/ticket/9739

### Background: 

Consider a multipart request as such:

Body:
```
--d66f495a-c4d1-487c-9277-9ab1a20001cc
Content-Disposition: form-data; name=""content""
Content-Type: multipart/form-data; charset=utf-8

Anything
--d66f495a-c4d1-487c-9277-9ab1a20001cc--
```

Header:
`Content-Type: multipart/form-data; boundary=d66f495a-c4d1-487c-9277-9ab1a20001cc`

A new change in Python 3.7 considers this request multipart header as invalid, which according to @twm is not compliant with the latest change in the RFC (2015).

Hence, on new Python versions, when the request is parsed, it tries to get the boundary from the multipart body `Content-Type` header and it returns empty string since there is none, and throws saying that is is `Invalid Boundary`
 ","Why would a file be split into multipart? Did you mean multiple files (`multipart/mixed`, [RFC 2388 section 4.2](https://tools.ietf.org/html/rfc2388#section-4.2), deprecated in [RFC 7578 section 4.3](https://tools.ietf.org/html/rfc7578#section-4.3))? Or chunked transfer encoding, which happens at a different layer?",I'll attach the actual request soon to make it clear. I may be wrong here
square/okhttp,https://github.com/square/okhttp/issues/5651,"com.squareup.okhttp3:okhttp:3.11.0

device：oppo、vivo 97% huawei:ALE-UL00 3.0%
Android system version:
oppo+vivo 6.0.1; huawei:6.0.0



java.lang.ArrayIndexOutOfBoundsException: size=1021 offset=0 byteCount=-791501174879550467
	at okio.Util.checkOffsetAndCount(Util.java:30)
	at okio.Buffer.write(Buffer.java:1275)
	at okio.RealBufferedSink.write(RealBufferedSink.java:41)
	at okhttp3.internal.http2.Http2Writer.headers(Http2Writer.java:307)
	at okhttp3.internal.http2.Http2Writer.synStream(Http2Writer.java:127)
	at okhttp3.internal.http2.Http2Connection.newStream(Http2Connection.java:258)
	at okhttp3.internal.http2.Http2Connection.newStream(Http2Connection.java:230)
	at okhttp3.internal.http2.Http2Codec.writeRequestHeaders(Http2Codec.java:113)
	at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:50)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at com.facebook.react.modules.network.NetworkingModule$1.intercept(NetworkingModule.java:291)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:126)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:200)
	at okhttp3.RealCall$AsyncCall.execute(RealCall.java:147)
	at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
	at java.lang.Thread.run(Thread.java:818)",Can you reproduce this?,"> Looks like concurrent access to a buffer? Or perhaps a bug in the platform?
> 
> Can you reproduce this?

I use the oppo phone with system version 6.0.1, which can be reproduced, but most other phones are fine"
square/okhttp,https://github.com/square/okhttp/issues/5617,"Trying to iterate over a `Headers` instance does not work when using plain Java 11 and JPMS.

The reason is that `Headers implements Iterator<kotlin.Pair>` and `kotlin.Pair` is not available to JPMS.

This works fine in Java 8 (as the Kotlin stdlib ends up in the classpath), but does not work when using Java 11 and proper JPMS modules, because the application class that iterates over the `Headers` would need to JPMS-_read_ `kotlin.Pair`, which would require a directive in the application `module-info.java`.
Unfortunately the Kotlin stdlib does not support JPMS (no `Automatic-Module-Name` in the manifest, no `module-info.class` in the jar), so that leaves the application relying on automatic modules with unstable module names.

This can be worked around iterating using `Headers.names()` and `Headers.values(name)`.

FTR, I encountered this problem in [CometD 6](https://github.com/cometd/cometd/tree/6.0.x) which is based on Java 11 and JPMS.",What action are you proposing OkHttp take here?,"I know OkHttp 4 has been rewritten in Kotlin, so not sure what to suggest here.

Personally, I would like OkHttp classes that are APIs, such as `Headers`, to explicitly not have Kotlin classes in method signatures, class inheritance, type parameters, etc.
That would ensure maximum usability from Java 11 + JPMS, as the only dependencies an application would need to require in `module-info.java` would be Java-only ones.

I don't think it's a Kotlin issue as they need to remain Java 6 compatible and such, so for Kotlin JPMS modules are far far away.

However, removing `implements Iterable<kotlin.Pair>` may be an incompatible change, so I raised this issue just as a heads-up, as there is an easy workaround to iterate over `Headers`.

Trying to iterate over `Headers` using `Iterable` would not even compile with Java 11 + JPMS, so it's a hard error, but as I said easily workaroundable with a small code change.
I only found this example in my usage of OkHttp, but it may be possible that there are other cases where there is no work around."
square/okhttp,https://github.com/square/okhttp/issues/5595,"The okhttp client  version is 3.11.0.
Exception is:
`
Caused by: java.net.ProtocolException: Unexpected status line: 800
       at okhttp3.internal.http.StatusLine.parse(StatusLine.java:69) 
       at okhttp3.internal.http1.Http1Codec.readResponseHeaders(Http1Codec.java:189)
       at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:88) 
       at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45) 
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) 
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) 
       at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93) 
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) 
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) 
       at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93) 
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) 
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) 
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) 
       at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:200) 
       at okhttp3.RealCall.execute(RealCall.java:77) 
`",Can you share the headers and status of the preceding response?,"> Most likely a disagreement in the content length of the previous response. Can you share the headers and status of the preceding response?

@swankjesse thanks for the comments.
The right response information is:
![image](https://user-images.githubusercontent.com/6115258/68674374-b8147780-0590-11ea-86c4-bfd420489c47.png)
"
square/okhttp,https://github.com/square/okhttp/issues/5587,"Hi,

We are still not sure about the root cause but our acceptance tests execution phase is failing sometimes due to `MockWebserver` (**4.2.1**) crashing when the following error happens in `acceptConnections()`:

```
11-05 11:53:36.557  5607 23163 E AndroidRuntime: FATAL EXCEPTION: MockWebServer
11-05 11:53:36.557  5607 23163 E AndroidRuntime: Process: com.xxx.xxx.xxx, PID: 5607
11-05 11:53:36.557  5607 23163 E AndroidRuntime: java.lang.AssertionError: java.lang.reflect.InvocationTargetException
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at okhttp3.internal.platform.android.AndroidSocketAdapter.a(SourceFile:86)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at okhttp3.internal.platform.AndroidPlatform.b(SourceFile:86)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at okhttp3.mockwebserver.MockWebServer$SocketHandler.handle(MockWebServer.kt:516)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at okhttp3.mockwebserver.MockWebServer$serveConnection$$inlined$execute$1.run(Util.kt:580)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at java.lang.Thread.run(Thread.java:764)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: Caused by: java.lang.reflect.InvocationTargetException
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at java.lang.reflect.Method.invoke(Native Method)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at okhttp3.internal.platform.android.AndroidSocketAdapter.a(SourceFile:81)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	... 6 more
11-05 11:53:36.557  5607 23163 E AndroidRuntime: Caused by: java.lang.NullPointerException: ssl == null
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at com.android.org.conscrypt.NativeCrypto.getApplicationProtocol(Native Method)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at com.android.org.conscrypt.NativeSsl.getApplicationProtocol(NativeSsl.java:568)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at com.android.org.conscrypt.ConscryptFileDescriptorSocket.getApplicationProtocol(ConscryptFileDescriptorSocket.java:1085)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	at com.android.org.conscrypt.OpenSSLSocketImpl.getAlpnSelectedProtocol(OpenSSLSocketImpl.java:134)
11-05 11:53:36.557  5607 23163 E AndroidRuntime: 	... 8 more
```

Any ideas about this? Shouldn't this be handled by `MockWebserver`?

Thanks in advance!",Which device? Which Android release?,It's an emulator running API 28
square/okhttp,https://github.com/square/okhttp/issues/5575,"**There are the implementations i have been using**

    implementation 'com.squareup.retrofit2:retrofit:2.6.0'
    implementation 'com.google.code.gson:gson:2.8.5'
    implementation 'com.squareup.retrofit2:converter-gson:2.6.0'
    implementation 'com.squareup.okhttp3:okhttp:4.2.1'
    implementation 'com.squareup.okhttp3:logging-interceptor:3.10.0'


**This is the network interceptor class**

```
class NetworkConnectionInterceptor(
    context: Context
) : Interceptor {


    private val applicationContext = context.applicationContext

    override fun intercept(chain: Interceptor.Chain): Response {
        return if (!isConnectionOn()) {
            throw NoConnectivityException()
        } else if(!isInternetAvailable()) {
            throw NoInternetException()
        } else {
            chain.proceed(chain.request())
        }
    }

    private fun isInternetAvailable(): Boolean {
        return try {
            val timeoutMs = 1500
            val sock = Socket()
            val sockaddr = InetSocketAddress(""8.8.8.8"", 53)

            sock.connect(sockaddr, timeoutMs)
            sock.close()

            true
        } catch (e: IOException) {
            false
        }
    }

    private fun isConnectionOn(): Boolean {
        val connectivityManager =
            applicationContext.getSystemService(Context.CONNECTIVITY_SERVICE) as
                    ConnectivityManager

        return if (android.os.Build.VERSION.SDK_INT >=
            android.os.Build.VERSION_CODES.M) {
            postAndroidMInternetCheck(connectivityManager)
        } else {
            preAndroidMInternetCheck(connectivityManager)
        }
    }

    @RequiresApi(Build.VERSION_CODES.M)
    private fun postAndroidMInternetCheck(
        connectivityManager: ConnectivityManager): Boolean {
        val network = connectivityManager.activeNetwork
        val connection =
            connectivityManager.getNetworkCapabilities(network)

        return connection != null && (
                connection.hasTransport(NetworkCapabilities.TRANSPORT_WIFI) ||
                        connection.hasTransport(NetworkCapabilities.TRANSPORT_CELLULAR))
    }

    private fun preAndroidMInternetCheck(
        connectivityManager: ConnectivityManager): Boolean {
        val activeNetwork = connectivityManager.activeNetworkInfo
        if (activeNetwork != null) {
            @Suppress(""DEPRECATION"")
            return (activeNetwork.type == ConnectivityManager.TYPE_WIFI ||
                    activeNetwork.type == ConnectivityManager.TYPE_MOBILE)
        }
        return false
    }

}
```

**My Retrofit client**

```
operator fun invoke(
            networkConnectionInterceptor: NetworkConnectionInterceptor
        ): ApiUtil {

            val builder = OkHttpClient.Builder()
            builder.connectTimeout(5, TimeUnit.SECONDS)
            builder.writeTimeout(10, TimeUnit.SECONDS)

            val interceptor = HttpLoggingInterceptor()
            interceptor.level = HttpLoggingInterceptor.Level.BODY

            val client = OkHttpClient.Builder()
                .addInterceptor(interceptor)
                .addInterceptor(networkConnectionInterceptor)
                .build()


            builder.cache(null)

            val gson = GsonBuilder()
                .setLenient()
                .create()

            val retrofit = Retrofit.Builder()
                .baseUrl(BASE_URL)
                .addConverterFactory(GsonConverterFactory.create(gson))
                .client(client)
                .build()

            return retrofit.create(ApiUtil::class.java)
            
        }
```

this is how i am calling the api's

```
fun onGetNationalities() {
        try {
            responseCallback?.onStarted()
            Coroutines.main {
                val nationalitiesResponse = repository.getNationalities()
                nationalitiesResponse?.let {
                    if (it.success) {
                        responseCallback?.onSuccess(it)
                    } else {
                        responseCallback?.onFailure(it.errorMessage)
                    }
                }
            }
        } catch (e: Exception) {
            responseCallback?.onAlert(
                e.cause?.localizedMessage
                    ?: MessageUtils.SOMETHING_WENT_WRONG
            )
        } catch (e: NoInternetException) {
            responseCallback?.onAlert(e.message!!)
        }catch (e: NoConnectivityException) {
            responseCallback?.onAlert(e.message!!)
        }
    }
```

**NoInternetException and NoConnectivityException are two exception classes**

```
class NoConnectivityException : IOException() {
    override val message: String
        get() =
            ""No network available, please check your WiFi or Data connection""
}
```

```
class NoInternetException() : IOException() {
    override val message: String
        get() =
            ""No internet available, please check your connected WIFi or Data""
}
```

This is not happening everytime for example if i am calling an api on button click and internet is not active, exception thrown from the intercepor will be caught in the function from where i am calling the api but if i call an api on the start on e.g signup form so i can get the nationalities for signup as in my example the interceptor will crash while throwing the exception plus it also crash sometime on the chain.proceed with the Sockettimeoutexception etc. The crash is reproducible.


",Which versions of OkHttp and Retrofit? I believe this was recently fixed in Retrofit.,"@swankjesse I have added the gradle implementations at the above but these are the one I am using


implementation 'com.squareup.retrofit2:retrofit:2.6.0'
implementation 'com.google.code.gson:gson:2.8.5'
implementation 'com.squareup.retrofit2:converter-gson:2.6.0'
implementation 'com.squareup.okhttp3:okhttp:4.2.1'
implementation 'com.squareup.okhttp3:logging-interceptor:3.10.0'"
square/okhttp,https://github.com/square/okhttp/issues/5519,"We observed clients not pooling connections because although they shared a connection pool, they had different instances of NullProxySelector.",Which version did this start?  :(,"The SecurityManager managed to cause this! It's the worst.
https://github.com/square/okhttp/pull/5332"
square/okhttp,https://github.com/square/okhttp/issues/5506,"stack trace:
 java.lang.NullPointerException: Attempt to invoke virtual method 'okhttp3.internal.connection.RealConnectionPool okhttp3.internal.Internal.realConnectionPool(okhttp3.ConnectionPool)' on a null object reference
     at okhttp3.internal.connection.Transmitter.<init>(Transmitter.java:81)
     at okhttp3.RealCall.newRealCall(RealCall.java:64)
     at okhttp3.OkHttpClient.newCall(OkHttpClient.java:401)
     at retrofit2.ServiceMethod.toCall(ServiceMethod.java:113)
     at retrofit2.OkHttpCall.createRawCall(OkHttpCall.java:184)
     at retrofit2.OkHttpCall.execute(OkHttpCall.java:167)
     at retrofit2.adapter.rxjava2.CallExecuteObservable.subscribeActual(CallExecuteObservable.java:42)
     at io.reactivex.Observable.subscribe(Observable.java:12246)
     at retrofit2.adapter.rxjava2.BodyObservable.subscribeActual(BodyObservable.java:34)
     at io.reactivex.Observable.subscribe(Observable.java:12246)
     at io.reactivex.internal.operators.observable.ObservableSingleSingle.subscribeActual(ObservableSingleSingle.java:35)
     at io.reactivex.Single.subscribe(Single.java:3575)
     at io.reactivex.internal.operators.single.SingleSubscribeOn$SubscribeOnObserver.run(SingleSubscribeOn.java:89)
     at io.reactivex.Scheduler$DisposeTask.run(Scheduler.java:578)
     at io.reactivex.internal.schedulers.ScheduledRunnable.run(ScheduledRunnable.java:66)
     at io.reactivex.internal.schedulers.ScheduledRunnable.call(ScheduledRunnable.java:57)
     at java.util.concurrent.FutureTask.run(FutureTask.java:266)
     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:301)
     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)
     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)
     at java.lang.Thread.run(Thread.java:764)

version: latest

we use dagger to initialize okhttp and retrofit instances:

```
    @Provides
    @Singleton
    fun providesRetrofit(gsonConverterFactory: GsonConverterFactory, rxJava2CallAdapterFactory: RxJava2CallAdapterFactory,
                         okHttpClient: OkHttpClient, context: Context): Retrofit =
            Retrofit.Builder().baseUrl(context.getString(R.string.api_endpoint))
                    .addConverterFactory(gsonConverterFactory)
                    .addCallAdapterFactory(rxJava2CallAdapterFactory)
                    .client(okHttpClient)
                    .build()

    @Provides
    @Singleton
    fun providesOkHttpClient(cache: Cache): OkHttpClient {
        val client = OkHttpClient.Builder()
                .cache(cache)
                .connectTimeout(20, TimeUnit.SECONDS)
                .writeTimeout(30, TimeUnit.SECONDS)
                .readTimeout(10, TimeUnit.SECONDS)
                .addInterceptor(HttpLoggingInterceptor().setLevel(HttpLoggingInterceptor.Level.BODY))

        return client.build()
    }

```
bug happens when in single activity app with ""do not keep activities"" setting in developer options flag turned on and when pick photo intent is executed and then in onActivityResult we try to upload this photo....activity is recreated but okhttp instance is somehow not properly/completely initialised (for test purposes I added 5 seconds delay to wait if it will be initialised, but with no luck, the same error occured.. to sum it up, after reset, it's unusable)",Can you confirm this in a debugger? Put breakpoints on OkHttpClient.java lines 131 and 141 and tell me which hits first.,"when app first starts , `  Internal.instance = new Internal() `at  line 131 is called, and then  `return connectionPool.delegate;` at line 141 is called.  After photo gallery windows is shown and returned back, when call is made, neither of previous lines are called.. I also checked if injected version of OkHttpClient is the same and it is..

I also noticed another crash (probably the same reason) during  the call that was made right before activity was destroyed.

```
   @Override public RealConnectionPool realConnectionPool(ConnectionPool connectionPool) {
        return connectionPool.delegate;
      }
```
was called but  `Internal.instance` was null, as shown at the picture:
<img width=""1040"" alt=""Screenshot 2019-09-28 at 01 50 03"" src=""https://user-images.githubusercontent.com/6105846/65808194-0e6d5880-e193-11e9-8a20-0be85a037f3b.png"">

and then, the stack trace was:

```
    java.lang.NullPointerException: Attempt to invoke virtual method 'void okhttp3.internal.Internal.apply(okhttp3.ConnectionSpec, javax.net.ssl.SSLSocket, boolean)' on a null object reference
        at okhttp3.internal.connection.ConnectionSpecSelector.configureSecureSocket(ConnectionSpecSelector.java:77)
        at okhttp3.internal.connection.RealConnection.connectTls(RealConnection.java:329)
        at okhttp3.internal.connection.RealConnection.establishProtocol(RealConnection.java:300)
        at okhttp3.internal.connection.RealConnection.connect(RealConnection.java:185)
        at okhttp3.internal.connection.ExchangeFinder.findConnection(ExchangeFinder.java:224)
        at okhttp3.internal.connection.ExchangeFinder.findHealthyConnection(ExchangeFinder.java:108)
        at okhttp3.internal.connection.ExchangeFinder.find(ExchangeFinder.java:88)
        at okhttp3.internal.connection.Transmitter.newExchange(Transmitter.java:169)
        at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:41)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:142)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:117)
        at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:94)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:142)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:117)
        at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:142)
        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:88)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:142)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:117)
        at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:221)
        at okhttp3.RealCall.execute(RealCall.java:81)
```

It's different error, but probably the same problem, so I guess it's not necessary to create another issue for that...
"
square/okhttp,https://github.com/square/okhttp/issues/5505,"This is my build.gradle

```
apply plugin: 'kotlin'

dependencies {
    def dependencies = rootProject.ext.repositoryDependencies
    def testDependencies = rootProject.ext.repositoryTestDependencies

    implementation project("":domain"")

    implementation dependencies.kotlin
    implementation dependencies.moshi
    implementation dependencies.rxJavaAdapter
    implementation dependencies.okHttp3
    implementation dependencies.jodaTime
    testImplementation testDependencies.okHttpMock
    testImplementation testDependencies.okHttp3
}

sourceCompatibility = ""1.8""
targetCompatibility = ""1.8""

compileKotlin {
    kotlinOptions {
        jvmTarget = ""1.8""
    }
}
compileTestKotlin {
    kotlinOptions {
        jvmTarget = ""1.8""
    }
}

compileJava {
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}
```

Kotlin version:
`  kotlin              : ""org.jetbrains.kotlin:kotlin-stdlib-jdk8:1.3.50,`

Okhttp3 version:
`okHttp3                 : ""com.squareup.okhttp3:okhttp:4.2.0,`

Failing method:
```
fun OkHttpClient.Builder.addQueryParameterInterceptor(name: String, value: String): OkHttpClient.Builder {
    addInterceptor {
        var request = it.request()
        val url = request.url.newBuilder().addQueryParameter(name, value).build()
        request = request.newBuilder().url(url).build()
        it.proceed(request)
    }
    return this
}
```

Using `url()` is deprecated in `Request` and suggests using the val `url`.

However building with `request.url.etc` I get `cannot access url it is public/*package*/ in Request`

I looked at the migration guide and changed the java compatibility to 1.8.

Thank you for the help.",Do you have two copies of OkHttp on your classpath?,"Hello, @swankjesse, no only one copy of OkHttp3, if you mean this line: `testImplementation testDependencies.okHttp3` I removed it and tried and still get the error. One is `implementation` while the other is `testImplementation`. However, other than those, there isn't any other copy of okhttp, I also removed the `testImplementation` one so there is only one implementation in the build.gradle. 

Here's a screenshot of the error I am getting:

![url](https://user-images.githubusercontent.com/22520376/65778547-774fd300-e189-11e9-9760-ae68412eeba3.png)

And here's a screenshot when using `.url()` instead of `.url`:

![sss](https://user-images.githubusercontent.com/22520376/65778830-f7763880-e189-11e9-9704-3001928480db.png)
"
square/okhttp,https://github.com/square/okhttp/issues/5475,"I have an android app in kotlin that talks to an express nodeJS api via mutual authentication. The app is designed to keep collecting data after the screen is off/on, survive reboots, etc. This is done with the user's consent. 

This is occuring on an Android 8.1 Samsung tablet that has no other apps installed (other than the standard samsung installs)

After some time of the screen being off, (Time until the error shows up ranges from 20 minutes to 3 hours) we get the below exception until we restart (We left it running in this error state for >8 hours, and it never recovered) the app or recreate retrofit object. The foreground service is still running and collecting data without an issue. 

The issue is not a server problem, I had a shell script curl the server with the same parameters and that worked for ~16 hours. 

We have tried: 

* Setting client header 'Connection', 'close'
* Setting server header 'Connection', 'close' 
* both of the above
* Setting client header 'Connection', 'Keep-Alive'
* Setting server header 'Connection', 'Keep-Alive'
* Both of the above
* Combinations of all of the above
* Checking for a server performance issue
* Making body smaller (Current limit is `100` items, which translates to a ~`120kb` body)
* Some other things I am forgetting


**Workaround**: 
    When this exception is thrown, we create a new retrofit service, drain all connectionss, then resume posting to the API. 

**Versions used**:
``` 
implementation 'com.squareup.retrofit2:retrofit:2.6.1'
implementation 'com.squareup.retrofit2:converter-gson:2.6.1'
implementation 'com.squareup.okhttp3:okhttp:4.2.0'
implementation 'com.squareup.okhttp3:logging-interceptor:4.2.0'
implementation 'com.squareup.okhttp3:okhttp-brotli:4.2.0'

```

**Stack Trace**: 
```
 javax.net.ssl.SSLException: Read error: ssl=0xa65d7940: I/O error during system call, Connection reset by peer
        at com.android.org.conscrypt.NativeCrypto.SSL_read(Native Method)
        at com.android.org.conscrypt.SslWrapper.read(SslWrapper.java:391)
        at com.android.org.conscrypt.ConscryptFileDescriptorSocket$SSLInputStream.read(ConscryptFileDescriptorSocket.java:567)
        at okio.InputStreamSource.read(Okio.kt:102)
        at okio.AsyncTimeout$source$1.read(AsyncTimeout.kt:159)
        at okio.RealBufferedSource.indexOf(RealBufferedSource.kt:349)
        at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.kt:222)
        at okhttp3.internal.http1.Http1ExchangeCodec.readHeaderLine(Http1ExchangeCodec.kt:210)
        at okhttp3.internal.http1.Http1ExchangeCodec.readResponseHeaders(Http1ExchangeCodec.kt:181)
        at okhttp3.internal.connection.Exchange.readResponseHeaders(Exchange.kt:105)
        at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.kt:82)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.kt:37)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.kt:82)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.kt:84)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.kt:71)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at com.someCompany.someApp.api.RetrofitFactory$logoutInterceptor$$inlined$invoke$1.intercept(Interceptor.kt:75)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at okhttp3.brotli.BrotliInterceptor.intercept(BrotliInterceptor.kt:39)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at okhttp3.logging.HttpLoggingInterceptor.intercept(HttpLoggingInterceptor.kt:215)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at com.someCompany.someApp.api.RetrofitFactory$headersInterceptor$$inlined$invoke$1.intercept(Interceptor.kt:75)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.kt:184)
        at okhttp3.RealCall$AsyncCall.run(RealCall.kt:136)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)
        at java.lang.Thread.run(Thread.java:764)
```

**What the server sees:**

```
BadRequestError: request aborted 
 at IncomingMessage.onAborted (/app/node_modules/raw-body/index.js:231:10) 
 at emitNone (events.js:106:13) 
 at IncomingMessage.emit (events.js:208:7)
 at abortIncoming (_http_server.js:445:9) 
 at socketOnClose (_http_server.js:438:3) 
 at emitOne (events.js:121:20) 
 at TLSSocket.emit (events.js:211:7) 
 at _handle.close (net.js:561:12) 
 at Socket.done (_tls_wrap.js:360:7) 
 at Object.onceWrapper (events.js:315:30) 
 at emitOne (events.js:116:13) 
 at Socket.emit (events.js:211:7) 
 at TCP._handle.close [as _onclose] (net.js:561:12) 
```

**RetrofitFactory:**
```
object RetrofitFactory {
    fun makeRetrofitService(context: Context, isAuthenticated: Boolean = false): RetrofitService {
        val baseUrl: String = if (BuildConfig.DEBUG) {
            ""https://api.staging.someCompany.com/""
        } else {
            ""https://api-api.someCompany.com/""
        }
        return Retrofit.Builder().baseUrl(baseUrl)
            .addConverterFactory(GsonConverterFactory.create(makeGson()))
            .client(makeClient(context, isAuthenticated))
            .build().create(RetrofitService::class.java)
    }

    private fun makeGson(): Gson {
        return GsonBuilder().excludeFieldsWithModifiers(Modifier.TRANSIENT).create()
    }
    fun makeClient(context: Context, isAuthenticated: Boolean): OkHttpClient {
        val hostnameVerifier = HostnameVerifier { hostname, _ ->
            HttpsURLConnection.getDefaultHostnameVerifier().run {
                if (BuildConfig.DEBUG) {
                    hostname == ""relay-api.staging.someCompany.com""
                } else {
                    hostname == ""relay-api.someCompany.com""
                }
            }
        }

        val sslAndMgr = if (isAuthenticated) {
            clientAuthSslContext(context)
        } else {
            basicSslContext(context)
        }

        return OkHttpClient.Builder()
            .connectTimeout(15, TimeUnit.SECONDS)
            .readTimeout(15, TimeUnit.SECONDS)
            .sslSocketFactory(sslAndMgr.first, sslAndMgr.second)
            .addInterceptor(headersInterceptor()).addInterceptor(loggingInterceptor())
            .addInterceptor(BrotliInterceptor)
            .addInterceptor(logoutInterceptor())
            .hostnameVerifier(hostnameVerifier)
            .retryOnConnectionFailure(true)
            .build()
    }
    private fun loggingInterceptor() = HttpLoggingInterceptor().apply {
        level =
            if (BuildConfig.DEBUG) HttpLoggingInterceptor.Level.BODY else HttpLoggingInterceptor.Level.NONE
    }


    private fun logoutInterceptor() = Interceptor { chain ->
        val mainResponse = chain.proceed(chain.request())

        if (mainResponse.code == 401) {
            Certificates(someApp().applicationContext).logout()
        }
        mainResponse
    }
    private fun headersInterceptor() = Interceptor { chain ->
        chain.proceed(
            (chain.request().newBuilder()
                .addHeader(""Accept"", ""application/json"")
                .addHeader(""Accept-Language"", ""en"")
                .addHeader(""Content-Type"", ""application/json"").build()
                    )
        )
    }

    private fun basicSslContext(context: Context): Pair<SSLSocketFactory, X509TrustManager> {
        val certMgr = Certificates(context)
        val keyStore = KeyStore.getInstance(KeyStore.getDefaultType())
        keyStore.load(null, null)

        keyStore.setCertificateEntry(""serverCert"", certMgr.loadServerChain())
        val trustMgrFactory =
            TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm())
        trustMgrFactory.init(keyStore)

        val sslContext = SSLContext.getInstance(""TLS"")
        sslContext.init(null, trustMgrFactory.trustManagers, null)
        return Pair(sslContext.socketFactory, trustMgrFactory.trustManagers[0] as X509TrustManager)
    }

    private fun clientAuthSslContext(context: Context): Pair<SSLSocketFactory, X509TrustManager> {
        val certMgr = Certificates(context) //This is a helper that loads certificates/PKs as needed

        val keyStore = KeyStore.getInstance(KeyStore.getDefaultType())
        keyStore.load(null, null)
        keyStore.setCertificateEntry(""ca"", certMgr.loadServerChain())
        keyStore.setCertificateEntry(""client"", certMgr.loadClientCert())
        keyStore.setKeyEntry(
            ""private"",
            certMgr.loadPrivateKey(),
            null,
            arrayOf(certMgr.loadClientCert(), certMgr.loadCA())
        )

        val kmf: KeyManagerFactory = KeyManagerFactory.getInstance(""X509"")

        kmf.init(keyStore, null)

        val trustMgrFactory =
            TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm())
        trustMgrFactory.init(keyStore)
        val sslContext = SSLContext.getInstance(""TLS"")
        sslContext.init(kmf.keyManagers, trustMgrFactory.trustManagers, null)

        return Pair(object : DelegatingSSLSocketFactory(sslContext.socketFactory) { //DelegatingSSLSocketFactory from https://github.com/square/okhttp/blob/master/okhttp/src/test/java/okhttp3/DelegatingSSLSocketFactory.java 
            @Throws(
                IOException::class
            )
            override fun configureSocket(sslSocket: SSLSocket): SSLSocket {
                sslSocket.sslParameters.needClientAuth = true
                sslSocket.needClientAuth = true
                return super.configureSocket(sslSocket)
            }
        }, trustMgrFactory.trustManagers[0] as X509TrustManager)
    }
}
```

**Where we actually call the api:**
```
val res = CoroutineScope(Dispatchers.IO).launch {
            try {

                //call Room DB and get list of items out

                val body = BulkRelayRequest(items.toTypedArray())
                val response = apiService.postBulkRelayLogs(body)

                if (response.isSuccessful) {
                   //update room DB
                    Log.i(TAG, ""Posted ***** with ids ${response.body()!!.payload.ids}"")
                } else {
                    //failure :(
                    val eParams = Bundle()
                    firebaseAnalytics.logEvent(""API_SEND_FAILED"", eParams)
                    Log.e(TAG, ""Error: failed to post ****** to API"")
                }
            } catch(e: SSLException)
            {
                isDraining = true
                apiService = RetrofitFactory.makeRetrofitService(context, true)
                Log.e(TAG, ""SSL Error occurred. Draining connections and restarting retrofit"")
            }
            catch (e: Throwable) {
                val eParams = Bundle()
                firebaseAnalytics.logEvent(""API_SEND_FAILED"", eParams)
                Log.e(TAG, ""Error: failed to post *** to API and threw an exception"", e)
            }
            finally {
                connectionsActive--
            }
        }
    res.ensureActive()
```",Can you reproduce on other devices? ,"Yes, on other Samsung 8.1 devices. We were starting to test on other versions, but we developed the workaround, so we concluded our testing."
square/okhttp,https://github.com/square/okhttp/issues/5468,"When the field value contains the ampersand ""&"" for example, ""Brothers & Co"" and I use that value like filter in the query, after encoding string to query I have ampersand ""&"" in the filter body, like this:
 https://example.eu/exsource/User?ormat=json&$filter=(username%20eq%20%27examlpleusername%27%20and%20filtername%20eq%20%2Brothers%20&%20Co%27)&asOfDate=2019-09-13

So this request does not work and I become Http response with status code 500. For correct work I should to convert it to ""%26"" additionally.",Which version are you using?,Now I am using the latest version - 4.2.0
square/okhttp,https://github.com/square/okhttp/issues/5464,"I suspect only an issue if we look at the handshake certificates on Android with the MockWebServer.

```
07:13:09 V/InstrumentationResultParser: There was 1 failure:
07:13:09 V/InstrumentationResultParser: 1) testMockWebserverRequest(okhttp.android.test.OkHttpTest)
07:13:09 V/InstrumentationResultParser: javax.net.ssl.SSLPeerUnverifiedException
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.platform.AndroidPlatform$AndroidCertificateChainCleaner.clean(AndroidPlatform.kt:189)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.RealConnection$connectTls$1.invoke(RealConnection.kt:377)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.RealConnection$connectTls$1.invoke(RealConnection.kt:70)
07:13:09 V/InstrumentationResultParser: at kotlin.SynchronizedLazyImpl.getValue(LazyJVM.kt:74)
07:13:09 V/InstrumentationResultParser: at okhttp3.Handshake.peerCertificates(Unknown Source:7)
07:13:09 V/InstrumentationResultParser: at okhttp3.Handshake.toString(Handshake.kt:127)
07:13:09 V/InstrumentationResultParser: at java.lang.String.valueOf(String.java:2924)
07:13:09 V/InstrumentationResultParser: at java.lang.StringBuilder.append(StringBuilder.java:132)
07:13:09 V/InstrumentationResultParser: at okhttp3.logging.LoggingEventListener.secureConnectEnd(LoggingEventListener.kt:76)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.RealConnection.establishProtocol(RealConnection.kt:311)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.RealConnection.connect(RealConnection.kt:178)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.ExchangeFinder.findConnection(ExchangeFinder.kt:236)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.ExchangeFinder.findHealthyConnection(ExchangeFinder.kt:109)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.ExchangeFinder.find(ExchangeFinder.kt:77)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.Transmitter.newExchange$okhttp(Transmitter.kt:162)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.kt:35)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.kt:82)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.kt:84)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.kt:71)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
07:13:09 V/InstrumentationResultParser: at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.kt:192)
07:13:09 V/InstrumentationResultParser: at okhttp3.RealCall.execute(RealCall.kt:66)
07:13:09 V/InstrumentationResultParser: at okhttp.android.test.OkHttpTest.testMockWebserverRequest(OkHttpTest.kt:198)
07:13:09 V/InstrumentationResultParser: at java.lang.reflect.Method.invoke(Native Method)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
07:13:09 V/InstrumentationResultParser: at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
07:13:09 V/InstrumentationResultParser: at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
07:13:09 V/InstrumentationResultParser: at android.support.test.internal.runner.junit4.statement.RunBefores.evaluate(RunBefores.java:80)
07:13:09 V/InstrumentationResultParser: at android.support.test.internal.runner.junit4.statement.RunAfters.evaluate(RunAfters.java:61)
07:13:09 V/InstrumentationResultParser: at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
07:13:09 V/InstrumentationResultParser: at org.junit.rules.RunRules.evaluate(RunRules.java:20)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
07:13:09 V/InstrumentationResultParser: at android.support.test.runner.AndroidJUnit4.run(AndroidJUnit4.java:101)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.Suite.runChild(Suite.java:128)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.Suite.runChild(Suite.java:27)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
07:13:09 V/InstrumentationResultParser: at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
07:13:09 V/InstrumentationResultParser: at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
07:13:09 V/InstrumentationResultParser: at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
07:13:09 V/InstrumentationResultParser: at android.support.test.internal.runner.TestExecutor.execute(TestExecutor.java:56)
07:13:09 V/InstrumentationResultParser: at android.support.test.runner.AndroidJUnitRunner.onStart(AndroidJUnitRunner.java:384)
07:13:09 V/InstrumentationResultParser: at android.app.Instrumentation$InstrumentationThread.run(Instrumentation.java:2189)
07:13:09 V/InstrumentationResultParser: Caused by: java.lang.reflect.InvocationTargetException
07:13:09 V/InstrumentationResultParser: at java.lang.reflect.Method.invoke(Native Method)
07:13:09 V/InstrumentationResultParser: at okhttp3.internal.platform.AndroidPlatform$AndroidCertificateChainCleaner.clean(AndroidPlatform.kt:186)
07:13:09 V/InstrumentationResultParser: ... 60 more
07:13:09 V/InstrumentationResultParser: Caused by: java.security.cert.CertificateException: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found.
07:13:09 V/InstrumentationResultParser: at com.android.org.conscrypt.TrustManagerImpl.verifyChain(TrustManagerImpl.java:674)
07:13:09 V/InstrumentationResultParser: at com.android.org.conscrypt.TrustManagerImpl.checkTrustedRecursive(TrustManagerImpl.java:551)
07:13:09 V/InstrumentationResultParser: at com.android.org.conscrypt.TrustManagerImpl.checkTrusted(TrustManagerImpl.java:507)
07:13:09 V/InstrumentationResultParser: at com.android.org.conscrypt.TrustManagerImpl.checkServerTrusted(TrustManagerImpl.java:335)
07:13:09 V/InstrumentationResultParser: at android.security.net.config.NetworkSecurityTrustManager.checkServerTrusted(NetworkSecurityTrustManager.java:113)
07:13:09 V/InstrumentationResultParser: at android.security.net.config.RootTrustManager.checkServerTrusted(RootTrustManager.java:133)
07:13:09 V/InstrumentationResultParser: at java.lang.reflect.Method.invoke(Native Method)
07:13:09 V/InstrumentationResultParser: at android.net.http.X509TrustManagerExtensions.checkServerTrusted(X509TrustManagerExtensions.java:101)
07:13:09 V/InstrumentationResultParser: ... 62 more
07:13:09 V/InstrumentationResultParser: Caused by: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found.
07:13:09 V/InstrumentationResultParser: ... 70 more
```","Why didn't it validate in the initial handshake?

We should fix our cleaner to catch, log a warning, and return unclean certificates in this case?","I assumed it was because while we now clean at most once, it is only if you use either pinning, or access the cleaned certs. We didn't previously clean if it was enough that the SSL handshake code (Android or JVM) found a valid chain to the known root CA.  And the root CA doesn't need to be in the list provided by the server IIUC.

I'll try to prove we use the same certs for verifying.  I hope it's not a new bug, prefer it to a broken assumption with self signed certs. :)"
square/okhttp,https://github.com/square/okhttp/issues/5426,"We upgraded to the latest, and now our build fails with:

[2019-09-06T01:15:49.953Z] Caused by: java.lang.NoSuchMethodError: okhttp3.Cookie.toString(Z)Ljava/lang/String;
[2019-09-06T01:15:49.953Z] at okhttp3.JavaNetCookieJar.saveFromResponse(JavaNetCookieJar.java:43)
[2019-09-06T01:15:49.953Z] at okhttp3.internal.http.HttpHeaders.receiveHeaders(HttpHeaders.kt:207)
[2019-09-06T01:15:49.953Z] at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.kt:86)
[2019-09-06T01:15:49.953Z] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
[2019-09-06T01:15:49.953Z] at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.kt:71)
[2019-09-06T01:15:49.953Z] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
[2019-09-06T01:15:49.953Z] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
[2019-09-06T01:15:49.953Z] at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.kt:184)
[2019-09-06T01:15:49.953Z] at okhttp3.RealCall.execute(RealCall.kt:66)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.hub.rest.CredentialsRestConnection.clientAuthenticate(CredentialsRestConnection.java:86)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.hub.rest.RestConnection.connect(RestConnection.java:128)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.hub.rest.RestConnection.handleExecuteClientCall(RestConnection.java:350)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.hub.rest.RestConnection.handleExecuteClientCall(RestConnection.java:317)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.hub.request.HubRequest.executePost(HubRequest.java:85)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.hub.api.bom.BomImportRequestService.importBomFile(BomImportRequestService.java:55)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.hub.buildtool.BuildToolHelper.deployHubOutput(BuildToolHelper.java:71)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.gradle.task.BuildBomTask.deployHubBDIO(BuildBomTask.java:240)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.gradle.task.BuildBomTask.performTask(BuildBomTask.java:153)
[2019-09-06T01:15:49.953Z] at com.blackducksoftware.integration.gradle.task.BuildBomTask.task(BuildBomTask.java:130)
[2019-09-06T01:15:49.953Z] at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:103)

We don't see in the release notes anything saying that method has been removed.

Can you put it back? If not, we can't upgrade to your latest, because we need to run blackduck until we replace it (long process).

You replied ""Presumably you are mixing a 3.14 version of JavaNetCookieJar from okhttp-httpurlconnection with 4.x of okhttp. Can you upgrade both?"" and then asked for more info and then closed it 8 minutes later. I was in standup. And I can't reopen a bug closed by a code owner. So here it is again.

./gradlew dependencies shows no occurrence of okhttp-httpurlconnection on any of our classpaths.

We are only using (or trying to use) com.squareup.okhttp3:okhttp:4.1.1.","Can you use your IDE to see which jar is providing it?

<img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/231923/64460535-81cefd80-d0f2-11e9-960f-a0be281a9e14.png"">

See above it is not in the core okhttp jar.","It's not present anywhere in the classpath in my IDE (which is IntelliJ). To look for it just requires CMD o, and the class name. When I do that for Cookie and search down in the list, I get the com.squareup.okhttp3 jar. When I do that for JavaNetCookieJar, there's no match. It's also not anywhere in the Gradle 5.5.1 uber-jar."
square/okhttp,https://github.com/square/okhttp/issues/5390,"```
    api 'com.squareup.okhttp3:okhttp:4.1.0'
```

Occur sometimes. 

```
W/System.err: java.io.IOException: unexpected end of stream on http://172.16.10.21:8880/...
        at okhttp3.internal.http1.Http1ExchangeCodec.readResponseHeaders(Http1ExchangeCodec.kt:205)
        at okhttp3.internal.connection.Exchange.readResponseHeaders(Exchange.kt:105)
        at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.kt:82)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.kt:37)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
        at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.kt:82)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
W/System.err:     at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.kt:84)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.kt:71)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:112)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:87)
W/System.err:     at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.kt:184)
        at okhttp3.RealCall.execute(RealCall.kt:66)
        at com.lcbtn.utils.HttpUtils.get(HttpUtils.java:125)
        at com.lcbtn.utils.HttpUtils$2.run(HttpUtils.java:84)
        at java.lang.Thread.run(Thread.java:818)
    Caused by: java.io.EOFException: \n not found: limit=0 content=…
W/System.err:     at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.kt:231)
        at okhttp3.internal.http1.Http1ExchangeCodec.readHeaderLine(Http1ExchangeCodec.kt:210)
        at okhttp3.internal.http1.Http1ExchangeCodec.readResponseHeaders(Http1ExchangeCodec.kt:181)
    	... 19 more
```

```
$ curl http://172.16.10.21:8880/FSCPService/Program\?providerId\=cntv\&cityId\=7680\&programID\=CNTV2-1200064244\&cntv-version\=1006 -v 
*   Trying 172.16.10.21:8880...
* TCP_NODELAY set
* Connected to 172.16.10.21 (172.16.10.21) port 8880 (#0)
> GET /FSCPService/Program?providerId=cntv&cityId=7680&programID=CNTV2-1200064244&cntv-version=1006 HTTP/1.1
> Host: 172.16.10.21:8880
> User-Agent: curl/7.65.3
> Accept: */*
> 
* Mark bundle as not supporting multiuse
< HTTP/1.1 301 Moved Permanently
< Server: NGINX(CnPanel,LNMP)
< Date: Fri, 23 Aug 2019 02:59:34 GMT
< Content-Type: text/html
< Content-Length: 192
< Location: http://172.16.10.21:8880/FSCPService/Program/?providerId=cntv&cityId=7680&programID=CNTV2-1200064244&cntv-version=1006
< Connection: keep-alive
< 
<html>
<head><title>301 Moved Permanently</title></head>
<body bgcolor=""white"">
<center><h1>301 Moved Permanently</h1></center>
<hr><center>NGINX(CnPanel,LNMP)</center>
</body>
</html>
* Connection #0 to host 172.16.10.21 left intact

```

","Can you provide a test server we can test against? This is likely a problem with the response from the server, possibly differs because of different headers or connection negotiation.  Without that, we can't help.",
square/okhttp,https://github.com/square/okhttp/issues/5387,"Not 100% reproduce depend on device (100% failed on vivo X20A version: 8.1.0). 

Repro code
```kt
class MainActivity : AppCompatActivity() {

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
        Timber.plant(Timber.DebugTree())
        net.setOnClickListener {
            Thread {
                Timber.w(""network"")
                val request = Request.Builder()
                        .url(""http://45.63.13.41:3000/playlist/detail?id=2451836751"")
                        .get()
                        .addHeader(""Cache-Control"", ""no-cache"")
                        .addHeader(""Accept-Encoding"", ""gzip, deflate"")
                        .build()

                val client = OkHttpClient()
                val response = client.newCall(request).execute()
                val body = response.body?.string()

                Timber.w(""response = "" + body)
            }.start()
        }
    }
}
```

Okhttp version: `com.squareup.okhttp3:okhttp:4.1.0`

StackTrace
```console
E/AndroidRuntime: FATAL EXCEPTION: Thread-2
    Process: me.gengjiawen.quickstart, PID: 4865
    java.net.ProtocolException: unexpected end of stream
        at okhttp3.internal.http1.Http1ExchangeCodec$FixedLengthSource.read(Http1ExchangeCodec.kt:392)
        at okhttp3.internal.connection.Exchange$ResponseBodySource.read(Exchange.kt:279)
        at okio.Buffer.writeAll(Buffer.kt:1104)
        at okio.RealBufferedSource.readString(RealBufferedSource.kt:194)
        at okhttp3.ResponseBody.string(ResponseBody.kt:187)
        at me.gengjiawen.switchdemo.MainActivity$onCreate$1$1.run(MainActivity.kt:29)
        at java.lang.Thread.run(Thread.java:764)
```

Tried https://github.com/square/okhttp/issues/1490#issuecomment-78621872, but no luck.

Same code works on kotlin jvm.
The url also works on curl, browser, Node.js.","Do you use node.js?

Thanks in advance,

Best regards,
Nicolas ","yes, I am using Node.js."
square/okhttp,https://github.com/square/okhttp/issues/5383,"i used latest version of Okhttp Logging interceptor
when i received JSON that represent Arabic language it looks like this

`""name"":""\u0641\u0646\u062f\u0642 \u062a\u062c\u0631\u064a\u0628""`

please add support for encoding Arabic language
",Might be your JSON encoder to blame?,"When dealing with it in an android app it works fine , but in logcat appears like that"
square/okhttp,https://github.com/square/okhttp/issues/5372,"Extremely similar to https://github.com/square/okhttp/issues/4086 but applicable IBM JDK8

java version ""1.8.0_181""
Java(TM) SE Runtime Environment (build 8.0.5.20 - pxa6480sr5fp20ifix-20180809_01(SR5 FP20+IJ08001))
IBM J9 VM (build 2.9, JRE 1.8.0 Linux amd64-64-Bit Compressed References 20180809_394103 (JIT enabled, AOT enabled)
OpenJ9   - cce432b
OMR      - 7ce4228
IBM      - 98805ca)
JCL - 20180719_01 based on Oracle jdk8u181-b12

We compile in 7 because half of our environments are in 7 and the other half are in 8 so we use the 3.12.3 library but noticed the issues is there in the latest 4.1 as well, just doesn't seem to work in IBM JDK8 given what's happening in the internal/platform package 
There's some logic in there that handles the JDK7 route but still leaves IBM JDK broken because the response differs from openjdk when calling SSLContext.getInstance(""TLS"")

```
  public SSLContext getSSLContext() {
    String jvmVersion = System.getProperty(""java.specification.version"");
    if (""1.7"".equals(jvmVersion)) {
      try {
        // JDK 1.7 (public version) only support > TLSv1 with named protocols
        return SSLContext.getInstance(""TLSv1.2"");
      } catch (NoSuchAlgorithmException e) {
        // fallback to TLS
      }
    }

    try {
      return SSLContext.getInstance(""TLS"");
    } catch (NoSuchAlgorithmException e) {
      throw new IllegalStateException(""No TLS provider"", e);
    }
  }
```

After some remote debugging/troubleshooting discovered when it's establishing the connections is where the issue begins to arise the supported protocols is set to TLSv1 because of the above query to the JRE for supported/preferred TLS Setting 

Unable to find acceptable protocols. isFallback=false, modes=[ConnectionSpec(cipherSuites=[TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_GCM_SHA384, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA, SSL_RSA_WITH_3DES_EDE_CBC_SHA], tlsVersions=[TLS_1_3, TLS_1_2], supportsTlsExtensions=true), ConnectionSpec()], supported protocols=[TLSv1] 
","Can you use this workaround https://www.ibm.com/support/knowledgecenter/en/SSYKE2_8.0.0/com.ibm.java.security.component.80.doc/security-component/jsse2Docs/matchsslcontext_tls.html

```
com.ibm.jsse2.overrideDefaultTLS =[true|false]
```

What would you expect the logic on IBM JDKs to be?",
square/okhttp,https://github.com/square/okhttp/issues/5337,"```
java.lang.NullPointerException: Attempt to invoke virtual method 'java.lang.Object java.lang.ref.Reference.get()' on a null object reference
    at okhttp3.ConnectionPool.int pruneAndGetAllocationCount(okhttp3.internal.connection.RealConnection,long)(ConnectionPool.java:261)
    at okhttp3.ConnectionPool.long cleanup(long)(ConnectionPool.java:211)
    at okhttp3.ConnectionPool$1.void run()(ConnectionPool.java:60)
    at java.util.concurrent.ThreadPoolExecutor.null runWorker(null)(ThreadPoolExecutor.java:1133)
    at java.util.concurrent.ThreadPoolExecutor$Worker.null run(null)(ThreadPoolExecutor.java:607)
    at java.lang.Thread.null run(null)(Thread.java:761)
```

version: 3.12.0
",Which JVM or Android version? Looks like a VM bug to me.,"java version : 1.8
android version : 7.1 - 8.0
"
square/okhttp,https://github.com/square/okhttp/issues/5321,"I 've asked a question on [stackoverflow](https://stackoverflow.com/q/57308220/11265297)

The connection check takes 1 ms, but my request only takes 5ms. So speed down 1/5.
Is it possible to add a config to disable the check?","Can you use HTTP/2?  That would avoid this logic.

We should probably consider this for https://github.com/square/okhttp/issues/4530",
square/okhttp,https://github.com/square/okhttp/issues/5314,"OkHttp version: 3.12 - 3.14 (only these version tested)
Android version: Android 5 - 8 (only these version tested)

I have a service running on AWS ElasticBeanstalk(EB) and balanced by AWS ElasticLoadBalancer(ELB) handles user uploads. HTTP works totally fine across android/ios/web/electron. Some days ago, I add HTTPS to ELB, each platform works just like before except Android with okhttp have a really low transfer speed both upload and download.
The [SSL Security Policies of ELB](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html) is configured use `FS-2018-06` and `2016-08` both have this issue (only test these two).
Currently this part code is replace by HttpsUrlConnection and have a similar speed to other platform.

The upload part code is quite simple
``` Kotlin
val rawFile = File(dataDir, ""<filename>.zip"")
val httpUrl = HttpUrl.get(""https://<domain_to_service>"")
    .newBuilder()
    .addQueryParameter(""<foo1>"", ""<bar1>"")
    .addQueryParameter(""<foo2>"", ""<bar2>"")
    .build()
val okHttpClient = OkHttpClient.Builder()
    .build()
val request = Request.Builder()
    .url(httpUrl)
    .post(RequestBody.create(MediaType.get(""application/zip""), rawFile))
    .build()
okHttpClient.newCall(request).enqueue(object: Callback {
    ...notify user transfer over...
})
```

Events, I POST a 128MB file:
```
I/System.out: 0.000 callStart
I/System.out: 0.019 dnsStart
D/libc: [NET] android_getaddrinfofornet+,hn 31(0x75736572646174),sn(),hints(known),family 0,flags 4
    [NET] android_getaddrinfofornet-, err=8
    [NET] android_getaddrinfofornet+,hn 31(0x75736572646174),sn(),hints(known),family 0,flags 1024
    [NET] android_getaddrinfofornet-, pass to proxy
    [NET] android_getaddrinfo_proxy+
D/libc: [NET] android_getaddrinfo_proxy get netid:0
D/libc: [NET] android_getaddrinfo_proxy-, success
I/System.out: 0.297 dnsEnd
I/System.out: 0.302 connectStart
I/System.out: 0.596 secureConnectStart
I/System.out: 1.342 secureConnectEnd
I/System.out: 1.359 connectEnd
    1.359 connectionAcquired
I/System.out: 8.229 requestHeadersStart
I/System.out: 8.241 requestHeadersEnd
    8.242 requestBodyStart
I/System.out: 637.926 requestBodyEnd
    637.926 responseHeadersStart
I/System.out: 646.833 responseHeadersEnd
    646.833 responseBodyStart
    646.839 responseBodyEnd
    646.840 connectionReleased
    646.840 callEnd
```

Network in Profiler, mostly at 0.4MB/s, but on other device same network is at least 3MB/s:
[first 30 seconds](https://imgur.com/hZNj7IH)",Do you have a test URL I could hit?  Happy for you to DM me @yschimke ,"@yschimke I build a test environment with almost the same server configure but no actual server code. I test use the same code above get only 400KB/s upload speed and NodeJS axios I have 3MB/s upload speed.

Test url is here: https://a9828e89-fdee-4924-9d1a-b5adb6424e92.fungo.dev/
If the certificate is issued by Amazon, you are hitting the right server."
square/okhttp,https://github.com/square/okhttp/issues/5252,"I use OkHttp version is 3.14.2，when I debug，I find it will enter else block in CallServerInterceptor：
```
if (requestBody.isDuplex()) {
          // Prepare a duplex body so that the application can send a request body later.
          exchange.flushRequest()
          val bufferedRequestBody = exchange.createRequestBody(request, true).buffer()
          requestBody.writeTo(bufferedRequestBody)
        } else {
          // Write the request body if the ""Expect: 100-continue"" expectation was met.
          val bufferedRequestBody = exchange.createRequestBody(request, false).buffer()
          requestBody.writeTo(bufferedRequestBody)
          bufferedRequestBody.close()
        }
```
and then it will enter `Exchange.close()`,then `bodyComplete(bytesReceived, false, true, e)`","Do you consume the entire response body? Please provide an executable test case! Here's one to get you started:
https://github.com/square/okhttp/blob/master/okhttp/src/test/java/okhttp3/EventListenerTest.java#L1247","thank you for your reply
I find reason after I report this Bug, and I comment it on my Bug page, but now I can not find it 
the cause of the bug is i am not consume the entire response body
in my origin code , i do not consume the entire response body, here is my origin code: 
```
if (response.isSuccessful) {
                internal?.deleteLogFile(file.absolutePath)
            }
```
here is my new code:
```
if (response.isSuccessful) {
                response.body()?.string()
                internal?.deleteLogFile(file.absolutePath)
            }
```
my new code is work.
but I think some times people do not consume entire response body, so I think the better way is that it can Implicit invoke by okhttp framework"
square/okhttp,https://github.com/square/okhttp/issues/5248,"Already asked about that a long time ago and was refused :)

But before we could package cheat and use the code, now there's no more possible cheat.

That piece of code is highly optimized and very useful, it's sad to have to copy paste a bunch of things to reproduce it.

What would be missing to have that as a public API?",What’s the use case?,"1) 
I receive data from a backend that I need to encode with specific set before appending them to an url later when actually loading it.
Since it's on a performance critical path and dealing with many thousands, I do the encoding before saving to database. OkHTTP code fit that needs of specific sets and is way faster and allocation efficient than OS versions (Specially since I then need to do some replace in the generated string to fix the applied set)

2)
Less important as less critical path, but I do need to generate simple static string urls with encoded login/password and place holders with manual encoding allocate a lot less than create a full blown httpurl and convert to string. (For that one I could use provided httpurl api)
"
square/okhttp,https://github.com/square/okhttp/issues/5244,"I assume new tests we will increasingly write with Kotlin, particularly with some kotlin specific surface area.  So tagging the tests that should remain in Java would be useful, and migrating some to cleaner Kotlin APIs e.g. CallTest? ",Should we create a JavaSourceCompatibilityTest? Or a set of them? Then we don’t have to rely on the tests to have that side responsibility?,Yep. Sounds good. Just wanted to have discussion and noted plan. 
square/okhttp,https://github.com/square/okhttp/issues/5236,"Is it possible to add the ""$""  to the replaceAll when creating a new URI in the code below?

```
public URI uri() {
        String uri = newBuilder().reencodeForUri().toString();
        try {
            return new URI(uri);
        } catch (URISyntaxException e) {
            try {
                return URI.create(uri.replaceAll(""[\\u0000-\\u001F\\u007F-\\u009F\\p{javaWhitespace}]"", FRAGMENT_ENCODE_SET));
            } catch (Exception e2) {
                throw new RuntimeException(e);
            }
        }
    }
```


We have a library, that uses OkHttp crashing our android app because one of their customers is providing the following buggy URL: "" https://${imp_tracker_1}/"".

We have debugged the code and it's throwing an exception at the second Catch of the function above. Since $ is a reserved character for URI and does nothing I think it would be a good idea to have it treated when trying to create a new URI.","What about http://$/?

```
  @Test public void hostContainsIllegalCharacter() throws Exception {
    assertInvalid(""http://\n/"", ""Invalid URL host: \""\n\"""");
    assertInvalid(""http:// /"", ""Invalid URL host: \"" \"""");
    assertInvalid(""http://%20/"", ""Invalid URL host: \""%20\"""");
    // added here
    assertInvalid(""http://$/"", ""Invalid URL host: \""%20\"""");
  }
```
Or is there some sensible encoding to pass to URI constructor?

Specifically that catch block is documented as handling the fragment, which I accept for stripping.  But this case involves a $ in the host.
",
square/okhttp,https://github.com/square/okhttp/issues/5232,"I am using  implementation 'com.squareup.okhttp3:okhttp:3.11.0' 
and after I upgrade to 3.14.2 I got the following issue. all the api is not work with the following issue. How can I do with this to jump this issue. 
I am using android studio 3.4.1 and I am in Shanghai of China.
HTTP FAILED: javax.net.ssl.SSLHandshakeException: Handshake failed.

Hope hear soon from u. 

following is my script:
    implementation 'com.google.code.gson:gson:2.8.2'
        implementation('com.squareup.retrofit2:retrofit:2.6.0') {
        // exclude Retrofit’s OkHttp peer-dependency module and define your own module import
        exclude module: 'okhttp'
    }
    implementation 'com.squareup.okhttp3:okhttp:3.14.2'","Can you raise this on stackoverflow with a working example? It's often environmental e.g. phone, server, tls version/cipher related.

If you can make a reproduction as a test case for OkHttp then reopen here.",
square/okhttp,https://github.com/square/okhttp/issues/5230,"http://square.github.io/okhttp/events/

<img width=""379"" alt=""image"" src=""https://user-images.githubusercontent.com/231923/59973218-6d1fa680-9594-11e9-8c13-97ff18f12b0a.png"">

Between callStart and dns event there is likely a thread context switch.  Awkwardly there are API interactions, e.g. the Proxy selection which is essentially implicit here.  This event is hidden from event listeners.

I'd like to be able to make decisions in a ProxySelector based on the active call, but it's not easy to track either through direct API parameters or implicitly via the associated call/thread etc.

```
        at ee.schimke.okhttp.android.factory.AndroidProxySelector.select(AndroidProxySelector.kt:12)
        at okhttp3.internal.connection.RouteSelector.resetNextProxy(RouteSelector.java:115)
        at okhttp3.internal.connection.RouteSelector.<init>(RouteSelector.java:63)
        at okhttp3.internal.connection.ExchangeFinder.<init>(ExchangeFinder.java:75)
        at okhttp3.internal.connection.Transmitter.prepareToConnect(Transmitter.java:138)
        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:79)
``` 

Options

1) a OkHttp Proxy API with this information
2) add events around Proxy selection to EventListener

Why should we care?

1) At least on Android multiple networks might have different proxies e.g. Cellular is direct, Wifi has a corporate proxy.
2) Proxy selection is an ""interesting"" event we aren't tracking. ","Maybe this?

```
/**
 * Invoked prior to a proxy selection.
 *
 * This will be invoked for route selection regardless of whether the client
 * is configured with a single proxy, a proxy selector, or neither.
 * 
 * @param url a URL with only the scheme, hostname, and port specified.
 */
open fun proxySelectStart(call: Call, url: HttpUrl)

/**
 * Invoked after proxy selection.
 * 
 * Note that the list of proxies is never null, but it may be a list containing
 * only [Proxy.NO_PROXY]. This comes up in several situations:
 * 
 * * If neither a proxy nor proxy selector is configured.
 * * If the proxy is configured explicitly as [Proxy.NO_PROXY].
 * * If the proxy selector returns only [Proxy.NO_PROXY].
 * * If the proxy selector returns an empty list or null.
 *
 * Otherwise it lists the proxies in the order they will be attempted.
 * 
 * @param url a URL with only the scheme, hostname, and port specified.
 */
open fun proxySelectEnd(call: Call, url: HttpUrl, proxies: List<Proxy>)
```","I'll check the locks, but if we were holding locks we were potentially executing javascript of Proxy PAC files, so that's a more serious problem."
square/okhttp,https://github.com/square/okhttp/issues/5204,"
1 java.util.Collections$EmptyList.get(Collections.java:4514)
--
2 okhttp3.internal.connection.RealConnection.connectTls(RealConnection.java:326)
3 okhttp3.internal.connection.RealConnection.establishProtocol(RealConnection.java:283)
4 okhttp3.internal.connection.RealConnection.connect(RealConnection.java:168)
5 okhttp3.internal.connection.StreamAllocation.findConnection(StreamAllocation.java:257)
6 okhttp3.internal.connection.StreamAllocation.findHealthyConnection(StreamAllocation.java:135)
7 okhttp3.internal.connection.StreamAllocation.newStream(StreamAllocation.java:114)
8 okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:42)
9 okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
10 okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
11 okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
12 okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
13 okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
14 okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
15 okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
16 okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:126)
17 okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
18 okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
19 okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:254)
20 okhttp3.RealCall$AsyncCall.execute(RealCall.java:200)
21 okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
22 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
23 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
24 java.lang.Thread.run(Thread.java:784)


",Which version are you using? Please paste test case or your branch URL that can reproduce the error.,
square/okhttp,https://github.com/square/okhttp/issues/5167,"Yes, I'm using the ProGuard rules from readme.

```
Warning: okhttp3.internal.platform.ConscryptPlatform$configureTrustManager$1: ca
n't find superclass or interface org.conscrypt.ConscryptHostnameVerifier
Warning: okhttp3.Authenticator$Companion$NONE$1: can't find referenced class okh
ttp3.Authenticator$DefaultImpls
Warning: okhttp3.Authenticator$Companion$NONE$1: can't find referenced class okh
ttp3.Authenticator$DefaultImpls
Warning: okhttp3.CookieJar$Companion$NO_COOKIES$1: can't find referenced class o
khttp3.CookieJar$DefaultImpls
Warning: okhttp3.CookieJar$Companion$NO_COOKIES$1: can't find referenced class o
khttp3.CookieJar$DefaultImpls
Warning: okhttp3.Dns$Companion$SYSTEM$1: can't find referenced class okhttp3.Dns
$DefaultImpls
Warning: okhttp3.Dns$Companion$SYSTEM$1: can't find referenced class okhttp3.Dns
$DefaultImpls
Warning: okhttp3.internal.http2.PushObserver$Companion$CANCEL$1: can't find refe
renced class okhttp3.internal.http2.PushObserver$DefaultImpls
Warning: okhttp3.internal.http2.PushObserver$Companion$CANCEL$1: can't find refe
renced class okhttp3.internal.http2.PushObserver$DefaultImpls
Warning: okhttp3.internal.io.FileSystem$Companion$SYSTEM$1: can't find reference
d class okhttp3.internal.io.FileSystem$DefaultImpls
Warning: okhttp3.internal.io.FileSystem$Companion$SYSTEM$1: can't find reference
d class okhttp3.internal.io.FileSystem$DefaultImpls
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt$Version
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt$Version
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt$Version
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt$Version
Warning: okhttp3.internal.platform.ConscryptPlatform$Companion: can't find refer
enced class org.conscrypt.Conscrypt$Version
Warning: okhttp3.internal.platform.ConscryptPlatform$configureTrustManager$1: ca
n't find referenced class org.conscrypt.ConscryptHostnameVerifier
```","What's your ProGuard version? We saw a similar issue with Okio.
https://github.com/square/okio/issues/516",
square/okhttp,https://github.com/square/okhttp/issues/5148,"We got the security issue in the okhttp.
With the IBM Application Security, we got the following trace. Please check



javax.net.ssl.SSLParameters.setCipherSuites(java.lang.String[]):void | SSLParameters | (javax\net\ssl\SSLParameters.java:140)
-- | -- | --
[Framework Code, 8 lines removed] | ... | (...)
com.android.org.conscrypt.OpenSSLSocketImpl.startHandshake():void | OpenSSLSocketImpl | (com\android\org\conscrypt\OpenSSLSocketImpl.java:351)
okhttp3.internal.connection.RealConnection.connectTls(okhttp3.internal.connection.ConnectionSpecSelector):void | RealConnection | (okhttp3\internal\connection\RealConnection.java:318)
okhttp3.internal.connection.RealConnection.establishProtocol(okhttp3.internal.connection.ConnectionSpecSelector, int, okhttp3.Call, okhttp3.EventListener):void | RealConnection | (okhttp3\internal\connection\RealConnection.java:282)
okhttp3.internal.connection.RealConnection.connect(int, int, int, int, boolean, okhttp3.Call, okhttp3.EventListener):void | RealConnection | (okhttp3\internal\connection\RealConnection.java:167)
okhttp3.internal.connection.StreamAllocation.findConnection(int, int, int, int, boolean):okhttp3.internal.connection.RealConnection | StreamAllocation | (okhttp3\internal\connection\StreamAllocation.java:257)
okhttp3.internal.connection.StreamAllocation.findHealthyConnection(int, int, int, int, boolean, boolean):okhttp3.internal.connection.RealConnection | StreamAllocation | (okhttp3\internal\connection\StreamAllocation.java:135)
okhttp3.internal.connection.StreamAllocation.newStream(okhttp3.OkHttpClient, okhttp3.Interceptor.Chain, boolean):okhttp3.internal.http.HttpCodec | StreamAllocation | (okhttp3\internal\connection\StreamAllocation.java:114)
okhttp3.internal.connection.ConnectInterceptor.intercept(okhttp3.Interceptor.Chain):okhttp3.Response | ConnectInterceptor | (okhttp3\internal\connection\ConnectInterceptor.java:42)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request, okhttp3.internal.connection.StreamAllocation, okhttp3.internal.http.HttpCodec, okhttp3.internal.connection.RealConnection):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:147)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:121)
okhttp3.internal.cache.CacheInterceptor.intercept(okhttp3.Interceptor.Chain):okhttp3.Response | CacheInterceptor | (okhttp3\internal\cache\CacheInterceptor.java:93)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request, okhttp3.internal.connection.StreamAllocation, okhttp3.internal.http.HttpCodec, okhttp3.internal.connection.RealConnection):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:147)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:121)
okhttp3.internal.http.BridgeInterceptor.intercept(okhttp3.Interceptor.Chain):okhttp3.Response | BridgeInterceptor | (okhttp3\internal\http\BridgeInterceptor.java:93)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request, okhttp3.internal.connection.StreamAllocation, okhttp3.internal.http.HttpCodec, okhttp3.internal.connection.RealConnection):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:147)
okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(okhttp3.Interceptor.Chain):okhttp3.Response | RetryAndFollowUpInterceptor | (okhttp3\internal\http\RetryAndFollowUpInterceptor.java:126)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request, okhttp3.internal.connection.StreamAllocation, okhttp3.internal.http.HttpCodec, okhttp3.internal.connection.RealConnection):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:147)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:121)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request, okhttp3.internal.connection.StreamAllocation, okhttp3.internal.http.HttpCodec, okhttp3.internal.connection.RealConnection):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:147)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:121)
okhttp3.logging.HttpLoggingInterceptor.intercept(okhttp3.Interceptor.Chain):okhttp3.Response | HttpLoggingInterceptor | (okhttp3\logging\HttpLoggingInterceptor.java:212)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request, okhttp3.internal.connection.StreamAllocation, okhttp3.internal.http.HttpCodec, okhttp3.internal.connection.RealConnection):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:147)
okhttp3.internal.http.RealInterceptorChain.proceed(okhttp3.Request):okhttp3.Response | RealInterceptorChain | (okhttp3\internal\http\RealInterceptorChain.java:121)
okhttp3.RealCall.getResponseWithInterceptorChain():okhttp3.Response | RealCall | (okhttp3\RealCall.java:200)
okhttp3.RealCall.AsyncCall.execute():void | RealCall$AsyncCall | (okhttp3\RealCall.java:147)
okhttp3.internal.NamedRunnable.run():void | NamedRunnable | (okhttp3\internal\NamedRunnable.java:32)
java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor.Worker):void | ThreadPoolExecutor | (java\util\concurrent\ThreadPoolExecutor.java:1162)
java.util.concurrent.ThreadPoolExecutor.Worker.run():void | ThreadPoolExecutor$Worker | (java\util\concurrent\ThreadPoolExecutor.java:636)
java.lang.Thread.run():void | Thread | (java\lang\Thread.java:764)



Please check this and let us know. We are using, 
implementation 'com.squareup.retrofit2:retrofit:2.1.0'
implementation 'com.squareup.okhttp3:logging-interceptor:3.4.1'",What's the headline on the exception?,
square/okhttp,https://github.com/square/okhttp/issues/4981,"must reconnect to wifi or restart your app to get back to normal after a problem occurs.
",What are our next steps? We could offer a service to evict the connection pool when the network changes?,"We have encountered the same problem in a project before, and finally solved it like this:

`if (e instanceof SocketTimeoutException){
            OkHttp.getInstance().okHttpClient.dispatcher().cancelAll();
            OkHttp.getInstance().okHttpClient.connectionPool().evictAll();
    }
`
But there is a downside to this, the app must fail once and the next visit will succeed.

Based on the results of our current tests, this may be a bug in the okhttp connection pool module, which is very easy to appear on a particular machine. The step is to open the application, wait a few minutes, and then trigger the event to access the network. To be sure, the network on the machine is normal at this time, other applications can access the network normally, and a new okhttpClient can be created in the current application to access the network.
"
square/okhttp,https://github.com/square/okhttp/issues/4975,"When using R8 (Android shrinker) the following warnings are produced on build. These are harmless and won't fail to the build but it would be nice get rid of these.

```
AGPBI: {""kind"":""warning"",""text"":""Type `org.conscrypt.Conscrypt` was not found, it is required for default or static interface methods desugaring of `java.security.Provider okhttp3.internal.platform.ConscryptPlatform.getProvider()`"",""sources"":[{""file"":""/Projects/Wez/NextEpisode/app/build/intermediates/transforms/FirebasePerformancePlugin/debug/80/okhttp3/internal/platform/ConscryptPlatform.class""}],""tool"":""D8""}
AGPBI: {""kind"":""warning"",""text"":""synthesized for lambda desugaring: Type `okhttp3.Dns$-CC` was not found, it is required for default or static interface methods desugaring of `java.util.List okhttp3.-$$Lambda$Dns$mTkNcZf2K4euny3_jks6Cac6Az0.lookup(java.lang.String)`"",""sources"":[{}],""tool"":""D8""}
AGPBI: {""kind"":""warning"",""text"":""synthesized for lambda desugaring: Type `okhttp3.Authenticator$-CC` was not found, it is required for default or static interface methods desugaring of `okhttp3.Request okhttp3.-$$Lambda$Authenticator$xBBU2iHkJpDKH0vhaB2vteUyEoc.authenticate(okhttp3.Route, okhttp3.Response)`"",""sources"":[{}],""tool"":""D8""}
```",why does google treat developers like guinea pigs?,
square/okhttp,https://github.com/square/okhttp/issues/4974,"OkHttpClient.kt uses java.util.Random in the newWebSocket() method. java.util.Random is considered cryptically insecure due to the predictability of Linear Congruential Generators (LCGs). An attacker may be able to calculate the seed the number was generated by the use of Brute Force attacks as the class does generate enough entropy to truly be random.

Java includes a class named SecureRandom or java.util.SecureRandom to address this vulnerability and should be used in all instances where Random is used. The Random Number Generator (RNG) used for SecureRandom is considered stronger as it compiles based on a truly random pattern.","How does the spec mandate that you use java.util.Random? java.security.SecureRandom extends Random and can be used as drop-in replacement.
Even though this is not a security issue, the finding is reported by static analysis tools and might prevent the adoption of okhttp in enterprise projects.

",
square/okhttp,https://github.com/square/okhttp/issues/4951,"I know that **okhttp** now have already supported `h2-prior-knowledge`.

However, it is still inconvenient to use, because `h2_prior_knowledge` cannot be used with other protocols at the same time.

In my project, I use **okhttp** to access the REST APIs of other modules inside the project. Because the project will eventually be deployed on the intranet, there is no incentive to use https. At the same time, I need to use **okhttp** to access some external resources on the Internet. At this time, I have to instantiate two `OkHttpClient`s. It is very inconvenient to always pay attention to which one to access which resource.

If **okhttp** supports `h2c`, it will be very convenient to be compatible with both `h2` and `http/1.1` servers.
And it also matches the spirit of **okhttp** that recommending only one `OkHttpClient`.",How do you specificy which calls use h2c?,"Maybe, `h2c` is not enabled by default. But if I add `h2c` to the `OkHttpClient`, every **http** call add `Upgrade` to the http header. If the server support it, it will go with `h2c`. If the server does not support it, it simply ignore it, and it will go with 'http/1.1'."
square/okhttp,https://github.com/square/okhttp/issues/4917,"We created an EventListener implementation to collect metrics data for insights.
We collect the data and thru a helper class we push it fire-and-forget to a dedicated api on our back-end.

On dev environments (debug run) and unit tests (mocked apps) we are able to successfully collect insights data (all EventListener methods get called).
On staging and prod environments, we have cases where:
a- `callStart()`, `dnsStart()`, `dnsEnd()`, `connectStart()` were called, **but** `secureConnectStart()` nor `secureConnectEnd()` nor `connectEnd()` nor `connectFailed()` nor `connectionAcquired()` were called
b- `callStart()` to `responseHeadersEnd()` were called, **but** `responseBodyStart()` nor `responseBodyEnd()` nor `connectionReleased()` nor `callEnd()` were called

For all the cases:
- okHttp v3.11.0 on dev, staging & prod
- okHttp v3.12.x was also tested (dev and staging) with the same behavior
- we call secured endpoints (https with valid TLS certificates) 
- the app has no weird functioning (no missed responses from backend nor missing payload from responses) 
- presence of `HttpLoggingInterceptor` in the interceptor chain (enabled or not) makes no difference (at least not worse)

Here you can take a look at the two classes that handle the collect and push the metrics:
https://gist.github.com/rkuzner/1b2e2224c4586fc7d0eb390f5f59632f",Can you make this into an executable test case? I suspect it’s more likely to be an issue with your environments (prod vs. staging vs. test) than with OkHttp.,"Hi! 

We're working on making this into an reproducible test case, keeping the minimum needed for it to work and also checking if there is no other component that might interfere.

In the meantime, there is some additional info/clarifications:
- what I named as _staging_ are experimental versions that we run _internally_ with _live_ accounts
- on a few debug runs (on emulators) had also missing calls to Listener methods, sadly i'm not able to reproduce the case. I suspect this has something to do with cleaning the build and/or rebuilding the project.
- i need to confirm if our implementation of `connectionAcquired()` has some `null reference` issues with `connection.socket()`

I'll keep you updated!"
square/okhttp,https://github.com/square/okhttp/issues/4857,"![image](https://user-images.githubusercontent.com/29397850/55389472-e7c5c080-5567-11e9-8312-bdf2a0682835.png)
![image](https://user-images.githubusercontent.com/29397850/55389488-f1e7bf00-5567-11e9-84c9-80a5664a002b.png)
","What's the type of `realChain`? If it's `okhttp3.Interceptor.Chain` then I'm not able to find the `streamAllocation()` method in previous versions of OkHttp. Is it an extension function defined somewhere else?

Also, please prefer using English when filing issues on this project, as this is the language the majority of maintainers and contributors use. Thanks!",thanks for  your reply ，
square/okhttp,https://github.com/square/okhttp/issues/4761,"Hey, folks - I think I'm running into something that appears to be a regression in 3.14 around the new exchange mechanism. I can reproduce this 100% of the time in my app by creating a specific scenario.

Here's the basic setup. We have an interceptor that does a lot of things for us, including setting headers and handling retries for auth errors. Here's a simplified version of the code, eliding a lot of details around how the retries are triggered:

```
@Override
public Response intercept(Chain chain) throws IOException {
  Request originalRequest = chain.request();
  Request.Builder builder = originalRequest.newBuilder();
  // Add headers/etc here.
  Request request = builder.build();
  Response response = chain.proceed(request);

  if (isError(response)) {
    // Grab a new auth token, etc.
    response = chain.proceed(retry);
    return response;
  }
}
```

In 3.13.1, this seems to work just fine. In 3.14.0, this crashes with the following error:

```
03-22 11:52:21.889 E/AndroidRuntime(10135): java.lang.IllegalStateException: exchange != null
03-22 11:52:21.889 E/AndroidRuntime(10135): 	at okhttp3.internal.connection.Transmitter.newExchange(Transmitter.java:159)
03-22 11:52:21.889 E/AndroidRuntime(10135): 	at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:41)
...
```

It doesn't seem to matter if you mutate the request or not. Even just using (as above) a newly built version of the request produces the same behavior.

Any ideas what's happening here? I'm going to revert our library back to 3.13 for now to work around this, but I'm curious what could be causing this.",Can you see if closing it fixes things?,"Ah, good callout! It looks like closing the previous response before retrying *does* fix the crash on 3.14. I was able to change my code to the follow and re-run the same scenarios with no crashes:

```
@Override
public Response intercept(Chain chain) throws IOException {
  Request originalRequest = chain.request();
  Request.Builder builder = originalRequest.newBuilder();
  // Add headers/etc here.
  Request request = builder.build();
  Response response = chain.proceed(request);

  if (isError(response)) {
    // Grab a new auth token, etc.
    response.close();
    Request retry = request.newBuilder().build();
    response = chain.proceed(retry);
    return response;
  }
}
```

That definitely gets me unblocked, but it's interesting that this changed in the new version. Maybe something to note in the documentation for the future?

Thanks for the rapid response! (And of course, for all the work on maintaining this core library. :-) )"
square/okhttp,https://github.com/square/okhttp/issues/4699,"We are observing crashes in a Android app that are caused by the exhaustion of the available File Descriptors.
This seems to happen if many requests are `Call.enqueue`ed. We already made sure that we only have a single OkHttp instance.
While debugging it on a rooted emulator it seems to only happen if `OkHttpClient.Builder.cache()` is used.
### `Call.enqueue`ing a few thousand calls, with a Cache set, leads to:
- number of open File Descriptors goes up quite fast (well beyond 1k) and decreases slowly as the requests are being processed. If it does not crash because of missing File Descriptors it will go back to a normal number again once requests are finishing. 
```
...
/proc/<pid>/fd # ls -al | wc -l                                                                                        
967
/proc/<pid>/fd # ls -al | wc -l                                                                                        
1327
/proc/<pid>/fd # ls -al | wc -l                                                                                        
1617
/proc/<pid>/fd # ls -al | wc -l                                                                                        
1963
/proc/<pid>/fd # ls -al | wc -l                                                                                        
1547
/proc/<pid>/fd # ls -al | wc -l                                                                                        
1040
/proc/<pid>/fd # ls -al | wc -l                                                                                        
536
/proc/<pid>/fd # ls -al | wc -l                                                                                        
149
```
and there are thousand of open File Descriptors like:
```
/proc/<pid>/fd # ls -al

/<path-to-the-http-cache>/c5c99e84ce2ff13078cb523c95d74dff.1.tmp
/<path-to-the-http-cache>/e4e886e180225e2e05a2e1cf94537ef9.1.tmp
/<path-to-the-http-cache>/80de10600cb6c424fe994169e1135620.1.tmp
/<path-to-the-http-cache>/043d5411a5b6f8930d8c34397b983e74.1.tmp
```

### `Call.enqueue`ing a few thousand calls, with**out** a Cache set, leads to:
- steady number of open File Descriptors that stays around that number while the requests are being fetched
```
/proc/<pid>/fd # ls -al | wc -l                                                                                        
150
```

For both runs (with and without cache) the app storage was cleared (nothing cached yet), so I think it is caused by OkHttp Cache writing all the responses to the File System.
",Do you close the HTTP response when you’re done reading it?,"I'm quite sure we are closing the response properly, otherwise the file descriptors should also skyrocket during the run that has no cache in place, right?
However to make sure that my understanding of kotlins [`use`](https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.io/use.html) and suspend functions ([`suspendCancellableCoroutine`](https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/suspend-cancellable-coroutine.html)) is not failing me, here is how the requests are triggered:
```kt
@Throws(IOException::class)
suspend fun get(params): Data {
    val req = Request.Builder().....build()
    httpClient.newCall(req).await().use { response ->
        return when (response.code()) {
            // just extracting some data from the response
            200  -> Data(response.header(""content-type""), response.body()?.bytes() ?: throw IOException(""body missing""))
            else -> throw IOException(""${response.code()} - Unexpected Response during resource get"")
        }
    }
}
```

The response is `await`ed with this (very similar to how it is done in [gildor/kotlin-coroutines-okhttp](https://github.com/gildor/kotlin-coroutines-okhttp/blob/257ad2e0c3784a363876096d1bb5c201a366ded1/src/main/kotlin/ru/gildor/coroutines/okhttp/CallAwait.kt#L36-L57)):
```kt
suspend fun Call.await(): Response {
    return suspendCancellableCoroutine { continuation ->
        enqueue(object : Callback {
            override fun onResponse(call: Call, response: Response) {
                continuation.resume(response)
            }
            override fun onFailure(call: Call, e: IOException) {
                continuation.resumeWithException(e)
            }
        })
        continuation.invokeOnCancellation { cancel() }
    }
}
```

I also just decompiled the result and it looks like the `use` just wraps the whole block into a big `try{...}finally{response.close()}`"
square/okhttp,https://github.com/square/okhttp/issues/4691,"```
NumberFormatException: Invalid BigInteger: 82cb8efb37a1e084693f6d8cf8b35f0082aaf61676a7c8bf37ec06396037168a635278a1a8fa5c138cd9eb&bFab4`4df@1/3scd7r5eec2le de4g8a4-9""3eet
       at java.math.BigInt.invalidBigInteger(BigInt.java:90)
       at java.math.BigInt.checkString(BigInt.java:144)
       at java.math.BigInt.putHexString(BigInt.java:103)
       at java.math.BigInteger.<init>(BigInteger.java:244)
       at com.android.org.conscrypt.PinListEntry.validatePin(PinListEntry.java:133)
       at com.android.org.conscrypt.PinListEntry.addPins(PinListEntry.java:121)
       at com.android.org.conscrypt.PinListEntry.<init>(PinListEntry.java:77)
       at com.android.org.conscrypt.CertPinManager.rebuild(CertPinManager.java:91)
       at com.android.org.conscrypt.CertPinManager.<init>(CertPinManager.java:49)
       at com.android.org.conscrypt.TrustManagerImpl.<init>(TrustManagerImpl.java:137)
       at com.android.org.conscrypt.TrustManagerImpl.<init>(TrustManagerImpl.java:97)
       at com.android.org.conscrypt.TrustManagerFactoryImpl.engineGetTrustManagers(TrustManagerFactoryImpl.java:80)
       at javax.net.ssl.TrustManagerFactory.getTrustManagers(TrustManagerFactory.java:219)
       at okhttp3.internal.Util.platformTrustManager(Util.java:667)
       at okhttp3.OkHttpClient.<init>(OkHttpClient.java:257)
       at okhttp3.OkHttpClient$Builder.build(OkHttpClient.java:1040)
```

 Android 4.4.2
 Galaxy Tab4 7.0
",Do you have a test case where this consistently happens?,only crashlytics report
square/okhttp,https://github.com/square/okhttp/issues/4670,"When upgrading from 3.12.1 to 3.13.1 I get this exception:
```

    javax.net.ssl.SSLHandshakeException: Handshake failed
        at com.android.org.conscrypt.ConscryptFileDescriptorSocket.startHandshake(ConscryptFileDescriptorSocket.java:286)
        at okhttp3.internal.connection.RealConnection.connectTls(RealConnection.java:320)
        at okhttp3.internal.connection.RealConnection.establishProtocol(RealConnection.java:284)
        at okhttp3.internal.connection.RealConnection.connect(RealConnection.java:169)
        at okhttp3.internal.connection.StreamAllocation.findConnection(StreamAllocation.java:257)
        at okhttp3.internal.connection.StreamAllocation.findHealthyConnection(StreamAllocation.java:135)
        at okhttp3.internal.connection.StreamAllocation.newStream(StreamAllocation.java:114)
        at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:42)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:94)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:125)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at org.foo.manager.service.HttpClient$LoggingInterceptor.intercept(HttpClient.java:122)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:264)
        at okhttp3.RealCall.execute(RealCall.java:93)
        at retrofit2.OkHttpCall.execute(OkHttpCall.java:186)
        at retrofit2.adapter.rxjava2.CallExecuteObservable.subscribeActual(CallExecuteObservable.java:45)
        at io.reactivex.Observable.subscribe(Observable.java:12246)
        at retrofit2.adapter.rxjava2.BodyObservable.subscribeActual(BodyObservable.java:34)
...
     Caused by: javax.net.ssl.SSLProtocolException: SSL handshake aborted: ssl=0xe31d0a08: Failure in SSL library, usually a protocol error
    error:100000f0:SSL routines:OPENSSL_internal:UNSUPPORTED_PROTOCOL (external/boringssl/src/ssl/handshake_client.cc:576 0xe09aba43:0x00000000)
        at com.android.org.conscrypt.NativeCrypto.SSL_do_handshake(Native Method)
        at com.android.org.conscrypt.NativeSsl.doHandshake(NativeSsl.java:375)
        at com.android.org.conscrypt.ConscryptFileDescriptorSocket.startHandshake(ConscryptFileDescriptorSocket.java:224)
        at okhttp3.internal.connection.RealConnection.connectTls(RealConnection.java:320)
        at okhttp3.internal.connection.RealConnection.establishProtocol(RealConnection.java:284)
        at okhttp3.internal.connection.RealConnection.connect(RealConnection.java:169)
        at okhttp3.internal.connection.StreamAllocation.findConnection(StreamAllocation.java:257)
        at okhttp3.internal.connection.StreamAllocation.findHealthyConnection(StreamAllocation.java:135)
        at okhttp3.internal.connection.StreamAllocation.newStream(StreamAllocation.java:114)
        at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:42)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:94)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:125)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at org.foo.manager.service.HttpClient$LoggingInterceptor.intercept(HttpClient.java:122)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:264)
        at okhttp3.RealCall.execute(RealCall.java:93)
        at retrofit2.OkHttpCall.execute(OkHttpCall.java:186)

```

```
    public class LoggingInterceptor implements Interceptor {
        @EverythingIsNonNull
        @Override
        public okhttp3.Response intercept(Chain chain) throws IOException {
            Request request = chain.request();

            long t1 = System.nanoTime();

            okhttp3.Response response = chain.proceed(request);

            long t2 = System.nanoTime();
            String log = String.format(""<-- Received response for %s in %.1fms%n%s"", response.request().url(), (t2 - t1) / 1e6d, response.headers());

            if (response.body() != null) {
                MediaType contentType = response.body().contentType();
                byte[] bytes = response.body().bytes();
                String content = new String(bytes, Charset.forName(""ISO-8859-1""));
                Log.d(""OkHttp"", log + ""\n"" + content);

                ResponseBody wrappedBody = ResponseBody.create(contentType, bytes);
                return response.newBuilder().body(wrappedBody).build();
            }
            Log.d(""OkHttp"", log);
            return response;
        }
    }

```
","Does this help?
https://medium.com/square-corner-blog/okhttp-3-13-requires-android-5-818bb78d07ce",yes
square/okhttp,https://github.com/square/okhttp/issues/4669,"When upgrading from 3.12.1 to 3.13.0 I get these exceptions:

```
2019-02-27 22:47:21.106 24799-24799 E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.fletech.trackid, PID: 24799
    java.lang.AssertionError: java.lang.reflect.InvocationTargetException
        at okhttp3.internal.platform.AndroidPlatform.buildCertificateChainCleaner(AndroidPlatform.java:201)
        at okhttp3.internal.tls.CertificateChainCleaner.get(CertificateChainCleaner.java:41)
        at okhttp3.OkHttpClient$Builder.sslSocketFactory(OkHttpClient.java:821)
        at org.foo.manager.service.HttpClient.getHttpClientBuilder(HttpClient.java:102)
        at org.foo.manager.service.HttpClient.getClient(HttpClient.java:166)
        at org.foo.manager.service.WebSocketRx.<init>(WebSocketRx.java:49)
        at org.foo.manager.service.WebSocketRx.init(WebSocketRx.java:37)
        at org.foo.manager.service.Devices.init(Devices.java:36)
        at org.foo.manager.MainApplication.onCreate(MainApplication.java:46)
        at android.app.Instrumentation.callApplicationOnCreate(Instrumentation.java:1154)
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5871)
        at android.app.ActivityThread.access$1100(ActivityThread.java:199)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1650)
        at android.os.Handler.dispatchMessage(Handler.java:106)
        at android.os.Looper.loop(Looper.java:193)
        at android.app.ActivityThread.main(ActivityThread.java:6669)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:858)
     Caused by: java.lang.reflect.InvocationTargetException
        at java.lang.reflect.Constructor.newInstance0(Native Method)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:343)
        at okhttp3.internal.platform.AndroidPlatform.buildCertificateChainCleaner(AndroidPlatform.java:196)
        at okhttp3.internal.tls.CertificateChainCleaner.get(CertificateChainCleaner.java:41) 
        at okhttp3.OkHttpClient$Builder.sslSocketFactory(OkHttpClient.java:821) 
        at org.foo.manager.service.HttpClient.getHttpClientBuilder(HttpClient.java:102) 
        at org.foo.manager.service.HttpClient.getClient(HttpClient.java:166) 
        at org.foo.manager.service.WebSocketRx.<init>(WebSocketRx.java:49) 
        at org.foo.manager.service.WebSocketRx.init(WebSocketRx.java:37) 
        at org.foo.manager.service.Devices.init(Devices.java:36) 
        at org.foo.manager.MainApplication.onCreate(MainApplication.java:46) 
        at android.app.Instrumentation.callApplicationOnCreate(Instrumentation.java:1154) 
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5871) 
        at android.app.ActivityThread.access$1100(ActivityThread.java:199) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1650) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:193) 
        at android.app.ActivityThread.main(ActivityThread.java:6669) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:858) 
     Caused by: java.lang.IllegalArgumentException: Required method checkServerTrusted(X509Certificate[], String, String, String) missing
        at android.net.http.X509TrustManagerExtensions.<init>(X509TrustManagerExtensions.java:72)
        at java.lang.reflect.Constructor.newInstance0(Native Method) 
        at java.lang.reflect.Constructor.newInstance(Constructor.java:343) 
        at okhttp3.internal.platform.AndroidPlatform.buildCertificateChainCleaner(AndroidPlatform.java:196) 
        at okhttp3.internal.tls.CertificateChainCleaner.get(CertificateChainCleaner.java:41) 
        at okhttp3.OkHttpClient$Builder.sslSocketFactory(OkHttpClient.java:821) 
        at org.foo.manager.service.HttpClient.getHttpClientBuilder(HttpClient.java:102) 
        at org.foo.manager.service.HttpClient.getClient(HttpClient.java:166) 
        at org.foo.manager.service.WebSocketRx.<init>(WebSocketRx.java:49) 
        at org.foo.manager.service.WebSocketRx.init(WebSocketRx.java:37) 
        at org.foo.manager.service.Devices.init(Devices.java:36) 
        at org.foo.manager.MainApplication.onCreate(MainApplication.java:46) 
        at android.app.Instrumentation.callApplicationOnCreate(Instrumentation.java:1154) 
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5871) 
        at android.app.ActivityThread.access$1100(ActivityThread.java:199) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1650) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:193) 
        at android.app.ActivityThread.main(ActivityThread.java:6669) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:858) 

```
```
    private OkHttpClient.Builder getHttpClientBuilder(boolean ignoreSslErrors) {
        if(!ignoreSslErrors){
            return new OkHttpClient.Builder();
        }

        final TrustManager[] trustAllCerts = new TrustManager[] {
                new X509TrustManager() {
                    @Override
                    public void checkClientTrusted(java.security.cert.X509Certificate[] chain, String authType) throws CertificateException {
                    }

                    @Override
                    public void checkServerTrusted(java.security.cert.X509Certificate[] chain, String authType) throws CertificateException {
                    }

                    @Override
                    public java.security.cert.X509Certificate[] getAcceptedIssuers() {
                        return new java.security.cert.X509Certificate[]{
                        };
                    }
                }
        };

        SSLContext sslContext;
        try {
            sslContext = SSLContext.getInstance(""SSL"");
            sslContext.init(null, trustAllCerts, new java.security.SecureRandom());
        }
        catch (Exception exception){
            throw new RuntimeException(exception);
        }

        final SSLSocketFactory sslSocketFactory = sslContext.getSocketFactory();
        OkHttpClient.Builder builder = new OkHttpClient.Builder();
        builder.sslSocketFactory(sslSocketFactory, (X509TrustManager) trustAllCerts[0]);
        builder.hostnameVerifier((hostname, session) -> true);
        return builder;
    }

```","Does adding another `checkServerTrusted` method fix?

```
        final TrustManager[] trustAllCerts = new TrustManager[] {
                new X509TrustManager() {
                    @Override
                    public void checkClientTrusted(java.security.cert.X509Certificate[] chain, String authType) throws CertificateException {
                    }

                    @Override
                    public void checkServerTrusted(java.security.cert.X509Certificate[] chain, String authType) throws CertificateException {
                    }

                    // Called reflectively by X509TrustManagerExtensions.
                    public void checkServerTrusted(java.security.cert.X509Certificate[], String authType, String host) {
                    }

                    @Override
                    public java.security.cert.X509Certificate[] getAcceptedIssuers() {
                        return new java.security.cert.X509Certificate[]{
                        };
                    }
                }
        };
```",
square/okhttp,https://github.com/square/okhttp/issues/4615,"Specifically, if this line is executed:

https://github.com/square/okhttp/blob/5ecd590c8c0cd7833ed378c8702d3a228817b4e8/okhttp/src/main/java/okhttp3/internal/platform/Jdk8WithJettyBootPlatform.java#L85

and that ALPN class is on the normal classpath, in addition to the boot classpath, then the class will be initialized from the class' ClassLoader, _not_ from the 'null' (system / bootstrap) classloader.

Then, Jetty will fail to initialize its `OpenJDK8ServerALPNProcessor` because the following check will fail:

https://github.com/eclipse/jetty.project/blob/f88f856673f2e8768042c973481ad78d41910e22/jetty-alpn/jetty-alpn-openjdk8-server/src/main/java/org/eclipse/jetty/alpn/openjdk8/server/OpenJDK8ServerALPNProcessor.java#L44-L45

We've usually hit this failure case when initializing okhttp clients in tests first (simply due to an unfortunate class load ordering), and only later loading the [jetty ALPN agent](https://github.com/jetty-project/jetty-alpn-agent) dynamically by calling a method [Http2Agent.install](https://github.com/palantir/conjure-java-runtime/blob/4f7e9c6428b356394771ef136f22bb4ad825877e/jetty-http2-agent/src/main/java/com/palantir/conjure/java/http2/Http2Agent.java#L33-L50) in a static initializer.

TODO:

- [x] test: https://github.com/square/okhttp/pull/4617
",Why is it on both class paths? Wanna send a PR to force the boot class loader?,"Because if you want to support java 9+ too, then you need to depend on `org.eclipse.jetty:jetty-alpn-java-server`, which brings `org.eclipse.jetty.alpn:alpn-api` as a dependency, which contains that same class 😉 "
square/okhttp,https://github.com/square/okhttp/issues/4572,"I am using Retrofit2 with OkHttp. Everything is working fine with it except the one thing - a network call when app is closed or in background.

**Working**
Whenever Firebase notification arrives, I make a network call to fetch data related to that notifications and then show notification.

**Scenario**
Consider an Android app which is in background or closed and notification arrives.

**What's Happening**
Notification arrives successfully, I can see it. But when I try to make a call, it is always giving an error _Failed to connect to: *******_ and I can't see any call coming on server.

I have seen some similar type of issues but none of them could help me.
Here's a list:

1. https://github.com/square/okhttp/issues/1771
2. https://github.com/square/okhttp/issues/3146
3. https://github.com/square/okhttp/issues/1037
4. https://github.com/square/okhttp/issues/1792


Some suggested to use _connectionPool_ and some to use _pingInterval_. Nothing worked in my case. I am not sure if it's bug of Retrofit or OkHttp.

Below is the piece of code I am using for the call. Remember that it's working perfectly fine when app is in foreground.


        OkHttpClient.Builder builder = getHttpBuilder()
                .connectionSpecs(getSpecList());

        retrofit = new Retrofit.Builder()
                .baseUrl(Session.getBaseUrl())
                .client(builder.build())
                .build();


        Call<ResponseBody> call = retrofit
                .create(Webservice.class)
                .pullNotify(authToken, ivB64, digest, Session.getTimestamp());
        call.enqueue(new Callback<ResponseBody>() {
            @Override
            public void onResponse(Call<ResponseBody> call, Response<ResponseBody> response) {
                listener.onNetworkCallSuccess(response);
            }

            @Override
            public void onFailure(Call<ResponseBody> call, Throwable t) {
                listener.onNetworkCallFailure(t);
            }
        });


It always returns `SocketTimeoutException`. Any help/guidance is appreciated.","How can I make simple network request on Oreo in background, without showing notification with service?",
square/okhttp,https://github.com/square/okhttp/issues/4551,"I was to use OkHttp with RxJava2. Would you consider porting the Retrofit RxJava2 Adapters to OkHttp? I did it myself in my own project, and it seemed pretty simple. I understand that you might not want to publish this with OkHttp itself, but maybe you could make an `adapter-rxjava2` jar like Retrofit provides.

The API could look something like:
```
public final class ReactivexCallAdapter {
    private final boolean isAsync;
    @Nullable
    private final Scheduler scheduler;

    public static ReactivexCallAdapter create() {
        return new ReactivexCallAdapter(false, null);
    }

    public static ReactivexCallAdapter createAsync() {
        return new ReactivexCallAdapter(true, null);
    }

    public static ReactivexCallAdapter createWithScheduler(Scheduler scheduler) {
        return new ReactivexCallAdapter(false, scheduler);
    }

    private ReactivexCallAdapter(boolean isAsync, @Nullable Scheduler scheduler) {
        this.isAsync = isAsync;
        this.scheduler = scheduler;
    }

    public Completable completable(Call call) {
        Observable<Response> observable = unassumbledObservable(call);
        return observable.ignoreElements();
    }

    public Flowable<Response> flowable(Call call) {
        Observable<Response> observable = unassumbledObservable(call);
        return observable.toFlowable(BackpressureStrategy.LATEST);
    }

    public Maybe<Response> maybe(Call call) {
        Observable<Response> observable = unassumbledObservable(call);
        return observable.singleElement();
    }

    public Observable<Response> observable(Call call) {
        Observable<Response> observable = unassumbledObservable(call);
        return RxJavaPlugins.onAssembly(observable);
    }

    public Single<Response> single(Call call) {
        Observable<Response> observable = unassumbledObservable(call);
        return observable.singleOrError();
    }

    private Observable<Response> unassumbledObservable(Call call) {
        Observable<Response> originalObservable;
        if (isAsync) {
            originalObservable = new CallEnqueueObservable(call);
        } else {
            originalObservable = new CallEnqueueObservable(call);
        }

        Observable<Response> observable;
        if (scheduler == null) {
            observable = originalObservable;
        } else {
            observable = originalObservable.subscribeOn(scheduler);
        }

        return observable;
    }
}
```
",What's the difference between this and Retrofit?,This all makes good sense. Thanks for the prompt responses!
square/okhttp,https://github.com/square/okhttp/issues/4548,"I'm using `implementation 'com.squareup.okhttp3:okhttp:3.11.0'`

My application crashes on initialization at the following line, but only in production builds: 
```java
public class OkHttp3WebClient implements IWebClient {
    private static final String TAG = OkHttp3WebClient.class.getSimpleName().substring(0, 15);
    ...
}
```

I followed the ""guidance"" for ProGuard rules [here](https://github.com/square/okhttp/blob/master/okhttp/src/main/resources/META-INF/proguard/okhttp3.pro)

What I've found is that the application crashes on the line above with `java.lang.ExceptionInInitializerError Caused by: java.lang.StringIndexOutOfBoundsException: length=1; index=15`

I believe what is happening that ProGuard is mapping the name to some class `C`.  Then `C.class.getSimpleName()` becomes a one character string `""C""`.  So `""C"".substring(0,15)` throws an `StringIndexOutOfBoundsException`

There was an older discussion about this, but [issue 2230](https://github.com/square/okhttp/issues/2230) was closed a long time ago.","what's the substring for?

jshell> java.lang.Runtime.class.getSimpleName()
$1 ==> ""Runtime""",You are correct. Apologies for the false alarm.
square/okhttp,https://github.com/square/okhttp/issues/4539,"Hi, it seems like the cache response contains the old response while the network response is new and modified.

We're on android using  'com.squareup.okhttp3:okhttp:3.11.0'

See example below of the headers we get this in the same Response, notice the network response has 200 status code and a newer LastModified, different ETag etc.

The expected result would be that the cache response would contain the same (new) data as the network response in cases where the network response is fresher.


**network response**
Response{protocol=http/1.1, code=200, message=OK, url=http://xxx.yyy.zzz/test} 
headers: Content-Type: application/octet-stream
    Content-Length: 3093384
    Connection: keep-alive
    Date: Mon, 07 Jan 2019 09:11:45 GMT
    Last-Modified: Mon, 07 Jan 2019 09:11:15 GMT
    ETag: ""18905c1f58feca0c6df495f7cc2e6846""
    x-amz-version-id: 6J9k_vF2g.lPoELovv9G.rUPpfnk2h4r
    Accept-Ranges: bytes
    Server: AmazonS3
    Age: 10
    X-Cache: Hit from cloudfront
    Via: 1.1 32c8da10203574baccb74b8f771a7ffb.cloudfront.net (CloudFront)
    X-Amz-Cf-Id: FVvnNF3QD5I0vELy78FoVxYgvJeqRsCACGdbbh5W8MGtARkg0lH9CQ==

**cache response** 
Response{protocol=http/1.1, code=200, message=OK, url=http://http://xxx.yyy.zzz/test} 
headers: Content-Type: application/octet-stream
    Content-Length: 3093323
    Connection: keep-alive
    Last-Modified: Sun, 06 Jan 2019 15:03:31 GMT
    Accept-Ranges: bytes
    Date: Mon, 07 Jan 2019 09:09:11 GMT
    ETag: ""9725f2a6b04151c54f8a420be6fa7690""
    x-amz-version-id: vKJV3auEiruTggNKvciHJoy1LWscENFM
    Server: AmazonS3
    Age: 65063
    X-Cache: Hit from cloudfront
    Via: 1.1 e64eb476d8f76c461d21278e018e194f.cloudfront.net (CloudFront)
    X-Amz-Cf-Id: R53ZU9rO1_ZWlueMU3Xo1ZOeDX5ibAv9TFDgp2uchC6rfg9fBCtk-A==","Does this explain it?
https://publicobject.com/2015/03/26/how-do-http-caching-heuristics-work/

Your server needs to include a cache-control header in the response.","yes, both networkResponse and cacheResponse I copied above are from the same response. The networkResponse is with code 200. "
square/okhttp,https://github.com/square/okhttp/issues/4533,"Android community heavily rely on okhttp. It basically everywhere. But there is no android related test in this repo. I am thinking introduce an android sample and do proguard or other android related thing.

So any ideas ?",What Android support is missing? OkHttp is not an Android-specific library so it's built on the behavior of the `java.*` APIs. Android ships those APIs so any behavior difference is an OS bug. What specifically are you asking for?,"Like ensure R8/Proguard rules are correct. From this https://github.com/facebook/react-native/pull/22877, it looks like something is broken."
square/okhttp,https://github.com/square/okhttp/issues/4485,"[XNIO-2 task-52][ERROR][ServiceFallbackProvider:38] fallbackResponse - ServiceFallbackProvider.fallbackResponse:route=websrv-auth,cause=com.netflix.client.ClientException
	at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:118)
	at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:186)
	at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:51)
	at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302)
	at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:46)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:48)
	at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:33)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41)
	at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51)
	at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.Observable.subscribe(Observable.java:10247)
	at rx.Observable.subscribe(Observable.java:10214)
	at rx.internal.operators.BlockingOperatorToFuture.toFuture(BlockingOperatorToFuture.java:51)
	at rx.observables.BlockingObservable.toFuture(BlockingObservable.java:411)
	at com.netflix.hystrix.HystrixCommand.queue(HystrixCommand.java:378)
	at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:344)
	at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:161)
	at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:114)
	at com.netflix.zuul.ZuulFilter.runFilter(ZuulFilter.java:117)
	at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:193)
	at com.netflix.zuul.FilterProcessor.runFilters(FilterProcessor.java:157)
	at com.netflix.zuul.FilterProcessor.route(FilterProcessor.java:118)
	at com.netflix.zuul.ZuulRunner.route(ZuulRunner.java:96)
	at com.netflix.zuul.http.ZuulServlet.route(ZuulServlet.java:116)
	at com.netflix.zuul.http.ZuulServlet.service(ZuulServlet.java:81)
	at org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:165)
	at org.springframework.cloud.netflix.zuul.web.ZuulController.handleRequest(ZuulController.java:44)
	at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:52)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.cloud.sleuth.instrument.web.ExceptionLoggingFilter.doFilter(ExceptionLoggingFilter.java:48)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at brave.servlet.TracingFilter.doFilter(TracingFilter.java:86)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)
	at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)
	at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84)
	at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62)
	at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65)
	at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36)
	at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132)
	at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57)
	at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
	at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46)
	at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64)
	at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60)
	at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77)
	at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43)
	at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
	at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)
	at io.undertow.servlet.handlers.SessionRestoringHandler.handleRequest(SessionRestoringHandler.java:119)
	at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292)
	at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81)
	at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138)
	at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135)
	at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48)
	at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43)
	at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272)
	at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81)
	at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104)
	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336)
	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: okhttp3.internal.http2.StreamResetException: stream was reset: PROTOCOL_ERROR
	at rx.exceptions.Exceptions.propagate(Exceptions.java:58)
	at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:464)
	at rx.observables.BlockingObservable.single(BlockingObservable.java:341)
	at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112)
	... 151 more
Caused by: okhttp3.internal.http2.StreamResetException: stream was reset: PROTOCOL_ERROR
	at okhttp3.internal.http2.Http2Stream.takeResponseHeaders(Http2Stream.java:153)
	at okhttp3.internal.http2.Http2Codec.readResponseHeaders(Http2Codec.java:127)
	at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:88)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:126)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
	at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
	at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:200)
	at okhttp3.RealCall.execute(RealCall.java:77)
	at org.springframework.cloud.netflix.ribbon.okhttp.RetryableOkHttpLoadBalancingClient$1.doWithRetry(RetryableOkHttpLoadBalancingClient.java:133)
	at org.springframework.cloud.netflix.ribbon.okhttp.RetryableOkHttpLoadBalancingClient$1.doWithRetry(RetryableOkHttpLoadBalancingClient.java:102)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:180)
	at org.springframework.cloud.netflix.ribbon.okhttp.RetryableOkHttpLoadBalancingClient.executeWithRetry(RetryableOkHttpLoadBalancingClient.java:95)
	at org.springframework.cloud.netflix.ribbon.okhttp.RetryableOkHttpLoadBalancingClient.execute(RetryableOkHttpLoadBalancingClient.java:146)
	at org.springframework.cloud.netflix.ribbon.okhttp.RetryableOkHttpLoadBalancingClient.execute(RetryableOkHttpLoadBalancingClient.java:58)
	at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104)
	at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303)
	at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287)
	at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231)
	at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286)
	at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144)
	at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185)
	at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180)
	at rx.Observable.unsafeSubscribe(Observable.java:10151)
	at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94)
	at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
	at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
	at rx.Observable.subscribe(Observable.java:10247)
	at rx.Observable.subscribe(Observable.java:10214)
	at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:444)
	... 153 more",Do you know what the HTTP/2 server is? As-is there’s not much to reproduce this. ,"The sever is undertow , I have create the same issue in the JIRA for them . "
square/okhttp,https://github.com/square/okhttp/issues/4481,"For the release OkHttp 3.13 I’d like to change our requirements from this:

 * Android 2.3+ (released December 6, 2010)
 * Java 7+ (released July 2011)

To this:

 * Android 5.0+ (released November 12, 2014)
 * Java 8+ (released March 2014)

These minimums ensure our TLS stack supports both TLSv1.2 and ALPN. Requiring TLSv1.2 is important because we’re soon going to [disable](https://github.com/square/okhttp/issues/4319) TLSv1.0 and TLSv1.1 by default!

I think we want to ship Java 8 bytecode and use lambas and method references. Downstream Android applications may need to enable desugaring in D8 when building APKs.

We should avoid hard requirements on Java 8 APIs (java.time). We will instead continue to offer them as convenience overloads. Java 8 APIs aren’t available until API 26 (released August 2017).","Would we consider releasing 3.12.x with *critical* security fixes, or just abandon really old clients?  FWIW I'm for this, I just think it's worth stating what the plan would be.","@yschimke Exactly. We’ll do long term fixes on the 3.12 branch, but new features will require newer devices."
square/okhttp,https://github.com/square/okhttp/issues/4441,"Per @swankjesse 

> we might need to move the callStart callback to only occur if you actually use the network","Would it be more useful to keep callStart, callEnd marking the start and end for clients, but expose an event for a cache hit instead?",
square/okhttp,https://github.com/square/okhttp/issues/4419,I don’t think this works. We should add a test to confirm that it does.,Should `UnixDomainSocketFactory` and `UnixDomainServerSocketFactory` move to a new `okhttp-unixdomainsockets` Maven module to allow using them from both the UNIX domain sockets sample and MockWebServer tests?,"@kikin81 please report the bug to the device makers?

@amirlivneh no. We won't need a dependency from MockWebServer to fix this bug."
square/okhttp,https://github.com/square/okhttp/issues/4245,Would be neater to just set RealConnection.noNewStreams when we approach the limit.,Can I take pick up issue if no one else is working?,
square/okhttp,https://github.com/square/okhttp/issues/4071,"
Hi! I apologize in advance for this bug report since it will be more FYI than a specific to the point bug report as we have not been able to identify the root cause of it nor reproduce it (I know, I wish we had more info than the below).

Problem: Intermittently we see our app clients using okhttp 3.6.0 launching 60+ POST requests when only one should have been sent. These requests were launched within sub-millisecond of each other hence spamming our API.

App runs React Native 0.55.3 and utilizing the standard fetch() call which in turns falls back on okhttp 3.6.0.

Communication path:   App -> AWS ELB -> Apache server.

Some patterns that might hold true (we haven't seen any deviation from this.. but who knows, black swans are out there we might just not have observed them yet):
- Problem is only with POST requests. We haven't observed this with GET/PATCH/DELETE yet.
- Problem is only when going over HTTP/2. When we turn off HTTP/2 on our ELB we don't observe any clients having the issue any longer.
- Problem only seems to exhibit when the Apache/ELB responds with error code >= 400. We haven't observed it happening when error code is 200.

We estimate this to happen in approx 0.1% of all requests or so. Hence, infrequently.

Reproduction: We have been able to find a scenario that can reproduce it but we observe it hundreds of times per day when HTTP/2 is enabled.

We are quite certain that the issue isn't with our app logic since we do not have any logic for retries or anything similar. The problem would be down the stack, in React Native or Okhttp.

I wanted to open this issue in case it has been observed by anyone else out there and they know the root cause for it or if they have a reliable reproduction of it, in such case we could help patch the behavior (assuming the problem is with okhttp).","What specific error codes are returned?  Is it possible that there is a HTTP/2 stream error returned by the server?  There is some HTTP/2 specific retries e.g. REFUSED_STREAM.

I don't think we can resolve just from this report.  If its reproducible in a public server then we can work out the bug and fix.","Hi, some additional findings based on some log review we did today:

- When the issue starts the bytes received for the first request is let's say 104 bytes, for all subsequent spamming requests it is 23 bytes. Another example has first payload of 151 bytes and the rest is 19.

- When the spams start it launches all the requests in about 20-60ms total then it rests for almost exactly 60 seconds and the restart with launching requests again. We have seen it launch more than 200 requests in 30ms. It could be due to the bug, or due to some security mechanisms AWS / Android might deploy.

- The error code returned by our ELB is 408. Regarding specific HTTP/2 error codes, the access logs in ELB doesn't contain them so we not able to answer that question unfortunately. We do not have access to any device log where this error has occurred so we can't look there either.

Regarding Authenticator, this is how our Javascript looks:

```
let conf = { method: 'POST', headers: { 'Accept': 'application/json', 'X-APIKEY': this.apiKey }};
let response = await fetch(""https://domain.com/api"", conf);
```

In React Native they seem to have implemented fetch() in the following way utilizing Okhttp:
```
import okhttp3.Request;

Request.Builder requestBuilder;

requestBuilder = new Request.Builder().url(url);
requestBuilder.headers(requestHeaders);
```

"
square/okhttp,https://github.com/square/okhttp/issues/4043,"I have an i ssue where OkHttp does not revalidate requests. (3.10.0)
If the cache-control says ""must-revalidate"", the request should be revalidated.

In that case, the `CacheStrategy` should return a not null network request:

```kotlin
@Test
fun shouldRevalidate() {
  val nowMillis = 1527845183942 // =Fri Jun 01 2018 09:26:23
  val request = Request.Builder()
      .method(""GET"", null)
      .url(""https://my.url.com/v1/item/d002fbef-7061-4d92-9958-7b128cf85855"")
      .build()

  val handshake = Handshake.get(
      TlsVersion.TLS_1_2,
      CipherSuite.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, emptyList(), emptyList()
  )
  val cacheCandidate = Response.Builder()
      .code(200)
      .addHeader(""date"", ""Fri, 01 Jun 2018 07:45:40 GMT"")
      .addHeader(""cache-control"", ""private, must-revalidate"")
      .addHeader(""last-modified"", ""Thu, 31 May 2018 08:04:53 GMT"")
      .sentRequestAtMillis(1527839142145) //=Fri Jun 01 2018 07:45:42
      .receivedResponseAtMillis(1527839142295)  //=Fri Jun 01 2018 07:45:42 
      .request(request)
      .protocol(Protocol.HTTP_1_1)
      .handshake(handshake)
      .message("""")
      .build()

  val cacheStrategy = CacheStrategy.Factory(nowMillis, request, cacheCandidate)
      .get()
  assertThat(cacheStrategy.networkRequest).isNotNull()
}
```",Could you build the test case with the `OkHttpClient` and `MockWebServer`?? Here's an example: https://github.com/square/okhttp/blob/master/okhttp-tests/src/test/java/okhttp3/CacheTest.java#L1204,"Not sure this is the equivalent:

```kotlin
class Test {

  @JvmField
  @Rule
  val server = MockWebServer()

  private val cache = Cache(File("".""), Long.MAX_VALUE)
  private val client = OkHttpClient.Builder()
      .cache(cache)
      .build()

  @Test
  fun test() {
    server.enqueue(
        MockResponse()
            .setBody(""A"")
            .addHeader(""date"", formatDate(400, TimeUnit.MILLISECONDS))
            .addHeader(""cache-control"", ""private, must-revalidate"")
            .addHeader(""last-modified"", formatDate(-1, TimeUnit.DAYS))
    )
    server.enqueue(MockResponse().setBody(""B""))

    assertEquals(""A"", body(server.url(""/"")))
    Thread.sleep(1000)
    assertEquals(""B"", body(server.url(""/"")))
  }

  private fun body(url: HttpUrl): String? {
    val request = Request.Builder()
        .url(url)
        .build()
    return client.newCall(request)
        .execute()
        .body()
        ?.string()
  }

  private fun formatDate(millisDiff: Long, timeUnit: TimeUnit): String {
    val time = System.currentTimeMillis() + timeUnit.toMillis(millisDiff)
    val date = Date(time)
    return HttpDate.format(date)
  }
}
```

I think the problem here lies in the fact that the server time is slightly more in the future than the client time. 

Notice the 1000ms sleep time - we are after the `date` sent from the server."
square/okhttp,https://github.com/square/okhttp/issues/4030,"Main class close() method - **Close any persistent connections.**
```
  private void close() {
    client.connectionPool().evictAll(); // Close any persistent connections.
  }
```
ConnectionPool.evictAll() - **Close and remove all idle connections in the pool.**
```
  /**
   * Close and remove all idle connections in the pool.
   */
  public void evictAll() {
    List<RealConnection> evictedConnections = new ArrayList<>();
    synchronized (this) {
      for (Iterator<RealConnection> i = connections.iterator(); i.hasNext(); ) {
        RealConnection connection = i.next();
        if (connection.allocations.isEmpty()) {
          connection.noNewStreams = true;
          evictedConnections.add(connection);
          i.remove();
        }
      }
    }

    for (RealConnection connection : evictedConnections) {
      closeQuietly(connection.socket());
    }
  }
```
Condition `connection.allocations.isEmpty()` closes the connection only if there are no active streams in this connection

list of revisions:
1. **ConnectionPool** Rename evictAll() -> **closeIdle()**
2. Mark evictAll() method is Deprecated 
3. **ConnectionPool** Add method **closeAll()** - Close any persistent connections.
4. **Main** close() method call client.connectionPool().closeAll()
5. fix OkHttpClient javadoc
6. fix tests

Correct me if I'm wrong.",What’s the motivation? If you want to interrupt in-flight calls you can do that with `Call.cancel()`.,"@swankjesse If I call the close () method in the Main class, I expect that all connections will be closed, not just those that are inactive."
square/okhttp,https://github.com/square/okhttp/issues/4012,"OKHttp3 version 3.10. Android application
After a successful connection and a short period of inactivity, the OKHttp3 websocket throws a EOFException in response to a code 101, ""Switching Protocols"" response. This then disconnects the socket and our application is forced to re-connect again.
Is there anyway to control this so the socket does not close ? 
Is this expected behavior?
Our iOS and server side tests against the same server did not show this behaivor and remained connected until the applications disconnected them explicitely.

RealWebsocket class:

public void connect(OkHttpClient client) { ...

               try {
                    RealWebSocket.this.listener.onOpen(RealWebSocket.this, response);
                    String name = ""OkHttp WebSocket "" + request.url().redact();
                    RealWebSocket.this.initReaderAndWriter(name, streams);
                    streamAllocation.connection().socket().setSoTimeout(0);
                    RealWebSocket.this.loopReader();
                } catch (Exception var6) {
                    RealWebSocket.this.failWebSocket(var6, (Response)null);
                }
(Response return code 101)
",Could you provide an executable test case? Nothing actionable here.,"Issue Resolved:
Apologies, I should have specified that I am also using the wonderful STOMP client on top of the OKHttp3Client websockets:
https://github.com/NaikSoftware/StompProtocolAndroid by Nickolay Savchenko (Nickolay Savchenko
NaikSoftware). This library does an exceptional job of implementing the STOMP protocol integrated with OKHttp3 websockets. 
This is where I fell short by using the wrong StompClient.over method to provide my url, which will create a default websocket instance that has a default socket read timeout (30 seconds ?). The  solution for me was to use the alternative StompClient.over method, allowing for a reference to an application instance of the OKHttp3Client. This allows the application set it's desired timeouts beyond any defaults.

Thank you to all of you who did try to assist me."
square/okhttp,https://github.com/square/okhttp/issues/3921,"I want to put the date header (https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Date) on all my requests.

```java
static final ThreadLocal<DateFormat> DATE_HEADER_FORMAT =
      new ThreadLocal<DateFormat>() {
        @Override protected DateFormat initialValue() {
          DateFormat format = new SimpleDateFormat(""EEE, dd MMM yyyy HH:mm:ss 'GMT'"", Locale.US);
          format.setTimeZone(TimeZone.getTimeZone(""GMT""));
          return format;
        }
      };
...
requestBuilder.addHeader(""Date"", DATE_HEADER_FORMAT.get().format(new Date())
```

I'd like to remove this code in favor of perhaps `okhttp3.Headers.setDate(Date)`.

The downside is that it opens up discussion about other general headers that _could_ be added to the Headers API. Is this general-purpose enough?","Would it be worth a sweep through https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers?

Date is also pretty common in responses.",
square/okhttp,https://github.com/square/okhttp/issues/3898,"After updating from `3.9.1` to `3.10.0` `mockwebserver` tests got stuck.

This is how I configure the `HttpClient` (I'm setting up `HTTPS` and _Certificate Pinning_ ) 👀
```java
private OkHttpClient configureHttpClient() {
    CertificatePinnerFactory factory = new CertificatePinnerFactory();
    OkHttpClient.Builder builder = client.newBuilder()
      .addInterceptor(new GzipRequestInterceptor())
      .retryOnConnectionFailure(true)
      .certificatePinner(factory.provideCertificatePinnerFor(environment))
      .connectionSpecs(Arrays.asList(ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS));
    if (isSocketFactoryUnset(sslSocketFactory, x509TrustManager)) {
      builder.sslSocketFactory(sslSocketFactory, x509TrustManager);
    }

    return builder.build();
  }
```

`3.9.1` 👇
```
Feb 27, 2018 9:15:56 PM okhttp3.mockwebserver.MockWebServer$2 execute
INFO: MockWebServer[59072] starting to accept connections
Feb 27, 2018 9:15:57 PM okhttp3.mockwebserver.MockWebServer$3 processOneRequest
INFO: MockWebServer[59072] received request: POST /events/v2?access_token=anyAccessToken HTTP/1.1 and responded: HTTP/1.1 204 OK
```

`3.10.0` 👇
```
Feb 27, 2018 9:12:04 PM okhttp3.mockwebserver.MockWebServer$2 execute
INFO: MockWebServer[59055] starting to accept connections
Feb 27, 2018 9:12:06 PM okhttp3.mockwebserver.MockWebServer$3 processConnection
WARNING: MockWebServer[59055] connection from /127.0.0.1 didn't make a request
```

Following you can find a failing test 👀
```java
package com.mapbox.android.telemetry;


import android.content.Context;

import org.junit.Test;

import java.net.HttpURLConnection;
import java.util.Arrays;
import java.util.List;

import okhttp3.Callback;
import okhttp3.HttpUrl;
import okhttp3.mockwebserver.MockResponse;
import okhttp3.mockwebserver.MockWebServer;
import okhttp3.mockwebserver.RecordedRequest;
import okhttp3.internal.tls.SslClient;

import static org.junit.Assert.assertEquals;
import static org.mockito.Mockito.RETURNS_DEEP_STUBS;
import static org.mockito.Mockito.mock;

public class Foo {

  @Test
  public void foo() throws Exception {
    MockWebServer server = new MockWebServer();
    server.useHttps(SslClient.localhost().socketFactory, false);
    server.start();
    Context mockedContext = mock(Context.class, RETURNS_DEEP_STUBS);
    MapboxTelemetry.applicationContext = mockedContext;
    TelemetryClient telemetryClient = obtainATelemetryClient(""anyAccessToken"", ""anyUserAgent"", server);
    List<Event> mockedEvent = obtainAnEvent();
    MockResponse mockResponse = new MockResponse();
    mockResponse.setResponseCode(HttpURLConnection.HTTP_NO_CONTENT);
    mockResponse.setBody("""");
    server.enqueue(mockResponse);
    Callback mockedCallback = mock(Callback.class);

    telemetryClient.sendEvents(mockedEvent, mockedCallback);

    RecordedRequest request = server.takeRequest();
    assertEquals(""/events/v2?access_token=anyAccessToken"", request.getPath());
  }

  TelemetryClient obtainATelemetryClient(String accessToken, String userAgent, MockWebServer server) {
    TelemetryClientSettings mockedTelemetryClientSettings = provideDefaultTelemetryClientSettings(server);
    Logger mockedLogger = mock(Logger.class);
    return new TelemetryClient(accessToken, userAgent, mockedTelemetryClientSettings, mockedLogger);
  }

  private TelemetryClientSettings provideDefaultTelemetryClientSettings(MockWebServer server) {
    HttpUrl localUrl = obtainBaseEndpointUrl(server);
    SslClient sslClient = SslClient.localhost();

    return new TelemetryClientSettings.Builder()
      .baseUrl(localUrl)
      .sslSocketFactory(sslClient.socketFactory)
      .x509TrustManager(sslClient.trustManager)
      .build();
  }

  private List<Event> obtainAnEvent() {
    Event theEvent = new AppUserTurnstile(""anySdkIdentifier"", ""anySdkVersion"", false);

    return obtainEvents(theEvent);
  }

  private List<Event> obtainEvents(Event... theEvents) {
    return Arrays.asList(theEvents);
  }

  private HttpUrl obtainBaseEndpointUrl(MockWebServer server) {
    return server.url(""/"");
  }
}
```

☝️ is using https://github.com/mapbox/mapbox-events-android code.

You can check that we only bumped OkHttp version to `3.10.0` 👉 https://github.com/mapbox/mapbox-events-android/commit/c92a4acdf684cedc003c769f44a62c345ce596f9 and after that tests got stuck.

Tried many things without luck 😓
Any hints? What did it change that could affect tests in that sense? 

",Can you attach a debugger and check out where OkHttp gets stuck?,"Everything is working fine until https://github.com/square/okhttp/blob/9a6f88dc34cb68d341ec1a7e4c79546fa1c18c96/mockwebserver/src/main/java/okhttp3/mockwebserver/MockWebServer.java#L475 which calls [`readRequest(socket, source, sink, sequenceNumber)`](https://github.com/square/okhttp/blob/master/mockwebserver/src/main/java/okhttp3/mockwebserver/MockWebServer.java#L511) which also calls [`source.readUtf8LineStrict()`](https://github.com/square/okhttp/blob/master/mockwebserver/src/main/java/okhttp3/mockwebserver/MockWebServer.java#L588) which ends up calling `RealBufferedSource#readUtf8LineStrict` which finally throws a `java.io.EOFException` (`\n not found: limit=0 content=…`) because apparently the size of the `Buffer` is `0`.
Then the exception is bubble up to `readRequest` which returns `null` https://github.com/square/okhttp/blob/9a6f88dc34cb68d341ec1a7e4c79546fa1c18c96/mockwebserver/src/main/java/okhttp3/mockwebserver/MockWebServer.java#L590 and then `processOneRequest` returns `false` https://github.com/square/okhttp/blob/9a6f88dc34cb68d341ec1a7e4c79546fa1c18c96/mockwebserver/src/main/java/okhttp3/mockwebserver/MockWebServer.java#L512 which breaks the `processOneRequest` loop and logs the `WARNING: MockWebServer[59055] connection from /127.0.0.1 didn't make a request` message because `sequenceNumber` is `0`.
After that the test is still running (apparently waiting for new requests).

It seems that there's an issue when getting the buffer from the socket and in `3.10.0` we're not able to read that kind of requests anymore. I know that `3.10.0` brings Okio `1.14.0`. Could it be related? My guess is that the root of the issue is around https://github.com/square/okhttp/blob/0b74bba08805c28f6aede626cf06f213ef6480f2/mockwebserver/src/main/java/okhttp3/mockwebserver/MockWebServer.java#L472

Let me know if you need any further information."
square/okhttp,https://github.com/square/okhttp/issues/3872,"First of all sorry for not providing a failing test here, but I struggled to do that for this case.

I was just implementing an Authenticator when I found that when `Authenticator.authenticate()` throws an exception (it has a catched `IOException` in its signature, so that seems to be an expected case) the `RetryAndFollowUpInterceptor` will never release its `StreamAllocation` - as opposed to when returning `null` in `authenticate()`.

Here are the according lines in the `RetryAndFollowUpInterceptor`:

```java
Request followUp = followUpRequest(response, streamAllocation.route());

if (followUp == null) {
    if (!forWebSocket) {
      streamAllocation.release();
    }
    return response;
}
```

Shouldn't there be a try catch around the call to `followUpRequest()` to handle that case and and then re-throw the exception?",Can I work it ?,
square/okhttp,https://github.com/square/okhttp/issues/3827,"hello,
recording to this [issue](https://github.com/square/retrofit/issues/2630) it looks like OkHttp has a problem with status code `408`.
just want to put it here to be fixed.","Can you provide a sample of the response headers you are sending with the 408? Or a reproduction test case?

There is changed handling of 408 in 3.10, which has not yet been released. I don't think it fixes it however. https://github.com/square/okhttp/pull/3753 But even if that doesn't help you can see examples in that PR of how to make a reproduction test case.

Also relevant is a fix in August for 408 handling https://github.com/square/okhttp/pull/3500","@yschimke 
something like this

> General:
Request URL:http://exampledomain:port/api
Request Method:GET
Status Code:408 
Remote Address:exampledomain:port
Referrer Policy:no-referrer-when-downgrade
----------
> Response-Headers:
Access-Control-Allow-Credentials:true
Access-Control-Allow-Origin:http://example-server-ip:port
Access-Control-Expose-Headers:Set-Cookie
Content-Language:en
Content-Length:X
Content-Type:text/html;charset=utf-8
Date:Tue, 06 Feb 2018 23:12:09 GMT
Server:Apache TomEE
Vary:Origin

I'm not quite sure because we changed the status code but just status code and other things are remained so it should like the above (I copied the exact response from chrome, hope it's become useful)"
square/okhttp,https://github.com/square/okhttp/issues/3786,"Hi,
I am using okhttp to upload a file to a server (actually presigned URL of AWS S3).
My server (the one which uses okhttp and does the upload) is also hosted on AWS and is deployed within a docker.
I noticed that it takes about 8 seconds to upload a 30MB file, where if I just use a cURL command that does the same thing (also inside the docker) it takes 1.5 seconds.
After some digging I noticed that when okhttp is working the CPU is reaching 100%, where with cURL it is not really affected. I also tested using a much stronger ec2 instance (40vCPU), and still took 8 seconds and 100% CPU of the docker.
When I run my JAR outside of the docker it actually worked in appropriate time (2~ seconds), but I still noticed a significant CPU spike during the upload.
Eventually I changed to a different http library ([apache HttpClient](https://hc.apache.org/httpcomponents-client-4.5.x/httpclient/apidocs/index.html)) and it is working just like the cURL command (1.5 seonds and not CPU spikes)

### Code snippet of okhttp usage of uploading:
```java
RequestBody body = RequestBody.create(MediaType.parse(""multipart/form-data""), new File(filePath));
Request req = new Request.Builder()
                        .url(signedUrl)
                        .put(body)                        
                        .build();
client.newCall(req).execute();
```

### Code snippet of different http lib which is working well:
```java
File file = new File(filePath);
MultipartEntityBuilder builder = MultipartEntityBuilder.create();
builder.addBinaryBody(""file"", file, ContentType.MULTIPART_FORM_DATA, file.getName())
            .setMode(HttpMultipartMode.BROWSER_COMPATIBLE);
HttpPut put = new HttpPut(signedUrl);
put.setEntity(builder.build());
HttpClient client = HttpClientBuilder.create().build();
client.execute(put);
```

If you need more details I will gladly add whatever is needed","Can you sample a stacktrace of the service while it's being slow? I wonder if OkHttp is negotiating HTTP/2 which could explain dramatically different performance vs. other clients.

Tracing information is available either with a profiler, or just with calling jstack while OkHttp is spinning.","I am not familiar with jstack but will try to take a look at it next week. 
Forgot to mention that some of my digging I listened to the okhttp events and most of those 8 seconds are being while it is writing the http body. Also I can say that it is trying HTTP/1.1 and one of my tests was with this portocol only."
square/okhttp,https://github.com/square/okhttp/issues/3767,"I'm seeing a case in handling redirects where it _appears_ that okhttp isn't following a redirect. After digging through okhttp with the failing url, okhttp is functioning ""correctly"" - the redirect url is invalid. Therefore, okhttp doesn't follow the redirect, and returns a response with response code 302.

A test illustrating this:
```
Request request = new Request.Builder().url(originalUrl).build();
Response response = okhttp.newCall(request).execute();

log(response.code());
log(response.isSuccessful());
```
results in:
```
302
false
```

Example for `originalUrl`:
```
<originalUrl>, <host>, and <paths> have been used as substitutes for real urls, hosts, and paths

<-- 302 Found <originalUrl>
Date: Sun, 07 Jan 2018 17:04:43 GMT
Server: Apache/2.4.10 (Debian) PHP/5.6.24-0+deb8u1 OpenSSL/1.0.1t
X-Powered-By: PHP/5.6.24-0+deb8u1
Expires: Thu, 19 Nov 1981 08:52:00 GMT
Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0
Location: http://.<host>/<path>
Access-Control-Allow-Origin: *
Connection: close
Content-Type: text/html; charset=UTF-8
<-- END HTTP
```

And yes, `followRedirects` and `followSslRedirects` are enabled

What's going on here is that the 302 redirect location is an illegally formatted URL - in my case, something like `http://.<somehost>/<path>` (note the leading `.` to the hostname). OkHttp's `RetryAndFollowUpInterceptor` reads this Location, and tries to parse it with `HttpUrl`. That, correctly, fails. At this point, the retry interceptor just returns and allows the 302 to propagate up:
https://github.com/square/okhttp/blob/cd84d79c3574de81f23802f832f2ead6ad38a735/okhttp/src/main/java/okhttp3/internal/http/RetryAndFollowUpInterceptor.java#L307-L312

Now, any sane client should be able to detect that the end response is not successful and handle it gracefully. But through reading through app logs, there's no indication as to what the actual failure was. The failed url parsing on the redirect location is simply swallowed here deep in OkHttp, without any mechanism to inform the client that the error occurred.

Should a failed HttpUrl parse be bubbled up as an exception?
","What's the alternative? I definitely think delivering a 302 that can't be
followed it weird.

What do browsers do?

On Sun, Jan 7, 2018 at 10:21 PM Jesse Wilson <notifications@github.com>
wrote:

> I think this is asking a slightly different question – given a redirect
> that we can’t follow should the call throw?
>
> —
> You are receiving this because you commented.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/square/okhttp/issues/3767#issuecomment-355877879>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAEEEet-tq8i96LcuzCuFU9I4orLHodsks5tIYnDgaJpZM4RV1aO>
> .
>
","@swankjesse is right in that I think the first question is what is the expected behavior? I could see a reasonable argument going something along the lines of ""well, we already provide an API for `Response.isSuccessful()`, so the precedent already exists for a failure condition that isn't bubbled up through an exception"". Obviously the flip side of that argument is why are there different classifications of errors - those that throw and those that don't, and are those classifications clearly defined as to what type of error falls in each bucket? 

Then of course I see a few arguments for the throws, including my original confusion that spurred this, which is that I thought OkHttp was broken and that it wasn't following the redirect, because it gave me no indication at all that it tried, nor that it was the redirect that was the root cause of the overall call failure.

Of course to @JakeWharton's point, a throws on `parse` and `resolve` would seem to be one sane option to raising the exception, especially if that's already been a desire.

My one request though on any new exception is to avoid putting URLs into the exception message. URLs, especially for content, can be considered customer sensitive data that we won't log. For example, that's why we use [parse](https://github.com/square/okhttp/blob/cd84d79c3574de81f23802f832f2ead6ad38a735/okhttp/src/main/java/okhttp3/HttpUrl.java#L899) and not [Request.Builder.url(String)](https://github.com/square/okhttp/blob/cd84d79c3574de81f23802f832f2ead6ad38a735/okhttp/src/main/java/okhttp3/Request.java#L142-L144)"
square/okhttp,https://github.com/square/okhttp/issues/3759,"What kind of issue is this?

 - [x] Bug report. If you’ve found a bug, spend the time to write a failing test. Bugs with tests
       get fixed. Here’s an example: https://gist.github.com/swankjesse/981fcae102f513eb13ed

This issue can't be reproduced in a test. I'll do my best to explain.

```
>> GET http://myserver.mycompany.com/.../businesses.20180104.json.gz
<< 200 OK
<< connection -> [keep-alive]
<< accept-ranges -> [bytes]
<< content-disposition -> [attachment; filename=""businesses.20180104.json.gz""; filename*=UTF-8''businesses.20180104.json.gz] 
<< content-type -> [application/x-gzip]
<< content-length -> [3384998203]
<< date -> [Fri, 05 Jan 2018 00:43:32 GMT]
<< etag -> [0e49d5fa7ba9f68058bfbb4a98bef032c3a73871]
<< last-modified -> [Thu, 04 Jan 2018 23:54:26 GMT]
<< x-artifactory-id -> [9732f56568ea1e3d:59294f65:160b8066066:-8000]
<< x-checksum-md5 -> [451ca1b1414e7b511de874e61fd33eb2]
<< x-artifactory-filename -> [businesses.20180104.json.gz]
<< server -> [Artifactory/5.3.0]
<< x-checksum-sha1 -> [0e49d5fa7ba9f68058bfbb4a98bef032c3a73871]
```
As you can see, the server doesn't set a `Content-Encoding = gzip` header, so I do that in an interceptor.

Each record is newline delimited JSON string that is inserted into Couchbase. There are around 12 million records in total. Using okhttp, processing fails after about 130000 with the following exception:
```
Caused by: java.io.IOException: gzip finished without exhausting source
	at okio.GzipSource.read(GzipSource.java:100)
	at okio.RealBufferedSource$1.read(RealBufferedSource.java:430)
```

However, if I don't set the `Content-Encoding` header (thus skipping `GzipSource`), and wrap the input stream with `GZIPInputStream`, everything works as expected. I've also tried setting `Transfer-Encoding = chunked` on the response and removing the `Content-Length` header, but to no avail.

So, question is, if `GZIPInputStream` doesn't have a problem, why does `GzipSource`? And since it does, why won't it report what it thinks is the issue? I've a test that runs on a smaller file, 100 records, and it works.

I've seen https://github.com/square/okhttp/issues/3457, but unlike the reporter, it's not possible for me to capture the hex body of a 3.4 GB stream.
  
  
  ",Why not just handle this as you are doing via GZIPInputStream on the original response? ,"> just handle this as you are doing via GZIPInputStream

That's what I've been forced to do, but when something doesn't work, I like to understand why, not just write it off as bad luck 😃

> incorrectly sending the original content-length

The `Content-Length` returned is correct; I know that because I can download the file using curl or browser, and it is the said size on disk. Also, like you said, I've tried without `Content-Length` header as well.

> contains some trailing bytes (or server is incorrectly adding something)...left in the buffer

I've collected exactly that using Netty (I've been trying multiple clients to rule out a potential okhttp bug). I can post that, or if you tell me how to collect what's left in the buffer using okhttp, I will do that.


  "
square/okhttp,https://github.com/square/okhttp/issues/3749,"https://developer.android.com/training/articles/security-gms-provider.html

> Rather than using this class, we encourage app developers to use high-level methods for interacting with cryptography. Most apps can use APIs like HttpsURLConnection without needing to set a custom TrustManager or create an SSLCertificateSocketFactory.

n.b. I know OkHttp does the hostname verification they are actually talking about above, but I think the comment applies generally.

Question
1) why not use the best security available automatically if it is present
2) why require extra steps over other APIs like HttpsURLConnection that it's possible to forget
3) Why not warn via debug logging when older clients are not using the updated provider 
4) Can this cause differences in reported issues like ""this works in Volley""",Would that be worth it?,"I've used the API, but yeah the context could be tough to resolve nicely.  The other option would be to warn if this has not been installed.

I'd like to make sure we encourage the best security practices possible, and also minimise support load due to apps on phones with old versions of SSL providers.  Put this out there for discussion,  happy to consider all options and not rush anything."
square/okhttp,https://github.com/square/okhttp/issues/3719,"Hi there!

First at all thank you very much for your library!

I've integrated okhttp3 since couple months ago; there were no problem until yesterday with an user (Huawei, model MHA-L29, on Android 7.0):

```
Fatal Exception: java.lang.IllegalArgumentException: Unexpected TLS version: NONE
       at okhttp3.TlsVersion.forJavaName(TlsVersion.java:53)
       at okhttp3.Handshake.get(Handshake.java:56)
       at okhttp3.internal.connection.RealConnection.connectTls(RealConnection.java:300)
       at okhttp3.internal.connection.RealConnection.establishProtocol(RealConnection.java:268)
       at okhttp3.internal.connection.RealConnection.connect(RealConnection.java:160)
       at okhttp3.internal.connection.StreamAllocation.findConnection(StreamAllocation.java:256)
       at okhttp3.internal.connection.StreamAllocation.findHealthyConnection(StreamAllocation.java:134)
       at okhttp3.internal.connection.StreamAllocation.newStream(StreamAllocation.java:113)
       at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:42)
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
       at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
       at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
       at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:125)
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
       at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
       at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:200)
       at okhttp3.RealCall$AsyncCall.execute(RealCall.java:147)
       at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
       at java.lang.Thread.run(Thread.java:776)
```
Have you got some ideas about this crash?

Thank you very much guys!","Does your app change the SSL provider in any way? to GMS services e.g. include ProviderInstaller.installIfNeeded.  It could also just be the setup of that phone.

Is it a one-off or consistently reproducible?

I've seen a similar issue in rare timing cases either before or after a network issue, a non-standard SSL provider can return NONE as the string.  OkHttp might have to handle this more gracefully.

https://github.com/google/conscrypt/blob/c88f9f55a523f128f0e4dace76a34724bfa1e88c/common/src/main/java/org/conscrypt/SSLNullSession.java#L149-L151","Hi!

About your questions:

- ""Does your app change the SSL provider in any way? to GMS services e.g. include ProviderInstaller.installIfNeeded"" : no change
- ""Is it a one-off or consistently reproducible?"" : just only 1 crash until now

Is there a manner to catch this exception in my App to avoid a crash?"
square/okhttp,https://github.com/square/okhttp/issues/3706,"[Brotli](https://tools.ietf.org/html/rfc7932) content-encoding is supported by the major browsers, and it looks like there is pretty good support on the web server side too. 

It could be supported transparently like gzip is, so that when OkHttp receives a request with the header `Content-Encoding: br` OkHttp uses Brotli decompression transparently.

Brotli content-encoding has reduced our payload size by about 20% for the average response.","How small is a Brotli decoder? We get gzip for free from the Java APIs. I don't see much value in transparent, built-in Brotli unless it can be implemented in a few hundred lines or less so as to not bloat the library. Otherwise a standalone artifact that has a Brotli interceptor seems like a better approach.","Yeah, it would be more than a few hundred lines. a separate, optional artifact sounds like the right approach."
square/okhttp,https://github.com/square/okhttp/issues/3685,"what are your thoughts about having a strict mode that would detect common issues like multithreaded use of a Response.  Was thinking it could be useful to ask people to flip it on if they are getting issues with cancellation, or unexpected end of stream etc.  To that matter, what are the exact rules?  a response body must be consumed by any single thread, cancellation must be done by the same thread?",Maybe something like that?,This page is awesomely helpful https://github.com/square/okhttp/wiki/Concurrency
square/okhttp,https://github.com/square/okhttp/issues/3683,"We are adding QUIC (https://www.chromium.org/quic) support to the OKHttp by adding a QUIC interceptor. The QUIC interceptor can transmit request packets and response packets over QUIC between the OKHttp client and a QUIC proxy or a QUIC server. To integrate QUIC into existing okhttp codes, we plan to add QUIC(“quic”) to the Protocol enum in Protocol.java to be used in the QUIC interceptor. We can contribute back the QUIC interceptor to the OKHttp git if this addition can be approved. Can the committee approve this addition? Thanks.
",Who is “we” ?,
square/okhttp,https://github.com/square/okhttp/issues/3583,"There are a lot of thread lock, the following is jstack information. I do not know why this will happen, which leads to my memory and cpu are rising

""http-nio-8891-exec-152"" #571 daemon prio=5 os_prio=0 tid=0x00007f79047a2000 nid=0x5a2c waiting for monitor entry [0x00007f78e4380000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at okio.AsyncTimeout.scheduleTimeout(AsyncTimeout.java:75)
	- waiting to lock <0x0000000087b012a0> (a java.lang.Class for okio.AsyncTimeout)
	at okio.AsyncTimeout.enter(AsyncTimeout.java:69)
	at okio.AsyncTimeout$2.read(AsyncTimeout.java:209)
	at okio.RealBufferedSource.indexOf(RealBufferedSource.java:306)
	at okio.RealBufferedSource.indexOf(RealBufferedSource.java:300)
	at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:196)
	at com.squareup.okhttp.internal.http.Http1xStream.readResponse(Http1xStream.java:186)
	at com.squareup.okhttp.internal.http.Http1xStream.readResponseHeaders(Http1xStream.java:127)
	at com.squareup.okhttp.internal.http.HttpEngine.readNetworkResponse(HttpEngine.java:737)
	at com.squareup.okhttp.internal.http.HttpEngine.access$200(HttpEngine.java:87)
	at com.squareup.okhttp.internal.http.HttpEngine$NetworkInterceptorChain.proceed(HttpEngine.java:722)
	at com.squareup.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:576)
	at com.squareup.okhttp.Call.getResponse(Call.java:287)
	at com.squareup.okhttp.Call$ApplicationInterceptorChain.proceed(Call.java:243)
	at com.farmfriend.common.http.OkHttpRetryHandler.chainProceed(OkHttpRetryHandler.java:48)
	at com.farmfriend.common.http.OkHttpRetryHandler.retryHandler(OkHttpRetryHandler.java:31)
	at com.farmfriend.common.http.OkHttpRetryHandler.intercept(OkHttpRetryHandler.java:25)
	at com.squareup.okhttp.Call$ApplicationInterceptorChain.proceed(Call.java:232)
	at com.farmfriend.common.http.OkHttpAddHeaderHandler.addHeadersHandler(OkHttpAddHeaderHandler.java:41)
	at com.farmfriend.common.http.OkHttpAddHeaderHandler.intercept(OkHttpAddHeaderHandler.java:27)
	at com.squareup.okhttp.Call$ApplicationInterceptorChain.proceed(Call.java:232)
	at com.squareup.okhttp.Call.getResponseWithInterceptorChain(Call.java:205)
	at com.squareup.okhttp.Call.execute(Call.java:80)
	at com.farmfriend.common.http.OkHttpUtil.post(OkHttpUtil.java:90)
	at com.farmfriend.common.http.OkHttpUtil.ral(OkHttpUtil.java:110)
	at com.farmfriend.weather.util.MojiWeatherUtil.getWeatherInfoFromNet(MojiWeatherUtil.java:43)
	at com.farmfriend.weather.service.impl.GetMojiWeatherInfoServiceImpl.getMapToWeatherEntity(GetMojiWeatherInfoServiceImpl.java:459)
	at com.farmfriend.weather.service.impl.GetMojiWeatherInfoServiceImpl.getOrderInfoWeather(GetMojiWeatherInfoServiceImpl.java:171)
	at com.farmfriend.weather.controller.WeatherServerController.getOrderInfoWeather(WeatherServerController.java:75)
	at com.farmfriend.weather.controller.WeatherServerController$$FastClassBySpringCGLIB$$5b434648.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:52)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168)
	at org.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:47)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168)
	at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:52)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)
	at com.farmfriend.weather.controller.WeatherServerController$$EnhancerBySpringCGLIB$$1a7115a.getOrderInfoWeather(<generated>)
	at sun.reflect.GeneratedMethodAccessor524.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:648)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	- locked <0x00000000f20a5f90> (a org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:745)

my okhttp version 2.7.5",Can you provide a thread dump of the thread that currently holds that lock? Will say `0x00007f78e4380000` is held.,"ok!  following is whole dump file : 


[dump.zip](https://github.com/square/okhttp/files/1276495/dump.zip)
"
square/okhttp,https://github.com/square/okhttp/issues/3424,"I am using okhttp 3.8.0 and getting a lot crashes in crashlytics with this stacktrace 

<pre>
Fatal Exception: java.util.concurrent.RejectedExecutionException: Task d.bh@33f4a51 rejected from java.util.concurrent.ThreadPoolExecutor@63d82b6[Shutting down, pool size = 5, active threads = 5, queued tasks = 0, completed tasks = 22]
       at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2049)
       at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:814)
       at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1360)
       at okhttp3.Dispatcher.promoteCalls(Dispatcher.java:164)
       at okhttp3.Dispatcher.finished(Dispatcher.java:200)
       at okhttp3.Dispatcher.finished(Dispatcher.java:187)
       at okhttp3.RealCall$AsyncCall.execute(RealCall.java:151)
       at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
       at java.lang.Thread.run(Thread.java:762)
</pre>


What colud be the reason of this ?",Maybe we should handle this error and call `Callback.onFailure()` with a cancelation? That would be pretty reasonable.,
square/okhttp,https://github.com/square/okhttp/issues/3368,"When I open AndroidStudio3.0Preview in the New Android Profiler function when there is a failure,
Closed to resume.
Probably a preview version of the bug.


![05fd8a70-b368-429c-8a7c-ecccf754888c](https://cloud.githubusercontent.com/assets/9566116/26242243/49faa202-3cba-11e7-8c66-542df4935be9.png)

 - [ ] 05-19 17:20:53.777 15693-15693/com.about.zhiye W/System.err: java.lang.NullPointerException: Attempt to invoke virtual method 'java.lang.Class java.lang.Object.getClass()' on a null object reference
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at com.android.tools.profiler.support.network.OkHttpInterceptorHandler.wrapResponseBody(OkHttpInterceptorHandler.java:108)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at com.android.tools.profiler.support.network.OkHttpInterceptorHandler.wrapResponse(OkHttpInterceptorHandler.java:74)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at com.android.tools.profiler.support.network.OkHttpInterceptorHandler.invoke(OkHttpInterceptorHandler.java:39)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at java.lang.reflect.Proxy.invoke(Proxy.java:393)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at $Proxy0.intercept(Unknown Source)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:120)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at com.about.zhiye.api.ApiRetrofit$1.intercept(ApiRetrofit.java:94)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:92)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:67)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:185)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at okhttp3.RealCall.execute(RealCall.java:69)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at retrofit2.OkHttpCall.execute(OkHttpCall.java:174)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at retrofit2.adapter.rxjava.CallExecuteOnSubscribe.call(CallExecuteOnSubscribe.java:40)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at retrofit2.adapter.rxjava.CallExecuteOnSubscribe.call(CallExecuteOnSubscribe.java:24)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at retrofit2.adapter.rxjava.BodyOnSubscribe.call(BodyOnSubscribe.java:33)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at retrofit2.adapter.rxjava.BodyOnSubscribe.call(BodyOnSubscribe.java:25)
05-19 17:20:53.778 15693-15693/com.about.zhiye W/System.err:     at rx.Observable.unsafeSubscribe(Observable.java:10346)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:48)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:33)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.Observable.unsafeSubscribe(Observable.java:10346)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:48)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:33)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.Observable.unsafeSubscribe(Observable.java:10346)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.operators.OperatorSubscribeOn$SubscribeOnSubscriber.call(OperatorSubscribeOn.java:100)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.schedulers.CachedThreadScheduler$EventLoopWorker$1.call(CachedThreadScheduler.java:230)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at java.util.concurrent.FutureTask.run(FutureTask.java:237)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:269)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
05-19 17:20:53.779 15693-15693/com.about.zhiye W/System.err:     at java.lang.Thread.run(Thread.java:818)

",What makes you think this is an OkHttp but vs a tools bug?,
square/okhttp,https://github.com/square/okhttp/issues/3334,"There is such a crash reported from our app:

```
Caused by java.lang.InternalError: java.util.MissingResourceException: Can't find bundle for base name sun.util.logging.resources.logging, locale en_AU
       at java.util.logging.Logger$1.run(Logger.java:1385)
       at java.util.logging.Logger$1.run(Logger.java:1379)
       at java.security.AccessController.doPrivileged(AccessController.java:41)
       at java.util.logging.Logger.findSystemResourceBundle(Logger.java:1378)
       at java.util.logging.Logger.findResourceBundle(Logger.java:1425)
       at java.util.logging.Logger.setupResourceInfo(Logger.java:1523)
       at java.util.logging.Logger.(Logger.java)
       at java.util.logging.Logger.(Logger.java)
       at java.util.logging.LogManager$SystemLoggerContext.demandLogger(LogManager.java:734)
       at java.util.logging.LogManager.demandSystemLogger(LogManager.java:399)
       at java.util.logging.Logger.getPlatformLogger(Logger.java:474)
       at java.util.logging.LoggingProxyImpl.getLogger(LoggingProxyImpl.java:41)
       at sun.util.logging.LoggingSupport.getLogger(LoggingSupport.java:100)
       at sun.util.logging.PlatformLogger$JavaLoggerProxy.(PlatformLogger.java)
       at sun.util.logging.PlatformLogger$JavaLoggerProxy.(PlatformLogger.java)
       at sun.util.logging.PlatformLogger.(PlatformLogger.java)
       at sun.util.logging.PlatformLogger.getLogger(PlatformLogger.java:205)
       at java.net.CookieManager.put(CookieManager.java:262)
       at okhttp3.JavaNetCookieJar.saveFromResponse(SourceFile:47)
       at okhttp3.internal.http.HttpEngine.receiveHeaders(SourceFile:866)
       at okhttp3.internal.http.HttpEngine.readResponse(SourceFile:598)
       at okhttp3.RealCall.getResponse(SourceFile:241)
       at okhttp3.RealCall$ApplicationInterceptorChain.proceed(SourceFile:198)
       at okhttp3.RealCall.getResponseWithInterceptorChain(SourceFile:160)
       at okhttp3.RealCall.execute(SourceFile:57)
```
We are using okhttp v3.2.0.
And the configuration is looks like this:
```java
CookieHandler cookieHandler = new CookieManager(cookieStore, CookiePolicy.ACCEPT_ALL);
OkHttpClient.Builder okHttpBuilder = okHttpClient.newBuilder()
        .cache(cache)
        .cookieJar(new JavaNetCookieJar(cookieHandler))
        .connectTimeout(HTTP_TIMEOUT, TimeUnit.SECONDS)
        .readTimeout(HTTP_TIMEOUT, TimeUnit.SECONDS);
this.okHttpClient = okHttpBuilder.build();
```

This crash is not easy to reproduce.
I'm not sure if it's an OS bug, because it only happens on Android 7 according to our collected data.




","Can you execute the following on the offending device? My guess is that there’s a problem with the way the Java library on the device was packaged and an important localization resource was omitted.

```
import java.util.Enumeration;
import java.util.Locale;
import java.util.ResourceBundle;

public class MissingBundleCheck {
  public static void main(String[] args) {
    ResourceBundle bundle = ResourceBundle.getBundle(
        ""sun.util.logging.resources.logging"", new Locale(""en"", ""AU""),
        ClassLoader.getSystemClassLoader());
    for (Enumeration<String> k = bundle.getKeys(); k.hasMoreElements(); ) {
      String key = k.nextElement();
      System.out.println(key + "": "" + bundle.getString(key));
    }
  }
}
```

When I run it on my Android 7 device everything works properly.

```
ALL: ALL
FINE: FINE
INFO: INFO
OFF: OFF
SEVERE: SEVERE
CONFIG: CONFIG
FINEST: FINEST
FINER: FINER
WARNING: WARNING
```

Also: which device is this? Might be a bogus device.",@swankjesse The crash report is collected from users. So I can not reach the buggy device.
square/okhttp,https://github.com/square/okhttp/issues/3235,"OkHttp does not properly escape URL query parameters that contain curly braces.

Tomcat 7.0.73+, 8.0.39+, and 8.5.7+ will reject these requests with the following error:
```
Mar 20, 2017 2:47:59 PM org.apache.coyote.http11.Http11Processor service
INFO: Error parsing HTTP request header
 Note: further occurrences of HTTP header parsing errors will be logged at DEBUG level.
java.lang.IllegalArgumentException: Invalid character found in the request target. The valid characters are defined in RFC 7230 and RFC 3986
        at org.apache.coyote.http11.Http11InputBuffer.parseRequestLine(Http11InputBuffer.java:471)
        at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:667)
        at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
        at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)
        at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
        at java.lang.Thread.run(Thread.java:745)
```

These are the characters that Tomcat will now reject as part of the URI request line (see org.apache.tomcat.util.http.parser.HttpParser):
```
            if (IS_CONTROL[i] || i > 127 ||
                    i == ' ' || i == '\""' || i == '#' || i == '<' || i == '>' || i == '\\' ||
                    i == '^' || i == '`'  || i == '{' || i == '|' || i == '}') {
                IS_NOT_REQUEST_TARGET[i] = true;  // reject the character!
```

To solve issue, the characters included in HttpUrl.QUERY_COMPONENT_ENCODE_SET may need to be changed.  Here is current definition:
```
static final String QUERY_COMPONENT_ENCODE_SET = "" \""'<>#&="";
```

These 

","Can you ask the Tomcat authors to fix their server? Seems like they’re shutting out a lot of popular browsers with that check.

curl:
```
GET /?a={} HTTP/1.1
User-Agent: curl/7.51.0
```

Firefox:
```
GET /?a={} HTTP/1.1
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:52.0) Gecko/20100101 Firefox/52.0
```

Chrome:
```
GET /?a={} HTTP/1.1
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36
```

Safari:
```
GET /?a={} HTTP/1.1
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/602.4.8 (KHTML, like 
```

Wget does conform though, for what that’s worth.
```
GET /?a=%7B%7D HTTP/1.1
User-Agent: Wget/1.16.1 (darwin13.4.0)
```","I sympathize, believe me.  See the ticket referenced above for how I discovered the problem.

In attempting to craft a workaround, I've discovered that HttpClient (4.5.2) appears to be aligned with Tomcat in terms of what is valid URL:

```
    String original = ""http://mycompany.com:80/path/query.html?json={}"";

    // parse with OkHttp3 works
    String url = HttpUrl.parse(original).toString();
		
    // parse with HttpClient fails
    // Illegal character in query at index 45: http://mycompany.com:80/path/query.html?json={}
    String url2 = new URIBuilder(original).toString();
```

"
square/okhttp,https://github.com/square/okhttp/issues/3221,"It happened in version 3.1.2.
```
java.lang.NullPointerException: Attempt to invoke virtual method 'void java.util.Calendar.setLenient(boolean)' on a null object reference
	at java.text.DateFormat.setLenient(DateFormat.java:659)
	at okhttp3.internal.http.HttpDate$1.initialValue(HttpDate.java:42)
	at okhttp3.internal.http.HttpDate$1.initialValue(HttpDate.java:38)
	at java.lang.ThreadLocal$Values.getAfterMiss(ThreadLocal.java:430)
	at java.lang.ThreadLocal.get(ThreadLocal.java:65)
	at okhttp3.internal.http.HttpDate.format(HttpDate.java:114)
	at okhttp3.Cookie.toString(Cookie.java:542)
```

When i configured `cookieJar` overriding `loadForRequest` method  to print cookie using `item.toString()` , it happended.

My code:

```
        mOkHttpClient = new OkHttpClient.Builder()
                .connectTimeout(CONNECT_TIMIE_OUT, TimeUnit.SECONDS)
                .writeTimeout(WRITE_TIME_OUT, TimeUnit.SECONDS)
                .readTimeout(READ_TIME_OUT, TimeUnit.SECONDS)
                .cookieJar(new CookieJar() {
                    private final PersistentCookieStore cookieStore = new PersistentCookieStore(AppContext.getInstance());

                    @Override
                    public void saveFromResponse(HttpUrl url, List<Cookie> cookies) {
                        if (cookies != null && cookies.size() > 0) {
                            LogUtil.d(TAG, ""saveCookie:"");
                            for (Cookie item : cookies) {
                                cookieStore.add(url, item);
                                if (item != null) {
                                    LogUtil.d(TAG, ""cookie:"" + item.toString());
                                }
                            }
                        }
                    }

                    @Override
                    public List<Cookie> loadForRequest(HttpUrl url) {
                        LogUtil.d(TAG, ""loadCookie:"");
                        List<Cookie> cookies = cookieStore.get(url);
                        for (Cookie item : cookies) {
                            if (item != null) {
                                LogUtil.d(TAG, ""cookie:"" + item.toString());
                            }
                        }
                        return cookies;
                    }
                })
                .build();
```",Which JVM or device did this occur on? Can you reproduce it consistently?,"I can't reproduce it because it is a third-party platform statistics. 
The device is  HuaiWei P8ALE-TL00 running Android 6.0 ROM."
square/okhttp,https://github.com/square/okhttp/issues/3200,"I use OKhttp 3.5.0, often crashes.

![1](https://cloud.githubusercontent.com/assets/17741114/23495767/82bc5916-ff55-11e6-8816-3ae2e7351d73.jpeg)


The above is the error log！",Could you help us to reproduce with an executable test case?,"This is the third party statistics, I'm trying to reproduce"
square/okhttp,https://github.com/square/okhttp/issues/3116,"java.lang.InternalError: Thread starting during runtime shutdown
	at java.lang.Thread.nativeCreate(Native Method)
	at java.lang.Thread.start(Thread.java:1063)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:921)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1328)
	at okhttp3.internal.ws.RealWebSocket$1.onClose(SourceFile:82)
	at okhttp3.internal.ws.WebSocketReader.readControlFrame(SourceFile:205)
	at okhttp3.internal.ws.WebSocketReader.processNextFrame(SourceFile:106)
	at okhttp3.internal.ws.RealWebSocket.readMessage(SourceFile:97)
	at okhttp3.ws.WebSocketCall.createWebSocket(SourceFile:152)
	at okhttp3.ws.WebSocketCall.access$000(SourceFile:41)
	at okhttp3.ws.WebSocketCall$1.onResponse(SourceFile:97)
	at okhttp3.RealCall$AsyncCall.execute(SourceFile:126)
	at okhttp3.internal.NamedRunnable.run(SourceFile:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
	at java.lang.Thread.run(Thread.java:818)",Can you tear down OkHttp before shutting down your JVM?,"I saw this exception on my statistics platform.so,I don't know the user's operation.I thought the user maybe kills app when OkHttp initiates a network request?"
square/okhttp,https://github.com/square/okhttp/issues/2916,"We’re exploring building this. We could reuse the same request, response, and interceptor types.
","Can you please clarify naming?
2. Will `OkHttpServer` result in deletion of `MockWebServer` or it'll be used under the hood of `MockWebServer`?
","TBD.
"
square/okhttp,https://github.com/square/okhttp/issues/2851,"I have 2 Android apps which use Retrofit 2, with the latest version of okhttp. Last week, we enabled http/2 on our API, at the Akamai control panel. That same day, we started getting complaints that users could no longer do certain things in the apps,  and it quickly became apparent that it was only Android apps, and only DELETE calls 
","Can you give us more to go on? Perhaps use Charles to record what OkHttp did and how that differs from what it should do?
","Sorry, hit the submit button accidentally.  Finishing my thought :

Only DELETE calls are failing.  We tested turning  off H2 support, and all was well again, and turned it back on,  and is failing again. 

What can I do to help troubleshoot this issue? 
"
square/retrofit,https://github.com/square/retrofit/issues/2907,"What kind of issue is this?

 - [x] Question. This issue tracker is not the place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use Stack
       Overflow. https://stackoverflow.com/questions/tagged/retrofit

 - [ ] Bug report. If you’ve found a bug, spend the time to write a failing test. Bugs with tests
       get fixed. Here’s an example: https://gist.github.com/swankjesse/6608b4713ad80988cdc9

 - [ ] Feature Request. Start by telling us what problem you’re trying to solve. Often a solution
       already exists! Don’t send pull requests to implement new features without first getting our
       support. Sometimes we leave features out on purpose to keep the project small.

I am using Retrofit on Android.

I define a service `GitHubService`.

    public interface GithubService {
    
        @GET(""users/{user}"")
        Call<ResponseBody> fetchUserInfo(@Path(""user"") String user);
    
    }

Then I create service.

        Retrofit retrofit = new Retrofit.Builder()
                .baseUrl(""http://api.github.com"")
                .build();

        GithubService service = retrofit.create(GithubService.class);
        Call<ResponseBody> call = service.fetchUserInfo(""coxier"");
        call.enqueue(...);
As you see, I use above code to get user info of github. And above code works well for me. Now I want to know how Retofit works so I read source code.The code below is `Retrofit#create`. After reading, I still don't know its magic then I decide to debug Retroft.

    public <T> T create(final Class<T> service) {
      ...
      return (T) Proxy.newProxyInstance(...,
          new InvocationHandler() {
            ...
            @Override public Object invoke(..)
                throws Throwable {
       
              if (method.getDeclaringClass() == Object.class) {
                return method.invoke(this, args);
              }
              ...
              return loadServiceMethod(method).invoke(args != null ? args : emptyArgs);
            }
          });
    }

I debug at `if(method.getDeclaringClass() == Object.class)` line ,however it crashes. I don't know why it crashes. 
",What exception is thrown in the crash?,"> I don't know why debugging doesn't work but I can't see a way that Retrofit is somehow causing it. I'm able to put a breakpoint inside the invocation handler and have it work in my app.
> 
> What exception is thrown in the crash?

It's very strange. I did not find any crash log."
square/retrofit,https://github.com/square/retrofit/issues/2526,"I was trying to debug my retrofit call but it crashes every single time I enter the async callback, specifically the below line:
`mApiService.getReviews(mMovie.getId(), PrivateApiKey.YOUR_API_KEY).enqueue(new Callback<ReviewRootResponse>() {
    @Override
     public void onResponse(){}
    @Override
     public void onFailure(){}
     });
`
Running the app w/o debugger from Android Studio works fine. Crashes only in debug mode.
Logcat is as follows:
`10-16 18:37:23.158 6690-6697/com.example.android.designpattern A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x14 in tid 6697 (JDWP)`","What
action do you expect us to take for this? Also you haven't really provided
enough information to even discern the cause of the crash.

On Mon, Oct 16, 2017 at 10:47 PM k3rn3l16 <notifications@github.com> wrote:

> I was trying to debug my retrofit call but it crashes every single time I
> enter the async callback, specifically the below line:
> mApiService.getReviews(mMovie.getId(),
> PrivateApiKey.YOUR_API_KEY).enqueue(new Callback<ReviewRootResponse>() {
> @Override public void onResponse(){} @Override public void onFailure(){} });
> Running the app w/o debugger from Android Studio works fine. Crashes only
> in debug mode.
> Logcat is as follows:
> 10-16 18:37:23.158 6690-6697/com.example.android.designpattern A/libc:
> Fatal signal 11 (SIGSEGV), code 1, fault addr 0x14 in tid 6697 (JDWP)
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/square/retrofit/issues/2526>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAEEEULxDEHEZBArSbm_gEPsY5cBWtwJks5stBUlgaJpZM4P7gSQ>
> .
>
","Ok let me give you all the information I have.
Below is my setup.
**Client**
```
public class TmdbApiClient {
	private static Retrofit retrofit = null;

	public static Retrofit getClient() {
		// Check if already initialized
		if (retrofit == null) {
			retrofit = new Retrofit.Builder()
					.baseUrl(TmdbApiService.BASE_URL)
					.addConverterFactory(GsonConverterFactory.create())
					.build();
		}

		// Return retrofit object
		return retrofit;
	}
```
**Endpoint**
```
public interface TmdbApiService {

	String BASE_URL = ""https://api.themoviedb.org/3/"";

	@GET(""movie/{id}/reviews"")
	Call<ReviewRootResponse> getReviews(
			@Path(""id"") int movieId,
			@Query(""api_key"") String apiKey
	);
}
```
**Method**
```
private void loadReviews(Movie movie) {
		TmdbApiService mApiService = TmdbApiClient.getClient().create(TmdbApiService.class);
		mApiService.getReviews(movie.getId(), PrivateApiKey.YOUR_API_KEY).enqueue(new Callback<ReviewRootResponse>() {
			@Override
			public void onResponse(Call<ReviewRootResponse> call, Response<ReviewRootResponse> response) {
				String url = call.request().url().toString();
				Log.d(LOG_TAG, ""URL: "" + url);
				if (response.isSuccessful()) {
					if (response != null) {
						mReviewAdapter.setReviews(response.body().getReviews());
					}
				}
			}

			@Override
			public void onFailure(Call<ReviewRootResponse> call, Throwable t) {
				Log.d(LOG_TAG, t.toString());
			}
		});
	}
```
**Call**
```
        @Override
	public View onCreateView(LayoutInflater inflater, ViewGroup container,
	                         Bundle savedInstanceState) {
		// Inflate the layout for this fragment
		View detailMovieView = inflater.inflate(R.layout.fragment_movie_detail, container, false);
		ButterKnife.bind(this, detailMovieView);

		// Get passed-in movie object
		mIntent = getActivity().getIntent();
		Movie movie = mIntent.getParcelableExtra(""Movie"");
                
		loadReviews(movie);

		// Return view
		return detailMovieView;
	}
```
In debug mode, when I step into the below line my app crashes and the logcat is already attached to this issue.
`mApiService.getReviews(movie.getId(), PrivateApiKey.YOUR_API_KEY).enqueue(new Callback<ReviewRootResponse>() {`

I hope I have given you all the information. Please let me know If the issue is purely IDE related, I'll talk to the appropriate team."
square/retrofit,https://github.com/square/retrofit/issues/2294,"
package in.jsroyal.apiconsume.api;
import android.widget.Toast;

import in.jsroyal.apiconsume.model.ItemResponse;
import retrofit2.Call;
import retrofit2.http.GET;
import retrofit2.http.Query;


public interface Service {
    @GET(""/search/users"")
    Call<ItemResponse> getItems(
            @Query(""location"") String location,
            @Query(""language"") String language
    );
}

getting null value?
but https://api.github.com/search/users?q=india
It will give you json response.",Can you make a minimal sample or a test case?,"Nope.
When I give this direct URL then it works.

public interface Service {
    @GET(""/search/users?q=location:india+language:java"")
    Call<ItemResponse> getItems(
//            @Query(""location"") String location,
//            @Query(""language"") String language
    );
}
But above case it's not.
Why???"
square/javapoet,https://github.com/square/javapoet/issues/619,"I don not kown whether this because of javapoet,but when I use javapoet to produce my java code,this problem appeared,details as follows:
```
Execution failed for task ':app:compileDebugJavaWithJavac'.
> java.lang.ClassCastException: com.sun.tools.javac.code.Symbol$MethodSymbol cannot be cast to javax.lang.model.element.TypeElement

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

* Get more help at https://help.gradle.org

BUILD FAILED in 16s
```
if this is not because of javapoet,can you tell me what is wrong, sorry for my recklessness.",Can you “run with --stacktrace option to get the stack trace”?,"this is the result:
```
* Exception is:
org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':app:compileDebugJavaWithJavac'.
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:100)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:70)
	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:63)
	at org.gradle.api.internal.tasks.execution.ResolveTaskOutputCachingStateExecuter.execute(ResolveTaskOutputCachingStateExecuter.java:54)
	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)
	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88)
	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:52)
	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)
	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54)
	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)
	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34)
	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.run(DefaultTaskGraphExecuter.java:248)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:197)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:107)
	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:241)
	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:230)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.processTask(DefaultTaskPlanExecutor.java:124)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.access$200(DefaultTaskPlanExecutor.java:80)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:105)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:99)
	at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.execute(DefaultTaskExecutionPlan.java:625)
	at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.executeWithTask(DefaultTaskExecutionPlan.java:580)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.run(DefaultTaskPlanExecutor.java:99)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)
Caused by: java.lang.RuntimeException: java.lang.ClassCastException: com.sun.tools.javac.code.Symbol$MethodSymbol cannot be cast to javax.lang.model.element.TypeElement
	at com.sun.tools.javac.main.Main.compile(Main.java:553)
	at com.sun.tools.javac.api.JavacTaskImpl.doCall(JavacTaskImpl.java:129)
	at com.sun.tools.javac.api.JavacTaskImpl.call(JavacTaskImpl.java:138)
	at org.gradle.api.internal.tasks.compile.JdkJavaCompiler.execute(JdkJavaCompiler.java:49)
	at org.gradle.api.internal.tasks.compile.JdkJavaCompiler.execute(JdkJavaCompiler.java:36)
	at org.gradle.api.internal.tasks.compile.NormalizingJavaCompiler.delegateAndHandleErrors(NormalizingJavaCompiler.java:99)
	at org.gradle.api.internal.tasks.compile.NormalizingJavaCompiler.execute(NormalizingJavaCompiler.java:52)
	at org.gradle.api.internal.tasks.compile.NormalizingJavaCompiler.execute(NormalizingJavaCompiler.java:37)
	at org.gradle.api.internal.tasks.compile.CleaningJavaCompilerSupport.execute(CleaningJavaCompilerSupport.java:35)
	at org.gradle.api.internal.tasks.compile.CleaningJavaCompilerSupport.execute(CleaningJavaCompilerSupport.java:25)
	at org.gradle.api.internal.tasks.compile.incremental.IncrementalCompilationFinalizer.execute(IncrementalCompilationFinalizer.java:39)
	at org.gradle.api.internal.tasks.compile.incremental.IncrementalCompilationFinalizer.execute(IncrementalCompilationFinalizer.java:24)
	at org.gradle.api.tasks.compile.JavaCompile.performCompilation(JavaCompile.java:198)
	at org.gradle.api.tasks.compile.JavaCompile.compile(JavaCompile.java:129)
	at com.android.build.gradle.tasks.factory.AndroidJavaCompile.compile(AndroidJavaCompile.java:95)
	at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73)
	at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$IncrementalTaskAction.doExecute(DefaultTaskClassInfoStore.java:173)
	at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:134)
	at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:121)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$1.run(ExecuteActionsTaskExecuter.java:122)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:197)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:107)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:111)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:92)
	... 27 more
Caused by: java.lang.ClassCastException: com.sun.tools.javac.code.Symbol$MethodSymbol cannot be cast to javax.lang.model.element.TypeElement
	at site.gemus.processors.RxEventBusProcessor.process(RxEventBusProcessor.java:48)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.callProcessor(JavacProcessingEnvironment.java:794)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.discoverAndRunProcs(JavacProcessingEnvironment.java:705)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.access$1800(JavacProcessingEnvironment.java:91)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment$Round.run(JavacProcessingEnvironment.java:1035)
	at com.sun.tools.javac.processing.JavacProcessingEnvironment.doProcessing(JavacProcessingEnvironment.java:1176)
	at com.sun.tools.javac.main.JavaCompiler.processAnnotations(JavaCompiler.java:1170)
	at com.sun.tools.javac.main.JavaCompiler.compile(JavaCompiler.java:856)
	at com.sun.tools.javac.main.Main.compile(Main.java:523)
	... 52 more

```"
square/leakcanary,https://github.com/square/leakcanary/issues/1712,"### Description

Not working in my project, for resource not found in dex?

### Steps to Reproduce


1. open some actitivity
2.  dump the heap
3. crash

### Version Information

* LeakCanary version: 2.0, 2.1
* Android OS version: Android 10
* Gradle version: gradle-5.6.2,  android build plugin 3.4.2


### leakcannery log 
D/LeakCanary: Already scheduled retained check, ignoring (found new object retained)
D/LeakCanary: Already scheduled retained check, ignoring (found new object retained)
D/LeakCanary: Checking retained object because app became invisible
D/LeakCanary: Found 5 retained references, dumping the heap
D/LeakCanary: Analysis in progress, working on: PARSING_HEAP_DUMP
D/LeakCanary: Analysis in progress, working on: EXTRACTING_METADATA
D/LeakCanary: Analysis in progress, working on: FINDING_RETAINED_OBJECTS
D/LeakCanary: Analysis in progress, working on: FINDING_PATHS_TO_RETAINED_OBJECTS


it seems to be work but do not have  R field in dex?","Can you check against other android versions? I don't see how this could be Android 10 only. Based on the limited information I have, it looks like a build issue on your end, e.g. building with the AAR didn't properly include all resources.",
square/leakcanary,https://github.com/square/leakcanary/issues/1670,"### Description

Leak canary appears to crash intermittently if automation tests are run with dumpHeap forced on

### Steps to Reproduce

Not sure, it takes a number of unrelated instrumentation tests running for it to occur. Looking at the trace, might be related to how fast a test can close and reopen the app?

**Expected behavior:**
Don't crash

### Version Information

* LeakCanary version: 2.0-b5
* Android OS version: 28
* Gradle version: 5.6.2

### Additional information
<!-- language: none -->
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: FATAL EXCEPTION: IntentService[HeapAnalyzerService]
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: java.lang.IllegalStateException: Hprof file missing due to: [Older than all other hprof files] /storage/emulated/0/Download/leakcanary-mypackagename/2019-12-04_08-55-13_155.hprof
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: 	at leakcanary.internal.HeapAnalyzerService.onHandleIntentInForeground(HeapAnalyzerService.kt:50)
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: 	at leakcanary.internal.ForegroundService.onHandleIntent(ForegroundService.kt:55)
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: 	at android.app.IntentService$ServiceHandler.handleMessage(IntentService.java:76)
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: 	at android.os.Handler.dispatchMessage(Handler.java:106)
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: 	at android.os.Looper.loop(Looper.java:214)
	12-04 08:59:30.651  8365 11564 E AndroidRuntime: 	at android.os.HandlerThread.run(HandlerThread.java:65)

Not sure how to attach hprof files with a 10mb limit (they're huge even compressed), but I suspect it's not that useful anyhow.

![Leaks_SamsungS9_1](https://user-images.githubusercontent.com/41120437/70750841-10e84480-1ce4-11ea-8210-8b61fbfe0097.png)



",Do we want to keep more heap dumps than the limit? Do we want to drop the oldest analyzing requests? The newests?,"> - Do you set LeakCanary.Config.maxStoredHeapDumps to a value different than the default?

Nope

> - `automation tests are run with dumpHeap forced on` why do that? Have you seen this? https://square.github.io/leakcanary/recipes/#running-leakcanary-in-instrumentation-tests

It was an accident. In another conversation I mentioned junit on my classpath. Initially I overrode that check, then I ended up reimplementing that check with a different test class as the marker. Longterm I suppose I can use `leak_canary_test_class_name`, whenever that gets released.

So long story short, this isn't really an issue for me."
square/leakcanary,https://github.com/square/leakcanary/issues/1634,"### Description

LeakCanary beta 3 correctly sees [BiometricPrompt](https://developer.android.com/reference/android/hardware/biometrics/BiometricPrompt.html) holding on to the `mAuthenticationCallback` field. Logcat snippets showing both versions processing the leaking event are [here](https://gist.github.com/msfjarvis/c955835b7074722c8d61f8d553c01319).

### Steps to Reproduce

Sample project: https://github.com/msfjarvis/leakcanary-test-project

1. Checkout the sample project to [`d3f9bbfedf78fc3bdb2ecc889e7bfc4637835fa3`](https://github.com/msfjarvis/leakcanary-test-project/commit/d3f9bbfedf78fc3bdb2ecc889e7bfc4637835fa3), so you can be on LeakCanary beta 3. 
2. Install and launch the app, authenticate with fingerprint, and then use home to go back. LeakCanary will automatically analyze and find the leak.
3. Now switch to `master` and repeat step 2, LeakCanary will dump heap and analyze it again, but will fail to find any leaks.

**Expected behavior:** LeakCanary beta 4 should also see the leak

### Version Information

* LeakCanary version: 2.0-beta-4
* Android OS version: 10
* Gradle version: 6.0.1

### Additional Information

This exact leak also [seems to exist](https://stackoverflow.com/questions/53481621/memory-leak-but-how-can-i-pass-a-different-context-than-the-one-of-the-activity/53825372#53825372) in [FingerprintManager](https://developer.android.com/reference/android/hardware/fingerprint/FingerprintManager.html) as well and was never fixed. I haven't found any fixes or workarounds yet so an update to framework leaks might be in order.",Can you share the hprof file from the leak found in Beta 3? That way I can repro automatically & git bissect.,"> @msfjarvis Thanks for the detailed report! Can you share the hprof file from the leak found in Beta 3? That way I can repro automatically & git bissect.

Absolutely, there you go. [2019-11-25_21-47-40_879.hprof](https://transfer.sh/qe4wb/2019-11-25_21-47-40_879.hprof)"
square/leakcanary,https://github.com/square/leakcanary/issues/1624,"### Description

java.lang.NoSuchMethodError: No interface method getBuffer()Lokio/Buffer

![viber_image_2019-11-18_13-30-09](https://user-images.githubusercontent.com/13106194/69051771-f933de00-0a0d-11ea-914b-f28f4584f3cf.jpg)

### Version Information

* LeakCanary version: 2.0-beta-3
* Android OS version: all
* Gradle version: 4.10.2

### Additional Information

```
java.lang.NoSuchMethodError: No interface method getBuffer()Lokio/Buffer; in class Lokio/BufferedSource; or its super classes (declaration of 'okio.BufferedSource' appears in /data/app/com.viber.voip-6ojoFjZTeEeqwsTlqLMPvA==/base.apk!classes5.dex)
at shark.Hprof.moveReaderTo(Hprof.kt:43)
at shark.internal.HprofInMemoryIndex$Companion.createReadingHprof(HprofInMemoryIndex.kt:404)
at shark.internal.HprofInMemoryIndex$Companion.createReadingHprof$default(HprofInMemoryIndex.kt:346)
at shark.HprofHeapGraph$Companion.indexHprof(HprofHeapGraph.kt:187)
at shark.HeapAnalyzer.analyze(HeapAnalyzer.kt:100)
at leakcanary.internal.HeapAnalyzerService.onHandleIntentInForeground(HeapAnalyzerService.kt:61) 
at leakcanary.internal.ForegroundService.onHandleIntent(ForegroundService.kt:55)
at android.app.IntentService$ServiceHandler.handleMessage(IntentService.java:78)
at android.os.Handler.dispatchMessage(Handler.java:107) at android.os.Looper.loop(Looper.java:214)
at android.os.HandlerThread.run(HandlerThread.java:67)
```
",Can you please provide the Okio version? If not I will close the issue until we can repro.,
square/leakcanary,https://github.com/square/leakcanary/issues/1607,"### Description

My App runs well before 'debugImplementation 'com.squareup.leakcanary:leakcanary-android:2.0-beta-3', but it crash after that.
The application using kotlin and androidx, enable multiple-dex.

```
    --------- beginning of crash
10723-10859/com.wizarpos.nigeriapay E/AndroidRuntime: FATAL EXCEPTION: IntentService[HeapAnalyzerService]
    kotlin.TypeCastException: null cannot be cast to non-null type java.io.File
        at leakcanary.internal.HeapAnalyzerService.onHandleIntentInForeground(HeapAnalyzerService.kt:46)
        at leakcanary.internal.ForegroundService.onHandleIntent(ForegroundService.kt:55)
        at android.app.IntentService$ServiceHandler.handleMessage(IntentService.java:66)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:148)
        at android.os.HandlerThread.run(HandlerThread.java:61)
```
","Can you please try running it with a previous version like this: `debugImplementation 'com.squareup.leakcanary:leakcanary-android:2.0-beta-2'`

Also, what device / OS version are you running?","> Thanks for reporting this issue, we will take a look.
> Can you please try running it with a previous version like this: `debugImplementation 'com.squareup.leakcanary:leakcanary-android:2.0-beta-2'`
> 
> Also, what device / OS version are you running?

Android 6.0.1, beta-2 still crash, now it works by using 1.6.3  .."
square/leakcanary,https://github.com/square/leakcanary/issues/1597,"Error message：

```
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.xincaidong.truemerger, PID: 29219
    java.lang.RuntimeException: Unable to get provider leakcanary.internal.LeakCanaryFileProvider: java.lang.ClassNotFoundException: Didn't find class ""leakcanary.internal.LeakCanaryFileProvider"" on path: DexPathList[[zip file ""/data/app/com.xincaidong.truemerger-dH6uDnSLWeCztjnKidrcTA==/base.apk""],nativeLibraryDirectories=[/data/app/com.xincaidong.truemerger-dH6uDnSLWeCztjnKidrcTA==/lib/arm64, /data/app/com.xincaidong.truemerger-dH6uDnSLWeCztjnKidrcTA==/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]
        at android.app.ActivityThread.installProvider(ActivityThread.java:6542)
        at android.app.ActivityThread.installContentProviders(ActivityThread.java:6030)
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5936)
        at android.app.ActivityThread.access$1200(ActivityThread.java:200)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1673)
        at android.os.Handler.dispatchMessage(Handler.java:106)
        at android.os.Looper.loop(Looper.java:201)
        at android.app.ActivityThread.main(ActivityThread.java:6815)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:547)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:873)
     Caused by: java.lang.ClassNotFoundException: Didn't find class ""leakcanary.internal.LeakCanaryFileProvider"" on path: DexPathList[[zip file ""/data/app/com.xincaidong.truemerger-dH6uDnSLWeCztjnKidrcTA==/base.apk""],nativeLibraryDirectories=[/data/app/com.xincaidong.truemerger-dH6uDnSLWeCztjnKidrcTA==/lib/arm64, /data/app/com.xincaidong.truemerger-dH6uDnSLWeCztjnKidrcTA==/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]
        at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:171)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:379)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:312)
        at android.app.AppComponentFactory.instantiateProvider(AppComponentFactory.java:121)
        at androidx.core.app.CoreComponentFactory.instantiateProvider(CoreComponentFactory.java:60)
        at android.app.ActivityThread.installProvider(ActivityThread.java:6526)
        at android.app.ActivityThread.installContentProviders(ActivityThread.java:6030) 
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5936) 
        at android.app.ActivityThread.access$1200(ActivityThread.java:200) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1673) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:201) 
        at android.app.ActivityThread.main(ActivityThread.java:6815) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:547) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:873) 
```

Dependency：
```
debugImplementation 'com.squareup.leakcanary:leakcanary-android:2.0-beta-3'
```

不集成的时候，都是可以运行的，一集成之后就跑不了。项目是使用了AndroidX的，语言是java

Edit with translation from Google translate:

> When it is not integrated, it can be run, and it cannot run after integration. The project uses AndroidX and the language is java",Does the issue remain if you try using **2.0-beta-2** version of the lib?,"yes,I still have problems with this version 2.0-beta-2. I guess if I used Alibaba's hotfix.I have 2 Applications.This is my wrong log.SophixStubApplication is the application of hotfix.There is also a my own application.
```
java.lang.RuntimeException: Unable to create application com.xincaidong.truemerger.base.SophixStubApplication: java.lang.RuntimeException: abandon initialization: installProviders
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5959)
        at android.app.ActivityThread.access$1200(ActivityThread.java:200)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1673)
        at android.os.Handler.dispatchMessage(Handler.java:106)
        at android.os.Looper.loop(Looper.java:201)
        at android.app.ActivityThread.main(ActivityThread.java:6815)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:547)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:873)
     Caused by: java.lang.RuntimeException: abandon initialization: installProviders
        at com.taobao.sophix.a.c.a(Sophix:739)
        at com.taobao.sophix.a.c.p(Sophix:671)
        at com.taobao.sophix.a.c.b(Sophix:683)
        at com.taobao.sophix.a.e.a(Sophix:203)
        at com.taobao.sophix.SophixApplication.onCreate(Sophix:16)
        at android.app.Instrumentation.callApplicationOnCreate(Instrumentation.java:1155)
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5954)
        at android.app.ActivityThread.access$1200(ActivityThread.java:200) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1673) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:201) 
        at android.app.ActivityThread.main(ActivityThread.java:6815) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:547) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:873) 
     Caused by: java.lang.reflect.InvocationTargetException
        at java.lang.reflect.Method.invoke(Native Method)
        at com.taobao.sophix.a.c.p(Sophix:668)
        at com.taobao.sophix.a.c.b(Sophix:683) 
        at com.taobao.sophix.a.e.a(Sophix:203) 
        at com.taobao.sophix.SophixApplication.onCreate(Sophix:16) 
        at android.app.Instrumentation.callApplicationOnCreate(Instrumentation.java:1155) 
        at android.app.ActivityThread.handleBindApplication(ActivityThread.java:5954) 
        at android.app.ActivityThread.access$1200(ActivityThread.java:200) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1673) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:201) 
        at android.app.ActivityThread.main(ActivityThread.java:6815) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:547) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:873) 
     Caused by: java.lang.RuntimeException: Unable to get provider leakcanary.internal.LeakCanaryFileProvider: java.lang.ClassNotFoundException: Didn't find class ""leakcanary.internal.LeakCanaryFileProvider"" on path: DexPathList[[zip file ""/data/app/com.xincaidong.truemerger-ji2WskANWPbI6eXML9bS5g==/base.apk""],nativeLibraryDirectories=[/data/app/com.xincaidong.truemerger-ji2WskANWPbI6eXML9bS5g==/lib/arm64, /data/app/com.xincaidong.truemerger-ji2WskANWPbI6eXML9bS5g==/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]
```"
square/leakcanary,https://github.com/square/leakcanary/issues/1592,"### Description

We are seeing instrumentation tests failing due to the following stack trace:
```
:
    at shark.Hprof$Companion.open(Hprof.kt:70)
    at shark.HeapAnalyzer.analyze(HeapAnalyzer.kt:98)
    at leakcanary.InstrumentationLeakDetector.detectLeaks(InstrumentationLeakDetector.kt:169)
    at leakcanary.FailTestOnLeakRunListener.detectLeaks(FailTestOnLeakRunListener.kt:105)
    at leakcanary.FailTestOnLeakRunListener.testFinished(FailTestOnLeakRunListener.kt:87)
    at org.junit.runner.notification.SynchronizedRunListener.testFinished(SynchronizedRunListener.java:56)
    at org.junit.runner.notification.RunNotifier$7.notifyListener(RunNotifier.java:190)
    at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)
    at org.junit.runner.notification.RunNotifier.fireTestFinished(RunNotifier.java:187)
    at org.junit.internal.runners.model.EachTestNotifier.fireTestFinished(EachTestNotifier.java:38)
    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:331)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
    at androidx.test.runner.AndroidJUnit4.run(AndroidJUnit4.java:104)
    at org.junit.runners.Suite.runChild(Suite.java:128)
    at org.junit.runners.Suite.runChild(Suite.java:27)
    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
    at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
    at androidx.test.internal.runner.TestExecutor.execute(TestExecutor.java:56)
    at androidx.test.runner.AndroidJUnitRunner.onStart(AndroidJUnitRunner.java:392)
    at com.XXX.test.instrumentation.runner.XXXAndroidJUnitRunner.onStart(XXXAndroidJUnitRunner.java:54)
    at android.app.Instrumentation$InstrumentationThread.run(Instrumentation.java:2022)
Caused by: :
Caused by: java.lang.IllegalArgumentException: Hprof file is 0 byte length
```
Leakcanary is enabled on Instrumentation tests with the appraoch suggested in:
https://github.com/square/leakcanary/blob/133a8f1febf4156ab139c9b4a436f669e501b077/docs/api/leakcanary-android-instrumentation/leakcanary/-instrumentation-leak-detector/-init-.md#add-an-instrumentation-test-listener

The issue happens ONLY on Moto G4 - athene with Android 7.
It appears that in slow devices, there might be a race condition between when heap is dumped and when heap is parsed.

**Update**: We ran the tests on several devices running Android 7, however we noticed the issue only on Moto G4 - athene.
### Steps to Reproduce

[Provide a sample project, a .hprof file or a failing test]

1. [First Step]
2. [Second Step]
3. [and so on...]

**Expected behavior:** [What you expect to happen]

### Version Information

* LeakCanary version: `2.0-beta-3`
* Android OS version: 7
* Gradle version:

### Additional Information

Any additional information, configuration or data that might be necessary to reproduce the issue.
",Can you tell by looking at the timestamp of when the heap dump file was last modified (vs timestamp of when dumping heap) ?,"> timestamp of when the heap dump file was last modified

Looks like it's not logged in logs anywhere. Our devices are remote so it's difficult to grab file info.
I'll try to reproduce it locally."
square/leakcanary,https://github.com/square/leakcanary/issues/1558,"### Description

Updating to beta 3 from beta 2 I noticed that heap analysis became much slower (I'm assuming because of changes in https://github.com/square/leakcanary/pull/1543)

We mainly use LeakCanary in instrumentation tests on CI via Firebase test lab, and with beta 3 a heap analysis takes 14 minutes. This is really problematic because Firebase test matrices time out at 30 minutes, so if multiple tests have the same leak then the test matrix can't complete.

Leak canary v1, as well as v2-beta1, also had similarly slow performance that made it infeasible for us to use in instrumentation tests. Thankfully, beta 2 brought the analysis time down to about 5 minutes so we could actually use it.

I'm following the standard instructions for using leak canary with instrumentation tests. We also run our Firebase tests on a Pixel 3 physical device, which is the fastest one available. Running analysis locally on an emulator is a bit faster, but still around 10 minutes.

### Steps to Reproduce

hprof file at:
https://drive.google.com/file/d/1xJYE7YogS1Ae2sHyjbk5ZXlu6U0mjGBN/view?usp=sharing

1. Run heap analysis on hprof file with LeakCanary v2.0-beta-3
2. Takes ~14 minutes to complete on Pixel 3 Firebase device
3. Heap analysis with beta 2 seemed to be about half as long.

**Expected behavior:** [What you expect to happen]
For a ~70MB heap dump I'm not sure what the expected analysis time is, but this big of a regression across versions forces us to stay on beta 2 for now.

### Version Information

* LeakCanary version: v2.0-beta-3
* Android OS version: API 28
* Gradle version: 4.10.2

### Additional Information

As a side note, I am using a subclass of `FailTestOnLeakRunListener` that blocks heap analysis after one leak is found (in following tests). This helps to prevent the test matrix from taking too long and timing out if several of the tests have a leak. I am not sure if our heap analysis is much slower than others, or how other people are using instrumentation tests with leak canary, but a change like this was necessary for us to even be able to use it.","Can you import the file into LeakCanary and reanalyze it just to confirm? You can do that by opening the LeakCanary launcher app and going into the menu:

![Screenshot_1567801420](https://user-images.githubusercontent.com/557033/64458216-9a66f580-d0a9-11e9-85dd-b007309683ca.png)
","Wow, that's very interesting that it runs so quickly for you. I imported the file into the leak canary app on an emulator and it still took about ten minutes.

Here is the logcat output I get on Firebase btw
```
08-24 18:03:13.997: D/LeakCanary(15402): Heap Analysis:
08-24 18:03:13.997: D/LeakCanary(15402): HeapAnalysisSuccess(heapDumpFile=/data/user/0/com.airbnb.android.development/files/instrumentation_tests_heapdump.hprof, createdAtTimeMillis=1566694993995, analysisDurationMillis=707706, applicationLeaks=[], libraryLeaks=[LibraryLeak(className=com.airbnb.android.lib.mvrxtest.HappoTestActivity, leakTrace=
08-24 18:03:13.997: D/LeakCanary(15402): ┬
08-24 18:03:13.997: D/LeakCanary(15402): ├─ android.view.inputmethod.InputMethodManager
08-24 18:03:13.997: D/LeakCanary(15402): │    Leaking: NO (InputMethodManager↓ is not leaking and a class is never leaking)
08-24 18:03:13.997: D/LeakCanary(15402): │    GC Root: System class
08-24 18:03:13.997: D/LeakCanary(15402): │    ↓ static InputMethodManager.sInstance
08-24 18:03:13.997: D/LeakCanary(15402): ├─ android.view.inputmethod.InputMethodManager
08-24 18:03:13.997: D/LeakCanary(15402): │    Leaking: NO (InputMethodManager is a singleton)
08-24 18:03:13.997: D/LeakCanary(15402): │    ↓ InputMethodManager.mCurRootView
08-24 18:03:13.997: D/LeakCanary(15402): │                         ~~~~~~~~~~~~
08-24 18:03:13.997: D/LeakCanary(15402): ├─ com.android.internal.policy.DecorView
08-24 18:03:13.997: D/LeakCanary(15402): │    Leaking: YES (View.mContext references a destroyed activity)
08-24 18:03:13.997: D/LeakCanary(15402): │    mContext instance of com.android.internal.policy.DecorContext, wrapping activity com.airbnb.android.lib.mvrxtest.HappoTestActivity with mDestroyed = true
08-24 18:03:13.997: D/LeakCanary(15402): │    View#mParent is null
08-24 18:03:13.997: D/LeakCanary(15402): │    View#mAttachInfo is null (view detached)
08-24 18:03:13.997: D/LeakCanary(15402): │    View.mWindowAttachCount = 1
08-24 18:03:13.997: D/LeakCanary(15402): │    ↓ DecorView.mContentRoot
08-24 18:03:13.997: D/LeakCanary(15402): ├─ android.widget.LinearLayout
08-24 18:03:13.997: D/LeakCanary(15402): │    Leaking: YES (DecorView↑ is leaking and View.mContext references a destroyed activity)
08-24 18:03:13.997: D/LeakCanary(15402): │    mContext instance of com.airbnb.android.lib.mvrxtest.HappoTestActivity with mDestroyed = true
08-24 18:03:13.997: D/LeakCanary(15402): │    View#mParent is set
08-24 18:03:13.997: D/LeakCanary(15402): │    View#mAttachInfo is null (view detached)
08-24 18:03:13.997: D/LeakCanary(15402): │    View.mWindowAttachCount = 1
08-24 18:03:13.997: D/LeakCanary(15402): │    ↓ LinearLayout.mContext
08-24 18:03:13.997: D/LeakCanary(15402): ╰→ com.airbnb.android.lib.mvrxtest.HappoTestActivity
08-24 18:03:13.997: D/LeakCanary(15402): ​     Leaking: YES (LinearLayout↑ is leaking and Activity#mDestroyed is true and ObjectWatcher was watching this)
08-24 18:03:13.997: D/LeakCanary(15402): ​     key = 64f96c24-818e-4785-ba38-f856d4d8f44d
08-24 18:03:13.997: D/LeakCanary(15402): ​     watchDurationMillis = 5326
08-24 18:03:13.997: D/LeakCanary(15402): ​     retainedDurationMillis = 325
08-24 18:03:13.997: D/LeakCanary(15402): , retainedHeapByteSize=8116, pattern=instance field android.view.inputmethod.InputMethodManager#mCurRootView, description=The singleton InputMethodManager is holding a reference to mCurRootView long after the activity has been destroyed. Observed on ICS MR1: https://github.com/square/leakcanary/issues/1#issuecomment-100579429 Hack: https://gist.github.com/pyricau/4df64341cc978a7de414)])
```

Any idea why it may be running so much more quickly on your emulator?"
square/leakcanary,https://github.com/square/leakcanary/issues/1532,"### Description

Leak analysis failed - error suggested I report this failure to LeakCanary. Including a link to .hprof and the logcat below.

### Steps to Reproduce

https://drive.google.com/open?id=1Eez5QchPJ9zjQqK-noO-qzh95tplHz82

```2019-08-12 14:53:02.159 16258-16289/com.radiocom.staging D/LeakCanary: Found 2 retained references, dumping the heap
2019-08-12 14:53:02.176 16258-16289/com.radiocom.staging I/adiocom.stagin: hprof: heap dump ""/storage/emulated/0/Download/leakcanary-com.radiocom.staging/2019-08-12_14-53-02_168.hprof"" starting...
2019-08-12 14:53:08.147 16258-16289/com.radiocom.staging D/LeakCanary: Checking retained object because found new object retained
2019-08-12 14:53:08.147 16258-16289/com.radiocom.staging D/LeakCanary: No retained objects
2019-08-12 14:53:08.253 16258-23141/com.radiocom.staging D/LeakCanary: Analysis in progress, working on: PARSING_HEAP_DUMP
2019-08-12 14:53:21.928 16258-23141/com.radiocom.staging D/LeakCanary: Analysis in progress, working on: REPORTING_HEAP_ANALYSIS
2019-08-12 14:53:21.931 16258-23141/com.radiocom.staging D/LeakCanary: HeapAnalysisFailure(heapDumpFile=/storage/emulated/0/Download/leakcanary-com.radiocom.staging/2019-08-12_14-53-02_168.hprof, createdAtTimeMillis=1565643201930, analysisDurationMillis=13678, exception=
    java.lang.RuntimeException: Not enough memory to allocate buffers for rehashing: 2097152 -> 4194304
        at shark.internal.hppc.LongObjectScatterMap.allocateBuffers(LongObjectScatterMap.kt:275)
        at shark.internal.hppc.LongObjectScatterMap.allocateThenInsertThenRehash(LongObjectScatterMap.kt:307)
        at shark.internal.hppc.LongObjectScatterMap.set(LongObjectScatterMap.kt:99)
        at shark.internal.HprofInMemoryIndex$Builder.onHprofRecord(HprofInMemoryIndex.kt:170)
        at shark.HprofReader.readHprofRecords(HprofReader.kt:424)
        at shark.internal.HprofInMemoryIndex$Companion.createReadingHprof(HprofInMemoryIndex.kt:249)
        at shark.internal.HprofInMemoryIndex$Companion.createReadingHprof$default(HprofInMemoryIndex.kt:211)
        at shark.HprofHeapGraph$Companion.indexHprof(HprofHeapGraph.kt:187)
        at shark.HeapAnalyzer.analyze(HeapAnalyzer.kt:100)
        at leakcanary.internal.HeapAnalyzerService.onHandleIntentInForeground(HeapAnalyzerService.kt:61)
        at leakcanary.internal.ForegroundService.onHandleIntent(ForegroundService.kt:55)
        at android.app.IntentService$ServiceHandler.handleMessage(IntentService.java:76)
        at android.os.Handler.dispatchMessage(Handler.java:106)
        at android.os.Looper.loop(Looper.java:193)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: java.lang.OutOfMemoryError: Failed to allocate a 33554456 byte allocation with 10849984 free bytes and 10MB until OOM, max allowed footprint 201326592, growth limit 201326592
        at shark.internal.hppc.LongObjectScatterMap.allocateBuffers(LongObjectScatterMap.kt:269)
        at shark.internal.hppc.LongObjectScatterMap.allocateThenInsertThenRehash(LongObjectScatterMap.kt:307) 
        at shark.internal.hppc.LongObjectScatterMap.set(LongObjectScatterMap.kt:99) 
        at shark.internal.HprofInMemoryIndex$Builder.onHprofRecord(HprofInMemoryIndex.kt:170) 
        at shark.HprofReader.readHprofRecords(HprofReader.kt:424) 
        at shark.internal.HprofInMemoryIndex$Companion.createReadingHprof(HprofInMemoryIndex.kt:249) 
        at shark.internal.HprofInMemoryIndex$Companion.createReadingHprof$default(HprofInMemoryIndex.kt:211) 
        at shark.HprofHeapGraph$Companion.indexHprof(HprofHeapGraph.kt:187) 
        at shark.HeapAnalyzer.analyze(HeapAnalyzer.kt:100) 
        at leakcanary.internal.HeapAnalyzerService.onHandleIntentInForeground(HeapAnalyzerService.kt:61) 
        at leakcanary.internal.ForegroundService.onHandleIntent(ForegroundService.kt:55) 
        at android.app.IntentService$ServiceHandler.handleMessage(IntentService.java:76) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:193) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
    
    )
```

Trying to trigger memory leaks within app with LeakCanary monitoring, LeakCanary had a HeapAnalysisFailure

### Version Information

* LeakCanary version: LeakCanary 2.0-beta-2 cc5b133
* Phone: Pixel 2 XL
* Android OS version: 9
* Gradle version: gradle-4.10.1
","Maybe initial list of GC roots?
- Then down to 153Mb and slowing building back up to 190Mb => 4) What's that about?

Generally, we have two directions to investigate: a) the baseline memory required post hprof indexing, and how to lower that and b) the spikes while analyzing. The baseline is the most impactful right now.

I dumped the heap post indexing:

- The object cache uses 120Mb, the hprof string cache 13Mb
- Object cache (LongObjectScatterMap):
  - => Keys: 33Mb for the array
  - => values: 87Mb including 16Mb for the array => 71Mb for the rest => matches the remaining.
  - IndexedInstance (1.4M): 45Mb
  - PrimitiveArray (514K): 16Mb
  - ObjectArray (213K): 7Mb
  - Class (27K classes): 1Mb",
square/leakcanary,https://github.com/square/leakcanary/issues/1526,"### Description

```
java.lang.RuntimeException: Unable to start activity ComponentInfo{cn.itsite.glomax/leakcanary.internal.activity.LeakActivity}: java.lang.ClassCastException: leakcanary.internal.activity.LeakActivity cannot be cast to androidx.appcompat.app.AppCompatActivity
```

### dependencies

```
    debugImplementation 'com.squareup.leakcanary:leakcanary-android:2.0-beta-2'

```

Thank you for your wonderful lib.
Could you tell me how to solve this problem?My Activity extends AppCompatActivity.",Can you provide the full stracktrace? What were you trying to do?,"I'm glad to hear from you

full stracktrace as follow:
```
    java.lang.RuntimeException: Unable to start activity ComponentInfo{cn.itsite.glomax/leakcanary.internal.activity.LeakActivity}: java.lang.ClassCastException: leakcanary.internal.activity.LeakActivity cannot be cast to androidx.appcompat.app.AppCompatActivity
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2951)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3086)
        at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:78)
        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:108)
        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:68)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1816)
        at android.os.Handler.dispatchMessage(Handler.java:106)
        at android.os.Looper.loop(Looper.java:193)
        at android.app.ActivityThread.main(ActivityThread.java:6718)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:858)
     Caused by: java.lang.ClassCastException: leakcanary.internal.activity.LeakActivity cannot be cast to androidx.appcompat.app.AppCompatActivity
        at cn.itsite.main.App.onActivityCreated(App.java:36)
        at android.app.Application.dispatchActivityCreated(Application.java:220)
        at android.app.Activity.onCreate(Activity.java:1048)
        at leakcanary.internal.activity.LeakActivity.onCreate(LeakActivity.kt:23)
        at android.app.Activity.performCreate(Activity.java:7144)
        at android.app.Activity.performCreate(Activity.java:7135)
        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1271)
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2931)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3086) 
        at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:78) 
        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:108) 
        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:68) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1816) 
        at android.os.Handler.dispatchMessage(Handler.java:106) 
        at android.os.Looper.loop(Looper.java:193) 
        at android.app.ActivityThread.main(ActivityThread.java:6718) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:858) 
```

I just wanted to integrate the latest version into my project.
When memory leaks, there is a prompt, so I click on the launch icon, but it flashes back and there was exception logs.
"
square/leakcanary,https://github.com/square/leakcanary/issues/1512,"### Description

Can't build the app with LeakCanary when using material theme (Theme.MaterialComponents.NoActionBar).

Caused by: java.lang.IllegalStateException: You need to use a Theme.AppCompat theme (or descendant) with this activity.

### Version Information

* LeakCanary version: 2.0-alpha-3
* Android OS version: API28
* Gradle version: 3.4.2","Can you provide the full stacktrace?

Can you try with the [latest release](https://square.github.io/leakcanary/changelog) of LeakCanary?",
square/leakcanary,https://github.com/square/leakcanary/issues/1124,"```
* FAILURE in 1.6.1 26145bf:java.lang.IllegalStateException: Could not find the com.squareup.leakcanary.KeyedWeakReference class in the heap dump.
at com.squareup.leakcanary.HeapAnalyzer.findLeakingReference(HeapAnalyzer.java:216)
at com.squareup.leakcanary.HeapAnalyzer.checkForLeak(HeapAnalyzer.java:172)
at com.squareup.leakcanary.internal.HeapAnalyzerService.onHandleIntentInForeground(HeapAnalyzerService.java:67)
at com.squareup.leakcanary.internal.ForegroundService.onHandleIntent(ForegroundService.java:55)
at android.app.IntentService$ServiceHandler.handleMessage(IntentService.java:65)
at android.os.Handler.dispatchMessage(Handler.java:111)
at android.os.Looper.loop(Looper.java:224)
at android.os.HandlerThread.run(HandlerThread.java:61)

* Reference Key: d469243b-dcc5-4fc8-874f-88865002c276
* Device: OPPO OPPO OPPO R9m R9m
* Android Version: 5.1 API: 22 LeakCanary: 1.6.1 26145bf
* Durations: watch=685299ms, gc=281ms, heap dump=7374ms, analysis=4502ms
* Excluded Refs:
| Field: android.os.Message.obj
| Field: android.os.Message.next
| Field: android.os.Message.target
| Field: android.view.inputmethod.InputMethodManager.mNextServedView
| Field: android.view.inputmethod.InputMethodManager.mServedView
| Field: android.view.inputmethod.InputMethodManager.mServedInputConnection
| Field: android.view.inputmethod.InputMethodManager.mCurRootView
| Field: android.animation.LayoutTransition$1.val$parent
| Field: android.view.textservice.SpellCheckerSession$1.this$0
| Field: android.widget.SpellChecker$1.this$0
| Field: android.support.v7.internal.widget.ActivityChooserModel.mActivityChoserModelPolicy
| Field: android.widget.ActivityChooserModel.mActivityChoserModelPolicy
| Field: android.accounts.AccountManager$AmsTask$Response.this$1
| Field: android.media.MediaScannerConnection.mContext
| Field: android.os.UserManager.mContext
| Field: android.media.AudioManager$1.this$0
| Field: android.widget.Editor$Blink.this$0
| Field: android.net.ConnectivityManager.sInstance
| Field: android.view.Choreographer$FrameDisplayEventReceiver.mMessageQueue (always)
| Static field: android.text.TextLine.sCached
| Thread:FinalizerWatchdogDaemon (always)
| Thread:main (always)
| Thread:LeakCanary-Heap-Dump (always)
| Class:java.lang.ref.WeakReference (always)
| Class:java.lang.ref.SoftReference (always)
| Class:java.lang.ref.PhantomReference (always)
| Class:java.lang.ref.Finalizer (always)
| Class:java.lang.ref.FinalizerReference (always)
```",Can you upload the corresponding heapdump?,
square/leakcanary,https://github.com/square/leakcanary/issues/710,"I was trying out Leak Canary for the first time today and I couldn't get it to show a notification for an obvious leak (storing a view in a static variable). After debugging into the source code, I found that [Leak Canary will simply do nothing as long as a debugger is attached][1].

Which makes sense to me, but I think a lot of first-time users like me will be surprised that nothing is happening when they first fire up their app in the emulater after installing Leak Canary. So it might be a good idea to document this behaviour right under the installation instructions in the README of this repo, so first-time users are aware of this restriction.

Thanks for the awesome library!

[1]: https://github.com/square/leakcanary/blob/master/leakcanary-watcher/src/main/java/com/squareup/leakcanary/RefWatcher.java#L106",How about the FAQ instead?,"Sure, if you feel that's the right place"
square/leakcanary,https://github.com/square/leakcanary/issues/512,"LeakCanary Version: 1.3.1
In my team, we wanted to have an option to disable/enable leakcanary at runtime, because the library freezes our app a lot and it is not usable. So we've created a small adapter so we can have a no-op watcher in debug builds. Something like this:

```
if (isLekcanaryEnabled()) {
    watcher = new WatcherAdapter(
            LeakCanary.install(ctx));
} else {
    watcher = new NoOpWatcher();
}
```

I think it would be nice to have such feature in the library itself.
What do you think? If you think it is a nice idea, I am ready to contribute.

Thanks.
","Why don't you just use `RefWatcher.DISABLED`?

That is basically the no-op implementation you are looking for.
","Didn't know about it.
"
square/leakcanary,https://github.com/square/leakcanary/issues/469,"![image](https://cloud.githubusercontent.com/assets/7311419/14101118/c6f9eac6-f5c4-11e5-8f65-dea830dc1c3b.png)
","What version of LeakCanary are you using?
",
square/leakcanary,https://github.com/square/leakcanary/issues/417,"In com.sumxiang.noteapp:1.0:2.
- FAILURE:
  java.lang.NullPointerException: java.lang.NullPointerException
  at com.squareup.leakcanary.HahaHelper.classInstanceValues(HahaHelper.java:143)
  at com.squareup.leakcanary.HahaHelper.asString(HahaHelper.java:73)
  at com.squareup.leakcanary.HahaHelper.threadName(HahaHelper.java:55)
  at com.squareup.leakcanary.ShortestPathFinder.enqueueGcRoots(ShortestPathFinder.java:133)
  at com.squareup.leakcanary.ShortestPathFinder.findPath(ShortestPathFinder.java:82)
  at com.squareup.leakcanary.HeapAnalyzer.findLeakTrace(HeapAnalyzer.java:112)
  at com.squareup.leakcanary.HeapAnalyzer.checkForLeak(HeapAnalyzer.java:87)
  at com.squareup.leakcanary.internal.HeapAnalyzerService.onHandleIntent(HeapAnalyzerService.java:58)
  at android.app.IntentService$ServiceHandler.handleMessage(IntentService.java:65)
  at android.os.Handler.dispatchMessage(Handler.java:102)
  at android.os.Looper.loop(Looper.java:136)
  at android.os.HandlerThread.run(HandlerThread.java:61)
- Reference Key: 17ea16ba-cb43-4a23-bd9e-18c6ad09b2d2
- Device: Xiaomi Xiaomi HM 1SW armani
- Android Version: 4.4.4 API: 19 LeakCanary: 1.4-beta1 02804f3
- Durations: watch=5018ms, gc=123ms, heap dump=580ms, analysis=4082ms
- Excluded Refs:
  | Field: android.app.ActivityThread$ActivityClientRecord.nextIdle
  | Field: android.widget.Editor$EasyEditSpanController.this$0
  | Field: android.widget.Editor$SpanController.this$0
  | Field: android.os.Message.obj
  | Field: android.os.Message.next
  | Field: android.os.Message.target
  | Field: android.view.inputmethod.InputMethodManager.mNextServedView
  | Field: android.view.inputmethod.InputMethodManager.mServedView
  | Field: android.view.inputmethod.InputMethodManager.mServedInputConnection
  | Field: android.view.inputmethod.InputMethodManager.mCurRootView
  | Field: android.animation.LayoutTransition$1.val$parent
  | Field: android.view.textservice.SpellCheckerSession$1.this$0
  | Field: android.support.v7.internal.widget.ActivityChooserModel.mActivityChoserModelPolicy
  | Field: android.widget.ActivityChooserModel.mActivityChoserModelPolicy
  | Field: android.speech.SpeechRecognizer$InternalListener.this$0
  | Field: android.accounts.AccountManager$AmsTask$Response.this$1
  | Field: android.media.MediaScannerConnection.mContext
  | Field: android.os.UserManager.mContext
  | Field: android.appwidget.AppWidgetHost$Callbacks.this$0
  | Field: android.media.AudioManager$1.this$0
  | Field: android.view.Choreographer$FrameDisplayEventReceiver.mMessageQueue (always)
  | Static field: android.text.TextLine.sCached
  | Thread:FinalizerWatchdogDaemon (always)
  | Thread:main (always)
  | Thread:LeakCanary-Heap-Dump (always)
  | Class:java.lang.ref.WeakReference (always)
  | Class:java.lang.ref.SoftReference (always)
  | Class:java.lang.ref.PhantomReference (always)
  | Class:java.lang.ref.Finalizer (always)
  | Class:java.lang.ref.FinalizerReference (always)
  | Root Class:android.os.Binder (always)
  dump http://pan.baidu.com/s/1c0KU7y4
","Does it happen on other devices as well?

@jrodbx yet another string parsing in heap dump problem? Not sure.. this is in API 19.
","but i have bad english, but at last i have provide  the heap dump.
the file i upload to baiduyun,if you can't download ,tell me your email,i will send to you
"
square/leakcanary,https://github.com/square/leakcanary/issues/285,"Sometimes the Toast with the message ""Dumping memory, app will freeze. Brrr."" appears on my application and does not disappear. 
I also get a few ANR while this message is visible (I think this is expected) and always select wait instead of killing the application. 
The only way to remove the Toast is killing the application.
To install the leakcanary I only added the install method on the application class (`LeakCanary.install(this);`). It is necessary to do something more? 

On my device (OnePlus One with Android 5.1.1) I never get this behaviour but on Android emulator with Android 6.0 it happens with some frequency.  
","Can the permission be removed from the releaseCompile version though? The storage permission still comes through even for release builds, which might seem strange to users.
",
square/leakcanary,https://github.com/square/leakcanary/issues/265,"I've got this:

```
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$1: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$Itr
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$2: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$Itr
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$RandomAccessWrappedList: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$RandomAccessWrappedList: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedList
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$SortedAsMap: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$AsMap
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$SortedKeySet: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$KeySet
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedList: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedList: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedList$WrappedListIterator: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedList$WrappedListIterator: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection$WrappedIterator
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedSet: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedSortedSet: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedSortedSet: can't find referenced class com.squareup.haha.guava.collect.AbstractMapBasedMultimap$com.squareup.haha.guava.collect.AbstractMapBasedMultimap$WrappedCollection
Warning: com.squareup.haha.guava.collect.AbstractMultimap$EntrySet: can't find referenced class com.squareup.haha.guava.collect.AbstractMultimap$com.squareup.haha.guava.collect.AbstractMultimap$Entries
Warning: com.squareup.haha.guava.collect.ImmutableMultimap$1: can't find referenced class com.squareup.haha.guava.collect.ImmutableMultimap$com.squareup.haha.guava.collect.ImmutableMultimap$Itr
Warning: com.squareup.haha.guava.collect.ImmutableMultimap$2: can't find referenced class com.squareup.haha.guava.collect.ImmutableMultimap$com.squareup.haha.guava.collect.ImmutableMultimap$Itr
Warning: com.squareup.haha.guava.collect.MapMakerInternalMap$EntryIterator: can't find referenced class com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$HashIterator
Warning: com.squareup.haha.guava.collect.MapMakerInternalMap$HashIterator: can't find referenced class com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$WriteThroughEntry
Warning: com.squareup.haha.guava.collect.MapMakerInternalMap$HashIterator: can't find referenced class com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$WriteThroughEntry
Warning: com.squareup.haha.guava.collect.MapMakerInternalMap$HashIterator: can't find referenced class com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$WriteThroughEntry
Warning: com.squareup.haha.guava.collect.MapMakerInternalMap$KeyIterator: can't find referenced class com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$HashIterator
Warning: com.squareup.haha.guava.collect.MapMakerInternalMap$ValueIterator: can't find referenced class com.squareup.haha.guava.collect.MapMakerInternalMap$com.squareup.haha.guava.collect.MapMakerInternalMap$HashIterator
Warning: com.squareup.haha.perflib.io.MemoryMappedFileBuffer: can't find referenced class sun.misc.Cleaner
Warning: com.squareup.haha.perflib.io.MemoryMappedFileBuffer: can't find referenced class sun.nio.ch.DirectBuffer
Warning: com.squareup.haha.perflib.io.MemoryMappedFileBuffer: can't find referenced class sun.misc.Cleaner
Warning: com.squareup.haha.perflib.io.MemoryMappedFileBuffer: can't find referenced class sun.nio.ch.DirectBuffer
Warning: com.squareup.haha.trove.THashMap$EntryView: can't find referenced class com.squareup.haha.trove.THashMap$com.squareup.haha.trove.THashMap$MapBackedView
Warning: com.squareup.haha.trove.THashMap$KeyView: can't find referenced class com.squareup.haha.trove.THashMap$com.squareup.haha.trove.THashMap$MapBackedView
Warning: com.squareup.haha.trove.THashMap$ValueView: can't find referenced class com.squareup.haha.trove.THashMap$com.squareup.haha.trove.THashMap$MapBackedView
Warning: there were 50 unresolved references to classes or interfaces.
         You may need to add missing library jars or update their versions.
         If your code works fine without the missing classes, you can suppress
         the warnings with '-dontwarn' options.
         (http://proguard.sourceforge.net/manual/troubleshooting.html#unresolvedclass)
Exception while processing task
```

Even though in my proguard.cfg:

```
-keep class org.eclipse.mat.** { *; }
-keep class com.squareup.leakcanary.** { *; }
-keep class com.squareup.haha.** { *; }
-keep class sun.misc.** { *; }
-keep class sun.nio.** { *; }
```
","What happens when you turn off proguard in your app, does LeakCanary work just fine?
",
square/leakcanary,https://github.com/square/leakcanary/issues/155,"This is on a Galaxy Nexus:

```
 StrictMode policy violation; ~duration=102 ms: android.os.StrictMode$StrictModeDiskReadViolation: policy=95 violation=2
    at android.os.StrictMode$AndroidBlockGuardPolicy.onReadFromDisk(StrictMode.java:1089)
    at libcore.io.BlockGuardOs.read(BlockGuardOs.java:148)
    at libcore.io.IoBridge.read(IoBridge.java:422)
    at java.io.FileInputStream.read(FileInputStream.java:179)
    at org.apache.harmony.security.provider.crypto.RandomBitsSupplier.getUnixDeviceRandom(RandomBitsSupplier.java:111)
    at org.apache.harmony.security.provider.crypto.RandomBitsSupplier.getRandomBits(RandomBitsSupplier.java:159)
    at org.apache.harmony.security.provider.crypto.SHA1PRNG_SecureRandomImpl.engineNextBytes(SHA1PRNG_SecureRandomImpl.java:288)
    at java.security.SecureRandom.nextBytes(SecureRandom.java:273)
    at java.util.UUID.randomUUID(UUID.java:130)
    at com.squareup.leakcanary.RefWatcher.watch(RefWatcher.java:96)
    at com.squareup.leakcanary.RefWatcher.watch(RefWatcher.java:80)
    at com.squareup.leakcanary.ActivityRefWatcher.onActivityDestroyed(ActivityRefWatcher.java:76)
    at com.squareup.leakcanary.ActivityRefWatcher$1.onActivityDestroyed(ActivityRefWatcher.java:59)
    at android.app.Application.dispatchActivityDestroyed(Application.java:210)
    at android.app.Activity.onDestroy(Activity.java:1396)
    at android.app.Activity.performDestroy(Activity.java:4629)
    at android.app.Instrumentation.callActivityOnDestroy(Instrumentation.java:1079)
    at android.app.ActivityThread.performDestroyActivity(ActivityThread.java:3099)
    at android.app.ActivityThread.handleDestroyActivity(ActivityThread.java:3130)
    at android.app.ActivityThread.handleRelaunchActivity(ActivityThread.java:3328)
    at android.app.ActivityThread.access$700(ActivityThread.java:123)
    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1151)
    at android.os.Handler.dispatchMessage(Handler.java:99)
    at android.os.Looper.loop(Looper.java:137)
    at android.app.ActivityThread.main(ActivityThread.java:4424)
    at java.lang.reflect.Method.invokeNative(Native Method)
    at java.lang.reflect.Method.invoke(Method.java:511)
    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:784)
    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:551)
    at dalvik.system.NativeStart.main(Native Method)
 Shutting down VM
 threadid=1: thread exiting with uncaught exception (group=0x40a461f8)
 FATAL EXCEPTION: main
 android.os.StrictMode$StrictModeViolation: policy=95 violation=2
    at android.os.StrictMode.executeDeathPenalty(StrictMode.java:1326)
    at android.os.StrictMode.access$1300(StrictMode.java:111)
    at android.os.StrictMode$AndroidBlockGuardPolicy.handleViolation(StrictMode.java:1319)
    at android.os.StrictMode$AndroidBlockGuardPolicy$1.run(StrictMode.java:1206)
    at android.os.Handler.handleCallback(Handler.java:605)
    at android.os.Handler.dispatchMessage(Handler.java:92)
    at android.os.Looper.loop(Looper.java:137)
    at android.app.ActivityThread.main(ActivityThread.java:4424)
    at java.lang.reflect.Method.invokeNative(Native Method)
    at java.lang.reflect.Method.invoke(Method.java:511)
    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:784)
    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:551)
    at dalvik.system.NativeStart.main(Native Method)
 GC_CONCURRENT freed 237K, 3% free 12786K/13127K, paused 3ms+2ms
   Force finishing activity com.example.leakcanary/.MainActivity
 Activity pause timeout for ActivityRecord{41f6cfd8 com.example.leakcanary/.MainActivity}
```
","What version of LeakCanary are you using?
",
square/picasso,https://github.com/square/picasso/issues/1236,"```
Picasso.with(this).load(mMediaTransmission.getPictureFilePath()).resize(0, 400).into(new Target() {
            @Override
            public void onBitmapLoaded(Bitmap bitmap, Picasso.LoadedFrom from) {
                mCropView.setBackgroundBitmap(bitmap);
            }

            @Override
            public void onBitmapFailed(Drawable errorDrawable) {
            }

            @Override
            public void onPrepareLoad(Drawable placeHolderDrawable) {

            }
        });
```

if the pictureFile is large image, picasso will never load success
","What exception is passed to the exception handler on `Picasso.Builder` when the image is loaded?
","@JakeWharton  no exception !  maybe the time of the Picasso load picture file is too long ！ Glide work well!
"
square/picasso,https://github.com/square/picasso/issues/658,"My english is poor,so just look Code.

in UrlConnectionDownloader.java . I change some code in method  look like:

@Override
    public Response load(Uri uri, boolean localCacheOnly) throws IOException {
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.ICE_CREAM_SANDWICH) {
            installCacheIfNeeded(context);
        }

```
    HttpURLConnection connection = openConnection(uri);
    connection.setUseCaches(true);
    if (localCacheOnly) {
        connection.setRequestProperty(""Cache-Control"",
                ""only-if-cached,max-age="" + Integer.MAX_VALUE);
    }
    // 我只是添加了这一句代码，来让本地磁盘缓存，不根据服务器header头中的缓存字段缓存，而是 本地磁盘缓存永久有效
    connection.addRequestProperty(""Cache-Control"", ""max-stale=""
            + Integer.MAX_VALUE);// 允许读取陈旧的（header头中Cache-Control:max-age
                                    // 过期）磁盘缓存条目

    int responseCode = connection.getResponseCode();
    if (responseCode >= 300) {
        connection.disconnect();
        throw new ResponseException(responseCode + "" ""
                + connection.getResponseMessage());
    }

    long contentLength = connection.getHeaderFieldInt(""Content-Length"", -1);
    boolean fromCache = parseResponseSourceHeader(connection
            .getHeaderField(RESPONSE_SOURCE));

    System.out.println(""应答报头信息：""+connection
            .getHeaderField(RESPONSE_SOURCE));
    System.out.println(""是否从磁盘读取的缓存：""+fromCache);

    return new Response(connection.getInputStream(), fromCache,
            contentLength);
}
```

According to information printed,The result is read from the disk cache. But  in the  method load()  of NetworkRequestHandler.java    , look code:

---

```
         Bitmap bitmap = response.getBitmap();
    if (bitmap != null) {
        System.out.println(""NetworkRequestHandler  直接从downloader中获取到了Bitmap"");
        return new Result(bitmap, loadedFrom);
    }

    InputStream is = response.getInputStream();
    if (is == null) {
        return null;
    }
    // Sometimes response content length is zero when requests are being
    // replayed. Haven't found
    // root cause to this but retrying the request seems safe to do so.
    if (response.getContentLength() == 0) {
        Utils.closeQuietly(is);
        throw new IOException(
                ""Received response with 0 content-length header."");
    }
    if (loadedFrom == NETWORK && response.getContentLength() > 0) {
        stats.dispatchDownloadFinished(response.getContentLength());
    }
    try {
        return new Result(decodeStream(is, data), NETWORK);
    } finally {
        Utils.closeQuietly(is);
    }
```

---

  Bitmap bitmap = response.getBitmap();  bitmap is null, so  Will perform  return new Result(decodeStream(is, data), NETWORK); 

This is a bug? 
","Do you want to send a pull request?
","sorry , i am a Novice .  i  will not  send a  pull  request....
"
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/50462,"### Problem Description
Discovery EC2 doesn't retry EC2 describe calls on throttle or exceptions due to `NO_RETRY_CONDITION`  which has the potential to make the throttling worse. Although there is a logic to exponentially backoff in such cases, backoff doesn't kick in.

https://github.com/elastic/elasticsearch/blob/7203ceefd8761cdbfd9d4510cdda1ac968caf11d/plugins/discovery-ec2/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2ServiceImpl.java#L82-L90

AWS [reference](https://github.com/aws/aws-sdk-java/blob/de3ea40fbd783f1a667f24303399f5ed2a0279ec/aws-java-sdk-core/src/main/java/com/amazonaws/retry/RetryPolicy.java#L140-L148)

","Wouldn't we have to fix those as well to really get proper retrying here? It seems like we'd only be fixing part of the calls to retry if we just did something like move to using the default retry condition in the code you pasted?

(I ran into this when I tried to test retries by faking `500`s in the EC2 mock we use, if we only fixed this one spot which I'm not sure is all that valueable it still wouldn't be entirely trivial to test the fix either would it or do you have an idea?)","@original-brownbear Please correct me if I misunderstood your point but aren't the two calls made to different endpoint and hence logically different entities.
1. DescribeInstance - EC2 control plane(via SDK)
2. Instance Metadata - http://169.254.169.254/latest/meta-data/ (via URL#openConnection())

While for (1) we need retries for cases when a large cluster(100 node or more) loses a master and then PeerFinder on all nodes do a per second EC2 call causing account level limits to be breached.
(2) might be different than this though(haven't encountered throttling so far for this) and I certainly think (1) is valueable and worth the change.

Testing
We tested (1) by restarting masters on a 150 node cluster, which lead to more calls getting throttled without the fix. While DEFAULT_RETRY ensured back off kicks in. We could see from the timestamp of the exception stack trace. Having said this, we are working on a better test plan"
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/50088,"The cat nodes API performs a `ClusterStateAction` then a `NodesInfoAction`. It accepts the `?local` parameter and passes this to the `ClusterStateAction` but this parameter has no effect on the `NodesInfoAction`. This is surprising, because `GET _cat/nodes?local` looks like it might be a completely local call but in fact it still depends on every node in the cluster.

I think the `?local` parameter does not make sense on this API and we should remove it.",May I work on this one? Any hints are appreciated.,"Sure, go ahead. See e.g. https://github.com/elastic/elasticsearch/pull/49458 for another example of how to deprecate something properly."
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/50056,"A few things related to the `o.e.a.s.m.TransportMasterNodeAction` logging messages.

User reported the following debug messages showing up after upgrading to 7.5.0 (from 7.3):

```
[2019-12-03T22:47:59,669][DEBUG][o.e.a.s.m.TransportMasterNodeAction] [node.infra] Get stats for datafeed '_all'
[2019-12-03T22:48:09,650][DEBUG][o.e.a.s.m.TransportMasterNodeAction] [node.infra] Get stats for datafeed '_all'
[2019-12-03T22:48:19,618][DEBUG][o.e.a.s.m.TransportMasterNodeAction] [node.infra] Get stats for datafeed '_all'
[2019-12-03T22:48:29,713][DEBUG][o.e.a.s.m.TransportMasterNodeAction] [node.infra] Get stats for datafeed '_all'
[2019-12-03T22:48:39,655][DEBUG][o.e.a.s.m.TransportMasterNodeAction] [node.infra] Get stats for datafeed '_all'
[2019-12-03T22:48:49,669][DEBUG][o.e.a.s.m.TransportMasterNodeAction] [node.infra] Get stats for datafeed '_all'
[2019-12-03T22:48:59,668][DEBUG][o.e.a.s.m.TransportMasterNodeAction] [node.infra] Get stats for datafeed '_all'
```

These are showing up in the logs because Elasticsearch has the logger for `org.elasticsearch.action` set to DEBUG by default.  It seems like we may want to use a different package to log these under?

Also, this user has a Gold license but their nodes had ML enabled (explicitly via `xpack.ml.enabled: true`) because they were previously testing ML. After setting `xpack.ml.enabled: false`, the above messages stopped showing up (expected).  Should a gold license have disabled this type of monitoring stats for ML even when `xpack.ml.enabled` is set to true?","Should a gold license have disabled this type of monitoring stats for ML even when xpack.ml.enabled is set to true?

Licensing does not affect what gets loaded as far as I understand. We check the license in specific API calls. But we want the flexibility of being able to load the plugin as that allows different features in the plugin to be licensed differently (e.g. basic features).

",
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/49970,"<!--

** Please read the guidelines below. **

Issues that do not follow these guidelines are likely to be closed.

1.  GitHub is reserved for bug reports and feature requests. The best place to
    ask a general question is at the Elastic [forums](https://discuss.elastic.co).
    GitHub is not the place for general questions.

2.  Is this bug report or feature request for a supported OS? If not, it
    is likely to be closed.  See https://www.elastic.co/support/matrix#show_os

3.  Please fill out EITHER the feature request block or the bug report block
    below, and delete the other block.

-->

<!-- Feature request -->

**Describe the feature**:
Hi, 
I found 'too many files open' problem in my ES enviroment.  And I use the commad `ls -al /proc/ES_PID/fd` , found that ES opened particularly large number of translog files.  
After some search on this problem , I tried to restart  a runing normally ES (6.6.1).  I found that ，**every time ES is restarted, there will be one more translog file on some shards**. And all the translogs have no operation data, like  below( The server time is incorrect，but I don't think it's concern ):

![image](https://user-images.githubusercontent.com/16160751/70388387-0419d700-19ec-11ea-8699-6da28123a33f.png)

<!-- Bug report -->

**Elasticsearch version** (`bin/elasticsearch --version`):
Version: 6.6.1, Build: default/tar/1fd8f69/2019-02-13T17:10:04.160291Z, JVM: 1.8.0_60
**Plugins installed**: []
No Plugins
**JVM version** (`java -version`):
java version ""1.8.0_60""
Java(TM) SE Runtime Environment (build 1.8.0_60-b27)
**OS version** (`uname -a` if on a Unix-like system):
Centos 7.6
Linux 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
**Description of the problem including expected versus actual behavior**:
Empty translog files(no operation data) keep increasing.
Old translog exist beyond 12 hours(index.translog.retention.age = 12h).
I think empty translog files should be deleted or don't creat new translog files.
**Steps to reproduce**:
restart ES node
Please include a *minimal* but *complete* recreation of the problem, including
(e.g.) index creation, mappings, settings, query etc.  The easier you make for
us to reproduce it, the more likely that somebody will take the time to look at it.

 1.  defautl index setting as follow:
`""settings"":{  
              ""index.number_of_replicas"":""0"",
              ""index.refresh_interval"":""10s"",
              ""index.number_of_shards"":""1"",
              ""index.routing.allocation.require.tag"":""hot"",
              ""index.indexing.slowlog.level"": ""info"",
              ""index.indexing.slowlog.threshold.index.trace"": ""500ms"",
              ""index.indexing.slowlog.threshold.index.debug"": ""2s"",
              ""index.indexing.slowlog.threshold.index.info"": ""5s"",
              ""index.indexing.slowlog.threshold.index.warn"": ""10s"",
              ""index.search.slowlog.level"": ""info"",
              ""index.search.slowlog.threshold.fetch.trace"": ""200ms"",
              ""index.search.slowlog.threshold.fetch.debug"": ""500ms"",
              ""index.search.slowlog.threshold.fetch.info"": ""800ms"",
              ""index.search.slowlog.threshold.fetch.warn"": ""1s"",
              ""index.search.slowlog.threshold.query.trace"": ""500ms"",
              ""index.search.slowlog.threshold.query.debug"": ""2s"",
              ""index.search.slowlog.threshold.query.info"": ""5s"",
              ""index.search.slowlog.threshold.query.warn"": ""10s"",
               ""index.translog.durability"": ""async"",
               ""index.translog.flush_threshold_size"": ""5000mb"",
               ""index.translog.sync_interval"": ""120s"",
               ""index.mapping.ignore_malformed"": true
   }
`
 2.  Auto create index use the dynamic mapping, and index name is created by date, only the index created today is active. Indices  created before today have no data to index.
 3.  Restart ES, the translog of indices  created before today (no data to index) keep increasing

If I missed some configuration， please let me know.
I'd be happy to provide additional details, whatever is needed.

Thanks!

","Maybe we should?

In the meantime a `POST /index/_flush?force` will, I think, clean things up.","Hi @DaveCTurner ,
  Thanks a lot for your answer.
  And is there any command like `elasticsearch-traslog trim` for translog merge?  Because before merging all the translog ,my ES node recovey very slowly even can't start (too many open files.)"
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/48950,"<!-- Bug report -->

**Elasticsearch version** (`bin/elasticsearch --version`): 7.4.2 - Java Client 7.4.2

**Plugins installed**: []

**JVM version** (`java -version`): jdk11

**OS version** (`uname -a` if on a Unix-like system): unix docker

**Description of the problem including expected versus actual behavior**:
Node-Sniffer for Java-Rest-Client fails parsing the new `hostname/ip:port` format properly.
Client is initalized with a consul-address containing the port. instead the hostname is just used with port 80, the sniff() fails with an ConnectionException.
=> expected IP and port are extracted 192.168.0.185:9202
=> actual only hostname is parsed integration-stack-01.com.pany

**Steps to reproduce**:

Please include a *minimal* but *complete* recreation of the problem, including
(e.g.) index creation, mappings, settings, query etc.  The easier you make for
us to reproduce it, the more likely that somebody will take the time to look at it.

 1. setup clusternode with hostname so publish_address : ""integration-stack-01.com.pany/192.168.0.185:9202""
 2. create simple main-Class Java starting a Client and Sniffer
 3. Sniffer fails at sniff() because address is parsed not properly

**Provide logs (if relevant)**:
```
GET http://elasticsearch3.service.int.consul:9202/_nodes/http?pretty
```
```
{
  ""_nodes"" : {
    ""total"" : 3,
    ""successful"" : 3,
    ""failed"" : 0
  },
  ""cluster_name"" : ""company-int-3"",
  ""nodes"" : {
    ""qGSyScvjRK2jbujcpo9t3g"" : {
      ""name"" : ""integration-stack-01"",
      ""transport_address"" : ""192.168.0.185:9302"",
      ""host"" : ""integration-stack-01.com.pany"",
      ""ip"" : ""192.168.0.185"",
      ""version"" : ""7.4.2"",
      ""build_flavor"" : ""default"",
      ""build_type"" : ""tar"",
      ""build_hash"" : ""2f90bbf7b93631e52bafb59b3b049cb44ec25e96"",
      ""roles"" : [
        ""ingest"",
        ""master"",
        ""data"",
        ""ml""
      ],
      ""attributes"" : {
        ""ml.machine_memory"" : ""67498500096"",
        ""ml.max_open_jobs"" : ""20""
      },
      ""http"" : {
        ""bound_address"" : [
          ""[::]:9202""
        ],
        ""publish_address"" : ""integration-stack-01.com.pany/192.168.0.185:9202"",
        ""max_content_length_in_bytes"" : 104857600
      }
    },
	...
```
Error:
```
16:46:03.278 [pool-1-thread-1] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 13] connection request failed
16:46:03.278 [pool-1-thread-1] DEBUG org.elasticsearch.client.RestClient - request [GET http://integration-stack-03.com.pany/_nodes/http?timeout=1000ms] failed
```
Example:
```
package com.pany.elasticsearchrestclients;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestClientBuilder;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.client.sniff.SniffOnFailureListener;
import org.elasticsearch.client.sniff.Sniffer;

public class TestStarter
{
	public static void main(final String[] args)
	{
		SniffOnFailureListener sniffOnFailureListener = new SniffOnFailureListener();
		RestClientBuilder builder = RestClient.builder(new HttpHost(""elasticsearch3.service.int.consul"", 9202)).setFailureListener(sniffOnFailureListener);
		RestHighLevelClient client = new RestHighLevelClient(builder);
		Sniffer sniffer = Sniffer.builder(client.getLowLevelClient()).setSniffAfterFailureDelayMillis(1_000).setSniffIntervalMillis(500).build();
		sniffOnFailureListener.setSniffer(sniffer);
	}
}

```","What is giving out this address? is it consul itself? 
","
> ```
> 		RestClientBuilder builder = RestClient.builder(new HttpHost(""elasticsearch3.service.int.consul"", 9202)).setFailureListener(sniffOnFailureListener);
>```
initalizing the client works seamlessly, it connects with the provided consul address to the cluster, connection established ( and connection stays if no sniffer is used )
> 
> Node-Sniffer for Java-Rest-Client fails 
> parsing the new hostname/ip:port format properly.

then the Node Sniffer kicks in and does its round, parsing the response from the nodes endpoint. here it receives the publish_address in the es7 format hostname/ip:port.
the json parser inside the node sniffer parses the value into a String and creates a new URI - here it fails, everything after the slash is considered as a path, the port is neglected and an URI with hostname and port 80 (-1) is created. the sniffer returns the new found nodes, updates the client, no connection anymore.

I will provide the settings file of our cluster if necessary.
"
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/47276,"**Elasticsearch version**: 7.3.2

**Plugins installed**: []

**JVM version** (`java -version`): 1.8.0

**OS version**: Centos-7.4

We have been running an elasticsearch cluster consisting of 5 modes for quite some time now. After upgrade to v7, we have noticed a lot of times our nodes refuse to start with
an error `nested: IOException[failed to find metadata for existing index XXX`.

The first time I encountered this error, I searched the discuss board and found [this](https://discuss.elastic.co/t/failed-to-find-metadata-for-existing-index-after-node-restart/191507) which talks of stronger startup checks enforced by ES-7.x and points to data directory getting corrupted due to external factors. Thinking it may be the same probloem, I duly took the node offline and ran a disk check which reported no errors. So I deleted the data directory, started the node and that was that.

However, the next time I did a rolling upgrade of my cluster, a different node failed with a similar error (The index name was different). I followed the same emergency procedure (delete data directory and restart node) and cluster was fixed.

Now after every rolling upgrade I seem to run into this error with atleast one of my node. The index name always points to a closed index. The error occurs only on restart (never while elasticsearch is running).

I find it hard to believe that all 5 of my nodes have a disk problem because:
- I have run `fsck` everytime this error has occurred and no errors have been reported.
- Elasticsearch runs without a problem for days on end (A disk error or other programs corrupting the data would cause running elasticsearch to crash as had happended on one of my nodes about a year back).

Yesterday we had a power issue at the data-center which led to all nodes getting power cycled. Upon restart 4 out of 5 modes failed to start with same errors. On all 4 nodes, the names of indexes was different (The indexes in question were ""closed""). I had no option but to delete all data on those 4 nodes (Thus losing about 80% of elasticsearch data).

The errors seen were

```
[2019-09-30T10:36:58,205][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [esnode3] uncaught exception in thread [main]
org.elasticsearch.bootstrap.StartupException: ElasticsearchException[failed to bind service]; nested: IOException[failed to find metadata for existing index ssl-2019.09.20 [location: GmslGWkHTLGQowmMHFut7A, generation: 11]];
        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:163) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:150) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-7.3.2.jar:7.3.2]
        at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:115) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-7.3.2.jar:7.3.2]
Caused by: org.elasticsearch.ElasticsearchException: failed to bind service
        at org.elasticsearch.node.Node.<init>(Node.java:617) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.node.Node.<init>(Node.java:258) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) ~[elasticsearch-7.3.2.jar:7.3.2]
        ... 6 more
Caused by: java.io.IOException: failed to find metadata for existing index ssl-2019.09.20 [location: GmslGWkHTLGQowmMHFut7A, generation: 11]
        at org.elasticsearch.gateway.MetaStateService.loadFullState(MetaStateService.java:99) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.gateway.GatewayMetaState.upgradeMetaData(GatewayMetaState.java:141) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.gateway.GatewayMetaState.<init>(GatewayMetaState.java:95) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.node.Node.<init>(Node.java:492) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.node.Node.<init>(Node.java:258) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) ~[elasticsearch-7.3.2.jar:7.3.2]
        ... 6 more
[2019-09-30T10:36:58,210][INFO ][o.e.x.m.p.NativeController] [esnode3] Native controller process has stopped - no new native processes can be started
```


and

```
[2019-09-30T10:39:59,737][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [esnode2] uncaught exception in thread [main]
org.elasticsearch.bootstrap.StartupException: ElasticsearchException[failed to bind service]; nested: IOException[failed to find metadata for existing index dns-2019.09.22 [location: ZMenLry9Qxe5-2-XNrWj2A, generation: 15]];
        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:163) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:150) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-7.3.2.jar:7.3.2]
        at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:115) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-7.3.2.jar:7.3.2]
Caused by: org.elasticsearch.ElasticsearchException: failed to bind service
        at org.elasticsearch.node.Node.<init>(Node.java:617) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.node.Node.<init>(Node.java:258) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) ~[elasticsearch-7.3.2.jar:7.3.2]
        ... 6 more
Caused by: java.io.IOException: failed to find metadata for existing index dns-2019.09.22 [location: ZMenLry9Qxe5-2-XNrWj2A, generation: 15]
        at org.elasticsearch.gateway.MetaStateService.loadFullState(MetaStateService.java:99) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.gateway.GatewayMetaState.upgradeMetaData(GatewayMetaState.java:141) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.gateway.GatewayMetaState.<init>(GatewayMetaState.java:95) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.node.Node.<init>(Node.java:492) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.node.Node.<init>(Node.java:258) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:221) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) ~[elasticsearch-7.3.2.jar:7.3.2]
        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:159) ~[elasticsearch-7.3.2.jar:7.3.2]
        ... 6 more
```

Is it possible that data of closed indexes is not being persisted properly (leading to issues at restart)? Can this be mitigated somehow (Maybe rolling back to less stronger consistency checks)?

","Can you clarify that point for us? If this only affects data-only nodes we might be able to provide instructions on how to get the node running again, without losing data.","@ywelsch Thanks for looking at this

- These are not master eligible nodes. There are 3 other master elegible nodes in the cluster (which don't store any data). While doing a rolling upgrade, the script processes all the master eligible nodes first and then moves to data nodes.

All data nodes (the kind which show failure) have similar config to one given below

```
cluster.name: nemo-cluster 

node.name: esnode1

bootstrap.memory_lock: true
network.host: _site:ipv4_
discovery.zen.ping.unicast.hosts: 
    - 10.44.0.43
    - 10.44.0.44
    - 10.44.0.45
    
discovery.zen.minimum_master_nodes: 1

# Fix 9201 for intra cluster comm
transport.port: 9201

path.logs: /var/log/elasticsearch
path.data: /data/elasticsearch

# Settings related to node

node.master: false
node.data: true
node.ingest: true

# Monitoring settings (6.3+)
xpack.monitoring.enabled: true

```

The master elgible nodes are `10.44.0.43,44,45` which don't show any failure.

- Closed indices are mostly created on 7.x. For the latest issue, the indices mentioned in the logs above were created using 7.x"
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/46070,"The decuded mappings introduced in #43742 seems to miss exposing mappings based on scripted fields. For example, using the following in Kibana Dev Console:

```json
POST _data_frame/transforms/_preview
{
  ""source"": {
    ""index"": [
      ""filebeat-nginx-elasticco-anon-2017""
    ]
  },
  ""pivot"": {
    ""group_by"": {
      ""source.address"": {
        ""terms"": {
          ""field"": ""source.address""
        }
      }
    },
    ""aggregations"": {
      ""@timestamp_max"": {
        ""max"": {
          ""field"": ""@timestamp""
        }
      },
      ""@timestamp_min"": {
        ""min"": {
          ""field"": ""@timestamp""
        }
      },
      ""duration"": {
        ""bucket_script"": {
          ""buckets_path"": {
            ""min"": ""@timestamp_min"",
            ""max"": ""@timestamp_max""
          },
          ""script"": ""(params.max - params.min)/1000""
        }
      }
    }
  }
}
```

Will return:

```
{
  ""preview"" : [
    {
      ""duration"" : 3236636.783,
      ""@timestamp_min"" : ""2017-02-01T06:02:10.303Z"",
      ""@timestamp_max"" : ""2017-03-10T17:06:07.086Z"",
      ""source"" : {
        ""address"" : """"
      }
    },
    ...
   {
      ""duration"" : 0.0,
      ""@timestamp_min"" : ""2017-02-09T08:07:07.963Z"",
      ""@timestamp_max"" : ""2017-02-09T08:07:07.963Z"",
      ""source"" : {
        ""address"" : ""0.104.130.123""
      }
    }
  ],
  ""mappings"" : {
    ""properties"" : {
      ""@timestamp_min"" : {
        ""type"" : ""date""
      },
      ""@timestamp_max"" : {
        ""type"" : ""date""
      },
      ""source.address"" : {
        ""type"" : ""keyword""
      }
    }
  }
}
```

You can see that `duration` is part of the preview documents, but it's missing from the `mappings` part.

This affects the Kibana data frame transforms wizard in `7.3+`: For the transforms preview table, the columns visible are based on the `mappings`, so the `duration` column will not show up at all.","Why not make the columns that are visible be the fields in the preview objects? We return a set number of them, so iterating through them and picking out the unique field names seems more reliable. ",@benwtrent Thanks for clarifying! We can definitely fix it on the client side I was just not aware that there's a chance that fields would not be part of the mapping. I created a [corresponding issue in the Kibana repo](https://github.com/elastic/kibana/issues/44251) and will close this one. 
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/45594,"**Steps**

1. Create a repository with a slow write rate, like 1kb
2. Create policy that uses the slow repo
3. Execute that policy, observe that a snapshot is in progress, and the policy information includes in progress information
4. Execute the policy again while the snapshot hasn't finished, observe that the request hangs and eventually times out with a 504 response code","Can you describe how you reproduced this in more detail? When I run through the same behavior the second execute call returns with the snapshot name, which then fails (as expected) with a warning in the logs and registers it as a failed snapshot in the SLM policy

```
[elasticsearch] [2019-08-15T08:35:23,107][INFO ][o.e.x.s.SnapshotLifecycleTask] [node-0] snapshot lifecycle policy [daily-snapshots] issuing create snapshot [production-snap-2019.08.15-sdycfgceq1ozhvqhbdhyfg]
[elasticsearch] [2019-08-15T08:35:23,145][INFO ][o.e.s.SnapshotsService   ] [node-0] snapshot [repo:production-snap-2019.08.15-sdycfgceq1ozhvqhbdhyfg/eXVrbzxrRHmceBWpy70iPQ] started
[elasticsearch] [2019-08-15T08:35:23,188][INFO ][o.e.c.m.MetaDataCreateIndexService] [node-0] [.slm-history-1-2019.08] creating index, cause [auto(bulk api)], templates [.slm-history], shards [1]/[0], mappings [_doc]


[elasticsearch] [2019-08-15T08:35:27,333][INFO ][o.e.x.s.SnapshotLifecycleTask] [node-0] snapshot lifecycle policy [daily-snapshots] issuing create snapshot [production-snap-2019.08.15-e4coq5clrdaatbhcbzb93q]
[elasticsearch] [2019-08-15T08:35:27,356][WARN ][o.e.s.SnapshotsService   ] [node-0] [repo][production-snap-2019.08.15-e4coq5clrdaatbhcbzb93q] failed to create snapshot
[elasticsearch] org.elasticsearch.snapshots.ConcurrentSnapshotExecutionException: [repo:production-snap-2019.08.15-e4coq5clrdaatbhcbzb93q]  a snapshot is already running
[elasticsearch] 	at org.elasticsearch.snapshots.SnapshotsService$1.execute(SnapshotsService.java:286) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:697) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:319) ~[elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:214) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:151) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:699) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT]
[elasticsearch] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
[elasticsearch] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
[elasticsearch] 	at java.lang.Thread.run(Thread.java:834) [?:?]
```

Repo/policy I'm using:

```
PUT /_snapshot/repo
{
  ""type"": ""fs"",
  ""settings"": {
    ""location"": ""repo"",
    ""max_snapshot_bytes_per_sec"": ""10b""
  }
}

PUT /_slm/policy/daily-snapshots
{
  ""schedule"": ""1 2 3 * * ?"",
  ""name"": ""<production-snap-{now/d}>"",
  ""repository"": ""repo"",
  ""config"": {
    ""indices"": [""foo-*"", ""important""],
    ""ignore_unavailable"": true,
    ""include_global_state"": false
  }
}
```","@dakrone The approximate total size of my indices is 22mb and I set my repo to 1kb per second. Here is a sequence of my requests:

```json
# Repo configuration
# GET /_snapshot/slow-repo
{
  ""slow-repo"" : {
    ""type"" : ""fs"",
    ""settings"" : {
      ""location"" : ""test"",
      ""max_snapshot_bytes_per_sec"" : ""1kb""
    }
  }
}

# Policy configuration
# GET /_slm/policy/slow-test
{
  ""slow-test"" : {
    ""version"" : 1,
    ""modified_date_millis"" : 1565885533675,
    ""policy"" : {
      ""name"" : ""slow-test"",
      ""schedule"" : ""0 0 0 ? * 7"",
      ""repository"" : ""slow-repo"",
      ""config"" : { }
    },
    ""next_execution_millis"" : 1566000000000
  }
}

# Executing policy the first time
# PUT /_slm/policy/slow-test/_execute
{
  ""snapshot_name"" : ""slow-test-_wl2wwbpseudgpqlbosnnq""
}

# Checking policy information after executing - in progress information is listed
# GET /_slm/policy/slow-test
{
  ""slow-test"" : {
    ""version"" : 1,
    ""modified_date_millis"" : 1565885533675,
    ""policy"" : {
      ""name"" : ""slow-test"",
      ""schedule"" : ""0 0 0 ? * 7"",
      ""repository"" : ""slow-repo"",
      ""config"" : { }
    },
    ""last_success"" : {
      ""snapshot_name"" : ""slow-test-_wl2wwbpseudgpqlbosnnq"",
      ""time"" : 1565885694939
    },
    ""next_execution_millis"" : 1566000000000,
    ""in_progress"" : {
      ""name"" : ""slow-test-_wl2wwbpseudgpqlbosnnq"",
      ""uuid"" : ""9kEheisWQ5i_4IlT0AamMg"",
      ""state"" : ""STARTED"",
      ""start_time_millis"" : 1565885694668
    }
  }
}

# Executing policy the second time time - it times out
# PUT /_slm/policy/slow-test/_execute
{
  ""statusCode"": 504,
  ""error"": ""Gateway Time-out"",
  ""message"": ""Client request timeout""
}
```

The failure from the second execution does not show up in in policy information or ES logs **until** I delete the snapshot that is currently in progress. "
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/45247,"**Elasticsearch version** (`bin/elasticsearch --version`): 7.3 (cloud)

**JVM version** (`java -version`): Cloud

**OS version** (`uname -a` if on a Unix-like system): Cloud

**Description of the problem including expected versus actual behavior**:
Since upgrading to 7.3 on my cloud cluster I have been unable to create working rollup jobs. If I create one via API I get a success beck, but then the job does not show up when I try to GET it and I'm told the task doesn't exist if I try to delete it. At the same time if I try to create it again I'm told one with that id already exists, if I delete that I'm then told the metadata exists, if I delete the rollup index I'm then still told a task with that id exists. I've found not way to view or delete the task if that's separate from the job. Trying again with a new id ""works"" and then repeats this pattern of being invisible and unable to start because it ""doesn't exist"" even though it ""already exists"" when creating anew.

I've also tried to create the job via Kibana with problems. I get an error on creation ""Request failed with a error. An internal server error occurred."" followed by the same issues about the job already existing while it's also not showing up on the list of jobs. I did once or twice get a job with no terms or metrics to create, but even then that seems to mostly fail. The log shows the following error when creating via kibana (note that this happens even with most ""empty"" jobs that don't mention the heat_set_point field, which is one I am trying to target with the real job).

[instance-0000000004] failed to notify ClusterStateListener java.lang.IllegalArgumentException: Two sibling aggregations cannot have the same name: [heat_set_point.avg._count] at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.addAggregator(AggregatorFactories.java:298) ~[elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.subAggregation(AbstractAggregationBuilder.java:80) ~[elasticsearch-7.3.0.jar:7.3.0] at java.util.ArrayList.forEach(ArrayList.java:1540) ~[?:?] at java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1083) ~[?:?] at org.elasticsearch.xpack.rollup.job.RollupIndexer.createCompositeBuilder(RollupIndexer.java:166) ~[?:?] at org.elasticsearch.xpack.rollup.job.RollupIndexer.<init>(RollupIndexer.java:94) ~[?:?] at org.elasticsearch.xpack.rollup.job.RollupIndexer.<init>(RollupIndexer.java:78) ~[?:?] at org.elasticsearch.xpack.rollup.job.RollupJobTask$ClientRollupPageManager.<init>(RollupJobTask.java:103) ~[?:?] at org.elasticsearch.xpack.rollup.job.RollupJobTask.<init>(RollupJobTask.java:210) ~[?:?] at org.elasticsearch.xpack.rollup.job.RollupJobTask$RollupJobPersistentTasksExecutor.createTask(RollupJobTask.java:85) ~[?:?] at org.elasticsearch.persistent.PersistentTasksNodeService$1.createTask(PersistentTasksNodeService.java:163) ~[elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.tasks.TaskManager.register(TaskManager.java:114) ~[elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.persistent.PersistentTasksNodeService.startTask(PersistentTasksNodeService.java:166) ~[elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.persistent.PersistentTasksNodeService.clusterChanged(PersistentTasksNodeService.java:115) ~[elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.cluster.service.ClusterApplierService.lambda$callClusterStateListeners$6(ClusterApplierService.java:503) [elasticsearch-7.3.0.jar:7.3.0] at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:?] at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734) [?:?] at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658) [?:?] at org.elasticsearch.cluster.service.ClusterApplierService.callClusterStateListeners(ClusterApplierService.java:500) [elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:477) [elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:418) [elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:165) [elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:688) [elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.3.0.jar:7.3.0] at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.3.0.jar:7.3.0] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?] at java.lang.Thread.run(Thread.java:834) [?:?]

","Could you paste the output of `GET /_rollup/data/_all` ?  I'd like to see what jobs are on the cluster currently.  I'm thinking one of them might have invalid syntax (which we missed when the job was created) which is breaking things later.

","Ah, I was unaware of that endpoint. I had been doing GET /_rollup/job/* to list jobs and was seeing nothing. This list however is a bit big and includes data from a bunch of deleted jobs. The rollup indexes are deleted too. Is there a way to clean these out?"
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/44970,"**Elasticsearch version** (`bin/elasticsearch --version`): 7.2, 7.3

**Plugins installed**: []

**JVM version** (`java -version`): Bundled JDK

**OS version** (`uname -a` if on a Unix-like system): ESS and Darwin Kernel Version 18.6.0

**Description of the problem including expected versus actual behavior**: Watcher web hook actions do not return a 200 status code for POST requests.

**Steps to reproduce**: Execute a watch with a webhook action.

Please include a *minimal* but *complete* recreation of the problem, including
(e.g.) index creation, mappings, settings, query etc.  The easier you make for
us to reproduce it, the more likely that somebody will take the time to look at it.

 1. Create watch with a webhook action.
 2. Force execute watch, or wait for it to trigger

As of `7.2`, webhook actions are are returning a `302` http status code for POST requests, as opposed to `200`. After some initial discussions with @jakelandis, there is nothing obvious in the codebase that would cause this.

The same exact webhook action in `7.1` and below works fine. All other http clients (tested with curl, wget and postman) all return the expected response. 

This has been tested (an initially spotted) in ESS, and also on my MBP.","can you provide a reproducible example here? I tried this and this properly returns 200, so there must be something else that you are doing

```
POST _watcher/watch/_execute
{
  ""watch"": {
    ""trigger"": {
      ""schedule"": {
        ""interval"": ""10h""
      }
    },
    ""input"": {
      ""http"": {
        ""request"": {
          ""url"" : ""https://httpbin.org/status/200""
        }
      }
    },
    ""actions"": {
      ""logme"": {
        ""logging"": {
          ""text"": ""{{ctx.payload._status_code}}""
        }
      }
    }
  }
}
```

I also tried `https://www.elastic.co/` as an URL, and that one also returned the proper error code.","Hey @spinscale ,

Here is one of the watches:

```
{
  ""trigger"": {
    ""schedule"": {
      ""interval"": ""1m""
    }
  },
  ""input"": {
    ""search"": {
      ""request"": {
        ""search_type"": ""query_then_fetch"",
        ""indices"": [
          ""ct-*""
        ],
        ""rest_total_hits_as_int"": true,
        ""body"": {
          ""query"": {
            ""bool"": {
              ""must"": [
                {
                  ""query_string"": {
                    ""query"": ""dns_name:*.swiftcrypto.com AND log_entry_stage.keyword :\""Certificate\""""
                  }
                },
                {
                  ""range"": {
                    ""@timestamp"": {
                      ""gte"": ""now-1m""
                    }
                  }
                }
              ]
            }
          },
          ""sort"": [
            {
              ""@timestamp"": {
                ""order"": ""desc""
              }
            }
          ]
        }
      }
    }
  },
  ""condition"": {
    ""compare"": {
      ""ctx.payload.hits.total"": {
        ""gt"": 0
      }
    }
  },
  ""actions"": {
    ""stdlib"": {
      ""webhook"": {
        ""scheme"": ""https"",
        ""host"": ""jamesspi.lib.id"",
        ""port"": 443,
        ""method"": ""post"",
        ""path"": ""/swiftcrypto-sec-bot@dev/ct/"",
        ""params"": {},
        ""headers"": {
          ""Content-Type"": ""application/x-www-form-urlencoded""
        },
        ""body"": ""dnsname={{#ctx.payload.hits.hits}}{{_source.dns_name}},{{/ctx.payload.hits.hits}}&title=New%20Certificate%20Detected&title_url=https://ffa0e3abcb444c9ab93ffcefcbdb60a8.europe-west1.gcp.cloud.es.io:9243/app/kibana#/doc/2ecb6bd0-1d85-11e9-85c5-335acafba1db/ct-*/doc?id={{ctx.payload.hits.hits.0._id}}&_g=()&text={{ctx.payload.hits.total}}%20New%20certificates%20have%20been%20created%20according%20to%20certificate%20transparency%20logs%20in%20the%20last%20minute.&issuer={{#ctx.payload.hits.hits}}{{_source.issuer_organisation}},{{/ctx.payload.hits.hits}}&entry={{#ctx.payload.hits.hits}}{{_source.log_entry_url}},{{/ctx.payload.hits.hits}}&main_text=SwiftCrypto%20Alert%20""
      }
    }
  },
  ""throttle_period_in_millis"": 3000
}
```

As described, it is only returning `302` for `POST` requests. In your example, you're making a `GET` request. `GET` is still working as expected.

Here is a doc if you want to try:

```
{
    ""Pubkey"": ""d9a7713ba8ea233f3580feade68be568d7246baba8cf540022a365c3f600a687"",
    ""log_entry_id"": ""673984766"",
    ""@timestamp"": ""2019-08-04T01:10:04.016Z"",
    ""log_entry_stage"": ""Certificate"",
    ""dns_name"": ""loader.swiftcrypto.com"",
    ""sha256"": ""476719470ca9028146cd5831623bf2eb149e71b0f12dee5aa048852b25f80b63"",
    ""certificate_expiry_date"": ""2019-11-02T00:08:00.000Z"",
    ""issuer_organisation"": ""Let's Encrypt"",
    ""certificate_generation_date"": ""2019-08-04T00:08:00.000Z"",
    ""issuer_country_code"": ""US"",
    ""issuer_common_name"": ""Let's Encrypt Authority X3"",
    ""log_entry_url"": ""https://ct.googleapis.com/logs/argon2019/""
  }
```
"
elastic/elasticsearch,https://github.com/elastic/elasticsearch/issues/44172,"Copy - paste from here https://discuss.elastic.co/t/pushing-auto-follow-pattern-results-in-a-null-pointer-exception-on-elasticsearch-side/189666/2

<!-- Bug report -->

**Elasticsearch version** (`bin/elasticsearch --version`):
6.8.1
**Plugins installed**: []
none.

**JVM version** (`java -version`):
openjdk version ""1.8.0_212""
OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_212-b04)
OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.212-b04, mixed mode)

**OS version** (`uname -a` if on a Unix-like system):
Linux ip-10-176-68-180 4.14.62-65.117.amzn1.x86_64 #1 SMP Fri Aug 10 20:03:52 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

**Description of the problem including expected versus actual behavior**:


So, we installed elasticsearch 6.8.1 on 6 nodes and are trying to setup CCR with two clusters - 3 nodes each. License is activated and valid, remote settings are set (seed, nodes and cluster name). But now, somehow when I try to push the autofollow pattern like this

``` 
curl -X PUT ""localhost:9200/_ccr/auto_follow/AutoFollowerPatterns"" -H 'Content-Type: application/json' -d'
{
  ""remote_cluster"" : ""elastic-uswest"",
  ""leader_index_patterns"" :
  [
    ""visit*""
  ],
  ""follow_index_pattern"" : ""ccr-{{leader_index}}""
}
'
``` 
it results into that response:

```
{
  ""error"" : {
    ""root_cause"" : [
      {
        ""type"" : ""remote_transport_exception"",
        ""reason"" : ""[10.176.70.184][10.176.70.184:9300][cluster:admin/xpack/ccr/auto_follow_pattern/put]""
      }
    ],
    ""type"" : ""null_pointer_exception"",
    ""reason"" : null
  },
  ""status"" : 500
}
```
Digging a bit deeper into the logs of elasticsearch, we can see this message:
```
[2019-07-09T10:10:49,510][WARN ][r.suppressed             ] [10.176.68.180] path: /_ccr/auto_follow/AutoFollowerPatterns, params: {name=AutoFollowerPatterns}
org.elasticsearch.transport.RemoteTransportException: [10.176.69.160][10.176.69.160:9300][cluster:admin/xpack/ccr/auto_follow_pattern/put]
Caused by: java.lang.NullPointerException
        at org.elasticsearch.xpack.ccr.CcrLicenseChecker.hasPrivilegesToFollowIndices(CcrLicenseChecker.java:318) ~[?:?]
        at org.elasticsearch.xpack.ccr.action.TransportPutAutoFollowPatternAction.lambda$masterOperation$2(TransportPutAutoFollowPatternAction.java:88) ~[?:?]
        at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.action.support.ContextPreservingActionListener.onResponse(ContextPreservingActionListener.java:43) ~[elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.action.ActionListenerResponseHandler.handleResponse(ActionListenerResponseHandler.java:54) ~[elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleResponse(TransportService.java:1104) ~[elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.transport.TcpTransport$1.doRun(TcpTransport.java:985) ~[elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.common.util.concurrent.EsExecutors$DirectExecutorService.execute(EsExecutors.java:193) ~[elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.transport.TcpTransport.handleResponse(TcpTransport.java:977) [elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.transport.TcpTransport.messageReceived(TcpTransport.java:952) [elasticsearch-6.8.1.jar:6.8.1]
        at org.elasticsearch.transport.TcpTransport.inboundMessage(TcpTransport.java:763) [elasticsearch-6.8.1.jar:6.8.1]
...
```
Our initial thought was, that the security module could cause the error - because of this word in the exception: hasPrivilegesToFollowIndices. So, we removed all unnecessary modules and the error still occurs.

**Installed modules:**
![image](https://user-images.githubusercontent.com/12306801/60977862-7482d600-a330-11e9-9df9-a252d9ee3b5b.png)


**Steps to reproduce**:
Sadly, I cannot reproduce the bug. When I tried it, it always worked fine. It happened on this one particular environment and now we cannot fix it. 

","Do you see any ""failed to read authentication"" error log messages with an accompanying exception message and stack trace in the logs, around the time that this occurred?",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1358,"<!--
GitHub is reserved *only* for bug reports and feature requests. The best place
to ask a general question is at the Elastic forums at
https://discuss.elastic.co/c/elasticsearch-and-hadoop.
If you are in fact posting a bug report or a feature request, please 
include one and only one of the below blocks in your new issue.
-->

### What kind an issue is this?

- [ * ] Bug report. If you’ve found a bug, please provide a code snippet or test to reproduce it below.   
    The easier it is to track down the bug, the faster it is solved. 
- [ ] Feature Request. Start by telling us what problem you’re trying to solve.  
    Often a solution already exists! Don’t send pull requests to implement new features without 
    first getting our support. Sometimes we leave features out on purpose to keep the project small.

<!--
If you are filing a bug report, please fill provide responses for all 
of the below items.
Remove the feature block.
-->

### Issue description

I am developing part of spark (v2.4.3) which reads elasticsearch (v7.3.0) on spring-boot 2 (web) using es-hadoop (v7.3.1).

** ref https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html

When I run it with ""mvn spring-boot:run"" it works fine.

But, When I run it with ""java -jar output.jar"", JavaEsSpark make error about accessing elasticsearch. I thought in many ways but I don't know why.

""ExceptionInInitializerError: null .. RestService"" 
""sql.DefaultSource15 could not be instantiated"" 
""URI is not a hierarchical .. version.""

I ask for your help (-.-)

** ps. I checked packages in jar file. => OK. I tried with SparkSession, but also fail. (java -jar execution)

** my code https://github.com/maxmin93/agens-spark/blob/master/src/main/java/net/bitnine/agensspark/AgenssparkApplication.java

### Steps to reproduce

Code:

```java
LOGGER.info(""SpringBootSpark To Elasticsearch Application: {}, {}, {}, {}""
                , appName, nodes, port, sparkHome);

String master = ""local[*]"";
SparkConf conf = new SparkConf()
        .setAppName(appName)
        .setSparkHome(sparkHome)
        .setMaster(master)
                .set(""spark.executor.memory"", ""2g"")
        .set(""spark.driver.memory"", ""2g"")
        .set(""spark.eventLog.enabled"",""false"")
        .set(""es.nodes.wan.only"", ""true"")
        .set(""es.nodes"", nodes)
        .set(""es.port"", port)
        .set(""es.mapping.id"", ""id"")
        .set(""es.write.operation"", ""upsert"")
        .set(""es.index.read.missing.as.empty"", ""true"");

        JavaSparkContext jsc = new JavaSparkContext(conf);

// for DEBUG
System.out.println(""\n\n==================================\n"");
System.out.println(Arrays.stream(jsc.getConf().getAll()).map(t->{
    return t._1()+""=""+t._2();
}).collect(Collectors.joining("", "")));

JavaPairRDD<String, Map<String, Object>> esRDD =
    JavaEsSpark.esRDD(jsc, resource, ""?q=datasource:sample"");
System.out.println(""\n**count = ""+esRDD.count());
```

Strack trace:

```
java.lang.ExceptionInInitializerError: null
	at org.elasticsearch.hadoop.rest.RestService.findPartitions(RestService.java:216) ~[elasticsearch-hadoop-7.3.1.jar!/:7.3.1]
	at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions$lzycompute(AbstractEsRDD.scala:79) ~[elasticsearch-hadoop-7.3.1.jar!/:7.3.1]
	at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions(AbstractEsRDD.scala:78) ~[elasticsearch-hadoop-7.3.1.jar!/:7.3.1]
	at org.elasticsearch.spark.rdd.AbstractEsRDD.getPartitions(AbstractEsRDD.scala:48) ~[elasticsearch-hadoop-7.3.1.jar!/:7.3.1]
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253) ~[spark-core_2.11-2.4.3.jar!/:2.4.3]
...
Caused by: java.lang.IllegalArgumentException: URI is not hierarchical
	at java.io.File.<init>(File.java:418) ~[na:1.8.0_121]
	at org.elasticsearch.hadoop.util.IOUtils.toCanonicalFilePath(IOUtils.java:242) ~[elasticsearch-hadoop-7.3.1.jar!/:7.3.1]
	at org.elasticsearch.hadoop.util.Version.<clinit>(Version.java:66) ~[elasticsearch-hadoop-7.3.1.jar!/:7.3.1]
	... 27 common frames omitted
``` 

### Version Info

OS:         :  MacOS lastest
JVM         :  1.8
Hadoop/Spark:  null/2.4.3
ES-Hadoop   :  7.3.1
ES          :  7.3.0

<!--
If you are filing a feature request, please remove the above bug
report block and provide responses for all of the below items.
-->

### Feature description
",How are you constructing your jar file for your operation? Are you adding ES-Hadoop as a jar to your classpath? Are you repackaging it in with your client code in a new jar? The error indicates that the path to the Version.class file is not hierarchical which means that it may not be packaged correctly or accessable in a way that ES-Hadoop expects it to be.,"Thanks a lot of your reply.

Spring boot executable jar is made by spring-boot-maven-plugin in pom.xml as normally. And I exactly declared dependency about ""es-hadoop"" or ""es-spark"". And I made sure confirm the existence of dependency libraries on my target jar file.

** my pom.xml
https://github.com/maxmin93/agens-spark/blob/master/pom.xml

** p.s
Above that git repository is the one only for testing JavaEsSpark with just application main.

I tried another way like as using CLASSPATH env variable or run jar with -Dload.path or -cp, so on..
But all did not work. And I tried using local maven repository although maven can access es-hadoop libraries through Central repository.

I have been holding this problem for over a few week. OTL

----------------
java -jar target/agensspark-0.0.1-SNAPSHOT.jar -Dloader.path=/Users/bgmin/Servers/es-hadoop/dist/

jar -tf agensspark-0.0.1-SNAPSHOT.jar (<-- my target jar file)
==>
BOOT-INF/lib/elasticsearch-hadoop-7.3.2.jar
...
BOOT-INF/lib/hadoop-annotations-2.6.5.jar
BOOT-INF/lib/hadoop-auth-2.6.5.jar
BOOT-INF/lib/hadoop-client-2.6.5.jar
BOOT-INF/lib/hadoop-common-2.6.5.jar
BOOT-INF/lib/hadoop-hdfs-2.6.5.jar
BOOT-INF/lib/hadoop-mapreduce-client-app-2.6.5.jar
BOOT-INF/lib/hadoop-mapreduce-client-common-2.6.5.jar
BOOT-INF/lib/hadoop-mapreduce-client-core-2.6.5.jar
BOOT-INF/lib/hadoop-mapreduce-client-jobclient-2.6.5.jar
BOOT-INF/lib/hadoop-mapreduce-client-shuffle-2.6.5.jar
BOOT-INF/lib/hadoop-yarn-api-2.6.5.jar
BOOT-INF/lib/hadoop-yarn-client-2.6.5.jar
BOOT-INF/lib/hadoop-yarn-common-2.6.5.jar
BOOT-INF/lib/hadoop-yarn-server-common-2.6.5.jar
..
BOOT-INF/lib/spark-catalyst_2.11-2.4.3.jar
BOOT-INF/lib/spark-core_2.11-2.4.3.jar
BOOT-INF/lib/spark-graphx_2.11-2.4.3.jar
BOOT-INF/lib/spark-kvstore_2.11-2.4.3.jar
BOOT-INF/lib/spark-launcher_2.11-2.4.3.jar
BOOT-INF/lib/spark-mllib-local_2.11-2.4.3.jar
BOOT-INF/lib/spark-network-common_2.11-2.4.3.jar
BOOT-INF/lib/spark-network-shuffle_2.11-2.4.3.jar
BOOT-INF/lib/spark-sketch_2.11-2.4.3.jar
BOOT-INF/lib/spark-sql_2.11-2.4.3.jar
BOOT-INF/lib/spark-tags_2.11-2.4.3.jar
BOOT-INF/lib/spark-unsafe_2.11-2.4.3.jar
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1198,"I was saving my dataframe to es using es-hadoop connector:

Dataframe code was like this:
    val someData = Seq(
      Row(8, ""Däniken			12Erich von""),
      Row(64, ""mouse12""),
      Row(-27, ""horse12""))

    val someSchema = List(
      StructField(""number"", IntegerType, true),
      StructField(""key"", StringType, true))

    val someDF = sparkSession.createDataFrame(
      sparkSession.sparkContext.parallelize(someData),
      StructType(someSchema))
      someDF

Thereafter, changed dataframe to add additional field to the document.


val someData = Seq(
      Row(8, ""Dniken	12Erich von"", "" "" ),
      Row(64, ""mouse12"", "" ""),
      Row(-27, ""horse12"", "" ""))

    val someSchema = List(
      StructField(""number"", IntegerType, true),
      StructField(""key"", StringType, true),StructField(""key1"", StringType, true))

    val someDF = sparkSession.createDataFrame(
      sparkSession.sparkContext.parallelize(someData),
      StructType(someSchema))
      someDF


Getting following exception:

Exception in thread ""main"" org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Illegal unquoted character ((CTRL-CHAR, code 9)): has to be escaped using backslash to be included in string value
 at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@712a668e; line: 1, column: 26]
	at org.elasticsearch.hadoop.rest.RestClient.checkResponse(RestClient.java:424)
	at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:382)
	at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:364)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:216)
	at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.tryFlush(BulkProcessor.java:185)
	at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.flush(BulkProcessor.java:460)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.delete(RestRepository.java:402)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.insert(DefaultSource.scala:582)
	at org.elasticsearch.spark.sql.DefaultSource.createRelation(DefaultSource.scala:104)
	at org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:426)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:215)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:198)


OS:         :  
JVM         :  1.8
Hadoop/Spark: 2.1  
ES-Hadoop   :  6.2.1
ES          :  6.2.4

Note: This happen when i have defined ""es.mapping.id"" as ""KEY""
",Can you provide trace level logs from the `org.elasticsearch.hadoop.rest.commonshttp` package?,"018-10-08 09:29:02,541 DEBUG commonshttp.CommonsHttpTransportFactory - Creating new CommonsHttpTransport
2018-10-08 09:29:02,575 TRACE commonshttp.CommonsHttpTransport - Opening HTTP transport to 1xx.xx.xxx.xxx:9200
2018-10-08 09:29:02,583 TRACE commonshttp.CommonsHttpTransport - Tx [GET]@[1xx.xx.xxx.xxx:9200][]?[null] w/ payload [null]
2018-10-08 09:29:03,101 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [200-OK] [{
  ""name"" : ""elasticsearch-271802973-19-393763619.p.com-data"",
  ""cluster_name"" : ""test-cluster"",
  ""cluster_uuid"" : ""iD02rOP8R72VK-mr-jltWw"",
  ""version"" : {
    ""number"" : ""6.2.4"",
    ""build_hash"" : ""ccec39f"",
    ""build_date"" : ""2018-04-12T20:37:28.497551Z"",
    ""build_snapshot"" : false,
    ""lucene_version"" : ""7.2.1"",
    ""minimum_wire_compatibility_version"" : ""5.6.0"",
    ""minimum_index_compatibility_version"" : ""5.0.0""
  },
  ""tagline"" : ""You Know, for Search""
}
]
2018-10-08 09:29:03,133 TRACE commonshttp.CommonsHttpTransport - Closing HTTP transport to 1xx.xx.xxx.xxx:9200
2018-10-08 09:29:03,138 DEBUG commonshttp.CommonsHttpTransportFactory - Creating new CommonsHttpTransport
2018-10-08 09:29:03,138 TRACE commonshttp.CommonsHttpTransport - Opening HTTP transport to 1xx.xx.xxx.xxx:9200
2018-10-08 09:29:03,139 TRACE commonshttp.CommonsHttpTransport - Tx [HEAD]@[1xx.xx.xxx.xxx:9200][index]?[null] w/ payload [null]
2018-10-08 09:29:03,661 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [200-OK] [null]
2018-10-08 09:29:03,662 TRACE commonshttp.CommonsHttpTransport - Tx [HEAD]@[1xx.xx.xxx.xxx:9200][index/_mapping/docs]?[null] w/ payload [null]
2018-10-08 09:29:03,912 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [200-OK] [null]
2018-10-08 09:29:03,914 TRACE commonshttp.CommonsHttpTransport - Tx [DELETE]@[1xx.xx.xxx.xxx:9200][index/docs/_query]?[q=*] w/ payload [null]
2018-10-08 09:29:04,164 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [400-Bad Request] [{""error"":{""root_cause"":[{""type"":""illegal_argument_exception"",""reason"":""request [/index/docs/_query] contains unrecognized parameter: [q]""}],""type"":""illegal_argument_exception"",""reason"":""request [/index/docs/_query] contains unrecognized parameter: [q]""},""status"":400}]
2018-10-08 09:29:04,176 INFO  rest.RestRepository - Skipping delete by query as the plugin is not installed...
2018-10-08 09:29:04,183 TRACE commonshttp.CommonsHttpTransport - Tx [POST]@[1xx.xx.xxx.xxx:9200][index/docs/_search]?[scroll=10m&_source=false&size=500&sort=_doc] w/ payload [null]
2018-10-08 09:29:04,437 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [200-OK] [{""_scroll_id"":""DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAOWFjJJWWxPY3c1VHBhTFJOb3FTYXZzakEAAAAAAAADwRY0RnZjMFlRcVItMjU4RVl1UjlhZXJ3AAAAAAAAAsoWaGh2MHV0LTNRYVdaMS03SEx5OUM5dwAAAAAAAALLFmI0c2M2NjAtUlRtcmg0R294X2RNOGcAAAAAAAAFrhZNU3NSM1IxY1JOeTlNTHZDMzBSMDdB"",""took"":4,""timed_out"":false,""_shards"":{""total"":5,""successful"":5,""skipped"":0,""failed"":0},""hits"":{""total"":3,""max_score"":null,""hits"":[{""_index"":""index"",""_type"":""docs"",""_id"":""mouse12"",""_score"":null,""sort"":[0]},{""_index"":""index"",""_type"":""docs"",""_id"":""Däniken\t12Erich von"",""_score"":null,""sort"":[0]},{""_index"":""index"",""_type"":""docs"",""_id"":""horse12"",""_score"":null,""sort"":[1]}]}}]
2018-10-08 09:29:04,474 TRACE commonshttp.CommonsHttpTransport - Tx [POST]@[1xx.xx.xxx.xxx:9200][_search/scroll]?[scroll=5m] w/ payload [{""scroll_id"":""DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAOWFjJJWWxPY3c1VHBhTFJOb3FTYXZzakEAAAAAAAADwRY0RnZjMFlRcVItMjU4RVl1UjlhZXJ3AAAAAAAAAsoWaGh2MHV0LTNRYVdaMS03SEx5OUM5dwAAAAAAAALLFmI0c2M2NjAtUlRtcmg0R294X2RNOGcAAAAAAAAFrhZNU3NSM1IxY1JOeTlNTHZDMzBSMDdB""}]
2018-10-08 09:29:04,732 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [200-OK] [{""_scroll_id"":""DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAOWFjJJWWxPY3c1VHBhTFJOb3FTYXZzakEAAAAAAAADwRY0RnZjMFlRcVItMjU4RVl1UjlhZXJ3AAAAAAAAAsoWaGh2MHV0LTNRYVdaMS03SEx5OUM5dwAAAAAAAALLFmI0c2M2NjAtUlRtcmg0R294X2RNOGcAAAAAAAAFrhZNU3NSM1IxY1JOeTlNTHZDMzBSMDdB"",""took"":8,""timed_out"":false,""_shards"":{""total"":5,""successful"":5,""skipped"":0,""failed"":0},""hits"":{""total"":3,""max_score"":null,""hits"":[]}}]
2018-10-08 09:29:04,734 TRACE commonshttp.CommonsHttpTransport - Tx [PUT]@[1xx.xx.xxx.xxx:9200][index/docs/_bulk]?[null] w/ payload [{""delete"":{""_id"":""mouse12""}}
{""delete"":{""_id"":""Däniken	12Erich von""}}
{""delete"":{""_id"":""horse12""}}
]
2018-10-08 09:29:04,993 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [500-Internal Server Error] [{""error"":{""root_cause"":[{""type"":""json_parse_exception"",""reason"":""Illegal unquoted character ((CTRL-CHAR, code 9)): has to be escaped using backslash to be included in string value\n at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@28f84893; line: 1, column: 28]""}],""type"":""json_parse_exception"",""reason"":""Illegal unquoted character ((CTRL-CHAR, code 9)): has to be escaped using backslash to be included in string value\n at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@28f84893; line: 1, column: 28]""},""status"":500}]
2018-10-08 09:29:04,993 TRACE commonshttp.CommonsHttpTransport - Tx [DELETE]@[1xx.xx.xxx.xxx:9200][_search/scroll]?[null] w/ payload [{""scroll_id"":[""DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAOWFjJJWWxPY3c1VHBhTFJOb3FTYXZzakEAAAAAAAADwRY0RnZjMFlRcVItMjU4RVl1UjlhZXJ3AAAAAAAAAsoWaGh2MHV0LTNRYVdaMS03SEx5OUM5dwAAAAAAAALLFmI0c2M2NjAtUlRtcmg0R294X2RNOGcAAAAAAAAFrhZNU3NSM1IxY1JOeTlNTHZDMzBSMDdB""]}]
2018-10-08 09:29:05,243 TRACE commonshttp.CommonsHttpTransport - Rx @[xxx.xx.xxx.xxx] [200-OK] [{""succeeded"":true,""num_freed"":5}]
2018-10-08 09:29:05,246 INFO  spark.SparkContext - Invoking stop() from shutdown hook
2018-10-08 09:29:05,255 INFO  server.ServerConnector - Stopped ServerConnector@6f7923a5{HTTP/1.1}{0.0.0.0:4040}
2018-10-08 09:29:05,257 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@302f7971{/stages/stage/kill,null,UNAVAILABLE}
2018-10-08 09:29:05,257 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@13d4992d{/jobs/job/kill,null,UNAVAILABLE}
2018-10-08 09:29:05,257 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5082d622{/api,null,UNAVAILABLE}
2018-10-08 09:29:05,257 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@18e36d14{/,null,UNAVAILABLE}
2018-10-08 09:29:05,257 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@418c5a9c{/static,null,UNAVAILABLE}
2018-10-08 09:29:05,257 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5a5338df{/executors/threadDump/json,null,UNAVAILABLE}
2018-10-08 09:29:05,257 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6ee4d9ab{/executors/threadDump,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1fb19a0{/executors/json,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@732d0d24{/executors,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5e3d57c7{/environment/json,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6bf08014{/environment,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4416d64f{/storage/rdd/json,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@50dfbc58{/storage/rdd,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73a8da0f{/storage/json,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@10f7f7de{/storage,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@11f0a5a1{/stages/pool/json,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1b45c0e{/stages/pool,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5026735c{/stages/stage/json,null,UNAVAILABLE}
2018-10-08 09:29:05,258 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1672fe87{/stages/stage,null,UNAVAILABLE}
2018-10-08 09:29:05,259 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7cbd9d24{/stages/json,null,UNAVAILABLE}
2018-10-08 09:29:05,259 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6676f6a0{/stages,null,UNAVAILABLE}
2018-10-08 09:29:05,259 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@147a5d08{/jobs/job/json,null,UNAVAILABLE}
2018-10-08 09:29:05,259 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1bae316d{/jobs/job,null,UNAVAILABLE}
2018-10-08 09:29:05,259 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2ce6c6ec{/jobs/json,null,UNAVAILABLE}
2018-10-08 09:29:05,259 INFO  handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5c45d770{/jobs,null,UNAVAILABLE}
2018-10-08 09:29:05,260 INFO  ui.SparkUI - Stopped Spark web UI at http://xxx.xx.xxx.xxx:4040"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1173,"
Issue description- I need to send timestamp data in format ""yyyy-MM-dd hh:mm:ss"" from spark SQL dataframe to Elasticsearch. However, when I send the timestamp it changes to unix time format in Elasticsearch. For me, timestamp in Spark(2018-02-01 01:02:59) changes to ""timestamp"":1517587361000

### Description-
## Steps to reproduce
## Code

1. scala> conf.set(""es.resource.write"",""my-collection/{@timestamp|yyyy-MM-dd'T'HH:mm:ss}"")
2. Setup sqlcontext and create dataframe
3. scala> dframe.show()
+----------------------+-------------------+-------------+-------------------+
|UserName|destination_airport|    client_ip|          timestamp|
+----------------------+-------------------+-------------+-------------------+
|            xxxxx|                      xxxx| 10.81.xx.xxx|2018-02-01 01:02:59|
|            xxxxx|                      xxxx| 10.81.xx.xxx|2018-02-01 01:02:00|
|            xxxxx|                      xxxx| 10.81.xx.xxx|2018-02-01 01:02:04|

4. scala> dframe.printSchema()
root
 |-- UserName: string (nullable = true)
 |-- destination_airport: string (nullable = true)
 |-- client_ip: string (nullable = true)
 |-- timestamp: timestamp (nullable = true)

5. scala> dframe.saveToEs(""test/docs"")

In elasticsearch-
1. $curl -X GET ""localhost:9200/test/_search"" -H 'Content-Type: application/json' -d'
{
    ""query"": {
        ""match_all"": {}
    }
}
'

# OUTPUT-

""_source"":{""destination_airport"":""XXXX"",""client_ip"":""10.XX.XX.XXX"",""timestamp"":1517587361000}}


OS:         : Mac  
JVM         :  
Hadoop/Spark:Spark 2.3  
ES-Hadoop   :  
ES          :  6.2
","Did you try to specify a mapping before, with the right date format you want?","Thanks for the reply. I did set mapping type. But it did not work for me.

CODE SNIPPET:-

In ES:-
>curl -X PUT ""localhost:9200/index12"" -H 'Content-Type: application/json' -d'
{
  ""mappings"": {
    ""_doc"": {
      ""properties"": {
        ""date1"": {
          ""type"":   ""date"",
          ""format"": ""yyyy-mm-dd""
        }
      }
    }
  }
}
'

In Spark:-
scala> dataOut.select($""date1"").show
+----------+
|     date1|
+----------+
|2018-02-01|
|2018-02-01|

scala> dataOut.select($""date1"").saveToEs(""index12/_doc"")

Returns error with String-""Caused by: org.elasticsearch.hadoop.EsHadoopException: Could not write all entries for bulk operation [1000/1000]. Error sample (first [5] error messages):
	failed to parse [date1]""

"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1102,"Hello, I'm using spark SQL in order to extract data from elastic into csv files.

used software versions :
- elastic 5.5.2
- spark SQL 2.1.1
- elasticsearch-spark-20_2.11 5.5.2
- scala 2.11.8

I query elastic using alias.
When the alias is updated (remove and add new indices) during spark job processing, this last one fails.

Does it possible to preserve the same index from the beginning to end of the spark job execution (atomic process) ?

My workaround is searching the indices associated to the alias at the beginning of the spark job and initialize the dataframe with these indices.
Does it exist a better solution ?

my steps are
- t0 : first call to elastic via alias (here index-0 is used)
- t1 : alias update from index-0 to index-1
- t2 : second call to elastic via alias (here index-1 is used) **==> it failed**

In my case, data in elastic is schemaless. So, in case an attribute is not present after the alias updated then the second query to elastic failed.

My workaround has been successfully validated. In that case the steps become :
- init: get the indices associated to the alias (get index-0)
- t0 : first call to elastic via index-0
- t1 : alias update from index-0 to index-1
- t2 : second call to elastic via index-0 **==> it succeeded**
","Could you elaborate when exactly you are performing each of the given steps? Saying ""Xth call to elastic"" doesn't really give us much to work with.",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1082,"### Version Info 
Spark:  2.2.0
ES-Hadoop   :  5.6.0
ES          :  5.6.0

### Problem:
I am using sparksql to access data in elasticsearch. I use the following statement to register an index as hive table:
```
create table student using org.elasticsearch.spark.sql options (resource 'student/info', nodes '10.xxx.xxx.xx:9200')
```
However, when I run query statement on table student, I always get  EsHadoopIllegalArgumentException:
```
org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot find mapping for hdfs://HACluster/home/work/hive/warehouse/gz_test.db/student - one is required before using Spark SQL
	at org.elasticsearch.spark.sql.SchemaUtils$.discoverMappingAndGeoFields(SchemaUtils.scala:120)
	at org.elasticsearch.spark.sql.SchemaUtils$.discoverMapping(SchemaUtils.scala:91)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.lazySchema$lzycompute(DefaultSource.scala:112)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.lazySchema(DefaultSource.scala:112)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.buildScan(DefaultSource.scala:174)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.buildScan(DefaultSource.scala:106)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy$$anonfun$11.apply(DataSourceStrategy.scala:277)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy$$anonfun$11.apply(DataSourceStrategy.scala:277)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy$$anonfun$pruneFilterProject$1.apply(DataSourceStrategy.scala:321)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy$$anonfun$pruneFilterProject$1.apply(DataSourceStrategy.scala:320)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy.pruneFilterProjectRaw(DataSourceStrategy.scala:401)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy.pruneFilterProject(DataSourceStrategy.scala:316)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy.apply(DataSourceStrategy.scala:273)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:62)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:62)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:92)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:77)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:74)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:74)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:66)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:92)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:84)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:89)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:89)
	at org.apache.spark.sql.execution.QueryExecution.hiveResultString(QueryExecution.scala:118)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:76)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:340)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:379)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:248)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
```
Since es-hadoop works well with spark1.6 on my machine, I think there must be some differences between spark1.6 and spark2.2. After digging into this problem, I find that the elements order in map type parameter which  passed to ```createRelation``` method of ```DefaultSource``` is different:
#### spark1.6
Map(
path->hdfs://HACluster/home/work/hive/warehouse/gz_test.db/student,
nodes->10.xxx.xxx.xx:9200
resource->student/info
serialization.format->1
)
#### spark2.2
Map(
nodes->10.xxx.xxx.xx:9200
resource->student/info
serialization.format->1,
path->hdfs://HACluster/home/work/hive/warehouse/gz_test.db/student
)

Because *path* comes after *resource* in spark2.2, when this map type parameter parsed by ```params``` function in ```DefaultSource```, the value of  *path* will be wrongly parsed as ```es.resource``` and then EsHadoopIllegalArgumentException occurred. 
```
es.resource->student/info     //spark1.6
es.resource->hdfs://HACluster/home/work/hive/warehouse/gz_test.db/student     //spark2.2
```
Here is what ```params```function looks like:
```scala
private def params(parameters: Map[String, String]) = {
    // '.' seems to be problematic when specifying the options
    val params = parameters.map { case (k, v) => (k.replace('_', '.'), v)}. map { case (k, v) =>
      if (k.startsWith(""es."")) (k, v)
      else if (k == ""path"" && !parameters.get(""resource"").isDefined) (ConfigurationOptions.ES_RESOURCE, v)
      else if (k == ""pushdown"") (Utils.DATA_SOURCE_PUSH_DOWN, v)
      else if (k == ""strict"") (Utils.DATA_SOURCE_PUSH_DOWN_STRICT, v)
      else if (k == ""double.filtering"") (Utils.DATA_SOURCE_KEEP_HANDLED_FILTERS, v)
      else (""es."" + k, v)
    }
    // validate path
    params.getOrElse(ConfigurationOptions.ES_RESOURCE_READ, 
        params.getOrElse(ConfigurationOptions.ES_RESOURCE, throw new EsHadoopIllegalArgumentException(""resource must be specified for Elasticsearch resources."")))
        
    params
  }
```
Should this be a bug of es-hadoop? Though I am not using the latest version of es-hadoop, I believe it has the same problem.

","Could you elaborate on your statement above:

> spark1.6
Map(
path->hdfs://HACluster/home/work/hive/warehouse/gz_test.db/student,
nodes->10.xxx.xxx.xx:9200
resource->student/info
serialization.format->1
)
spark2.2
Map(
nodes->10.xxx.xxx.xx:9200
resource->student/info
serialization.format->1,
path->hdfs://HACluster/home/work/hive/warehouse/gz_test.db/student
)

Are these configuration lines that you've seen within the ES-Hadoop project or are they lines from your project? I'll see if I can reproduce the erroneous settings parsing. The order of the configuration terms in the map should not affect the final result. If it does, I'd consider it a bug.","@jbaiera I am sorry I didn't make it clear. The configurations in the map is what spark passed to ES-Hadoop when create relation (which finally accepted by method `params`). Because the elements of the map come in different order in spark2.2, ES-Hadoop wrongly parses `hdfs://HACluster/home/work/hive/warehouse/gz_test.db/student` as `es-resource`.  I have fixed this in my work and now it works well with spark2.2. And I would love to work on this problem. "
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1057,"### What kind an issue is this?

- [x] Bug report.

### Issue description

We have an issue with data consistency when storing data in Elasticsearch using Spark and elasticsearch-spark connector. Job finishes successfully, but when we compare the original data (stored in S3), with the data stored in ES, some documents are not present in Elasticsearch.

I'm looking for some guidance in order to debug this issue.

1) I want to understand why Elasticsearch doesn't have all the data although Spark says it finished the job and saved the data
2) What can we do to ensure that we write data to ES in a consistent manner?

### Steps to reproduce

This issue doesn't always happen and unfortunately we cannot reproduce it on demand. The only indicator we found that correlates with occurrences of this bug, is the presence of the failed stage while saving data in Elasticsearch.  Jobs which have this stage failure eventually complete successfully, but the data is inconsistent. 

![extractobjectstoelasticsearchnested maxruntimsec 43200 yarn_queue default date 2017-10-09 object_type leads env production 2017-10-09 15-08-26](https://user-images.githubusercontent.com/1457102/31339713-0f724bca-ad04-11e7-993d-3a9a311f1094.png)

We use the following configuration:
- Elasticsearch:
  - ""es.write.operation"": ""index""
  - ""es.nodes.discovery"": ""false""
  - ""es.nodes.wan.only"": ""true""
- Spark:
  - write mode: ""append""

### Version Info

OS:         :  Amazon Linux
JVM         :  1.8
Hadoop/Spark:  Hadoop 2.7.3 (Amazon), Spark 2.2.0
ES-Hadoop   :  elasticsearch-spark-20_2.11:5.5.2
ES          :  5.3 (Amazon Elasticsearch Service).",Could you share the details for the errors your tasks are experiencing?,
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1034,"Zipkin is currently testing Elasticsearch 6.x for our dependency linking spark job and we noticed that latest snapshots break 2.x. Looking at wire logs, it seems this is around scroll ids, as you'll notice that with snapshot no scrolls are used, eventhough 5.5.1 is ok. I reverted 1190be71dcca9cfabb9af1ce43e5cc4a6546a68b and things are back to normal. I suspect there's something subtle missed.

Log from version 5.5.1, note presence of `POST /_search/scroll?scroll=5m`
```
17/08/08 13:34:40 INFO ElasticsearchDependenciesJob: Processing spans from test_zipkin_dependency-2017-08-08/span
17/08/08 13:35:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/08 13:35:11 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""GET /_cluster/health/test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Length: 389[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:11 DEBUG content: << ""{""cluster_name"":""elasticsearch"",""status"":""yellow"",""timed_out"":false,""number_of_nodes"":1,""number_of_data_nodes"":1,""active_primary_shards"":5,""active_shards"":5,""relocating_shards"":0,""initializing_shards"":0,""unassigned_shards"":5,""delayed_unassigned_shards"":0,""number_of_pending_tasks"":0,""number_of_in_flight_fetch"":0,""task_max_waiting_in_queue_millis"":0,""active_shards_percent_as_number"":50.0}""
17/08/08 13:35:11 DEBUG header: >> ""GET / HTTP/1.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Length: 364[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:11 DEBUG content: << ""{[\n]""
17/08/08 13:35:11 DEBUG content: << ""  ""name"" : ""Amber Hunt"",[\n]""
17/08/08 13:35:11 DEBUG content: << ""  ""cluster_name"" : ""elasticsearch"",[\n]""
17/08/08 13:35:11 DEBUG content: << ""  ""cluster_uuid"" : ""yhWaWc2jRaWNz2u6W2TbLQ"",[\n]""
17/08/08 13:35:11 DEBUG content: << ""  ""version"" : {[\n]""
17/08/08 13:35:11 DEBUG content: << ""    ""number"" : ""2.4.5"",[\n]""
17/08/08 13:35:11 DEBUG content: << ""    ""build_hash"" : ""c849dd13904f53e63e88efc33b2ceeda0b6a1276"",[\n]""
17/08/08 13:35:11 DEBUG content: << ""    ""build_timestamp"" : ""2017-04-24T16:18:17Z"",[\n]""
17/08/08 13:35:11 DEBUG content: << ""    ""build_snapshot"" : false,[\n]""
17/08/08 13:35:11 DEBUG content: << ""    ""lucene_version"" : ""5.5.4""[\n]""
17/08/08 13:35:11 DEBUG content: << ""  },[\n]""
17/08/08 13:35:11 DEBUG content: << ""  ""tagline"" : ""You Know, for Search""[\n]""
17/08/08 13:35:11 DEBUG content: << ""}[\n]""
17/08/08 13:35:11 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08/span HTTP/1.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""GET /test_zipkin_dependency-2017-08-08/_search_shards HTTP/1.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Length: 1153[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:11 DEBUG content: << ""{""nodes"":{""sZf5lCQfRomZi7ZzPag3MQ"":{""name"":""Amber Hunt"",""transport_address"":""172.17.0.6:9300"",""attributes"":{}}},""shards"":[[{""state"":""STARTED"",""primary"":true,""node"":""sZf5lCQfRomZi7ZzPag3MQ"",""relocating_node"":null,""shard"":0,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""uLa2nlToQp-BYhCG_Xgb3w""}}],[{""state"":""STARTED"",""primary"":true,""node"":""sZf5lCQfRomZi7ZzPag3MQ"",""relocating_node"":null,""shard"":1,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""sQtBMY8NR52OQ2_0l7IvQw""}}],[{""state"":""STARTED"",""primary"":true,""node"":""sZf5lCQfRomZi7ZzPag3MQ"",""relocating_node"":null,""shard"":2,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""7gYXJ4AiR6WoEhXU0AtSQA""}}],[{""state"":""STARTED"",""primary"":true,""node"":""sZf5lCQfRomZi7ZzPag3MQ"",""relocating_node"":null,""shard"":3,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""SLpufC8ySVmV7krxWD7kHQ""}}],[{""state"":""STARTED"",""primary"":true,""node"":""sZf5lCQfRomZi7ZzPag3MQ"",""relocating_node"":null,""shard"":4,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""gnOnhHCsTsaigWlIdRaFvg""}}]]}""
17/08/08 13:35:11 DEBUG header: >> ""GET /test_zipkin_dependency-2017-08-08/span/_mapping HTTP/1.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:11 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""Content-Length: 925[\r][\n]""
17/08/08 13:35:11 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:11 DEBUG content: << ""{""test_zipkin_dependency-2017-08-08"":{""mappings"":{""span"":{""_all"":{""enabled"":false},""properties"":{""annotations"":{""type"":""nested"",""dynamic"":""false"",""properties"":{""endpoint"":{""dynamic"":""false"",""properties"":{""serviceName"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""value"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""binaryAnnotations"":{""type"":""nested"",""dynamic"":""false"",""properties"":{""endpoint"":{""dynamic"":""false"",""properties"":{""serviceName"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""key"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256},""value"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""duration"":{""type"":""long""},""id"":{""type"":""string""},""name"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256},""timestamp_millis"":{""type"":""date"",""format"":""epoch_millis""},""traceId"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}}}}}""
17/08/08 13:35:12 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A2%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A3%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A0%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A1%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A4%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:35:12 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzExOnNaZjVsQ1FmUm9tWmk3WnpQYWczTVE7MTt0b3RhbF9oaXRzOjE7"",""took"":4,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":1,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzE0OnNaZjVsQ1FmUm9tWmk3WnpQYWczTVE7MTt0b3RhbF9oaXRzOjA7"",""took"":2,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:35:12 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzEyOnNaZjVsQ1FmUm9tWmk3WnpQYWczTVE7MTt0b3RhbF9oaXRzOjA7"",""took"":1,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzEzOnNaZjVsQ1FmUm9tWmk3WnpQYWczTVE7MTt0b3RhbF9oaXRzOjA7"",""took"":1,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzE1OnNaZjVsQ1FmUm9tWmk3WnpQYWczTVE7MTt0b3RhbF9oaXRzOjA7"",""took"":4,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:35:12 DEBUG header: >> ""POST /_search/scroll?scroll=5m HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 80[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""scroll_id"":""c2NhbjsxOzExOnNaZjVsQ1FmUm9tWmk3WnpQYWczTVE7MTt0b3RhbF9oaXRzOjE7""}""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 750[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{""_scroll_id"":""c2NhbjswOzE7dG90YWxfaGl0czoxOw=="",""took"":15,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":1,""max_score"":0.0,""hits"":[{""_index"":""test_zipkin_dependency-2017-08-08"",""_type"":""span"",""_id"":""AV3AVnw4E4f7903zZKvx"",""_score"":0.0,""_source"":{""timestamp_millis"":1502150400050,""traceId"":""000000000000000a"",""id"":""000000000000000a"",""name"":"""",""annotations"":[{""timestamp"":1502150400050000,""value"":""cs"",""endpoint"":{""serviceName"":""web"",""ipv4"":""124.13.90.3"",""port"":80,""ipv6"":""2001:db8::c001""}},{""timestamp"":1502150400072000,""value"":""error"",""endpoint"":{""serviceName"":""app"",""ipv4"":""172.17.0.2"",""port"":8080}},{""timestamp"":1502150400100000,""value"":""sr"",""endpoint"":{""serviceName"":""app"",""ipv4"":""172.17.0.2"",""port"":8080}}]}}]}}""
17/08/08 13:35:12 DEBUG header: >> ""DELETE /_search/scroll HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 50[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""scroll_id"":[""c2NhbjswOzE7dG90YWxfaGl0czoxOw==""]}""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 404 Not Found[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 404 Not Found[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 2[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 INFO ElasticsearchDependenciesJob: Saving dependency links to test_zipkin_dependency-2017-08-08/dependencylink
17/08/08 13:35:12 DEBUG header: >> ""GET / HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 364[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{[\n]""
17/08/08 13:35:12 DEBUG content: << ""  ""name"" : ""Amber Hunt"",[\n]""
17/08/08 13:35:12 DEBUG content: << ""  ""cluster_name"" : ""elasticsearch"",[\n]""
17/08/08 13:35:12 DEBUG content: << ""  ""cluster_uuid"" : ""yhWaWc2jRaWNz2u6W2TbLQ"",[\n]""
17/08/08 13:35:12 DEBUG content: << ""  ""version"" : {[\n]""
17/08/08 13:35:12 DEBUG content: << ""    ""number"" : ""2.4.5"",[\n]""
17/08/08 13:35:12 DEBUG content: << ""    ""build_hash"" : ""c849dd13904f53e63e88efc33b2ceeda0b6a1276"",[\n]""
17/08/08 13:35:12 DEBUG content: << ""    ""build_timestamp"" : ""2017-04-24T16:18:17Z"",[\n]""
17/08/08 13:35:12 DEBUG content: << ""    ""build_snapshot"" : false,[\n]""
17/08/08 13:35:12 DEBUG content: << ""    ""lucene_version"" : ""5.5.4""[\n]""
17/08/08 13:35:12 DEBUG content: << ""  },[\n]""
17/08/08 13:35:12 DEBUG content: << ""  ""tagline"" : ""You Know, for Search""[\n]""
17/08/08 13:35:12 DEBUG content: << ""}[\n]""
17/08/08 13:35:12 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""PUT /test_zipkin_dependency-2017-08-08/dependencylink/_bulk HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 103[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""index"":{""_id"":""web|app""}}[\n]""
17/08/08 13:35:12 DEBUG content: >> ""{""id"":""web|app"",""parent"":""web"",""child"":""app"",""callCount"":1,""errorCount"":0}[\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 207[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{""took"":7,""errors"":false,""items"":[{""index"":{""_index"":""test_zipkin_dependency-2017-08-08"",""_type"":""dependencylink"",""_id"":""web|app"",""_version"":1,""_shards"":{""total"":2,""successful"":1,""failed"":0},""status"":201}}]}""
17/08/08 13:35:12 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/_refresh HTTP/1.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Host: 192.168.99.100:32981[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""Content-Length: 0[\r][\n]""
17/08/08 13:35:12 DEBUG header: >> ""[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""Content-Length: 50[\r][\n]""
17/08/08 13:35:12 DEBUG header: << ""[\r][\n]""
17/08/08 13:35:12 DEBUG content: << ""{""_shards"":{""total"":10,""successful"":5,""failed"":0}}""
```

Log from version 6.0.0.BUILD-SNAPSHOT, note absense of `POST /_search/scroll?scroll=5m`
```
17/08/08 13:32:39 INFO ElasticsearchDependenciesJob: Processing spans from test_zipkin_dependency-2017-08-08/span
17/08/08 13:32:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/08 13:32:40 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""GET /_cluster/health/test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:40 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""Content-Length: 389[\r][\n]""
17/08/08 13:32:40 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:40 DEBUG content: << ""{""cluster_name"":""elasticsearch"",""status"":""yellow"",""timed_out"":false,""number_of_nodes"":1,""number_of_data_nodes"":1,""active_primary_shards"":5,""active_shards"":5,""relocating_shards"":0,""initializing_shards"":0,""unassigned_shards"":5,""delayed_unassigned_shards"":0,""number_of_pending_tasks"":0,""number_of_in_flight_fetch"":0,""task_max_waiting_in_queue_millis"":0,""active_shards_percent_as_number"":50.0}""
17/08/08 13:32:41 DEBUG header: >> ""GET / HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 358[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{[\n]""
17/08/08 13:32:41 DEBUG content: << ""  ""name"" : ""Rock"",[\n]""
17/08/08 13:32:41 DEBUG content: << ""  ""cluster_name"" : ""elasticsearch"",[\n]""
17/08/08 13:32:41 DEBUG content: << ""  ""cluster_uuid"" : ""7wqy9S9VS_OEg_x0onupow"",[\n]""
17/08/08 13:32:41 DEBUG content: << ""  ""version"" : {[\n]""
17/08/08 13:32:41 DEBUG content: << ""    ""number"" : ""2.4.5"",[\n]""
17/08/08 13:32:41 DEBUG content: << ""    ""build_hash"" : ""c849dd13904f53e63e88efc33b2ceeda0b6a1276"",[\n]""
17/08/08 13:32:41 DEBUG content: << ""    ""build_timestamp"" : ""2017-04-24T16:18:17Z"",[\n]""
17/08/08 13:32:41 DEBUG content: << ""    ""build_snapshot"" : false,[\n]""
17/08/08 13:32:41 DEBUG content: << ""    ""lucene_version"" : ""5.5.4""[\n]""
17/08/08 13:32:41 DEBUG content: << ""  },[\n]""
17/08/08 13:32:41 DEBUG content: << ""  ""tagline"" : ""You Know, for Search""[\n]""
17/08/08 13:32:41 DEBUG content: << ""}[\n]""
17/08/08 13:32:41 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08 HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""HEAD /test_zipkin_dependency-2017-08-08/span HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: text/plain; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 0[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""GET /test_zipkin_dependency-2017-08-08/_search_shards HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 1147[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{""nodes"":{""X9QcQ6N6Spm-4YkmOwVdpw"":{""name"":""Rock"",""transport_address"":""172.17.0.6:9300"",""attributes"":{}}},""shards"":[[{""state"":""STARTED"",""primary"":true,""node"":""X9QcQ6N6Spm-4YkmOwVdpw"",""relocating_node"":null,""shard"":0,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""U93DnwDITxKnyBEIhXvppA""}}],[{""state"":""STARTED"",""primary"":true,""node"":""X9QcQ6N6Spm-4YkmOwVdpw"",""relocating_node"":null,""shard"":1,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""priFUo5zT5W7jDpyE1VcZg""}}],[{""state"":""STARTED"",""primary"":true,""node"":""X9QcQ6N6Spm-4YkmOwVdpw"",""relocating_node"":null,""shard"":2,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""o2YQUDI-Raij9iqkw9RPVQ""}}],[{""state"":""STARTED"",""primary"":true,""node"":""X9QcQ6N6Spm-4YkmOwVdpw"",""relocating_node"":null,""shard"":3,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""vnhG0BDvSyW181nYiWBajQ""}}],[{""state"":""STARTED"",""primary"":true,""node"":""X9QcQ6N6Spm-4YkmOwVdpw"",""relocating_node"":null,""shard"":4,""index"":""test_zipkin_dependency-2017-08-08"",""version"":2,""allocation_id"":{""id"":""rYX8S2TFRcKmHWLvZ142gw""}}]]}""
17/08/08 13:32:41 DEBUG header: >> ""GET /test_zipkin_dependency-2017-08-08/span/_mapping HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 925[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{""test_zipkin_dependency-2017-08-08"":{""mappings"":{""span"":{""_all"":{""enabled"":false},""properties"":{""annotations"":{""type"":""nested"",""dynamic"":""false"",""properties"":{""endpoint"":{""dynamic"":""false"",""properties"":{""serviceName"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""value"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""binaryAnnotations"":{""type"":""nested"",""dynamic"":""false"",""properties"":{""endpoint"":{""dynamic"":""false"",""properties"":{""serviceName"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""key"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256},""value"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}},""duration"":{""type"":""long""},""id"":{""type"":""string""},""name"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256},""timestamp_millis"":{""type"":""date"",""format"":""epoch_millis""},""traceId"":{""type"":""string"",""index"":""not_analyzed"",""ignore_above"":256}}}}}}""
17/08/08 13:32:41 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A0%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A1%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A3%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A2%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""POST /test_zipkin_dependency-2017-08-08/span/_search?search_type=scan&scroll=5m&size=50&preference=_shards%3A4%3B_local HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 26[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""query"":{""match_all"":{}}}""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzExOlg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjE7"",""took"":6,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":1,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzEzOlg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7"",""took"":8,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:32:41 DEBUG header: >> ""DELETE /_search/scroll HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""DELETE /_search/scroll HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 82[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 82[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""scroll_id"":[""c2NhbjsxOzEzOlg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7""]}""
17/08/08 13:32:41 DEBUG content: >> ""{""scroll_id"":[""c2NhbjsxOzExOlg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjE7""]}""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzEyOlg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7"",""took"":9,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:32:41 DEBUG header: >> ""DELETE /_search/scroll HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 82[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""scroll_id"":[""c2NhbjsxOzEyOlg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7""]}""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzE0Olg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7"",""took"":1,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 201[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: << ""{""_scroll_id"":""c2NhbjsxOzE1Olg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7"",""took"":1,""timed_out"":false,""_shards"":{""total"":1,""successful"":1,""failed"":0},""hits"":{""total"":0,""max_score"":0.0,""hits"":[]}}""
17/08/08 13:32:41 DEBUG header: >> ""DELETE /_search/scroll HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 2[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 2[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 82[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""scroll_id"":[""c2NhbjsxOzE0Olg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7""]}""
17/08/08 13:32:41 DEBUG header: >> ""DELETE /_search/scroll HTTP/1.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Type: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Accept: application/json[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Host: 192.168.99.100:32978[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""Content-Length: 82[\r][\n]""
17/08/08 13:32:41 DEBUG header: >> ""[\r][\n]""
17/08/08 13:32:41 DEBUG content: >> ""{""scroll_id"":[""c2NhbjsxOzE1Olg5UWNRNk42U3BtLTRZa21Pd1ZkcHc7MTt0b3RhbF9oaXRzOjA7""]}""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 2[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 2[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""HTTP/1.1 200 OK[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""Content-Length: 2[\r][\n]""
17/08/08 13:32:41 DEBUG header: << ""[\r][\n]""
17/08/08 13:32:41 INFO ElasticsearchDependenciesJob: No spans found at test_zipkin_dependency-2017-08-08/span
```",Can you share your reproduction steps here? I'll start working on a fix.,"Hi james. Thanks for looking into it.

In hopes that this doesnt cause you too much work..

Clone https://github.com/openzipkin/zipkin-dependencies

Set this to the snapshot version
https://github.com/openzipkin/zipkin-dependencies/blob/master/elasticsearch/pom.xml

Run this
https://github.com/openzipkin/zipkin-dependencies/blob/master/elasticsearch/src/test/java/zipkin/storage/elasticsearch/http/ElasticsearchV2DependenciesTest.java

Note this uses docker!

If this is too much I can try to isolate a test given an example test case
for things like this.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1019,"<!--
GitHub is reserved *only* for bug reports and feature requests. The best place
to ask a general question is at the Elastic forums at
https://discuss.elastic.co/c/elasticsearch-and-hadoop.
If you are in fact posting a bug report or a feature request, please 
include one and only one of the below blocks in your new issue.
-->

### What kind an issue is this?

- [ ] Bug report.

**Not able to use kryoserializer for writing data into Elastic Search.** 

When i just set the ""spark.serializer"" as KryoSerializer.class.getName() in spark conf it is giving me exception

org.elasticsearch.hadoop.serialization.EsHadoopSerializationException: Cannot handle type [class com.spark.apps.pojo.AnalyticsOneDayData] within type [class com.spark.apps.pojo.AnalyticsDailyAggregatedData],

and when i add 

""es.ser.writer.value.class"" as KryoSerializer.class.getName() i get below exception 

org.elasticsearch.hadoop.EsHadoopIllegalStateException: Cannot instantiate class [org.apache.spark.serializer.KryoSerializer]

as the ObjectUtils does clz.newInstance and there is no default constructor for KryoSerializer.
	

<!--
If you are filing a bug report, please fill provide responses for all 
of the below items.
Remove the feature block.
-->

### Issue description

Description

I want to insert a nested structure into Elastic Search. The corresponding java classes are 


```
public class DailyAggregatedData implements Serializable {

	private static final long serialVersionUID = -9150958167164783629L;
	String id;
	String cId;
	OneDayData[] aggregatedData;
}
```


```
public class OneDayData implements Serializable{

	private static final long serialVersionUID = 8982330246703144883L;
	String date;
	long xcount;
	long ycount;
}
```




### Steps to reproduce

Code:

```
                SparkConf sparkConf = new SparkConf();
		sparkConf.set(EsSparkConstants.ES_INDEX_AUTO_CREATE, ""true"");
		sparkConf.set(EsSparkConstants.ES_RESOURCE, ""indexName"");
		sparkConf.set(EsSparkConstants.ES_NDOES, ""localhost"");
		sparkConf.set(EsSparkConstants.ES_PORT, ""9200"");
		sparkConf.set(EsSparkConstants.ES_NODES_WAN_ONLY, ""true"");
		sparkConf.set(""spark.serializer"", KryoSerializer.class.getName());

                 SparkConf sparkConf = buildSparkConf();
		JavaSparkContext javaSparkContext = new JavaSparkContext(sparkConf);

                //build JavaRDD this is working fine.
                JavaRDD<DailyAggregatedData> DailyAggregatedDataRDD = 

                JavaEsSpark.saveToEs(javaRDD,
		 ""indexName"", propertiesMap);
```

Test/code snippet

Strack trace:

with just ""spark.serializer""

`org.elasticsearch.hadoop.serialization.EsHadoopSerializationException: Cannot handle type [class com.spark.apps.pojo.AnalyticsOneDayData] within type [class com.spark.apps.pojo.AnalyticsDailyAggregatedData], instance [com.spark.apps.pojo.AnalyticsOneDayData@41c7150a] within instance [com.spark.apps.pojo.AnalyticsDailyAggregatedData@18fb1a1d] using writer [org.spark.serialization.ScalaValueWriter@660cef49] 
`


when i add ""es.ser.writer.value.class""

```
org.elasticsearch.hadoop.EsHadoopIllegalStateException: Cannot instantiate class [org.apache.spark.serializer.KryoSerializer]
	at org.elasticsearch.hadoop.util.ObjectUtils.instantiate(ObjectUtils.java:43)
	at org.elasticsearch.hadoop.util.ObjectUtils.instantiate(ObjectUtils.java:52)
	at org.elasticsearch.hadoop.util.ObjectUtils.instantiate(ObjectUtils.java:48)
	at org.elasticsearch.hadoop.serialization.bulk.AbstractBulkFactory.<init>(AbstractBulkFactory.java:169)
	at org.elasticsearch.hadoop.serialization.bulk.IndexBulkFactory.<init>(IndexBulkFactory.java:27)
	at org.elasticsearch.hadoop.serialization.bulk.BulkCommands.create(BulkCommands.java:40)
	at org.elasticsearch.hadoop.rest.RestRepository.lazyInitWriting(RestRepository.java:127)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:158)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.InstantiationException: org.apache.spark.serializer.KryoSerializer
	at java.lang.Class.newInstance(Class.java:427)
	at org.elasticsearch.hadoop.util.ObjectUtils.instantiate(ObjectUtils.java:41)
	... 16 more
Caused by: java.lang.NoSuchMethodException: org.apache.spark.serializer.KryoSerializer.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.newInstance(Class.java:412)
	... 17 more
```



### Version Info

OS:         :  Amazon Linux (Running Spark Cluster on AWS)
JVM         :  JDK8
Hadoop/Spark:  
Hadoop distribution:Amazon 2.7.3
Applications:Spark 2.0.2

ES-Hadoop   :  5.3
ES          :  5.3

<!--
If you are filing a feature request, please remove the above bug
report block and provide responses for all of the below items.
-->

### Feature description
","Does this succeed without the KryoSerializer configured in `spark.serializer`? I see that your classes implement Serializable, but are not case classes nor are Bean compliant with setters and getters. If you convert them to either Scala Case Classes or Java Bean styled objects does this work?","It was not working without KryoSerializer as well and was throwing similar exception as with spark.serializer as kryo.

I have getters and setters in my actual code for all the fields but i haven't pasted that here .

Is this because of array of objects within an object ? Is that supported with default serializer ?
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/1015,"<!--
GitHub is reserved *only* for bug reports and feature requests. The best place
to ask a general question is at the Elastic forums at
https://discuss.elastic.co/c/elasticsearch-and-hadoop.
If you are in fact posting a bug report or a feature request, please 
include one and only one of the below blocks in your new issue.
-->

### What kind an issue is this?

- [X ] Bug report. If you’ve found a bug, please provide a code snippet or test to reproduce it below.   
    The easier it is to track down the bug, the faster it is solved. 
- [ ] Feature Request. Start by telling us what problem you’re trying to solve.  
    Often a solution already exists! Don’t send pull requests to implement new features without 
    first getting our support. Sometimes we leave features out on purpose to keep the project small.

<!--
If you are filing a bug report, please fill provide responses for all 
of the below items.
Remove the feature block.
-->

### Issue description

Description:
I am trying to import data into ES using ES-Hadoop. I need the document ID to be a combination of two fields concatenated together: <field1>_<field2>. I don't want the concatenated string to be a field in the document since the other two fields are already there. 

### Steps to reproduce

Code:

```
DEFINE EsStorage org.elasticsearch.hadoop.pig.EsStorage('es.nodes=${es_client_nodes}',
                'es.port=443'
                , 'es.write.operation=upsert'
                , 'es.mapping.exclude=documentID'
                , 'es.mapping.include=businessDayDate, retailStoreID, workstationID, transactionNumber, transactionDate, transactionLineItemSequenceNumber, retnRetailStoreID, retnWorkstationID, retnTransactionNumber, retnBusinessDayDate, retnDataSourceCode, retnGlobalTransactionID, retnTransactionLineItemSequenceNumber'
                , 'es.mapping.id=documentID'
                , 'es.http.timeout=1000m'
                , 'es.batch.write.retry.count=1'
                , 'es.batch.http.retries=1'
                ,'es.index.auto.create = true'
                ,'es.net.ssl= true'
                ,'es.nodes.wan.only=true'
                ,'es.net.http.auth.user=${es_user}'
                ,'es.net.http.auth.pass=${es_key}'
                ,'es.net.ssl.protocol=TLS'

... Various filters and joins ...

retn_items = FOREACH retn_details_without_voids GENERATE
                        documentID as documentID
                        , businessDayDate as businessDayDate
                        , retailStoreID as retailStoreID
                        , workstationID as workstationID
                        , transactionNumber as transactionNumber
                        , transactionDate as transactionDate
                        , transactionLineItemSequenceNumber as transactionLineItemSequenceNumber
                        , retnRetailStoreID as retnRetailStoreID
                        , retnWorkstationID as retnWorkstationID
                        , retnTransactionNumber as retnTransactionNumber
                        , retnBusinessDayDate as retnBusinessDayDate
                        , retnDataSourceCode as retnDataSourceCode
                        , retnGlobalTransactionID as retnGlobalTransactionID
                        , retnTransactionLineItemSequenceNumber as retnTransactionLineItemSequenceNumber;

STORE retn_items INTO '$tran_index/retnitem' USING EsStorage;
```

Strack trace:

Driver:
```
6825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezDagBuilder  - For vertex - scope-370: parallelism=70, memory=7296, java opts=-Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx5836m -Dlog4j.configuratorClass=org.apache.tez.common.TezLog4jConfigurator -Dlog4j.configuration=tez-container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dtez.root.logger=TRACE,CLA
17/07/18 18:44:41 INFO tez.TezDagBuilder: For vertex - scope-370: parallelism=70, memory=7296, java opts=-Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx5836m -Dlog4j.configuratorClass=org.apache.tez.common.TezLog4jConfigurator -Dlog4j.configuration=tez-container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dtez.root.logger=TRACE,CLA
6825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezDagBuilder  - Processing aliases: retn_detail_with_void_data,retn_details_without_voids,retn_items
17/07/18 18:44:41 INFO tez.TezDagBuilder: Processing aliases: retn_detail_with_void_data,retn_details_without_voids,retn_items
6825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezDagBuilder  - Detailed locations: retn_detail_with_void_data[477,29],retn_detail_with_void_data[-1,-1],retn_details_without_voids[478,29],retn_items[480,13]
17/07/18 18:44:41 INFO tez.TezDagBuilder: Detailed locations: retn_detail_with_void_data[477,29],retn_detail_with_void_data[-1,-1],retn_details_without_voids[478,29],retn_items[480,13]
6826 [main] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezDagBuilder  - Pig features in the vertex: HASH_JOIN
17/07/18 18:44:41 INFO tez.TezDagBuilder: Pig features in the vertex: HASH_JOIN
17/07/18 18:44:41 WARN mr.EsOutputFormat: Speculative execution enabled for reducer - consider disabling it to prevent data corruption
6878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezJobCompiler  - Total estimated parallelism is 89
17/07/18 18:44:41 INFO tez.TezJobCompiler: Total estimated parallelism is 89
6987 [PigTezLauncher-0] INFO  org.apache.pig.tools.pigstats.tez.TezScriptState  - Pig script settings are added to the job
17/07/18 18:44:41 INFO tez.TezScriptState: Pig script settings are added to the job
17/07/18 18:44:41 INFO client.TezClient: Tez Client Version: [ component=tez-api, version=0.8.4, revision=154f1ef53e2d6ed126b0957d7995e0a610947608, SCM-URL=scm:git:https://git-wip-us.apache.org/repos/asf/tez.git, buildTime=2017-06-01T05:53:19Z ]
17/07/18 18:44:41 INFO impl.TimelineClientImpl: Timeline service address: http://ip-172-18-109-126.us-west-2.compute.internal:8188/ws/v1/timeline/
17/07/18 18:44:41 INFO client.RMProxy: Connecting to ResourceManager at ip-172-18-109-126.us-west-2.compute.internal/172.18.109.126:8032
17/07/18 18:44:41 INFO client.TezClient: Using org.apache.tez.dag.history.ats.acls.ATSHistoryACLPolicyManager to manage Timeline ACLs
17/07/18 18:44:41 INFO impl.TimelineClientImpl: Timeline service address: http://ip-172-18-109-126.us-west-2.compute.internal:8188/ws/v1/timeline/
17/07/18 18:44:41 INFO client.TezClient: Session mode. Starting session.
17/07/18 18:44:41 INFO client.TezClientUtils: Using tez.lib.uris value from configuration: hdfs:///apps/tez/tez.tar.gz
17/07/18 18:44:41 INFO client.TezClientUtils: Using tez.lib.uris.classpath value from configuration: null
17/07/18 18:44:42 INFO client.TezClient: Tez system stage directory hdfs://ip-172-18-109-126.us-west-2.compute.internal:8020/tmp/temp-1469282549/.tez/application_1500403084622_0001 doesn't exist and is created
17/07/18 18:44:42 INFO acls.ATSHistoryACLPolicyManager: Created Timeline Domain for History ACLs, domainId=Tez_ATS_application_1500403084622_0001
17/07/18 18:44:42 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
17/07/18 18:44:42 INFO impl.YarnClientImpl: Submitted application application_1500403084622_0001
17/07/18 18:44:42 INFO client.TezClient: The url to track the Tez Session: http://ip-172-18-109-126.us-west-2.compute.internal:20888/proxy/application_1500403084622_0001/
14588 [PigTezLauncher-0] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezJob  - Submitting DAG PigLatin:retnItems2.pig-0_scope-0
17/07/18 18:44:48 INFO tez.TezJob: Submitting DAG PigLatin:retnItems2.pig-0_scope-0
17/07/18 18:44:48 INFO client.TezClient: Submitting dag to TezSession, sessionName=PigLatin:retnItems2.pig, applicationId=application_1500403084622_0001, dagName=PigLatin:retnItems2.pig-0_scope-0, callerContext={ context=PIG, callerType=PIG_SCRIPT_ID, callerId=PIG-retnItems2.pig-6f4dd558-53be-4c9d-bbc5-941d2aee240b }
17/07/18 18:44:49 INFO client.TezClient: Submitted dag to TezSession, sessionName=PigLatin:retnItems2.pig, applicationId=application_1500403084622_0001, dagName=PigLatin:retnItems2.pig-0_scope-0
17/07/18 18:44:49 INFO impl.TimelineClientImpl: Timeline service address: http://ip-172-18-109-126.us-west-2.compute.internal:8188/ws/v1/timeline/
17/07/18 18:44:49 INFO client.RMProxy: Connecting to ResourceManager at ip-172-18-109-126.us-west-2.compute.internal/172.18.109.126:8032
15505 [PigTezLauncher-0] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezJob  - Submitted DAG PigLatin:retnItems2.pig-0_scope-0. Application id: application_1500403084622_0001
17/07/18 18:44:49 INFO tez.TezJob: Submitted DAG PigLatin:retnItems2.pig-0_scope-0. Application id: application_1500403084622_0001
15940 [main] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezLauncher  - HadoopJobId: job_1500403084622_0001
17/07/18 18:44:50 INFO tez.TezLauncher: HadoopJobId: job_1500403084622_0001
16512 [Timer-0] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezJob  - DAG Status: status=RUNNING, progress=TotalTasks: 74 Succeeded: 0 Running: 0 Failed: 0 Killed: 0, diagnostics=, counters=null
17/07/18 18:44:50 INFO tez.TezJob: DAG Status: status=RUNNING, progress=TotalTasks: 74 Succeeded: 0 Running: 0 Failed: 0 Killed: 0, diagnostics=, counters=null
36512 [Timer-0] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezJob  - DAG Status: status=RUNNING, progress=TotalTasks: 6 Succeeded: 5 Running: 1 Failed: 0 Killed: 0 FailedTaskAttempts: 2, diagnostics=, counters=null
17/07/18 18:45:10 INFO tez.TezJob: DAG Status: status=RUNNING, progress=TotalTasks: 6 Succeeded: 5 Running: 1 Failed: 0 Killed: 0 FailedTaskAttempts: 2, diagnostics=, counters=null
17/07/18 18:45:15 INFO counters.Limits: Counter limits initialized with parameters:  GROUP_NAME_MAX=256, MAX_GROUPS=500, COUNTER_NAME_MAX=64, MAX_COUNTERS=120
40670 [PigTezLauncher-0] INFO  org.apache.pig.backend.hadoop.executionengine.tez.TezJob  - DAG Status: status=FAILED, progress=TotalTasks: 6 Succeeded: 5 Running: 0 Failed: 1 Killed: 0 FailedTaskAttempts: 4, diagnostics=Vertex failed, vertexName=scope-370, vertexId=vertex_1500403084622_0001_1_05, diagnostics=[Task failed, taskId=task_1500403084622_0001_1_05_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1500403084622_0001_1_05_000000_0:org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [es-elb.ertm-e3.aws.cloud.nordstrom.net:443] returned Bad Request(400) - [StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]]; Bailing out..
        at org.elasticsearch.hadoop.rest.RestClient.retryFailedEntries(RestClient.java:207)
        at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:170)
        at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:225)
        at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:248)
        at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:267)
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.doClose(EsOutputFormat.java:214)
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.close(EsOutputFormat.java:196)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.close(PigOutputFormat.java:154)
        at org.apache.tez.mapreduce.output.MROutput.flush(MROutput.java:546)
        at org.apache.pig.backend.hadoop.executionengine.tez.runtime.PigProcessor.run(PigProcessor.java:272)
        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:748)
], TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1500403084622_0001_1_05_000000_1:org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [es-elb.ertm-e3.aws.cloud.nordstrom.net:443] returned Bad Request(400) - [StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]]; Bailing out..
        at org.elasticsearch.hadoop.rest.RestClient.retryFailedEntries(RestClient.java:207)
        at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:170)
        at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:225)
        at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:248)
        at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:267)
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.doClose(EsOutputFormat.java:214)
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.close(EsOutputFormat.java:196)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.close(PigOutputFormat.java:154)
        at org.apache.tez.mapreduce.output.MROutput.flush(MROutput.java:546)
        at org.apache.pig.backend.hadoop.executionengine.tez.runtime.PigProcessor.run(PigProcessor.java:272)
        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:748)
], TaskAttempt 2 failed, info=[Error: Error while running task ( failure ) : attempt_1500403084622_0001_1_05_000000_2:org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [es-elb.ertm-e3.aws.cloud.nordstrom.net:443] returned Bad Request(400) - [StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]]; Bailing out..
```
Worker:
```
2017-07-18 19:24:45,801 [DEBUG] [TezChild] |rest.NetworkClient|: Opening (pinned) network client to
 es-elb.x-e3.aws.cloud.example.net:443
2017-07-18 19:24:45,801 [DEBUG] [TezChild] |params.DefaultHttpParams|: Set parameter http.method.re
try-handler = org.elasticsearch.hadoop.rest.commonshttp.CommonsHttpTransport$1@169ef9f2
2017-07-18 19:24:45,801 [DEBUG] [TezChild] |params.DefaultHttpParams|: Set parameter http.connectio
n-manager.timeout = 60000000
2017-07-18 19:24:45,801 [DEBUG] [TezChild] |params.DefaultHttpParams|: Set parameter http.socket.ti
meout = 60000000
2017-07-18 19:24:45,801 [DEBUG] [TezChild] |params.DefaultHttpParams|: Set parameter http.protocol.
credential-charset = UTF-8
2017-07-18 19:24:45,801 [DEBUG] [TezChild] |params.DefaultHttpParams|: Set parameter http.protocol.
content-charset = UTF-8
2017-07-18 19:24:45,801 [DEBUG] [TezChild] |commonshttp.CommonsHttpTransport|: SSL Connection enabl
ed
2017-07-18 19:24:45,801 [TRACE] [TezChild] |httpclient.HttpState|: enter HttpState.setCredentials(A
uthScope, Credentials)
2017-07-18 19:24:45,802 [INFO] [TezChild] |commonshttp.CommonsHttpTransport|: Using detected HTTP A
uth credentials...
2017-07-18 19:24:45,802 [DEBUG] [TezChild] |params.DefaultHttpParams|: Set parameter http.authentic
ation.preemptive = true
2017-07-18 19:24:45,802 [DEBUG] [TezChild] |params.DefaultHttpParams|: Set parameter http.tcp.nodel
ay = true
2017-07-18 19:24:45,802 [TRACE] [TezChild] |commonshttp.CommonsHttpTransport|: Opening HTTP transpo
rt to es-elb.x-e3.aws.cloud.example.net:443
2017-07-18 19:24:45,803 [TRACE] [TezChild] |mr.EsOutputFormat|: Starting heartbeat for task_1500403
0846225_0004_r_000000
2017-07-18 19:24:45,809 [TRACE] [TezChild] |bulk.AbstractBulkFactory|: Instantiated value writer [o
rg.elasticsearch.hadoop.pig.PigValueWriter@9723224]
2017-07-18 19:24:45,809 [TRACE] [TezChild] |bulk.AbstractBulkFactory|: Instantiated id extractor [P
igFieldExtractor for field [[documentID]]]
2017-07-18 19:24:45,828 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=172, length=140
2017-07-18 19:24:45,828 [TRACE] [TezChild] |pig.EsStorage|: Writing out tuple (1110108647_1,2017-01
-12T16:00:00.000-0800,0808,8567,4082,2017-01-07T16:00:00.000-0800,1,808,8568,6552,2017-01-16T16:00:
00.000-0800,RETN,1110108647,1)
2017-07-18 19:24:45,828 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=42, length=49
2017-07-18 19:24:45,829 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=22, length=35
2017-07-18 19:24:45,829 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=168, length=135
2017-07-18 19:24:45,829 [TRACE] [TezChild] |pig.EsStorage|: Writing out tuple (1110122661_1,2017-01
-08T16:00:00.000-0800,4,4316,1371,2017-01-16T16:00:00.000-0800,1,4,4316,1410,2017-01-23T16:00:00.00
0-0800,RETN,1110122661,1)
2017-07-18 19:24:45,829 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=22, length=35
2017-07-18 19:24:45,830 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=42, length=50
2017-07-18 19:24:45,830 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=62, length=59
2017-07-18 19:24:45,830 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=22, length=35
2017-07-18 19:24:45,830 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=166, length=137
2017-07-18 19:24:45,830 [TRACE] [TezChild] |pig.EsStorage|: Writing out tuple (1110327539_1,2017-01
-09T16:00:00.000-0800,48,1201,7,2017-01-18T16:00:00.000-0800,1,48,1206,584,2017-02-20T16:00:00.000-
0800,RETN,1110327539,1)
2017-07-18 19:24:45,830 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=166, length=136
2017-07-18 19:24:45,831 [TRACE] [TezChild] |pig.EsStorage|: Writing out tuple (1110327545_1,2017-01
-09T16:00:00.000-0800,48,1201,10,2017-01-18T16:00:00.000-0800,3,48,1221,11,2017-02-20T16:00:00.000-
0800,RETN,1110327545,1)
2017-07-18 19:24:45,831 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1
, bytesRead=165, length=138
2017-07-18 19:24:45,831 [TRACE] [TezChild] |pig.EsStorage|: Writing out tuple (1110327546_1,2017-01-09T16:00:00.000-0800,48,1201,9,2017-01-18T16:00:00.000-0800,3,48,1221,12,2017-02-20T16:00:00.000-0800,RETN,1110327546,1)
2017-07-18 19:24:45,831 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1, bytesRead=42, length=50
2017-07-18 19:24:45,832 [DEBUG] [TezChild] |impl.IFile|: currentKeyLength=-1, currentValueLength=-1, bytesRead=22, length=35
2017-07-18 19:24:45,832 [DEBUG] [IPC Client (1754444726) connection to ip-XXX-XXX-XXX-XXX.us-west-2.compute.internal/XXX.XXX.XXX.XXX:43380 from application_1500403084622_0004] |security.SaslRpcClient|: reading next wrapped RPC packet
2017-07-18 19:24:45,832 [DEBUG] [IPC Parameter Sending Thread #0] |ipc.Client|: IPC Client (1754444726) connection to ip-XXX-XXX-XXX-XXX.us-west-2.compute.internal/XXX.XXX.XXX.XXX:43380 from application_1500403084622_0004 sending #8
2017-07-18 19:24:45,832 [DEBUG] [IPC Parameter Sending Thread #0] |security.SaslRpcClient|: wrapping token of length:232
2017-07-18 19:24:45,833 [DEBUG] [IPC Client (1754444726) connection to ip-XXX-XXX-XXX-XXX.us-west-2.compute.internal/XXX.XXX.XXX.XXX:43380 from application_1500403084622_0004] |security.SaslRpcClient|: unwrapping token of length:62
2017-07-18 19:24:45,834 [DEBUG] [IPC Client (1754444726) connection to ip-XXX-XXX-XXX-XXX.us-west-2.compute.internal/XXX.XXX.XXX.XXX:43380 from application_1500403084622_0004] |ipc.Client|: IPC Client (1754444726) connection to ip-XXX-XXX-XXX-XXX.us-west-2.compute.internal/XXX.XXX.XXX.XXX:43380 from application_1500403084622_0004 got value #8
2017-07-18 19:24:45,834 [DEBUG] [TezChild] |ipc.RPC|: Call: canCommit 2
2017-07-18 19:24:45,834 [TRACE] [TezChild] |mr.EsOutputFormat|: Closing RecordWriter [null][null]
2017-07-18 19:24:45,834 [TRACE] [TezChild] |mr.EsOutputFormat|: Stopping heartbeat for task_15004030846225_0004_r_000000
2017-07-18 19:24:45,834 [DEBUG] [TezChild] |rest.RestRepository|: Closing repository and connection to Elasticsearch ...
2017-07-18 19:24:45,834 [DEBUG] [TezChild] |rest.RestRepository|: Sending batch of [3236] bytes/[6] entries
2017-07-18 19:24:45,836 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.clearRequestBody()
2017-07-18 19:24:45,836 [TRACE] [TezChild] |commonshttp.CommonsHttpTransport|: Tx [PUT]@[es-elb.x-e3.aws.cloud.example.net:443][retnitems-e3-2017-01/retnitem/_bulk] w/ payload [{""update"":{""_id"":""1110108646_1""}}
{""doc_as_upsert"":true,""doc"":{""documentID"":""1110108646_1"",---sensitive fields removed----, ""retnTransactionLineItemSequenceNumber"":""1""}}
{""update"":{""_id"":""1110108647_1""}}
{""doc_as_upsert"":true,""doc"":{""documentID"":""1110108647_1"",---sensitive fields removed----,""retnTransactionLineItemSequenceNumber"":""1""}}
{""update"":{""_id"":""1110122661_1""}}
{""doc_as_upsert"":true,""doc"":{""documentID"":""1110122661_1"",---sensitive fields removed----""retnTransactionLineItemSequenceNumber"":""1""}}
{""update"":{""_id"":""1110327539_1""}}
{""doc_as_upsert"":true,""doc"":{""documentID"":""1110327539_1"",---sensitive fields removed----""retnTransactionLineItemSequenceNumber"":""1""}}
{""update"":{""_id"":""1110327545_1""}}
{""doc_as_upsert"":true,""doc"":{""documentID"":""1110327545_1"",---sensitive fields removed----""retnTransactionLineItemSequenceNumber"":""1""}}
{""update"":{""_id"":""1110327546_1""}}
{""doc_as_upsert"":true,""doc"":{""documentID"":""1110327546_1"",---sensitive fields removed----""retnTransactionLineItemSequenceNumber"":""1""}}
]
2017-07-18 19:24:45,836 [TRACE] [TezChild] |httpclient.HttpClient|: enter HttpClient.executeMethod(HttpMethod)
2017-07-18 19:24:45,836 [TRACE] [TezChild] |httpclient.HttpClient|: enter HttpClient.executeMethod(HostConfiguration,HttpMethod,HttpState)
2017-07-18 19:24:45,836 [DEBUG] [TezChild] |httpclient.HttpMethodDirector|: Preemptively sending default basic credentials
2017-07-18 19:24:45,836 [DEBUG] [TezChild] |httpclient.HttpMethodDirector|: Authenticating with BASIC <any realm>@es-elb.x-e3.aws.cloud.example.net:443
2017-07-18 19:24:45,836 [TRACE] [TezChild] |httpclient.HttpState|: enter HttpState.getCredentials(AuthScope)
2017-07-18 19:24:45,836 [TRACE] [TezChild] |auth.BasicScheme|: enter BasicScheme.authenticate(Credentials, HttpMethod)
2017-07-18 19:24:45,836 [TRACE] [TezChild] |auth.BasicScheme|: enter BasicScheme.authenticate(UsernamePasswordCredentials, String)
2017-07-18 19:24:45,836 [TRACE] [TezChild] |httpclient.HttpMethodBase|: HttpMethodBase.addRequestHeader(Header)
2017-07-18 19:24:45,836 [TRACE] [TezChild] |httpclient.HttpMethodDirector|: Attempt number 1 to process request
2017-07-18 19:24:45,836 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.open()
2017-07-18 19:24:45,836 [DEBUG] [TezChild] |httpclient.HttpConnection|: Open connection to es-elb.x-e3.aws.cloud.example.net:443
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.execute(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.writeRequest(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.writeRequestLine(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.generateRequestLine(HttpConnection, String, String, String, String)
2017-07-18 19:24:45,840 [DEBUG] [TezChild] |wire.header|: >> ""PUT /retnitems-e3-2017-01/retnitem/_bulk HTTP/1.1[\r][\n]""
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.print(String)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[])
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[], int, int)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.writeRequestHeaders(HttpState,HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.addRequestHeaders(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |methods.ExpectContinueMethod|: enter ExpectContinueMethod.addRequestHeaders(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.addRequestHeaders(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.addUserAgentRequestHeaders(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.addHostRequestHeader(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [DEBUG] [TezChild] |httpclient.HttpMethodBase|: Adding Host request header
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.addCookieRequestHeader(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpState|: enter HttpState.getCookies()
2017-07-18 19:24:45,840 [TRACE] [TezChild] |cookie.CookieSpec|: enter CookieSpecBase.match(String, int, String, boolean, Cookie[])
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.addProxyConnectionHeader(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.addContentLengthRequestHeader(HttpState, HttpConnection)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.getRequestContentLength()
2017-07-18 19:24:45,840 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.hasRequestContent()
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpMethodBase|: HttpMethodBase.addRequestHeader(Header)
2017-07-18 19:24:45,840 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.renerateRequestBody()
2017-07-18 19:24:45,840 [DEBUG] [TezChild] |wire.header|: >> ""Authorization: Basic ZXNfdXNlcjpFcnRtX2VzX3VzM3I=[\r][\n]""
2017-07-18 19:24:45,840 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.print(String)
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[])
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[], int, int)
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.header|: >> ""User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]""
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.print(String)
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[])
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[], int, int)
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.header|: >> ""Host: es-elb.x-e3.aws.cloud.example.net[\r][\n]""
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.print(String)
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[])
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[], int, int)
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.header|: >> ""Content-Length: 3236[\r][\n]""
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.print(String)
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[])
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[], int, int)
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.header|: >> ""Content-Type: application/json; charset=UTF-8[\r][\n]""
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.print(String)
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[])
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[], int, int)
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.writeLine()
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.writeLine()
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[])
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.write(byte[], int, int)
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.header|: >> ""[\r][\n]""
2017-07-18 19:24:45,841 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.writeRequestBody(HttpState, HttpConnection)
2017-07-18 19:24:45,841 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.hasRequestContent()
2017-07-18 19:24:45,841 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.getRequestContentLength()
2017-07-18 19:24:45,841 [TRACE] [TezChild] |methods.EntityEnclosingMethod|: enter EntityEnclosingMethod.hasRequestContent()
2017-07-18 19:24:45,841 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.getRequestOutputStream()
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.content|: >> ""{""update"":{""_id"":""1110108646_1""}}[\n]""
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.content|: >> ""{""doc_as_upsert"":true,""doc"":{""documentID"":""1110108646_1"",---sensitive fields removed----,""retnTransactionLineItemSequenceNumber"":""1""}}[\n]""
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.content|: >> ""{""update"":{""_id"":""1110108647_1""}}[\n]""
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.content|: >> ""{""doc_as_upsert"":true,""doc"":{""documentID"":""1110108647_1"",---sensitive fields removed----,""retnTransactionLineItemSequenceNumber"":""1""}}[\n]""
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.content|: >> ""{""update"":{""_id"":""1110122661_1""}}[\n]""
2017-07-18 19:24:45,841 [DEBUG] [TezChild] |wire.content|: >> ""{""doc_as_upsert"":true,""doc"":{""documentID"":""1110122661_1"",---sensitive fields removed----,""retnTransactionLineItemSequenceNumber"":""1""}}[\n]""
2017-07-18 19:24:45,853 [DEBUG] [TezChild] |wire.content|: >> ""{""update"":{""_id"":""1110327539_1""}}[\n]""
2017-07-18 19:24:45,854 [DEBUG] [TezChild] |wire.content|:---sensitive fields removed----,""retnTransactionLineItemSequenceNumber"":""1""}}[\n]""
2017-07-18 19:24:45,854 [DEBUG] [TezChild] |wire.content|: >> ""{""update"":{""_id"":""1110327545_1""}}[\n]""
2017-07-18 19:24:45,854 [DEBUG] [TezChild] |wire.content|: >> ""{""doc_as_upsert"":true,""doc"":{""documentID"":""1110327545_1"",---sensitive fields removed----,""retnTransactionLineItemSequenceNumber"":""1""}}[\n]""
2017-07-18 19:24:45,854 [DEBUG] [TezChild] |wire.content|: >> ""{""update"":{""_id"":""1110327546_1""}}[\n]""
2017-07-18 19:24:45,854 [DEBUG] [TezChild] |wire.content|: >> ""{""doc_as_upsert"":true,""doc"":{""documentID"":""1110327546_1"",---sensitive fields removed----,""retnTransactionLineItemSequenceNumber"":""1""}}[\n]""
2017-07-18 19:24:45,855 [DEBUG] [TezChild] |methods.EntityEnclosingMethod|: Request body sent
2017-07-18 19:24:45,855 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.flushRequestOutputStream()
2017-07-18 19:24:45,855 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.readResponse(HttpState, HttpConnection)
2017-07-18 19:24:45,855 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.readStatusLine(HttpState, HttpConnection)
2017-07-18 19:24:45,855 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.readLine()
2017-07-18 19:24:45,855 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readLine(InputStream, String)
2017-07-18 19:24:45,855 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readRawLine()
2017-07-18 19:24:45,860 [DEBUG] [TezChild] |wire.header|: << ""HTTP/1.1 200 OK[\r][\n]""
2017-07-18 19:24:45,860 [DEBUG] [TezChild] |wire.header|: << ""HTTP/1.1 200 OK[\r][\n]""
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.readResponseHeaders(HttpState,HttpConnection)
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.getResponseInputStream()
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HeaderParser.parseHeaders(InputStream, String)
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readLine(InputStream, String)
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readRawLine()
2017-07-18 19:24:45,860 [DEBUG] [TezChild] |wire.header|: << ""Content-Type: application/json; charset=UTF-8[\r][\n]""
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readLine(InputStream, String)
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readRawLine()
2017-07-18 19:24:45,860 [DEBUG] [TezChild] |wire.header|: << ""Content-Length: 1426[\r][\n]""
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readLine(InputStream, String)
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readRawLine()
2017-07-18 19:24:45,860 [DEBUG] [TezChild] |wire.header|: << ""Connection: keep-alive[\r][\n]""
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readLine(InputStream, String)
2017-07-18 19:24:45,860 [TRACE] [TezChild] |httpclient.HttpParser|: enter HttpParser.readRawLine()
2017-07-18 19:24:45,860 [DEBUG] [TezChild] |wire.header|: << ""[\r][\n]""
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.processResponseHeaders(HttpState, HttpConnection)
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.processCookieHeaders(Header[], HttpState, HttpConnection)
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.readResponseBody(HttpState, HttpConnection)
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.readResponseBody(HttpConnection)
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.getResponseInputStream()
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter HttpMethodBase.canResponseHaveBody(int)
2017-07-18 19:24:45,861 [DEBUG] [TezChild] |httpclient.HttpMethodBase|: Buffering response body
2017-07-18 19:24:45,861 [DEBUG] [TezChild] |wire.content|: << ""{""took"":4,""errors"":true,""items"":[{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110108646_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110108647_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110122661_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110327539_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110327545_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110327546_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}}]}""
2017-07-18 19:24:45,861 [DEBUG] [TezChild] |httpclient.HttpMethodBase|: Should NOT close connection in response to directive: keep-alive
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.isResponseAvailable()
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.releaseConnection()
2017-07-18 19:24:45,861 [DEBUG] [TezChild] |httpclient.HttpConnection|: Releasing connection back to connection manager.
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HttpMethodBase|: enter getContentCharSet( Header contentheader )
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HeaderElement|: enter HeaderElement.parseElements(String)
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HeaderElement|: enter HeaderElement.parseElements(char[])
2017-07-18 19:24:45,861 [TRACE] [TezChild] |httpclient.HeaderElement|: enter HeaderElement.getParameterByName(String)
2017-07-18 19:24:45,861 [TRACE] [TezChild] |commonshttp.CommonsHttpTransport|: Rx @[XXX.XXX.XXX.XXX] [200-OK] [{""took"":4,""errors"":true,""items"":[{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110108646_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110108647_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110122661_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110327539_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110327545_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}},{""update"":{""_index"":""retnitems-e3-2017-01"",""_type"":""retnitem"",""_id"":""1110327546_1"",""status"":400,""error"":""StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]""}}]}]
2017-07-18 19:24:45,861 [DEBUG] [TezChild] |httpclient.HttpMethodBase|: re-creating response stream from byte array
2017-07-18 19:24:45,861 [DEBUG] [TezChild] |httpclient.HttpMethodBase|: re-creating response stream from byte array
2017-07-18 19:24:45,871 [TRACE] [TezChild] |commonshttp.CommonsHttpTransport|: Closing HTTP transport to es-elb.x-e3.aws.cloud.example.net:443
2017-07-18 19:24:45,871 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.close()
2017-07-18 19:24:45,871 [TRACE] [TezChild] |httpclient.HttpConnection|: enter HttpConnection.closeSockedAndStreams()
2017-07-18 19:24:45,872 [ERROR] [TezChild] |runtime.PigProcessor|: Encountered exception while processing:
org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [es-elb.x-e3.aws.cloud.example.net:443] returned Bad Request(400) - [StrictDynamicMappingException[mapping set to strict, dynamic introduction of [documentID] within [retnitem] is not allowed]]; Bailing out..
        at org.elasticsearch.hadoop.rest.RestClient.retryFailedEntries(RestClient.java:207)
        at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:170)
        at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:225)
        at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:248)
        at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:267)
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.doClose(EsOutputFormat.java:214)
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.close(EsOutputFormat.java:196)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.close(PigOutputFormat.java:154)
        at org.apache.tez.mapreduce.output.MROutput.flush(MROutput.java:546)
        at org.apache.pig.backend.hadoop.executionengine.tez.runtime.PigProcessor.run(PigProcessor.java:272)
        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:370)
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:748)



``` 

### Version Info

OS:         :  4.4.35-33.55.amzn1.x86_64
JVM         :  openjdk version ""1.8.0_131""
Hadoop/Spark:  Hadoop 2.7.3-amzn-2
ES-Hadoop   :  pig-2.4.2
ES          :  1.x

<!--
If you are filing a feature request, please remove the above bug
report block and provide responses for all of the below items.
-->

### Feature description
","Could you include the logs from the workers? I have a hunch on where this might be breaking, but I want to make sure that it's not something else.

Edit: To elaborate - it seems that the serialization code for Pig does not uniformly apply the field filtering logic the same way that serialization code for other integrations do. I've still got some work to do in order to flesh out the exact place that it's breaking, but it definitely smells like a bug with Pig.",Added the workers logs
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/992,"### Issue description

In Pyspark, reading ES data with the option es.scroll.limit seems to cause the error ElasticsearchIllegalArgumentException[Malformed scrollId []]

### Steps to reproduce

df = spark.read.format(""org.elasticsearch.spark.sql"") 
.option(""es.nodes"", ""{my es nodes}"")
.option(""es.port"", ""9200"")
.option(""es.net.http.auth.user"", """") 
.option(""es.net.http.auth.pass"", """") 
.option(""es.net.proxy.http.host"", """")
.option(""es.net.proxy.http.port"", """")
.option(""es.net.proxy.http.user"", """")
.option(""es.net.proxy.http.pass"", """") 
.option(""pushdown"", ""true"") 
.option(""es.scroll.limit"",10)
.load(""{my index/type}"")
.select(""date"")

//first df.show is working
df.show() 
//second df.show is not
df.show() 

Strack trace:

17/05/17 15:54:14 WARN TaskSetManager: Lost task 0.0 in stage 7.0 (TID 41, 149.56.241.70, executor 2): org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: ElasticsearchIllegalArgumentException[Malformed scrollId []]

at org.elasticsearch.hadoop.rest.RestClient.checkResponse(RestClient.java:488)
at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:446)
at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:436)
at org.elasticsearch.hadoop.rest.RestClient.scroll(RestClient.java:497)
...
at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
...
at java.lang.Thread.run(Thread.java:745)

17/05/17 15:54:14 ERROR TaskSetManager: Task 0 in stage 7.0 failed 4 times; aborting job
Py4JJavaError Traceback (most recent call last)
in ()
----> 1 df.show()

/usr/local/spark/python/pyspark/sql/dataframe.pyc in show(self, n, truncate)
315 """"""
316 if isinstance(truncate, bool) and truncate:
--> 317 print(self._jdf.showString(n, 20))
318 else:
319 print(self._jdf.showString(n, int(truncate)))

/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in call(self, *args)
1131 answer = self.gateway_client.send_command(command)
1132 return_value = get_return_value(
-> 1133 answer, self.gateway_client, self.target_id, self.name)
1134 
1135 for temp_arg in temp_args:

/usr/local/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)
...
317 raise Py4JJavaError(
318 ""An error occurred while calling {0}{1}{2}.\n"".
--> 319 format(target_id, ""."", name), value)
320 else:
321 raise Py4JError(

Py4JJavaError: An error occurred while calling o110.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 4 times, most recent failure: Lost task 0.3 in stage 7.0 (TID 45, 149.56.241.70, executor 0): org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: ElasticsearchIllegalArgumentException[Malformed scrollId []]
...

Driver stacktrace:
at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1469)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1457)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1456)
at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1456)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)
at scala.Option.foreach(Option.scala:257)
at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1684)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1639)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1628)
at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2015)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2036)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)
at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)
at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:2785)
at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2112)
at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2112)
at org.apache.spark.sql.Dataset$$anonfun$57.apply(Dataset.scala:2769)
at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)
at org.apache.spark.sql.Dataset.withAction(Dataset.scala:2768)
at org.apache.spark.sql.Dataset.head(Dataset.scala:2112)
at org.apache.spark.sql.Dataset.take(Dataset.scala:2325)
at org.apache.spark.sql.Dataset.showString(Dataset.scala:251)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
at py4j.Gateway.invoke(Gateway.java:280)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.GatewayConnection.run(GatewayConnection.java:214)
at java.lang.Thread.run(Thread.java:745)
Caused by: org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: ElasticsearchIllegalArgumentException[Malformed scrollId []]

at org.elasticsearch.hadoop.rest.RestClient.checkResponse(RestClient.java:488)
at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:446)
at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:436)
at org.elasticsearch.hadoop.rest.RestClient.scroll(RestClient.java:497)
at org.elasticsearch.hadoop.rest.RestRepository.scroll(RestRepository.java:375)
at org.elasticsearch.hadoop.rest.ScrollQuery.hasNext(ScrollQuery.java:112)
...
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
... 1 more

### Version Info

OS:         :  Ubuntu 16.10
JVM         :  1.8.0_111
Hadoop/Spark:  2.2.0
ES-Hadoop   :  elasticsearch-spark-20_2.11-5.1.2.
ES          :  1.7.1

As seen <a href=""https://discuss.elastic.co/t/eshadoopinvalidrequest-malformed-scrollid-caused-by-es-scroll-limit/85990/5"">here</a>, James thinks it could be a backwards compatibility bug with ES 1.7.",Could you increase the logging to `TRACE` on the `org.elasticsearch.hadoop.rest.commonshttp` package and post the job logs here? That should hopefully shed some light on the missing scroll id.,
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/868,"<!--
GitHub is reserved *only* for bug reports and feature requests. The best place
to ask a general question is at the Elastic forums at
https://discuss.elastic.co/c/elasticsearch-and-hadoop.
If you are in fact posting a bug report or a feature request, please 
include one and only one of the below blocks in your new issue.
-->
### What kind an issue is this?
- [X ] Bug report. If you’ve found a bug, please provide a code snippet or test to reproduce it below.  
  The easier it is to track down the bug, the faster it is solved. 
- [ ] Feature Request. Start by telling us what problem you’re trying to solve.  
  Often a solution already exists! Don’t send pull requests to implement new features without 
  first getting our support. Sometimes we leave features out on purpose to keep the project small.
### Issue description

Description
### Steps to reproduce

Code:
  val sparkConf: SparkConf = new SparkConf().setAppName(""ES Test"")
        sparkConf.set(""es.read.field.include"", ""myFields"")
    val sql = SparkSession.builder().config(sparkConf).getOrCreate()

```
val index = ""index""

val dataSet = sql.esDF(s""$index/myType"")
```

Test/code snippet
See above

Strack trace:

2016-10-12 09:38:11,256 [Executor task launch worker-7] ERROR org.elasticsearch.hadoop.rest.NetworkClient - Node [127.0.
0.1:9200] failed (Invalid target URI POST@null/index/myType/_search?sort=_doc&scroll=5m&size=50&_source=myFields&preference=_shards:3|_local); no other nodes left - aborting...
2016-10-12 09:38:11,261 [Executor task launch worker-1] ERROR org.apache.spark.executor.Executor - Exception in task 1.0
 in stage 0.0 (TID 1)
org.elasticsearch.hadoop.rest.EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all
nodes failed; tried [[127.0.0.1:9200]]
        at org.elasticsearch.hadoop.rest.NetworkClient.execute(NetworkClient.java:150)
        at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:444)
        at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:436)
        at org.elasticsearch.hadoop.rest.RestRepository.scroll(RestRepository.java:363)
        at org.elasticsearch.hadoop.rest.ScrollQuery.hasNext(ScrollQuery.java:92)
        at org.elasticsearch.spark.rdd.AbstractEsRDDIterator.hasNext(AbstractEsRDDIterator.scala:43)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
        at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
        at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:3
70)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
        at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
        at org.apache.spark.scheduler.Task.run(Task.scala:85)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Stack trace goes here

```

### Version Info

OS:         :  Windows 7
JVM         :  Oracle 8
Hadoop/Spark:  2.0 and 2.01
ES-Hadoop   :  5.0 RC1
ES          :  5.0 RC1

The same code works fine with ES-Hadoop 5.0 Beta1 and ES 5.0 Beta1
I thought it might be the null in POST@null/index/myType/_search?sort=_doc&scroll=5m&size=50&_source=myFields&preference=_shards:3|_local)

So I tried setting es.nodes.path.prefix to """" but this did not fix it.  Since this code worked fine with the beta I think it is a bug in the RC.
```
","Could you post your mappings, index settings and any Spark settings that you have configured?
","The only thing I set in the spark settings are:
es.read.field.include = Name, Street, id, City, DOB, SSN
spark.sql.warehouse.dir = file:///C:/Users/me/spark-warehouse

I am running spark in standalone mode on the same machine as ES
Here are the mapping and index settings:

```
{
  ""myIndex"": {
    ""aliases"": {},
    ""mappings"": {
      ""Occupancies"": {
        ""_routing"": {
          ""required"": true
        },
        ""properties"": {
          ""DOB"": {
            ""type"": ""text"",
            ""analyzer"": ""date_analyzer"",
            ""fielddata"": true
          },
          ""Name"": {
            ""type"": ""text"",
            ""analyzer"": ""my_name_analyzer"",
            ""fielddata"": true
          },
          ""Street"": {
            ""type"": ""text"",
            ""analyzer"": ""address_analyzer""
          },
          ""clusterID"": {
            ""type"": ""text"",
            ""fielddata"": true
          }
        }
      }
    },
    ""settings"": {
      ""index"": {
        ""number_of_shards"": ""8"",
        ""provided_name"": ""myIndex"",
        ""creation_date"": ""1476290276005"",
        ""analysis"": {
          ""filter"": {
            ""address_formatter"": {
              ""name"": ""address_formatter"",
              ""type"": ""my_token_filter""
            },
            ""date_formatter"": {
              ""name"": ""date_formatter"",
              ""type"": ""my_token_filter""
            }
          },
          ""analyzer"": {
            ""address_analyzer"": {
              ""filter"": ""address_formatter"",
              ""type"": ""custom"",
              ""tokenizer"": ""standard""
            },
            ""date_analyzer"": {
              ""filter"": ""date_formatter"",
              ""type"": ""custom"",
              ""tokenizer"": ""standard""
            }
          }
        },
        ""number_of_replicas"": ""0"",
        ""uuid"": ""k3eXM7YGTpS9Srkddrn5Ug"",
        ""version"": {
          ""created"": ""5000051""
        }
      }
    }
  }
}
```
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/792,"### Issue description

I don't want to index fields with NULL values. It looks like a bug.

Original JSON document that I read from a file doesn't contain NULL values. A mapping doesn't use null_value also. After data loaded in data frame some fields like name.prefix, addresses.address2 are NULLs and these fields are created in ES index. 

Partial result from ES 

```
                     ""address1"": ""156 JUSTIN AVE"",
                     ""address2"": null,
                     ""asofdate"": null,
                     ""captured_at"": ""2016-06-10t05:34:01.616z"",
                     ""cd"": ""01"",
```
### Steps to reproduce

Code:

```
val personsDF = sqlContext.read.schema(sampleDataDF.schema).json(""data-file"")
val parentsDF = personsDF.select(""id"", ""sources"", ""captured_at"", ""identities"", ""names"", ""addresses"")
parentDF.saveToEs(""persons/person"", config)
```

parentsDF schema:

```
parentDF: org.apache.spark.sql.DataFrame = [id: string, sources: array<string>, captured_at: string, identities: struct<hhseq:bigint,m_matchkey:string,nb_id:string,r_matchkey:string,rnc_regid:string,strat_id:bigint,voter_id:string>, names: array<struct<captured_at:string,first_name:string,hash_value:string,instances:bigint,last_name:string,middle_name:string,owners:array<string>,prefix:string,sources:array<string>,suffix:string,value:string>>, addresses: array<struct<address1:string,address2:string,asofdate:string,captured_at:string,cd:string,cen_block:string,cen_tract:string,city:string,congressional_districts:array<string>,crc:string,dpc:string,fips:string,hash_value:string,instances:bigint,lat:double,ld:string,location:array<double>,lon:double,mail_score:bigint,owners:array<string>,raw_value:string,sd:string,sources:array<string>,state:string,street1:string,street2:string,type:string,value:string,zip:string,zip4:string>>]
```

parentsDF sample - parentsDF.take(1)

```
rres5: Array[org.apache.spark.sql.Row] = Array([546db9f0de8e558dacced669cc8d15b7,WrappedArray(value),2016-06-10t05:34:01.209z,[1111,null,111-08d1-11e2-b0f9-111,0626~~83~111~~~,{111-111-4fd6-983d-111},111,001377677],WrappedArray([2016-06-10t05:34:01.209z,value,value,1,value,e,WrappedArray(tv),null,WrappedArray(value),null,value]),WrappedArray([PERRY ST,UNIT 171,2014-04-23T00:00:00.000Z,2016-06-10t05:34:01.209z,02,8005,903100,value,WrappedArray(CT-02),c001,469,09015,83STCT06260,1,41.912786,051,WrappedArray(-77.897427, 41.912786),-77.897427,7,WrappedArray(tv),PERRY ST UNIT, PUTNAM, CT 06260,029,WrappedArray(value),CT,PERRY,null,registered,PERRY ST, UNIT, PUTNAM, CT 06260,06260,2249], [CROOKED TRAIL EXT,null,null,2016-06-10t05:34:01.209z,02,null,null,WOODSTOCK,WrappedArray(CT-02),null,null,09015,EXTCT06281,1,null,051,null,null,7,WrappedArray(tv),CROOKED TRAIL EXT, WOOD, CT 06281,029,WrappedArray(voterrecord201602),CT,null,null,mailing,TRAIL EXT, WOOD, CT 06281,06281,null])])
```
### Version Info

Hadoop/Spark:  Spark 1.6
ES-Hadoop   :  2.3.2
ES          :  2.3.1
","Do you have a data sample, it can be as simple as one, two entries/lines? It would help a lot in reproducing the problem and finding the bug.

Thanks,
","It works as expected if I am writing existing JSON to ES

```
>cat persons.txt
{""id"":""1"",""sources"":[""source1""],""captured_at"":""2016-06-10t05:34:01.578z"",""name"":{""fname"":""fname1"",""mname"":""mname1"",""lname"":""lname1""},""child_details"":{""value"":""details""}}
{""id"":""2"",""sources"":[""source1""],""captured_at"":""2016-06-10t05:34:01.578z"",""name"":{""fname"":""fname2"",""lname"":""lname2""},""child_details"":{""value"":""details""}}
```

```
import org.elasticsearch.spark.sql._

var config: Map[String,String] = Map()
config += (""es.nodes"" -> ""ip-xxx"")
config += (""es.mapping.id"" -> ""id"")  

val rdd = sc.textFile(""/mnt/spark/tests/persons.json"")
org.elasticsearch.spark.rdd.EsSpark.saveJsonToEs(rdd, ""persons_dev/person"", config)
```

Result (mname field for person2 hasn't been created)

```
""hits"": [
    {
       ""_source"": {
          ""id"": ""1"",
          ""name"": {
             ""fname"": ""fname1"",
             ""lname"": ""lname1"",
             ""mname"": ""mname1""
          }
       }
    },
    {
       ""_source"": {
          ""id"": ""2"",
          ""name"": {
             ""fname"": ""fname2"",
             ""lname"": ""lname2""
          }
       }
    }
 ]
```

But it creates mname field with NULL value if I save a data frame. 
I understand that when the JSON objects have been transformed to the typed data frame, we already have these NULL values. The question is can you add a feature to reject NULLs and don't index such fields? 

```
 val person1 = """"""{""id"":""1"",""sources"":[""source1""],""captured_at"":""2016-06-10t05:34:01.578z"",""name"":{""fname"":""fname1"",""mname"":""mname1"",""lname"":""lname1""},""child_details"":{""value"":""details""}}""""""      
 val person2 = """"""{""id"":""2"",""sources"":[""source1""],""captured_at"":""2016-06-10t05:34:01.579z"",""name"":{""fname"":""fname2"",""lname"":""lname2""},""child_details"":{""value"":""details""}}""""""

 val jsonRdd = sc.makeRDD(Seq(person1, person2))

 val jsonDf = sqlContext.read.json(jsonRdd).toDF.select($""id"", $""name"")
```

```
jsonDf.printSchema


 > jsonDf.printSchema
 root
  |-- id: string (nullable = true)
  |-- name: struct (nullable = true)
  |    |-- fname: string (nullable = true)
  |    |-- lname: string (nullable = true)
  |    |-- mname: string (nullable = true)
```

```
> jsonDf.collect
Array[org.apache.spark.sql.Row] = Array([1,[fname1,lname1,mname1]], [2,[fname2,lname2,null]])
```

```
import org.elasticsearch.spark.sql._

var config: Map[String,String] = Map()
config += (""es.nodes"" -> ""ip-xxx"")
config += (""es.mapping.id"" -> ""id"")  

jsonDf.saveToEs(""persons_dev/person"", config)
```

Result (mname field for person2 has been created)

```
""hits"": [
    {
       ""_source"": {
          ""id"": ""1"",
          ""name"": {
             ""fname"": ""fname1"",
             ""lname"": ""lname1"",
             ""mname"": ""mname1""
          }
       }
    },
    {
       ""_source"": {
          ""id"": ""2"",
          ""name"": {
             ""fname"": ""fname2"",
             ""lname"": ""lname2"",
             ""mname"": null
          }
       }
    }
 ]
```

Thank you in advance!
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/697,"Hi
I'm testing new nightly build of elasticsearch spark lib and I`m running into difficulties when creating spark DF
I'm using spark 1.5.2 and elasticsearch-spark_2.10-2.3.0.BUILD-20160211.040132-9.jar

```
  val options = Map(
    ""pushdown"" -> ""true"",
    ""es.nodes.discovery"" -> ""true"",
    ""es.nodes"" -> ""10.0.0.230"",
    ""es.port"" -> ""9200"",
    ""es.nodes.client.only"" -> ""true"",
    ""es.index.read.missing.as.empty"" -> ""true""
  )


  val y = sqlContext.esDF(""logstash-sy-ship-2016.01.29/logs"", options)
  y.first()
  println(y.schema.treeString)

```

```
16/02/11 16:43:25 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, dwh-mapr-dev-01): scala.MatchError: Buffer(_default) (of class scala.collection.convert.Wrappers$JListWrapper)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:295)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:294)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:260)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:250)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:260)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:250)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$$anonfun$createToCatalystConverter$2.apply(CatalystTypeConverters.scala:401)
        at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:63)
        at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:60)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
        at scala.collection.AbstractIterator.to(Iterator.scala:1157)
        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
        at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:88)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
16/02/11 16:43:25 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, dwh-mapr-dev-01): scala.MatchError: Buffer(_default) (of class scala.collection.convert.Wrappers$JListWrapper)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:295)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:294)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:260)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:250)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:260)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:250)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$$anonfun$createToCatalystConverter$2.apply(CatalystTypeConverters.scala:401)
        at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:63)
        at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:60)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
        at scala.collection.AbstractIterator.to(Iterator.scala:1157)
        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
        at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:88)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
        at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447)
        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)
        at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:215)
        at org.apache.spark.sql.execution.Limit.executeCollect(basicOperators.scala:207)
        at org.apache.spark.sql.DataFrame$$anonfun$collect$1.apply(DataFrame.scala:1385)
        at org.apache.spark.sql.DataFrame$$anonfun$collect$1.apply(DataFrame.scala:1385)
        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)
        at org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:1903)
        at org.apache.spark.sql.DataFrame.collect(DataFrame.scala:1384)
        at org.apache.spark.sql.DataFrame.head(DataFrame.scala:1314)
        at org.apache.spark.sql.DataFrame.head(DataFrame.scala:1321)
        at org.apache.spark.sql.DataFrame.first(DataFrame.scala:1328)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:32)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:34)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:36)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:38)
        at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:40)
        at $iwC$$iwC$$iwC$$iwC.<init>(<console>:42)
        at $iwC$$iwC$$iwC.<init>(<console>:44)
        at $iwC$$iwC.<init>(<console>:46)
        at $iwC.<init>(<console>:48)
        at <init>(<console>:50)
        at .<init>(<console>:54)
        at .<clinit>(<console>)
        at .<init>(<console>:7)
        at .<clinit>(<console>)
        at $print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
        at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
        at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
        at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:674)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

Caused by: scala.MatchError: Buffer(_default) (of class scala.collection.convert.Wrappers$JListWrapper)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:295)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:294)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:260)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:250)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:260)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:250)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
        at org.apache.spark.sql.catalyst.CatalystTypeConverters$$anonfun$createToCatalystConverter$2.apply(CatalystTypeConverters.scala:401)
        at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:63)
        at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:60)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
        at scala.collection.AbstractIterator.to(Iterator.scala:1157)
        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
        at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:88)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

```
","Can you please post your mapping in ES and the output from `df.schema.treeString`?
","Hi
schema:

```
 |-- @timestamp: timestamp (nullable = true)
 |-- @version: string (nullable = true)
 |-- campaign: struct (nullable = true)
 |    |-- affiliate_id: string (nullable = true)
 |    |-- camp_id: string (nullable = true)
 |    |-- camp_network: string (nullable = true)
 |    |-- created_time: timestamp (nullable = true)
 |    |-- sub_camp_id: string (nullable = true)
 |    |-- url: string (nullable = true)
 |    |-- url_object: struct (nullable = true)
 |    |    |-- address: string (nullable = true)
 |    |    |-- parameters: struct (nullable = true)
 |    |    |    |-- ad_id: string (nullable = true)
 |    |    |    |-- camp_id: string (nullable = true)
 |    |    |    |-- fb_locale: string (nullable = true)
 |    |    |    |-- fb_source: string (nullable = true)
 |    |    |    |-- page_type: string (nullable = true)
 |    |    |    |-- signed_request: string (nullable = true)
 |    |    |    |-- sub_id: string (nullable = true)
 |-- current_state: struct (nullable = true)
 |    |-- level: long (nullable = true)
 |-- event_data: struct (nullable = true)
 |    |-- action: string (nullable = true)
 |    |-- activity: string (nullable = true)
 |    |-- amount: string (nullable = true)
 |    |-- date_0: timestamp (nullable = true)
 |    |-- camp_id: string (nullable = true)
 |    |-- captain_charges: long (nullable = true)
 |    |-- captain_id: long (nullable = true)
 |    |-- cargo: string (nullable = true)
 |    |-- contractor_id: string (nullable = true)
 |    |-- country: string (nullable = true)
 |    |-- crew: string (nullable = true)
 |    |-- def_id: long (nullable = true)
 |    |-- dest_id: string (nullable = true)
 |    |-- device: string (nullable = true)
 |    |-- done: long (nullable = true)
 |    |-- earn: struct (nullable = true)
 |    |    |-- material: struct (nullable = true)
 |    |    |    |-- 1: long (nullable = true)
 |    |    |    |-- 2: long (nullable = true)
 |    |    |    |-- 3: long (nullable = true)
 |    |    |    |-- 4: long (nullable = true)
 |    |    |    |-- 5: long (nullable = true)
 |    |    |    |-- 6: long (nullable = true)
 |    |    |    |-- 7: long (nullable = true)
 |    |    |    |-- 8: long (nullable = true)
 |    |    |-- xp: long (nullable = true)
 |    |-- string_1: string (nullable = true)
 |    |-- string_2: string (nullable = true)
 |    |-- id_1: long (nullable = true)
 |    |-- id_2: long (nullable = true)
 |    |-- id_3: long (nullable = true)
 |    |-- gender: string (nullable = true)
 |    |-- inst_id: string (nullable = true)
 |    |-- invited_by: long (nullable = true)
 |    |-- ip: string (nullable = true)
 |    |-- lang: string (nullable = true)
 |    |-- date_2: timestamp (nullable = true)
 |    |-- level: integer (nullable = true)
 |    |-- login_time: timestamp (nullable = true)
 |    |-- material_id: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- outpost_id: string (nullable = true)
 |    |-- id_4: string (nullable = true)
 |    |-- id_5: long (nullable = true)
 |    |-- platform: string (nullable = true)
 |    |-- progress: long (nullable = true)
 |    |-- ref: string (nullable = true)
 |    |-- register_ip: string (nullable = true)
 |    |-- register_time: timestamp (nullable = true)
 |    |-- session_token: string (nullable = true)
 |    |-- spent: struct (nullable = true)
 |    |    |-- material: struct (nullable = true)
 |    |    |    |-- 1: long (nullable = true)
 |    |    |    |-- 2: long (nullable = true)
 |    |    |    |-- 3: long (nullable = true)
 |    |    |    |-- 4: long (nullable = true)
 |    |    |    |-- 5: long (nullable = true)
 |    |    |    |-- 6: long (nullable = true)
 |    |    |    |-- 7: long (nullable = true)
 |    |    |    |-- 8: long (nullable = true)
 |    |-- sub_camp_id: string (nullable = true)
 |    |-- surname: string (nullable = true)
 |    |-- target_id: long (nullable = true)
 |    |-- type: string (nullable = true)
 |    |-- user_type: string (nullable = true)
 |-- event_type: string (nullable = true)
 |-- geoip: struct (nullable = true)
 |    |-- location: struct (nullable = true)
 |    |    |-- lat: double (nullable = true)
 |    |    |-- lon: double (nullable = true)
 |-- id_6: long (nullable = true)
 |-- project: string (nullable = true)
 |-- static: struct (nullable = true)
 |    |-- int_1: integer (nullable = true)
 |    |-- date_3: timestamp (nullable = true)
 |    |-- b_t: string (nullable = true)
 |    |-- camp_id: string (nullable = true)
 |    |-- camp_network: string (nullable = true)
 |    |-- country: string (nullable = true)
 |    |-- d_i_g: integer (nullable = true)
 |    |-- device: string (nullable = true)
 |    |-- disabled: long (nullable = true)
 |    |-- e_1: string (nullable = true)
 |    |-- e_2: string (nullable = true)
 |    |-- f_id: long (nullable = true)
 |    |-- fn_string: string (nullable = true)
 |    |-- gid: string (nullable = true)
 |    |-- g: string (nullable = true)
 |    |-- i: long (nullable = true)
 |    |-- lang: string (nullable = true)
 |    |-- language: string (nullable = true)
 |    |-- l_string: string (nullable = true)
 |    |-- login_type: string (nullable = true)
 |    |-- name: string (nullable = true)
 |    |-- pid: long (nullable = true)
 |    |-- platform: string (nullable = true)
 |    |-- pid_2: string (nullable = true)
 |    |-- ref: string (nullable = true)
 |    |-- register_ip: string (nullable = true)
 |    |-- register_platform: string (nullable = true)
 |    |-- register_time: timestamp (nullable = true)
 |    |-- sub_camp_id: string (nullable = true)
 |    |-- su_string: string (nullable = true)
 |    |-- url: string (nullable = true)
 |    |-- url_object: struct (nullable = true)
 |    |    |-- address: string (nullable = true)
 |    |    |-- parameters: struct (nullable = true)
 |    |    |    |-- __mref: string (nullable = true)
 |    |    |    |-- ad_id: string (nullable = true)
 |    |    |    |-- app_request_type: string (nullable = true)
 |    |    |    |-- camp_id: string (nullable = true)
 |    |    |    |-- count: string (nullable = true)
 |    |    |    |-- fb_action_ids: string (nullable = true)
 |    |    |    |-- fb_action_types: string (nullable = true)
 |    |    |    |-- fb_appcenter: string (nullable = true)
 |    |    |    |-- fb_bmpos: string (nullable = true)
 |    |    |    |-- fb_locale: string (nullable = true)
 |    |    |    |-- fb_source: string (nullable = true)
 |    |    |    |-- fbs: string (nullable = true)
 |    |    |    |-- fref: string (nullable = true)
 |    |    |    |-- hc_location: string (nullable = true)
 |    |    |    |-- notif_t: string (nullable = true)
 |    |    |    |-- page_type: string (nullable = true)
 |    |    |    |-- ref: string (nullable = true)
 |    |    |    |-- request_ids: string (nullable = true)
 |    |    |    |-- signed_request: string (nullable = true)
 |    |    |    |-- sub_id: string (nullable = true)
 |    |-- user_type: string (nullable = true)
 |-- tech: struct (nullable = true)
 |    |-- app_version_client: string (nullable = true)
 |    |-- app_version_server: string (nullable = true)
 |    |-- a_id: string (nullable = true)
 |    |-- browser: string (nullable = true)
 |    |-- browser_version: string (nullable = true)
 |    |-- default: boolean (nullable = true)
 |    |-- device: string (nullable = true)
 |    |-- device_model: string (nullable = true)
 |    |-- login_type: string (nullable = true)
 |    |-- os: string (nullable = true)
 |    |-- os_version: string (nullable = true)
 |    |-- platform: string (nullable = true)
 |    |-- resolution: string (nullable = true)
 |-- timestamp: timestamp (nullable = true)
```

my mappings

```
{
  ""logstash-sy-ship-2016.01.29"": {
    ""mappings"": {
      ""logs"": {
        ""dynamic_templates"": [
          {
            ""SUBJECT_STRINGS_ONLY"": {
              ""mapping"": {
                ""index"": ""not_analyzed"",
                ""type"": ""string"",
                ""doc_values"": true
              },
              ""path_match"": ""event_data.subject.*""
            }
          },
          {
            ""URL_OBJECT_STRINGS_ONLY"": {
              ""mapping"": {
                ""index"": ""not_analyzed"",
                ""type"": ""string"",
                ""doc_values"": true
              },
              ""path_match"": ""*url_object.parameters.*""
            }
          },
          {
            ""date_fields"": {
              ""mapping"": {
                ""format"": ""dateOptionalTime"",
                ""type"": ""date"",
                ""doc_values"": true
              },
              ""match"": ""*"",
              ""match_mapping_type"": ""date""
            }
          },
          {
            ""string_fields"": {
              ""mapping"": {
                ""index"": ""not_analyzed"",
                ""omit_norms"": true,
                ""type"": ""string"",
                ""doc_values"": true
              },
              ""match"": ""*"",
              ""match_mapping_type"": ""string""
            }
          },
          {
            ""integer_fields"": {
              ""mapping"": {
                ""type"": ""integer"",
                ""doc_values"": true
              },
              ""match"": ""*"",
              ""match_mapping_type"": ""integer""
            }
          },
          {
            ""long_fields"": {
              ""mapping"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""match"": ""*"",
              ""match_mapping_type"": ""long""
            }
          },
          {
            ""float_fields"": {
              ""mapping"": {
                ""type"": ""float"",
                ""doc_values"": true
              },
              ""match"": ""*"",
              ""match_mapping_type"": ""float""
            }
          },
          {
            ""double_fields"": {
              ""mapping"": {
                ""type"": ""double"",
                ""doc_values"": true
              },
              ""match"": ""*"",
              ""match_mapping_type"": ""double""
            }
          }
        ],
        ""_all"": {
          ""enabled"": true
        },
        ""properties"": {
          ""@timestamp"": {
            ""type"": ""date"",
            ""doc_values"": true,
            ""format"": ""dateOptionalTime""
          },
          ""@version"": {
            ""type"": ""string"",
            ""index"": ""not_analyzed""
          },
          ""campaign"": {
            ""properties"": {
              ""affiliate_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""camp_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""camp_network"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""created_time"": {
                ""type"": ""date"",
                ""doc_values"": true,
                ""format"": ""dateOptionalTime""
              },
              ""sub_camp_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""url"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""url_object"": {
                ""properties"": {
                  ""address"": {
                    ""type"": ""string"",
                    ""index"": ""not_analyzed"",
                    ""doc_values"": true
                  },
                  ""parameters"": {
                    ""properties"": {
                      ""ad_id"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""camp_id"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_locale"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_source"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""page_type"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""signed_request"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""sub_id"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      }
                    }
                  }
                }
              }
            }
          },
          ""current_state"": {
            ""properties"": {
              ""level"": {
                ""type"": ""long"",
                ""doc_values"": true
              }
            }
          },
          ""event_data"": {
            ""properties"": {
              ""action"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""activity"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""amount"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""date_0"": {
                ""type"": ""date"",
                ""doc_values"": true,
                ""ignore_malformed"": true,
                ""format"": ""YYYY-MM-dd""
              },
              ""camp_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""0""
              },
              ""captain_charges"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""captain_id"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""cargo"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""contractor_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""country"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""XX""
              },
              ""crew"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""def_id"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""dest_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""device"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""unknown""
              },
              ""done"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""earn"": {
                ""properties"": {
                  ""material"": {
                    ""properties"": {
                      ""1"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""2"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""3"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""4"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""5"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""6"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""7"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""8"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      }
                    }
                  },
                  ""xp"": {
                    ""type"": ""long"",
                    ""doc_values"": true
                  }
                }
              },
              ""string_1"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""string_2"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""id_1"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""id_2"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""id_3"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""gender"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""inst_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""invited_by"": {
                ""type"": ""long"",
                ""doc_values"": true,
                ""null_value"": 0
              },
              ""ip"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""lang"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""date_2"": {
                ""type"": ""date"",
                ""doc_values"": true,
                ""format"": ""dateOptionalTime""
              },
              ""level"": {
                ""type"": ""integer"",
                ""doc_values"": true,
                ""null_value"": 0
              },
              ""login_time"": {
                ""type"": ""date"",
                ""doc_values"": true,
                ""format"": ""dateOptionalTime""
              },
              ""material_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""name"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""outpost_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""id_4"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""id_5"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""platform"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""unknown""
              },
              ""progress"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""ref"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""register_ip"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""register_time"": {
                ""type"": ""date"",
                ""doc_values"": true,
                ""format"": ""dateOptionalTime""
              },
              ""session_token"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""spent"": {
                ""properties"": {
                  ""material"": {
                    ""properties"": {
                      ""1"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""2"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""3"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""4"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""5"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""6"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""7"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      },
                      ""8"": {
                        ""type"": ""long"",
                        ""doc_values"": true
                      }
                    }
                  }
                }
              },
              ""sub_camp_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""0""
              },
              ""surname"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""target_id"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""type"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""user_type"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""user""
              }
            }
          },
          ""event_type"": {
            ""type"": ""string"",
            ""index"": ""not_analyzed"",
            ""doc_values"": true,
            ""null_value"": ""unknown""
          },
          ""geoip"": {
            ""dynamic"": ""true"",
            ""properties"": {
              ""location"": {
                ""type"": ""geo_point"",
                ""doc_values"": true
              }
            }
          },
          ""id_6"": {
            ""type"": ""long"",
            ""doc_values"": true
          },
          ""project"": {
            ""type"": ""string"",
            ""index"": ""not_analyzed"",
            ""doc_values"": true,
            ""null_value"": ""unknown""
          },
          ""static"": {
            ""properties"": {
              ""int_1"": {
                ""type"": ""integer"",
                ""doc_values"": true
              },
              ""date_3"": {
                ""type"": ""date"",
                ""doc_values"": true,
                ""ignore_malformed"": true,
                ""format"": ""dateOptionalTime""
              },
              ""b_t"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""camp_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""0""
              },
              ""camp_network"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""country"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""XX""
              },
              ""d_i_g"": {
                ""type"": ""integer"",
                ""doc_values"": true
              },
              ""device"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""unknown""
              },
              ""disabled"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""e_1"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""e_2"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""f_id"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""fn_string"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""gid"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""g"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""i"": {
                ""type"": ""long"",
                ""doc_values"": true,
                ""null_value"": 0
              },
              ""lang"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""language"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""l_string"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""login_type"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""name"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""pid"": {
                ""type"": ""long"",
                ""doc_values"": true
              },
              ""platform"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""unknown""
              },
              ""pid_2"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""ref"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""register_ip"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""register_platform"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""unknown""
              },
              ""register_time"": {
                ""type"": ""date"",
                ""doc_values"": true,
                ""format"": ""dateOptionalTime""
              },
              ""sub_camp_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""0""
              },
              ""su_string"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""url"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""url_object"": {
                ""properties"": {
                  ""address"": {
                    ""type"": ""string"",
                    ""index"": ""not_analyzed"",
                    ""doc_values"": true
                  },
                  ""parameters"": {
                    ""properties"": {
                      ""__mref"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""ad_id"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""app_request_type"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""camp_id"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""count"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_action_ids"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_action_types"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_appcenter"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_bmpos"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_locale"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fb_source"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fbs"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""fref"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""hc_location"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""notif_t"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""page_type"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""ref"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""request_ids"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""signed_request"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      },
                      ""sub_id"": {
                        ""type"": ""string"",
                        ""index"": ""not_analyzed"",
                        ""doc_values"": true
                      }
                    }
                  }
                }
              },
              ""user_type"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true,
                ""null_value"": ""user""
              }
            }
          },
          ""tech"": {
            ""properties"": {
              ""app_version_client"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""app_version_server"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""a_id"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""browser"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""browser_version"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""default"": {
                ""type"": ""boolean""
              },
              ""device"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""device_model"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""login_type"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""os"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""os_version"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""platform"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              },
              ""resolution"": {
                ""type"": ""string"",
                ""index"": ""not_analyzed"",
                ""doc_values"": true
              }
            }
          },
          ""timestamp"": {
            ""type"": ""date"",
            ""doc_values"": true,
            ""format"": ""dateOptionalTime""
          }
        }
      }
    }
  }
}
```
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/664,"Hi
I'm using spark 1.5.2 with scala 2.10.4 and ES 1.7.2. I`m tring to get read data from es with spark sql as data frame and using elasticsearch-spark 2.2.0-rc1

but if I try to print first row I get `Position for 'static.region' not found in row; typically this is caused by a mapping inconsistency` error

I tried `es.mapping.include` and `es.mapping.exclude` options with no luck

in my data there is always static.region field with null value but if I print schema there is no mapping for this field. Also there is no mapping for this field when checking the index mapping

```
 val options = Map(
    ""pushdown"" -> ""true"",
    ""es.nodes.discovery"" -> ""true"",
    ""es.nodes"" -> ""10.0.0.230"",
    ""es.port"" -> ""9200"",
    ""es.nodes.client.only"" -> ""true"",
    ""es.mapping.include""->""event_data"",
    ""es.field.read.empty.as.null"" -> ""true"",
    ""es.index.read.missing.as.empty"" -> ""true""
  ) 
 val y = sqlContext.esDF(""logstash-2015.12.01/logs"", options)
 y.first()
16/01/21 09:33:36 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.elasticsearch.hadoop.EsHadoopIllegalStateException: Position for 'static.region' not found in row; typically this is caused by a mapping inconsistency
    at org.elasticsearch.spark.sql.RowValueReader$class.addToBuffer(RowValueReader.scala:40)
    at org.elasticsearch.spark.sql.ScalaRowValueReader.addToBuffer(ScalaEsRowValueReader.scala:13)
    at org.elasticsearch.spark.sql.ScalaRowValueReader.addToMap(ScalaEsRowValueReader.scala:90)
    at org.elasticsearch.hadoop.serialization.ScrollReader.map(ScrollReader.java:661)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:588)
    at org.elasticsearch.hadoop.serialization.ScrollReader.map(ScrollReader.java:661)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:588)
    at org.elasticsearch.hadoop.serialization.ScrollReader.readHitAsMap(ScrollReader.java:383)
    at org.elasticsearch.hadoop.serialization.ScrollReader.readHit(ScrollReader.java:318)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:213)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:186)
    at org.elasticsearch.hadoop.rest.RestRepository.scroll(RestRepository.java:438)
    at org.elasticsearch.hadoop.rest.ScrollQuery.hasNext(ScrollQuery.java:86)
    at org.elasticsearch.spark.rdd.AbstractEsRDDIterator.hasNext(AbstractEsRDDIterator.scala:43)
    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
    at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:308)
    at scala.collection.Iterator$class.foreach(Iterator.scala:727)
    at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
    at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
    at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
    at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
    at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
    at scala.collection.AbstractIterator.to(Iterator.scala:1157)
    at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
    at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
    at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
    at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
    at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
    at org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(SparkPlan.scala:215)
    at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
    at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
    at org.apache.spark.scheduler.Task.run(Task.scala:88)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
16/01/21 09:33:36 WARN ThrowableSerializationWrapper: Task exception could not be deserialized
java.lang.ClassNotFoundException: org.elasticsearch.hadoop.EsHadoopIllegalStateException
    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
    at java.lang.Class.forName0(Native Method)
    at java.lang.Class.forName(Class.java:348)
    at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:67)
    at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1613)
    at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1518)
    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1774)
    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
    at org.apache.spark.ThrowableSerializationWrapper.readObject(TaskEndReason.scala:167)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1900)
    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)
    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)
    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
    at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:72)
    at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:98)
    at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:108)
    at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:105)
    at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:105)
    at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1699)
    at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:105)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
16/01/21 09:33:36 ERROR TaskResultGetter: Could not deserialize TaskEndReason: ClassNotFound with classloader org.apache.spark.repl.SparkIMain$TranslatingClassLoader@374ccb9
16/01/21 09:33:36 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, localhost): UnknownReason
16/01/21 09:33:36 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost): UnknownReason
Driver stacktrace:
    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)
    at scala.Option.foreach(Option.scala:236)
    at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447)
    at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
    at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)
    at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:215)
    at org.apache.spark.sql.execution.Limit.executeCollect(basicOperators.scala:207)
    at org.apache.spark.sql.DataFrame$$anonfun$collect$1.apply(DataFrame.scala:1385)
    at org.apache.spark.sql.DataFrame$$anonfun$collect$1.apply(DataFrame.scala:1385)
    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)
    at org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:1903)
    at org.apache.spark.sql.DataFrame.collect(DataFrame.scala:1384)
    at org.apache.spark.sql.DataFrame.head(DataFrame.scala:1314)
    at org.apache.spark.sql.DataFrame.head(DataFrame.scala:1321)
    at org.apache.spark.sql.DataFrame.first(DataFrame.scala:1328)
    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:30)
    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
    at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:47)
    at $iwC$$iwC$$iwC$$iwC.<init>(<console>:49)
    at $iwC$$iwC$$iwC.<init>(<console>:51)
    at $iwC$$iwC.<init>(<console>:53)
    at $iwC.<init>(<console>:55)
    at <init>(<console>:57)
    at .<init>(<console>:61)
    at .<clinit>(<console>)
    at .<init>(<console>:7)
    at .<clinit>(<console>)
    at $print(<console>)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
    at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)
    at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
    at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
    at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
    at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
    at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
    at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
    at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
    at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
    at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
    at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
    at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
    at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
    at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
    at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
    at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
    at org.apache.spark.repl.Main$.main(Main.scala:31)
    at org.apache.spark.repl.Main.main(Main.scala)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:497)
    at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:674)
    at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
    at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)
    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

println(y.schema.treeString)
root
 |-- @timestamp: timestamp (nullable = true)
 |-- @version: string (nullable = true)
 |-- event_data: struct (nullable = true)
     ....
 |-- static: struct (nullable = true)
 |    |-- camp_id: string (nullable = true)
 |    |-- camp_network: string (nullable = true)
 |    |-- country: string (nullable = true)
 |    |-- device: string (nullable = true)
 |    |-- disabled: long (nullable = true)
 |    |-- gender: string (nullable = true)
 |    |-- language: string (nullable = true)
 |    |-- platform: string (nullable = true)
 |    |-- ref: string (nullable = true)
 |    |-- register_ip: string (nullable = true)
 |    |-- register_platform: string (nullable = true)
 |    |-- register_time: timestamp (nullable = true)
 |    |-- url: string (nullable = true)
    ....
 |-- timestamp: timestamp (nullable = true)
```

```
me@console:~$ curl -X GET 'http://10.0.0.230:9200/logstash-2015.12.01/_mapping/logs/field/static.region'
{}
```
","Can you please try the latest [dev build](https://www.elastic.co/guide/en/elasticsearch/hadoop/master/install.html#download-dev)? It provides a fix for this (the lack of mapping caused the Spark integration to be tripped off by the data as it did not expect it to appear because of the mapping).
","yes, in the newest build it works
thanks
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/658,"Hi there,

when stoping a elastic search cluster on YARN (apache-2.6) the YARN app itself is killed but it leaves the ElasticSearch process running. Turns out that in [ApplicationMaster#close()](https://github.com/elastic/elasticsearch-hadoop/blob/master/yarn/src/main/java/org/elasticsearch/hadoop/yarn/am/ApplicationMaster.java) the rpc.finishAM(); fails with 

`6/01/13 11:59:18 WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): appattempt_1452523578157_0043_000001 not found in AMRMTokenSecretManager.
Exception in thread ""main"" org.elasticsearch.hadoop.yarn.am.EsYarnAmException: org.apache.hadoop.security.token.SecretManager$InvalidToken: appattempt_1452523578157_0043_000001 not found in AMRMTokenSecretManager.
    at org.elasticsearch.hadoop.yarn.am.AppMasterRpc.unregisterAM(AppMasterRpc.java:73)
    at org.elasticsearch.hadoop.yarn.am.AppMasterRpc.finishAM(AppMasterRpc.java:66)
    at org.elasticsearch.hadoop.yarn.am.ApplicationMaster.close(ApplicationMaster.java:92)
    at org.elasticsearch.hadoop.yarn.am.ApplicationMaster.main(ApplicationMaster.java:106)
Caused by: org.apache.hadoop.security.token.SecretManager$InvalidToken: appattempt_1452523578157_0043_000001 not found in AMRMTokenSecretManager.
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
    at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)
    at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104)
    at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.finishApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:94)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
    at com.sun.proxy.$Proxy8.finishApplicationMaster(Unknown Source)
    at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.unregisterApplicationMaster(AMRMClientImpl.java:378)
    at org.elasticsearch.hadoop.yarn.am.AppMasterRpc.unregisterAM(AppMasterRpc.java:71)
    ... 3 more
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): appattempt_1452523578157_0043_000001 not found in AMRMTokenSecretManager.
    at org.apache.hadoop.ipc.Client.call(Client.java:1468)
    at org.apache.hadoop.ipc.Client.call(Client.java:1399)
    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
    at com.sun.proxy.$Proxy7.finishApplicationMaster(Unknown Source)
    at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.finishApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:91)
    ... 12 more
`

and thus cluster.close(); is never called.
","What version of ES-Hadoop/YARN are you using and what Hadoop distro?
","Its elasticsearch-yarn-2.1.2 and apache-2.6.0.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/631,"Agree or disagree:

When saving an RDD to Elasticsearch, the Elasticsearch-Spark connector [uses `RDD.take` to check whether the input RDD is empty](https://github.com/elastic/elasticsearch-hadoop/blob/03c056142a5ab7422b81bb1f519fd67a9581405f/spark/core/main/scala/org/elasticsearch/spark/rdd/EsSpark.scala) (line 59).  This means that if the input RDD has not been persisted, it will be evaluated twice under `saveToEs`.  If the input RDD has a wide dependency, this could be costly.  Thus, the caller should persist the RDD before calling `saveToEs`.

``` spark
    if (rdd == null || rdd.partitions.length == 0 || rdd.take(1).length == 0) {
      return
    }
```
","Do you encounter any issues with your `RDD`s? Do you actually find the `RDD` being evaluated twice?
`rdd.take(1)` should trigger minimal evaluation of the `RDD` content which should be reused. 

Just to keep things clean, I've removed the `take(1)` for now.
","""Do you actually find the RDD being evaluated twice?""

At this point, no, I have not staged a test of it.  I had first posed this question as to best practices for using the Es-Spark connector.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/618,"I'm seeing an issue when using pyspark, Elasticsearch 1.7.0, elasticsearch-hadoop-2.1.2.jar on Spark 1.5.1 (all running on my Mac OS Yosemite system).  I run the simple program shown below (from the article at http://qbox.io/blog/elasticsearch-in-apache-spark-python).  After the print(es_rdd.first()) statement is executed, pyshark just hangs:

Using Python version 2.7.10 (default, Oct 19 2015 18:31:17)
SparkContext available as sc, HiveContext available as sqlContext.

<pre>
>>> es_rdd = sc.newAPIHadoopRDD(
...     inputFormatClass=""org.elasticsearch.hadoop.mr.EsInputFormat"",
...     keyClass=""org.apache.hadoop.io.NullWritable"",
...     valueClass=""org.elasticsearch.hadoop.mr.LinkedMapWritable"",
...     conf={ ""es.resource"" : ""titanic/passenger"" })
15/11/27 18:16:41 WARN EsInputFormat: Cannot determine task id...
>>> print(es_rdd.first())
15/11/27 18:16:50 WARN EsInputFormat: Cannot determine task id...
15/11/27 18:16:51 WARN SimpleHttpConnectionManager: SimpleHttpConnectionManager being used incorrectly.  Be sure that HttpMethod.releaseConnection() is always called and that only one thread and/or method is using this connection manager at a time.
</pre>

When I stop Elasticsearch I get the following output:

<pre>
15/11/27 18:33:32 ERROR NetworkClient: Node [10.0.0.2:9200] failed (The server 10.0.0.2 failed to respond with a valid HTTP response); no other nodes left - aborting...
15/11/27 18:33:32 WARN NewHadoopRDD: Exception in RecordReader.close()
org.elasticsearch.hadoop.rest.EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[10.0.0.2:9200]]
    at org.elasticsearch.hadoop.rest.NetworkClient.execute(NetworkClient.java:142)
    at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:329)
    at org.elasticsearch.hadoop.rest.RestClient.executeNotFoundAllowed(RestClient.java:337)
    at org.elasticsearch.hadoop.rest.RestClient.deleteScroll(RestClient.java:403)
    at org.elasticsearch.hadoop.rest.ScrollQuery.close(ScrollQuery.java:70)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.close(EsInputFormat.java:262)
    at org.apache.spark.rdd.NewHadoopRDD$$anon$1.org$apache$spark$rdd$NewHadoopRDD$$anon$$close(NewHadoopRDD.scala:190)
    at org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$3.apply(NewHadoopRDD.scala:156)
    at org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$3.apply(NewHadoopRDD.scala:156)
    at org.apache.spark.TaskContextImpl$$anon$1.onTaskCompletion(TaskContextImpl.scala:60)
    at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:79)
    at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:77)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:77)
    at org.apache.spark.scheduler.Task.run(Task.scala:90)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
(u'892', {u'fare': u'7.8292', u'name': u'Kelly, Mr. James', u'embarked': u'Q', u'age': u'34.5', u'parch': u'0', u'pclass': u'3', u'sex': u'male', u'ticket': u'330911', u'passengerid': u'892', u'sibsp': u'0', u'cabin': None})
</pre>

Note 10.0.0.2 is the IP address of my Mac.  At any rate, I end up getting the expected output (the last line above) after a series of error messages.  When I use elasticsearch-hadoop.2.1.0.jar instead of 2.1.2 I do not see this problem and the program runs without error.

Is this an incompatibility problem with elasticsearch-hadoop.2.1.2.jar, Elaseticsearch 1.7.0, and Spark 1.5.1? 
","Can you please check it out once is released and if it's not working, reopen the issue?

Thanks,
","OK will do.  Thanks.

On 1/8/16, Costin Leau notifications@github.com wrote:

> Closed #618.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/elastic/elasticsearch-hadoop/issues/618#event-509812823
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/617,"I have a document contains a list<string> field. when trying to read as Spark DataFrame. got this issue.

```
[ERROR] [11/26/2015 23:56:57.151] [ForkJoinPool-2-worker-3] [akka://service/user/service/$a/$a] org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, 172.17.0.127): scala.MatchError: Buffer(iphone, ipad) (of class scala.collection.convert.Wrappers$JListWrapper)
at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:295)
at org.apache.spark.sql.catalyst.CatalystTypeConverters$StringConverter$.toCatalystImpl(CatalystTypeConverters.scala:294)
at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)
at org.apache.spark.sql.catalyst.CatalystTypeConverters$$anonfun$createToCatalystConverter$2.apply(CatalystTypeConverters.scala:401)
at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:63)
at org.apache.spark.sql.execution.RDDConversions$$anonfun$rowToRowRdd$1$$anonfun$apply$2.apply(ExistingRDD.scala:60)
at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.insertAll(BypassMergeSortShuffleWriter.java:119)
at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:73)
at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
at org.apache.spark.scheduler.Task.run(Task.scala:88)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)

```

I'm using Elasticsearch 2.0, Spark 1.5.1 and Scala 2.10, elasticsearch-spark-2.2.0-beta1
","Can you please provide a sample of code and some info about the dataframe you are trying to read (its schema for example)?
The stacktrace is not very helpful
",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/614,"I think this is an es-spark problem, but it might also be an ES 2 problem

I have an ES 2.0 cluster which has a custom `publish.host` set:

`network.publish_host: _ec2:publicDns_`

this produces the following in `/_nodes/transport`:

```
{  
   ""cluster_name"":""es-test-cluster"",
   ""nodes"":{  
      ""nnDrgTgVSVqZPLUmP37E8w"":{  
         ""name"":""Living Tribunal"",
         ""transport_address"":""<some ip>:9300"",
         ""host"":""<some ip>.57"",
         ""ip"":""<some ip>.57"",
         ""version"":""2.0.0"",
         ""build"":""de54438"",
         ""http_address"":""<an EC2 public DNS>/<some ip>:9200""
         ...
```

The http_address is not parsed correctly, and the Rest client attempts to connect to a completely invalid address.
","What's the exception that you are getting? What is the address being used to connect?
","Stepping through it in the debugger, in `RestClient:discoverNodes()` it adds each node with:

`hosts.add(StringUtils.parseIpAddress(inet).toString());`

`parseIpAddress` doesn't seem to understand the format in the response from the server, which is in the format `foo.bar.amazonaws.com/10.10.0.23:9200`

I can definitely connect to both the hostname, and the ip, from the Spark cluster.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/581,"Using Spark 1.5.1 and elasticsearch-spark 2.1.1 I'm setting the es.mapping.id to a field in my JSON called ""feature_id"".  IDs are getting populated, but they don't match the value of the ""feature_id"" field in the document.

```
EsSpark.saveJsonToEs(
  rdd.map(_.toJson),
  ""myindex/features"",
  Map(
    ""es.nodes"" -> ""myhost.com"",
    ""es.mapping.id"" -> ""feature_id""
  )
)
```

```
{
  ""_index"": ""myindex"",
  ""_type"": ""features"",
  ""_id"": ""144136021837088505"",
  ""_score"": 1,
  ""_source"": {
    ""feature_id"": 144136021837088500,
    ...
  }
}
```
","Can you please post a sample doc? Is there another `feature_id` inside the document? Does it contain by any chance another 144136021837088500 - or is this number somewhere in an another document?
It looks like a bug but I'm trying to narrow down where do these numbers are coming from and thus what causes the bug to occur.
","Actually I think this is a false alarm.  I think the problem is my (Javascript) client incorrectly munging the Long value of feature_id.  When I do it with curl everything looks good.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/571,"Looks like a recent change to the version string comparison from ""1."" to ""1.x"" causes this Exception to be thrown. 

https://github.com/elastic/elasticsearch-hadoop/blob/master/mr/src/main/java/org/elasticsearch/hadoop/rest/InitializationUtils.java#L171

Running: Elasticsearch Hadoop v2.2.0.BUILD-SNAPSHOT with an ElasticSearch cluster version 1.5.0

Full stacktrace:

```
12 Oct 2015 17:16:17,709 INFO  Version        : Elasticsearch Hadoop v2.2.0.BUILD-SNAPSHOT [96c682d103]
Exception in thread ""main"" org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 1.5.0
    at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:172)
    at org.elasticsearch.hadoop.rest.RestService.findPartitions(RestService.java:229)
    at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions$lzycompute(AbstractEsRDD.scala:61)
    at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions(AbstractEsRDD.scala:60)
    at org.elasticsearch.spark.rdd.AbstractEsRDD.getPartitions(AbstractEsRDD.scala:27)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
    at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
    at org.apache.spark.Partitioner$$anonfun$2.apply(Partitioner.scala:58)
    at org.apache.spark.Partitioner$$anonfun$2.apply(Partitioner.scala:58)
    at scala.math.Ordering$$anon$5.compare(Ordering.scala:122)
    at java.util.TimSort.countRunAndMakeAscending(TimSort.java:324)
    at java.util.TimSort.sort(TimSort.java:189)
    at java.util.TimSort.sort(TimSort.java:173)
    at java.util.Arrays.sort(Arrays.java:659)
    at scala.collection.SeqLike$class.sorted(SeqLike.scala:615)
    at scala.collection.AbstractSeq.sorted(Seq.scala:40)
    at scala.collection.SeqLike$class.sortBy(SeqLike.scala:594)
    at scala.collection.AbstractSeq.sortBy(Seq.scala:40)
    at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:58)
    at org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$2.apply(PairRDDFunctions.scala:615)
    at org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$2.apply(PairRDDFunctions.scala:615)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
    at org.apache.spark.rdd.RDD.withScope(RDD.scala:306)
    at org.apache.spark.rdd.PairRDDFunctions.leftOuterJoin(PairRDDFunctions.scala:614)
    at org.apache.spark.api.java.JavaPairRDD.leftOuterJoin(JavaPairRDD.scala:572)
    at com.comcast.psp.elasticsearch.spark.SparkRunner.main(SparkRunner.java:126)
```
","Can you please try it out and report back?

Thanks
","It's working again, thanks for the quick fix.

Grabbed the latest snapshot using this maven dependency (I am using maven for this particular project):

```
        <dependency>
            <groupId>org.elasticsearch</groupId>
            <artifactId>elasticsearch-spark_2.10</artifactId>
            <version>2.2.0.BUILD-SNAPSHOT</version> 
        </dependency>
```
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/497,"The DataFrame returned by JavaEsSparkSQL.esDF contains Scala Buffers when a query string is specified, but not when the simpler overload is used.  Code snippet and log output is below.

``` java
    DataFrame rdd = null;
            SourceLoaderES.logger.info("" loading "" + indexName + ""/"" + docType + "" using REST to get column list "");

            String query = getQueryString(indexName, docType);
            SourceLoaderES.logger.debug(""ES query string"" + query);                 
           // rdd = JavaEsSparkSQL.esDF(_handler._sc, indexName + ""/"" + docType, query);

           rdd = JavaEsSparkSQL.esDF(_handler._sc, indexName + ""/"" + docType);
           DataFrame rdd2 = JavaEsSparkSQL.esDF(_handler._sc, indexName + ""/"" + docType, query);


        SourceLoaderES.logger.debug(""inferred SCHEMA "" + rdd.schema().toString());


        if (AdminMgr.getConfig(SyncRunner.DEBUG_ENABLE_DF_COUNTS) != null) {
            if (AdminMgr.getConfig(SyncRunner.DEBUG_ENABLE_DF_COUNTS).equals( ""true"")) {
               logger.warn("" DataFrame count: "" + rdd.count());
               logger.warn("" DataFrame first row: "" + rdd.showString(1));
            }
        }
        logger.warn("" DataFrame first row: "" + rdd.showString(1));
        logger.warn("" DataFrame2 first row: "" + rdd2.showString(1));
        //SourceLoaderES.logger.info(""ES SOURCE "" + sourceName + ""  SCHEMA "" + rdd.schema().toString());

```

Log output from this snippet:

```
2015-07-10 17:09:16,281 [ (Sync) 15 - Sync 1] INFO  com.dg.data.sync.SourceLoaderES -  loading g5b778bb6-faa0-41a0-bb36-8a4c54b13774_dg_dim1/dim_lookups using REST to get column list 
2015-07-10 17:09:16,297 [ (Sync) 15 - Sync 1] DEBUG com.dg.data.sync.SourceLoaderES -  returned mapping for query string: {""properties"":{""xid"":{""type"":""string""},""ApplicationLanguageId"":{""type"":""long""},""LookupKeyActive"":{""type"":""string""},""LookupKey"":{""type"":""long""},""LookupLevel"":{""type"":""long""},""LookupModule"":{""type"":""long""},""LookupKeyName"":{""type"":""string""}}}
2015-07-10 17:09:16,297 [ (Sync) 15 - Sync 1] DEBUG com.dg.data.sync.SourceLoaderES - ES query string{""query"":{""match_all"":{}},""fields"":[""xid"",""ApplicationLanguageId"",""LookupKeyActive"",""LookupKey"",""LookupLevel"",""LookupModule"",""LookupKeyName""]}
2015-07-10 17:09:16,359 [ (Sync) 15 - Sync 1] DEBUG com.dg.data.sync.SourceLoaderES - inferred SCHEMA StructType(StructField(ApplicationLanguageId,LongType,true), StructField(LookupKey,LongType,true), StructField(LookupKeyActive,StringType,true), StructField(LookupKeyName,StringType,true), StructField(LookupLevel,LongType,true), StructField(LookupModule,LongType,true), StructField(xid,StringType,true))
2015-07-10 17:09:16,641 [ (Sync) 15 - Sync 1] WARN  com.dg.data.sync.SourceLoaderES -  DataFrame first row: ApplicationLanguageId LookupKey LookupKeyActive LookupKeyName LookupLevel LookupModule xid           
1                     11        true            11 am         2           61           61-2-true-1-11
2015-07-10 17:09:16,797 [ (Sync) 15 - Sync 1] WARN  com.dg.data.sync.SourceLoaderES -  DataFrame2 first row: ApplicationLanguageId LookupKey  LookupKeyActive LookupKeyName LookupLevel LookupModule xid                 
Buffer(1)             Buffer(11) Buffer(true)    Buffer(11 am) Buffer(2)   Buffer(61)   Buffer(61-2-true-...
```
","What version of Es-hadoop and Spark are you using? Are you by any chance on Spark 1.3?
On 2.1.x and master, everything gets properly printed - maybe your query is special (can you share it)?
I've also noticed you are using `showString` which is not available in Spark 1.4 (in fact it is private).
Either way, I have tried the following snippets (which is part of the test suite) and I get no reference to `Buffer`:

```
println(JavaEsSparkSQL.esDF(sqc, target, ""?q=name:me*"", cfg.asJava).head())
```

```
[170,Mew,http://userserve-ak.last.fm/serve/252/42247291.jpg,6146220025000,http://www.last.fm/music/Mew]
```

```
JavaEsSparkSQL.esDF(sqc, target, ""?q=name:me*"", cfg.asJava).show(3)
```

```
+---+--------------------+--------------------+--------------+--------------------+
| id|                name|            pictures|          time|                 url|
+---+--------------------+--------------------+--------------+--------------------+
|170|                 Mew|http://userserve-...| 6146220025000|http://www.last.f...|
|918|            Megadeth|http://userserve-...|29656092025000|http://www.last.f...|
|996|Mike & The Mechanics|http://userserve-...|32117541625000|http://www.last.f...|
+---+--------------------+--------------------+--------------+--------------------+
```

Can you post your entire log and potentially turn on logging on the rest package (`org.elasticsearch.hadoop.rest`) all the way to `TRACE` and upload the result as a gist?

Thanks
","Your example test query string does not specify a set of fields to return,
only a constraint.  The ""fields"" query element is what causes the issue in
my tests, including in Spark 1.4.1.

I will provide more information as soon as I am able.

--Scott

On Tue, Jul 28, 2015 at 11:49 AM, Costin Leau notifications@github.com
wrote:

> @analyticswarescott https://github.com/analyticswarescott Unfortunately
> I'm unable to reproduce the problem. What version of Es-hadoop and Spark
> are you using? Are you by any chance on Spark 1.3?
> On 2.1.x and master, everything gets properly printed - maybe your query
> is special (can you share it)?
> I've also noticed you are using showString which is not available in
> Spark 1.4 (in fact it is private).
> Either way, I have tried the following snippets (which is part of the test
> suite) and I get no reference to Buffer:
> 
> println(JavaEsSparkSQL.esDF(sqc, target, ""?q=name:me*"", cfg.asJava).head())
> 
> [170,Mew,http://userserve-ak.last.fm/serve/252/42247291.jpg,6146220025000,http://www.last.fm/music/Mew]``` http://userserve-ak.last.fm/serve/252/42247291.jpg,6146220025000,http://www.last.fm/music/Mew%5D
> 
> println(JavaEsSparkSQL.esDF(sqc, target, ""?q=name:me*"", cfg.asJava).show(3)
> 
> +---+--------------------+--------------------+--------------+--------------------+
> | id| name| pictures| time| url|
> 
> +---+--------------------+--------------------+--------------+--------------------+
> |170| Mew|http://userserve-...| 6146220025000|http://www.last.f...|
> |918| Megadeth|http://userserve-...|29656092025000|http://www.last.f...|
> |996|Mike & The Mechanics|
> http://userserve-...|32117541625000|http://www.last.f...|
> 
> +---+--------------------+--------------------+--------------+--------------------+
> 
> Can you post your entire log and potentially turn on logging on the rest package (`org.elasticsearch.hadoop.rest`) all the way to `TRACE` and upload the result as a gist?
> 
> Thanks
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/elastic/elasticsearch-hadoop/issues/497#issuecomment-125526221
> .
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/482,"Using ES-hadoop 2.1.0.rc1, Spark 1.4.0. Elasticsearch 1.6.0

The ES index that we use contains various events with a variaty of fields but the (custom) schema that we defined has the ""common"" fields that the SQL query will use.

Somehow it still tries to map a field that is not in the schema nor used in the SQL causing a `ArrayIndexOutOfBoundsException` since the `indexOf` is returning `-1`

```
2015-06-23T17:09:28.060+0200 ERROR Executor.logError() - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ArrayIndexOutOfBoundsException: -1
    at scala.collection.mutable.ResizableArray$class.update(ResizableArray.scala:49)
    at scala.collection.mutable.ArrayBuffer.update(ArrayBuffer.scala:48)
    at org.elasticsearch.spark.sql.RowValueReader$class.addToBuffer(RowValueReader.scala:29)
    at org.elasticsearch.spark.sql.ScalaRowValueReader.addToBuffer(ScalaEsRowValueReader.scala:13)
    at org.elasticsearch.spark.sql.ScalaRowValueReader.addToMap(ScalaEsRowValueReader.scala:39)
    at org.elasticsearch.hadoop.serialization.ScrollReader.map(ScrollReader.java:636)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:559)
    at org.elasticsearch.hadoop.serialization.ScrollReader.map(ScrollReader.java:636)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:559)
    at org.elasticsearch.hadoop.serialization.ScrollReader.readHitAsMap(ScrollReader.java:358)
    at org.elasticsearch.hadoop.serialization.ScrollReader.readHit(ScrollReader.java:293)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:188)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:167)
    at org.elasticsearch.hadoop.rest.RestRepository.scroll(RestRepository.java:403)
    at org.elasticsearch.hadoop.rest.ScrollQuery.hasNext(ScrollQuery.java:76)
    at org.elasticsearch.spark.rdd.AbstractEsRDDIterator.hasNext(AbstractEsRDDIterator.scala:46)
    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:369)
    at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:413)
    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:369)
    at org.apache.spark.sql.execution.Aggregate$$anonfun$doExecute$1$$anonfun$7.apply(Aggregate.scala:154)
    at org.apache.spark.sql.execution.Aggregate$$anonfun$doExecute$1$$anonfun$7.apply(Aggregate.scala:149)
    at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:686)
    at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:686)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)
    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:70)
    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
    at org.apache.spark.scheduler.Task.run(Task.scala:70)
```
","Can you please provide an actual reproducible example?
What are you trying to do in Spark and what is the custom mapping you are mentioning here? Do note that the connector doesn't use the schema defined in Spark rather the one in Elastic.
In other words, if you define a ""common"" schema (whatever that means) in Spark SQL, that is used by Spark alone and not the connector which simply relies on the actual index mapping.
","@costin Thanks for the quick response, ignore the initial mapping story :) I cannot provide you an example. But have investigated the problem:

In our data the actual field in ES was always set to an empty array. This doesn't seem to update the mapping in ES. But it does exist in the document, so then ES Spark will try to detect the mapping for a field that doesn't have a mapping in ES.

When adding a value in the array the mapping is updated and the ES spark query works.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/440,"I'm getting the following warning in my log.

`15/04/29 10:04:38 WARN rdd.EsSpark: Incorrect classpath detected; Elasticsearch Spark compiled for Spark 1.0-1.2 but used with Spark 1.3.1`

I checked the code and it's using the absence of `org.elasticsearch.spark.sql.EsSchemaRDDWriter` to detect that this library was compiled for Spark 1.3.1.

In the snapshot I have that library does, indeed, exist.
","What is your environment? The behaviour you are describing is correct - `EsSchemaRDDWriter` is available only in the jar for Spark 1.0-1.2.
It's not clear from this report what is the issue...
","This specific Jar, https://oss.sonatype.org/content/repositories/snapshots/org/elasticsearch/elasticsearch-hadoop/2.1.0.BUILD-SNAPSHOT/elasticsearch-hadoop-2.1.0.BUILD-20150427.213847-382.jar, is what I'm using at the moment (because we need the conf change to use spark.es.nodes, etc.).

Are the snapshots not built for 1.3.1?
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/426,"For the Hadoop config value ""mapreduce.task.timeout"" (or ""mapred.task.timeout"" for Hadoop 1), a value of 0 is the equivalent of disabling that timeout.  However, the ES-Hadoop HeartBeat compares ""mapred.task.timeout"" to its own delay and throws an error if the heartbeat is greater than the task timeout.

I'm seeing this with 2.1.0.Beta3
### org.elasticsearch.hadoop.mr.HeartBeat

``` java

class HeartBeat {
    ...
    HeartBeat(final Progressable progressable, Configuration cfg, TimeValue delay, final Log log) {
        Assert.notNull(progressable, ""a valid progressable is required to report status to Hadoop"");
        TimeValue tv = HadoopCfgUtils.getTaskTimeout(cfg);
        Assert.isTrue(tv.getSeconds() > delay.getSeconds(), ""Hadoop timeout is shorter than the heartbeat"");
        ...
    }
    ...
}
```

The assert should probably be or'ing w/ a ""tv.getSeconds == 0"" or something like that.
","Can you please check it out?
Besides handling the infinite use case, I've also fixed an issue with the scheduling as the heartbeat was only activating one (per task) but now it should run continuously.

Cheers,
","Nice!  I just ran into that scheduling issue last night and hadn't yet diagnosed it, but looking at your commits now realize that you've fixed both of my problems in one swoop!

Thanks for the quick turnaround!
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/408,"Hi,

elasticsearch-hadoop 1.2.0.BUILD_SNAPSHOT
spark 1.2.0

I would like to include documents' metadata (more specifically the _id field) in Spark SQL Select query. I didn't find in elasticsearch documentation how exactly to do that when using Spark SQL, but I've read that in order to include documents metadata fields in the response, one needs to set es.read.metadata=true. After doing that, the following Exception is thrown:

```
2015-03-30 10:53:20,046 ERROR [task-result-getter-0] scheduler.TaskSetManager (Logging.scala:logError(75)) - Task 1 in stage 0.0 failed 1 times; aborting job
Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost): java.util.NoSuchElementException: key not found: _index
    at scala.collection.MapLike$class.default(MapLike.scala:228)
    at scala.collection.AbstractMap.default(Map.scala:58)
    at scala.collection.MapLike$class.apply(MapLike.scala:141)
    at scala.collection.AbstractMap.apply(Map.scala:58)
    at org.elasticsearch.spark.sql.RowValueReader$class.addToBuffer(RowValueReader.scala:32)
    at org.elasticsearch.spark.sql.ScalaRowValueReader.addToBuffer(ScalaRowValueReader.scala:9)
    at org.elasticsearch.spark.sql.ScalaRowValueReader.addToMap(ScalaRowValueReader.scala:16)
    at org.elasticsearch.hadoop.serialization.ScrollReader.readHitAsMap(ScrollReader.java:316)
    at org.elasticsearch.hadoop.serialization.ScrollReader.readHit(ScrollReader.java:290)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:186)
    at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:165)
    at org.elasticsearch.hadoop.rest.RestRepository.scroll(RestRepository.java:403)
    at org.elasticsearch.hadoop.rest.ScrollQuery.hasNext(ScrollQuery.java:76)
    at org.elasticsearch.spark.rdd.AbstractEsRDDIterator.hasNext(AbstractEsRDDIterator.scala:46)
    at org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.hasNext(InMemoryColumnarTableScan.scala:138)
    at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:248)
    at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:163)
    at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:70)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:228)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:263)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:230)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:263)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:230)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
    at org.apache.spark.sql.SchemaRDD.compute(SchemaRDD.scala:120)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:263)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:230)
    at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:263)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:230)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
    at org.apache.spark.scheduler.Task.run(Task.scala:56)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:745)
```

```
Driver stacktrace:
    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1214)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1203)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1202)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1202)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
    at scala.Option.foreach(Option.scala:236)
    at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:696)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1420)
    at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
    at akka.actor.ActorCell.invoke(ActorCell.scala:456)
    at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
    at akka.dispatch.Mailbox.run(Mailbox.scala:219)
    at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
```

The code:

``` scala
import org.apache.spark._
import org.apache.spark.sql._
import org.apache.spark.SparkContext._
import org.elasticsearch.spark._
import org.elasticsearch.spark.sql._
import org.elasticsearch.spark._

object Percolator
{
  def main(args: Array[String]) 
  {  
    val year = 2015;
    val month = 1;
    val day = 14;
    val hour = 17;
    val interval = 3;

    val sparkConf = new SparkConf().setAppName(""Percolator"")
    sparkConf.set(""es.read.metadata"", ""true"")

    val sc =  new SparkContext(sparkConf)
    val sqlContext = new SQLContext(sc)

    sqlContext.sql(""CREATE TEMPORARY TABLE INTERVALS    "" +
                   ""USING org.elasticsearch.spark.sql "" +
                   ""OPTIONS (resource 'events/intervals') "" )

    sqlContext.cacheTable(""INTERVALS"")        

    val intervSchemaRDD = 
      sqlContext.sql(""SELECT User, Year, Month, Day, Hour, DataStore, DbName, SchemaName, TableName, ColumnName, "" +
                     ""       0 as ResponseCount "" +
                     ""FROM INTERVALS "" +
                     ""WHERE Year     = "" + year +
                     ""AND   Month    = "" + month +
                     ""AND   Day      = "" + day +
                     ""AND   Hour     = "" + hour +
                     ""AND   Interval = "" + interval )

    val mapRDD = intervSchemaRDD.map { x => Map( ""User""          -> x(0), 
                                                 ""Year""          -> x(1),
                                                 ""Month""         -> x(2),
                                                 ""Day""           -> x(3),
                                                 ""Hour""          -> x(4),
                                                 ""DataStore""     -> x(5),
                                                 ""DbName""        -> x(6),
                                                 ""SchemaName""    -> x(7),
                                                 ""TableName""     -> x(8),
                                                 ""ColumnName""    -> x(9),
                                                 ""ResponseCount"" -> x(10))}

    mapRDD.foreach(elem => print(elem + ""\n\n""))
    mapRDD.saveToEs(""events/new"")
  }
}
```

Can you please advise if it is a bug or am I going in a wrong way to get the documents' metadata fields in the Spark SQL select query's output? What is the correct way to do that?

Also, can you please advise where to find the Mailing List for asking questions?

Thanks,
Dmitriy Fingerman
","Which one of your selects fails? Does the presence of `es.read.metadata` influences the way the queries run?

As for the mailing list, you can find it in the resource page in the docs; I'll update the project README so it can be found easily.
","Thanks for your response.
I am not sure which line of code of my program causes the exception because the exception stack trace doesn't show it, however, there is only one SELECT statement in the program. This happens only when the following line is present in the program: sparkConf.set(""es.read.metadata"", ""true"")

You mentioned that the document id is read anyway since the returned RDD is a PairRDD, but the result of SELECT statement is SchemaRDD[Row]. Can you please clarify about the PairRDD?

Thanks,
Dmitriy Fingerman
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/386,"I tried to export the whole ES index in JSON format several times without any success.

My current configuration:
ES version: 1.4.2
Hadoop Yarn version: 2.6.0.2.2.0.0-2041 (Hortonworks distribution)
ES Hadoop version: 2.1.0.BUILD-SNAPSHOT

ES cluster includes 8 datanodes
Hadoop cluster includes 6 datanodes

The ES index has 12 shards and about 1.2 billion documents.

When I run a Mapreduce Job ten of twelve tasks are completed successfully.

Two task are failed with the same errors:

Error: java.lang.IllegalArgumentException: Invalid position given=374535 -1 at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:234)

Error: java.lang.IllegalArgumentException: Invalid position given=367085 -1 at org.elasticsearch.hadoop.serialization.ScrollReader.read(ScrollReader.java:234) 

Another attempts are failed with same position numbers 
https://gist.github.com/ssemichev/b78898b4c82566f60985

It happens with different version of ES (0.9, 1.1, 1.4) and Hadoop (Hadoop and Hadoop YARN). I get the same errors for indexes with four and twelve shards (they store the same data), but it works for index with another mapping.

Originally data were inserted in ES index using ES Hadoop from raw JSON files without any error. 

Thanks
","Can you try and isolate the data that triggers it? Potentially enabling logging on the `rest` package and checking the documents that cause the issue?

Thanks,
","I agree, it seems it's data relative issue.

Do you mean add logging to source code? 
Or you are saying about enabling logging on the rest package at log4j configuration?
I can not see any logging record in the code.

Thanks
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/382,"Elasticsearch-hadoop: elasticsearch-hadoop-2.1.0.BUILD-20150224.023403-309.zip
Spark: 1.2.0

I'm attempting to take a very basic JSON document on HDFS and index it in ES using SchemaRDD.saveToEs().  According to the documentation under ""writing existing JSON to elasticsearch"" it should be as easy as creating a SchemaRDD via SQLContext.jsonFile() and then index using .saveToEs(), but I'm getting an error.

Replicating the problem:
1) Create JSON file on hdfs with the content:

```
{""key"":""value""}
```

2) Execute code in spark-shell

```
import org.apache.spark.SparkContext._
import org.elasticsearch.spark._

val sqlContext = new org.apache.spark.sql.SQLContext(sc)
import sqlContext._

val input = sqlContext.jsonFile(""hdfs://nameservice1/user/mshirley/test.json"")
input.saveToEs(""mshirley_spark_test/test"")
```

Error:

```
 org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [Bad Request(400) - Invalid JSON fragment received[[""value""]][MapperParsingException[failed to parse]; nested: ElasticsearchParseException[Failed to derive xcontent from (offset=13, length=9): [123, 34, 105, 110, 100, 101, 120, 34, 58, 123, 125, 125, 10, 91, 34, 118, 97, 108, 117, 101, 34, 93, 10]]; ]];
```

input object:

```
res1: org.apache.spark.sql.SchemaRDD = 
SchemaRDD[6] at RDD at SchemaRDD.scala:108
== Query Plan ==
== Physical Plan ==
PhysicalRDD [key#0], MappedRDD[5] at map at JsonRDD.scala:47
```

input.printSchema():

```
root
 |-- key: string (nullable = true)
```

Expected result:
I expect to be able to read a file from HDFS that contains a JSON document per line and submit that data to ES for indexing.
","Maybe your data (field `value`) contains some special chars that are not escaped properly?
","I can't duplicate your success using the same json document, so something else must be the issue.  Are you doing something different with the imports or with the sparkSQL context?

```
$ cat simple.json 
{""address"":{""streetAddress"":""asdf""},""age"":10, ""children"":[""child1"",""child2"",""child3""], ""firstname"": ""m"", ""isAlive"": true}
```

This json is valid according to jsonlint.

```
$ spark-shell --jars ~/elasticsearch-hadoop-2.1.0.BUILD-SNAPSHOT/dist/elasticsearch-spark_2.10-2.1.0.BUILD-SNAPSHOT.jar
<snip>
scala> import org.apache.spark.SparkContext._
import org.apache.spark.SparkContext._

scala> import org.elasticsearch.spark._
import org.elasticsearch.spark._

scala> 

scala> val sqlContext = new org.apache.spark.sql.SQLContext(sc)
sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@6a6b602

scala> import sqlContext._
import sqlContext._

scala> val input = sqlContext.jsonFile(this.getClass.getResource(""/simple.json"").toURI().toString())
<snip>
input: org.apache.spark.sql.SchemaRDD = 
SchemaRDD[6] at RDD at SchemaRDD.scala:108
== Query Plan ==
== Physical Plan ==
PhysicalRDD [address#0,age#1,children#2,firstname#3,isAlive#4], MappedRDD[5] at map at JsonRDD.scala:47

scala> input.printSchema
root
 |-- address: struct (nullable = true)
 |    |-- streetAddress: string (nullable = true)
 |-- age: integer (nullable = true)
 |-- children: array (nullable = true)
 |    |-- element: string (containsNull = false)
 |-- firstname: string (nullable = true)
 |-- isAlive: boolean (nullable = true)

scala> println(input.schema)
StructType(ArrayBuffer(StructField(address,StructType(ArrayBuffer(StructField(streetAddress,StringType,true))),true), StructField(age,IntegerType,true), StructField(children,ArrayType(StringType,false),true), StructField(firstname,StringType,true), StructField(isAlive,BooleanType,true)))

scala> input.saveToEs(""spark-test/json-file"")                                                                                                                                  [81/1985]
15/02/27 18:27:52 INFO BlockManager: Removing broadcast 1
15/02/27 18:27:52 INFO BlockManager: Removing block broadcast_1_piece0
15/02/27 18:27:52 INFO MemoryStore: Block broadcast_1_piece0 of size 1859 dropped from memory (free 277999146)
15/02/27 18:27:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:40090 in memory (size: 1859.0 B, free: 265.4 MB)
15/02/27 18:27:52 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/02/27 18:27:52 INFO BlockManager: Removing block broadcast_1
15/02/27 18:27:52 INFO MemoryStore: Block broadcast_1 of size 3176 dropped from memory (free 278002322)
15/02/27 18:27:52 INFO ContextCleaner: Cleaned broadcast 1
15/02/27 18:27:53 INFO SparkContext: Starting job: runJob at EsSpark.scala:51
15/02/27 18:27:53 INFO DAGScheduler: Got job 1 (runJob at EsSpark.scala:51) with 2 output partitions (allowLocal=false)
15/02/27 18:27:53 INFO DAGScheduler: Final stage: Stage 1(runJob at EsSpark.scala:51)
15/02/27 18:27:53 INFO DAGScheduler: Parents of final stage: List()
15/02/27 18:27:53 INFO DAGScheduler: Missing parents: List()
15/02/27 18:27:53 INFO DAGScheduler: Submitting Stage 1 (SchemaRDD[6] at RDD at SchemaRDD.scala:108
== Query Plan ==
== Physical Plan ==
PhysicalRDD [address#0,age#1,children#2,firstname#3,isAlive#4], MappedRDD[5] at map at JsonRDD.scala:47), which has no missing parents
15/02/27 18:27:53 INFO MemoryStore: ensureFreeSpace(6280) called with curMem=300234, maxMem=278302556
15/02/27 18:27:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.1 KB, free 265.1 MB)
15/02/27 18:27:53 INFO MemoryStore: ensureFreeSpace(3703) called with curMem=306514, maxMem=278302556
15/02/27 18:27:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KB, free 265.1 MB)
15/02/27 18:27:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40090 (size: 3.6 KB, free: 265.4 MB)
15/02/27 18:27:53 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/02/27 18:27:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:838
15/02/27 18:27:53 INFO DAGScheduler: Submitting 2 missing tasks from Stage 1 (SchemaRDD[6] at RDD at SchemaRDD.scala:108
== Query Plan ==
== Physical Plan ==
PhysicalRDD [address#0,age#1,children#2,firstname#3,isAlive#4], MappedRDD[5] at map at JsonRDD.scala:47)
15/02/27 18:27:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/02/27 18:27:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1384 bytes)
15/02/27 18:27:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 1384 bytes)
15/02/27 18:27:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/02/27 18:27:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/02/27 18:27:53 INFO HadoopRDD: Input split: file:/home/mshirley/simple.json:0+61
15/02/27 18:27:53 INFO HadoopRDD: Input split: file:/home/mshirley/simple.json:61+61
15/02/27 18:27:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1774 bytes result sent to driver
15/02/27 18:27:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 471 ms on localhost (1/2)
15/02/27 18:27:53 ERROR TaskContextImpl: Error in TaskCompletionListener
org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [Bad Request(400) - Invalid JSON fragment received[[[""asdf""],10,[""child1"",""child2"",""child3""],""m"",true]][
MapperParsingException[failed to parse]; nested: ElasticsearchParseException[Failed to derive xcontent from (offset=13, length=51): [123, 34, 105, 110, 100, 101, 120, 34, 58, 123, 125, 
 125, 10, 91, 91, 34, 97, 115, 100, 102, 34, 93, 44, 49, 48, 44, 91, 34, 99, 104, 105, 108, 100, 49, 34, 44, 34, 99, 104, 105, 108, 100, 50, 34, 44, 34, 99, 104, 105, 108, 100, 51, 34,    
 93, 44, 34, 109, 34, 44, 116, 114, 117, 101, 93, 10]]; ]]; Bailing out..
        at org.elasticsearch.hadoop.rest.RestClient.retryFailedEntries(RestClient.java:202)
        at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:166)

        at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:209)
        at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:233)
        at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:246)
        at org.elasticsearch.hadoop.rest.RestService$PartitionWriter.close(RestService.java:129)
        at org.elasticsearch.spark.rdd.EsRDDWriter$$anonfun$write$1.apply$mcV$sp(EsRDDWriter.scala:40)
        at org.apache.spark.TaskContextImpl$$anon$2.onTaskCompletion(TaskContextImpl.scala:57)                                                                                 [31/1985]
        at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:68)
        at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:66)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
        at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:58)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
15/02/27 18:27:53 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 2)
org.apache.spark.util.TaskCompletionListenerException: Found unrecoverable error [Bad Request(400) - Invalid JSON fragment received[[[""asdf""],10,[""child1"",""child2"",""child3""],""m"",true]]
[MapperParsingException[failed to parse]; nested: ElasticsearchParseException[Failed to derive xcontent from (offset=13, length=51): [123, 34, 105, 110, 100, 101, 120, 34, 58, 123, 125
, 125, 10, 91, 91, 34, 97, 115, 100, 102, 34, 93, 44, 49, 48, 44, 91, 34, 99, 104, 105, 108, 100, 49, 34, 44, 34, 99, 104, 105, 108, 100, 50, 34, 44, 34, 99, 104, 105, 108, 100, 51, 34
, 93, 44, 34, 109, 34, 44, 116, 114, 117, 101, 93, 10]]; ]]; Bailing out..
        at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:76)
        at org.apache.spark.scheduler.Task.run(Task.scala:58)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
15/02/27 18:27:53 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 2, localhost): org.apache.spark.util.TaskCompletionListenerException: Found unrecoverable error [Bad Request(400)
 - Invalid JSON fragment received[[[""asdf""],10,[""child1"",""child2"",""child3""],""m"",true]][MapperParsingException[failed to parse]; nested: ElasticsearchParseException[Failed to derive xco
ntent from (offset=13, length=51): [123, 34, 105, 110, 100, 101, 120, 34, 58, 123, 125, 125, 10, 91, 91, 34, 97, 115, 100, 102, 34, 93, 44, 49, 48, 44, 91, 34, 99, 104, 105, 108, 100,
49, 34, 44, 34, 99, 104, 105, 108, 100, 50, 34, 44, 34, 99, 104, 105, 108, 100, 51, 34, 93, 44, 34, 109, 34, 44, 116, 114, 117, 101, 93, 10]]; ]]; Bailing out..
        at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:76)
        at org.apache.spark.scheduler.Task.run(Task.scala:58)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)

15/02/27 18:27:53 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job

15/02/27 18:27:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
15/02/27 18:27:53 INFO TaskSchedulerImpl: Cancelling stage 1
15/02/27 18:27:53 INFO DAGScheduler: Job 1 failed: runJob at EsSpark.scala:51, took 0.627167 s
15/02/27 18:27:54 INFO BlockManager: Removing broadcast 2
15/02/27 18:27:54 INFO BlockManager: Removing block broadcast_2
15/02/27 18:27:54 INFO MemoryStore: Block broadcast_2 of size 6280 dropped from memory (free 277998619)
15/02/27 18:27:54 INFO BlockManager: Removing block broadcast_2_piece0
15/02/27 18:27:54 INFO MemoryStore: Block broadcast_2_piece0 of size 3703 dropped from memory (free 278002322)
15/02/27 18:27:54 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:40090 in memory (size: 3.6 KB, free: 265.4 MB)
15/02/27 18:27:54 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/02/27 18:27:54 INFO ContextCleaner: Cleaned broadcast 2
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 2, localhost): org.apache.sp
ark.util.TaskCompletionListenerException: Found unrecoverable error [Bad Request(400) - Invalid JSON fragment received[[[""asdf""],10,[""child1"",""child2"",""child3""],""m"",true]][MapperParsin
gException[failed to parse]; nested: ElasticsearchParseException[Failed to derive xcontent from (offset=13, length=51): [123, 34, 105, 110, 100, 101, 120, 34, 58, 123, 125, 125, 10, 91
, 91, 34, 97, 115, 100, 102, 34, 93, 44, 49, 48, 44, 91, 34, 99, 104, 105, 108, 100, 49, 34, 44, 34, 99, 104, 105, 108, 100, 50, 34, 44, 34, 99, 104, 105, 108, 100, 51, 34, 93, 44, 34,
 109, 34, 44, 116, 114, 117, 101, 93, 10]]; ]]; Bailing out..
        at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:76)
        at org.apache.spark.scheduler.Task.run(Task.scala:58)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
        at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1214)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1203)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1202)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1202)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:696)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1420)
        at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
        at akka.actor.ActorCell.invoke(ActorCell.scala:456)
        at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
        at akka.dispatch.Mailbox.run(Mailbox.scala:219)
        at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
        at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
```
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/362,"Given the dynamic configuration...

``` Java
hadoopConfiguration.set(""es.resource.write"", ""{nested.field}/type"");
```

And a document like...

``` JSON
{""nested"" : { ""field"" : ""value"" } }
```

The load will fail with ""Cannot find match for ""{nested.field}"". The work around is to either insert a dummy field before the target field or, if possible, re-order the nested sub fields. 

I did manage to debug the issue down to `org.elasticsearch.hadoop.serialization.ParsingUtils#doFind`. In particular this section...

``` Java
            if (token == Token.START_OBJECT) {
                token = parser.nextToken();  // <--- this eats the first FIELD_NAME token of the nested object
                if (matchingCurrentLevel == null) {
                    parser.skipChildren();
                }
                else {
                    doFind(parser, matchingCurrentLevel, active, inactive);
                }
            }
```

I expect moving the `parser.nextToken()` to inside the null check block would solve my particular problem since that is what's eating the FIELD_NAME token, but I don't know if it would break something else. 

**Edit**: To clarify, if ""field"" is the first property inside the nested object, then the error is triggered. If ""field"" is the second or later field, it works as expected. 
","Can you please try the latest dev builds published for both 2.1 and 2.0 branch and report back?

Thanks!
","This appears resolved in the latest branch.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/338,"Trying to figure out why this is always crashing.. someone pointed out might be a bug in 
EsInputFormat ?

```
14/12/10 15:46:49 ERROR PythonRDD: Python worker exited unexpectedly (crashed)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File ""/spark/python/pyspark/worker.py"", line 75, in main
    command = pickleSer._read_with_length(infile)
  File ""/spark/python/pyspark/serializers.py"", line 146, in _read_with_length
    length = read_int(stream)
  File ""/spark/python/pyspark/serializers.py"", line 464, in read_int
    raise EOFError
EOFError

        at org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:124)
        at org.apache.spark.api.python.PythonRDD$$anon$1.<init>(PythonRDD.scala:154)
        at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:87)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
        at org.apache.spark.scheduler.Task.run(Task.scala:54)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.UnsupportedOperationException
        at java.util.AbstractMap.put(AbstractMap.java:203)
        at java.util.AbstractMap.putAll(AbstractMap.java:273)
        at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.setCurrentValue(EsInputFormat.java:373)
        at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.setCurrentValue(EsInputFormat.java:322)
        at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.next(EsInputFormat.java:299)
        at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.nextKeyValue(EsInputFormat.java:227)
        at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:138)
        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        at scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:913)
        at scala.collection.Iterator$GroupedIterator.go(Iterator.scala:929)
        at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:968)
        at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:972)
```
","Can you provide some background on what you are trying to do? What version of Spark and Python are you using? I assume you are trying to interact with ES through the Map/Reduce layer instead of the Java/Scala API correct?
Did you report the bug somewhere else (you mentioned _someone_ pointed you here - she was right) is that discussion somewhere only - wondering whether there's some extra information in there that might prove useful.

Thanks!
","OK, am newbie, not quite sure what I am doing, so please bear with me. Someone on spark mailing list suggested it could be a bug in EsInputFormat

Versions:
spark-1.1.1-bin-hadoop2.4.tgz
Python 2.7.6

am trying to learn how to use PySpark to process data stored in Elasticseach. This is my code based on some examples I could find around:

I start iPython as follows:

```
[ root@rap-es:/spark ]$ IPYTHON=1 /spark/bin/pyspark --jars     /spark/elasticsearch-hadoop-2.1.0.BUILD-SNAPSHOT/dist/elasticsearch-hadoop-  2.1.0.BUILD-SNAPSHOT.jar                           
```

I run this with no errors:

```
es_rdd = sc.newAPIHadoopRDD(
    inputFormatClass=""org.elasticsearch.hadoop.mr.EsInputFormat"",
    keyClass=""org.apache.hadoop.io.NullWritable"",
    valueClass=""org.elasticsearch.hadoop.mr.LinkedMapWritable"",
    conf={
        ""es.resource"" : ""ar_2005/doc"",
        ""es.nodes"":""rap-es2.uis.georgetown.edu"",
        ""es.query"" :  """"""{""query"":{""match_all"":{}},""fields"":[""title""] }""""""
        }
    )
```

I run this with no errors also:

```
es_rdd.take(1)[0]
```

which prints my document title.

Then I try this which gives the exceptions I had pasted above:

```
from operator import add

titles=es_rdd.map(lambda d: d[1]['title'][0])
counts = titles.flatMap(lambda x: x.split(' ')).map(lambda x: (x, 1)).reduceByKey(add)                                                                                                                                      
output = counts.collect()    
```
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/331,"My env:

Hive: 0.13
elasticsearch-hadoop-hive: 2.0.2:

Similar to the following HQL:

```
from(select ip,site from logs) output         
INSERT OVERWRITE TABLE count_logs                             
select ip,site group by ip, site;
```

running and Hive Thrown a error:

```
Caused by: java.lang.ArithmeticException: / by zero                 
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWrite\
r.initSingleIndex(EsOutputFormat.java:230)                          
        at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWrite\
r.init(EsOutputFormat.java:199)                                     
        at org.elasticsearch.hadoop.hive.EsHiveOutputFormat$EsHiveR\
ecordWriter.write(EsHiveOutputFormat.java:58)                       
        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.processO\
p(FileSinkOperator.java:621)                                        
        at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator\
.java:796)                                                          
        at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(\
SelectOperator.java:87)                                             
```

I think EsHiveOutputFormat has a bug?
","How are you running Hive - what distro? Is it MR or Tez by any chance?
Anything shows up in the logs with respect to Elasticsearch shards?
","I using distro is CDH, and the version is 5.1.1

ElasticSearch is default settings,  I just change the server's IP.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/289,"'es.resource' = 'apache-2014.09./apache-access' or
'es.resource' = 'apache-2014.09.29,apache-2014.09.30/apache-access' 
are not working well for 'select count(*) from test' which is HiveQL.
The count result is not right.
'es.resource' configuration should support multiple indexes setting.
Or, at least give an error message.
","Could you explain what the expectation is and what is the actual result? es-hadoop does minimal interpretation of the index/type and feeds the information directly to Elasticsearch.
","The hive table I created is like below

CREATE EXTERNAL TABLE test
(
date timestamp,
clientip string,
request string
)
STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'
TBLPROPERTIES
(
'es.resource' = 'apache-2014.09.29/apache-access',
-- or
-- 'es.resource' = 'apache-2014.09.30/apache-access',
'es.mapping.names' = 'date:@timestamp'
);

and I used 'select count(*) from test;' which is a hive query to count the total number of rows of the table.
the result is same with ES count.
the count result are 1454536 and 215564 for each apache-2014.09.29 and apache-2014.09.30 index
then, I changed 'es.resource' = 'apache-2014.09.29/apache-access' to
'es.resource' = 'apache-2014.09.*/apache-access' or
'es.resource' = 'apache-2014.09.29,apache-2014.09.30/apache-access'
for including multiple indexes.
and I used 'select count(*) from test;' again to count the total number of documents of the indexes,
but the result is different with ES count.
the count result is 2919161 which should be 1670100 (1454536 + 215564).

---

environmental information
- centos base 6.4 64-bit / java version ""1.7.0_55""
- CDH-5.1.2-1.cdh5.1.2.p0.3
- hive 0.12.0
- elasticsearch-hadoop-2.0.1
- 3 nodes' hadoop and es cluster
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/283,"We are seeing an issue where the number of documents successfully created/indexed in ES is different  (more--very odd, or less) from the number of documents which we are giving ES to index. 

Specifically, we are using spark to grab specific correctly formatted json from a repository and simply write it to ES into a new index. The difference in documents only seems to occur if there is a large number of documents being inserted (specifically we tested with 929,660) and too few shards (specifically 1). We also did a test at a larger scale (roughly 9 million documents and over 100 shards) which also gave incorrect document counts. We have ruled out this being a spark issue, but  there are no apparent issues or exceptions in the logs (ES or Spark/ES-Hadoop), including when they are upped to debug. We do notice that ES does throttle the input. The fact that this only happens when large numbers of documents are created/indexed and that it seems to alleviate when more shards are added to balance the load points it to a load issue. I believe this to be an issue with ES core, but I was interested in seeing if anyone else here had seen this due to ES-hadoop being able to create a load issue more easily than the normal api. We have tried ES-hadoop 2.1.0-beta and 2.0.1 release with the same results.

I can provide more details as needed, but as there is nothing in the logs, there are not many other observables that I can detail. It is very similar to: http://elasticsearch-users.115913.n3.nabble.com/missing-documents-after-bulk-indexing-td4056100.html, however I  am not seeing any exceptions. Please let me know if anyone has seen this issue or has any resolution. 
","Can you provide some information on your environment - in particular ES version, Spark, Java version and number?

Thanks,
","@costin Thanks for responding. This is an issue regarding the actual number of indexed documents in a fresh index in ES (0 documents, created just before the indexing job begins) being different than the number of documents that were given to ES (by spark) to create/index. So spark gives ES 929,660 json documents to index, however sometimes only 924,000 (roughly) are indexed. I have seen the actual number of documents in ES fluctuate between missing up to 5000 or missing as few as 3. On other instances it has had too many documents, up to almost double--still with a fresh index and the same number of documents input. There is no decipherable pattern and the same documents are used for every run. My last run: ES reports 1,409,124 documents, but spark submitted only 929,660 for indexing. The index contained 0 documents to start, nothing else is writing to it, it contains 1 shard and 0 replicas. The number of shards and replicas does seem to matter--the trend is with a higher number of shards, a lower number of replicas and a lower number of total documents attempting to be indexed, we will see the exactly correct number of documents under those conditions, but that is very difficult for me to verify and extrapolate those results in any significant way. I have also tried using both the new native RDD format for spark in the beta release, as well as the old output format based format inside of spark in both the beta and the 2.0.1 releases.

Although I don't think it is related to #268, as a side question, how can I see those metrics when using spark? From the documentation, it looked as if the metrics used the hadoop counter infrastructure, which to my knowledge would be independent of the spark job. Is it possible to see these when using the spark API?

ES version: 1.3.0 (9 data nodes, 3 masters, 1 load balancer)
Spark version: 1.0.0 (1 master, 9 workers)
Java version: 1.8.0_11

Spark and ES are running on the same nodes (spark on a subset or the ES nodes). Working on posting some logs.

Thanks again for your help and response.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/280,"When having `mapreduce.job.ubertask.enable` set to `true` applications, that are executed in uber mode, fail.
There seems to be a problem with the task id:

```
2014-09-25 17:01:27,976 WARN [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Exception running local (uberized) 'child' : java.lang.IllegalArgumentException: TaskId string : attempt_1411539203871_0014_m_000000_0 is not properly formed
        at org.apache.hadoop.mapreduce.TaskID.forName(TaskID.java:233)
        at org.apache.hadoop.mapred.TaskID.forName(TaskID.java:195)
        at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:51)
        at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:226)
        at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.init(EsInputFormat.java:367)
        at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.initialize(EsInputFormat.java:191)
        at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:525)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:763)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
        at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runSubtask(LocalContainerLauncher.java:370)
        at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runTask(LocalContainerLauncher.java:295)
        at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.access$200(LocalContainerLauncher.java:181)
        at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler$1.run(LocalContainerLauncher.java:224)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)

```

Here are the full logs of the crashes in mapreduce and pig
https://gist.github.com/AndreasHoermandinger/a89ec7df4334fa2c98e0
As data I used the shakespeare.json file provided in the 10 minute kibana walkthrough: http://www.elasticsearch.org/guide/en/kibana/current/snippets/shakespeare.json
","Can you please try it out and report back?
","@costin Yes, it works. Thank you!
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/243,"I am getting the following exception when pushing data from hadoop M/R job. When this happens, the node in question is responding and cluster is also healthy (green). Also, plenty of resources on the box. CPU usage is less than 30%, free memory is over 50G. With this exception, the hadoop map task is failing and getting restarted and eventually succeeding (may be by connecting to a different ES node). These errors are not consistent. They are very intermittent.

``` java
org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot find node with id [Q4pQkOIJSSi2oXRXGUVs8w]
    at org.elasticsearch.hadoop.util.Assert.notNull(Assert.java:40)
    at org.elasticsearch.hadoop.rest.RestRepository.getWriteTargetPrimaryShards(RestRepository.java:251)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.initSingleIndex(EsOutputFormat.java:218)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.init(EsOutputFormat.java:201)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.write(EsOutputFormat.java:159)
    at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:638)
    at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
    at afi.search.hadoop.es.ESMapper1.map(ESMapper1.java:227)
    at afi.search.hadoop.es.ESMapper1.map(ESMapper1.java:1)
    at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
    at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)
    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:364)
    at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:415)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
    at org.apache.hadoop.mapred.Child.main(Child.java:249)
```
","What Elastic version are you using? Is there some relocation happening (new nodes coming or leaving the cluster) during the job?
",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/231,"Hi guys, 
I have a little problem when I want to read ES.
My application receive json from external source, enrich and merge the enriched value with the raw data. I got a problem when I want to read back the data for aggregation,

The problem is in:
 org.elasticsearch.hadoop.serialization.dto.mapping.Field.add(Field.java:110)

Here the field.properties() is null so I got null pointer exception.

How can I solve this (or how can I get the raw json from ES?)
","Do you have a sample JSON that causes the issue? Try turning on logging to see the data that goes through the wire.
","Now I not get any NPE, meanwhile I have a problem. In elastic search I got a very large dynamic data (so I can't create type mapping). Can I read the elasticsearch result as raw json? (the ES mapping type is wrong sometime, example It's got """" where it's need a number, try to put the double value to long etc)
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/220,"I'm using the ""repository-hdfs"" plugin to store snapshots on HDFS with Elasticsearch 1.1.1. It seems that Elasticsearch doesn't properly close the TCP connections after a snapshot is created.

The result for me was a ""too many open files"" errors in the Elasticsearch logs. Using the ""lsof"" command I found a pile of more than 50k TCP connections in the CLOSE_WAIT state and as many  file descriptors.
","What version of the repository-hdfs plugin are you using? Any information on where the TCP connections point to? Also what version of hadoop are you using?

Thanks
","I'm using : 
- hadoop 2.0.0 (cdh 4.1.2)
- repository-hdfs 2.0.0-light
- Debian Wheezy

The TCP connections are pointing to the nodes of my hadoop cluster. Here is an extract of ""lsof"" output for the elasticsearch process : 

```
java    68073 elasticsearch 6747u  IPv4           15823974       0t0      TCP es08:57227->cdh4worker04:50010 (CLOSE_WAIT)
java    68073 elasticsearch 6748u  IPv4           15824908       0t0      TCP es08:57651->cdh4worker05:50010 (CLOSE_WAIT)
java    68073 elasticsearch 6749u  IPv4           15818656       0t0      TCP es08:54883->cdh4worker12:50010 (CLOSE_WAIT)
```

I noticed that even few hours after the last snapshot, the connections are still not closed.

Thanks for your help
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/215,"Pre 1.7 jackson versions are not properly detected resulting in an invalid code path being executed. This typically occurs on MapR distros.
","Might it be related to this same issue even after the fix?

```
2014-06-17 19:08:08,491 FATAL org.apache.hadoop.mapred.Child: Error running child : java.lang.NoSuchMethodError: org.codehaus.jackson.map.ObjectMapper.reader(Ljava/lang/Class;)Lorg/codehaus/jackson/map/ObjectReader;
    at org.elasticsearch.hadoop.rest.RestClient.retryFailedEntries(RestClient.java:163)
    at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:156)
    at org.elasticsearch.hadoop.rest.RestRepository.sendBatch(RestRepository.java:170)
    at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:189)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.doClose(EsOutputFormat.java:294)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.close(EsOutputFormat.java:276)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.close(PigOutputFormat.java:149)
    at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.close(MapTask.java:561)
    at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:670)
    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:334)
    at org.apache.hadoop.mapred.Child$4.run(Child.java:270)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:396)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1126)
    at org.apache.hadoop.mapred.Child.main(Child.java:264)
```
","Try the 2.0.1.BUILD not the 2.1.0. Specifically https://oss.sonatype.org/content/repositories/snapshots/org/elasticsearch/elasticsearch-hadoop/2.0.1.BUILD-SNAPSHOT/

Can you also confirm the MapR version used?

Thanks,
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/208,"Hi,

I am using 
hadoop version 1.2.1
pig version 0.12.0
elasticsearch version 1.0.0

I have defined the <b>mapping</b> as below,
{
""doc"" : {
""mappings"" : {
""id"" : {
""properties"" : {
""details"" : {
""properties"" : {
""age"" : {
""type"" : ""integer"",
""store"" : true
},
""name"" : {
""type"" : ""string"",
""store"" : true
},
""no"" : {
""type"" : ""integer"",
""store"" : true
}
}
}
}
}
}
}
}

I have a file on hdfs <b>sample.txt</b>

1,rock,21
2,haddin,23
1,frank,22
2,marvel,24

Below is my <b>Pig script</b>

REGISTER elasticsearch-hadoop-1.3.0.dev-build.jar
A = load 'sample' using PigStorage(',') as (no:long,name:chararray,age:long);
A = group A by $0;
A = foreach A generate $1 as details;
store A into 'doc/id' using org.elasticsearch.hadoop.pig.EsStorage();

<b>Error Report:</b>

org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [Bad Request(400) - [MapperParsingException[object mapping [details] trying to serialize a value with no field associated with it, current value [1]]]]; Bailing out..
at org.elasticsearch.hadoop.rest.RestClient.retryFailedEntries(RestClient.java:190)
at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:156)
at org.elasticsearch.hadoop.rest.RestRepository.sendBatch(RestRepository.java:170)
at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:189)
at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.doClose(EsOutputFormat.java:293)
at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.close(EsOutputFormat.java:275)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.close(PigOutputFormat.java:149)
at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:578)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:651)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:415)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
at org.apache.hadoop.mapred.Child.main(Child.java:249)

The same script works fine when I am using <b>elasticsearch-hadoop-1.3.0 M3</b> stable version and <b>elasticsearch-hadoop-1.3.0 M2</b> (which are not works for proxy setting). But it doesn’t work with <b>elasticsearch-hadoop M3 dev build</b> and <b>2.0 RC1</b> (which are work for proxy setting). There may be the issue while parsing an object.

Thanks,
","Why are using M3 dev build? M3 > M3 dev build. And both are deprecated by the 2.0 RC1 release. Use that version.

I've tried replicating your test on 2.0 RC1 with Pig 0.12.1 and I get a different error, expected though. If you `DUMP` your data before inserting it into Pig, you'll get:

```
({(1,rock,21),(1,frank,22)})
({(2,haddin,23),(2,marvel,24)})
```

And the error is

```
org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [Bad Request(400) - [MapperParsingException[failed to parse [details]]; nested: NumberFormatException[For input string: ""rock""]; ]]; Bailing out..
```

And that's because when using automatic mapping, the first entry in the tuple is a number (which is used by the mapping), the second a string which fails the mapping.

Additionally, take a look at the Pig docs, especially this section which might have affected you
http://www.elasticsearch.org/guide/en/elasticsearch/hadoop/current/pig.html#tuple-names

P.S. To increase readability please use formatting as I did before (which you did use sporadically) or a gist; makes reading stack traces and json human readable.
Again, see: http://www.elasticsearch.org/guide/en/elasticsearch/hadoop/current/troubleshooting.html#help
","Hi costin,

Thank you for your quick response and valuable info. I will follow your instructions.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/207,"Hi,

In elasticsearch-hadoop M3 dev build and 2.0 RC1, Group/Object Datatype does not support while indexing.
But it works fine in M2.
## Pig Script:

REGISTER elasticsearch-hadoop-1.3.0.BUILD-SNAPSHOT.jar

DEFINE EsStorage org.elasticsearch.hadoop.pig.EsStorage('`');

user = LOAD 'forum/user' USING PigStorage('`') As (sid:long,fname:chararray,emailid:chararray);

user = FOREACH user Generate $0,$1,$2;

user = group user by $0;

STORE user INTO 'index1/user' USING EsStorage;
## Error Report :

org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [Bad Request(400) - [MapperParsingException[failed to parse [name]]; nested: NumberFormatException[For input string: ""name""]; ]]; Bailing out..
    at org.elasticsearch.hadoop.rest.RestClient.retryFailedEntries(RestClient.java:190)
    at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:156)
    at org.elasticsearch.hadoop.rest.RestRepository.sendBatch(RestRepository.java:170)
    at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:189)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.doClose(EsOutputFormat.java:293)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.close(EsOutputFormat.java:275)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.close(PigOutputFormat.java:149)
    at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:578)
    at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:651)
    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
    at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:415)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
    at org.apache.hadoop.mapred.Child.main(Child.java:249)

Thanks,
","Why do you specify `'` in the `EsStorage` constructor? - that has no value or meaning.
",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/195,"Using user authentication causes a NPE in CommonsHttpTransport. Disabling authentication works just fine.
","Did I understand anything wrong ? Please find the script and stacktrace.

Script:

DEFINE EsStorage org.elasticsearch.hadoop.pig.EsStorage('es.nodes=IP-x:port-y'
,'es.net.proxy.http.host=IP-x'
,'es.net.proxy.http.port=port-y'
,'es.net.proxy.http.user=username'
,'es.net.proxy.http.password=password'
);

Stacktrace:

org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: [GET] on [_nodes/transport] failed; server[IP-x:port-y] returned [401|Unauthorized:]
    at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:300)
    at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:266)
    at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:270)
    at org.elasticsearch.hadoop.rest.RestClient.get(RestClient.java:108)
    at org.elasticsearch.hadoop.rest.RestClient.discoverNodes(RestClient.java:90)
    at org.elasticsearch.hadoop.rest.InitializationUtils.discoverNodesIfNeeded(InitializationUtils.java:61)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.init(EsOutputFormat.java:181)
    at org.elasticsearch.hadoop.mr.EsOutputFormat$EsRecordWriter.write(EsOutputFormat.java:158)
    at org.elasticsearch.hadoop.pig.EsStorage.putNext(EsStorage.java:191)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:139)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:98)
    at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:638)
    at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapOnly$Map.collect(PigMapOnly.java:48)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.runPipeline(PigGenericMapBase.java:284)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:277)
    at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:64)
    at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
    at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)
    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:364)
    at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:415)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
    at org.apache.hadoop.mapred.Child.main(Child.java:249)

Thanks.
","The fix addressed the NPE mainly not the authorization itself. Can you confirm whether it works without it and double check the user/pass?

Thank,
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/188,"Me again with another, probably silly, question.
Im trying to index many files which are already in the hdfs.
Indexing single files is no problem, no I'm passing all the files which should be indexed at once through the command line using the script above.
For a few minutes it works fine, until it gives this error:

```
ERROR 2997: Encountered IOException. Out of nodes and retries; caught exception


register /home/kolbe/elasticsearch-hadoop-1.3.0.M2/dist/elasticsearch-hadoop-1.3.0.M2-yarn.jar
a = load '$files' using PigStorage() as (json:chararray);
store a into '$index' using org.elasticsearch.hadoop.pig.EsStorage('es.input.json=true','es.nodes=<adress>:9200');
```
","Can you post the entire stacktrace somewhere along with your script?

Thanks!
","https://gist.github.com/Foolius/10552798
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/169,"```
 Recently I come across a strange problem. I want to use the elasticsearch-1.0.0 as a backend storage for hive. I use the elasticsearch-hadoop-1.3.0.M2 to create hive tables on elasticsearch. The hive sql are as followings:
```

create external table supplier_es (S_SUPPKEY BIGINT, S_NAME STRING, S_ADDRESS STRING, S_NATIONKEY BIGINT, S_PHONE STRING, S_ACCTBAL DOUBLE, S_COMMENT STRING) stored by 'org.elasticsearch.hadoop.hive.EsStorageHandler' TBLPROPERTIES('es.resource'='q9/supplier','es.index.auto.create'='true'，'es.nodes' = 'localhost:9200');  

create external table nation_es (N_NATIONKEY BIGINT, N_NAME STRING, N_REGIONKEY BIGINT, N_COMMENT STRING) stored by 'org.elasticsearch.hadoop.hive.EsStorageHandler' TBLPROPERTIES('es.resource'='q9/nation','es.index.auto.create'='true','es.nodes' = 'localhost:9200'); 

The table join operation is as followings:

select s_suppkey, n_name from supplier_es s join nation_es n on n.n_nationkey = s.s_nationkey;

the error messages( I get from the log file):
2014-03-19 15:16:39,447 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2014-03-19 15:16:39,448 INFO [main] org.apache.hadoop.hive.ql.exec.MapOperator: fpath:hdfs://server-220:8020/user/hive/warehouse/nation_es
2014-03-19 15:16:39,462 INFO [main] org.apache.hadoop.hive.ql.exec.MapOperator: getPathToAliases
2014-03-19 15:16:39,463 INFO [main] org.apache.hadoop.hive.ql.exec.MapOperator: Adding alias s to work list for file hdfs://server-220:8020/user/hive/warehouse/supplier_es
2014-03-19 15:16:39,465 ERROR [main] org.apache.hadoop.hive.ql.exec.MapOperator: Configuration does not have any alias for path: hdfs://server-220:8020/user/hive/warehouse/nation_es
2014-03-19 15:16:39,480 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: Error in configuring object
    at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109)
    at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75)
    at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)
    at org.apache.hadoop.mapred.MapTask.runOldMapper_aroundBody2(MapTask.java:434)
    at org.apache.hadoop.mapred.MapTask$AjcClosure3.run(MapTask.java:1)
    at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149)
    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.reflect.InvocationTargetException
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106)
    ... 19 more
Caused by: java.lang.RuntimeException: Error in configuring object
    at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109)
    at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75)
    at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)
    at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:38)
    ... 24 more
Caused by: java.lang.reflect.InvocationTargetException
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106)
    ... 27 more
Caused by: java.lang.RuntimeException: Map operator initialization failed
    at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:142)
    ... 32 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent
    at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:419)
    at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:110)
    ... 32 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent
    at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:413)
    ... 33 more
I have try to figure out the problem, but I can't find out the reason. I ask anyone for help. Thanks very much.
","what distro and version of Hadoop and Hive are you using? I'm assuming the Intel one but I'm interested in the versions of all the aforementioned components.

Thanks,
","I use the hadoop verison 2.2.0 and hive version 0.12.0. By the way I have a try with the lastest master version . The problem has happened again.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/162,"Please note EsTap was/is working as expected in 1.3.0.M2, however, it seems to be broken in the last ~2 weeks of nightly builds. Also note, our usage pattern or code did not change between the release of 1.3.0.M2 and today (2014-03-05).
","Can you expand on that - what exception do you encounter?
","Hello Costin: thanks for the quick response! Ok, so the exception I'm seeing is below, I pared down everything to keep things simple for debug purposes, but, basically I'm creating an EsTap to an index/type together with an array of fields of interest, then simply outputting all data from the tap to stdout, no queries to complicate matters, no ""es.query"" config param either since this also doesn't seem to be working any longer. Note, if I use 1.3.0.M2, everything works as expected, but, not so with the snapshots.
14/03/05 15:19:11 ERROR stream.TrapHandler: caught Throwable, no trap available, rethrowing
cascading.tuple.TupleException: unable to read from input identifier: 'unknown'
    at cascading.tuple.TupleEntrySchemeIterator.hasNext(TupleEntrySchemeIterator.java:127)
    at cascading.flow.stream.SourceStage.map(SourceStage.java:76)
    at cascading.flow.stream.SourceStage.run(SourceStage.java:58)
    at cascading.flow.hadoop.FlowMapper.run(FlowMapper.java:127)
    at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:358)
    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:307)
    at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:177)
Caused by: java.lang.IllegalStateException: Cannot build scroll [adevents-2014-02-12/click/_search?search_type=scan&scroll=5&size=50&_source=ri,bot_act,psn,sts,ptz,pv_lo,cid&preference=_shards:1;_only_node:s6gZjGaBT6KFEpn23r5vgA]
    at org.elasticsearch.hadoop.rest.QueryBuilder.build(QueryBuilder.java:201)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.next(EsInputFormat.java:286)
    at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:192)
    at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:176)
    at cascading.tap.hadoop.util.MeasuredRecordReader.next(MeasuredRecordReader.java:61)
    at org.elasticsearch.hadoop.cascading.EsHadoopScheme.source(EsHadoopScheme.java:154)
    at cascading.tuple.TupleEntrySchemeIterator.getNext(TupleEntrySchemeIterator.java:140)
    at cascading.tuple.TupleEntrySchemeIterator.hasNext(TupleEntrySchemeIterator.java:120)
    ... 6 more
Caused by: java.io.IOException: Out of nodes and retries; caught exception
    at org.elasticsearch.hadoop.rest.NetworkClient.execute(NetworkClient.java:98)
    at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:250)
    at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:246)
    at org.elasticsearch.hadoop.rest.RestClient.scan(RestClient.java:274)
    at org.elasticsearch.hadoop.rest.RestRepository.scan(RestRepository.java:97)
    at org.elasticsearch.hadoop.rest.QueryBuilder.build(QueryBuilder.java:199)
    ... 13 more
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/158,"Hi!

 I'm trying to work with pig over an ES index. In my ES index I have arrays of strings that I can't read without error in pig. A gist recreation is here: https://gist.github.com/jpparis-orange/9329308#file-espigarray (ES index creation and pig commands).

Here is my configuration:
- elasticsearch-1.0.0
- elasticsearch-hadoop-yarn.jar from 1.3.0.M2
- hadoop-2.2.0-bin
- hive-0.12.0-bin
- pig-0.12.0 but recompiled pig-0.12.0-withouthadoop.jar for yarn

If I declare the pig array with my_array:{ the_tuple: ( the_item: chararray ) }, I get (more detailled stack in the gist)
java.lang.OutOfMemoryError: Java heap space
    at java.util.Arrays.copyOf(Arrays.java:2367)
    at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:130)

 If I use the (incorrect) pig syntax my_array:(), I can print the array, but if I try to COUNT the elements, I get this error:
<line 2, column 52> Could not infer the matching function for org.apache.pig.builtin.COUNT as multiple or none of them fit. Please use an explicit cast.

Thanks for any hints!
jp
","Can you enable logging in Pig and report back? I'm still unsure why an array (created by es-hadoop or otherwise) would cause this issue in Pig - especially when only 2 items are contained within.

As an alternative you could load the array as individual items and then manually create the bag through `TOBAG`.
",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/157,"Hello!

 I'm trying to read double value with hive. I have prepared a gist recreation here : https://gist.github.com/jpparis-orange/9321708#file-eshivedouble.

Here is the version of the different components I use:
- elasticsearch-1.0.0
- elasticsearch-hadoop-yarn.jar from 1.3.0.M2
- hadoop-2.2.0-bin
- hive-0.12.0-bin

If I select a double field in hive, I get the following exception:
Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row [Error getting row data with exception java.lang.ClassCastException: org.apache.hadoop.io.DoubleWritable cannot be cast to org.apache.hadoop.hive.serde2.io.DoubleWritable
    at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableDoubleObjectInspector.get(WritableDoubleObjectInspector.java:35)
    at org.apache.hadoop.hive.serde2.SerDeUtils.buildJSONString(SerDeUtils.java:277)
...
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row [Error getting row data with exception java.lang.ClassCastException: org.apache.hadoop.io.DoubleWritable cannot be cast to org.apache.hadoop.hive.serde2.io.DoubleWritable
    at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableDoubleObjectInspector.get(WritableDoubleObjectInspector.java:35)
    at org.apache.hadoop.hive.serde2.SerDeUtils.buildJSONString(SerDeUtils.java:277)
...
Caused by: java.lang.ClassCastException: org.apache.hadoop.io.DoubleWritable cannot be cast to org.apache.hadoop.hive.serde2.io.DoubleWritable
    at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableDoubleObjectInspector.get(WritableDoubleObjectInspector.java:35)
    at org.apache.hadoop.hive.serde2.lazy.LazyUtils.writePrimitiveUTF8(LazyUtils.java:218)

jp
","Can you please check it out, build it locally and try it out? A simple `gradlew -x test build` should be enough. As an alternative you can wait for the nightly build to publish an artifact but that will take 20-30' until all the build plans complete.
Note that there's no yarn jar - the default one works in both environments.

Cheers,
","Hi!
I have downloaded the master... and my test runs fine now.

Thanks 
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/152,"using http://typesafe.artifactoryonline.com/typesafe/sonatype-snapshots/org/elasticsearch/elasticsearch-hadoop/1.3.0.BUILD-SNAPSHOT/elasticsearch-hadoop-1.3.0.BUILD-20140224.171205-318.jar
I get
org.apache.spark.SparkException: Job aborted: Task 0.0:0 failed 1 times (most recent failure: Exception failure: java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker)

The code is the same as shown in #148 
This is related to #151 for spark integration

```
$ sbt run
[info] Loading project definition from /Users/rbraley/IdeaProjects/elasticsearch-spark-example/project
[info] Set current project to elasticsearch-spark-example (in build file:/Users/rbraley/IdeaProjects/elasticsearch-spark-example/)
[info] Running io.traintracks.elasticsearch.spark.example.SimpleApp
14/02/25 12:00:39 INFO slf4j.Slf4jLogger: Slf4jLogger started
14/02/25 12:00:39 INFO Remoting: Starting remoting
14/02/25 12:00:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@192.168.2.88:50171]
14/02/25 12:00:39 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@192.168.2.88:50171]
14/02/25 12:00:39 INFO spark.SparkEnv: Registering BlockManagerMaster
14/02/25 12:00:39 INFO storage.DiskBlockManager: Created local directory at /var/folders/rn/p2d7mh016b34qvm47jybmg380000gn/T/spark-local-20140225120039-5926
14/02/25 12:00:39 INFO storage.MemoryStore: MemoryStore started with capacity 890.9 MB.
14/02/25 12:00:39 INFO network.ConnectionManager: Bound socket to port 50172 with id = ConnectionManagerId(192.168.2.88,50172)
14/02/25 12:00:40 INFO storage.BlockManagerMaster: Trying to register BlockManager
14/02/25 12:00:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager 192.168.2.88:50172 with 890.9 MB RAM
14/02/25 12:00:40 INFO storage.BlockManagerMaster: Registered BlockManager
14/02/25 12:00:40 INFO spark.HttpServer: Starting HTTP Server
14/02/25 12:00:40 INFO server.Server: jetty-7.6.8.v20121106
14/02/25 12:00:40 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50173
14/02/25 12:00:40 INFO broadcast.HttpBroadcast: Broadcast server started at http://192.168.2.88:50173
14/02/25 12:00:40 INFO spark.SparkEnv: Registering MapOutputTracker
14/02/25 12:00:40 INFO spark.HttpFileServer: HTTP File server directory is /var/folders/rn/p2d7mh016b34qvm47jybmg380000gn/T/spark-d9105b10-cb2a-4acc-9e43-58c947b7f5e5
14/02/25 12:00:40 INFO spark.HttpServer: Starting HTTP Server
14/02/25 12:00:40 INFO server.Server: jetty-7.6.8.v20121106
14/02/25 12:00:40 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50174
14/02/25 12:00:40 INFO server.Server: jetty-7.6.8.v20121106
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/pool,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/metrics/json,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
14/02/25 12:00:40 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
14/02/25 12:00:40 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
14/02/25 12:00:40 INFO ui.SparkUI: Started Spark Web UI at http://192.168.2.88:4040
2014-02-25 12:00:40.450 java[974:6b0f] Unable to load realm info from SCDynamicStore
14/02/25 12:00:40 INFO storage.MemoryStore: ensureFreeSpace(32969) called with curMem=0, maxMem=934163251
14/02/25 12:00:40 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.2 KB, free 890.9 MB)
14/02/25 12:00:40 INFO mr.EsInputFormat: Discovered mapping {demo=[test=STRING]} for [demo/demo]
14/02/25 12:00:40 INFO mr.EsInputFormat: Created [5] shard-splits
14/02/25 12:00:40 INFO spark.SparkContext: Starting job: foreach at SimpleApp.scala:18
14/02/25 12:00:40 INFO scheduler.DAGScheduler: Got job 0 (foreach at SimpleApp.scala:18) with 5 output partitions (allowLocal=false)
14/02/25 12:00:40 INFO scheduler.DAGScheduler: Final stage: Stage 0 (foreach at SimpleApp.scala:18)
14/02/25 12:00:40 INFO scheduler.DAGScheduler: Parents of final stage: List()
14/02/25 12:00:40 INFO scheduler.DAGScheduler: Missing parents: List()
14/02/25 12:00:40 INFO scheduler.DAGScheduler: Submitting Stage 0 (HadoopRDD[0] at hadoopRDD at SimpleApp.scala:16), which has no missing parents
14/02/25 12:00:41 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from Stage 0 (HadoopRDD[0] at hadoopRDD at SimpleApp.scala:16)
14/02/25 12:00:41 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
14/02/25 12:00:41 INFO scheduler.TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/02/25 12:00:41 INFO scheduler.TaskSetManager: Serialized task 0.0:0 as 2714 bytes in 7 ms
14/02/25 12:00:41 INFO executor.Executor: Running task ID 0
14/02/25 12:00:41 INFO storage.BlockManager: Found block broadcast_0 locally
14/02/25 12:00:41 INFO rdd.HadoopRDD: Input split: ShardInputSplit [node=[RYrePPv6SpGV-NOehFoEuw/Natchios, Elektra|127.0.0.1:9200],shard=0]
14/02/25 12:00:41 ERROR mr.EsInputFormat: Cannot determine task id - current properties are {fs.s3n.impl=org.apache.hadoop.fs.s3native.NativeS3FileSystem, mapred.task.cache.levels=2, hadoop.tmp.dir=/tmp/hadoop-${user.name}, hadoop.native.lib=true, map.sort.class=org.apache.hadoop.util.QuickSort, es.internal.mr.target.resource=demo/demo, ipc.client.idlethreshold=4000, mapred.system.dir=${hadoop.tmp.dir}/mapred/system, mapred.job.tracker.persist.jobstatus.hours=0, io.skip.checksum.errors=false, fs.default.name=file:///, mapred.cluster.reduce.memory.mb=-1, mapred.child.tmp=./tmp, fs.har.impl.disable.cache=true, es.internal.es.version=0.90.10, mapred.skip.reduce.max.skip.groups=0, mapred.heartbeats.in.second=100, mapred.tasktracker.dns.nameserver=default, io.sort.factor=10, mapred.task.timeout=600000, mapred.max.tracker.failures=4, hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory, fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem, mapred.job.tracker.jobhistory.lru.cache.size=5, mapred.skip.map.auto.incr.proc.count=true, mapreduce.job.complete.cancel.delegation.tokens=true, io.mapfile.bloom.size=1048576, mapreduce.reduce.shuffle.connect.timeout=180000, mapred.jobtracker.blacklist.fault-timeout-window=180, tasktracker.http.threads=40, mapred.job.shuffle.merge.percent=0.66, fs.ftp.impl=org.apache.hadoop.fs.ftp.FTPFileSystem, io.bytes.per.checksum=512, mapred.output.compress=false, mapred.combine.recordsBeforeProgress=10000, mapred.healthChecker.script.timeout=600000, topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping, mapred.reduce.slowstart.completed.maps=0.05, mapred.reduce.max.attempts=4, es.ser.reader.value.class=org.elasticsearch.hadoop.mr.WritableValueReader, fs.ramfs.impl=org.apache.hadoop.fs.InMemoryFileSystem, mapred.skip.map.max.skip.records=0, mapred.cluster.map.memory.mb=-1, hadoop.security.group.mapping=org.apache.hadoop.security.ShellBasedUnixGroupsMapping, mapred.job.tracker.persist.jobstatus.dir=/jobtracker/jobsInfo, fs.s3.buffer.dir=${hadoop.tmp.dir}/s3, job.end.retry.attempts=0, fs.file.impl=org.apache.hadoop.fs.LocalFileSystem, mapred.local.dir.minspacestart=0, mapred.output.compression.type=RECORD, topology.script.number.args=100, io.mapfile.bloom.error.rate=0.005, mapred.cluster.max.reduce.memory.mb=-1, mapred.max.tracker.blacklists=4, mapred.task.profile.maps=0-2, mapred.userlog.retain.hours=24, mapred.job.tracker.persist.jobstatus.active=false, hadoop.security.authorization=false, local.cache.size=10737418240, mapred.map.tasks=2, mapred.min.split.size=0, mapred.child.java.opts=-Xmx200m, mapreduce.job.counters.limit=120, mapred.job.queue.name=default, mapred.job.tracker.retiredjobs.cache.size=1000, ipc.server.listen.queue.size=128, mapred.inmem.merge.threshold=1000, job.end.retry.interval=30000, mapreduce.tasktracker.outofband.heartbeat.damper=1000000, mapred.skip.attempts.to.start.skipping=2, fs.checkpoint.dir=${hadoop.tmp.dir}/dfs/namesecondary, mapred.reduce.tasks=1, mapred.merge.recordsBeforeProgress=10000, mapred.userlog.limit.kb=0, mapred.job.reduce.memory.mb=-1, webinterface.private.actions=false, hadoop.security.token.service.use_ip=true, io.sort.spill.percent=0.80, mapred.job.shuffle.input.buffer.percent=0.70, mapred.map.tasks.speculative.execution=true, hadoop.util.hash.type=murmur, mapred.map.max.attempts=4, mapreduce.job.acl-view-job= , mapred.job.tracker.handler.count=10, mapreduce.reduce.shuffle.read.timeout=180000, mapred.tasktracker.expiry.interval=600000, mapred.jobtracker.job.history.block.size=3145728, mapred.jobtracker.maxtasks.per.job=-1, keep.failed.task.files=false, ipc.client.tcpnodelay=false, mapred.task.profile.reduces=0-2, mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, io.map.index.skip=0, ipc.server.tcpnodelay=false, mapred.jobtracker.blacklist.fault-bucket-width=15, es.resource=demo/demo, mapred.job.map.memory.mb=-1, hadoop.logfile.size=10000000, mapred.reduce.tasks.speculative.execution=true, mapreduce.tasktracker.outofband.heartbeat=false, mapreduce.reduce.input.limit=-1, hadoop.security.authentication=simple, fs.checkpoint.period=3600, mapred.job.reuse.jvm.num.tasks=1, mapred.jobtracker.completeuserjobs.maximum=100, mapred.task.tracker.task-controller=org.apache.hadoop.mapred.DefaultTaskController, fs.s3.maxRetries=4, mapred.cluster.max.map.memory.mb=-1, mapreduce.reduce.shuffle.maxfetchfailures=10, mapreduce.job.acl-modify-job= , fs.hftp.impl=org.apache.hadoop.hdfs.HftpFileSystem, mapred.local.dir=${hadoop.tmp.dir}/mapred/local, fs.s3.sleepTimeSeconds=10, fs.trash.interval=0, mapred.submit.replication=10, fs.har.impl=org.apache.hadoop.fs.HarFileSystem, mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, mapred.tasktracker.dns.interface=default, mapred.job.tracker=local, io.seqfile.sorter.recordlimit=1000000, mapred.line.input.format.linespermap=1, mapred.jobtracker.taskScheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler, fs.webhdfs.impl=org.apache.hadoop.hdfs.web.WebHdfsFileSystem, mapred.local.dir.minspacekill=0, io.sort.record.percent=0.05, fs.kfs.impl=org.apache.hadoop.fs.kfs.KosmosFileSystem, mapred.temp.dir=${hadoop.tmp.dir}/mapred/temp, mapred.tasktracker.reduce.tasks.maximum=2, fs.checkpoint.edits.dir=${fs.checkpoint.dir}, mapred.tasktracker.tasks.sleeptime-before-sigkill=5000, mapred.job.reduce.input.buffer.percent=0.0, mapred.tasktracker.indexcache.mb=10, es.internal.hosts=, mapreduce.job.split.metainfo.maxsize=10000000, hadoop.logfile.count=10, mapred.skip.reduce.auto.incr.proc.count=true, io.seqfile.compress.blocksize=1000000, fs.s3.block.size=67108864, mapred.tasktracker.taskmemorymanager.monitoring-interval=5000, mapred.acls.enabled=false, mapred.queue.default.state=RUNNING, mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging, mapred.queue.names=default, fs.hsftp.impl=org.apache.hadoop.hdfs.HsftpFileSystem, mapred.task.tracker.http.address=0.0.0.0:50060, mapred.reduce.parallel.copies=5, io.seqfile.lazydecompress=true, io.sort.mb=100, ipc.client.connection.maxidletime=10000, mapred.task.tracker.report.address=127.0.0.1:0, mapred.compress.map.output=false, hadoop.security.uid.cache.secs=14400, mapred.healthChecker.interval=60000, ipc.client.kill.max=10, ipc.client.connect.max.retries=10, fs.s3.impl=org.apache.hadoop.fs.s3.S3FileSystem, mapred.user.jobconf.limit=5242880, mapred.job.tracker.http.address=0.0.0.0:50030, io.file.buffer.size=4096, mapred.jobtracker.restart.recover=false, io.serializations=org.apache.hadoop.io.serializer.WritableSerialization, mapred.task.profile=false, jobclient.output.filter=FAILED, mapred.tasktracker.map.tasks.maximum=2, io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec, fs.checkpoint.size=67108864}
14/02/25 12:00:41 ERROR executor.Executor: Exception in task ID 0
java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker
    at org.elasticsearch.hadoop.util.Assert.notNull(Assert.java:38)
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:57)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/25 12:00:41 INFO scheduler.TaskSetManager: Starting task 0.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/02/25 12:00:41 INFO scheduler.TaskSetManager: Serialized task 0.0:1 as 2714 bytes in 0 ms
14/02/25 12:00:41 INFO executor.Executor: Running task ID 1
14/02/25 12:00:41 WARN scheduler.TaskSetManager: Lost TID 0 (task 0.0:0)
14/02/25 12:00:41 INFO storage.BlockManager: Found block broadcast_0 locally
14/02/25 12:00:41 INFO rdd.HadoopRDD: Input split: ShardInputSplit [node=[RYrePPv6SpGV-NOehFoEuw/Natchios, Elektra|127.0.0.1:9200],shard=1]
14/02/25 12:00:41 ERROR mr.EsInputFormat: Cannot determine task id - current properties are {fs.s3n.impl=org.apache.hadoop.fs.s3native.NativeS3FileSystem, mapred.task.cache.levels=2, hadoop.tmp.dir=/tmp/hadoop-${user.name}, hadoop.native.lib=true, map.sort.class=org.apache.hadoop.util.QuickSort, es.internal.mr.target.resource=demo/demo, ipc.client.idlethreshold=4000, mapred.system.dir=${hadoop.tmp.dir}/mapred/system, mapred.job.tracker.persist.jobstatus.hours=0, io.skip.checksum.errors=false, fs.default.name=file:///, mapred.cluster.reduce.memory.mb=-1, mapred.child.tmp=./tmp, fs.har.impl.disable.cache=true, es.internal.es.version=0.90.10, mapred.skip.reduce.max.skip.groups=0, mapred.heartbeats.in.second=100, mapred.tasktracker.dns.nameserver=default, io.sort.factor=10, mapred.task.timeout=600000, mapred.max.tracker.failures=4, hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory, fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem, mapred.job.tracker.jobhistory.lru.cache.size=5, mapred.skip.map.auto.incr.proc.count=true, mapreduce.job.complete.cancel.delegation.tokens=true, io.mapfile.bloom.size=1048576, mapreduce.reduce.shuffle.connect.timeout=180000, mapred.jobtracker.blacklist.fault-timeout-window=180, tasktracker.http.threads=40, mapred.job.shuffle.merge.percent=0.66, fs.ftp.impl=org.apache.hadoop.fs.ftp.FTPFileSystem, io.bytes.per.checksum=512, mapred.output.compress=false, mapred.combine.recordsBeforeProgress=10000, mapred.healthChecker.script.timeout=600000, topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping, mapred.reduce.slowstart.completed.maps=0.05, mapred.reduce.max.attempts=4, es.ser.reader.value.class=org.elasticsearch.hadoop.mr.WritableValueReader, fs.ramfs.impl=org.apache.hadoop.fs.InMemoryFileSystem, mapred.skip.map.max.skip.records=0, mapred.cluster.map.memory.mb=-1, hadoop.security.group.mapping=org.apache.hadoop.security.ShellBasedUnixGroupsMapping, mapred.job.tracker.persist.jobstatus.dir=/jobtracker/jobsInfo, fs.s3.buffer.dir=${hadoop.tmp.dir}/s3, job.end.retry.attempts=0, fs.file.impl=org.apache.hadoop.fs.LocalFileSystem, mapred.local.dir.minspacestart=0, mapred.output.compression.type=RECORD, topology.script.number.args=100, io.mapfile.bloom.error.rate=0.005, mapred.cluster.max.reduce.memory.mb=-1, mapred.max.tracker.blacklists=4, mapred.task.profile.maps=0-2, mapred.userlog.retain.hours=24, mapred.job.tracker.persist.jobstatus.active=false, hadoop.security.authorization=false, local.cache.size=10737418240, mapred.map.tasks=2, mapred.min.split.size=0, mapred.child.java.opts=-Xmx200m, mapreduce.job.counters.limit=120, mapred.job.queue.name=default, mapred.job.tracker.retiredjobs.cache.size=1000, ipc.server.listen.queue.size=128, mapred.inmem.merge.threshold=1000, job.end.retry.interval=30000, mapreduce.tasktracker.outofband.heartbeat.damper=1000000, mapred.skip.attempts.to.start.skipping=2, fs.checkpoint.dir=${hadoop.tmp.dir}/dfs/namesecondary, mapred.reduce.tasks=1, mapred.merge.recordsBeforeProgress=10000, mapred.userlog.limit.kb=0, mapred.job.reduce.memory.mb=-1, webinterface.private.actions=false, hadoop.security.token.service.use_ip=true, io.sort.spill.percent=0.80, mapred.job.shuffle.input.buffer.percent=0.70, mapred.map.tasks.speculative.execution=true, hadoop.util.hash.type=murmur, mapred.map.max.attempts=4, mapreduce.job.acl-view-job= , mapred.job.tracker.handler.count=10, mapreduce.reduce.shuffle.read.timeout=180000, mapred.tasktracker.expiry.interval=600000, mapred.jobtracker.job.history.block.size=3145728, mapred.jobtracker.maxtasks.per.job=-1, keep.failed.task.files=false, ipc.client.tcpnodelay=false, mapred.task.profile.reduces=0-2, mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, io.map.index.skip=0, ipc.server.tcpnodelay=false, mapred.jobtracker.blacklist.fault-bucket-width=15, es.resource=demo/demo, mapred.job.map.memory.mb=-1, hadoop.logfile.size=10000000, mapred.reduce.tasks.speculative.execution=true, mapreduce.tasktracker.outofband.heartbeat=false, mapreduce.reduce.input.limit=-1, hadoop.security.authentication=simple, fs.checkpoint.period=3600, mapred.job.reuse.jvm.num.tasks=1, mapred.jobtracker.completeuserjobs.maximum=100, mapred.task.tracker.task-controller=org.apache.hadoop.mapred.DefaultTaskController, fs.s3.maxRetries=4, mapred.cluster.max.map.memory.mb=-1, mapreduce.reduce.shuffle.maxfetchfailures=10, mapreduce.job.acl-modify-job= , fs.hftp.impl=org.apache.hadoop.hdfs.HftpFileSystem, mapred.local.dir=${hadoop.tmp.dir}/mapred/local, fs.s3.sleepTimeSeconds=10, fs.trash.interval=0, mapred.submit.replication=10, fs.har.impl=org.apache.hadoop.fs.HarFileSystem, mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, mapred.tasktracker.dns.interface=default, mapred.job.tracker=local, io.seqfile.sorter.recordlimit=1000000, mapred.line.input.format.linespermap=1, mapred.jobtracker.taskScheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler, fs.webhdfs.impl=org.apache.hadoop.hdfs.web.WebHdfsFileSystem, mapred.local.dir.minspacekill=0, io.sort.record.percent=0.05, fs.kfs.impl=org.apache.hadoop.fs.kfs.KosmosFileSystem, mapred.temp.dir=${hadoop.tmp.dir}/mapred/temp, mapred.tasktracker.reduce.tasks.maximum=2, fs.checkpoint.edits.dir=${fs.checkpoint.dir}, mapred.tasktracker.tasks.sleeptime-before-sigkill=5000, mapred.job.reduce.input.buffer.percent=0.0, mapred.tasktracker.indexcache.mb=10, es.internal.hosts=, mapreduce.job.split.metainfo.maxsize=10000000, hadoop.logfile.count=10, mapred.skip.reduce.auto.incr.proc.count=true, io.seqfile.compress.blocksize=1000000, fs.s3.block.size=67108864, mapred.tasktracker.taskmemorymanager.monitoring-interval=5000, mapred.acls.enabled=false, mapred.queue.default.state=RUNNING, mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging, mapred.queue.names=default, fs.hsftp.impl=org.apache.hadoop.hdfs.HsftpFileSystem, mapred.task.tracker.http.address=0.0.0.0:50060, mapred.reduce.parallel.copies=5, io.seqfile.lazydecompress=true, io.sort.mb=100, ipc.client.connection.maxidletime=10000, mapred.task.tracker.report.address=127.0.0.1:0, mapred.compress.map.output=false, hadoop.security.uid.cache.secs=14400, mapred.healthChecker.interval=60000, ipc.client.kill.max=10, ipc.client.connect.max.retries=10, fs.s3.impl=org.apache.hadoop.fs.s3.S3FileSystem, mapred.user.jobconf.limit=5242880, mapred.job.tracker.http.address=0.0.0.0:50030, io.file.buffer.size=4096, mapred.jobtracker.restart.recover=false, io.serializations=org.apache.hadoop.io.serializer.WritableSerialization, mapred.task.profile=false, jobclient.output.filter=FAILED, mapred.tasktracker.map.tasks.maximum=2, io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec, fs.checkpoint.size=67108864}
14/02/25 12:00:41 ERROR executor.Executor: Exception in task ID 1
java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker
    at org.elasticsearch.hadoop.util.Assert.notNull(Assert.java:38)
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:57)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/25 12:00:41 WARN scheduler.TaskSetManager: Loss was due to java.lang.IllegalArgumentException
java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker
    at org.elasticsearch.hadoop.util.Assert.notNull(Assert.java:38)
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:57)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/25 12:00:41 ERROR scheduler.TaskSetManager: Task 0.0:0 failed 1 times; aborting job
14/02/25 12:00:41 INFO scheduler.TaskSchedulerImpl: Remove TaskSet 0.0 from pool
14/02/25 12:00:41 INFO scheduler.TaskSchedulerImpl: Ignoring update with state RUNNING from TID 1 because its task set is gone
14/02/25 12:00:41 INFO scheduler.TaskSchedulerImpl: Ignoring update with state FAILED from TID 1 because its task set is gone
14/02/25 12:00:41 INFO scheduler.DAGScheduler: Failed to run foreach at SimpleApp.scala:18
[error] (run-main) org.apache.spark.SparkException: Job aborted: Task 0.0:0 failed 1 times (most recent failure: Exception failure: java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker)
org.apache.spark.SparkException: Job aborted: Task 0.0:0 failed 1 times (most recent failure: Exception failure: java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$abortStage$1.apply(DAGScheduler.scala:1028)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$abortStage$1.apply(DAGScheduler.scala:1026)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$abortStage(DAGScheduler.scala:1026)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$processEvent$10.apply(DAGScheduler.scala:619)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$processEvent$10.apply(DAGScheduler.scala:619)
    at scala.Option.foreach(Option.scala:236)
    at org.apache.spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:619)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$start$1$$anon$2$$anonfun$receive$1.applyOrElse(DAGScheduler.scala:207)
    at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
    at akka.actor.ActorCell.invoke(ActorCell.scala:456)
    at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
    at akka.dispatch.Mailbox.run(Mailbox.scala:219)
    at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
[trace] Stack trace suppressed: run last compile:run for the full output.
14/02/25 12:00:41 INFO network.ConnectionManager: Selector thread was interrupted!
java.lang.RuntimeException: Nonzero exit code: 1
    at scala.sys.package$.error(package.scala:27)
[trace] Stack trace suppressed: run last compile:run for the full output.
[error] (compile:run) Nonzero exit code: 1
[error] Total time: 3 s, completed Feb 25, 2014 12:00:41 PM
rbraley at Ryans-MacBook-Pro in ~/IdeaProjects/elasticsearch-spark-example on master*
$ sbt package
[info] Loading project definition from /Users/rbraley/IdeaProjects/elasticsearch-spark-example/project
[info] Set current project to elasticsearch-spark-example (in build file:/Users/rbraley/IdeaProjects/elasticsearch-spark-example/)
[success] Total time: 0 s, completed Feb 25, 2014 12:01:11 PM
rbraley at Ryans-MacBook-Pro in ~/IdeaProjects/elasticsearch-spark-example on master*
$ sbt run
[info] Loading project definition from /Users/rbraley/IdeaProjects/elasticsearch-spark-example/project
[info] Set current project to elasticsearch-spark-example (in build file:/Users/rbraley/IdeaProjects/elasticsearch-spark-example/)
[info] Running io.traintracks.elasticsearch.spark.example.SimpleApp
14/02/25 12:01:17 INFO slf4j.Slf4jLogger: Slf4jLogger started
14/02/25 12:01:17 INFO Remoting: Starting remoting
14/02/25 12:01:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@192.168.2.88:50178]
14/02/25 12:01:17 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@192.168.2.88:50178]
14/02/25 12:01:17 INFO spark.SparkEnv: Registering BlockManagerMaster
14/02/25 12:01:17 INFO storage.DiskBlockManager: Created local directory at /var/folders/rn/p2d7mh016b34qvm47jybmg380000gn/T/spark-local-20140225120117-e711
14/02/25 12:01:17 INFO storage.MemoryStore: MemoryStore started with capacity 890.9 MB.
14/02/25 12:01:17 INFO network.ConnectionManager: Bound socket to port 50179 with id = ConnectionManagerId(192.168.2.88,50179)
14/02/25 12:01:17 INFO storage.BlockManagerMaster: Trying to register BlockManager
14/02/25 12:01:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager 192.168.2.88:50179 with 890.9 MB RAM
14/02/25 12:01:17 INFO storage.BlockManagerMaster: Registered BlockManager
14/02/25 12:01:17 INFO spark.HttpServer: Starting HTTP Server
14/02/25 12:01:18 INFO server.Server: jetty-7.6.8.v20121106
14/02/25 12:01:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50180
14/02/25 12:01:18 INFO broadcast.HttpBroadcast: Broadcast server started at http://192.168.2.88:50180
14/02/25 12:01:18 INFO spark.SparkEnv: Registering MapOutputTracker
14/02/25 12:01:18 INFO spark.HttpFileServer: HTTP File server directory is /var/folders/rn/p2d7mh016b34qvm47jybmg380000gn/T/spark-f407ba7c-5455-476d-8cfe-250296e45668
14/02/25 12:01:18 INFO spark.HttpServer: Starting HTTP Server
14/02/25 12:01:18 INFO server.Server: jetty-7.6.8.v20121106
14/02/25 12:01:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50181
14/02/25 12:01:18 INFO server.Server: jetty-7.6.8.v20121106
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/pool,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/metrics/json,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
14/02/25 12:01:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
14/02/25 12:01:18 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
14/02/25 12:01:18 INFO ui.SparkUI: Started Spark Web UI at http://192.168.2.88:4040
2014-02-25 12:01:18.391 java[1012:690f] Unable to load realm info from SCDynamicStore
14/02/25 12:01:18 INFO storage.MemoryStore: ensureFreeSpace(32969) called with curMem=0, maxMem=934163251
14/02/25 12:01:18 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.2 KB, free 890.9 MB)
14/02/25 12:01:18 INFO mr.EsInputFormat: Discovered mapping {demo=[test=STRING]} for [demo/demo]
14/02/25 12:01:18 INFO mr.EsInputFormat: Created [5] shard-splits
14/02/25 12:01:18 INFO spark.SparkContext: Starting job: foreach at SimpleApp.scala:18
14/02/25 12:01:18 INFO scheduler.DAGScheduler: Got job 0 (foreach at SimpleApp.scala:18) with 5 output partitions (allowLocal=false)
14/02/25 12:01:18 INFO scheduler.DAGScheduler: Final stage: Stage 0 (foreach at SimpleApp.scala:18)
14/02/25 12:01:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
14/02/25 12:01:18 INFO scheduler.DAGScheduler: Missing parents: List()
14/02/25 12:01:18 INFO scheduler.DAGScheduler: Submitting Stage 0 (HadoopRDD[0] at hadoopRDD at SimpleApp.scala:16), which has no missing parents
14/02/25 12:01:18 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from Stage 0 (HadoopRDD[0] at hadoopRDD at SimpleApp.scala:16)
14/02/25 12:01:18 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
14/02/25 12:01:18 INFO scheduler.TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/02/25 12:01:18 INFO scheduler.TaskSetManager: Serialized task 0.0:0 as 2714 bytes in 7 ms
14/02/25 12:01:18 INFO executor.Executor: Running task ID 0
14/02/25 12:01:18 INFO storage.BlockManager: Found block broadcast_0 locally
14/02/25 12:01:18 INFO rdd.HadoopRDD: Input split: ShardInputSplit [node=[RYrePPv6SpGV-NOehFoEuw/Natchios, Elektra|127.0.0.1:9200],shard=0]
14/02/25 12:01:19 ERROR mr.EsInputFormat: Cannot determine task id - current properties are {fs.s3n.impl=org.apache.hadoop.fs.s3native.NativeS3FileSystem, mapred.task.cache.levels=2, hadoop.tmp.dir=/tmp/hadoop-${user.name}, hadoop.native.lib=true, map.sort.class=org.apache.hadoop.util.QuickSort, es.internal.mr.target.resource=demo/demo, ipc.client.idlethreshold=4000, mapred.system.dir=${hadoop.tmp.dir}/mapred/system, mapred.job.tracker.persist.jobstatus.hours=0, io.skip.checksum.errors=false, fs.default.name=file:///, mapred.cluster.reduce.memory.mb=-1, mapred.child.tmp=./tmp, fs.har.impl.disable.cache=true, es.internal.es.version=0.90.10, mapred.skip.reduce.max.skip.groups=0, mapred.heartbeats.in.second=100, mapred.tasktracker.dns.nameserver=default, io.sort.factor=10, mapred.task.timeout=600000, mapred.max.tracker.failures=4, hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory, fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem, mapred.job.tracker.jobhistory.lru.cache.size=5, mapred.skip.map.auto.incr.proc.count=true, mapreduce.job.complete.cancel.delegation.tokens=true, io.mapfile.bloom.size=1048576, mapreduce.reduce.shuffle.connect.timeout=180000, mapred.jobtracker.blacklist.fault-timeout-window=180, tasktracker.http.threads=40, mapred.job.shuffle.merge.percent=0.66, fs.ftp.impl=org.apache.hadoop.fs.ftp.FTPFileSystem, io.bytes.per.checksum=512, mapred.output.compress=false, mapred.combine.recordsBeforeProgress=10000, mapred.healthChecker.script.timeout=600000, topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping, mapred.reduce.slowstart.completed.maps=0.05, mapred.reduce.max.attempts=4, es.ser.reader.value.class=org.elasticsearch.hadoop.mr.WritableValueReader, fs.ramfs.impl=org.apache.hadoop.fs.InMemoryFileSystem, mapred.skip.map.max.skip.records=0, mapred.cluster.map.memory.mb=-1, hadoop.security.group.mapping=org.apache.hadoop.security.ShellBasedUnixGroupsMapping, mapred.job.tracker.persist.jobstatus.dir=/jobtracker/jobsInfo, fs.s3.buffer.dir=${hadoop.tmp.dir}/s3, job.end.retry.attempts=0, fs.file.impl=org.apache.hadoop.fs.LocalFileSystem, mapred.local.dir.minspacestart=0, mapred.output.compression.type=RECORD, topology.script.number.args=100, io.mapfile.bloom.error.rate=0.005, mapred.cluster.max.reduce.memory.mb=-1, mapred.max.tracker.blacklists=4, mapred.task.profile.maps=0-2, mapred.userlog.retain.hours=24, mapred.job.tracker.persist.jobstatus.active=false, hadoop.security.authorization=false, local.cache.size=10737418240, mapred.map.tasks=2, mapred.min.split.size=0, mapred.child.java.opts=-Xmx200m, mapreduce.job.counters.limit=120, mapred.job.queue.name=default, mapred.job.tracker.retiredjobs.cache.size=1000, ipc.server.listen.queue.size=128, mapred.inmem.merge.threshold=1000, job.end.retry.interval=30000, mapreduce.tasktracker.outofband.heartbeat.damper=1000000, mapred.skip.attempts.to.start.skipping=2, fs.checkpoint.dir=${hadoop.tmp.dir}/dfs/namesecondary, mapred.reduce.tasks=1, mapred.merge.recordsBeforeProgress=10000, mapred.userlog.limit.kb=0, mapred.job.reduce.memory.mb=-1, webinterface.private.actions=false, hadoop.security.token.service.use_ip=true, io.sort.spill.percent=0.80, mapred.job.shuffle.input.buffer.percent=0.70, mapred.map.tasks.speculative.execution=true, hadoop.util.hash.type=murmur, mapred.map.max.attempts=4, mapreduce.job.acl-view-job= , mapred.job.tracker.handler.count=10, mapreduce.reduce.shuffle.read.timeout=180000, mapred.tasktracker.expiry.interval=600000, mapred.jobtracker.job.history.block.size=3145728, mapred.jobtracker.maxtasks.per.job=-1, keep.failed.task.files=false, ipc.client.tcpnodelay=false, mapred.task.profile.reduces=0-2, mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, io.map.index.skip=0, ipc.server.tcpnodelay=false, mapred.jobtracker.blacklist.fault-bucket-width=15, es.resource=demo/demo, mapred.job.map.memory.mb=-1, hadoop.logfile.size=10000000, mapred.reduce.tasks.speculative.execution=true, mapreduce.tasktracker.outofband.heartbeat=false, mapreduce.reduce.input.limit=-1, hadoop.security.authentication=simple, fs.checkpoint.period=3600, mapred.job.reuse.jvm.num.tasks=1, mapred.jobtracker.completeuserjobs.maximum=100, mapred.task.tracker.task-controller=org.apache.hadoop.mapred.DefaultTaskController, fs.s3.maxRetries=4, mapred.cluster.max.map.memory.mb=-1, mapreduce.reduce.shuffle.maxfetchfailures=10, mapreduce.job.acl-modify-job= , fs.hftp.impl=org.apache.hadoop.hdfs.HftpFileSystem, mapred.local.dir=${hadoop.tmp.dir}/mapred/local, fs.s3.sleepTimeSeconds=10, fs.trash.interval=0, mapred.submit.replication=10, fs.har.impl=org.apache.hadoop.fs.HarFileSystem, mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, mapred.tasktracker.dns.interface=default, mapred.job.tracker=local, io.seqfile.sorter.recordlimit=1000000, mapred.line.input.format.linespermap=1, mapred.jobtracker.taskScheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler, fs.webhdfs.impl=org.apache.hadoop.hdfs.web.WebHdfsFileSystem, mapred.local.dir.minspacekill=0, io.sort.record.percent=0.05, fs.kfs.impl=org.apache.hadoop.fs.kfs.KosmosFileSystem, mapred.temp.dir=${hadoop.tmp.dir}/mapred/temp, mapred.tasktracker.reduce.tasks.maximum=2, fs.checkpoint.edits.dir=${fs.checkpoint.dir}, mapred.tasktracker.tasks.sleeptime-before-sigkill=5000, mapred.job.reduce.input.buffer.percent=0.0, mapred.tasktracker.indexcache.mb=10, es.internal.hosts=, mapreduce.job.split.metainfo.maxsize=10000000, hadoop.logfile.count=10, mapred.skip.reduce.auto.incr.proc.count=true, io.seqfile.compress.blocksize=1000000, fs.s3.block.size=67108864, mapred.tasktracker.taskmemorymanager.monitoring-interval=5000, mapred.acls.enabled=false, mapred.queue.default.state=RUNNING, mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging, mapred.queue.names=default, fs.hsftp.impl=org.apache.hadoop.hdfs.HsftpFileSystem, mapred.task.tracker.http.address=0.0.0.0:50060, mapred.reduce.parallel.copies=5, io.seqfile.lazydecompress=true, io.sort.mb=100, ipc.client.connection.maxidletime=10000, mapred.task.tracker.report.address=127.0.0.1:0, mapred.compress.map.output=false, hadoop.security.uid.cache.secs=14400, mapred.healthChecker.interval=60000, ipc.client.kill.max=10, ipc.client.connect.max.retries=10, fs.s3.impl=org.apache.hadoop.fs.s3.S3FileSystem, mapred.user.jobconf.limit=5242880, mapred.job.tracker.http.address=0.0.0.0:50030, io.file.buffer.size=4096, mapred.jobtracker.restart.recover=false, io.serializations=org.apache.hadoop.io.serializer.WritableSerialization, mapred.task.profile=false, jobclient.output.filter=FAILED, mapred.tasktracker.map.tasks.maximum=2, io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec, fs.checkpoint.size=67108864}
14/02/25 12:01:19 ERROR executor.Executor: Exception in task ID 0
java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker
    at org.elasticsearch.hadoop.util.Assert.notNull(Assert.java:38)
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:57)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/25 12:01:19 INFO scheduler.TaskSetManager: Starting task 0.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/02/25 12:01:19 INFO scheduler.TaskSetManager: Serialized task 0.0:1 as 2714 bytes in 0 ms
14/02/25 12:01:19 INFO executor.Executor: Running task ID 1
14/02/25 12:01:19 WARN scheduler.TaskSetManager: Lost TID 0 (task 0.0:0)
14/02/25 12:01:19 INFO storage.BlockManager: Found block broadcast_0 locally
14/02/25 12:01:19 INFO rdd.HadoopRDD: Input split: ShardInputSplit [node=[RYrePPv6SpGV-NOehFoEuw/Natchios, Elektra|127.0.0.1:9200],shard=1]
14/02/25 12:01:19 ERROR mr.EsInputFormat: Cannot determine task id - current properties are {fs.s3n.impl=org.apache.hadoop.fs.s3native.NativeS3FileSystem, mapred.task.cache.levels=2, hadoop.tmp.dir=/tmp/hadoop-${user.name}, hadoop.native.lib=true, map.sort.class=org.apache.hadoop.util.QuickSort, es.internal.mr.target.resource=demo/demo, ipc.client.idlethreshold=4000, mapred.system.dir=${hadoop.tmp.dir}/mapred/system, mapred.job.tracker.persist.jobstatus.hours=0, io.skip.checksum.errors=false, fs.default.name=file:///, mapred.cluster.reduce.memory.mb=-1, mapred.child.tmp=./tmp, fs.har.impl.disable.cache=true, es.internal.es.version=0.90.10, mapred.skip.reduce.max.skip.groups=0, mapred.heartbeats.in.second=100, mapred.tasktracker.dns.nameserver=default, io.sort.factor=10, mapred.task.timeout=600000, mapred.max.tracker.failures=4, hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory, fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem, mapred.job.tracker.jobhistory.lru.cache.size=5, mapred.skip.map.auto.incr.proc.count=true, mapreduce.job.complete.cancel.delegation.tokens=true, io.mapfile.bloom.size=1048576, mapreduce.reduce.shuffle.connect.timeout=180000, mapred.jobtracker.blacklist.fault-timeout-window=180, tasktracker.http.threads=40, mapred.job.shuffle.merge.percent=0.66, fs.ftp.impl=org.apache.hadoop.fs.ftp.FTPFileSystem, io.bytes.per.checksum=512, mapred.output.compress=false, mapred.combine.recordsBeforeProgress=10000, mapred.healthChecker.script.timeout=600000, topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping, mapred.reduce.slowstart.completed.maps=0.05, mapred.reduce.max.attempts=4, es.ser.reader.value.class=org.elasticsearch.hadoop.mr.WritableValueReader, fs.ramfs.impl=org.apache.hadoop.fs.InMemoryFileSystem, mapred.skip.map.max.skip.records=0, mapred.cluster.map.memory.mb=-1, hadoop.security.group.mapping=org.apache.hadoop.security.ShellBasedUnixGroupsMapping, mapred.job.tracker.persist.jobstatus.dir=/jobtracker/jobsInfo, fs.s3.buffer.dir=${hadoop.tmp.dir}/s3, job.end.retry.attempts=0, fs.file.impl=org.apache.hadoop.fs.LocalFileSystem, mapred.local.dir.minspacestart=0, mapred.output.compression.type=RECORD, topology.script.number.args=100, io.mapfile.bloom.error.rate=0.005, mapred.cluster.max.reduce.memory.mb=-1, mapred.max.tracker.blacklists=4, mapred.task.profile.maps=0-2, mapred.userlog.retain.hours=24, mapred.job.tracker.persist.jobstatus.active=false, hadoop.security.authorization=false, local.cache.size=10737418240, mapred.map.tasks=2, mapred.min.split.size=0, mapred.child.java.opts=-Xmx200m, mapreduce.job.counters.limit=120, mapred.job.queue.name=default, mapred.job.tracker.retiredjobs.cache.size=1000, ipc.server.listen.queue.size=128, mapred.inmem.merge.threshold=1000, job.end.retry.interval=30000, mapreduce.tasktracker.outofband.heartbeat.damper=1000000, mapred.skip.attempts.to.start.skipping=2, fs.checkpoint.dir=${hadoop.tmp.dir}/dfs/namesecondary, mapred.reduce.tasks=1, mapred.merge.recordsBeforeProgress=10000, mapred.userlog.limit.kb=0, mapred.job.reduce.memory.mb=-1, webinterface.private.actions=false, hadoop.security.token.service.use_ip=true, io.sort.spill.percent=0.80, mapred.job.shuffle.input.buffer.percent=0.70, mapred.map.tasks.speculative.execution=true, hadoop.util.hash.type=murmur, mapred.map.max.attempts=4, mapreduce.job.acl-view-job= , mapred.job.tracker.handler.count=10, mapreduce.reduce.shuffle.read.timeout=180000, mapred.tasktracker.expiry.interval=600000, mapred.jobtracker.job.history.block.size=3145728, mapred.jobtracker.maxtasks.per.job=-1, keep.failed.task.files=false, ipc.client.tcpnodelay=false, mapred.task.profile.reduces=0-2, mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, io.map.index.skip=0, ipc.server.tcpnodelay=false, mapred.jobtracker.blacklist.fault-bucket-width=15, es.resource=demo/demo, mapred.job.map.memory.mb=-1, hadoop.logfile.size=10000000, mapred.reduce.tasks.speculative.execution=true, mapreduce.tasktracker.outofband.heartbeat=false, mapreduce.reduce.input.limit=-1, hadoop.security.authentication=simple, fs.checkpoint.period=3600, mapred.job.reuse.jvm.num.tasks=1, mapred.jobtracker.completeuserjobs.maximum=100, mapred.task.tracker.task-controller=org.apache.hadoop.mapred.DefaultTaskController, fs.s3.maxRetries=4, mapred.cluster.max.map.memory.mb=-1, mapreduce.reduce.shuffle.maxfetchfailures=10, mapreduce.job.acl-modify-job= , fs.hftp.impl=org.apache.hadoop.hdfs.HftpFileSystem, mapred.local.dir=${hadoop.tmp.dir}/mapred/local, fs.s3.sleepTimeSeconds=10, fs.trash.interval=0, mapred.submit.replication=10, fs.har.impl=org.apache.hadoop.fs.HarFileSystem, mapred.map.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec, mapred.tasktracker.dns.interface=default, mapred.job.tracker=local, io.seqfile.sorter.recordlimit=1000000, mapred.line.input.format.linespermap=1, mapred.jobtracker.taskScheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler, fs.webhdfs.impl=org.apache.hadoop.hdfs.web.WebHdfsFileSystem, mapred.local.dir.minspacekill=0, io.sort.record.percent=0.05, fs.kfs.impl=org.apache.hadoop.fs.kfs.KosmosFileSystem, mapred.temp.dir=${hadoop.tmp.dir}/mapred/temp, mapred.tasktracker.reduce.tasks.maximum=2, fs.checkpoint.edits.dir=${fs.checkpoint.dir}, mapred.tasktracker.tasks.sleeptime-before-sigkill=5000, mapred.job.reduce.input.buffer.percent=0.0, mapred.tasktracker.indexcache.mb=10, es.internal.hosts=, mapreduce.job.split.metainfo.maxsize=10000000, hadoop.logfile.count=10, mapred.skip.reduce.auto.incr.proc.count=true, io.seqfile.compress.blocksize=1000000, fs.s3.block.size=67108864, mapred.tasktracker.taskmemorymanager.monitoring-interval=5000, mapred.acls.enabled=false, mapred.queue.default.state=RUNNING, mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging, mapred.queue.names=default, fs.hsftp.impl=org.apache.hadoop.hdfs.HsftpFileSystem, mapred.task.tracker.http.address=0.0.0.0:50060, mapred.reduce.parallel.copies=5, io.seqfile.lazydecompress=true, io.sort.mb=100, ipc.client.connection.maxidletime=10000, mapred.task.tracker.report.address=127.0.0.1:0, mapred.compress.map.output=false, hadoop.security.uid.cache.secs=14400, mapred.healthChecker.interval=60000, ipc.client.kill.max=10, ipc.client.connect.max.retries=10, fs.s3.impl=org.apache.hadoop.fs.s3.S3FileSystem, mapred.user.jobconf.limit=5242880, mapred.job.tracker.http.address=0.0.0.0:50030, io.file.buffer.size=4096, mapred.jobtracker.restart.recover=false, io.serializations=org.apache.hadoop.io.serializer.WritableSerialization, mapred.task.profile=false, jobclient.output.filter=FAILED, mapred.tasktracker.map.tasks.maximum=2, io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec, fs.checkpoint.size=67108864}
14/02/25 12:01:19 ERROR executor.Executor: Exception in task ID 1
java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker
    at org.elasticsearch.hadoop.util.Assert.notNull(Assert.java:38)
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:57)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/25 12:01:19 WARN scheduler.TaskSetManager: Loss was due to java.lang.IllegalArgumentException
java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker
    at org.elasticsearch.hadoop.util.Assert.notNull(Assert.java:38)
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:57)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/25 12:01:19 ERROR scheduler.TaskSetManager: Task 0.0:0 failed 1 times; aborting job
14/02/25 12:01:19 INFO scheduler.TaskSchedulerImpl: Remove TaskSet 0.0 from pool
14/02/25 12:01:19 INFO scheduler.TaskSchedulerImpl: Ignoring update with state RUNNING from TID 1 because its task set is gone
14/02/25 12:01:19 INFO scheduler.TaskSchedulerImpl: Ignoring update with state FAILED from TID 1 because its task set is gone
14/02/25 12:01:19 INFO scheduler.DAGScheduler: Failed to run foreach at SimpleApp.scala:18
[error] (run-main) org.apache.spark.SparkException: Job aborted: Task 0.0:0 failed 1 times (most recent failure: Exception failure: java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker)
org.apache.spark.SparkException: Job aborted: Task 0.0:0 failed 1 times (most recent failure: Exception failure: java.lang.IllegalArgumentException: Unable to determine task id - please report your distro/setting through the issue tracker)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$abortStage$1.apply(DAGScheduler.scala:1028)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$abortStage$1.apply(DAGScheduler.scala:1026)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$abortStage(DAGScheduler.scala:1026)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$processEvent$10.apply(DAGScheduler.scala:619)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$processEvent$10.apply(DAGScheduler.scala:619)
    at scala.Option.foreach(Option.scala:236)
    at org.apache.spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:619)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$start$1$$anon$2$$anonfun$receive$1.applyOrElse(DAGScheduler.scala:207)
    at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
    at akka.actor.ActorCell.invoke(ActorCell.scala:456)
    at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
    at akka.dispatch.Mailbox.run(Mailbox.scala:219)
    at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
[trace] Stack trace suppressed: run last compile:run for the full output.
14/02/25 12:01:19 INFO network.ConnectionManager: Selector thread was interrupted!
java.lang.RuntimeException: Nonzero exit code: 1
    at scala.sys.package$.error(package.scala:27)
[trace] Stack trace suppressed: run last compile:run for the full output.
[error] (compile:run) Nonzero exit code: 1
[error] Total time: 3 s, completed Feb 25, 2014 12:01:19 PM
```
","Can you please check it out?
","Checked it out and it works! Nice
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/148,"Not sure if I am missing something but I thought this error might be upstream. Here is how to repeat.
### _build.sbt_

``` scala
name := ""elasticsearch-spark-example""

version := ""1.0""

scalaVersion := ""2.10.3""

libraryDependencies ++= Seq(
  ""org.apache.spark""  %% ""spark-core"" % ""0.9.0-incubating"",
  ""org.elasticsearch""  % ""elasticsearch-hadoop"" % ""1.3.0.BUILD-SNAPSHOT""
)

resolvers ++= Seq(
  ""Typesafe Sonatype Snapshots"" at ""http://typesafe.artifactoryonline.com/typesafe/sonatype-snapshots/"",
  ""Sonatype OSS"" at ""http://oss.sonatype.org/content/repositories/snapshots/"",
  ""Akka Repository"" at ""http://repo.akka.io/releases/"",
  ""Conjars"" at ""http://conjars.org/repo""
)
```
### SimpleApp.scala

``` scala
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.hadoop.mapred.JobConf
import org.elasticsearch.hadoop.mr.EsInputFormat


object SimpleApp {
  def main(args: Array[String]) {
    val conf = new JobConf()
    conf.set(""es.resource"", ""demo/demo"")

    val sc = new SparkContext(""local"", ""Simple App"")

    val data = sc.hadoopRDD(conf, classOf[EsInputFormat[String,String]], classOf[String], classOf[String], 6)

    data foreach println
  }
}
```

Here's the stacktrace

```
$ sbt run
[info] Loading project definition from /Users/rbraley/IdeaProjects/elasticsearch-spark-example/project
[info] Set current project to elasticsearch-spark-example (in build file:/Users/rbraley/IdeaProjects/elasticsearch-spark-example/)
[info] Updating {file:/Users/rbraley/IdeaProjects/elasticsearch-spark-example/}elasticsearch-spark-example...
[info] Resolving org.fusesource.jansi#jansi;1.4 ...
[info] Done updating.
[info] Running io.traintracks.elasticsearch.spark.example.SimpleApp
14/02/24 17:28:00 INFO slf4j.Slf4jLogger: Slf4jLogger started
14/02/24 17:28:00 INFO Remoting: Starting remoting
14/02/24 17:28:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@192.168.2.88:61423]
14/02/24 17:28:00 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@192.168.2.88:61423]
14/02/24 17:28:00 INFO spark.SparkEnv: Registering BlockManagerMaster
14/02/24 17:28:00 INFO storage.DiskBlockManager: Created local directory at /var/folders/rn/p2d7mh016b34qvm47jybmg380000gn/T/spark-local-20140224172800-6e2d
14/02/24 17:28:00 INFO storage.MemoryStore: MemoryStore started with capacity 890.9 MB.
14/02/24 17:28:00 INFO network.ConnectionManager: Bound socket to port 61424 with id = ConnectionManagerId(192.168.2.88,61424)
14/02/24 17:28:00 INFO storage.BlockManagerMaster: Trying to register BlockManager
14/02/24 17:28:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager 192.168.2.88:61424 with 890.9 MB RAM
14/02/24 17:28:00 INFO storage.BlockManagerMaster: Registered BlockManager
14/02/24 17:28:00 INFO spark.HttpServer: Starting HTTP Server
14/02/24 17:28:00 INFO server.Server: jetty-7.6.8.v20121106
14/02/24 17:28:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:61425
14/02/24 17:28:00 INFO broadcast.HttpBroadcast: Broadcast server started at http://192.168.2.88:61425
14/02/24 17:28:00 INFO spark.SparkEnv: Registering MapOutputTracker
14/02/24 17:28:00 INFO spark.HttpFileServer: HTTP File server directory is /var/folders/rn/p2d7mh016b34qvm47jybmg380000gn/T/spark-bec0c9ef-0032-4894-a4cb-25da4a33e0b0
14/02/24 17:28:00 INFO spark.HttpServer: Starting HTTP Server
14/02/24 17:28:00 INFO server.Server: jetty-7.6.8.v20121106
14/02/24 17:28:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:61426
14/02/24 17:28:01 INFO server.Server: jetty-7.6.8.v20121106
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/pool,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/metrics/json,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
14/02/24 17:28:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
14/02/24 17:28:01 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
14/02/24 17:28:01 INFO ui.SparkUI: Started Spark Web UI at http://192.168.2.88:4040
2014-02-24 17:28:01.361 java[80822:6313] Unable to load realm info from SCDynamicStore
14/02/24 17:28:01 INFO storage.MemoryStore: ensureFreeSpace(32969) called with curMem=0, maxMem=934163251
14/02/24 17:28:01 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 32.2 KB, free 890.9 MB)
14/02/24 17:28:01 INFO mr.EsInputFormat: Discovered mapping {demo=[test=STRING]} for [demo/demo]
14/02/24 17:28:01 INFO mr.EsInputFormat: Created [5] shard-splits
14/02/24 17:28:01 INFO spark.SparkContext: Starting job: foreach at SimpleApp.scala:18
14/02/24 17:28:01 INFO scheduler.DAGScheduler: Got job 0 (foreach at SimpleApp.scala:18) with 5 output partitions (allowLocal=false)
14/02/24 17:28:01 INFO scheduler.DAGScheduler: Final stage: Stage 0 (foreach at SimpleApp.scala:18)
14/02/24 17:28:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
14/02/24 17:28:01 INFO scheduler.DAGScheduler: Missing parents: List()
14/02/24 17:28:01 INFO scheduler.DAGScheduler: Submitting Stage 0 (HadoopRDD[0] at hadoopRDD at SimpleApp.scala:16), which has no missing parents
14/02/24 17:28:01 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from Stage 0 (HadoopRDD[0] at hadoopRDD at SimpleApp.scala:16)
14/02/24 17:28:01 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
14/02/24 17:28:01 INFO scheduler.TaskSetManager: Starting task 0.0:0 as TID 0 on executor localhost: localhost (PROCESS_LOCAL)
14/02/24 17:28:01 INFO scheduler.TaskSetManager: Serialized task 0.0:0 as 2705 bytes in 5 ms
14/02/24 17:28:01 INFO executor.Executor: Running task ID 0
14/02/24 17:28:01 INFO storage.BlockManager: Found block broadcast_0 locally
14/02/24 17:28:01 INFO rdd.HadoopRDD: Input split: ShardInputSplit [node=[tXu2eOa5SsS3xwBId-m81A/Magnum I|127.0.0.1:9200],shard=0]
14/02/24 17:28:01 ERROR executor.Executor: Exception in task ID 0
java.lang.NullPointerException
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:51)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/24 17:28:01 INFO scheduler.TaskSetManager: Starting task 0.0:1 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/02/24 17:28:01 INFO scheduler.TaskSetManager: Serialized task 0.0:1 as 2705 bytes in 0 ms
14/02/24 17:28:01 INFO executor.Executor: Running task ID 1
14/02/24 17:28:01 WARN scheduler.TaskSetManager: Lost TID 0 (task 0.0:0)
14/02/24 17:28:01 INFO storage.BlockManager: Found block broadcast_0 locally
14/02/24 17:28:01 INFO rdd.HadoopRDD: Input split: ShardInputSplit [node=[tXu2eOa5SsS3xwBId-m81A/Magnum I|127.0.0.1:9200],shard=1]
14/02/24 17:28:01 ERROR executor.Executor: Exception in task ID 1
java.lang.NullPointerException
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:51)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/24 17:28:01 WARN scheduler.TaskSetManager: Loss was due to java.lang.NullPointerException
java.lang.NullPointerException
    at org.elasticsearch.hadoop.mr.HeartBeat.<init>(HeartBeat.java:51)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.init(EsInputFormat.java:204)
    at org.elasticsearch.hadoop.mr.EsInputFormat$ShardRecordReader.<init>(EsInputFormat.java:167)
    at org.elasticsearch.hadoop.mr.EsInputFormat$WritableShardRecordReader.<init>(EsInputFormat.java:328)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:449)
    at org.elasticsearch.hadoop.mr.EsInputFormat.getRecordReader(EsInputFormat.java:66)
    at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:156)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
    at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)
    at org.apache.spark.scheduler.Task.run(Task.scala:53)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
    at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)
14/02/24 17:28:01 ERROR scheduler.TaskSetManager: Task 0.0:0 failed 1 times; aborting job
14/02/24 17:28:01 INFO scheduler.TaskSchedulerImpl: Remove TaskSet 0.0 from pool
14/02/24 17:28:01 INFO scheduler.TaskSchedulerImpl: Ignoring update with state RUNNING from TID 1 because its task set is gone
14/02/24 17:28:01 INFO scheduler.TaskSchedulerImpl: Ignoring update with state FAILED from TID 1 because its task set is gone
14/02/24 17:28:01 INFO scheduler.DAGScheduler: Failed to run foreach at SimpleApp.scala:18
[error] (run-main) org.apache.spark.SparkException: Job aborted: Task 0.0:0 failed 1 times (most recent failure: Exception failure: java.lang.NullPointerException)
org.apache.spark.SparkException: Job aborted: Task 0.0:0 failed 1 times (most recent failure: Exception failure: java.lang.NullPointerException)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$abortStage$1.apply(DAGScheduler.scala:1028)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$abortStage$1.apply(DAGScheduler.scala:1026)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$abortStage(DAGScheduler.scala:1026)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$processEvent$10.apply(DAGScheduler.scala:619)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$processEvent$10.apply(DAGScheduler.scala:619)
    at scala.Option.foreach(Option.scala:236)
    at org.apache.spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:619)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$start$1$$anon$2$$anonfun$receive$1.applyOrElse(DAGScheduler.scala:207)
    at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
    at akka.actor.ActorCell.invoke(ActorCell.scala:456)
    at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
    at akka.dispatch.Mailbox.run(Mailbox.scala:219)
    at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
[trace] Stack trace suppressed: run last compile:run for the full output.
14/02/24 17:28:02 INFO network.ConnectionManager: Selector thread was interrupted!
java.lang.RuntimeException: Nonzero exit code: 1
    at scala.sys.package$.error(package.scala:27)
[trace] Stack trace suppressed: run last compile:run for the full output.
[error] (compile:run) Nonzero exit code: 1
[error] Total time: 10 s, completed Feb 24, 2014 5:28:02 PM
```
","Can you please post/upload the properties somewhere so I can take a better look at them?

Thanks.
",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/138,"Im encountering strange behaviour when I write into elasticsearch from hive using the current master branch of es-hadoop.

I have one es-server running on the default port 9200, and another on port 9800.
When I define the hive external Table like this:

``` sql
CREATE EXTERNAL TABLE andy.test_with_es_port (
    id STRING,
    virt_cat BIGINT)
STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'
TBLPROPERTIES('es.resource' = 'testing/reco',
              'es.nodes'='localhost',
              'es.port'='9800',
              'es.nodes.discovery' = 'false');

INSERT OVERWRITE TABLE andy.test_with_es_port
SELECT 
    id,
    virt_cat
from andy.test_data limit 10;
```

Then the following happens. 
1. The 'testing' index is created on both(!) servers.
2. The 'testing' index on the default port contains data. (it shouldnt be here at all)
3. The 'testing' index on port 9800 is empty (this is where i expected the data to land in).

If I do another test and not use es.port, but instead define the port in the es.nodes string:

``` sql
CREATE EXTERNAL TABLE andy.test_with_port_string (
    id STRING,
    virt_cat BIGINT,
    keyword STRING,
    recommended_products ARRAY<BIGINT>)
STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'
TBLPROPERTIES('es.resource' = 'testing/reco',
              'es.nodes'='localhost:9800',
              'es.nodes.discovery' = 'false');

INSERT OVERWRITE TABLE andy.test_with_port_string
SELECT 
    id,
    virt_cat
from andy.test_data limit 10;
```

Then es-hadoop works as expected, writing only to the server on port 9800 (with data)
and not to the server on the default port.
","Can you please enable logging on the mr (`org.elasticsearch.hadoop.mr`) and network (`org.elasticsearch.hadoop.rest`) package and post somewhere the logs?
After that can you please try the master - I've added a small fix which might address your issue (but since I couldn't reproduce it, I can't tell for sure)?

Thanks!
",
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/130,"Until now elasticsearch-hadoop uses the fields parameter in the query to elasticsearch to choose the fields used in the columns (or the aliases thereof). this worked fine until elasticsearch 1.0.0. beta2, but stopped working for elasticsearch 1.0.0rc1 when using fields that had a nested structure (I am not talking about nested mapping, i realize that is not supported yet).  this causes an exception (ElasticsearchIllegalArgumentException[field [categories] isn't a leaf field]}) if categories is a map or any other kind of nested structure. to solve this problem, it makes sense to use the _source parameter instead. I am creating a pull request that solves the problem for me (hive only) but am not sure if it is feature complete, more of an example for you to look at.
","Can you post an example (Es mapping and Hive table)?
","Here is a simplified form. examples document (using all default mapping, no mapping defined by me):
{
    ""id"": 1230912,
    ""min_price"": 10,
    ""name"": ""bla"",
    ""categories"": {
        ""0"": [
            [
                1,
                720,
                758,
                781
            ],
            [
                2,
                3,
                4
            ]
        ],
        ""1"": [
            [
                284
            ]
        ]
    },
    ""default_variant"": {
        ""attributes"": {
            ""attributes_1"": [
                49,
                53
            ]
        }
    }
}

and the hive table:

CREATE EXTERNAL TABLE external_sources.elastic_search_products(
    product_id BIGINT,
    min_price BIGINT,
    name STRING,
    virtual_categories MAP<STRING,ARRAY<ARRAY<INT>>>,
    default_variant MAP<STRING,MAP<STRING,ARRAY<INT>>>)
STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'
TBLPROPERTIES('es.resource' = 'searching/product/_search?q=*',
              'es.nodes'='my_ip_address',
              'es.port'='9200',
              'es.nodes.discovery' = 'false',
              'es.mapping.names' = 'virtual_categories:categories,product_id:id,default_variant:default_variant.attributes.attributes_1');
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/118,"hive> select \* from user;
OK
Failed with exception java.io.IOException:java.lang.IllegalStateException: [GET] on [/index/user/&search_type=scan&scroll=10m&size=50&preference=_shards:4;_only_node:MP7Zl3owTRm8O2V6cWvOSg] failed; server[http://10.0.2.15:9200] returned [{""_index"":""index"",""_type"":""user"",""_id"":""&search_type=scan&scroll=10m&size=50&preference=_shards:4;_only_node:MP7Zl3owTRm8O2V6cWvOSg"",""exists"":false}]
Time taken: 0.387 seconds

as you can see:
&search_type should be ?search_type
","What is your table definition?
The query is indeed incorrect but I'm unable to reproduce this problem with the current code as a valid query (even if one is not specified) is always used.
","FYI:

downloaded from:
https://download.elasticsearch.org/hadoop/hadoop-latest.zip

hive script:

hive> CREATE EXTERNAL TABLE user  (id INT, name STRING)     > STORED BY 'org.elasticsearch.hadoop.hive.ESStorageHandler'     > TBLPROPERTIES('es.resource' = '/index/user/',     >               'es.index.auto.create' = 'true');

hive> CREATE TABLE user_source  (id INT, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','; 
hive> LOAD DATA LOCAL INPATH '/tmp/files1.txt' INTO TABLE user_source;  
hive> INSERT OVERWRITE TABLE user     >     SELECT s.id, s.name FROM user_source s;

ES:
bash-4.1$ curl localhost:9200/index/user/_search?q=*&pretty=true [1] 13588 bash-4.1$ {""took"":3,""timed_out"":false,""_shards"":{""total"":5,""successful"":5,""failed"":0},""hits"":{""total"":4,""max_score"":1.0,""hits"":[{""_index"":""index"",""_type"":""user"",""_id"":""3x4bEcriRvS6AHkX2Sb7UA"",""_score"":1.0, ""_source"" : {""id"":2,""name"":""lcdem""}},{""_index"":""index"",""_type"":""user"",""_id"":""_3rGVWhaTSCixYxRzBUSLQ"",""_score"":1.0, ""_source"" : {""id"":4,""name"":""jack""}},{""_index"":""index"",""_type"":""user"",""_id"":""T-Q_icjgR8ehsH3IV-twWw"",""_score"":1.0, ""_source"" : {""id"":1,""name"":""medcl""}},{""_index"":""index"",""_type"":""user"",""_id"":""Vdz0sryBT5u0e9hfoMY8Tg"",""_score"":1.0, ""_source"" : {""id"":3,""name"":""tom""}}]}}

---

## Medcl'

http://log.medcl.net

------------------ Original ------------------
From: ""Costin Leau""; 
Date: 2013Äê12ÔÂ18ÈÕ(ÐÇÆÚÈý) Áè³¿1:02
To: ""elasticsearch/elasticsearch-hadoop""; 
Cc: ""Medcl'""; 
Subject: Re: [elasticsearch-hadoop] wrong query generated by hive (#118)

Are you using the latest master or not? What is your table definition?
 The query is indeed incorrect but I'm unable to reproduce this problem with the current code as a valid query (even if one is not specified) is always used.

¡ª
Reply to this email directly or view it on GitHub.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/116,"If the date data in ES format is 2013-12-01 12:12:12.876 will report an error.

Read through the hive when reporting format error
","Can you be more specific? Is format you mention in ES or Hive?  What's the
date format in ES? Also what version of Hive are you using and what is your
column definition? Can you also paste the stacktrace/error you are getting?

Thanks

Costin

Sent on the run
On Dec 10, 2013 8:42 AM, ""董明"" notifications@github.com wrote:

> If the date data in ES format is 2013-12-01 12:12:12.876 will report an
> error.
> 
> Read through the hive when reporting format error
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/elasticsearch/elasticsearch-hadoop/issues/116
> .
","in class :org.elasticsearch.hadoop.hive.HiveValueReader   , date() Method，
I modified the code below, can solve this problem

```
@Override
protected Object date(String value) {
    long time = 0;
    if (value != null && !"""".equals(value)) {
        if (value.indexOf("" "") == 10 && value.indexOf(""."") == 19) {
            try {
                time = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss.sss"").parse(value).getTime();
            } catch (ParseException e) {
                e.printStackTrace();
                time = DatatypeConverter.parseDateTime(value).getTimeInMillis();
            }
        } else {
            time = DatatypeConverter.parseDateTime(value).getTimeInMillis();
        }
    }

    return new TimestampWritable(new Timestamp(time));
}
```
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/90,"Depending on the data being sent, an empty payload might be sent to ES which can result in the following error:

```
> 2013-10-02 18:08:09,001 [Thread-6] WARN  org.apache.hadoop.mapred.LocalJobRunner - job_local278308746_0001
> java.lang.IllegalStateException: [POST] on [wikipedia/terms/_bulk] failed; server[http://localhost:9200] returned 
> [{""error"":""ActionRequestValidationException[Validation Failed: 1: no requests added;]"",""status"":500}]
> at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:178)
> at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:165)
> at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:95)
> at org.elasticsearch.hadoop.rest.BufferedRestClient.flushBatch(BufferedRestClient.java:192)
> at org.elasticsearch.hadoop.rest.BufferedRestClient.close(BufferedRestClient.java:202)
> at org.elasticsearch.hadoop.mr.ESOutputFormat$ESRecordWriter.close(ESOutputFormat.java:148)
> at org.elasticsearch.hadoop.mr.ESOutputFormat$ESRecordWriter.close(ESOutputFormat.java:140)
```
","What is the limit on document size?
","How big is your document and your terms? Can you also post your exception as the ESStorage should not crash but throw a 
controlled exception instead?
Note that from the es-hadoop side we don't impose any limits except for the bulk write which are configurable are mapped 
after ES - see this page [1].

Thanks,

[1] http://www.elasticsearch.org/guide/en/elasticsearch/hadoop/current/configuration.html

On 03/10/2013 12:57 PM, Willem Robert van Hage wrote:

> I've discovered this occurs when inserting a very large document. Very large terms also make the ESStorage crash, but
> with an array out of bounds exception. The limit on term length seems to be 256 bytes. What is the limit on document size?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/elasticsearch/elasticsearch-hadoop/issues/90#issuecomment-25610008.

## 

Costin
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/84,"Hi  everyone

While inserting data into elasticsearch from Hive I have around this weid bug where elasticsearch columns all end up being called _col0 ..._colN 

In my earlier tests I don't remember this happening.

My test table and insert are:

CREATE EXTERNAL TABLE es_mock_write (
    user STRING,  
    session STRING,  
    medium_source STRING)
STORED BY 'org.elasticsearch.hadoop.hive.ESStorageHandler'
TBLPROPERTIES('es.resource' = 'dmp_demo/db_demo/','es.host'='esaddr');

INSERT OVERWRITE TABLE es_mock_write select 
    userid,
       concat_ws(""|"",collect_set(session) ) ,
       concat_ws(""|"",collect_set(concat(medium,'/',source))) 
 FROM mock.mock_events
","Did you set an explicit ES schema?
Also, I would try using column aliases in the INSERT statement (userid AS userid, ...).
","Hello

I have tried a couple of things, recreating different indexes and tables a new.
using column aliases
nothing seems to do the trick I still have _col0 ..._colN in the resulting ES index.
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/82,"Hello

I have had this problem previously and took the latest master to benefit from the bug fix.
It seems to have reappeared in a new form and this time my concat work around does not work any more:

my table only has strings:
CREATE EXTERNAL TABLE test (
user String)
STORED BY 'org.elasticsearch.hadoop.hive.ESStorageHandler'
TBLPROPERTIES('es.resource' = 'test/test/','es.host'='localhost')

and the insert
INSERT OVERWRITE TABLE test select 
  visitorid
 FROM events

my error
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to org.apache.hadoop.io.Text
    at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector.getPrimitiveWritableObject(WritableStringObjectInspector.java:40)
    at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector.getPrimitiveWritableObject(WritableStringObjectInspector.java:25)
    at org.elasticsearch.hadoop.hive.HiveValueWriter.write(HiveValueWriter.java:85)
    at org.elasticsearch.hadoop.hive.HiveValueWriter.write(HiveValueWriter.java:180)
    at org.elasticsearch.hadoop.hive.HiveValueWriter.write(HiveValueWriter.java:62)
    at org.elasticsearch.hadoop.hive.HiveValueWriter.write(HiveValueWriter.java:44)
    at org.elasticsearch.hadoop.serialization.ContentBuilder.value(ContentBuilder.java:251)
    at org.elasticsearch.hadoop.hive.ESSerDe.serialize(ESSerDe.java:101)
    at org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:586)
    at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:474) 
","Can you post an example on your table definitions? I have tried replicating this locally but the tests pass just fine. As a work around can you try and move your data from the external table to a normal hive table and then to the ES table?
I'll take a closer look at the SerDe to try to figure out what causes the issue.
","hi costin 

my table definition:
create external table mytable(
user String,
name String,
PARTITIONED BY (year INT, month INT, day INT)
row format serde 'com.bizo.hive.serde.csv.CSVSerde'
 with serdeproperties (
   ""separatorChar"" = ""\t"",
   ""quoteChar""     = ""`""
  )

I'll try with a normal hive table.
But I do think the issue comes from the Serde, in this case the csv serde.
thanks for the help 
"
elastic/elasticsearch-hadoop,https://github.com/elastic/elasticsearch-hadoop/issues/58,"I using Hive with ES and when a field named with sensitive chars in hive these fields doesn't work.

ES:
{""user"": {""name"": ""Joseph"", ""countryId"":""US""}}

Hive:
select \* from  user;
Returns:
Joseph  NULL
","What is your mapping in ES vs Hive? Can't you get around it (for now) by using an intermediate Hive table and then copying things over?
",
facebook/stetho,https://github.com/facebook/stetho/issues/466,"I have configed following useage.It can show viewtrees,but others does not show anyway!",Can you give more information on what you expect to see?,"I want to see database,sharepreference data and so on,but I just see viewtrees!"
facebook/stetho,https://github.com/facebook/stetho/issues/84,"When using Stetho to inspect database it seems it tries to change the journal mode of the database.

My app force writeAhead and keep a connection to the db the whole time so this generate logcat errors :

```
03-10 20:00:38.057    6477-7353/xxx E/SQLiteLog﹕ (5) statement aborts at 2: [PRAGMA journal_mode=PERSIST]
03-10 20:00:38.057    6477-7353/xxx W/SQLiteConnection﹕ Could not change the database journal mode of '/data/data/xxx/databases/xxx.db' from 'wal' to 'PERSIST' because the database is locked.  This usually means that there are other open connections to the database which prevents the database from enabling or disabling write-ahead logging mode.  Proceeding without changing the journal mode.
03-10 20:00:39.088    6477-7353/xxx E/SQLiteLog﹕ (5) statement aborts at 2: [PRAGMA journal_mode=PERSIST]
03-10 20:00:39.088    6477-7353/xxx W/SQLiteConnection﹕ Could not change the database journal mode of '/data/data/xxx/databases/xxx.db' from 'wal' to 'PERSIST' because the database is locked.  This usually means that there are other open connections to the database which prevents the database from enabling or disabling write-ahead logging mode.  Proceeding without changing the journal mode.
```

Is there a reason for that ? What are the impacts of the changes failing ?
And if you are just trying to activate writeAhead as the error suggest maybe just check before if it's not the case ?
","Maybe it works to just check for a `-wal` file? :)
","Well this sounds more complex indeed and in the end is not error prone due to concurrency issues :(

I suppose locks would prevents database corruption and just throws errors in Stetho.

Maybe for applications that needs to keep database opens add a callback in the instance builder to ask the application for the SQLiteConnection or whatever Stetho needs on target database ?
"
facebook/stetho,https://github.com/facebook/stetho/issues/59,"When I included this jar in my project, okhttp would crash when used with what looked like a proguard related issue.

I  get the following error

Caused by: java.lang.NoSuchFieldError: No static field METHODS of type Ljava/util/Set; in class Lcom/squareup/okhttp/internal/http/HttpMethod; or its superclasses (declaration of 'com.squareup.okhttp.internal.http.HttpMethod' appears in /data/app/shiftgig.com.worknow-2/base.apk

i've tried whitelisting that file in proguard to no avail. 
","Can you provide your proguard configuration?  I'm trying to repro locally and am so far unable to.  Not sure what's going on here or why adding Stetho would cause it.
",
facebook/facebook-java-business-sdk,https://github.com/facebook/facebook-java-business-sdk/issues/52,"0.4.0  AdsInsights can not get  all breakdown data ""age"",""country"",""gender"",""impression_device"" and other.
","Why these field are removed in 0.4.0?

At lease, we need method getField(String name) to do this()
",
facebook/fresco,https://github.com/facebook/fresco/issues/2293,"### Description
Hello, I've found a problem with scaling up images with Fresco with rounding params in Android 9.0.

When image is small and it need to be scaled up to fill View (with CENTER_CROP ScaleType for example) it displays with artifacts. Looks like pixels are not interpolated to fill the view, but scaled separately and image looks pixelated

At the screenshot: top picture looks as expected, and the bottom one (with rounding) pixelated
![screenshot_20190226-150018_my application](https://user-images.githubusercontent.com/2329931/53411821-9c544b80-39d8-11e9-8399-80c2cb01266b.jpg)

### Reproduction
run code on Android 9 device (reprodused on Samsung Galaxy S 9 and Pixel 2)
```
public class MainActivity extends AppCompatActivity {

    private static final String SMALL_IMAGE_URL = ""https://www.dropbox.com/s/5mxb5a2mae773c9/small.jpg?dl=1"";

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        Fresco.initialize(this);

        LinearLayout root = new LinearLayout(this);

        root.setOrientation(LinearLayout.VERTICAL);
        root.setLayoutParams(new ViewGroup.LayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.MATCH_PARENT));

        //first view without rounding
        SimpleDraweeView firstImage = new SimpleDraweeView(this);
        firstImage.setImageURI(SMALL_IMAGE_URL);
        firstImage.getHierarchy().setActualImageScaleType(ScalingUtils.ScaleType.CENTER_CROP);
        root.addView(firstImage, paramsForImage());

        //same view, but with rounding
        SimpleDraweeView secondImage = new SimpleDraweeView(this);
        secondImage.setImageURI(SMALL_IMAGE_URL);
        secondImage.getHierarchy().setActualImageScaleType(ScalingUtils.ScaleType.CENTER_CROP);
        secondImage.getHierarchy().setRoundingParams(RoundingParams.fromCornersRadius(24));
        root.addView(secondImage, paramsForImage());

        setContentView(root);
    }

    private LinearLayout.LayoutParams paramsForImage() {
        LinearLayout.LayoutParams result = new LinearLayout.LayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.MATCH_PARENT);
        result.weight = 1;
        return result;
    }

}
```

### Additional Information
May be BitmapShader, which is used for rounding, works unexpected at Android 9.0
Rounding with overlay color works fine

* Fresco version: 1.12.1
* Platform version: Android 9.0
","Do you need this for fully circular images or just for rounded corners @dmitrychistyakov ? As a workaround, if it's fully circular, you can use a BitmapTransformation that uses the native rounding filter instead, which is much more performant. ","@oprisnik I use both rounding corners and circle rounding. Thank you for BitmapTransformation hint, I'll try it"
facebook/fresco,https://github.com/facebook/fresco/issues/2278,"when i load a large gif in demo app decoder with movie decoder ,it doesn't work，the picture looks blurry.native decoder is work.
This is url(https://img2.tapimg.com/album/etag/FqOcaqDH1kQ16BuYuDinyhQkV_io.jpg?imageView2/2/w/984/interlace/1/ignore-error/1)
![screenshot_20190122-170505_fresco showcase](https://user-images.githubusercontent.com/17633836/51524485-1d17a900-1e69-11e9-922b-79a10114088b.jpg)
![screenshot_20190122-170449_fresco showcase](https://user-images.githubusercontent.com/17633836/51524491-230d8a00-1e69-11e9-8ae6-a038df894376.jpg)




* Fresco version: [1.11.0]
* Platform version: [28]
","Can you post the GIF somewhere else @didixyy ? I always get a ""403 Forbidden"".","> Can you post the GIF somewhere else @didixyy ? I always get a ""403 Forbidden"".
ok,  i upload the gif in the google 
https://photos.google.com/share/AF1QipNCPNAHcDh3ZzonQ5ushrZIZ-KCspAnq5BzkDtZlZVdf6td8EsFGHJCHOy_UBrqeQ/photo/AF1QipOlN3K_EY54oX1lCJIqVyClhRYJaFB_5ZuNGwHB?key=OThlczZQZndYV3E0ZW96RE93UUlyTHV0RV8xVDFR"
facebook/fresco,https://github.com/facebook/fresco/issues/2253,"### Description

When launching an Activity that uses Fresco, which has been generated via [Android App Bundle](https://developer.android.com/platform/technology/app-bundle/), it fails to find ""libimagepipeline.so"" and crashes the application.

### Reproduction

1. Create a sample application that uses Fresco
2. Generate a signed Bundle
3. Using [Bundle Tool](https://github.com/google/bundletool) build the APKs from the Bundle
4. Using Bundle Tool, install the APK on to your device
5. Navigate to Activity where Fresco is initialised
6. Observe crash

### Solution

I originally thought this might have been an issue with minify, R8, or Proguard, but I disabled all of those, and still observed the same result when building via App Bundle.

I have tested other components of my app that also use native libraries, but they all operate as expected, only with Fresco struggling to load the respective binary.

A temporary, but not ideal solution I found is disabling splitting of APK's by `abi` using the following configuration, but including all the binaries results in a significantly larger APK size.

```
android {
    // Rest of your configuration here
    
    bundle {
        abi {
            enableSplit false
        }
    }
}
```

### Additional Information

* Fresco version: 1.10.0
* Platform version: Samsung SM-G955F, Android 8.0.0",Does your error message looks like this one? [#2049](https://github.com/facebook/fresco/issues/2049),"Yes, roughly. However this issue while related I think more focuses on the
lack of support for Android App Bundle in either Fresco or SoLoader and
splitting binaries that way.

I could be mistaken, but this issue is reproducible on every device I've
tested, not just select brands.

And as per Fresco shipping guides, there is no note of the use case of
shipping via Android App Bundles, and we can't use the `splits` key as when
you use `bundle` the `splits` key is ignored.

On Tue, 11 Dec 2018, 06:40 KimiChiu, <notifications@github.com> wrote:

> Does your error message looks like this one? #2049
> <https://github.com/facebook/fresco/issues/2049>
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/facebook/fresco/issues/2253#issuecomment-446089907>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABUQnQ4cZ-sWkG5b72Ea81wiQjS02yjlks5u31NxgaJpZM4ZIsuf>
> .
>
"
facebook/fresco,https://github.com/facebook/fresco/issues/2249,"i'm getting this error everytime trying to build the samples! 

<img width=""1920"" alt=""screen shot 2018-11-30 at 10 40 12 pm"" src=""https://user-images.githubusercontent.com/19984252/49316757-a5796d80-f4fa-11e8-92a5-87d070e9712f.png"">

-------
stacktrace: 
```
2018-12-01 22:08:48.628 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:08:52.668 1670-1687/? E/BatteryStatsService: modem info is invalid: ModemActivityInfo{ mTimestamp=0 mSleepTimeMs=0 mIdleTimeMs=0 mTxTimeMs[]=[0, 0, 0, 0, 0] mRxTimeMs=0 mEnergyUsed=0}
2018-12-01 22:08:53.667 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:15:41.736 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:15:45.466 1670-1687/? E/BatteryStatsService: modem info is invalid: ModemActivityInfo{ mTimestamp=0 mSleepTimeMs=0 mIdleTimeMs=0 mTxTimeMs[]=[0, 0, 0, 0, 0] mRxTimeMs=0 mEnergyUsed=0}
2018-12-01 22:15:46.770 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:17:17.424 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:17:22.457 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:18:32.982 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:18:38.019 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
    
    --------- beginning of main
2018-12-01 22:22:00.002 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:22:00.021 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:22:00.033 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:22:00.042 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:22:00.055 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:23:00.003 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:23:00.026 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:23:00.040 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:23:00.049 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:24:00.004 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:24:20.542 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:24:20.643 1670-1687/? E/BluetoothAdapter: Bluetooth binder is null
2018-12-01 22:24:20.646 1670-1687/? E/KernelCpuSpeedReader: Failed to read cpu-freq: /sys/devices/system/cpu/cpu0/cpufreq/stats/time_in_state (No such file or directory)
2018-12-01 22:24:20.648 1670-1687/? E/BatteryStatsService: modem info is invalid: ModemActivityInfo{ mTimestamp=0 mSleepTimeMs=0 mIdleTimeMs=0 mTxTimeMs[]=[0, 0, 0, 0, 0] mRxTimeMs=0 mEnergyUsed=0}
2018-12-01 22:24:25.575 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:24:30.602 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:24:36.048 7721-6167/? E/WakeLock: GCM_HB_ALARM release without a matched acquire!
2018-12-01 22:25:00.007 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:25:00.800 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:25:03.644 1670-1687/? E/BatteryStatsService: modem info is invalid: ModemActivityInfo{ mTimestamp=0 mSleepTimeMs=0 mIdleTimeMs=0 mTxTimeMs[]=[0, 0, 0, 0, 0] mRxTimeMs=0 mEnergyUsed=0}
2018-12-01 22:25:05.832 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:25:15.212 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:25:15.223 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:26:00.008 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:27:00.008 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:28:00.005 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:28:00.017 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:28:00.028 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:28:22.100 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:28:25.085 1670-1687/? E/BatteryStatsService: modem info is invalid: ModemActivityInfo{ mTimestamp=0 mSleepTimeMs=0 mIdleTimeMs=0 mTxTimeMs[]=[0, 0, 0, 0, 0] mRxTimeMs=0 mEnergyUsed=0}
2018-12-01 22:28:27.130 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:29:00.010 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:30:00.012 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:31:00.010 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:31:55.432 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:32:00.005 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:32:00.018 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:33:00.011 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:34:00.004 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:34:00.015 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:35:00.013 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:36:00.043 1670-1683/? E/memtrack: Couldn't load memtrack module
2018-12-01 22:36:30.528 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:36:32.698 7721-22163/? E/ctxmgr: [AppIntervalImpl]closeInterval: ongoing
2018-12-01 22:36:35.527 28543-20318/? E/ActivityThread: Failed to find provider info for com.google.android.apps.gsa.testing.ui.audio.recorded
2018-12-01 22:36:35.694 7721-4872/? E/PlaceInferenceEngine: Position timestamp out of order. Previous: 1543696073742, Current: 1542832589000. Skipping this Position.

```

----------

  NDK| Version  | 18.1.5063045 | Installed
-- | -- | -- | --

NDK path:  /Users/doct0rX/Library/Android/sdk/ndk-bundle

---------

in my fresco/.gradle/local.properties:
```
ndk.path=/path/to/android_ndk/r10e

org.gradle.daemon=true
org.gradle.parallel=true
org.gradle.configureondemand=true
```

- build w/ gradle 4.4
- building on Emulator: Pixel 2 - API 26 - Android 8 (Oreo)
- OS: macOS 10.14.1",What's the stack trace? What version? What NDK version? What's in your local.properties / where did you set the NDK? (see https://frescolib.org/docs/building-from-source.html),@oprisnik updated...
facebook/fresco,https://github.com/facebook/fresco/issues/2115,"Fresco version: 1.8.1

When I try to initialize it I get this error:

```
W/SoLoader: Cannot get nativeLoad method
            java.lang.NoSuchMethodException: nativeLoad [class java.lang.String, class java.lang.ClassLoader, class java.lang.String]
                at java.lang.Class.getMethod(Class.java:2068)
                at java.lang.Class.getDeclaredMethod(Class.java:2047)
                at com.facebook.soloader.SoLoader.getNativeLoadRuntimeMethod(SoLoader.java:281)
                at com.facebook.soloader.SoLoader.initSoLoader(SoLoader.java:233)
                at com.facebook.soloader.SoLoader.initImpl(SoLoader.java:141)
                at com.facebook.soloader.SoLoader.init(SoLoader.java:120)
                at com.facebook.soloader.SoLoader.init(SoLoader.java:104)
                at com.facebook.drawee.backends.pipeline.Fresco.initialize(Fresco.java:63)
                at com.facebook.drawee.backends.pipeline.Fresco.initialize(Fresco.java:46)
```",Could you provide more details so that we can reproduce it? Which device are you using and which Android P version?,"This is the code in my class@onCreate() which extends Application:

```
ImagePipelineConfig config = ImagePipelineConfig.newBuilder(this)
                .setDownsampleEnabled(true)
                .build();
Fresco.initialize(this, config); // This throws the exception
```
This happens in the emulator which runs Android API P x86. I have not tested it in a real device.
"
facebook/fresco,https://github.com/facebook/fresco/issues/2081,"### Description
I want to hide simpleDraweeView after gif animation completion. So I have added AnimationListener and hide my controller onAnimationStop. But half of the time it does not call the onAnimationStop method. 
Let me know if I am doing something wrong.

```
 new BaseControllerListener() {
        @Override
        public void onFinalImageSet(
          String id,
          @Nullable Object imageInfo,
          @Nullable final Animatable animatable) {
          if (animatable != null) {
            AnimatedDrawable2 animatedDrawable = (AnimatedDrawable2) animatable;
            animatedDrawable.setAnimationListener(new AnimationListener() {
              @Override
              public void onAnimationStart(AnimatedDrawable2 drawable) {

                Log.i(TAG, ""onAnimationStart: "");
              }

              @Override
              public void onAnimationStop(AnimatedDrawable2 drawable) {
                .setVisibility(View.GONE);
                Log.i(TAG, ""onAnimationStop: "");
              }

              @Override
              public void onAnimationReset(AnimatedDrawable2 drawable) {
                Log.i(TAG, ""onAnimationReset: "");
              }

              @Override
              public void onAnimationRepeat(AnimatedDrawable2 drawable) {
                Log.i(TAG, ""onAnimationRepeat: "");
              }

              @Override
              public void onAnimationFrame(AnimatedDrawable2 drawable, int frameNumber) {
                Log.i(TAG, ""onAnimationFrame: ""+frameNumber);
              }
            });
            Log.i(TAG, ""animatable.start();: "");
            animatable.start();
          }
        }
      })
```

### Additional Information

* Fresco version:1.8.1
* Platform version: Android 7.1.1
","Could you share the code where you set up your `ImageRequest` and `DraweeController`?

Also CC @oprisnik ","@foghina I am loading gif from resource folder.

```
ImageRequest imageRequest = ImageRequestBuilder.newBuilderWithResourceId(R.raw.mobile_confiti).build();
    DraweeController controller = Fresco.newDraweeControllerBuilder()
      .setUri(imageRequest.getSourceUri())
      .setAutoPlayAnimations(false)
      .setControllerListener(myBaseControllerListener) .build();
```"
facebook/fresco,https://github.com/facebook/fresco/issues/2072,"### Description

there are sawteeth when setting rounding border to display round pic, Only on versions above 8.0

### Reproduction

Here's the code:
``` xml
    <com.facebook.drawee.view.SimpleDraweeView
        android:id=""@+id/active_img""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        fresco:actualImageScaleType=""fitXY""
        fresco:layout_constraintBottom_toBottomOf=""parent""
        fresco:layout_constraintLeft_toLeftOf=""parent""
        fresco:layout_constraintRight_toRightOf=""parent""
        fresco:layout_constraintTop_toTopOf=""parent""
        fresco:placeholderImageScaleType=""fitXY""
        fresco:roundedCornerRadius=""3.33dp""
        fresco:roundingBorderColor=""#FFEBEBEB""
        fresco:roundingBorderWidth=""0.33dp""/>
```
``` java
SimpleDraweeView mTopicImg = Views.findViewById(this, R.id.active_img);
Uri urii = Uri.parse(mPicUrl);
mTopicImg.setImageURI(uri);
```

###ImageLink:
![the whole picture](https://s1.ax1x.com/2018/03/20/9TOOns.png)
![detail picture](https://s1.ax1x.com/2018/03/20/9TOXBn.png)
![detailMark](https://s1.ax1x.com/2018/03/20/9TOj7q.png)

### Additional Information
* Only on versions above 8.0
* Fresco version: [fresco:1.8.0]
* Platform version: [OPPO R11s Android 8.1.0]
","Does removing the border help in your case?
Is it just that OPPO device or also other Android 8.1.0 devies?

**img1: Just setting rounding looks great**

![a](https://user-images.githubusercontent.com/908387/37768809-d4b9d9a0-2dc6-11e8-8f97-8760478d3f7d.png)

**img2: Adding a 0.33dp border looks ""ugly"" around the corners**

![b](https://user-images.githubusercontent.com/908387/37768814-d846e7c0-2dc6-11e8-866d-dc28c563ecb8.png)

![bb](https://user-images.githubusercontent.com/908387/37769140-ee3159fc-2dc7-11e8-8461-05ea9d12385f.png)
","removing the border is ok, but not the best solution,UI made compromises.
I only test it on OPPO devices, because we are equipment manufacturers，hope this problem can be fixed.
thankssssssss  ╭(●｀∀´●)╯╰(●’◡’●)╮ (●’◡’●)ﾉ ヾ(*´▽‘*)ﾉ"
facebook/fresco,https://github.com/facebook/fresco/issues/2040,"### Description

In Android Studio, up to date, with ndk 16.1.4479499, and Fresco lib sources from master branch, to last commit (yesterday), build fails with : 
```
./jpeg/jpeg_codec.cpp:180:3: error: use of undeclared identifier 'memset'; did you mean 'wmemset'?
  memset(&dinfo, 0, sizeof(struct jpeg_decompress_struct));
```
(...) and few more errors (...)
```
1: Task failed with an exception.
-----------
* What went wrong:
Execution failed for task ':imagepipeline:ndk_build_imagepipeline'.
```
```
2: Task failed with an exception.
-----------
* What went wrong:
Execution failed for task ':static-webp:ndk_build_static-webp'.
```
### Reproduction

Try to build again

* Fresco version: master to https://github.com/facebook/fresco/commit/06fe3719a3a3c659438b6c25a8008945e67156a0
* Platform version: debug build for api 24 - Android 6.0
",Can you check if adding those lines to the file might solve the problem? I don't have that NDK version ready at the moment - but otherwise I'll have a look on Monday :),"Hello,
I'm switching back to ndk 15c now.
I will test if it should be a temporary workaround.
I will check if `#include <string.h>` solves it.
Thanks,
Eric"
facebook/fresco,https://github.com/facebook/fresco/issues/2000,"#### Description
Excuse me.
I can not confirm this is a bug, but when I update Fresco version to 1.7.1, ResizeOptions is not working, but it works normally in version 1.5.0.
Please help me to test this function.
thx.

#### Reproduction
##### This is my code:
``` java
public static void loadImgByFile(CommonImageView imageView, String path) {
        if (imageView != null && !TextUtils.isEmpty(path)) {
            File file = new File(path);
            //if size too large then resize
            if (file.exists()) {
                BitmapFactory.Options options = new BitmapFactory.Options();
                options.inJustDecodeBounds = true;
                BitmapFactory.decodeFile(path, options);
                int imageHeight = options.outHeight;
                int imageWidth = options.outWidth;
                int maxSize = getGLESTextureMaxSize();
                Log.e(""texture---test---->"", ""imageHeight="" + imageHeight
                        + ""    imageWidth="" + imageWidth
                        + ""    maxSize="" + maxSize
                );
                if (maxSize <= imageHeight || maxSize <= imageWidth) {
                    ImageRequest request = ImageRequestBuilder.newBuilderWithSource(Uri.fromFile(file))
                            .setResizeOptions(new ResizeOptions(maxSize/2, maxSize/2,maxSize))
                            .build();

                    DraweeController controller = Fresco.newDraweeControllerBuilder()
                            .setImageRequest(request)
                            .setOldController(imageView.getController())
                            .build();
                    imageView.setController(controller);
                    Log.e(""texture---test---->"", ""controller="" + controller);
                    return;
                }
            }
            imageView.setImageURI(Uri.parse(""file://"" + path));
        }
    }
```

```java
private static int OPENGL_MAX_SIZE = 0;
    private static int getGLESTextureMaxSize() {
        if (OPENGL_MAX_SIZE != 0) {
            return OPENGL_MAX_SIZE;
        }
        EGL10 egl = (EGL10) EGLContext.getEGL();
        EGLDisplay dpy = egl.eglGetDisplay(EGL10.EGL_DEFAULT_DISPLAY);
        int[] vers = new int[2];
        egl.eglInitialize(dpy, vers);
        int[] configAttr = {
                EGL10.EGL_COLOR_BUFFER_TYPE, EGL10.EGL_RGB_BUFFER,
                EGL10.EGL_LEVEL, 0,
                EGL10.EGL_SURFACE_TYPE, EGL10.EGL_PBUFFER_BIT,
                EGL10.EGL_NONE
        };
        EGLConfig[] configs = new EGLConfig[1];
        int[] numConfig = new int[1];
        egl.eglChooseConfig(dpy, configAttr, configs, 1, numConfig);
        if (numConfig[0] == 0) {// TROUBLE! No config found.
        }
        EGLConfig config = configs[0];
        int[] surfAttr = {
                EGL10.EGL_WIDTH, 64,
                EGL10.EGL_HEIGHT, 64,
                EGL10.EGL_NONE
        };
        EGLSurface surf = egl.eglCreatePbufferSurface(dpy, config, surfAttr);
        final int EGL_CONTEXT_CLIENT_VERSION = 0x3098; // missing in EGL10
        int[] ctxAttrib = {
                EGL_CONTEXT_CLIENT_VERSION, 1,
                EGL10.EGL_NONE
        };
        EGLContext ctx = egl.eglCreateContext(dpy, config, EGL10.EGL_NO_CONTEXT, ctxAttrib);
        egl.eglMakeCurrent(dpy, surf, surf, ctx);
        int[] maxSize = new int[1];
        GLES10.glGetIntegerv(GLES10.GL_MAX_TEXTURE_SIZE, maxSize, 0);
        egl.eglMakeCurrent(dpy, EGL10.EGL_NO_SURFACE, EGL10.EGL_NO_SURFACE,
                EGL10.EGL_NO_CONTEXT);
        egl.eglDestroySurface(dpy, surf);
        egl.eglDestroyContext(dpy, ctx);
        egl.eglTerminate(dpy);
        OPENGL_MAX_SIZE = maxSize[0];
        return OPENGL_MAX_SIZE;
    }
```

##### When i run them in Fresco 1.7.1 ,the Logcat showing:
![image](https://user-images.githubusercontent.com/11972411/34199347-728b3488-e5a8-11e7-91d8-c93cebf50d68.png)

The ResizeOptions is not working.
SimpleDraweeView shows blank.
I think it is because that OpenGLRenderer can't load the jpeg image, when the height or width of the jpeg image is too large. DraweeController should have loaded the ResizeOptions which I set, but it uploaded the original image to OpenGLRenderer instead.

##### When i run them in  Fresco 1.5.0 ,the Logcat showing:
![image](https://user-images.githubusercontent.com/11972411/34199811-ecf7642a-e5a9-11e7-9d66-d5f81a113671.png)
The ResizeOptions is working normally.
SimpleDraweeView can show pictures.


#### Just a guess
I noticed in the page：
![image](https://user-images.githubusercontent.com/11972411/34200238-48be38c8-e5ab-11e7-9d68-99f2abc6407f.png)
Region decoding support is added in this version, this commit(bd249fa) changed ArtDecoder.
I can not confirm the problem because of this commit.


#### Some device parameters 
+ Device Model:  HUAWEI P9 (HUAWEI EVA-AL00)
+ Platform:  Android 7.0 
+ API level:  24
+ Screen resolution:  1080*1920
+ CPU:  Hisilicon Kirin 955 
+ RAM:  3.0 GB


",Would it be possible for you to share one of your test images so that we can try it out? Thanks!,"Hi @erikandre 
I uploaded a zip file containing three of the test images. 
[images.zip](http://6d0dbc33a6c02.cdn.sohucs.com/foobar/images.zip)
Please download and unzip the file, then put the images into SD card, and call setImageURI(Uri.fromFile(file)).

Those images are test cases of my project, to test corner situations. I can reproduce the issue with those images in Fresco 1.7.1.

Hope this post may help, thx!"
facebook/fresco,https://github.com/facebook/fresco/issues/1954,"We use GitHub Issues for bugs.

If you have a non-bug question, please ask on Stack Overflow: http://stackoverflow.com/questions/tagged/fresco

--- Please use this template, and delete everything above this line before submitting your issue --- 

Description

it can render a few frames , but crash later.

Reproduction
Play the webp -> https://github.com/KeepLearningKeepGoing/LearningNotes/blob/master/10002802_broken.webp

Solution


Additional Information
i got some log output for help. 
------------------------------------------
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410] JNI DETECTED ERROR IN APPLICATION: JNI MonitorEnter called with pending exception java.lang.IllegalStateException: Failed to decode frame
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.animated.webp.WebPFrame.nativeRenderFrame(int, int, android.graphics.Bitmap) (WebPFrame.java:-2)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.animated.webp.WebPFrame.renderFrame(int, int, android.graphics.Bitmap) (WebPFrame.java:50)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.imagepipeline.animated.impl.AnimatedDrawableBackendImpl.renderImageSupportsScaling(android.graphics.Canvas, com.facebook.imagepipeline.animated.base.AnimatedImageFrame) (AnimatedDrawableBackendImpl.java:203)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.imagepipeline.animated.impl.AnimatedDrawableBackendImpl.renderFrame(int, android.graphics.Canvas) (AnimatedDrawableBackendImpl.java:177)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.imagepipeline.animated.impl.AnimatedImageCompositor.renderFrame(int, android.graphics.Bitmap) (AnimatedImageCompositor.java:120)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at boolean com.facebook.fresco.animation.bitmap.wrapper.AnimatedDrawableBackendFrameRenderer.renderFrame(int, android.graphics.Bitmap) (AnimatedDrawableBackendFrameRenderer.java:74)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at boolean com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.renderFrameAndCache(int, com.facebook.common.references.CloseableReference, int) (DefaultBitmapFramePreparer.java:175)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at boolean com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.prepareFrameAndCache(int, int) (DefaultBitmapFramePreparer.java:154)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at boolean com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.prepareFrameAndCache(int, int) (DefaultBitmapFramePreparer.java:162)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.run() (DefaultBitmapFramePreparer.java:112)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.common.executors.ConstrainedExecutorService$Worker.run() (ConstrainedExecutorService.java:177)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) (ThreadPoolExecutor.java:1113)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void java.util.concurrent.ThreadPoolExecutor$Worker.run() (ThreadPoolExecutor.java:588)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void com.facebook.imagepipeline.core.PriorityThreadFactory$1.run() (PriorityThreadFactory.java:42)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at void java.lang.Thread.run() (Thread.java:818)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410] 
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]     in call to MonitorEnter
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]     from void com.facebook.animated.webp.WebPFrame.nativeRenderFrame(int, int, android.graphics.Bitmap)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410] ""Thread-7809"" prio=5 tid=86 Runnable
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   | group=""main"" sCount=0 dsCount=0 obj=0x33d2c100 self=0xd7724e00
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   | sysTid=31483 nice=10 cgrp=bg_non_interactive sched=0/0 handle=0xc7f7f930
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   | state=R schedstat=( 118803164 71801828 135 ) utm=11 stm=0 core=0 HZ=100
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   | stack=0xc7e7d000-0xc7e7f000 stackSize=1038KB
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   | held mutexes= ""mutator lock""(shared held)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #00 pc 0035cd85  /system/lib/libart.so (_ZN3art15DumpNativeStackERNSt3__113basic_ostreamIcNS0_11char_traitsIcEEEEiPKcPNS_9ArtMethodEPv+116)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #01 pc 0033d753  /system/lib/libart.so (_ZNK3art6Thread4DumpERNSt3__113basic_ostreamIcNS1_11char_traitsIcEEEE+138)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #02 pc 0024f8f9  /system/lib/libart.so (_ZN3art9JavaVMExt8JniAbortEPKcS2_+760)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #03 pc 0024ff97  /system/lib/libart.so (_ZN3art9JavaVMExt9JniAbortVEPKcS2_St9__va_list+54)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #04 pc 000fc033  /system/lib/libart.so (_ZN3art11ScopedCheck6AbortFEPKcz+30)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #05 pc 00100f0f  /system/lib/libart.so (_ZN3art11ScopedCheck5CheckERNS_18ScopedObjectAccessEbPKcPNS_12JniValueTypeE.constprop.95+5054)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #06 pc 0010cac3  /system/lib/libart.so (_ZN3art8CheckJNI12MonitorEnterEP7_JNIEnvP8_jobject+370)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #07 pc 000089cb  /data/app/com.sohu.qianfan-1/lib/arm/libstatic-webp.so (???)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #08 pc 00008b91  /data/app/com.sohu.qianfan-1/lib/arm/libstatic-webp.so (???)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #09 pc 000ea8c9  /system/lib/libart.so (art_quick_generic_jni_trampoline+40)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #10 pc 000e61d1  /system/lib/libart.so (art_quick_invoke_stub_internal+64)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #11 pc 003eb9e3  /system/lib/libart.so (art_quick_invoke_stub+170)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   native: #12 pc 000ff3a4  [stack:31483] (???)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.animated.webp.WebPFrame.nativeRenderFrame(Native method)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.animated.webp.WebPFrame.renderFrame(WebPFrame.java:50)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.imagepipeline.animated.impl.AnimatedDrawableBackendImpl.renderImageSupportsScaling(AnimatedDrawableBackendImpl.java:203)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   - locked <0x09d071be> (a com.facebook.imagepipeline.animated.impl.AnimatedDrawableBackendImpl)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.imagepipeline.animated.impl.AnimatedDrawableBackendImpl.renderFrame(AnimatedDrawableBackendImpl.java:177)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.imagepipeline.animated.impl.AnimatedImageCompositor.renderFrame(AnimatedImageCompositor.java:120)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.fresco.animation.bitmap.wrapper.AnimatedDrawableBackendFrameRenderer.renderFrame(AnimatedDrawableBackendFrameRenderer.java:74)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.renderFrameAndCache(DefaultBitmapFramePreparer.java:175)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.prepareFrameAndCache(DefaultBitmapFramePreparer.java:154)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.prepareFrameAndCache(DefaultBitmapFramePreparer.java:162)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.fresco.animation.bitmap.preparation.DefaultBitmapFramePreparer$FrameDecodeRunnable.run(DefaultBitmapFramePreparer.java:112)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.common.executors.ConstrainedExecutorService$Worker.run(ConstrainedExecutorService.java:177)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at com.facebook.imagepipeline.core.PriorityThreadFactory$1.run(PriorityThreadFactory.java:42)
10-27 16:05:41.425 29538-31483/xx A/art: art/runtime/java_vm_ext.cc:410]   at java.lang.Thread.run(Thread.java:818)

* Fresco version: [1.5.0]
* Platform version: [ALL Device]
","Can reproduce using the URI override in the sample app and then going to the WebP fragment: https://github.com/KeepLearningKeepGoing/LearningNotes/blob/master/10002802_broken.webp?raw=true

```
11-01 14:19:03.530  1281  1281 F DEBUG   : Build fingerprint: 'Android/sdk_google_phone_x86/generic_x86:6.0/MASTER/4174734:userdebug/test-keys'
11-01 14:19:03.530  1281  1281 F DEBUG   : Revision: '0'
11-01 14:19:03.530  1281  1281 F DEBUG   : ABI: 'x86'
11-01 14:19:03.530  1281  1281 F DEBUG   : pid: 3229, tid: 3229, name: amples.showcase  >>> com.facebook.fresco.samples.showcase <<<
11-01 14:19:03.530  1281  1281 F DEBUG   : signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------
11-01 14:19:03.533  1281  1281 F DEBUG   : Abort message: 'art/runtime/java_vm_ext.cc:410] JNI DETECTED ERROR IN APPLICATION: JNI MonitorEnter called with pending exception java.lang.IllegalStateException: Failed to decode frame'
11-01 14:19:03.533  1281  1281 F DEBUG   :     eax 00000000  ebx 00000c9d  ecx 00000c9d  edx 00000006
11-01 14:19:03.533  1281  1281 F DEBUG   :     esi b7754c50  edi 0000000b
11-01 14:19:03.533  1281  1281 F DEBUG   :     xcs 00000073  xds 0000007b  xes 0000007b  xfs 00000007  xss 0000007b
11-01 14:19:03.533  1281  1281 F DEBUG   :     eip b731d656  ebp 00000c9d  esp bfe4ca30  flags 00200202
11-01 14:19:03.537  1281  1281 F DEBUG   :
11-01 14:19:03.537  1281  1281 F DEBUG   : backtrace:
11-01 14:19:03.537  1281  1281 F DEBUG   :     #00 pc 00083656  /system/lib/libc.so (tgkill+22)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #01 pc 000815f8  /system/lib/libc.so (pthread_kill+70)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #02 pc 00027205  /system/lib/libc.so (raise+36)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #03 pc 000209e4  /system/lib/libc.so (abort+80)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #04 pc 005173cb  /system/lib/libart.so (art::Runtime::Abort()+377)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #05 pc 0014d9f3  /system/lib/libart.so (art::LogMessage::~LogMessage()+1343)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #06 pc 003a5252  /system/lib/libart.so (art::JavaVMExt::JniAbort(char const*, char const*)+3842)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #07 pc 003a5eac  /system/lib/libart.so (art::JavaVMExt::JniAbortV(char const*, char const*, char*)+116)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #08 pc 00163a10  /system/lib/libart.so (art::ScopedCheck::AbortF(char const*, ...)+62)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #09 pc 0016d9d2  /system/lib/libart.so (art::ScopedCheck::CheckThread(_JNIEnv*)+1890)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #10 pc 0016e4e1  /system/lib/libart.so (art::ScopedCheck::Check(art::ScopedObjectAccess&, bool, char const*, art::JniValueType*) (.constprop.114)+1489)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #11 pc 00183743  /system/lib/libart.so (art::CheckJNI::MonitorEnter(_JNIEnv*, _jobject*)+601)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #12 pc 0000a76f  /data/app/com.facebook.fresco.samples.showcase-1/lib/x86/libstatic-webp.so
11-01 14:19:03.537  1281  1281 F DEBUG   :     #13 pc 0000ab85  /data/app/com.facebook.fresco.samples.showcase-1/lib/x86/libstatic-webp.so
11-01 14:19:03.537  1281  1281 F DEBUG   :     #14 pc 00d27298  /data/app/com.facebook.fresco.samples.showcase-1/oat/x86/base.odex (offset 0x664000) (void com.facebook.animated.webp.WebPFrame.nativeRenderFrame(int, int, android.graphics.Bitmap)+156)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #15 pc 00d277a0  /data/app/com.facebook.fresco.samples.showcase-1/oat/x86/base.odex (offset 0x664000) (void com.facebook.animated.webp.WebPFrame.renderFrame(int, int, android.graphics.Bitmap)+84)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #16 pc 00d65a54  /data/app/com.facebook.fresco.samples.showcase-1/oat/x86/base.odex (offset 0x664000) (void com.facebook.imagepipeline.animated.impl.AnimatedDrawableBackendImpl.renderImageSupportsScaling(android.graphics.Canvas, com.facebook.imagepipeline.animated.base.AnimatedImageFrame)+1064)
11-01 14:19:03.537  1281  1281 F DEBUG   :     #17 pc 00d6694a  /data/app/com.facebook.fresco.samples.showcase-1/oat/x86/base.odex (offset 0x664000) (void com.facebook.imagepipeline.animated.impl.AnimatedDrawableBackendImpl.renderFrame(int, android.graphics.Canvas)+206)
```

@oprisnik is this something that looks familiar to you? We'll most likely need to check for pendingExceptions in libstatic-webp.so","@lambdapioneer  yes, it should not crash the app. What is more serious is that it can't be catched."
facebook/fresco,https://github.com/facebook/fresco/issues/1915,"I get this error:
![image](https://user-images.githubusercontent.com/5357526/30971610-0d0046ee-a471-11e7-8e96-54e577e52c13.png)
",What target are you trying to run / build?,"I don't have stable version of Android-Studio, but it's Beta 6 already, so should work fine.
All I did is Git-clone the repo, and open it on the IDE.
All gradle settings weren't changed from their default ones. 

The error occurred when updating the project to lates Gradle version.

However, after trying to import it again, without updating the gradle version, and it got a different issue:

![image](https://user-images.githubusercontent.com/5357526/31053027-5761ea1c-a69c-11e7-8f88-ec7b5b0f4f04.png)

Then I chose to sync project again, and now it works fine...

However, I tried the ""comparison"" sample, and out of all items there, when I tried ""fresco"" (with ""network"", as I did for all), it took more and more memory, till the app crashed silently. Is it intended to be this way?
Almost all others just got the memory have a random number, but none really crashed. 

I also noticed that sometimes when I try to build a sample I get a warning/error :
![image](https://user-images.githubusercontent.com/5357526/31053493-2a91d4f6-a6a7-11e7-9a19-8eb07fdfaaaf.png)
Sometimes it warns something about architecture.
However, when I choose to run, it runs fine...

"
facebook/fresco,https://github.com/facebook/fresco/issues/1909,"1) the way i used:

```
        ImageRequestBuilder imageRequestBuilder = ImageRequestBuilder.newBuilderWithSource(imageUri);
        imageRequestBuilder.setProgressiveRenderingEnabled(true);
        ImageRequest imageRequest = imageRequestBuilder.build();

        PipelineDraweeControllerBuilder controllerBuilder = Fresco.newDraweeControllerBuilder();
        // controllerBuilder.setOldController(frescoView.getController());
        controllerBuilder.setImageRequest(imageRequest);
        DraweeController controller = controllerBuilder.build();

        // GenericDraweeHierarchy genericDraweeHierarchy = frescoView.getHierarchy();

        frescoView.setController(controller);
```

2) So the question happend:
[issues.txt](https://github.com/facebook/fresco/files/1328230/issues.txt)

the issues.txt is my log for the problem;

3) last: the version that i use

```
    compile 'com.facebook.fresco:fresco:1.5.0'                // 主依赖
    compile 'com.facebook.fresco:animated-gif:1.5.0'  // 支持gif动图
    compile 'com.facebook.fresco:animated-webp:1.5.0'// 支持webp动态
    compile 'com.facebook.fresco:webpsupport:1.5.0'  // 支持webp静态
    compile 'com.facebook.fresco:imagepipeline-okhttp3:1.5.0'
```

",Can you tell us what device & Android version this happens on specifically? Your usage of Fresco looks ok.,"I try again many times;  the Device is ""魅族""；Android version : ""6.0""

and if i use the website:
""http://img.benditoutiao.com/material/20170914/081cf6c0-98e8-11e7-aecc-4fb4862aa761.png@!news-list-single-pic""
I cannot load the image;  It's like the log file I sent earlier；

but if i use the website:
https://raw.githubusercontent.com/yline/as_lib_sdk/master/pic/1024_1024_png/01.png
or
https://raw.githubusercontent.com/yline/as_lib_sdk/master/pic/640_1120_jpg/01.jpg
I can load the image as normal;

Therefore，
This makes it impossible for me to be comfortable with progressive loading api；

hope you can solve it. 


"
facebook/fresco,https://github.com/facebook/fresco/issues/1907,"hi, I've introduced fresco which version is 1.3.0. However, I got the SIGSEGV crashed at libstatic-webp.so when run on x86 android phone.  The stack info is: 
libstatic-webp.so + 0x7ca97
    eip = 0x683d9a97   esp = 0x6befd61c   ebp = 0x6f33e280   ebx = 0x6840df10
    esi = 0xf3f00000   edi = 0x0000000a   eax = 0x6f33df30   ecx = 0x00000000
    edx = 0x683e78f0   efl = 0x00210246
and the corresponding assemble instruction(reassemble by IDA) is ""movdqa  [esp+1Ch+var_1C], xmm6"". I looked at the function of movdqa on web, and there exist an detailed description at [1]. It said that 'when the source or destination operand is a memory operand, the operand must be aligned on a 16-byte boundary or a general-protection exception (#GP) will be generated.'  However, the esp value printed on stack info are not aligned 16-byte. So, I wonder if the unaligned esp access leaded to this crash. If so,   Can we add '-falign-stack=maintain-16-byte' flag to request compiler to avoid unaligned access? [2]

ref: [1]. http://x86.renejeschke.de/html/file_module_x86_id_183.html
[2].https://software.intel.com/en-us/forums/intel-c-compiler/topic/277295

Brs
newjor","What device / emulator and Android version does this happen on? Also, can you repro with the latest version of Fresco?

CC @lambdapioneer for native magic.","@foghina  the device crashed is ASUS T00J. Since the API of the Fresco are different between 1.3.0 and 1.5, and our project originally use 1.3.0, I do not try to upgrade to latest version.  I tried to rebuild the 1.3.0 by adding the flags '-mstackrealign -mincoming-stack-boundary=4', but the output library libstatic-webp.so has nothing different in the size and the function entry, and the app still crashed when using that library. I guess that may be not the esp disalignment leaded to crash. "
facebook/fresco,https://github.com/facebook/fresco/issues/1841,"Hi;
device：google pixel Android 7.1 and hauwei mate9  Android 7.0
Fresco is not visible on Android N devices, using the fragment jump, Android N below is ok.

Tested the other library is ok .

initialization，one/two：fresco  ， Three four：Glide 
![init](https://user-images.githubusercontent.com/10434110/28601909-8fa560ea-71ed-11e7-8129-62187746681b.png)

start fragment:
![load](https://user-images.githubusercontent.com/10434110/28601912-93c9c2d8-71ed-11e7-81ff-d10dd2174f54.png)








","What do you mean by ""fragment jump""? Is this a particular fragment transition?

Also which Fresco library are you using? Would be great if you can provide some small code sample that reproduces the issue.","yes,I use fresco and Glide to compare.   ""fragment jump"" is fargment Transaction. 
Here's my code：
**FrescoActivity**
public class FrescoActivity  extends AppCompatActivity {
    @Override
    protected void onCreate(@Nullable Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_fresco);
        if (savedInstanceState == null) {
            FragmentTransaction transaction = getSupportFragmentManager().beginTransaction();

            transaction.setTransition(FragmentTransaction.TRANSIT_FRAGMENT_OPEN);
            transaction.setCustomAnimations(
                    R.anim.h_fragment_enter,
                    R.anim.h_fragment_exit,
                    R.anim.h_fragment_pop_enter,
                    R.anim.h_fragment_pop_exit
            );
            transaction.replace(R.id.fl_container, FrescoMainFragment.newInstance());
            transaction.commit();
        }
    }
}

**FrescoMainFragment**
public class FrescoMainFragment extends Fragment {

    private SimpleDraweeView s1,s2,s3,s4;

    public static FrescoMainFragment newInstance() {
        
        Bundle args = new Bundle();
        FrescoMainFragment fragment = new FrescoMainFragment();
        fragment.setArguments(args);
        return fragment;
    }

    @Nullable
    @Override
    public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        View mView =inflater.inflate(R.layout.fragment_fresco, container, false);
        initView(mView);
        return mView;
    }

    private void initView(View mView) {
        s1= (SimpleDraweeView) mView.findViewById(R.id.s1);
        s2= (SimpleDraweeView) mView.findViewById(R.id.s2);
        s3= (SimpleDraweeView) mView.findViewById(R.id.s3);
        s4= (SimpleDraweeView) mView.findViewById(R.id.s4);
        s1.setImageURI(""http://odqp9ta7o.qnssl.com/5454114758854668288"");
        s2.setImageURI(""http://odqp9ta7o.qnssl.com/5464149113932808192"");
        Glide.with(this).load(""http://odqp9ta7o.qnssl.com/5429034688435023872"").into(s3);
        Glide.with(this).load(""http://odqp9ta7o.qnssl.com/5468585586862010368"").into(s4);

        Button btn= (Button) mView.findViewById(R.id.btn);

        btn.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                final FragmentTransaction transaction =  getFragmentManager().beginTransaction();
                transaction.setTransition(FragmentTransaction.TRANSIT_FRAGMENT_OPEN);
                transaction.setCustomAnimations(
                        R.anim.h_fragment_enter,
                        R.anim.h_fragment_exit,
                        R.anim.h_fragment_pop_enter,
                        R.anim.h_fragment_pop_exit
                );

                transaction.addToBackStack(null);

                transaction.hide(FrescoMainFragment.this);
                transaction.add(R.id.fl_container, OtherFragment.newInstance());
                transaction.commit();
            }
        });

    }

**OtherFragment**
public class OtherFragment extends Fragment {

    public static OtherFragment newInstance() {

        Bundle args = new Bundle();

        OtherFragment fragment = new OtherFragment();
        fragment.setArguments(args);
        return fragment;
    }

    @Nullable
    @Override
    public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        return inflater.inflate(R.layout.test_linearlayout, container, false);
    }
}
I think it might be this code：transaction.hide (FrescoMainFragment.this);

"
facebook/fresco,https://github.com/facebook/fresco/issues/1760,"  java.io.IOException: Invalid marker: 89
                                                                    at android.media.ExifInterface.getJpegAttributes(ExifInterface.java:1604)
                                                                    at android.media.ExifInterface.loadAttributes(ExifInterface.java:1335)
                                                                    at android.media.ExifInterface.<init>(ExifInterface.java:1053)
                                                                    at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer.getExifInterface(LocalExifThumbnailProducer.java:136)
                                                                    at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer$1.getResult(LocalExifThumbnailProducer.java:103)
                                                                    at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer$1.getResult(LocalExifThumbnailProducer.java:97)
                                                                    at com.facebook.common.executors.StatefulRunnable.run(StatefulRunnable.java:45)
                                                                    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1112)
                                                                    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:587)
                                                                    at java.lang.Thread.run(Thread.java:831)",Can you post a link to the file you're trying to display?,"sorry,My English is poor。。。 
The problem is the local photo album, with recyclerView loading of pictures, use fresco ""load"
facebook/fresco,https://github.com/facebook/fresco/issues/1748,"### Description

When using OKHttpClient with HttpLoggingInterceptor progressive loading doesn't seem to work. setProgress method is never called.

### Reproduction

HttpLoggingInterceptor interceptor = new HttpLoggingInterceptor();
interceptor.setLevel(HttpLoggingInterceptor.Level.BODY);

* Fresco version: 1.3.0
* Platform version: can reproduce on 7.1.2 didn't test on other devices.
","What do you mean with `setProgress` is not called? If you add a `ControllerListener`, you should see intermediate image calls for the first scans and the final image call once everything is available and has been decoded.

There is also an example here that lists all scans when they are rendered:

https://github.com/facebook/fresco/blob/master/samples/showcase/src/main/java/com/facebook/fresco/samples/showcase/imageformat/pjpeg/ImageFormatProgressiveJpegFragment.java","Sorry I think we misunderstood. The problem isn't about PJPEG, it's about the downloading of the image. Try adding this interceptor to the OKHttpClient used by Fresco. The method in GenericDraweeHierarchy::setProgress(float progress) will never be called before the end of the downloading. Therefore the loading drawable is not properly updated. It's probably a side effect of something but I couldn't figured it out. This is a minor issue though."
facebook/fresco,https://github.com/facebook/fresco/issues/1726,"### Description
The BitmapPool log below:
04-18 10:39:34.797 21848-21984/? V/unknown:BitmapPool: release (free) (object, size) = (37535584, 16384)
04-18 10:39:34.797 21848-21984/? V/unknown:BitmapPool: Used = (256, 10787136); Free = (0, 0)
04-18 10:39:34.797 21848-21977/? V/unknown:BitmapPool: Used = (257, 10803520); Free = (0, 0)
04-18 10:39:34.797 21848-21977/? V/unknown:BitmapPool: get (alloc) (object, size) = (84036b7, 16384)
04-18 10:39:34.797 21848-21977/? V/unknown:BitmapPool: release (free) (object, size) = (39308e33, 16384)
04-18 10:39:34.797 21848-21977/? V/unknown:BitmapPool: Used = (256, 10787136); Free = (0, 0)
04-18 10:39:34.807 21848-21982/? V/unknown:BitmapPool: Used = (257, 10803520); Free = (0, 0)
04-18 10:39:34.807 21848-21982/? V/unknown:BitmapPool: get (alloc) (object, size) = (1bf43b42, 16384)
04-18 10:39:34.807 21848-21982/? V/unknown:BitmapPool: release (free) (object, size) = (2dad25ee, 16384)
04-18 10:39:34.807 21848-21982/? V/unknown:BitmapPool: Used = (256, 10787136); Free = (0, 0)
04-18 10:39:34.807 21848-21975/? V/unknown:BitmapPool: Used = (257, 10803520); Free = (0, 0)
04-18 10:39:34.807 21848-21975/? V/unknown:BitmapPool: get (alloc) (object, size) = (35708589, 16384)
04-18 10:39:34.817 21848-21975/? V/unknown:BitmapPool: release (free) (object, size) = (afcb37f, 16384)
04-18 10:39:34.817 21848-21975/? V/unknown:BitmapPool: Used = (256, 10787136); Free = (0, 0)
04-18 10:39:34.817 21848-21976/? V/unknown:BitmapPool: Used = (257, 10803520); Free = (0, 0)
04-18 10:39:34.817 21848-21976/? V/unknown:BitmapPool: get (alloc) (object, size) = (5882dbc, 16384)
04-18 10:39:34.817 21848-21976/? V/unknown:BitmapPool: release (free) (object, size) = (1f80c125, 16384)
04-18 10:39:34.817 21848-21976/? V/unknown:BitmapPool: Used = (256, 10787136); Free = (0, 0)


Then there was a crash.This happens when I use ImagePipeline directly while repeating the same picture but rewriting the CacheKey in PostProcess for not allow it to use bitmap in memory. Because it can be reproduced this crash.The code is below:

```
imagePipeline.fetchDecodedImage(request, null);

@Override
            protected void onNewResultImpl(DataSource<CloseableReference<CloseableImage>> dataSource) {
                if (!dataSource.isFinished()) {
                    onFailureImpl(dataSource);
                    return;
                }

                CloseableReference<CloseableImage> result = dataSource.getResult();
                if (result != null) {
                    listener.success(new FrescoBitmapWrapper(result));
                    result.close();
                }
            }
```

Here i clone the result in FrescoBitmapWrapper's constructor.And then put the bitmap in the ImageView.

### Additional Information
* Fresco version: [1.0]
* Platform version: [android 4.0,5.0,6.0]
",How are you cloning the bitmap and using it? I suspect that the underlying bitmap is closed.,"```
public FrescoBitmapWrapper(CloseableReference<CloseableImage> ref) {
        mReference = ref.clone();
}

@Override
@Deprecated
public synchronized Bitmap get() {
    if (mReference != null) {
        CloseableImage image = mReference.get();
        if (image != null && image instanceof CloseableBitmap)
        return ((CloseableBitmap) image).getUnderlyingBitmap();
    }
    return null;
}

@Override
public void release() {
    if (release) {
        return;
    }
    CloseableReference.closeSafely(mReference);
    mReference = null;
    release = true;
}

@Override
public void setBitmap(ImageView imageView) {
    Bitmap bm = get();
    imageView.setImageBitmap(bm);
    Object tag = imageView.getTag(R.id.tag_key);
    if (tag != null && tag instanceof FrescoBitmapWrapper) {
        FrescoBitmapWrapper wrapper = (FrescoBitmapWrapper) tag;
        wrapper.release();
    }
    imageView.setTag(R.id.tag_key, this);
    imageView.addOnAttachStateChangeListener(new View.OnAttachStateChangeListener() {
        @Override
        public void onViewAttachedToWindow(View v) {
         }
         @Override
        public void onViewDetachedFromWindow(View v) {
            release();
        }
});
```
"
facebook/fresco,https://github.com/facebook/fresco/issues/1706,"I think following code snippet in `gif.cpp` may cause crash when `pSavedImage->ImageDesc.Height` is 0.
```c++
// Check size of image.
if (pSavedImage->ImageDesc.Width <= 0 &&
    pSavedImage->ImageDesc.Height <= 0 &&
    pSavedImage->ImageDesc.Width > (INT_MAX / pSavedImage->ImageDesc.Height)) {
  return GIF_ERROR;
}
```",Do you have an example GIF that crashes?,"http://p1.music.126.net/35Y3orENEaclRSwHUFWr1Q==/18983068253562273.gif
@oprisnik "
facebook/fresco,https://github.com/facebook/fresco/issues/1661,"Hi, we got some crash report from our users

```
Fatal Exception: java.lang.StackOverflowError: stack size 1036KB
       at java.io.ByteArrayInputStream.read(ByteArrayInputStream.java:145)
       at android.media.ExifInterface$ByteOrderAwarenessDataInputStream.readFully(ExifInterface.java:2353)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2029)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2046)
       at android.media.ExifInterface.readImageFileDirectory(ExifInterface.java:2019)
       at android.media.ExifInterface.readExifSegment(ExifInterface.java:1868)
       at android.media.ExifInterface.getJpegAttributes(ExifInterface.java:1667)
       at android.media.ExifInterface.loadAttributes(ExifInterface.java:1334)
       at android.media.ExifInterface.(ExifInterface.java:1052)
       at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer.getExifInterface(SourceFile:136)
       at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer$1.getResult(SourceFile:2103)
       at com.facebook.common.executors.StatefulRunnable.run(SourceFile:45)
       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1112)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:587)
       at java.lang.Thread.run(Thread.java:818)
```","Does this happen for specific images? Do you have a sample image where this can be reproduced with in one of our sample apps (e.g. the URI app)?
For what image format is this happening?",sorry those logs were collected from users and we are not able to get the images which cause the crash. And it seemed to be indroduced from fresco 1.0.0.
facebook/fresco,https://github.com/facebook/fresco/issues/1656," If Storage Permission is not granted, `fetchDecodedImage` in `ImagePipeline` fails when passed an `ImageRequest` with a MediaStore URI (e.g. `content://media/external/images/media/917`).

Error is `/storage/emulated/0/DCIM/Camera/20161128_142252.jpg: open failed: EACCES (Permission denied)`

My workaround was to convert the MediaStore Uri into a File Uri that is saved in the cache directory. The File Uri is then passed to Fresco.

```
if (UriUtil.isLocalCameraUri(uri)) {
   uri = copyMediaStoreUriToCacheDir(uri, filename);
}

    Uri copyMediaStoreUriToCacheDir(Uri uri, String filename) {

        String destinationFilename = App.getAppContext().getCacheDir().getAbsolutePath() + ""/"" + filename;

        BufferedInputStream bis = null;
        BufferedOutputStream bos = null;

        try {
            bis = new BufferedInputStream(App.getAppContext().getContentResolver().openInputStream(uri));
            bos = new BufferedOutputStream(new FileOutputStream(destinationFilename, false));
            byte[] buf = new byte[1024];
            bis.read(buf);
            do {
                bos.write(buf);
            } while (bis.read(buf) != -1);

            return Uri.fromFile(new File(destinationFilename));
        } catch (IOException e) {
            //
        } finally {
            try {
                if (bis != null) {
                    bis.close();
                }
                if (bos != null) {
                    bos.close();
                }
            } catch (IOException e) {
                //
            }
        }

        return null;
    }
```","What exactly is the issue here? I've tried using an `ACTION_PICK` intent to get a `content://media/external/...` URI and without the `EXTERNAL_STORAGE` permission it doesn't work. However, using a simple `ImageView` or using your `copyMediaStoreUriToCacheDir` to change the URI did not change this either. Images don't show up unless the permission is granted. Isn't that the expected behavior?","
@oprisnik: I'm using `ACTION_GET_CONTENT` intent.

`ACTION_PICK` is considered deprecated according to Diane Hackborn.

http://stackoverflow.com/questions/6486716/using-intent-action-pick-for-specific-path/6486827#6486827"
facebook/fresco,https://github.com/facebook/fresco/issues/1627,"4.4 system 。  cannoet load imag white  with log 
E/dalvikvm: ERROR: couldn't find native method

Requested: Lcom/facebook/imagepipeline/nativecode/Bitmaps;.nativeCopyBitmap:(Landroid/graphics/Bitmap;ILandroid/graphics/Bitmap;II)V


other system  can  use successful",Does this error happen all the time? Or just sometimes? What device with Android 4.4 is this happening on?,happen always on devices  smae as virtual devices and   other phone same xiaomi  also 。
facebook/fresco,https://github.com/facebook/fresco/issues/1618,"fresco 0.13, I got some crash message:,applicationContext.getFilesDir() return null?
/com/facebook/cache/disk/DiskStorageCache.java  
//TODO(t12287315): Remove the temp method for deleting created Preference in next release
  private static void maybeDeleteSharedPreferencesFile(
      Context context,
      String directoryName) {
    Context applicationContext = context.getApplicationContext();
    String path =
        applicationContext.getFilesDir().getParent() // java.lang.NullPointerException why??
            + File.separator
            + ""shared_prefs""
            + File.separator
            + SHARED_PREFS_FILENAME_PREFIX
            + directoryName;
    File file = new File(path + "".xml"");
    try {
      if (file.exists()) {
        file.delete();
      }
    } catch (Exception e) {
      FLog.e(TAG, ""Fail to delete SharedPreference from file system. "");
    }
  }

java.lang.NullPointerException: Attempt to invoke virtual method 'java.lang.String java.io.File.getParent()' on a null object reference
	at com.facebook.cache.disk.DiskStorageCache.maybeDeleteSharedPreferencesFile(SourceFile:782)
	at com.facebook.cache.disk.DiskStorageCache.access$300(SourceFile:50)
	at com.facebook.cache.disk.DiskStorageCache$1.run(SourceFile:193)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
	at java.lang.Thread.run(Thread.j","Can you consistently repro this, or was it a one-off? Also, what device / OS version is this happening on?",
facebook/fresco,https://github.com/facebook/fresco/issues/1610,"When I load a gif image on my x86 device, the image can be displayed at first, but soon it will crash after a few loops, here is the crash backtrace:

12-30 18:42:25.772 150-150/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
12-30 18:42:25.772 150-150/? I/DEBUG: Build fingerprint: 'Lenovo/K900/K900:4.3/JSS15Q/VIBEROM_V1.0_1418_DEV_K900:user/releasekey'
12-30 18:42:25.772 150-150/? I/DEBUG: Revision: '0'
12-30 18:42:25.772 150-150/? I/DEBUG: pid: 4773, tid: 4823, name: Thread-5812  >>> com.facebook.samples.demo <<<
12-30 18:42:25.772 150-150/? I/DEBUG: signal 11 (SIGSEGV), code 128 (SI_KERNEL), fault addr 00000000
12-30 18:42:25.802 150-150/? I/DEBUG:     eax 60bbac80  ebx 6108ef24  ecx 00001002  edx 60f61a14
12-30 18:42:25.802 150-150/? I/DEBUG:     esi 00000000  edi 00000000
12-30 18:42:25.802 150-150/? I/DEBUG:     xcs 00000073  xds 0000007b  xes 0000007b  xfs 00000000  xss 0000007b
12-30 18:42:25.802 150-150/? I/DEBUG:     eip 6106f8df  ebp 613ef154  esp 60f619cc  flags 00210206
12-30 18:42:25.812 150-150/? I/DEBUG: backtrace:
12-30 18:42:25.812 150-150/? I/DEBUG:     #00  pc 000058df  /data/app-lib/com.facebook.samples.demo-2/libgifimage.so
12-30 18:42:25.812 150-150/? I/DEBUG:     #01  pc 00006f31  /data/app-lib/com.facebook.samples.demo-2/libgifimage.so
12-30 18:42:25.812 150-150/? I/DEBUG:     #02  pc 00002c9b  /data/app-lib/com.facebook.samples.demo-2/libgifimage.so
12-30 18:42:25.812 150-150/? I/DEBUG:     #03  pc 000049bd  /data/app-lib/com.facebook.samples.demo-2/libgifimage.so

and this is the related code lines:
LOADING-MC0:bin loading$ ./i686-linux-android-addr2line -e libgifimage.so 000058df 00006f31 00002c9b 000049bd
/Users/loading/work/fresco/fresco-1.0.0/animated-gif/src/main/jni/../../../nativedeps/merge/giflib/dgif_lib.c:819
/Users/loading/work/fresco/fresco-1.0.0/animated-gif/src/main/jni/../../../nativedeps/merge/giflib/dgif_lib.c:457
/Users/loading/work/fresco/fresco-1.0.0/animated-gif/src/main/jni/gifimage/./gif.cpp:346
/Users/loading/work/fresco/fresco-1.0.0/animated-gif/src/main/jni/gifimage/./gif.cpp:1106 (discriminator 2)

besides gif image, an animated webp image may also cause a similar crash, the image is from fresco sample demo, https://www.gstatic.com/webp/animated/1.webp, and the backtrace looks like this：
12-30 18:44:11.012 150-150/? I/DEBUG: pid: 6445, tid: 6520, name: Thread-5908  >>> com.facebook.samples.demo <<<
12-30 18:44:11.012 150-150/? I/DEBUG: signal 11 (SIGSEGV), code 128 (SI_KERNEL), fault addr 00000000
12-30 18:44:11.042 150-150/? I/DEBUG:     eax 605482f0  ebx 63ef7ee0  ecx 00000000  edx 63ed2a20
12-30 18:44:11.042 150-150/? I/DEBUG:     esi f3ffc000  edi 00000006
12-30 18:44:11.042 150-150/? I/DEBUG:     xcs 00000073  xds 0000007b  xes 0000007b  xfs 00000000  xss 0000007b
12-30 18:44:11.042 150-150/? I/DEBUG:     eip 63ec53f7  ebp 605492c0  esp 61ddd58c  flags 00210246
12-30 18:44:11.052 150-150/? I/DEBUG: backtrace:
12-30 18:44:11.052 150-150/? I/DEBUG:     #00  pc 000763f7  /data/app-lib/com.facebook.samples.demo-1/libstatic-webp.so
12-30 18:44:11.052 150-150/? I/DEBUG:     #01  pc 0004c18e  /data/app-lib/com.facebook.samples.demo-1/libstatic-webp.so
12-30 18:44:11.052 150-150/? I/DEBUG:     #02  pc 0004d17a  /data/app-lib/com.facebook.samples.demo-1/libstatic-webp.so
12-30 18:44:11.052 150-150/? I/DEBUG:     #03  pc 00051a0b  /data/app-lib/com.facebook.samples.demo-1/libstatic-webp.so
12-30 18:44:11.052 150-150/? I/DEBUG:     #04  pc 00043124  /data/app-lib/com.facebook.samples.demo-1/libstatic-webp.so
12-30 18:44:11.052 150-150/? I/DEBUG:     #05  pc 000452d0  /data/app-lib/com.facebook.samples.demo-1/libstatic-webp.so
12-30 18:44:11.052 150-150/? I/DEBUG:     #06  pc 000097e0  /data/app-lib/com.facebook.samples.demo-1/libstatic-webp.so

LOADING-MC0:bin loading$ ./i686-linux-android-addr2line -e libstatic-webp.so 000763f7 0004c18e 0004d17a 00051a0b 00043124 000452d0 000097e0
/Users/loading/Android/NDK/android-ndk-r12b/toolchains/x86-4.9/prebuilt/darwin-x86_64/lib/gcc/i686-linux-android/4.9.x/include/emmintrin.h:979
/Users/loading/work/fresco/fresco-1.0.0/static-webp/src/main/jni/../../../nativedeps/merge/libwebp-0.5.1/src/dec/frame.c:47
/Users/loading/work/fresco/fresco-1.0.0/static-webp/src/main/jni/../../../nativedeps/merge/libwebp-0.5.1/src/dec/frame.c:511
/Users/loading/work/fresco/fresco-1.0.0/static-webp/src/main/jni/../../../nativedeps/merge/libwebp-0.5.1/src/dec/vp8.c:603
/Users/loading/work/fresco/fresco-1.0.0/static-webp/src/main/jni/../../../nativedeps/merge/libwebp-0.5.1/src/dec/webp.c:488
/Users/loading/work/fresco/fresco-1.0.0/static-webp/src/main/jni/../../../nativedeps/merge/libwebp-0.5.1/src/dec/webp.c:780
/Users/loading/work/fresco/fresco-1.0.0/static-webp/src/main/jni/static-webp/./webp.cpp:656


Can anyone help us? Many thanks for your kind help!
",Can you tell us on which exact device and Android version you are able to reproduce this?,"hi @lambdapioneer, I reproduce this issue on Lenovo K900, with android 4.3 inside"
facebook/fresco,https://github.com/facebook/fresco/issues/1608,"From GCC documentation:

-fno-weak
Do not use weak symbol support, even if it is provided by the linker. By default, G++ uses weak symbols if they are available. This option exists only for testing, and should not be used by end-users; it results in inferior code and has no benefits. This option may be removed in a future release of G++.

Let's not use it.",Do you want to create a PR for this change? I think it's just appearing in three places :) I'll then import that change and run it against our internal tests to make sure it has no observable negative impact.,
facebook/fresco,https://github.com/facebook/fresco/issues/1565,In zoomable sample this method does nothing. Only setTransformImmediate works. Please fix.,"Can you give us more details what the issue you're facing is (maybe with a video / gif of the issue), how to repro and what the desired behavior would be? ","When I use the ""zoomToPoint"" method as followed: 
`zoomToPoint(getMaxScaleFactor(), imagePoint, viewPoint, LIMIT_ALL, 400, null);`
in` AbstractAnimatedZoomableController->setTransform` method it calls `setTransformAnimated` method according to this code:
```
if (durationMs <= 0) {
      setTransformImmediate(newTransform);
    } else {
      setTransformAnimated(newTransform, durationMs, onAnimationComplete);
    }
```

and the method is as followed:

```
public void setTransformAnimated(
      final Matrix newTransform,
      long durationMs,
      @Nullable final Runnable onAnimationComplete) {
    FLog.v(getLogTag(), ""setTransformAnimated: duration %d ms"", durationMs);
    stopAnimation();
    Preconditions.checkArgument(durationMs > 0);
    Preconditions.checkState(!isAnimating());
    setAnimating(true);
    mValueAnimator.setDuration(durationMs);
    getTransform().getValues(getStartValues());
    newTransform.getValues(getStopValues());
    mValueAnimator.addUpdateListener(new ValueAnimator.AnimatorUpdateListener() {
      @Override
      public void onAnimationUpdate(ValueAnimator valueAnimator) {
        calculateInterpolation(getWorkingTransform(), (float) valueAnimator.getAnimatedValue());
        AnimatedZoomableController.super.setTransform(getWorkingTransform());
      }
    });
    mValueAnimator.addListener(new AnimatorListenerAdapter() {
      @Override
      public void onAnimationCancel(Animator animation) {
        FLog.v(getLogTag(), ""setTransformAnimated: animation cancelled"");
        onAnimationStopped();
      }
      @Override
      public void onAnimationEnd(Animator animation) {
        FLog.v(getLogTag(), ""setTransformAnimated: animation finished"");
        onAnimationStopped();
      }
      private void onAnimationStopped() {
        if (onAnimationComplete != null) {
          onAnimationComplete.run();
        }
        setAnimating(false);
        getDetector().restartGesture();
      }
    });
    mValueAnimator.start();
  }
```

but after that call nothing happens because this code is called immediatly after starting animation:

```
  public void stopAnimation() {
      /*
      if (!isAnimating()) {
        return;
      }
      FLog.v(getLogTag(), ""stopAnimation"");
      mValueAnimator.end();
      mValueAnimator.removeAllUpdateListeners();
      mValueAnimator.removeAllListeners(); */
  }
```

and where it is called is this method:

```
  @Override
  public void onGestureBegin(TransformGestureDetector detector) {
    FLog.v(getLogTag(), ""onGestureBegin"");
    stopAnimation();
    super.onGestureBegin(detector);
  }
```

In the conclusion when you set a duration for the animation it doesnt animate, it does nothing, in fact it shoud zoom with an animation to the desired scale.

How to reproduce:
call this meethod and see it does nothing:
`zoomToPoint(getMaxScaleFactor(), imagePoint, viewPoint, LIMIT_ALL, 400, null)
`

I hope I answered all your questions. Thanks for your interest."
facebook/fresco,https://github.com/facebook/fresco/issues/1547,"Recently, we've encountered several strange problems in `System.loadLibrary()`, it crashed in `dlopen` with several different msg, they are:

1. Bad file number

```
java.lang.UnsatisfiedLinkError
dlopen failed: ""/data/app-lib/tv.danmaku.bili-2/libimagepipeline.so"" phdr mmap failed: Bad file number
```

2. Has no loadable segemnts

```
java.lang.UnsatisfiedLinkError
dlopen failed: ""/data/app-lib/tv.danmaku.bili-1/libimagepipeline.so"" has no loadable segments
```

3. Invalid argument

```
java.lang.UnsatisfiedLinkError
Cannot load library: load_library(linker.cpp:785): can't load program header table: /data/app-lib/tv.danmaku.bili-2/libimagepipeline.so: Invalid argument
```

4. Bad ELF magic

```
java.lang.UnsatisfiedLinkError
dlopen failed: ""/data/app/tv.danmaku.bili-1/lib/arm/libimagepipeline.so"" has bad ELF magic
```


We have many other native lib but the problem seems only occur in Fresco's so(It seems only happend in `libimagepipeline.so` and `libmemtrunk.so`). It cannot be reproduced and we know the crash in our crash system.

===
**Fresco version**: 0.11.0
**Android system distribution**:
4.4.4(API 19) => 39.85%
4.3(API 18) => 19.13%
4.4.2(API 19) => 11.99%
5.1.1(API 22) => 11.06%
4.2.2(API 17) => 6.49%
**Manufacturer**:
Most in XIAOMI and VIVO","Do you by any chance have a local repro and can provide us with the logcat from the app start up to this issue? I'm inclined to say that this related to the specific models. Also, is this a one-off issue for those devices or is it happening on every start?

You can also try to use a native code loader for Android which might help to mitigate some of the issues. You can register with the `SoLoaderShim` from Fresco:
- https://github.com/KeepSafe/ReLinker
- https://github.com/facebook/SoLoader
","@lambdapioneer Sorry for late response, I've use something like `SoLoaderShim` in Fresco. But we cannot reproduce the crash. Yes it's related to specific model and it seems that every device just happen once or twice. "
facebook/fresco,https://github.com/facebook/fresco/issues/1539,"fresco 0.14.1:in Android 4.3 operating system oppo brand mobile phone
java.lang.NoSuchMethodError: android.os.StatFs.getBlockSizeLong
at com.facebook.common.statfs.StatFsHelper.getAvailableStorageSpace(StatFsHelper.java:137)
at com.facebook.common.statfs.StatFsHelper.testLowDiskSpace(StatFsHelper.java:114)
at com.facebook.cache.disk.DiskStorageCache.updateFileCacheSizeLimit(DiskStorageCache.java:584)
at com.facebook.cache.disk.DiskStorageCache.maybeEvictFilesInCacheDir(DiskStorageCache.java:485)
at com.facebook.cache.disk.DiskStorageCache.startInsert(DiskStorageCache.java:342)
at com.facebook.cache.disk.DiskStorageCache.insert(DiskStorageCache.java:377)
at com.facebook.imagepipeline.cache.BufferedDiskCache.writeToDiskCache(BufferedDiskCache.java:364)
at com.facebook.imagepipeline.cache.BufferedDiskCache.access$500(BufferedDiskCache.java:38)
at com.facebook.imagepipeline.cache.BufferedDiskCache$3.run(BufferedDiskCache.java:243)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1080)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:573)
at java.lang.Thread.run(Thread.java:838)","Can you provide me with the concrete model number? Does this reproduce consistently on that phone?
",
facebook/fresco,https://github.com/facebook/fresco/issues/1536,"When auto-rotate is enabled, it seems that the `ImageInfo` returned in the `ControllerListener.onFinalImageSet` is wrong for images that were rotated.

Namely if I have a 50x100 image with rotation 90, Fresco will auto-rotate this as 100x50 and display the image as wide, but the ImageInfo will report the image as having 50x100.

```
        ControllerListener<ImageInfo> listener = new BaseControllerListener<ImageInfo>() {
            @Override
            public void onFinalImageSet(String id, @Nullable ImageInfo imageInfo, @Nullable Animatable animatable) {
                int width = imageInfo.getWidth(); // Reports 50
                int height = imageInfo.getHeight(); // Reports 100
            }
        };

        DraweeController controller = Fresco.newDraweeControllerBuilder()
                .setUri(uri)
                .setControllerListener(listener)
                .build();
        draweeView.setController(controller);

```

Is this intended? If it is, is there a way to detect if a rotation occurred? 

I am trying to have images loaded in that are full width but variable height with the image's intended aspect ratio as described in this [SO post](http://stackoverflow.com/questions/33955510/facebook-fresco-using-wrap-conent/34075281#34075281).","What version of Fresco are you using? Does this still happen with v14.0.1? I think that @kirwan has been working on this in recent releases and it should work.
","Yea @oprisnik that's still happening with v14.0.1. I updated yesterday to check and seems like that's still the case.
"
facebook/fresco,https://github.com/facebook/fresco/issues/1504,"Hello. I'm getting a strange crash when loading a simple local gif.

10-18 18:00:57.522 8284-8284/com.goodrun.android.debug D/AndroidRuntime: Shutting down VM

```
FATAL EXCEPTION: main
 Process: com.goodrun.android.debug, PID: 8284
 java.lang.IndexOutOfBoundsException: Invalid index 1, size is 1
     at java.util.ArrayList.throwIndexOutOfBoundsException(ArrayList.java:255)
     at java.util.ArrayList.get(ArrayList.java:308)
     at com.facebook.drawee.controller.ForwardingControllerListener.onFinalImageSet(ForwardingControllerListener.java:91)
     at com.facebook.drawee.controller.AbstractDraweeController.onNewResultInternal(AbstractDraweeController.java:524)
     at com.facebook.drawee.controller.AbstractDraweeController.access$000(AbstractDraweeController.java:47)
     at com.facebook.drawee.controller.AbstractDraweeController$1.onNewResultImpl(AbstractDraweeController.java:469)
     at com.facebook.datasource.BaseDataSubscriber.onNewResult(BaseDataSubscriber.java:48)
     at com.facebook.datasource.AbstractDataSource$1.run(AbstractDataSource.java:181)
     at android.os.Handler.handleCallback(Handler.java:739)
     at android.os.Handler.dispatchMessage(Handler.java:95)
     at android.os.Looper.loop(Looper.java:148)
     at android.app.ActivityThread.main(ActivityThread.java:5417)
     at java.lang.reflect.Method.invoke(Native Method)
     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)
     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)
```","Do you have any calls to `removeListener()` in your code?

As a temporary measure you could remove calls to that method. We'll surely follow-up with a fix soon, but it will take until the next release to be available.
","I just figured out that this happens when calling ""setAutoPlayAnimations"" on DraweeController
"
facebook/fresco,https://github.com/facebook/fresco/issues/1500,"This occurs on specific device ZTE blade (possible, may be reproduced on another devices)
I simplified round demo from sources, so it shows only one image with scaleType CENTER and rounding method BITMAP_ONLY. I also change image to bigger one
Result on zte is:
![bitmap_shader_zte](https://cloud.githubusercontent.com/assets/2329931/19312293/72182dbc-909a-11e6-831b-cc3977cdfc0a.png)

Same code, but with rounding method OVERLAY_COLOR works well:
![overlay_color_zte](https://cloud.githubusercontent.com/assets/2329931/19312389/d955e7b2-909a-11e6-856f-4b436fbaa2ce.png)

Same code without any rounding works well too
And no problems on nexus 6 (and other devices) with any rounding method

In our application this bug reproduced in two ways (we are using BITMAP_ONLY method)
1) Image is loading black and staying black 
2) Image is loading well, but then another image on the screen is loading (for example when we scrolling recycler view), the first one becomes black. When another image scrolls away, the first one becomes normal again. You can see it on the video
https://youtu.be/rNt07hydWyE
The black are in the middle on the screen - image which won't load at all (as in demo)
And in the right up corner there is images which appear and disappear while image in bottom recycler view loading/unloading (view attaches, detaches from window)

Without rounding we have no problems at all. So, I assume there is some problem in RoundedBitmapDrawable which uses bitmap shaders to round corners
","Can you provide us with the sample image (and maybe copy paste the layout) so that it's easier for us to repro?
","You can just change 3 first rows in MainActivity class of round example

private static final Uri URI = Uri.parse(
 ""http://images.adsttc.com/media/images/5192/55ba/b3fc/4b8d/f000/005b/large_jpg/MBS_Image_by_BIG_01.jpg?1368544661"");
  private static final int WIDTH = 240;
  private static final int HEIGHT = 140;

and result 
![zte](https://cloud.githubusercontent.com/assets/2329931/19380380/b2a2fcca-91ff-11e6-831b-c41d799d9220.png)

And there is also one interesting message in log
10-14 11:14:55.533 15505-15532/com.facebook.samples.round E/OpenGLRenderer: GL error:  Out of memory!
which appears when i start to scroll up and down, and after scroll other images becomes black

Without bitmap shader rounding everything is ok, no errors in log
"
facebook/fresco,https://github.com/facebook/fresco/issues/1482,"Recently the library in our project is upgraded to 0.14.0, sometimes get the following exception:

E/unknown:TransformingConsumer: unhandled exception
                                                                               java.lang.IllegalArgumentException
                                                                                   at com.facebook.common.internal.Preconditions.checkArgument(Preconditions.java:108)
                                                                                   at com.facebook.imagepipeline.producers.ResizeAndRotateProducer.getRotationAngle(ResizeAndRotateProducer.java:288)
                                                                                   at com.facebook.imagepipeline.producers.ResizeAndRotateProducer.shouldRotate(ResizeAndRotateProducer.java:301)
                                                                                   at com.facebook.imagepipeline.producers.ResizeAndRotateProducer.shouldTransform(ResizeAndRotateProducer.java:228)
                                                                                   at com.facebook.imagepipeline.producers.ResizeAndRotateProducer.access$600(ResizeAndRotateProducer.java:43)
                                                                                   at com.facebook.imagepipeline.producers.ResizeAndRotateProducer$TransformingConsumer.onNewResultImpl(ResizeAndRotateProducer.java:128)
                                                                                   at com.facebook.imagepipeline.producers.ResizeAndRotateProducer$TransformingConsumer.onNewResultImpl(ResizeAndRotateProducer.java:76)
                                                                                   at com.facebook.imagepipeline.producers.BaseConsumer.onNewResult(BaseConsumer.java:49)
                                                                                   at com.facebook.imagepipeline.producers.AddImageTransformMetaDataProducer$AddImageTransformMetaDataConsumer.onNewResultImpl(AddImageTransformMetaDataProducer.java:48)
                                                                                   at com.facebook.imagepipeline.producers.AddImageTransformMetaDataProducer$AddImageTransformMetaDataConsumer.onNewResultImpl(AddImageTransformMetaDataProducer.java:32)
                                                                                   at com.facebook.imagepipeline.producers.BaseConsumer.onNewResult(BaseConsumer.java:49)
                                                                                   at com.facebook.imagepipeline.producers.MultiplexProducer$Multiplexer.onNextResult(MultiplexProducer.java:442)
                                                                                   at com.facebook.imagepipeline.producers.MultiplexProducer$Multiplexer$ForwardingConsumer.onNewResultImpl(MultiplexProducer.java:499)
                                                                                   at com.facebook.imagepipeline.producers.MultiplexProducer$Multiplexer$ForwardingConsumer.onNewResultImpl(MultiplexProducer.java:496)
                                                                                   at com.facebook.imagepipeline.producers.BaseConsumer.onNewResult(BaseConsumer.java:49)
                                                                                   at com.facebook.imagepipeline.producers.EncodedMemoryCacheProducer$1.onNewResultImpl(EncodedMemoryCacheProducer.java:94)
                                                                                   at com.facebook.imagepipeline.producers.EncodedMemoryCacheProducer$1.onNewResultImpl(EncodedMemoryCacheProducer.java:89)
                                                                                   at com.facebook.imagepipeline.producers.BaseConsumer.onNewResult(BaseConsumer.java:49)
                                                                                   at com.facebook.imagepipeline.producers.DiskCacheProducer$DiskCacheConsumer.onNewResultImpl(DiskCacheProducer.java:234)
                                                                                   at com.facebook.imagepipeline.producers.DiskCacheProducer$DiskCacheConsumer.onNewResultImpl(DiskCacheProducer.java:206)
                                                                                   at com.facebook.imagepipeline.producers.BaseConsumer.onNewResult(BaseConsumer.java:49)
                                                                                   at com.facebook.imagepipeline.producers.NetworkFetchProducer.notifyConsumer(NetworkFetchProducer.java:168)
                                                                                   at com.facebook.imagepipeline.producers.NetworkFetchProducer.maybeHandleIntermediateResult(NetworkFetchProducer.java:145)
                                                                                   at com.facebook.imagepipeline.producers.NetworkFetchProducer.onResponse(NetworkFetchProducer.java:104)
                                                                                   at com.facebook.imagepipeline.producers.NetworkFetchProducer.access$000(NetworkFetchProducer.java:37)
                                                                                   at com.facebook.imagepipeline.producers.NetworkFetchProducer$1.onResponse(NetworkFetchProducer.java:72)
                                                                                   at com.facebook.imagepipeline.producers.HttpUrlConnectionNetworkFetcher.fetchSync(HttpUrlConnectionNetworkFetcher.java:83)
                                                                                   at com.facebook.imagepipeline.producers.HttpUrlConnectionNetworkFetcher$1.run(HttpUrlConnectionNetworkFetcher.java:61)
                                                                                   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:422)
                                                                                   at java.util.concurrent.FutureTask.run(FutureTask.java:237)
                                                                                   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1112)
                                                                                   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:587)
                                                                                   at java.lang.Thread.run(Thread.java:841)

After debugging the code, found that it caused by the illegal rotation angle (-1, the default value in the EncodedImage).  

For some reason, it failed to decode the dimension information, which means the following expression returns null in the EncodedImage.java
Pair<Integer, Integer> dimensions = BitmapUtil.decodeDimensions(getInputStream());

I think mRotationAngle should be set to Zero in this case, right?
","Can you provide a particular image which results in this error? It would be useful to know whether you have any changes to the default `ImagePipelineConfig` or `ImageRequest` too.
","@kirwan, if I remembered, <a href=""http://7xjqxd.com1.z0.glb.clouddn.com/image/201609/27/51091ebcf76d07f88ca20bf9832aa682.jpg"">this picture</a> has the problem

And this is the request code in our project:

```
        ImageRequest request = ImageRequestBuilder.newBuilderWithSource(Uri.parse(url))
                .setProgressiveRenderingEnabled(true)
                .setRotationOptions(RotationOptions.forceRotation(RotationOptions.NO_ROTATION))
                .build();
        DraweeController controller = Fresco.newDraweeControllerBuilder()
                .setImageRequest(request)
                .setOldController(view.getController())
                .setRetainImageOnFailure(true)
                .setAutoPlayAnimations(true)
                .build();
        view.setController(controller);
```

For ImagePipelineConfig, only the memory configuration is changed.  
"
facebook/fresco,https://github.com/facebook/fresco/issues/1470,"I create custom view with MultiDraweeHolder. In this view I have the custom logic for drawing several images. Main big image and two rows below whith preview, but some images take this stack:
`java.lang.RuntimeException: Bogus Huffman table definition
                                                                            at com.facebook.imagepipeline.nativecode.JpegTranscoder.nativeTranscodeJpeg(Native Method)
                                                                            at com.facebook.imagepipeline.nativecode.JpegTranscoder.transcodeJpeg(JpegTranscoder.java:66)
                                                                            at com.facebook.imagepipeline.producers.ResizeAndRotateProducer$TransformingConsumer.doTransform(ResizeAndRotateProducer.java:154)
                                                                            at com.facebook.imagepipeline.producers.ResizeAndRotateProducer$TransformingConsumer.access$000(ResizeAndRotateProducer.java:72)
                                                                            at com.facebook.imagepipeline.producers.ResizeAndRotateProducer$TransformingConsumer$1.run(ResizeAndRotateProducer.java:89)
                                                                            at com.facebook.imagepipeline.producers.JobScheduler.doJob(JobScheduler.java:207)
                                                                            at com.facebook.imagepipeline.producers.JobScheduler.access$000(JobScheduler.java:27)
                                                                            at com.facebook.imagepipeline.producers.JobScheduler$1.run(JobScheduler.java:78)
                                                                            at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
                                                                            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
                                                                            at com.facebook.imagepipeline.core.PriorityThreadFactory$1.run(PriorityThreadFactory.java:43)
                                                                            at java.lang.Thread.run(Thread.java:818)`
Image for example: http://mobs.mail.ru/pthumb/2442026b434dd1533aa66027adf1bd73/r/-x-/news/pic/91/53/image403989_68937dd070195913eb586485d90dcb8e.jpg

Please, help me! Thanx!
PS: there is my custom views implementation.
[GalleriesArticleView.txt](https://github.com/facebook/fresco/files/479532/GalleriesArticleView.txt)
","Can you provide me details on the following questions:
- Which version of Fresco are you using?
- Does the bug reproduce consistently? (i.e. are always the same images failing)
- Do you use a custom network fetcher?
- Does the bug reproduce when you store the file on the device and replace the uri with `Uri.parse(""file:///path/to/the/image.jpg"")`?
","Hi @lambdapioneer 
I use fresco 0.13.0 .
I use this view in RecyclerView. Bug reproduce consistently,  but not always are the same images failing.  
I use default network fetcher
Bug not reproduce when I store the file on the device and replace the uri with filepath
"
facebook/fresco,https://github.com/facebook/fresco/issues/1453,"**closeableObject** could be closed unsafely in MultiplexProducer.Multiplexer#onNextResult

> com.facebook.imagepipeline.producers.MultiplexProducer.Multiplexer#onNextResult

```
      while (iterator.hasNext()) {
        Pair<Consumer<T>, ProducerContext> pair = iterator.next();
        synchronized (pair) {
          pair.first.onNewResult(closeableObject, isFinal);
        }
      }
```

**The Failed Situation is submitting two image request for the same url image, but their width/height is different.**
In result, one image request is successful, one image request is **failed**. e.g.
![image](https://cloud.githubusercontent.com/assets/815609/18239160/e53e1ee2-7375-11e6-9382-b51271d43426.png)
## Here, closeableObject should be cloneOrNull(closeableObject).
","Do you have a simple sample app which results in the screenshot you attached?

If you could send me that it would really help in testing what goes wrong. We think the second line you pointed to should stop this being an issue.
","@kirwan  sorry, I had deleted  the sameple app.
I just use imagepipeline not use drawee, call 

> com.facebook.imagepipeline.core.ImagePipeline#fetchDecodedImage 

**The Failed Situation is submitting two image request for the same url image, but their width/height is different.**
"
facebook/fresco,https://github.com/facebook/fresco/issues/1404,"HI：
I'm on the Samsung SM-G3818Android4.2.2: pictures do not show up, this is my picture address: https: //dn-runedu-img.qbox.me/5324277294619549696.   

Adjustment ResizeOptions on other mobile phone and some can not be displayed

public static void showImageEnty(SimpleDraweeView view, String url,
            int width, int height, int imageResouse) {
        if (url == null) {
            view.setImageURI(Uri
                    .parse(""res://com.zjcs.student/"" + imageResouse));
        } else {
            Uri uri = Uri.parse(url);
            ImageRequest request = ImageRequestBuilder
                    .newBuilderWithSource(uri)
                    .setResizeOptions(new ResizeOptions(width, height)).build();
            DraweeController controller = Fresco.newDraweeControllerBuilder()
                    .setOldController(view.getController())
//                  .setAutoPlayAnimations(true)
                    .setImageRequest(request).build();
            view.setController(controller);
        }
    }

 ImageUtils.showImageEnty(itemHolder.groupLogo, info.getImgUrl(), ScreenUtil.dp2px(activity, 48), ScreenUtil.dp2px(activity, 48)
                    , R.drawable.home_def_type);

<com.facebook.drawee.view.SimpleDraweeView
        android:id=""@+id/group_photo""
        android:layout_width=""48dp""
        android:layout_height=""48dp""
        android:layout_gravity=""center_horizontal""
        fresco:actualImageScaleType=""focusCrop""
        fresco:roundAsCircle=""true""
        fresco:failureImageScaleType=""center""
        fresco:placeholderImage=""@drawable/home_def_type""
        fresco:placeholderImageScaleType=""center""
        fresco:retryImage=""@drawable/home_def_type""
        fresco:retryImageScaleType=""center""
        android:layout_centerVertical=""true""
        android:layout_alignParentLeft=""true""
        android:layout_alignParentStart=""true"" />
","Can you check if your code works without `setResizeOptions` or `fresco:roundAsCircle`?
","@lambdapioneer 
1.Use another phone, when I ResizeOptions (48dp, 48dp), is not displayed.

08-08 18:39:44.655 22076-22076/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433df5d0 null -> 0: initialize
08-08 18:39:44.655 22076-22076/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433df5d0 0: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@433d3b48
08-08 18:39:44.705 22076-22076/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433df5d0 0: onAttach: request needs submit
08-08 18:39:44.710 22076-22076/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433df5d0 0: submitRequest: dataSource: 433e98d0
08-08 18:39:45.350 22076-22076/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433df5d0 0: final_failed @ onFailure: failure: java.lang.RuntimeException: Unsupported color conversion request

2.When I ResizeOptions (80dp, 80dp), increasing the width and height can be displayed

08-08 18:44:49.340 28179-28179/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433e3420 null -> 0: initialize
08-08 18:44:49.340 28179-28179/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433e3420 0: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@433d7960
08-08 18:44:49.385 28179-28179/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433e3420 0: onAttach: request needs submit
08-08 18:44:49.395 28179-28179/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433e3420 0: submitRequest: dataSource: 433ed720
08-08 18:44:50.245 28179-28179/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 433e3420 0: set_final_result @ onNewResult: image: CloseableReference 43414498

3.on SM-G3818Android4.2.2:  When I ResizeOptions (80dp, 80dp)

08-08 18:47:26.648 31142-31142/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 42758920 null -> 0: initialize
08-08 18:47:26.648 31142-31142/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 42758920 0: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@427802c8
08-08 18:47:26.679 31142-31142/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 42758920 0: onAttach: request needs submit
08-08 18:47:26.687 31142-31142/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 42758920 0: submitRequest: dataSource: 4275acc8
08-08 18:47:27.140 31142-31142/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 42758920 0: final_failed @ onFailure: failure: java.lang.RuntimeException: Unsupported color conversion request

4.on SM-G3818Android4.2.2:  

 SimpleDraweeView simpleDraweeView= (SimpleDraweeView) findViewById(R.id.group_photo);
        Uri uri = Uri.parse(""http://dn-runedu-img.qbox.me/5324277294619549696"");
        simpleDraweeView.setImageURI(uri);

08-08 18:52:23.906 5018-5018/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 427540d8 0: onDetach
08-08 18:52:25.953 5018-5018/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 4273ec68 null -> 1: initialize
08-08 18:52:25.953 5018-5018/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 4273ec68 1: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@427709e0
08-08 18:52:25.968 5018-5018/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 4273ec68 1: onAttach: request needs submit
08-08 18:52:25.968 5018-5018/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 4273ec68 1: submitRequest: dataSource: 42805bd8
08-08 18:52:25.992 5018-5018/com.zjcs.myapplication V/unknown:AbstractDraweeController: controller 4273ec68 1: final_failed @ onFailure: failure: java.lang.RuntimeException: Failed to pin Bitmap

Image is a problem or an error set ResizeOptions？？
"
facebook/fresco,https://github.com/facebook/fresco/issues/1294,"`JpegTranscoder.transcodeJpeg()` fails, if the jpeg uses CMYK colors. 

> java.lang.RuntimeException: Unsupported color conversion request
","Does this only happen when downscaling is enabled?
","Exactly, it only happens when scaling is applied. displaying CMYK jpegs without scaling works fine.
"
facebook/fresco,https://github.com/facebook/fresco/issues/1260,"Phone model: lenovo A820t
Android version: 4.1.2
kernel version: 3.4.5
Frseco version: 0.9.0

This phone will crash every time. This is my code

```
        ImagePipelineConfig imagePipelineConfig = ImagePipelineConfig.newBuilder(getApplicationContext())
                .setDecodeMemoryFileEnabled(true)
                .build();
        Fresco.initialize(this, imagePipelineConfig);
```

When I write like this.

```
Fresco.initialize(this);
```

It will be fine.
","Could you provide crash message from logcat ?
","This is my log, if you need more info, you can contact me anytime.

Michał Gregorczyk notifications@github.com于2016年5月31日周二 下午7:59写道：

> Thanks ! Could you provide crash message from logcat ?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/facebook/fresco/issues/1260#issuecomment-222667699,
> or mute the thread
> https://github.com/notifications/unsubscribe/AGJSwVrB8hD-rKcSTiSoVg-YtRVfp3skks5qHCKtgaJpZM4IqQBi
> .

--------- beginning of /dev/log/system

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc1, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc1, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc1, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc1, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc1, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x9d2, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x9d2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x9d2, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x9d2, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x9d2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x9d2, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc2, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc2, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc2, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc2, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc3, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc3, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc3, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc3, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc3, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc3, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc4, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc4, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc4, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc4, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc4, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc4, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc5, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc5, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc5, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc5, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc5, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc5, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc6, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc6, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc6, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc6, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc6, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc6, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc7, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc7, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc7, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc7, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc7, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc7, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc8, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc8, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc8, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc8, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc8, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc8, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc9, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc9, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc9, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fc9, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fc9, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fc9, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fca, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fca, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fca, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fca, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fca, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fca, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcb, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcb, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcb, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcb, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcb, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcb, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcc, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcc, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcc, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcc, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcc, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcc, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcd, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcd, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcd, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcd, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcd, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcd, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fce, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fce, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fce, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fce, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fce, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fce, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcf, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcf, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcf, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fcf, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fcf, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fcf, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd0, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd0, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd0, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd0, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd0, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd0, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd1, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd1, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd1, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd1, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd1, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd1, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd2, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd2, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd2, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd2, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd3, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd3, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd3, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd3, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd3, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd3, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd4, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd4, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd4, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd4, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd4, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd4, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd5, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd5, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd5, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd5, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd5, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd5, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd6, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd6, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd6, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd6, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd6, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd6, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd7, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd7, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd7, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd7, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd7, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd7, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd8, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd8, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd8, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd8, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd8, depth: 0x0, don't query if not necessary!!

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10076

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10076

D/FrameworkListener(  123): dispatchCommand data = (getaddrinfo pmir.3g.qq.com ^ 1024 0 1 0)

D/SocketClient(  123): SocketClient sendDatalocked done: 222

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd8, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd9, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd9, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd9, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fd9, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fd9, depth: 0x0, don't query if not necessary!!

D/PowerManagerService(  637): releaseWakeLock flags=0x1 tag=MediaScannerService total_time=32706ms

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fd9, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fda, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fda, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fda, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fda, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fda, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fda, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdb, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdb, depth: 0x0, don't query if not necessary!!

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10071

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdb, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdb, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdb, depth: 0x0, don't query if not necessary!!

D/FrameworkListener(  123): dispatchCommand data = (getaddrinfo masdk.3g.qq.com ^ 1024 0 1 0)

D/SocketClient(  123): SocketClient sendDatalocked done: 222

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/SocketClient(  123): SocketClient sendDatalocked done: 

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdb, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdc, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdc, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdc, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdc, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdc, depth: 0x0, don't query if not necessary!!

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10076

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdc, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdd, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdd, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdd, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdd, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdd, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdd, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fde, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fde, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fde, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fde, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fde, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fde, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdf, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdf, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdf, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fdf, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fdf, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fdf, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe0, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe0, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe0, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe0, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe0, depth: 0x0, don't query if not necessary!!

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10071

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10068

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10071

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe0, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe1, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe1, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe1, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe1, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe1, depth: 0x0, don't query if not necessary!!

D/PowerManagerService(  637): releaseWakeLock flags=0x1 tag=AlarmManager total_time=3063ms

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe1, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe2, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe2, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe2, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe2, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe2, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe3, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe3, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe3, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe3, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe3, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe3, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe4, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe4, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe4, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe4, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe4, depth: 0x0, don't query if not necessary!!

I/ActivityManager(  637): Process com.ijinshan.ShouJiKongService:perms (pid 4768) has died.

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe4, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe5, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe5, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe5, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe5, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe5, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe5, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe6, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe6, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe6, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe6, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe6, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe6, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe7, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe7, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe7, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe7, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe7, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe7, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe8, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe8, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe8, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe8, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe8, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe8, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe9, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe9, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe9, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fe9, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fe9, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fe9, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/ConnectivityService(  637): getActiveNetworkInfo:NetworkInfo: type: WIFI[], state: CONNECTED/CONNECTED, reason: (unspecified), extra: (none), roaming: false, failover: false, isAvailable: true, simId: 0/10070

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fea, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fea, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fea, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fea, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fea, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fea, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1feb, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1feb, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1feb, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1feb, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1feb, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1feb, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fec, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fec, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fec, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fec, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fec, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fec, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fed, property = 0xdc02

D/MtpPropertyGroup( 1635): createProperty: code = 0xdc02, type = 0x4

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fed, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fed, count = 1

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getObjectPropertyList: handle = 0x1fed, property = 0xffffffff

D/MtpPropertyGroup( 1635): getPropertyList handle: 0x1fed, depth: 0x0, don't query if not necessary!!

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&): handle = 0x1fed, count = 25

D/MtpDatabase_JNI( 1635): virtual android::MtpResponseCode MyMtpDatabase::getObjectPropertyList(android::MtpObjectHandle, uint32_t, uint32_t, int, int, android::MtpDataPacket&) result: 0x2001 

E/MtpServer( 1635): MtpServer::run mFD: 78

D/MtpDatabase( 1635): getOb
"
facebook/fresco,https://github.com/facebook/fresco/issues/1204,"When i try to use SimpleDraweeView.setUri to set a local png file to view.
There's some probability that always get  Problem decoding into existing bitmap
it only occurs when two SimpleDrawwView load same file;
my version is 0.10
![e1578611-a9a6-4e88-85cb-1414571dfaa8](https://cloud.githubusercontent.com/assets/1409727/15202388/603a3c34-182c-11e6-8f73-925715cf5a80.png)
","Can you also give us more context on what oyu have to do in order to reproduce this issue?
",
facebook/fresco,https://github.com/facebook/fresco/issues/1132,"when i use this api set place holder image, it's crashed.

SimpleDraweeView.getHierarchy().setPlaceholderImage(Drawable drawable)

I use last displayed drawable to set a place holder image with next display.

java.lang.StackOverflowError
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:342)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.FadeDrawable.invalidateSelf(FadeDrawable.java:100)
                                                       at com.facebook.drawee.drawable.ArrayDrawable.invalidateDrawable(ArrayDrawable.java:331)
                                                       at android.graphics.drawable.Drawable.invalidateSelf(Drawable.java:344)
                                                       at com.facebook.drawee.drawable.ForwardingDrawable.invalidateDrawable(ForwardingDrawable.java:185)
                                                    at android.gra
","Can you please share a snippet of your code?

You say you're using the last displayed drawable but I wonder if you're somehow setting a drawable inside the same hierarchy twice, creating an infinite loop.
",
facebook/fresco,https://github.com/facebook/fresco/issues/1101,"Initialize Fresco with the application context create a leak, according to LeakCanary.

```
In com.artico.delivery.pedidos:2.0:25.

com.cibersons.monchis.fragments.FranchisesFragment has leaked:
GC ROOT static com.facebook.drawee.backends.pipeline.Fresco.sDraweeControllerBuilderSupplier
references com.facebook.drawee.backends.pipeline.PipelineDraweeControllerBuilderSupplier.mContext
references com.cibersons.monchis.activities.MainActivity.adapter
references com.cibersons.monchis.adapter.TabAdapter.mCurrentPrimaryItem
references com.cibersons.monchis.fragments.MainFragment.mChildFragmentManager
references android.support.v4.app.FragmentManagerImpl.mCreatedMenus
references java.util.ArrayList.array
references array java.lang.Object[].[0]
references com.cibersons.monchis.fragments.CategoriaFragment.tabAdapter
references com.cibersons.monchis.adapter.TabAdapter.mFragments
references java.util.ArrayList.array
references array java.lang.Object[].[0]
leaks com.cibersons.monchis.fragments.FranchisesFragment instance

Reference Key: 369d383f-503a-40d4-9a95-26b8379fe4f0

Device: samsung samsung SM-G355M kanas3gub
Android Version: 4.4.2 API: 19 LeakCanary: 1.3.1
Durations: watch=5062ms, gc=211ms, heap dump=1588ms, analysis=43497ms

Details:

Class com.facebook.drawee.backends.pipeline.Fresco | static $staticOverhead = byte[] [id=0x41c79681;length=24;size=40] | static sDraweeControllerBuilderSupplier = com.facebook.drawee.backends.pipeline.PipelineDraweeControllerBuilderSupplier [id=0x4210b3e0]
Instance of com.facebook.drawee.backends.pipeline.PipelineDraweeControllerBuilderSupplier | mBoundControllerListeners = null | mContext = com.cibersons.monchis.activities.MainActivity [id=0x41ade3a0] | mImagePipeline = com.facebook.imagepipeline.core.ImagePipeline [id=0x4210b400] | mPipelineDraweeControllerFactory = com.facebook.drawee.backends.pipeline.PipelineDraweeControllerFactory [id=0x4210c9c8]
Instance of com.cibersons.monchis.activities.MainActivity 
```
","Can I ask you to double-check the context which is passed to `Fresco.initialize(Context)`?

The details above shows `mContext` (which is set to whatever you pass into that method) has an instance of `com.cibersons.monchis.activities.MainActivity` but I presume that's not your application class.
","@kirwan Hi, I checked one more time and it has to be the application context.
`ImagePipelineConfig config = ImagePipelineConfig.newBuilder(this)
        .setRequestListeners(requestListeners).build();
        Fresco.initialize(this, config);`
These lines are what I have in my application class, the only place where the initialization is done.
Could be something wrong there?
"
facebook/fresco,https://github.com/facebook/fresco/issues/1042,"# anr occurred many times on my app, and in the traces log said something about fresco, please help me  analyze it .look traces log at [ https://github.com/yychai/outOfProject/blob/master/traces.txt](url)
","Can you attach the txt file here on github?
","I'm sorry,and now I put the traces.txt log on [https://github.com/yychai/outOfProject/blob/master/traces.txt](url),
something said about fresco between line170 and line190. please look at it thank you very much.
"
facebook/fresco,https://github.com/facebook/fresco/issues/1033,"I have custom listview. In listview contain 200 items. When i am scrolling fast from top to bottom Or bottom to top listview showing wrong image. If i am scrolling slowly then its work fine.

**SimpleDraweeView in XML :**

``` xml
<com.facebook.drawee.view.SimpleDraweeView
            android:id=""@+id/fake_image_list_group""
            android:layout_width=""match_parent""
            android:layout_height=""@dimen/note_list_item_height""
            android:background=""@android:color/transparent""
            android:contentDescription=""@string/app_name"" />
```

**Set Image URI to SimpleDraweeView :**

``` java
GenericDraweeHierarchy hierarchy = setHierarchyForDraweeView(mImageView, 300);
hierarchy.setPlaceholderImage(new AsyncColorDrawable(context.getResources()));

hierarchy.setFailureImage(mContext.getResources().getDrawable(R.drawable.broken_image_black));
ImageRequest imageRequest = ImageRequestBuilder.newBuilderWithSource(Uri.fromFile(new File(mPath/*local path*/)))
        .setResizeOptions(new ResizeOptions(width, height)) 
        .setLocalThumbnailPreviewsEnabled(true) 
        .build(); 
DraweeController draweeController = Fresco.newDraweeControllerBuilder()
        .setImageRequest(imageRequest) 
        .setOldController(mImageView.getController()) 
        .setAutoPlayAnimations(false) 
        .build(); 
mImageView.setController(draweeController);
```

**SetHierarchyForDraweeView Function :**

``` java
private GenericDraweeHierarchy setHierarchyForDraweeView(SimpleDraweeView draweeView, int duration) {
    if (draweeView != null) {
        if (draweeView.getHierarchy() == null) {
            GenericDraweeHierarchyBuilder builder = new GenericDraweeHierarchyBuilder(mContext.getResources());
            GenericDraweeHierarchy hierarchy = builder
                    .setFadeDuration(duration)
                    .setPlaceholderImage(new AsyncColorDrawable(mContext.getResources())) 
                    .setFailureImage(mContext.getResources().getDrawable(R.drawable.broken_image_black))
                    .build(); 
            draweeView.setHierarchy(hierarchy);
        } else { 
            GenericDraweeHierarchy hierarchy = draweeView.getHierarchy();
            hierarchy.setFadeDuration(duration);
            return hierarchy;
        } 
    } 
    return null; 
}
```

**AsyncColorDrawable Class :**

``` java
private class AsyncColorDrawable extends ColorDrawable {
    public AsyncColorDrawable(Resources res) {
        super(res.getColor(R.color.application_container_background_color));
    } 
}
```

If i did anything wrong please figure it out. Thanks for advance.
I am posting in stackoverflow also please refer below link

http://stackoverflow.com/questions/35770109/fresco-listview-showing-wrong-image-when-fast-scrolling
","Could you capture and share with us logcat output when this happens? http://frescolib.org/docs/troubleshooting.html#investigating-issues-with-logcat
","My Log is 

```
03-08 16:05:28.041 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914078: onProducerStart: {requestId: 172, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.041 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914078: onProducerFinishWithSuccess: {requestId: 172, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.041 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914079: onProducerStart: {requestId: 172, producer: LocalFileFetchProducer}
03-08 16:05:28.051 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5918720); Free = (0, 0)
03-08 16:05:28.051 1848-2129/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (5601038, 65536)
03-08 16:05:28.051 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.051 1848-2129/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.051 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e1854fa 129: set_final_result @ onNewResult: image: CloseableReference 6b45f7f
03-08 16:05:28.051 1848-1848/com.test V/unknown:AbstractDraweeController: controller 5e7f3a2 128: onDetach
03-08 16:05:28.051 1848-1848/com.test V/unknown:AbstractDraweeController: controller 5e7f3a2 128: release: image: CloseableReference 2206c6c6
03-08 16:05:28.051 1848-2129/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.051 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.051 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914087: onProducerFinishWithSuccess: {requestId: 172, producer: LocalFileFetchProducer, elapsedTime: 8 ms, extraMap: null}
03-08 16:05:28.051 1848-2129/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (256a4b34, 65536)
03-08 16:05:28.061 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (118, 5853184); Free = (0, 0)
03-08 16:05:28.061 1848-2343/com.test V/unknown:RequestLoggingListener: time 1147914092: onProducerFinishWithSuccess: {requestId: 170, producer: DecodeProducer, elapsedTime: 43 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.061 1848-2343/com.test V/unknown:BitmapPool: release (free) (object, size) = (1efe36cc, 2868480)
03-08 16:05:28.061 1848-2343/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.061 1848-2135/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/2621f6cf-a2e9-4915-b7e8-3cc222ccafdc_list_portrait.png
03-08 16:05:28.061 1848-2135/com.test V/unknown:RequestLoggingListener: time 1147914094: onProducerStart: {requestId: 172, producer: DecodeProducer}
03-08 16:05:28.061 1848-2343/com.test V/unknown:RequestLoggingListener: time 1147914094: onRequestSuccess: {requestId: 170, elapsedTime: 54 ms}
03-08 16:05:28.061 1848-2345/com.test V/unknown:RequestLoggingListener: time 1147914094: onProducerFinishWithSuccess: {requestId: 171, producer: DecodeProducer, elapsedTime: 25 ms, extraMap: {queueTime=3, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.061 1848-2345/com.test V/unknown:BitmapPool: release (free) (object, size) = (1eb169cd, 2868480)
03-08 16:05:28.061 1848-2345/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.061 1848-2345/com.test V/unknown:RequestLoggingListener: time 1147914095: onRequestSuccess: {requestId: 171, elapsedTime: 41 ms}
03-08 16:05:28.061 1848-2135/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.061 1848-2135/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (b21f7e4, 2868480)
03-08 16:05:28.061 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e1854fa 129: onDetach
03-08 16:05:28.061 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e1854fa 129: setHierarchy: null
03-08 16:05:28.061 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e1854fa 129: release: image: CloseableReference 6b45f7f
03-08 16:05:28.071 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d null -> 132: initialize
03-08 16:05:28.071 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d 132: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@169118a0
03-08 16:05:28.071 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d 132: onAttach: request needs submit
03-08 16:05:28.071 1848-1848/com.test V/unknown:PipelineDraweeController: controller 3556344d: getDataSource
03-08 16:05:28.071 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914103: onRequestSubmit: {requestId: 173, callerContext: null, isPrefetch: false}
03-08 16:05:28.071 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914103: onProducerStart: {requestId: 173, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.071 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914104: onProducerFinishWithSuccess: {requestId: 173, producer: BitmapMemoryCacheGetProducer, elapsedTime: 1 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.071 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914104: onProducerStart: {requestId: 173, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.071 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914104: onProducerFinishWithSuccess: {requestId: 173, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.071 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914104: onProducerStart: {requestId: 173, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.071 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d 132: submitRequest: dataSource: 3a31eb02
03-08 16:05:28.071 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914104: onProducerFinishWithSuccess: {requestId: 173, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.071 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914104: onProducerStart: {requestId: 173, producer: LocalExifThumbnailProducer}
03-08 16:05:28.071 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3e7619dd 130: set_final_result @ onNewResult: image: CloseableReference 5746d76
03-08 16:05:28.081 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914109: onProducerFinishWithSuccess: {requestId: 173, producer: LocalExifThumbnailProducer, elapsedTime: 5 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.081 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914109: onProducerStart: {requestId: 173, producer: ThrottlingProducer}
03-08 16:05:28.081 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914109: onProducerFinishWithSuccess: {requestId: 173, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.081 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914110: onProducerStart: {requestId: 173, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.081 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914110: onProducerFinishWithSuccess: {requestId: 173, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.081 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914110: onProducerStart: {requestId: 173, producer: LocalFileFetchProducer}
03-08 16:05:28.081 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5869568); Free = (0, 0)
03-08 16:05:28.081 1848-2134/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (267dc13, 16384)
03-08 16:05:28.081 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.081 1848-2134/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.081 1848-2134/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.081 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.081 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914112: onProducerFinishWithSuccess: {requestId: 173, producer: LocalFileFetchProducer, elapsedTime: 2 ms, extraMap: null}
03-08 16:05:28.081 1848-2147/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/536be9a3-3d35-4361-bb59-f89f30f146c6_list_portrait.png
03-08 16:05:28.081 1848-2147/com.test V/unknown:RequestLoggingListener: time 1147914113: onProducerStart: {requestId: 173, producer: DecodeProducer}
03-08 16:05:28.081 1848-2147/com.test V/unknown:BitmapPool: Used = (52, 140538936); Free = (0, 0)
03-08 16:05:28.081 1848-2147/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (34dec849, 2868480)
03-08 16:05:28.081 1848-1848/com.test V/unknown:AbstractDraweeController: controller 5e7f3a2 128: setHierarchy: null
03-08 16:05:28.091 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e null -> 133: initialize
03-08 16:05:28.091 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e 133: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@3530fdaa
03-08 16:05:28.091 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e 133: onAttach: request needs submit
03-08 16:05:28.091 1848-2135/com.test V/unknown:RequestLoggingListener: time 1147914122: onProducerFinishWithSuccess: {requestId: 172, producer: DecodeProducer, elapsedTime: 28 ms, extraMap: {queueTime=1, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.091 1848-1848/com.test V/unknown:PipelineDraweeController: controller 1557b54e: getDataSource
03-08 16:05:28.091 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914122: onRequestSubmit: {requestId: 174, callerContext: null, isPrefetch: false}
03-08 16:05:28.091 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914122: onProducerStart: {requestId: 174, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.091 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914122: onProducerFinishWithSuccess: {requestId: 174, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.091 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914122: onProducerStart: {requestId: 174, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.091 1848-2135/com.test V/unknown:BitmapPool: release (free) (object, size) = (d3f81d0, 2868480)
03-08 16:05:28.091 1848-2135/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.091 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e 133: submitRequest: dataSource: 2f425f7c
03-08 16:05:28.091 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914123: onProducerFinishWithSuccess: {requestId: 174, producer: BackgroundThreadHandoffProducer, elapsedTime: 1 ms, extraMap: null}
03-08 16:05:28.091 1848-2135/com.test V/unknown:RequestLoggingListener: time 1147914123: onRequestSuccess: {requestId: 172, elapsedTime: 52 ms}
03-08 16:05:28.091 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914123: onProducerStart: {requestId: 174, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.091 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914123: onProducerFinishWithSuccess: {requestId: 174, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.091 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914123: onProducerStart: {requestId: 174, producer: LocalExifThumbnailProducer}
03-08 16:05:28.091 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914128: onProducerFinishWithSuccess: {requestId: 174, producer: LocalExifThumbnailProducer, elapsedTime: 5 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.091 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914128: onProducerStart: {requestId: 174, producer: ThrottlingProducer}
03-08 16:05:28.091 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914128: onProducerFinishWithSuccess: {requestId: 174, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.091 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914128: onProducerStart: {requestId: 174, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.091 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914128: onProducerFinishWithSuccess: {requestId: 174, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.091 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914128: onProducerStart: {requestId: 174, producer: LocalFileFetchProducer}
03-08 16:05:28.091 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (120, 5902336); Free = (0, 0)
03-08 16:05:28.101 1848-2129/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (2e42a005, 32768)
03-08 16:05:28.101 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.101 1848-2129/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.101 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1a7a795 131: set_final_result @ onNewResult: image: CloseableReference 17ea266f
03-08 16:05:28.101 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3e7619dd 130: onDetach
03-08 16:05:28.101 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3e7619dd 130: setHierarchy: null
03-08 16:05:28.101 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3e7619dd 130: release: image: CloseableReference 5746d76
03-08 16:05:28.101 1848-2129/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.101 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.101 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914137: onProducerFinishWithSuccess: {requestId: 174, producer: LocalFileFetchProducer, elapsedTime: 9 ms, extraMap: null}
03-08 16:05:28.101 1848-2129/com.test V/unknown:NativeMemoryChunkPool: release (reuse) (object, size) = (e1c049c, 4096)
03-08 16:05:28.101 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5898240); Free = (1, 4096)
03-08 16:05:28.101 1848-2129/com.test V/unknown:NativeMemoryChunkPool: release (reuse) (object, size) = (2ffcb602, 8192)
03-08 16:05:28.111 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (118, 5890048); Free = (2, 12288)
03-08 16:05:28.111 1848-2129/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (2fd010ff, 32768)
03-08 16:05:28.111 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (117, 5857280); Free = (2, 12288)
03-08 16:05:28.111 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b null -> 134: initialize
03-08 16:05:28.111 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b 134: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@33042cd1
03-08 16:05:28.111 1848-2136/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/b01dd5bf-2962-4161-b37b-c7069b4eb877_list_portrait.png
03-08 16:05:28.111 1848-2136/com.test V/unknown:RequestLoggingListener: time 1147914140: onProducerStart: {requestId: 174, producer: DecodeProducer}
03-08 16:05:28.111 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b 134: onAttach: request needs submit
03-08 16:05:28.111 1848-1848/com.test V/unknown:PipelineDraweeController: controller 2e9cba8b: getDataSource
03-08 16:05:28.111 1848-2147/com.test V/unknown:RequestLoggingListener: time 1147914141: onProducerFinishWithSuccess: {requestId: 173, producer: DecodeProducer, elapsedTime: 28 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.111 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914141: onRequestSubmit: {requestId: 175, callerContext: null, isPrefetch: false}
03-08 16:05:28.111 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914141: onProducerStart: {requestId: 175, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.111 1848-2136/com.test V/unknown:BitmapPool: Used = (52, 140538936); Free = (0, 0)
03-08 16:05:28.111 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914141: onProducerFinishWithSuccess: {requestId: 175, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.111 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914141: onProducerStart: {requestId: 175, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.111 1848-2136/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (2c13f768, 2868480)
03-08 16:05:28.111 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914141: onProducerFinishWithSuccess: {requestId: 175, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.111 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914141: onProducerStart: {requestId: 175, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.111 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b 134: submitRequest: dataSource: ab12026
03-08 16:05:28.111 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914141: onProducerFinishWithSuccess: {requestId: 175, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.111 1848-2147/com.test V/unknown:BitmapPool: release (free) (object, size) = (38c20fda, 2868480)
03-08 16:05:28.111 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914142: onProducerStart: {requestId: 175, producer: LocalExifThumbnailProducer}
03-08 16:05:28.111 1848-2147/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.111 1848-2147/com.test V/unknown:RequestLoggingListener: time 1147914142: onRequestSuccess: {requestId: 173, elapsedTime: 39 ms}
03-08 16:05:28.111 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d 132: set_final_result @ onNewResult: image: CloseableReference 1c523781
03-08 16:05:28.111 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914146: onProducerFinishWithSuccess: {requestId: 175, producer: LocalExifThumbnailProducer, elapsedTime: 4 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.111 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914146: onProducerStart: {requestId: 175, producer: ThrottlingProducer}
03-08 16:05:28.111 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914146: onProducerFinishWithSuccess: {requestId: 175, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.111 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914146: onProducerStart: {requestId: 175, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.111 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914147: onProducerFinishWithSuccess: {requestId: 175, producer: EncodedMemoryCacheProducer, elapsedTime: 1 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.111 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914147: onProducerStart: {requestId: 175, producer: LocalFileFetchProducer}
03-08 16:05:28.111 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (118, 5873664); Free = (2, 12288)
03-08 16:05:28.111 1848-2134/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (89a7467, 16384)
03-08 16:05:28.111 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.111 1848-2134/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.111 1848-2134/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.111 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.111 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914149: onProducerFinishWithSuccess: {requestId: 175, producer: LocalFileFetchProducer, elapsedTime: 2 ms, extraMap: null}
03-08 16:05:28.121 1848-2173/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/f9101a2e-1903-4277-bcf0-96c66cd2d0c4_list_portrait.png
03-08 16:05:28.121 1848-2173/com.test V/unknown:RequestLoggingListener: time 1147914150: onProducerStart: {requestId: 175, producer: DecodeProducer}
03-08 16:05:28.121 1848-2173/com.test V/unknown:BitmapPool: Used = (52, 140538936); Free = (0, 0)
03-08 16:05:28.121 1848-2173/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (3c69cabd, 2868480)
03-08 16:05:28.121 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 null -> 135: initialize
03-08 16:05:28.121 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 135: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@9cea350
03-08 16:05:28.121 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 135: onAttach: request needs submit
03-08 16:05:28.121 1848-1848/com.test V/unknown:PipelineDraweeController: controller 3fff18b2: getDataSource
03-08 16:05:28.121 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914154: onRequestSubmit: {requestId: 176, callerContext: null, isPrefetch: false}
03-08 16:05:28.121 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914154: onProducerStart: {requestId: 176, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.121 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914154: onProducerFinishWithSuccess: {requestId: 176, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.121 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914154: onProducerStart: {requestId: 176, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.121 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 135: submitRequest: dataSource: 4cff003
03-08 16:05:28.121 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914155: onProducerFinishWithSuccess: {requestId: 176, producer: BackgroundThreadHandoffProducer, elapsedTime: 1 ms, extraMap: null}
03-08 16:05:28.121 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914155: onProducerStart: {requestId: 176, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.121 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914155: onProducerFinishWithSuccess: {requestId: 176, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.121 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914156: onProducerStart: {requestId: 176, producer: LocalExifThumbnailProducer}
03-08 16:05:28.131 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914163: onProducerFinishWithSuccess: {requestId: 176, producer: LocalExifThumbnailProducer, elapsedTime: 7 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.131 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914164: onProducerStart: {requestId: 176, producer: ThrottlingProducer}
03-08 16:05:28.131 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914164: onProducerFinishWithSuccess: {requestId: 176, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.131 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1a7a795 131: onDetach
03-08 16:05:28.131 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914165: onProducerStart: {requestId: 176, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.131 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914165: onProducerFinishWithSuccess: {requestId: 176, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.131 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914165: onProducerStart: {requestId: 176, producer: LocalFileFetchProducer}
03-08 16:05:28.131 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5890048); Free = (2, 12288)
03-08 16:05:28.131 1848-2134/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (cfc4b80, 16384)
03-08 16:05:28.131 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.131 1848-2134/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.131 1848-2134/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.131 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.131 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914168: onProducerFinishWithSuccess: {requestId: 176, producer: LocalFileFetchProducer, elapsedTime: 3 ms, extraMap: null}
03-08 16:05:28.131 1848-2134/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (18931ace, 16384)
03-08 16:05:28.131 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (118, 5873664); Free = (2, 12288)
03-08 16:05:28.131 1848-2344/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/dffa4fb4-f989-4ac9-a77f-3324fff4384a_list_portrait.png
03-08 16:05:28.141 1848-2344/com.test V/unknown:RequestLoggingListener: time 1147914169: onProducerStart: {requestId: 176, producer: DecodeProducer}
03-08 16:05:28.141 1848-2136/com.test V/unknown:RequestLoggingListener: time 1147914173: onProducerFinishWithSuccess: {requestId: 174, producer: DecodeProducer, elapsedTime: 33 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.141 1848-2344/com.test V/unknown:BitmapPool: Used = (53, 143407416); Free = (0, 0)
03-08 16:05:28.141 1848-2344/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (33c20dfe, 2868480)
03-08 16:05:28.141 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1a7a795 131: release: image: CloseableReference 17ea266f
03-08 16:05:28.141 1848-2173/com.test V/unknown:RequestLoggingListener: time 1147914178: onProducerFinishWithSuccess: {requestId: 175, producer: DecodeProducer, elapsedTime: 28 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.141 1848-2136/com.test V/unknown:BitmapPool: release (free) (object, size) = (31074183, 2868480)
03-08 16:05:28.141 1848-2136/com.test V/unknown:BitmapPool: Used = (52, 140538936); Free = (0, 0)
03-08 16:05:28.141 1848-2136/com.test V/unknown:RequestLoggingListener: time 1147914178: onRequestSuccess: {requestId: 174, elapsedTime: 56 ms}
03-08 16:05:28.141 1848-2173/com.test V/unknown:BitmapPool: release (free) (object, size) = (2238ad7e, 2868480)
03-08 16:05:28.141 1848-2173/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.141 1848-2173/com.test V/unknown:RequestLoggingListener: time 1147914179: onRequestSuccess: {requestId: 175, elapsedTime: 38 ms}
03-08 16:05:28.151 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1a7a795 131: setHierarchy: null
03-08 16:05:28.151 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 null -> 136: initialize
03-08 16:05:28.151 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 136: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@2cd6ff87
03-08 16:05:28.151 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 136: onAttach: request needs submit
03-08 16:05:28.151 1848-1848/com.test V/unknown:PipelineDraweeController: controller 16849475: getDataSource
03-08 16:05:28.151 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914188: onRequestSubmit: {requestId: 177, callerContext: null, isPrefetch: false}
03-08 16:05:28.151 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914189: onProducerStart: {requestId: 177, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.161 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914189: onProducerFinishWithSuccess: {requestId: 177, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.161 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914192: onProducerStart: {requestId: 177, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.161 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914193: onProducerFinishWithSuccess: {requestId: 177, producer: BackgroundThreadHandoffProducer, elapsedTime: 1 ms, extraMap: null}
03-08 16:05:28.161 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 136: submitRequest: dataSource: 32d0c0a
03-08 16:05:28.161 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914193: onProducerStart: {requestId: 177, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.161 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914194: onProducerFinishWithSuccess: {requestId: 177, producer: BitmapMemoryCacheProducer, elapsedTime: 1 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.161 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914195: onProducerStart: {requestId: 177, producer: LocalExifThumbnailProducer}
03-08 16:05:28.161 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914198: onProducerFinishWithSuccess: {requestId: 177, producer: LocalExifThumbnailProducer, elapsedTime: 3 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.161 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914198: onProducerStart: {requestId: 177, producer: ThrottlingProducer}
03-08 16:05:28.161 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914198: onProducerFinishWithSuccess: {requestId: 177, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.161 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e 133: set_final_result @ onNewResult: image: CloseableReference 3a57895f
03-08 16:05:28.161 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914199: onProducerStart: {requestId: 177, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.171 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914199: onProducerFinishWithSuccess: {requestId: 177, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.171 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b 134: set_final_result @ onNewResult: image: CloseableReference 219a9fac
03-08 16:05:28.171 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914199: onProducerStart: {requestId: 177, producer: LocalFileFetchProducer}
03-08 16:05:28.171 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d 132: onDetach
03-08 16:05:28.171 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5890048); Free = (2, 12288)
03-08 16:05:28.171 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d 132: setHierarchy: null
03-08 16:05:28.171 1848-2129/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (2ce80a98, 16384)
03-08 16:05:28.171 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3556344d 132: release: image: CloseableReference 1c523781
03-08 16:05:28.171 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.171 1848-2129/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.171 1848-2129/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.171 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.171 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914205: onProducerFinishWithSuccess: {requestId: 177, producer: LocalFileFetchProducer, elapsedTime: 6 ms, extraMap: null}
03-08 16:05:28.171 1848-2344/com.test V/unknown:RequestLoggingListener: time 1147914205: onProducerFinishWithSuccess: {requestId: 176, producer: DecodeProducer, elapsedTime: 36 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.171 1848-2140/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/8dd56a98-3f6a-4b92-b0eb-33903803f4e3_list_portrait.png
03-08 16:05:28.171 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3997ded6 null -> 137: initialize
03-08 16:05:28.171 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3997ded6 137: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@169118a0
03-08 16:05:28.171 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3997ded6 137: onAttach: request needs submit
03-08 16:05:28.171 1848-1848/com.test V/unknown:PipelineDraweeController: controller 3997ded6: getDataSource
03-08 16:05:28.171 1848-2140/com.test V/unknown:RequestLoggingListener: time 1147914208: onProducerStart: {requestId: 177, producer: DecodeProducer}
03-08 16:05:28.171 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914209: onRequestSubmit: {requestId: 178, callerContext: null, isPrefetch: false}
03-08 16:05:28.171 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914209: onProducerStart: {requestId: 178, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.171 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914209: onProducerFinishWithSuccess: {requestId: 178, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.171 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914209: onProducerStart: {requestId: 178, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.181 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3997ded6 137: submitRequest: dataSource: 3e9f3844
03-08 16:05:28.181 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914209: onProducerFinishWithSuccess: {requestId: 178, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.181 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914210: onProducerStart: {requestId: 178, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.181 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914210: onProducerFinishWithSuccess: {requestId: 178, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.181 1848-2344/com.test V/unknown:BitmapPool: release (free) (object, size) = (3d52ee56, 2868480)
03-08 16:05:28.181 1848-2344/com.test V/unknown:BitmapPool: Used = (50, 134801976); Free = (0, 0)
03-08 16:05:28.181 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914213: onProducerStart: {requestId: 178, producer: LocalExifThumbnailProducer}
03-08 16:05:28.181 1848-2140/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.181 1848-2344/com.test V/unknown:RequestLoggingListener: time 1147914214: onRequestSuccess: {requestId: 176, elapsedTime: 60 ms}
03-08 16:05:28.181 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e 133: onDetach
03-08 16:05:28.181 1848-2140/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (3587dd2d, 2868480)
03-08 16:05:28.181 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e 133: setHierarchy: null
03-08 16:05:28.181 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1557b54e 133: release: image: CloseableReference 3a57895f
03-08 16:05:28.181 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914217: onProducerFinishWithSuccess: {requestId: 178, producer: LocalExifThumbnailProducer, elapsedTime: 4 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.181 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914218: onProducerStart: {requestId: 178, producer: ThrottlingProducer}
03-08 16:05:28.181 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914218: onProducerFinishWithSuccess: {requestId: 178, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.181 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914218: onProducerStart: {requestId: 178, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.181 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914218: onProducerFinishWithSuccess: {requestId: 178, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.181 1848-2203/com.test V/unknown:BitmapPool: release (free) (object, size) = (3baff0aa, 2868480)
03-08 16:05:28.181 1848-2203/com.test V/unknown:BitmapPool: Used = (50, 134801976); Free = (0, 0)
03-08 16:05:28.181 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914218: onProducerStart: {requestId: 178, producer: LocalFileFetchProducer}
03-08 16:05:28.191 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e0b1262 null -> 138: initialize
03-08 16:05:28.191 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e0b1262 138: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@3530fdaa
03-08 16:05:28.191 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e0b1262 138: onAttach: request needs submit
03-08 16:05:28.191 1848-1848/com.test V/unknown:PipelineDraweeController: controller 2e0b1262: getDataSource
03-08 16:05:28.191 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914222: onRequestSubmit: {requestId: 179, callerContext: null, isPrefetch: false}
03-08 16:05:28.191 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914222: onProducerStart: {requestId: 179, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.191 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914223: onProducerFinishWithSuccess: {requestId: 179, producer: BitmapMemoryCacheGetProducer, elapsedTime: 1 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.191 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914223: onProducerStart: {requestId: 179, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.191 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914223: onProducerFinishWithSuccess: {requestId: 179, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.191 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e0b1262 138: submitRequest: dataSource: 141cdff3
03-08 16:05:28.191 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914223: onProducerStart: {requestId: 179, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.191 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914224: onProducerFinishWithSuccess: {requestId: 179, producer: BitmapMemoryCacheProducer, elapsedTime: 1 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.191 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914224: onProducerStart: {requestId: 179, producer: LocalExifThumbnailProducer}
03-08 16:05:28.191 1848-2203/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (a11e89e, 32768)
03-08 16:05:28.191 1848-2203/com.test V/unknown:NativeMemoryChunkPool: Used = (118, 5857280); Free = (2, 12288)
03-08 16:05:28.191 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5873664); Free = (2, 12288)
03-08 16:05:28.191 1848-2129/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (57994b0, 16384)
03-08 16:05:28.191 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.191 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914229: onProducerFinishWithSuccess: {requestId: 179, producer: LocalExifThumbnailProducer, elapsedTime: 5 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.191 1848-2129/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.191 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914229: onProducerStart: {requestId: 179, producer: ThrottlingProducer}
03-08 16:05:28.201 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914229: onProducerFinishWithSuccess: {requestId: 179, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.201 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914229: onProducerStart: {requestId: 179, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.201 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914230: onProducerFinishWithSuccess: {requestId: 179, producer: EncodedMemoryCacheProducer, elapsedTime: 1 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.201 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914230: onProducerStart: {requestId: 179, producer: LocalFileFetchProducer}
03-08 16:05:28.201 1848-2129/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.201 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.201 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 135: set_final_result @ onNewResult: image: CloseableReference 3b134557
03-08 16:05:28.201 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b 134: onDetach
03-08 16:05:28.201 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914233: onProducerFinishWithSuccess: {requestId: 178, producer: LocalFileFetchProducer, elapsedTime: 15 ms, extraMap: null}
03-08 16:05:28.201 1848-2343/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/29d3f16a-1d9f-4b97-839b-b965c1339b05_list_portrait.png
03-08 16:05:28.201 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (120, 5906432); Free = (2, 12288)
03-08 16:05:28.201 1848-2343/com.test V/unknown:RequestLoggingListener: time 1147914234: onProducerStart: {requestId: 178, producer: DecodeProducer}
03-08 16:05:28.201 1848-2134/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (2d8bf2ae, 32768)
03-08 16:05:28.201 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.201 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b 134: release: image: CloseableReference 219a9fac
03-08 16:05:28.201 1848-2134/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.201 1848-2343/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.201 1848-2343/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (291b884f, 2868480)
03-08 16:05:28.211 1848-2134/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.211 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.211 1848-2134/com.test I/unknown:TiffUtil: Unsupported orientation
03-08 16:05:28.211 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914242: onProducerFinishWithSuccess: {requestId: 179, producer: LocalFileFetchProducer, elapsedTime: 12 ms, extraMap: null}
03-08 16:05:28.211 1848-2140/com.test V/unknown:RequestLoggingListener: time 1147914243: onProducerFinishWithSuccess: {requestId: 177, producer: DecodeProducer, elapsedTime: 35 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.211 1848-2140/com.test V/unknown:RequestLoggingListener: time 1147914243: onRequestSuccess: {requestId: 177, elapsedTime: 54 ms}
03-08 16:05:28.211 1848-2134/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (201b2b04, 32768)
03-08 16:05:28.211 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5873664); Free = (2, 12288)
03-08 16:05:28.211 1848-2345/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/e896c70b-3224-4b3f-aaad-ced08eb8362f_list_portrait.jpg
03-08 16:05:28.211 1848-2345/com.test V/unknown:RequestLoggingListener: time 1147914246: onProducerStart: {requestId: 179, producer: DecodeProducer}
03-08 16:05:28.211 1848-2345/com.test V/unknown:BitmapPool: Used = (52, 140538936); Free = (0, 0)
03-08 16:05:28.211 1848-2345/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (3e288bba, 2868480)
03-08 16:05:28.221 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e9cba8b 134: setHierarchy: null
03-08 16:05:28.221 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1db25a6b null -> 139: initialize
03-08 16:05:28.221 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1db25a6b 139: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@33042cd1
03-08 16:05:28.221 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1db25a6b 139: onAttach: request needs submit
03-08 16:05:28.221 1848-1848/com.test V/unknown:PipelineDraweeController: controller 1db25a6b: getDataSource
03-08 16:05:28.221 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914257: onRequestSubmit: {requestId: 180, callerContext: null, isPrefetch: false}
03-08 16:05:28.221 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914257: onProducerStart: {requestId: 180, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.221 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914257: onProducerFinishWithSuccess: {requestId: 180, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.221 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914257: onProducerStart: {requestId: 180, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.221 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914257: onProducerFinishWithSuccess: {requestId: 180, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.221 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914258: onProducerStart: {requestId: 180, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.221 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1db25a6b 139: submitRequest: dataSource: 163f49c8
03-08 16:05:28.221 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914258: onProducerFinishWithSuccess: {requestId: 180, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.221 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914258: onProducerStart: {requestId: 180, producer: LocalExifThumbnailProducer}
03-08 16:05:28.231 1848-2343/com.test V/unknown:RequestLoggingListener: time 1147914262: onProducerFinishWithSuccess: {requestId: 178, producer: DecodeProducer, elapsedTime: 28 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.231 1848-2343/com.test V/unknown:BitmapPool: release (free) (object, size) = (138b9173, 2868480)
03-08 16:05:28.231 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914262: onProducerFinishWithSuccess: {requestId: 180, producer: LocalExifThumbnailProducer, elapsedTime: 4 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.231 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914262: onProducerStart: {requestId: 180, producer: ThrottlingProducer}
03-08 16:05:28.231 1848-2343/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.231 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914263: onProducerFinishWithSuccess: {requestId: 180, producer: ThrottlingProducer, elapsedTime: 1 ms, extraMap: null}
03-08 16:05:28.231 1848-2343/com.test V/unknown:RequestLoggingListener: time 1147914263: onRequestSuccess: {requestId: 178, elapsedTime: 54 ms}
03-08 16:05:28.231 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914263: onProducerStart: {requestId: 180, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.231 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914263: onProducerFinishWithSuccess: {requestId: 180, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.231 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914263: onProducerStart: {requestId: 180, producer: LocalFileFetchProducer}
03-08 16:05:28.231 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (120, 5906432); Free = (2, 12288)
03-08 16:05:28.231 1848-2129/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (6c3a986, 32768)
03-08 16:05:28.231 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.241 1848-2129/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 136: set_final_result @ onNewResult: image: CloseableReference 202484e5
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 135: onDetach
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 135: setHierarchy: null
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3fff18b2 135: release: image: CloseableReference 3b134557
03-08 16:05:28.241 1848-2129/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.241 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.241 1848-2345/com.test V/unknown:RequestLoggingListener: time 1147914276: onProducerFinishWithSuccess: {requestId: 179, producer: DecodeProducer, elapsedTime: 30 ms, extraMap: {queueTime=2, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.241 1848-2345/com.test V/unknown:BitmapPool: release (free) (object, size) = (1e5e833a, 2868480)
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d null -> 140: initialize
03-08 16:05:28.241 1848-2345/com.test V/unknown:BitmapPool: Used = (50, 134801976); Free = (0, 0)
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 140: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@9cea350
03-08 16:05:28.241 1848-2345/com.test V/unknown:RequestLoggingListener: time 1147914276: onRequestSuccess: {requestId: 179, elapsedTime: 54 ms}
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 140: onAttach: request needs submit
03-08 16:05:28.241 1848-2129/com.test I/unknown:TiffUtil: Unsupported orientation
03-08 16:05:28.241 1848-1848/com.test V/unknown:PipelineDraweeController: controller 26476b9d: getDataSource
03-08 16:05:28.241 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914277: onProducerFinishWithSuccess: {requestId: 180, producer: LocalFileFetchProducer, elapsedTime: 14 ms, extraMap: null}
03-08 16:05:28.241 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914277: onRequestSubmit: {requestId: 181, callerContext: null, isPrefetch: false}
03-08 16:05:28.241 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914277: onProducerStart: {requestId: 181, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.241 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914277: onProducerFinishWithSuccess: {requestId: 181, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.241 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914277: onProducerStart: {requestId: 181, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.241 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914277: onProducerFinishWithSuccess: {requestId: 181, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.241 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914278: onProducerStart: {requestId: 181, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.241 1848-2129/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (1b6340a6, 32768)
03-08 16:05:28.241 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 140: submitRequest: dataSource: 27a0d812
03-08 16:05:28.241 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5873664); Free = (2, 12288)
03-08 16:05:28.241 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914278: onProducerFinishWithSuccess: {requestId: 181, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.241 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914278: onProducerStart: {requestId: 181, producer: LocalExifThumbnailProducer}
03-08 16:05:28.241 1848-2135/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/38811062-6896-44cd-94bf-9280d47aa0c0_list_portrait.jpg
03-08 16:05:28.241 1848-2135/com.test V/unknown:RequestLoggingListener: time 1147914278: onProducerStart: {requestId: 180, producer: DecodeProducer}
03-08 16:05:28.251 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914279: onProducerFinishWithSuccess: {requestId: 181, producer: LocalExifThumbnailProducer, elapsedTime: 1 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.251 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914279: onProducerStart: {requestId: 181, producer: ThrottlingProducer}
03-08 16:05:28.251 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914280: onProducerFinishWithSuccess: {requestId: 181, producer: ThrottlingProducer, elapsedTime: 1 ms, extraMap: null}
03-08 16:05:28.251 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914280: onProducerStart: {requestId: 181, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.251 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914280: onProducerFinishWithSuccess: {requestId: 181, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.251 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914280: onProducerStart: {requestId: 181, producer: LocalFileFetchProducer}
03-08 16:05:28.251 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (120, 5939200); Free = (2, 12288)
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3997ded6 137: set_final_result @ onNewResult: image: CloseableReference 1a1d8a61
03-08 16:05:28.251 1848-2134/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (363389e0, 65536)
03-08 16:05:28.251 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.251 1848-2134/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.251 1848-2135/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 2e0b1262 138: set_final_result @ onNewResult: image: CloseableReference 229a3247
03-08 16:05:28.251 1848-2135/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (113dabe3, 2868480)
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 136: onDetach
03-08 16:05:28.251 1848-2134/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.251 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.251 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914283: onProducerFinishWithSuccess: {requestId: 181, producer: LocalFileFetchProducer, elapsedTime: 3 ms, extraMap: null}
03-08 16:05:28.251 1848-2134/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (1bc1ffa7, 65536)
03-08 16:05:28.251 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5873664); Free = (2, 12288)
03-08 16:05:28.251 1848-2147/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/bb02e23c-4e79-4fd9-8b33-da9a8632c513_list_portrait.png
03-08 16:05:28.251 1848-2147/com.test V/unknown:RequestLoggingListener: time 1147914285: onProducerStart: {requestId: 181, producer: DecodeProducer}
03-08 16:05:28.251 1848-2147/com.test V/unknown:BitmapPool: Used = (52, 140538936); Free = (0, 0)
03-08 16:05:28.251 1848-2147/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (fb0635e, 2868480)
03-08 16:05:28.251 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914286: onRequestCancellation: {requestId: 181, elapsedTime: 9 ms}
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 140 -> 141: initialize
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 141: onDetach
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 141: setHierarchy: null
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 141: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@9cea350
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 141: onAttach: request needs submit
03-08 16:05:28.251 1848-1848/com.test V/unknown:PipelineDraweeController: controller 26476b9d: getDataSource
03-08 16:05:28.251 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914288: onRequestSubmit: {requestId: 182, callerContext: null, isPrefetch: false}
03-08 16:05:28.251 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914288: onProducerStart: {requestId: 182, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.251 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914288: onProducerFinishWithSuccess: {requestId: 182, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.251 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914288: onProducerStart: {requestId: 182, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 141: submitRequest: dataSource: 2515233f
03-08 16:05:28.251 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914288: onProducerFinishWithSuccess: {requestId: 182, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.251 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914288: onProducerStart: {requestId: 182, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.251 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 136: release: image: CloseableReference 202484e5
03-08 16:05:28.251 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914289: onProducerFinishWithSuccess: {requestId: 182, producer: BitmapMemoryCacheProducer, elapsedTime: 1 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.251 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914289: onProducerStart: {requestId: 182, producer: LocalExifThumbnailProducer}
03-08 16:05:28.261 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914290: onProducerFinishWithSuccess: {requestId: 182, producer: LocalExifThumbnailProducer, elapsedTime: 1 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.261 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914290: onProducerStart: {requestId: 182, producer: ThrottlingProducer}
03-08 16:05:28.261 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914290: onProducerFinishWithSuccess: {requestId: 182, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.261 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914290: onProducerStart: {requestId: 182, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.261 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914290: onProducerFinishWithSuccess: {requestId: 182, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.261 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914290: onProducerStart: {requestId: 182, producer: LocalFileFetchProducer}
03-08 16:05:28.261 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (120, 5939200); Free = (2, 12288)
03-08 16:05:28.261 1848-2129/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (3c77640c, 65536)
03-08 16:05:28.261 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.261 1848-2129/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.261 1848-2129/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (2d681c2c, 16384)
03-08 16:05:28.261 1848-2129/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.261 1848-2129/com.test I/unknown:TiffUtil: Unsupported orientation
03-08 16:05:28.261 1848-2129/com.test V/unknown:RequestLoggingListener: time 1147914292: onProducerFinishWithSuccess: {requestId: 182, producer: LocalFileFetchProducer, elapsedTime: 2 ms, extraMap: null}
03-08 16:05:28.261 1848-2129/com.test V/unknown:NativeMemoryChunkPool: release (free) (object, size) = (83686f9, 65536)
03-08 16:05:28.261 1848-2129/com.test V/unknown:NativeMemoryChunkPool: Used = (119, 5873664); Free = (2, 12288)
03-08 16:05:28.261 1848-2136/com.test V/unknown:RequestLoggingListener: time 1147914293: onProducerStart: {requestId: 182, producer: DecodeProducer}
03-08 16:05:28.261 1848-2136/com.test V/unknown:BitmapPool: Used = (53, 143407416); Free = (0, 0)
03-08 16:05:28.261 1848-2136/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (1a9b576a, 2868480)
03-08 16:05:28.261 1848-2135/com.test V/unknown:RequestLoggingListener: time 1147914298: onProducerFinishWithSuccess: {requestId: 180, producer: DecodeProducer, elapsedTime: 20 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.261 1848-2135/com.test V/unknown:BitmapPool: release (free) (object, size) = (15f5fd60, 2868480)
03-08 16:05:28.261 1848-2135/com.test V/unknown:BitmapPool: Used = (52, 140538936); Free = (0, 0)
03-08 16:05:28.261 1848-2135/com.test V/unknown:RequestLoggingListener: time 1147914299: onRequestSuccess: {requestId: 180, elapsedTime: 42 ms}
03-08 16:05:28.261 1848-1848/com.test V/unknown:AbstractDraweeController: controller 16849475 136: setHierarchy: null
03-08 16:05:28.271 1848-1848/com.test V/unknown:AbstractDraweeController: controller 153cb4f8 null -> 142: initialize
03-08 16:05:28.271 1848-1848/com.test V/unknown:AbstractDraweeController: controller 153cb4f8 142: setHierarchy: com.facebook.drawee.generic.GenericDraweeHierarchy@2cd6ff87
03-08 16:05:28.271 1848-1848/com.test V/unknown:AbstractDraweeController: controller 153cb4f8 142: onAttach: request needs submit
03-08 16:05:28.271 1848-1848/com.test V/unknown:PipelineDraweeController: controller 153cb4f8: getDataSource
03-08 16:05:28.271 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914304: onRequestSubmit: {requestId: 183, callerContext: null, isPrefetch: false}
03-08 16:05:28.271 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914304: onProducerStart: {requestId: 183, producer: BitmapMemoryCacheGetProducer}
03-08 16:05:28.271 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914304: onProducerFinishWithSuccess: {requestId: 183, producer: BitmapMemoryCacheGetProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.271 1848-1848/com.test V/unknown:RequestLoggingListener: time 1147914305: onProducerStart: {requestId: 183, producer: BackgroundThreadHandoffProducer}
03-08 16:05:28.271 1848-1848/com.test V/unknown:AbstractDraweeController: controller 153cb4f8 142: submitRequest: dataSource: 39cccdd1
03-08 16:05:28.271 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914305: onProducerFinishWithSuccess: {requestId: 183, producer: BackgroundThreadHandoffProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.271 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914305: onProducerStart: {requestId: 183, producer: BitmapMemoryCacheProducer}
03-08 16:05:28.271 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914305: onProducerFinishWithSuccess: {requestId: 183, producer: BitmapMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.271 1848-2128/com.test V/unknown:RequestLoggingListener: time 1147914305: onProducerStart: {requestId: 183, producer: LocalExifThumbnailProducer}
03-08 16:05:28.281 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914310: onProducerFinishWithSuccess: {requestId: 183, producer: LocalExifThumbnailProducer, elapsedTime: 5 ms, extraMap: {createdThumbnail=false}}
03-08 16:05:28.281 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914311: onProducerStart: {requestId: 183, producer: ThrottlingProducer}
03-08 16:05:28.281 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914311: onProducerFinishWithSuccess: {requestId: 183, producer: ThrottlingProducer, elapsedTime: 0 ms, extraMap: null}
03-08 16:05:28.281 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914311: onProducerStart: {requestId: 183, producer: EncodedMemoryCacheProducer}
03-08 16:05:28.281 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914311: onProducerFinishWithSuccess: {requestId: 183, producer: EncodedMemoryCacheProducer, elapsedTime: 0 ms, extraMap: {cached_value_found=false}}
03-08 16:05:28.281 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914311: onProducerStart: {requestId: 183, producer: LocalFileFetchProducer}
03-08 16:05:28.281 1848-2134/com.test V/unknown:NativeMemoryChunkPool: Used = (120, 5890048); Free = (2, 12288)
03-08 16:05:28.281 1848-2147/com.test V/unknown:RequestLoggingListener: time 1147914312: onProducerFinishWithSuccess: {requestId: 181, producer: DecodeProducer, elapsedTime: 27 ms, extraMap: {queueTime=1, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.281 1848-2134/com.test V/unknown:NativeMemoryChunkPool: get (alloc) (object, size) = (38f8036, 16384)
03-08 16:05:28.281 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (1, 16384); Free = (1, 16384)
03-08 16:05:28.281 1848-2147/com.test V/unknown:BitmapPool: release (free) (object, size) = (6712b51, 2868480)
03-08 16:05:28.281 1848-2134/com.test V/unknown:GenericByteArrayPool: get (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.281 1848-2147/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.281 1848-2134/com.test V/unknown:GenericByteArrayPool: release (reuse) (object, size) = (37fdaea5, 16384)
03-08 16:05:28.281 1848-2134/com.test V/unknown:GenericByteArrayPool: Used = (0, 0); Free = (2, 32768)
03-08 16:05:28.281 1848-2136/com.test V/unknown:RequestLoggingListener: time 1147914313: onProducerFinishWithSuccess: {requestId: 182, producer: DecodeProducer, elapsedTime: 20 ms, extraMap: {queueTime=0, imageType=DEFAULT, hasGoodQuality=true, bitmapSize=1328x540, isFinal=true}}
03-08 16:05:28.281 1848-2134/com.test V/unknown:RequestLoggingListener: time 1147914313: onProducerFinishWithSuccess: {requestId: 183, producer: LocalFileFetchProducer, elapsedTime: 2 ms, extraMap: null}
03-08 16:05:28.281 1848-2136/com.test V/unknown:BitmapPool: release (free) (object, size) = (2678269a, 2868480)
03-08 16:05:28.281 1848-2136/com.test V/unknown:BitmapPool: Used = (50, 134801976); Free = (0, 0)
03-08 16:05:28.281 1848-2173/com.test V/unknown:DownsampleUtil: Downsample - Specified size: 1328x540, image size: 1328x540 ratio: 1.0 x 1.0, ratio: 1.000 for file:///storage/emulated/0/Android/data/com.test/files/com.test/snapshot/79956d8b-20c0-42dd-8a97-7244d23794a3_list_portrait.png
03-08 16:05:28.281 1848-2173/com.test V/unknown:RequestLoggingListener: time 1147914314: onProducerStart: {requestId: 183, producer: DecodeProducer}
03-08 16:05:28.281 1848-2136/com.test V/unknown:RequestLoggingListener: time 1147914314: onRequestSuccess: {requestId: 182, elapsedTime: 26 ms}
03-08 16:05:28.281 1848-2173/com.test V/unknown:BitmapPool: Used = (51, 137670456); Free = (0, 0)
03-08 16:05:28.281 1848-2173/com.test V/unknown:BitmapPool: get (alloc) (object, size) = (38cb69c2, 2868480)
03-08 16:05:28.281 1848-1848/com.test V/unknown:AbstractDraweeController: controller 26476b9d 141: ignore_old_datasource @ onProgress: failure: null
03-08 16:05:28.281 1848-1848/com.test V/unknown:AbstractDraweeController: controller 1db25a6b 139: set_final_result @ onNewResult: image: CloseableReference 2ec2b45b
03-08 16:05:28.281 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3997ded6 137: onDetach
03-08 16:05:28.291 1848-1848/com.test V/unknown:AbstractDraweeController: controller 3997ded6 137: setHierarchy: null
```
"
facebook/fresco,https://github.com/facebook/fresco/issues/1027,"In the xml file , I edit the code like this:

```
    <com.facebook.drawee.view.SimpleDraweeView
        android:layout_width=""80dp""
        android:layout_height=""80dp""
        android:layout_alignParentBottom=""true""
        android:layout_marginBottom=""6dp""
        android:layout_marginLeft=""12dp""
        fresco:placeholderImage=""@drawable/drawable_u""
        fresco:placeholderImageScaleType=""centerCrop""
        fresco:roundingBorderWidth=""3dp""
        fresco:roundingBorderColor=""@android:color/white""
        fresco:roundAsCircle=""true""
        />
```

but it shows as the follow picture

![screenshot_2016-02-29-17-03-18](https://cloud.githubusercontent.com/assets/6849142/13390040/a6b2fcdc-df06-11e5-8b8e-4c05b7a0f0c6.png)

there is a circle line around this view

as I change the placeholderImage , it show like this

![screenshot_2016-02-29-16-56-06](https://cloud.githubusercontent.com/assets/6849142/13390063/d8c0a698-df06-11e5-9033-ea675379570b.png)

But when I change the roundingBorderWidth to 0dp, the link will disappear.

I think is that the border can't fill with all this view.

My english is not very good ....but,can what i wrote be understood?
","Could you please explain what you mean by ""link will disappear"" ? Is this issue about part of the image being rendered outside of the border ? 
","@michalgr  yes ! It is just like what you say!
"
facebook/fresco,https://github.com/facebook/fresco/issues/1017,"I want to remove the progressive rendering effect of jpg image. So I set ProgressiveRenderingEnabled false. I find the effect still appears.
public ImageRequest buildImageRequest() {
        ImageRequest request;
        if (mUri != null) {
            request = ImageRequestBuilder.newBuilderWithSource(mUri).setAutoRotateEnabled(mIsAutoRotateEnabled)
                    .setResizeOptions(mResizeOptions).setProgressiveRenderingEnabled(false).build();
        } else {
            request = ImageRequestBuilder.newBuilderWithResourceId(mResourceId)
                    .setAutoRotateEnabled(mIsAutoRotateEnabled).setResizeOptions(mResizeOptions).setProgressiveRenderingEnabled(false).build();
        }
        return request;
    }
","Can you debug yourself and see the value? 
","this is my code, 

``` java
public class FrescoView<DH extends DraweeHierarchy> extends View {
    private GenericDraweeHierarchy mHierarchy;
    private DraweeHolder<DH> mDraweeHolder;
    private boolean mInitialised = false;
    private int mDrawableWidth;
    private int mDrawableHeight;
    private Drawable mDrawable;
    private Matrix mDrawMatrix = null;
    private ImageView.ScaleType mScaleType;
    private Matrix mMatrix;
    private RectF mTempSrc = new RectF();
    private RectF mTempDst = new RectF();
    private boolean mIsDownload = false;
    private IFDrawableCallback mDrawableCallback;
    private Context mContext;

    public static void initQView(Context context, boolean isLowMemoryDevice) {
        FrescoImagePipeline.initialize(context, isLowMemoryDevice);
    }

    public FrescoView(Context context) {
        super(context);
        init(context);
    }


    public FrescoView(Context context, AttributeSet attrs) {
        super(context, attrs);
        init(context);
    }

    public FrescoView(Context context, AttributeSet attrs, int defStyleAttr) {
        super(context, attrs, defStyleAttr);
        init(context);
    }

    @TargetApi(Build.VERSION_CODES.LOLLIPOP)
    public FrescoView(Context context, AttributeSet attrs, int defStyleAttr, int defStyleRes) {
        super(context, attrs, defStyleAttr, defStyleRes);
        init(context);
    }

    private void init(Context context) {
        if (!mInitialised) {
            mHierarchy = new GenericDraweeHierarchyBuilder(getResources()).build();
            mDraweeHolder = (DraweeHolder<DH>) DraweeHolder.create(mHierarchy, context);
            mInitialised = true;
            mContext = context;
        }
        mIsDownload = false;
    }


    public DH getHierarchy() {
        return mDraweeHolder.getHierarchy();
    }

    @Override
    public void onStartTemporaryDetach() {
        super.onStartTemporaryDetach();
        mDraweeHolder.onDetach();
    }

    @Override
    public void onFinishTemporaryDetach() {
        super.onFinishTemporaryDetach();
        mDraweeHolder.onAttach();
    }

    @Override
    protected void onAttachedToWindow() {
        super.onAttachedToWindow();
        mDraweeHolder.onAttach();
    }

    @Override
    protected void onDetachedFromWindow() {
        super.onDetachedFromWindow();
        mDraweeHolder.onDetach();
    }

    @SuppressLint(""ClickableViewAccessibility"")
    @Override
    public boolean onTouchEvent(MotionEvent event) {
        return mDraweeHolder.onTouchEvent(event) || super.onTouchEvent(event);
    }

    @Override
    protected boolean verifyDrawable(Drawable who) {
        super.verifyDrawable(who);
        if (who == mDraweeHolder.getTopLevelDrawable()) {
            return true;
        }
        return false;
    }

    public void setDrawableCallback(IFDrawableCallback callback) {
        mDrawableCallback = callback;
        mIsDownload = false;
    }

    public void releaseDrawableCallback() {
        mDrawableCallback = null;
        mIsDownload = false;
    }

    public void setImageRequest(FImageRequest fImageRequest) {
        FLog.data(""isDownload="" + mIsDownload);
        if (fImageRequest != null) {
            int id = fImageRequest.getPlaceHolderResourceId();
            if (id != 0) {
                mHierarchy.setPlaceholderImage(id);
            }
            RoundingParams rp = fImageRequest.buildRoundingParams();
            ImageRequest request = fImageRequest.buildImageRequest();
            FLog.data(""ProgressiveRenderingEnabled=""+request.getProgressiveRenderingEnabled()); // this echo false;
            mHierarchy.setRoundingParams(rp);
            DraweeController controller = Fresco.newDraweeControllerBuilder()
                    .setImageRequest(request).setOldController(mDraweeHolder.getController())
                    .setControllerListener(new ControllerListener<ImageInfo>() {
                        @Override
                        public void onSubmit(String id, Object callerContext) {
                            FLog.data(""onSubmit id="" + id);
                        }

                        @Override
                        public void onFinalImageSet(String id, ImageInfo imageInfo, Animatable animatable) {
                            FLog.data(""onFinalImageSet id="" + id);
                            Drawable drawable = mDraweeHolder.getHierarchy().getTopLevelDrawable();

                            final int oldWidth = mDrawableWidth;
                            final int oldHeight = mDrawableHeight;
                            mDrawable = drawable;
                            updateDrawable(mDrawable);

                            if (oldWidth != mDrawableWidth || oldHeight != mDrawableHeight) {
                                requestLayout();
                            }
                            FHttpExecutor.getHttpExecutor().execute(new Runnable() {
                                @Override
                                public void run() {
                                    if (!mIsDownload && mDrawableCallback != null) {
                                        mDrawableCallback.onSuccess(mDrawable);
                                    }
                                }
                            });
                            mIsDownload = true;
                        }

                        @Override
                        public void onIntermediateImageSet(String id, ImageInfo imageInfo) {
                        }

                        @Override
                        public void onIntermediateImageFailed(String id, Throwable throwable) {
                        }

                        @Override
                        public void onFailure(String id, Throwable throwable) {
                            FLog.data(""onFailure id="" + id);
                            FHttpExecutor.getHttpExecutor().execute(new Runnable() {
                                @Override
                                public void run() {
                                    if (mDrawableCallback != null) {
                                        mDrawableCallback.onFailed();
                                    }
                                }
                            });
                        }

                        @Override
                        public void onRelease(String id) {
                            FLog.data(""onRelease id="" + id);
                            FHttpExecutor.getHttpExecutor().execute(new Runnable() {
                                @Override
                                public void run() {
                                    if (mDrawableCallback != null) {
                                        mDrawableCallback.onRelease();
                                    }
                                }
                            });
                        }
                    })
                    .build();
            mDraweeHolder.setController(controller);
        }
    }

    @SuppressLint(""NewApi"")
    @Override
    protected void onDraw(Canvas canvas) {
        super.onDraw(canvas);
        /*
        Drawable drawable = mDraweeHolder.getHierarchy().getTopLevelDrawable();

        final int oldWidth = mDrawableWidth;
        final int oldHeight = mDrawableHeight;
        mDrawable = drawable;
        updateDrawable(mDrawable);

        if (oldWidth != mDrawableWidth || oldHeight != mDrawableHeight) {
            requestLayout();
        }

        if (mDrawable != null && !mIsDownload && mDrawableCallbacks.size() > 0) {
            for (IFDrawableCallback callback : mDrawableCallbacks) {
                callback.onSuccess(mDrawable);
                mIsDownload = true;
            }
        }*/
        //mDrawable.draw(canvas);
    }

    public Drawable getDrawable() {
        return mDrawable;
    }

    private void updateDrawable(Drawable d) {
        if (d != null) {
            d.setCallback(this);
            if (d.isStateful()) {
                d.setState(getDrawableState());
            }
            d.setVisible(getVisibility() == VISIBLE, true);
            mDrawableWidth = d.getIntrinsicWidth();
            mDrawableHeight = d.getIntrinsicHeight();
            configureBounds();
        } else {
            mDrawableWidth = mDrawableHeight = -1;
        }
    }

    private void configureBounds() {
        if (mDrawable == null) {
            return;
        }

        int dwidth = mDrawableWidth;
        int dheight = mDrawableHeight;
        int vwidth = getWidth() - getPaddingLeft() - getPaddingRight();
        int vheight = getHeight() - getPaddingTop() - getPaddingBottom();

        boolean fits = (dwidth < 0 || vwidth == dwidth) &&
                (dheight < 0 || vheight == dheight);

        if (dwidth <= 0 || dheight <= 0 || ImageView.ScaleType.FIT_XY == mScaleType) {
            mDrawable.setBounds(0, 0, vwidth, vheight);
            mDrawMatrix = null;
        } else {
            mDrawable.setBounds(0, 0, dwidth, dheight);
            if (ImageView.ScaleType.MATRIX == mScaleType) {
                if (mMatrix.isIdentity()) {
                    mDrawMatrix = null;
                } else {
                    mDrawMatrix = mMatrix;
                }
            } else if (fits) {
                mDrawMatrix = null;
            } else if (ImageView.ScaleType.CENTER == mScaleType) {
                mDrawMatrix = mMatrix;
                mDrawMatrix.setTranslate((int) ((vwidth - dwidth) * 0.5f + 0.5f),
                        (int) ((vheight - dheight) * 0.5f + 0.5f));
            } else if (ImageView.ScaleType.CENTER_CROP == mScaleType) {
                mDrawMatrix = mMatrix;
                float scale;
                float dx = 0, dy = 0;

                if (dwidth * vheight > vwidth * dheight) {
                    scale = (float) vheight / (float) dheight;
                    dx = (vwidth - dwidth * scale) * 0.5f;
                } else {
                    scale = (float) vwidth / (float) dwidth;
                    dy = (vheight - dheight * scale) * 0.5f;
                }

                mDrawMatrix.setScale(scale, scale);
                mDrawMatrix.postTranslate((int) (dx + 0.5f), (int) (dy + 0.5f));
            } else if (ImageView.ScaleType.CENTER_INSIDE == mScaleType) {
                mDrawMatrix = mMatrix;
                float scale;
                float dx;
                float dy;

                if (dwidth <= vwidth && dheight <= vheight) {
                    scale = 1.0f;
                } else {
                    scale = Math.min((float) vwidth / (float) dwidth,
                            (float) vheight / (float) dheight);
                }

                dx = (int) ((vwidth - dwidth * scale) * 0.5f + 0.5f);
                dy = (int) ((vheight - dheight * scale) * 0.5f + 0.5f);

                mDrawMatrix.setScale(scale, scale);
                mDrawMatrix.postTranslate(dx, dy);
            } else {
                mTempSrc.set(0, 0, dwidth, dheight);
                mTempDst.set(0, 0, vwidth, vheight);
                mDrawMatrix = mMatrix;
                mDrawMatrix.setRectToRect(mTempSrc, mTempDst, scaleTypeToScaleToFit(mScaleType));
            }
        }
    }

    private static final Matrix.ScaleToFit[] sS2FArray = {
            Matrix.ScaleToFit.FILL,
            Matrix.ScaleToFit.START,
            Matrix.ScaleToFit.CENTER,
            Matrix.ScaleToFit.END
    };

    private static Matrix.ScaleToFit scaleTypeToScaleToFit(ImageView.ScaleType st) {
        return sS2FArray[st.ordinal() - 1];
    }
}
```
"
facebook/fresco,https://github.com/facebook/fresco/issues/992,"I need to make a circular reveal animation after the image is loaded by fresco in my android app. I listen to the download events as described here; http://frescolib.org/docs/listening-download-events.html#_ In the onFinalImageSet event I run the reveal effect as described here; http://developer.android.com/training/material/animations.html

The image is not shown. When I put a debug log to the onFinalImageSet event, I see that it's calling repeatedly. When I comment out the reveal function it's only called once, and works as expected. Somehow reveal effect triggers fresco to load the image over and over.
","can you share the code that you're using? or some logs to show what's happening? http://frescolib.org/docs/troubleshooting.html#setting-up-logcat
","Well I've changed my image loading library for that part of the project. I tried to reproduce it in a sample project and found out a similar problem. I created two activites. First one has a button to start the second one. In the second activity I've the image view with the circular reveal animation. When I start the second activity for the first time, it works fine. But when I press back and start the activity again the image view stays invisible until the animation ends, and just flashes and became visible. Here is the sample code;

```
public class MainActivity extends AppCompatActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        Button btnCircularReveal = (Button)findViewById(R.id.btnCircularReveal);
        btnCircularReveal.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                Intent intent = new Intent(getApplicationContext(), CircularRevealActivity.class);
                startActivity(intent);
            }
        });
    }
}
```

```
public class CircularRevealActivity extends AppCompatActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_circular_reveal);

        setImage();
    }

    private void setImage()
    {
        String url =""http://www.gstatic.com/webp/gallery/1.jpg"";
        SimpleDraweeView simpleDraweeView = (SimpleDraweeView)findViewById(R.id.my_image_view);

        ControllerListener controllerListener = new BaseControllerListener<ImageInfo>() {
            @Override
            public void onFinalImageSet(
                    String id,
                    @Nullable ImageInfo imageInfo,
                    @Nullable Animatable anim) {

                if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {
                    revealImage();
                }
            }

            @Override
            public void onIntermediateImageSet(String id, @Nullable ImageInfo imageInfo) {

            }

            @Override
            public void onFailure(String id, Throwable throwable) {

            }
        };

        DraweeController controller = Fresco.newDraweeControllerBuilder()
                .setControllerListener(controllerListener)
                .setUri(Uri.parse(url))
                .build();
        simpleDraweeView.setController(controller);
    }

    private void revealImage() {
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {
            final SimpleDraweeView simpleDraweeView = (SimpleDraweeView)findViewById(R.id.my_image_view);

            simpleDraweeView.setVisibility(View.INVISIBLE);
            int cx = simpleDraweeView.getWidth() / 2;
            int cy = simpleDraweeView.getHeight() / 2;

            int finalRadius = Math.max(simpleDraweeView.getWidth(), simpleDraweeView.getHeight());

            Animator animator = ViewAnimationUtils.createCircularReveal(simpleDraweeView, cx, cy, 0, finalRadius);
            animator.setDuration(3000);
            animator.addListener(new Animator.AnimatorListener() {
                @Override
                public void onAnimationStart(Animator animation) {
                    simpleDraweeView.setVisibility(View.VISIBLE);
                }

                @Override
                public void onAnimationEnd(Animator animation) {

                }

                @Override
                public void onAnimationCancel(Animator animation) {

                }

                @Override
                public void onAnimationRepeat(Animator animation) {

                }
            });
            animator.start();
        }
    }


}
```

```
<?xml version=""1.0"" encoding=""utf-8""?>
<android.support.design.widget.CoordinatorLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    xmlns:fresco=""http://schemas.android.com/apk/res-auto""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:fitsSystemWindows=""true""
    tools:context=""com.test.frescocircularreveal.CircularRevealActivity"">

    <com.facebook.drawee.view.SimpleDraweeView
        android:id=""@+id/my_image_view""
        android:layout_width=""match_parent""
        android:layout_height=""240dp"" />


</android.support.design.widget.CoordinatorLayout>
```
"
facebook/fresco,https://github.com/facebook/fresco/issues/962,"This is maybe expected behavior, but I can't find where this documented then, I'm trying to implement custom resizing logic for image before sending file out over network (I use Pipeline directly with `imagePipeline.fetchDecodedImage(imageRequest, ...)` and sending bitmap over on the DataSource callback), I expect image rotation happens on the Decoding step before postprocessor takes that decoded `sourceBitmap`, but it is not rotated as exif info suggest. On the other hand if I take postprocessor out and add `setResizingOptions()` instead, the bitmap is rotated correctly on the DataSource callback. Am I missing something? Is there better way to do it?

``` java
        ImageRequest imageRequest = ImageRequestBuilder.newBuilderWithSource(contentURI)
                .setAutoRotateEnabled(true)
                .setPostprocessor(new BasePostprocessor() {
                    @Override
                    public CloseableReference<Bitmap> process(Bitmap sourceBitmap, PlatformBitmapFactory bitmapFactory) {
                        float maxPixels = 1080 * 1080;
                        int originalWidth = sourceBitmap.getWidth();
                        int originalHeight = sourceBitmap.getHeight();
                        float scaleFactor = (Math.min(maxPixels / (originalWidth * originalHeight), 1));
                        CloseableReference<Bitmap> bitmapRef = bitmapFactory.createBitmap(
                                ((int) (originalWidth * scaleFactor)),
                                ((int) (originalHeight * scaleFactor)));
                        try {
                            Bitmap destBitmap = bitmapRef.get();
                            for (int x = 0; x < destBitmap.getWidth(); x++) {
                                for (int y = 0; y < destBitmap.getHeight(); y++) {
                                    destBitmap.setPixel(x, y,
                                            sourceBitmap.getPixel((int) (x / scaleFactor), (int) (y / scaleFactor)));
                                }
                            }
                            return CloseableReference.cloneOrNull(bitmapRef);
                        } finally {
                            CloseableReference.closeSafely(bitmapRef);
                        }
                    }
                })
                .build();
```
","May I see the code in your datasource callback?

Btw, Instead of doing for-loop and `setPixel/getPixel`, it is much more efficient (and the scaling quality will be much better) if you just do something like this:

```
Canvas canvas = new Canvas(destBitmap);
Rect destRect = new Rect(0,0,destBitmap.width(), destBitmap.height());
canvas.drawBitmap(sourceBitmap, null, destRect, paint);
```
","Thanks for this canvas trick, I've been trying to find a better way to transform that bitmap without using android's BitmapFactory, and haven't thought to look in canvas. 
And here is my datasource callback:

``` java
        new BaseBitmapDataSubscriber() {
            @Override
            protected void onNewResultImpl(@Nullable Bitmap bitmap) {
                if (bitmap == null) {
                    return;
                }
                ByteArrayOutputStream stream = null;
                try {
                    stream = new ByteArrayOutputStream();
                    bitmap.compress(Bitmap.CompressFormat.JPEG, AttachmentUtils.QUALITY, stream);
                    byteArray = stream.toByteArray();
                } finally {
                    if (stream != null) {
                        try {
                            stream.close();
                        } catch (IOException e) {
                            Crash.logException(e);
                        }
                    }
                }
            }

            @Override
            protected void onFailureImpl(DataSource<CloseableReference<CloseableImage>> dataSource) {
            }}, new DefaultExecutorSupplier(3).forBackgroundTasks()
```
"
facebook/fresco,https://github.com/facebook/fresco/issues/945,"java.lang.NoClassDefFoundError: com/facebook/drawee/R$styleable
    at com.facebook.drawee.view.GenericDraweeView.inflateHierarchy(GenericDraweeView.java:128)
    at com.facebook.drawee.view.GenericDraweeView.<init>(GenericDraweeView.java:77)
    at com.facebook.drawee.view.SimpleDraweeView.<init>(SimpleDraweeView.java:60)
    at sun.reflect.GeneratedConstructorAccessor124.newInstance(Unknown Source)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
    at org.jetbrains.android.uipreview.ViewLoader.createNewInstance(ViewLoader.java:458)
    at org.jetbrains.android.uipreview.ViewLoader.loadClass(ViewLoader.java:170)
    at org.jetbrains.android.uipreview.ViewLoader.loadView(ViewLoader.java:103)
    at com.android.tools.idea.rendering.LayoutlibCallbackImpl.loadView(LayoutlibCallbackImpl.java:170)
    at android.view.BridgeInflater.loadCustomView(BridgeInflater.java:247)
    at android.view.BridgeInflater.createViewFromTag(BridgeInflater.java:171)
    at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:704)
    at android.view.LayoutInflater.rInflate_Original(LayoutInflater.java:835)
    at android.view.LayoutInflater_Delegate.rInflate(LayoutInflater_Delegate.java:70)
    at android.view.LayoutInflater.rInflate(LayoutInflater.java:811)
    at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)
    at android.view.LayoutInflater.rInflate_Original(LayoutInflater.java:838)
    at android.view.LayoutInflater_Delegate.rInflate(LayoutInflater_Delegate.java:70)
    at android.view.LayoutInflater.rInflate(LayoutInflater.java:811)
    at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)
    at android.view.LayoutInflater.rInflate_Original(LayoutInflater.java:838)
    at android.view.LayoutInflater_Delegate.rInflate(LayoutInflater_Delegate.java:70)
    at android.view.LayoutInflater.rInflate(LayoutInflater.java:811)
    at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)
    at android.view.LayoutInflater.rInflate_Original(LayoutInflater.java:838)
    at android.view.LayoutInflater_Delegate.rInflate(LayoutInflater_Delegate.java:70)
    at android.view.LayoutInflater.rInflate(LayoutInflater.java:811)
    at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)
    at android.view.LayoutInflater.rInflate_Original(LayoutInflater.java:838)
    at android.view.LayoutInflater_Delegate.rInflate(LayoutInflater_Delegate.java:70)
    at android.view.LayoutInflater.rInflate(LayoutInflater.java:811)
    at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)
    at android.view.LayoutInflater.inflate(LayoutInflater.java:515)
    at android.view.LayoutInflater.inflate(LayoutInflater.java:394)
    at com.android.layoutlib.bridge.impl.RenderSessionImpl.inflate(RenderSessionImpl.java:223)
    at com.android.layoutlib.bridge.Bridge.createSession(Bridge.java:426)
    at com.android.ide.common.rendering.LayoutLibrary.createSession(LayoutLibrary.java:350)
    at com.android.tools.idea.rendering.RenderTask$2.compute(RenderTask.java:510)
    at com.android.tools.idea.rendering.RenderTask$2.compute(RenderTask.java:498)
    at com.intellij.openapi.application.impl.ApplicationImpl.runReadAction(ApplicationImpl.java:888)
    at com.android.tools.idea.rendering.RenderTask.createRenderSession(RenderTask.java:498)
    at com.android.tools.idea.rendering.RenderTask.access$600(RenderTask.java:72)
    at com.android.tools.idea.rendering.RenderTask$3.call(RenderTask.java:610)
    at com.android.tools.idea.rendering.RenderTask$3.call(RenderTask.java:607)
    at com.android.tools.idea.rendering.RenderService.runRenderAction(RenderService.java:362)
    at com.android.tools.idea.rendering.RenderTask.render(RenderTask.java:607)
    at com.android.tools.idea.rendering.RenderTask.render(RenderTask.java:629)
    at org.jetbrains.android.uipreview.AndroidLayoutPreviewToolWindowManager.doRender(AndroidLayoutPreviewToolWindowManager.java:652)
    at org.jetbrains.android.uipreview.AndroidLayoutPreviewToolWindowManager.access$1700(AndroidLayoutPreviewToolWindowManager.java:80)
    at org.jetbrains.android.uipreview.AndroidLayoutPreviewToolWindowManager$7$1.run(AndroidLayoutPreviewToolWindowManager.java:594)
    at com.intellij.openapi.progress.impl.CoreProgressManager$2.run(CoreProgressManager.java:152)
    at com.intellij.openapi.progress.impl.CoreProgressManager.registerIndicatorAndRun(CoreProgressManager.java:452)
    at com.intellij.openapi.progress.impl.CoreProgressManager.executeProcessUnderProgress(CoreProgressManager.java:402)
    at com.intellij.openapi.progress.impl.ProgressManagerImpl.executeProcessUnderProgress(ProgressManagerImpl.java:54)
    at com.intellij.openapi.progress.impl.CoreProgressManager.runProcess(CoreProgressManager.java:137)
    at org.jetbrains.android.uipreview.AndroidLayoutPreviewToolWindowManager$7.run(AndroidLayoutPreviewToolWindowManager.java:589)
    at com.intellij.util.ui.update.MergingUpdateQueue.execute(MergingUpdateQueue.java:320)
    at com.intellij.util.ui.update.MergingUpdateQueue.execute(MergingUpdateQueue.java:310)
    at com.intellij.util.ui.update.MergingUpdateQueue$2.run(MergingUpdateQueue.java:254)
    at com.intellij.util.ui.update.MergingUpdateQueue.flush(MergingUpdateQueue.java:269)
    at com.intellij.util.ui.update.MergingUpdateQueue.flush(MergingUpdateQueue.java:227)
    at com.intellij.util.ui.update.MergingUpdateQueue.run(MergingUpdateQueue.java:217)
    at com.intellij.util.concurrency.QueueProcessor.runSafely(QueueProcessor.java:238)
    at com.intellij.util.Alarm$Request$1.run(Alarm.java:351)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
","What version of Fresco?
",
facebook/fresco,https://github.com/facebook/fresco/issues/929,"Steps: 
1 - launch application with target 23 on Android 6
2 - adb shell bmgr fullbackup PACKAGE
3 - adb shell bmgr restore PACKAGE
4 - launch application - crash

Library initialized in Application class in onCreate

```
  Caused by: android.view.InflateException: Binary XML file line #79: Binary XML file line #31: Binary XML file line #7: Binary XML file line #7: Error inflating class com.facebook.drawee.view.SimpleDraweeView
                                                       at android.view.LayoutInflater.inflate(LayoutInflater.java:539)
                                                       at android.view.LayoutInflater.inflate(LayoutInflater.java:423)
                                                       at android.view.LayoutInflater.inflate(LayoutInflater.java:374)
                                                       at android.support.v7.app.AppCompatDelegateImplV7.setContentView(AppCompatDelegateImplV7.java:256)
                                                       at android.support.v7.app.AppCompatActivity.setContentView(AppCompatActivity.java:109)
```
","Can you provide the piece of XML that specifies SimpleDraweeView?
",
facebook/fresco,https://github.com/facebook/fresco/issues/908,"I have the same issue as in the #236.

But the solution provided did not work - i have a FLICKER when replacing the image.

First, I load the thumbnail. After that (on user action) I start loading the original image with low res image request set to thumbnail (that is already loaded). But I have the flicker anyway.

Is there any way to just keep the existing image and set the new one when it is ready?

P.S. Please note that I am also resizing the original image (replacing datasource could be tricky)
","Can you make sure that all the options specified in the thumbnail request and the low res request are exactly the same ? Here is the list of things that needs to match in order for bitmap cache hit (bitmap cache hit = no flicker): https://github.com/facebook/fresco/blob/0f3d52318631f2125e080d2a19f6fa13a31efb31/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/BitmapMemoryCacheKey.java#L39

Also, you do you use post-processors by any chance ?
","The two requests are exactly the same. And I also use the postprocessor for blurring. Here are the codes:

Thumbnail Request: (initially thumbnail is displayed)

```
    ImageRequest request = ImageRequestBuilder.newBuilderWithSource(Uri.parse(thumbUrl))
            .setResizeOptions(new ResizeOptions(thumbnailSize, thumbnailSize))
            .setPostprocessor(new BlurPostprocessor(App.getContext()))
            .build();
```

After that I load the original image (from disk) and set the following low image request:

```
    if (thumbUrl != null) {
        ImageRequest thumbRequest = ImageRequestBuilder.newBuilderWithSource(Uri.parse(thumbUrl))
                .setResizeOptions(new ResizeOptions(thumbnailSize, thumbnailSize))
                .setPostprocessor(new BlurPostprocessor(App.getContext()))
                .build();
        controllerBuilder.setLowResImageRequest(thumbRequest);
    }
```

Thumbnail size:

```
    int thumbnailSize = LayoutHelper.dpToPx(100);
```

And the cache related methods of the BlurPostprocessor:

```
@Override
public String getName() {
    return getClass().getSimpleName();
}

@Override
public CacheKey getPostprocessorCacheKey() {
    return new SimpleCacheKey(""radius="" + radius + "",sampling="" + sampling);
}
```

I am also using listeners for requests, but I don't think this can make any difference.
"
facebook/fresco,https://github.com/facebook/fresco/issues/876,"I had trouble with auto-rotating pictures with orientation in their exif, but figured out that downsampling was causing troubles. 
","Can you elaborate? What was the problem? And what version of Fresco are you using?
","I am using 0.8.1. 
I had problem with loading images from phone gallery on some devices - some images would show up rotated by 90 degrees. I figured out that images that have 90 or 270 (i.e portrait orientation) in their exif would show up horizontally. I read that fresco can auto-rotate images, so I tried setting .setAutoRotateEnabled(true), but it didn't have any effect. So I just started to experiment with fresco settings and figured out that setting .setDownsampleEnabled(false) solved that problem. 
"
facebook/fresco,https://github.com/facebook/fresco/issues/865,"java.lang.OutOfMemoryError

at com.facebook.imagepipeline.memory.GenericByteArrayPool.alloc(GenericByteArrayPool.java:67)
at com.facebook.imagepipeline.memory.GenericByteArrayPool.alloc(GenericByteArrayPool.java:29)
at com.facebook.imagepipeline.memory.BasePool.get(BasePool.java:259)
at com.facebook.imagepipeline.memory.FlexByteArrayPool.get(FlexByteArrayPool.java:51)
at com.facebook.imagepipeline.platform.KitKatPurgeableDecoder.decodeJPEGByteArrayAsPurgeable(KitKatPurgeableDecoder.java:85)
at com.facebook.imagepipeline.platform.DalvikPurgeableDecoder.decodeJPEGFromEncodedImage(DalvikPurgeableDecoder.java:89)
at com.facebook.imagepipeline.platform.KitKatPurgeableDecoder.decodeJPEGFromEncodedImage(KitKatPurgeableDecoder.java:32)
at com.facebook.imagepipeline.decoder.ImageDecoder.decodeJpeg(ImageDecoder.java:151)
at com.facebook.imagepipeline.decoder.ImageDecoder.decodeImage(ImageDecoder.java:85)
at com.facebook.imagepipeline.producers.DecodeProducer$ProgressiveDecoder.doDecode(DecodeProducer.java:188)
at com.facebook.imagepipeline.producers.DecodeProducer$ProgressiveDecoder.access$200(DecodeProducer.java:96)
at com.facebook.imagepipeline.producers.DecodeProducer$ProgressiveDecoder$1.run(DecodeProducer.java:128)
at com.facebook.imagepipeline.producers.JobScheduler.doJob(JobScheduler.java:207)
at com.facebook.imagepipeline.producers.JobScheduler.access$000(JobScheduler.java:27)
at com.facebook.imagepipeline.producers.JobScheduler$1.run(JobScheduler.java:78)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1076)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:569)
at com.facebook.imagepipeline.core.PriorityThreadFactory$1.run(PriorityThreadFactory.java:43)
at java.lang.Thread.run(Thread.java:856)

The problem occurs when the list is sliding fast.
Fresco 0.8.1
","how many of those are showing on a screen at the same time?
","setResizeOptions(new ResizeOptions(200, 200))   I've already done it.
"
facebook/fresco,https://github.com/facebook/fresco/issues/862,"Hello,

Erasing cache from android app manager make  prefetchToDiskCache() have a strange behavior : some uris are not fetched thus dataSource is called and return isFinished().

Goal : prefetchToDiskCache() for a list of Uris

1 - On first install and first run of app : all uris are well prefetched.

2 - Go to Android app manager and erase cache (not app data)

3 - relaunch prefetchToDiskCache() : some uris return isFinished() threw BaseDataSubscriber and onNewResultImpl() thus nothing has been downloaded. Always 16 uris from a list of 52 uris.

for (int i = 0; i < finalListNotInCache_2.length(); i++) {
            JSONObject json_obj = null;
            try {
                json_obj = finalListNotInCache_2.getJSONObject(i);
            } catch (JSONException e) {
                e.printStackTrace();
            }
           Uri urlImage = null;
            try {
                urlImage = Uri.parse(json_obj.getString(""IMAGE""));
            } catch (JSONException e) {
                e.printStackTrace();
            }
            ImagePipeline imagePipeline = Fresco.getImagePipeline();
            ImageRequest request = ImageRequestBuilder
                    .newBuilderWithSource(urlImage)
                    .setResizeOptions(new ResizeOptions(4096, 4096)
                    .build();
            //initiate prefetch
            `DataSource<Void> prefetchDataSource = imagePipeline.prefetchToDiskCache(request, this);`
        Log.d(""TEST PREFETCH_1"", String.valueOf(prefetchDataSource) + "" url: "" + String.valueOf(urlImage));

```
        final Uri finalUrlImage = urlImage;

        DataSubscriber<Void> subscriber = new BaseDataSubscriber<Void>() {
            @Override
            protected void onNewResultImpl(DataSource<Void> prefetchDataSource) {
                if (!prefetchDataSource.isFinished()) {
                    Log.d(""TEST PROGRESS_1 : "", String.valueOf(prefetchDataSource) + ""progress :"" + String.valueOf(prefetchDataSource.getProgress()) + "" url: "" + String.valueOf(countImages) + "" - "" + finalUrlImage);
                    return;
                }
                addOneMoreImage(); // ajoute 1 au compteur d'images countImages
                Log.d(""TEST PROGRESS_2 : "", String.valueOf(prefetchDataS`ource) + "" url: "" + String.valueOf(countImages) + "" - "" + finalUrlImage);
                tvNombreImagesInCache.setText(String.valueOf(nombreImagesInCache + countImages));
                tvNombreImagesNotInCache.setText(String.valueOf(nombreImagesNotInCache - countImages));
                prefetchDataSource.close();
                if (prefetchDataSource.isClosed()) {

                    Log.d(""TEST_IS_CLOSED_2 : "", String.valueOf(prefetchDataSource) + "" url: "" + String.valueOf(countImages) + "" - "" + finalUrlImage);

                }


            }

            @Override
            protected void onFailureImpl(DataSource<Void> dataSource) {
                Throwable t = dataSource.getFailureCause();
                Log.d(""TEST FAILURE : "", "" url: "" + finalUrlImage + ""T :"" + t);
                // handle failure

            }

        };
        prefetchDataSource.subscribe(subscriber, UiThreadImmediateExecutorService.getInstance());  //CallerThreadExecutor.getInstance() utilise UI pour update compteurs - UiThreadImmediateExecutorService.getInstance()

       }
```

Is there something I missed ?

Greatings,
Eric
","Can you try resizing to something much smaller? 4096 is huge, and may mean that there isn't space for all of the images that you are trying to prefetch. 
","Hello,

I'm logging all request now, with okHttp interceptors and log, tcpflow to webserver side.
Some urls aren't fetched and no request are send from Fresco. But, com.facebook.imagepipeline.datasource.ProducerToDataSourceAdapter onNewResultImpl() return isFinished() and datasource is closed.

For example, for a well fetched file : 
adb logs :

> 01-05 15:24:24.189 1073-1073/tld.domain.appname D/TEST PREFETCH_1: com.facebook.imagepipeline.datasource.ProducerToDataSourceAdapter@408d7170 url: http://www.domain.tld/LAMAILLE/alose.jpg
> 01-05 15:24:24.259 1073-2390/tld.domain.appname V/unknown:BufferedDiskCache: Did not find image for http://www.domain.tld/LAMAILLE/alose.jpg in staging area
> 01-05 15:24:24.259 1073-2390/tld.domain.appname V/unknown:BufferedDiskCache: Disk cache read for http://www.domain.tld/LAMAILLE/alose.jpg
> 01-05 15:24:24.259 1073-2390/tld.domain.appname V/unknown:BufferedDiskCache: Disk cache miss for http://www.domain.tld/LAMAILLE/alose.jpg
> 01-05 15:24:24.269 1073-14875/tld.domain.appname D/unknown:TEST_OKHTTP_1: Sending request http://www.domain.tld/LAMAILLE/alose.jpg on null
>                                                                                      Cache-Control: no-store
> 01-05 15:24:24.329 1073-14875/tld.domain.appname D/unknown:TEST_OKHTTP_2: Received response for http://www.domain.tld/LAMAILLE/alose.jpg in 55.0ms
>                                                                                      Date: Tue, 05 Jan 2016 14:15:14 GMT
>                                                                                      Server: Apache/2.2.22
>                                                                                      Content-Length: 238724
>                                                                                      Etag: W/""PSA-aj-vgvDVpQ3zG""
>                                                                                      Expires: Sun, 03 Jul 2016 13:31:21 GMT
>                                                                                      Cache-Control: max-age=15549367
>                                                                                      Vary: Accept
>                                                                                      X-Content-Type-Options: nosniff
>                                                                                      Keep-Alive: timeout=2
>                                                                                      Connection: Keep-Alive
>                                                                                      Content-Type: image/webp
>                                                                                      OkHttp-Selected-Protocol: http/1.1
>                                                                                      OkHttp-Sent-Millis: 1452003864296
>                                                                                      OkHttp-Received-Millis: 1452003864338
> 01-05 15:24:50.439 1073-2390/tld.domain.appname V/unknown:BufferedDiskCache: About to write to disk-cache for key http://www.domain.tld/LAMAILLE/alose.jpg
> 01-05 15:24:50.449 1073-1073/tld.domain.appname D/TEST PROGRESS_2 :: com.facebook.imagepipeline.datasource.ProducerToDataSourceAdapter@408d7170 url: 20 - http://www.domain.tld/LAMAILLE/alose.jpg
> 01-05 15:24:50.449 1073-1073/tld.domain.appname D/TEST_IS_CLOSED_2 :: com.facebook.imagepipeline.datasource.ProducerToDataSourceAdapter@408d7170 url: 20 - http://www.domain.tld/LAMAILLE/alose.jpg
> 01-05 15:24:50.519 1073-2390/tld.domain.appname V/unknown:BufferedDiskCache: Successful disk-cache write for key http://www.domain.tld/LAMAILLE/alose.jpg`

tcpflow logs :

> 192.168.001.001.56737-192.168.001.002.00080: GET /LAMAILLE/alose.jpg HTTP/1.1
> Cache-Control: no-store
> Host:  www.domain.tld
> Connection: Keep-Alive
> Accept-Encoding: gzip
> User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36 LaMaille/1.1
> Accept: image/webp,image/_,_/*;q=0.8
> 
> 192.168.001.001.33459-192.168.001.002.00080: GET /LAMAILLE/alose.jpg HTTP/1.1
> Cache-Control: no-store
> Host: www.domain.tld
> Connection: Keep-Alive
> Accept-Encoding: gzip
> User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36 LaMaille/1.1
> Accept: image/webp,image/_,_/*;q=0.8
> 192.168.001.002.00080-192.168.001.001.33459: HTTP/1.1 200 OK
> (...)

and a non well fetched file :
adb logs :

> 01-05 15:24:24.249 1073-1073/tld.domain.appname D/TEST PREFETCH_1: com.facebook.imagepipeline.datasource.ProducerToDataSourceAdapter@4082bda8 url: http://www.domain.tld/LAMAILLE/seiche_sepia_officinalis-2.jpg
> 01-05 15:24:39.039 1073-1073/tld.domain.appname D/TEST PROGRESS_2 :: com.facebook.imagepipeline.datasource.ProducerToDataSourceAdapter@4082bda8 url: 17 - http://www.domain.tld/LAMAILLE/seiche_sepia_officinalis-2.jpg
> 01-05 15:24:39.039 1073-1073/tld.domain.appname D/TEST_IS_CLOSED_2 :: com.facebook.imagepipeline.datasource.ProducerToDataSourceAdapter@4082bda8 url: 17 - http://www.domain.tld/LAMAILLE/seiche_sepia_officinalis-2.jpg

tcpflow logs : nothing

Thanks,

Eric
"
facebook/fresco,https://github.com/facebook/fresco/issues/838,"![jp479 tj0j _q vu3 s](https://cloud.githubusercontent.com/assets/1498653/11803725/75442126-a338-11e5-929a-72e2efd72373.png)

some android telephone will has this issue.
1. the view was set as ""Crop"" and loading animated image(like gif).
2. when rotate the view, it will happen to see the image out of view rect
","What kind of rotation animation did you implement?
Thanks
","Hello,
For example: 
1、an animated gif file（320x320）
2、the fresco view width=320, height=200, set as crop
3、the gif is playing, view.setRotation(45)
some telephone will see this issue. (the image will showing out of the view rect)
"
facebook/fresco,https://github.com/facebook/fresco/issues/823,"I got the exception:

```
E/StrictMode: A resource was acquired at attached stack trace but never released. See java.io.Closeable for information on avoiding resource leaks.
                                                            java.lang.Throwable: Explicit termination method 'close' not called
                                                                at dalvik.system.CloseGuard.open(CloseGuard.java:180)
                                                                at android.content.ContentResolver$CursorWrapperInner.<init>(ContentResolver.java:2507)
                                                                at android.content.ContentResolver.query(ContentResolver.java:515)
                                                                at android.content.ContentResolver.query(ContentResolver.java:434)
                                                                at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer.getRealPathFromUri(LocalExifThumbnailProducer.java:149)
                                                                at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer.getExifInterface(LocalExifThumbnailProducer.java:112)
                                                                at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer$1.getResult(LocalExifThumbnailProducer.java:81)
                                                                at com.facebook.imagepipeline.producers.LocalExifThumbnailProducer$1.getResult(LocalExifThumbnailProducer.java:75)
                                                                at com.facebook.common.executors.StatefulRunnable.run(StatefulRunnable.java:45)
                                                                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
                                                                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
                                                                at java.lang.Thread.run(Thread.java:818)
```
","Which version of Fresco do you use ?
",
facebook/fresco,https://github.com/facebook/fresco/issues/819,"![zshlo2hpx](https://cloud.githubusercontent.com/assets/1539296/11662136/e8e6befa-9ddd-11e5-910c-bbfd0323bf10.png)
Some images have those distinctive stripes on them. I can provide original photo if needed
","What version of fresco do you use ? Can you show us the code (java/xml) that configures SimpleDraweeView ?
",
facebook/fresco,https://github.com/facebook/fresco/issues/805,"Fresco can not get the correct format of some images that I can open in my laptop.
Here is the error log:

```
12-01 16:35:11.535 29714-29887/io.egg.now.alpha V/unknown:BufferedDiskCache: Successful read from disk cache for http://xxx.xxx.xxx/d/8d653663fc7d4406980a16bae1409132/151130?_upp=2&_upt=8b58d32f1449062748
12-01 16:35:11.535 29714-29887/io.egg.now.alpha V/unknown:RequestLoggingListener: time 95579973: onProducerFinishWithSuccess: {requestId: 52, producer: DiskCacheProducer, elapsedTime: 5 ms, extraMap: {cached_value_found=true}}
12-01 16:35:11.536 29714-29887/io.egg.now.alpha D/skia: --- SkImageDecoder::Factory returned null
12-01 16:35:11.536 29714-29889/io.egg.now.alpha V/unknown:RequestLoggingListener: time 95579974: onProducerStart: {requestId: 52, producer: DecodeProducer}
12-01 16:35:11.536 29714-29889/io.egg.now.alpha W/unknown:RequestLoggingListener: time 95579974: onProducerFinishWithFailure: {requestId: 52, stage: DecodeProducer, elapsedTime: 0 ms, extraMap: {hasGoodQuality=true, queueTime=0, isFinal=true}, throwable: java.lang.IllegalArgumentException: unknown image format}
12-01 16:35:11.536 29714-29889/io.egg.now.alpha W/unknown:RequestLoggingListener: time 95579974: onRequestFailure: {requestId: 52, elapsedTime: 11 ms, throwable: java.lang.IllegalArgumentException: unknown image format}
12-01 16:35:11.777 29714-29714/io.egg.now.alpha V/unknown:AbstractDraweeController: controller 24cccc28 38: final_failed @ onFailure: failure: java.lang.IllegalArgumentException: unknown image format
```
","Can you give us more information about those images? If you can upload one of them that would be very useful. If you can't upload it, if you could extract first couple (say 100) of bytes of the file, with some Hex editor, that would be also be helpful.
","I try to delete the cache directory,  and those images can be displayed correctly without errors. I guess Fresco caches the dirty data in the disk for unknown reason. It is better to clear the cached data if an error has occurred.
"
facebook/fresco,https://github.com/facebook/fresco/issues/790,"AnimatedDrawable ignores setDither() and setFilterBitmap(), it does not override the methods and does not set it to it's mPaint.

AnimatedDrawable should override

```
  @Override
  public void setDither(final boolean dither) {
    mPaint.setDither(dither);
    doInvalidateSelf();
  }

  @Override
  public void setFilterBitmap(final boolean filterBitmap) {
    mPaint.setFilterBitmap(filterBitmap);
    doInvalidateSelf();
  }
```

It is essential for my project images to disable it.
Currently I use very-very ugly reflection to find AniamtedDrawable in DraweeHierarchy to do this.
","Do you have any idea how to test it?
","Hi,
Thanks for the reply.

I set DrawableParams in onFinalImageSet().
The top level drawable is a ForwardingDrawable so it will automatically forward the parameters down to ArrayDrawable, which will automatically forward it to mLayers (which are AnimatedDrawable).

Set a small Drawable into the target ImageView. It should be pixelated and not blurry when working.

```
import com.facebook.drawee.backends.pipeline.PipelineDraweeControllerBuilder;
import com.facebook.drawee.controller.ControllerListener;
import com.facebook.drawee.generic.GenericDraweeHierarchy;
import com.facebook.drawee.interfaces.SimpleDraweeControllerBuilder;
import com.facebook.drawee.view.SimpleDraweeView;
import com.facebook.imagepipeline.image.ImageInfo;

import android.annotation.TargetApi;
import android.content.Context;
import android.graphics.drawable.Animatable;
import android.net.Uri;
import android.os.Build;
import android.support.annotation.Nullable;
import android.util.AttributeSet;

public class PixelatedSimpleDraweeView extends SimpleDraweeView
        implements ControllerListener<ImageInfo> {

    private final DrawableProperties mDrawableProperties = new DrawableProperties();

    public PixelatedDraweeView(final Context context,
            final GenericDraweeHierarchy hierarchy) {
        super(context, hierarchy);
        init();
    }

    public PixelatedDraweeView(final Context context) {
        super(context);
        init();
    }

    public PixelatedDraweeView(final Context context, final AttributeSet attrs) {
        super(context, attrs);
        init();
    }

    public PixelatedDraweeView(final Context context, final AttributeSet attrs,
            final int defStyle) {
        super(context, attrs, defStyle);
        init();
    }

    @TargetApi(Build.VERSION_CODES.LOLLIPOP)
    public PixelatedDraweeView(final Context context, final AttributeSet attrs,
            final int defStyleAttr, final int defStyleRes) {
        super(context, attrs, defStyleAttr, defStyleRes);
        init();
    }

    private void init() {
        mDrawableProperties.setDither(false);
        mDrawableProperties.setFilterBitmap(false);
    }

    /**
     * Displays an image given by the uri.
     *
     * @param uri uri of the image
     */
    @Override
    public void setImageURI(@Nullable final Uri uri) {
        setImageURI(uri, null);
    }

    /**
     * Displays an image given by the uri.
     *
     * @param uri           uri of the image
     * @param callerContext caller context
     */
    public void setImageURI(@Nullable final Uri uri, @Nullable final Object callerContext) {
        final SimpleDraweeControllerBuilder builder = getControllerBuilder()
                .setCallerContext(callerContext)
                .setUri(uri)
                .setOldController(getController());
        if (builder instanceof PipelineDraweeControllerBuilder) {
            ((PipelineDraweeControllerBuilder) builder).setControllerListener(this);
            ((PipelineDraweeControllerBuilder) builder).setAutoPlayAnimations(true);
        }
        setController(builder.build());
    }

    @Override
    public void onSubmit(final String id, final Object callerContext) {
    }

    @Override
    public void onFinalImageSet(final String id, @Nullable final ImageInfo imageInfo,
            @Nullable final Animatable animatable) {
        final Drawable drawable = getTopLevelDrawable();
        DrawableUtils.setDrawableProperties(drawable, mDrawableProperties)
    }

    @Override
    public void onIntermediateImageSet(final String id, @Nullable final ImageInfo imageInfo) {
    }

    @Override
    public void onIntermediateImageFailed(final String id, final Throwable throwable) {
    }

    @Override
    public void onFailure(final String id, final Throwable throwable) {
    }

    @Override
    public void onRelease(final String id) {
    }
}
```
"
facebook/fresco,https://github.com/facebook/fresco/issues/788,"![image](https://cloud.githubusercontent.com/assets/2942953/11360370/fef767a0-92be-11e5-94fb-e619a925fda2.png)

This may be caused by the file is symbolic link, the `isDirectory` method returns true, then the tree traversal is endless. But I'm not sure, and I don't know why there is a symbolic link file.
","What are you doing exactly? Can you paste the code that fails?
","Sorry, this stack trace is from our crash report system, so I don't know what exactly happened.
"
facebook/fresco,https://github.com/facebook/fresco/issues/678,"App is crash because I dont know why??

```
java.lang.IllegalStateException: Queue full
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at java.util.AbstractQueue.add(AbstractQueue.java:69)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at java.util.concurrent.ArrayBlockingQueue.add(ArrayBlockingQueue.java:282)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at com.facebook.drawee.components.DraweeEventTracker.recordEvent(DraweeEventTracker.java:52)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at com.facebook.drawee.view.DraweeHolder.onDetach(DraweeHolder.java:127)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at com.facebook.drawee.view.DraweeView.onStartTemporaryDetach(DraweeView.java:116)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.dispatchStartTemporaryDetach(View.java:8335)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.dispatchStartTemporaryDetach(ViewGroup.java:2663)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.dispatchStartTemporaryDetach(ViewGroup.java:2663)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.dispatchStartTemporaryDetach(ViewGroup.java:2663)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.AbsListView$RecycleBin.addScrapView(AbsListView.java:6551)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.GridView.onMeasure(GridView.java:1080)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.RelativeLayout.measureChild(RelativeLayout.java:697)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.RelativeLayout.onMeasure(RelativeLayout.java:481)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5535)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.FrameLayout.onMeasure(FrameLayout.java:436)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.RelativeLayout.measureChild(RelativeLayout.java:697)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.RelativeLayout.onMeasure(RelativeLayout.java:481)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5535)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.support.design.widget.CoordinatorLayout.onMeasureChild(CoordinatorLayout.java:607)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.support.design.widget.CoordinatorLayout.onMeasure(CoordinatorLayout.java:674)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.RelativeLayout.measureChildHorizontal(RelativeLayout.java:727)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.RelativeLayout.onMeasure(RelativeLayout.java:463)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.support.v4.widget.DrawerLayout.onMeasure(DrawerLayout.java:940)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5535)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.FrameLayout.onMeasure(FrameLayout.java:436)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.support.v7.internal.widget.ContentFrameLayout.onMeasure(ContentFrameLayout.java:135)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5535)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.LinearLayout.measureChildBeforeLayout(LinearLayout.java:1436)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.LinearLayout.measureVertical(LinearLayout.java:722)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.LinearLayout.onMeasure(LinearLayout.java:613)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5535)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.FrameLayout.onMeasure(FrameLayout.java:436)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5535)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.LinearLayout.measureChildBeforeLayout(LinearLayout.java:1436)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.LinearLayout.measureVertical(LinearLayout.java:722)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.LinearLayout.onMeasure(LinearLayout.java:613)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5535)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.widget.FrameLayout.onMeasure(FrameLayout.java:436)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at com.android.internal.policy.impl.PhoneWindow$DecorView.onMeasure(PhoneWindow.java:2615)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.View.measure(View.java:17547)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewRootImpl.performMeasure(ViewRootImpl.java:2015)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:1781)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1061)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:5885)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.Choreographer$CallbackRecord.run(Choreographer.java:767)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.Choreographer.doCallbacks(Choreographer.java:580)
10-21 10:31:27.699 8966-8966/com.zoho.notebook E/AndroidRuntime:     at android.view.Choreographer.doFrame(Choreographer.java:550)
```
","Do you create controllers or manipulate drawee components on non-ui thread ?
","No i am create and assign the controller in UI Thread only
"
facebook/fresco,https://github.com/facebook/fresco/issues/636,"Hello. I have an issue with ""wrap_conent"" height for remote thin images
onFinalImageSet i'm doint this

```
mSimpleDraweeView.setAspectRatio((float) imageInfo.getWidth() / imageInfo.getHeight());
```

This code code works fine for images were aspect ration is about 1 - 2

I have one special case.
I'm laoding a very thin image that should autofil his height, but for some reason it doesn't.

```
imageInfo.getWidth() = 641
imageInfo.getHeight() = 37
```

so aspectRatio is about 17

Image is resized about 3 times bigger than should be by height.

Here is the layout

```
 <com.facebook.drawee.view.SimpleDraweeView
            android:id=""@+id/thumbnail_image_view""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            fresco:actualImageScaleType=""fitCenter"" >
```

I think it happens only for very thin images because others with ( ex: 640x290) are resized properly.

Did anyone encountered this before?
","Could you give the image url and a screenshot of the problem please? 

What do you mean by ""it should autofill its height""?
","@IanChilds 
Here is the layout

```
 <com.facebook.drawee.view.SimpleDraweeView
            android:id=""@+id/thumbnail_image_view""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            fresco:actualImageScaleType=""fitCenter"" >
```

Here is the url of the image 
http://a.namshicdn.com/cms/vogue/men/2015/20042015/module_10_en.jpg

```
imageInfo.getWidth() = 640
imageInfo.getHeight() = 37
aspectRatio = 17
```

![device-2015-09-30-174520](https://cloud.githubusercontent.com/assets/1655758/10196473/b6e1172a-679b-11e5-8b29-fe9d987c226b.png)

The image has extra white space at bottom, the result of aspectRation equals to 17

Other images are properly resized 
http://a.namshicdn.com/cms/vogue/kids/2015/12082015/module_06_en.jpg
http://a.namshicdn.com/cms/vogue/kids/2015/04052015/module_05.jpg

```
imageInfo.getWidth() = 640
imageInfo.getHeight() = 290
aspectRatio = 2.2
```

By ""it should autofill its height"" I mean it should do same what ""wrap_content"" does.
I mean this code. 

```
aspectRatio = imageInfo.getWidth()/imageInfo.getHeight()
```

It works for aspectRation == 2.2 but not 17
"
facebook/fresco,https://github.com/facebook/fresco/issues/621,"Hi,Fresco.
First of all ,thanks for this amazing Android Image Loading Framework!
Here is the problems happened to me:
When I use SimpleDraweeView in ListView,loading android SD files,normally I scroll it ,nothing weird happens,but when I fast scroll it ,log tells me : 
""unknown:CloseableReference﹕ Finalized without closing: 42d7b6a8 42d7b718 (type = NativePooledByteBuffer)""
according to the issue #213 ,Using SimpleDraweeView will not encountered this problem,can you help me?
","Can you tell us what version of Android and what device you are using?
",
facebook/fresco,https://github.com/facebook/fresco/issues/613,"in 0.7.0
when I use `GenericDraweeHierarchyBuilder` to `setProgressBarImage` or `setRoundingParams`
the default fade in effect is gone,the image comes out directly...

If I delete `setProgressBarImage` and `setRoundingParams`, everything is normal and effect comes back

same problem also occur in older relases
","Could you provide other details of the problem please? Are you using the Drawee in the layout document or instantiate directly in the code?
","I wrote a class which extends `SimpleDraweeView` and in constructor method  

```
GenericDraweeHierarchyBuilder builder = new GenericDraweeHierarchyBuilder(getResources());
GenericDraweeHierarchy hierarchy = builder
                .setPlaceholderImage(mProgressDrawable)
                .setFadeDuration(400)
                .setRoundingParams(new RoundingParams() {
                    @Override
                    public boolean getRoundAsCircle() {
                        return true;
                    }
                })
                .build();
        setHierarchy(hierarchy);
```

In other files, I use this custom class to show images.

I use my custom class in XML just like `SimpleDraweeView`
"
facebook/fresco,https://github.com/facebook/fresco/issues/601," i load the image list of sdcard and scroll fast . the listview scroll not smooth. 
","What version are you using? 
","both 0.6.0 and 0.7.0 exist the condition.

limingwei234@163.com

From: IanChilds
Date: 2015-09-10 17:52
To: facebook/fresco
CC: limingwei234
Subject: Re: [fresco] load sdcard images not smooth (#601)
What version are you using? 
—
Reply to this email directly or view it on GitHub.
"
facebook/fresco,https://github.com/facebook/fresco/issues/589,"Fresco save bitmaps in the Android java VM heap on the Lollipop and upper. But it seems that Lollipop memory strategy dose not perform well on these devices. Facebook app runs on my Samsung Note4 would easily take almost 170M java heap memory!
If load the local camera images, memory usage raise up to 211M. Please refer to the following output. Since this device is not rooted, I can't provide the hprof dumps. But I can do that if we would do the future work.

```
$ adb shell dumpsys meminfo com.facebook.katana
Applications Memory Usage (kB):
Uptime: 24045894 Realtime: 182766077

** MEMINFO in pid 2941 [com.facebook.katana] **
                   Pss  Private  Private  Swapped     Heap     Heap     Heap
                 Total    Dirty    Clean    Dirty     Size    Alloc     Free
                ------   ------   ------   ------   ------   ------   ------
  Native Heap        0        0        0        0    96228    96228    51227
  Dalvik Heap   183464   183420        4    25504   211055   201411     9644
 Dalvik Other     1388     1388        0        0
        Stack     1532     1532        0        0
       Cursor        2        0        0        0
       Ashmem      128      128        0        0
    Other dev   111553   102592       12        0
     .so mmap    13889      604     7816     1388
    .apk mmap     2151        0      964        0
    .ttf mmap     3742        0     3240        0
    .dex mmap    78828        0    78136        0
    code mmap     4804        0     2560        0
   image mmap     8544     2300     2828        0
   Other mmap     1233        4      776        0
     Graphics    49920    49920        0        0
           GL   177804   177804        0        0
      Unknown    80796    80624      152     2380
        TOTAL   719778   600316    96488    29272   307283   297639    60871

 Objects
               Views:     1284         ViewRootImpl:        3
         AppContexts:       13           Activities:        9
              Assets:        6        AssetManagers:        6
       Local Binders:      104        Proxy Binders:       59
    Death Recipients:        1
     OpenSSL Sockets:        1

 SQL
         MEMORY_USED:     5359
  PAGECACHE_OVERFLOW:     4036          MALLOC_SIZE:       62

 DATABASES
      pgsz     dbsz   Lookaside(b)          cache  Dbname
         4      340            334      113/52/12  /data/data/com.facebook.katana/databases/contacts_db2
         4       36             30        17/43/6  /data/data/com.facebook.katana/databases/composer_db
         4      192             80        20/49/9  /data/data/com.facebook.katana/databases/notifications_db
         4       28             33         8/43/3  /data/data/com.facebook.katana/databases/admined_pages_db
         4       24             52         8/40/3  /data/data/com.facebook.katana/databases/minutiae_db
         4       56             30        49/44/4  /data/data/com.facebook.katana/databases/analytics_db2
         4      136             31    1237/1274/4  /data/data/com.facebook.katana/databases/prefs_db
         4      224             61         9/44/4  /data/data/com.facebook.katana/databases/qe_db
         4       28             44        16/53/7  /data/data/com.facebook.katana/databases/timeline_db
         4      240            128     451/102/14  /data/data/com.facebook.katana/databases/newsfeed_db
         4       44             51        12/36/5  /data/data/com.facebook.katana/databases/photos_db
         4      148            201      397/64/10  /data/data/com.facebook.katana/databases/threads_db2
         4     1520            196    1432/191/25  /data/data/com.facebook.katana/databases/graphql_cache
         4       28             49        10/43/3  /data/data/com.facebook.katana/databases/offline_mode_db

 Asset Allocations
    zip:/data/app/com.facebook.katana-1/base.apk:/resources.arsc: 8284K
    zip:/data/app/com.facebook.katana-1/base.apk:/assets/fonts/Roboto-Bold.ttf:
114K
    zip:/data/app/com.facebook.katana-1/base.apk:/assets/fonts/Roboto-Medium.ttf: 114K
```
","Can you please tell us how did you use the app? E.g. scrolling news feed, navigating to timeline, browsing photos etc. This will help us identify whether the issue is in some of the app components (e.g. not resizing local images when we should) or there is a flaw in Fresco memory management. Thanks!
","Hi @plamenko , This issue is very easy to reproduce. I scrolled many news and browse the social  photos.While I have scrolled down mass items, I scrolled up to the top again to click ""What's on your mind"", choose ""Photo/Video"", scroll the local photos down and up and then long click one photo to enter the photo tag page. Switch the images left and right. 
I runs an timing script(adb shell dumpsys meminfo com.facebook.katana | grep Heap) to monitor the app memory. After the java heap memory reach to about 260M, the ANR issue occured. But I can't see any useful information in the /data/anr/trace.txt, and the ""dumpsys meminfo com.facebook.katana"" command is always blocking. I dumped some other system status information in this link: http://www.bashshell.cn/Samsung_Note4.zip. Hope this is helpful. Thanks.

![image](https://cloud.githubusercontent.com/assets/1342575/9666073/9a4a71a6-52a6-11e5-9b32-02ffcfb26026.png)
"
facebook/fresco,https://github.com/facebook/fresco/issues/587,"Hi ,I recently encountered a problem that Fresco repeat request with same URI.For example,there is a listview, refresh it several times the problem happens, the requests of some pictures  are send repeatly.The following is the request I catch.
![image](https://cloud.githubusercontent.com/assets/10043199/9623463/90b0e622-5173-11e5-9612-2a8d1757be3e.png)
Can you help me?
","Can you provide some more information please?
- How/where do you initialize Fresco?
- What do you mean by refreshing the listview? Do you mean Adapter.dataSetChanged or something else?
- Can you please provide a verbose logcat: `adb logcat -v threadtime | grep -iE 'LoggingListener|AbstractDraweeController'`
","I simulated the situation that I had met.
Uri1,Uri2,Uri3  are different images, in my project it may happen that the list may use notifyDataSetChanged() many times at same time.So I simulated the situation ,you will find it will request the same uri several times.
![image](https://cloud.githubusercontent.com/assets/10043199/9697347/d31d1486-53bc-11e5-88bb-f6d9a501c081.png)

Try the following codes:

``` java
public class MainActivity extends Activity {
    SimpleDraweeView imageTest,imageTest2,imageTest3;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        Fresco.initialize(this);
        setContentView(R.layout.activity_main);


        imageTest2=(SimpleDraweeView)findViewById(R.id.user_avator1);
        imageTest=(SimpleDraweeView)findViewById(R.id.user_avator);
        imageTest3=(SimpleDraweeView)findViewById(R.id.user_avator2);


        final Uri uri1 = Uri.parse(""http://pic7.qiyipic.com/image/20150427/c3/9f/a_100011875_m_601_284_160.jpg"");
        final Uri uri2 = Uri.parse(""http://pic7.qiyipic.com/image/20150213/b2/aa/a_100010483_m_601_284_160.jpg"");
        final Uri uri3 = Uri.parse(""http://pic1.qiyipic.com/image/20150720/76/18/a_100013208_m_601_m5_284_160.jpg"");

        Button btn=(Button)findViewById(R.id.button);
        btn.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                for(int i=0;i<40;i++) {
                    imageTest2.setImageURI(uri1);
                    imageTest.setImageURI(uri2);
                    imageTest3.setImageURI(uri3);


                    imageTest3.setImageURI(uri2);
                    imageTest2.setImageURI(uri3);
                    imageTest.setImageURI(uri1);
                }
            }
        });
    }
}
```
"
facebook/fresco,https://github.com/facebook/fresco/issues/574,"Hello,

I'm using Fresco in a `RecyclerView`. I'm recycling the views properly and, of course, initializing Fresco just once in the `Application` class.

I see that there are other OOM issues reported, but all of them seem to occur due to huge images trying to be loaded into the memory.

In my case, as you can see in the following screenshots, the images are small.

![screen shot 2015-08-27 at 10 41 42](https://cloud.githubusercontent.com/assets/323266/9522066/e0da72e6-4ca8-11e5-9781-a3b5a376a090.png)

![screen shot 2015-08-27 at 10 47 50](https://cloud.githubusercontent.com/assets/323266/9522102/17c75ee0-4ca9-11e5-9df4-6ed1382cd6f6.png)

It seems it's only happening on Android 5.0+ with ART:

![screen shot 2015-08-27 at 10 48 28](https://cloud.githubusercontent.com/assets/323266/9522116/3f201d2e-4ca9-11e5-96e3-7a43bb482f77.png)

Any idea how to solve this issue? I have too many occurrences of these crashes :(

**EDIT 1:**

I am loading 6~8 images on-screen, at most. All of them are JPEGs of ~~250~~ 25 kB max.
Here's the [hprof file (heap dump)](https://www.dropbox.com/s/jxxgpkueo661g7h/heap.hprof?dl=0).

Thank you in advance,
Martin
","How many images do you have loaded on-screen? 

Could you attach a hprof file? See the [instructions](https://developer.android.com/tools/debugging/debugging-memory.html#ViewHeap) on how to generate them.
","@tyronen I updated the issue with the information you asked me. Thanks!
"
facebook/fresco,https://github.com/facebook/fresco/issues/569,"Hi guys,

First of all, great library! Only problem I've had so far is with caching of post processed images - I'm following the documentation put up, and have looked around, but can't seem to figure out what's going wrong here.

I have a FragmentStatePagerAdapter, with each fragment having a full-sized, blurred image as its background, and I have a post-processor that blurs the background image, and all of that is working fine. But when I scroll between the fragments back and forth, the blurred background image is reprocessed every time, which is really annoying. There's a section in the docs saying that post-processed images can be cached, and I'm doing everything it's saying I should, but images are still not being caches.

My post-processor:

```
public class BlurPostprocessor extends BasePostprocessor {
        private Context context;
        private String url;

        public BlurPostprocessor(Context context, String url) {
            this.context = context;
            this.url = url;
        }

        @Override
        public String getName() {
            return ""blurPostProcessor"";
        }

        @Override
        public CacheKey getPostprocessorCacheKey() {
            return new SimpleCacheKey(url);
        }

        @Override
        public void process(Bitmap destBitmap, Bitmap sourceBitmap) {
                // code that blurs the image into destBitmap
        }
    }
```

I've also tried implementing my own CacheKey before finding out about SimpleCacheKey, but that didn't work either. Any help would be appreciated!

Thanks!
","Can you show us the code where you are making the image request?
","```
ImageRequest request = ImageRequestBuilder.newBuilderWithSource(Uri.parse(srcString))
        .setPostprocessor(new BlurPostprocessor(background.getContext(), srcString))
        .build();

PipelineDraweeController controller = (PipelineDraweeController) Fresco.newDraweeControllerBuilder()
        .setImageRequest(request)
        .setOldController(background.getController())
        .build();

background.setController(controller);
```

Where `background` is a SimpleDraweeView.
"
facebook/fresco,https://github.com/facebook/fresco/issues/564,"There are about 100 images whose size is 2048*1536 will show in my project.I had used resizing.But I found that fresco can only load several images,and then all below images would load fail.  
By the way, I use viewPage with FragmentStatePagerAdapter.

The code I used to load image is below   

```
SimpleDraweeView imageView=new SimpleDraweeView(getContext());
imageView.setScaleType(ImageView.ScaleType.CENTER_CROP);
imageView.setLayoutParams(new LayoutParams(LayoutParams.MATCH_PARENT, this.deviceSize.y));
Uri uri = Uri.parse(this.imageUrls.get(i));
ImageRequest request = ImageRequestBuilder.newBuilderWithSource(uri)
         .setResizeOptions(new ResizeOptions(deviceSize.x, deviceSize.y))
         .build();
PipelineDraweeController controller = (PipelineDraweeController) Fresco.newDraweeControllerBuilder()
          .setOldController(imageView.getController())
          .setControllerListener(controllerListener)
          .setImageRequest(request)
          .build();
imageView.setController(controller);   
```

and the error   

```
E/unknown:﹕ Error loading 8
    com.facebook.imagepipeline.memory.BasePool$PoolSizeViolationException: Pool hard cap violation? Hard cap = 50331648Used size = 48168960Free size = 0Request size = 9633792
            at com.facebook.imagepipeline.memory.BasePool.get(BasePool.java:241)
            at com.facebook.imagepipeline.bitmaps.ArtBitmapFactory.doDecodeStaticImage(ArtBitmapFactory.java:131)
            at com.facebook.imagepipeline.bitmaps.ArtBitmapFactory.decodeJPEGFromPooledByteBuffer(ArtBitmapFactory.java:119)
            at com.facebook.imagepipeline.bitmaps.PlatformBitmapFactory.decodeJPEGFromPooledByteBuffer(PlatformBitmapFactory.java:106)
            at com.facebook.imagepipeline.decoder.ImageDecoder.decodeJpeg(ImageDecoder.java:135)
            at com.facebook.imagepipeline.decoder.ImageDecoder.decodeImage(ImageDecoder.java:83)
            at com.facebook.imagepipeline.producers.DecodeProducer$ProgressiveDecoder.doDecode(DecodeProducer.java:166)
            at com.facebook.imagepipeline.producers.DecodeProducer$ProgressiveDecoder.access$000(DecodeProducer.java:88)
            at com.facebook.imagepipeline.producers.DecodeProducer$ProgressiveDecoder$1.run(DecodeProducer.java:112)
            at com.facebook.imagepipeline.producers.DecodeProducer$ProgressiveDecoder$1.run(DecodeProducer.java:109)
            at com.facebook.imagepipeline.producers.JobScheduler.doJob(JobScheduler.java:214)
            at com.facebook.imagepipeline.producers.JobScheduler.access$000(JobScheduler.java:30)
            at com.facebook.imagepipeline.producers.JobScheduler$1.run(JobScheduler.java:68)
            at com.facebook.common.executors.SerialDelegatingExecutor.executeSingleCommand(SerialDelegatingExecutor.java:76)
            at com.facebook.common.executors.SerialDelegatingExecutor.access$000(SerialDelegatingExecutor.java:24)
            at com.facebook.common.executors.SerialDelegatingExecutor$1.run(SerialDelegatingExecutor.java:47)
            at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1112)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:587)
            at java.lang.Thread.run(Thread.java:818)
```

P.S. the example for the imageUrl
http://www.yccy.cc/xueermian/source/03-1.jpg
","What is `deviceSize`? How many images at once can be displayed? Ideally, you should never have more images displayed than to cover the device screen once. That means if you are dealing with full-screen images, you should only ever display one (or two).
","@plamenko deviceSize is the size of device's screen. There may be three or four images display at once. If the simpleDraweeView is not in screen,what is the best way to clear it's content and recycle the image cache?
"
facebook/fresco,https://github.com/facebook/fresco/issues/546,"```
java.lang.NoSuchFieldError: STROKE
at com.facebook.drawee.drawable.RoundedBitmapDrawable.<init>(RoundedBitmapDrawable.java:61)
at com.facebook.drawee.drawable.RoundedBitmapDrawable.fromBitmapDrawable(RoundedBitmapDrawable.java:73)
at com.facebook.drawee.generic.GenericDraweeHierarchy.maybeApplyRoundingBitmapOnly(GenericDraweeHierarchy.java:353)
at com.facebook.drawee.generic.GenericDraweeHierarchy.setImage(GenericDraweeHierarchy.java:445)
at com.facebook.drawee.controller.AbstractDraweeController.onNewResultInternal(AbstractDraweeController.java:467)
at com.facebook.drawee.controller.AbstractDraweeController.access$000(AbstractDraweeController.java:47)
at com.facebook.drawee.controller.AbstractDraweeController$1.onNewResultImpl(AbstractDraweeController.java:413)
at com.facebook.datasource.BaseDataSubscriber.onNewResult(BaseDataSubscriber.java:43)
at com.facebook.datasource.AbstractDataSource$1.run(AbstractDataSource.java:181)
at com.facebook.common.executors.UiThreadImmediateExecutorService.execute(UiThreadImmediateExecutorService.java:40)
at com.facebook.datasource.AbstractDataSource.notifyDataSubscriber(AbstractDataSource.java:172)
at com.facebook.datasource.AbstractDataSource.subscribe(AbstractDataSource.java:155)
at com.facebook.drawee.controller.AbstractDraweeController.submitRequest(AbstractDraweeController.java:429)
at com.facebook.drawee.controller.AbstractDraweeController.onAttach(AbstractDraweeController.java:332)
at com.facebook.drawee.view.DraweeHolder.attachController(DraweeHolder.java:276)
at com.facebook.drawee.view.DraweeHolder.setController(DraweeHolder.java:222)
at com.facebook.drawee.view.DraweeView.setController(DraweeView.java:87)
```
","Can you tell us which Android version do you run when you hit this issue ? What is the phone model ? Does it happen all the time or sporadically ?
","Hi.

Android 4.4 , Device : Y25 (y25) .

No. it happened only couple of times.
"
facebook/fresco,https://github.com/facebook/fresco/issues/543,"When I trying to use SimpleDraweeView.setImageURI(Uri.parse(""file:///storage/emulated/0/Pictures/JPEG_20150814_223226_-1110502600.jpg""));
The image loaded from the photo that I took from the camera is very small, but the image loaded from the other photo(ex. screenshots) is normal.
","What are the layout width and height of your view?
","I set the layout width and height to match parent and scale type is center. But the photo take from the phone camera is very small.Actually, it is a big one.
"
facebook/fresco,https://github.com/facebook/fresco/issues/537,"I show some picture using viewpager. Viewpager item is Fragment. 
 Even though Fregment is detroy. GC is not occur.
Keep add Image to memory. 

![11](https://cloud.githubusercontent.com/assets/6457985/9247708/69a155a4-41f0-11e5-8af0-5033929813af.png)

![222](https://cloud.githubusercontent.com/assets/6457985/9247792/1acb1540-41f1-11e5-95e7-01d21d49a062.png)

init Fresco

```
  ImagePipelineConfig config = OkHttpImagePipelineConfigFactory
                .newBuilder(this, DCB_RestfulAdapter.getClient())
                .build();
        Fresco.initialize(this, config);
```

showing image

```
 GenericDraweeHierarchyBuilder builder = new GenericDraweeHierarchyBuilder(getResources());
            GenericDraweeHierarchy hierarchy = builder.setFadeDuration(300)
            .setActualImageScaleType(ScalingUtils.ScaleType.FIT_CENTER)
            .setProgressBarImage(new CustomProgressbarDrawable(this))
            .build();

            hierarchy.setPlaceholderImage(R.drawable.ic_placeholder);


            ImageRequest imageRequest = ImageRequestBuilder.newBuilderWithSource(Uri.parse(url))
                .setResizeOptions(new ResizeOptions(Utils.getScreenWidth(getActivity()), Utils.getScreenHeight(getActivity())))
//                .setResizeOptions(new ResizeOptions(300, 300))
                .setAutoRotateEnabled(true)
                .build();


            DraweeController draweeController = Fresco.newDraweeControllerBuilder()

                    .setImageRequest(imageRequest)
                    .setAutoPlayAnimations(true)
                    .setOldController(view.getController())

                    .build();
            view.setController(draweeController);
            view.setHierarchy(hierarchy);
            view.setAspectRatio(1.33f);
```
","Can you confirm that Bitmaps take more space than that ?
","occur OOM.
"
firebase/firebase-admin-java,https://github.com/firebase/firebase-admin-java/issues/106,"I am using this admin sdk version 5.5.0 with the new firestore. I was making batch writes and noticing that larger ones (1000 documents) were not working. The listener of the apifuture gets called, but the objects are just not in my store. With smaller batches (500 documents)  it seems to work. I tried to find a maximum batch size or timeout in the documentation but with no success.
",Can you please also share a minimal code snippet that we can use to reproduce this?,
firebase/firebase-android-sdk,https://github.com/firebase/firebase-android-sdk/issues/1054,"<!-- DO NOT DELETE 
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->

### [REQUIRED] Step 2: Describe your environment

  * Android Studio version: 3.5.3
  * Firebase Component: Messaging
  * Component version: 20.1.0

### [REQUIRED] Step 3: Describe the problem
After updating our app from Firebase Messaging version 20.0.1 to version 20.1.0 we are now receiving duplicate class errors regarding Dagger. Our app uses Dagger 1.2.5. This appears to be related the resolution of [Issue 712](https://github.com/firebase/firebase-android-sdk/issues/712).

Errors are as follows:

- Duplicate class dagger.Lazy found in modules dagger-1.2.5.jar (com.squareup.dagger:dagger:1.2.5) and dagger-2.24.jar (com.google.dagger:dagger:2.24)
- Duplicate class dagger.MembersInjector found in modules dagger-1.2.5.jar (com.squareup.dagger:dagger:1.2.5) and dagger-2.24.jar (com.google.dagger:dagger:2.24)
- Duplicate class dagger.Module found in modules dagger-1.2.5.jar (com.squareup.dagger:dagger:1.2.5) and dagger-2.24.jar (com.google.dagger:dagger:2.24)
- Duplicate class dagger.Provides found in modules dagger-1.2.5.jar (com.squareup.dagger:dagger:1.2.5) and dagger-2.24.jar (com.google.dagger:dagger:2.24)

#### Steps to reproduce:

What happened? How can we make the problem occur?

Add Dagger 1.2.5 and Firebase Messaging 20.1.0 dependencies to your app",Can you share your dependencies from the build.gradle file?,"@aguatno 

We have about 10 modules in our solution (it is quite large), but the dependencies of concern I think are below. Thanks!

```
    // dependency injection (dagger)
    // Ref: http://square.github.io/dagger/
    implementation ""com.squareup.dagger:dagger:1.2.5""
    annotationProcessor ""com.squareup.dagger:dagger-compiler:1.2.5""

    // firebase messaging (required for supporting SNS over FCM)
    // note: do not update, causes clash with Dagger
    // ref: https://github.com/firebase/firebase-android-sdk/issues/1054
    implementation 'com.google.firebase:firebase-messaging:20.0.1'
```"
firebase/firebase-android-sdk,https://github.com/firebase/firebase-android-sdk/issues/901,"1. Fatal Exception: java.lang.RuntimeException: Error receiving broadcast Intent { act=android.net.conn.CONNECTIVITY_CHANGE flg=0x4000010 launchParam=MultiScreenLaunchParams { mDisplayId=0 mFlags=0 } bqHint=1 (has extras) } in com.google.firebase.iid.zzaz@790a33a
       at android.app.LoadedApk$ReceiverDispatcher$Args.run(LoadedApk.java:1195)
       at android.os.Handler.handleCallback(Handler.java:751)
       at android.os.Handler.dispatchMessage(Handler.java:95)
       at android.os.Looper.loop(Looper.java:154)
       at android.app.ActivityThread.main(ActivityThread.java:6682)
       at java.lang.reflect.Method.invoke(Method.java)
       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1520)
       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1410)


2. Caused by java.lang.IllegalArgumentException: Receiver not registered: com.google.firebase.iid.zzaz@790a33a
       at android.app.LoadedApk.forgetReceiverDispatcher(LoadedApk.java:1054)
       at android.app.ContextImpl.unregisterReceiver(ContextImpl.java:1376)
       at android.content.ContextWrapper.unregisterReceiver(ContextWrapper.java:659)
       at com.google.firebase.iid.zzaz.onReceive(zzaz.java:16)
       at android.app.LoadedApk$ReceiverDispatcher$Args.run(LoadedApk.java:1185)
       at android.os.Handler.handleCallback(Handler.java:751)
       at android.os.Handler.dispatchMessage(Handler.java:95)
       at android.os.Looper.loop(Looper.java:154)
       at android.app.ActivityThread.main(ActivityThread.java:6682)
       at java.lang.reflect.Method.invoke(Method.java)
       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1520)
       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1410)


version:
com.google.firebase:firebase-messaging:17.3.3
com.google.firebase:firebase-core:16.0.7
","Can you please provide the actual code to recreate this? It will make it easier to debug. If we can get code that demonstrates the issue, we'd be happy to dig into this. Thanks",
firebase/firebase-android-sdk,https://github.com/firebase/firebase-android-sdk/issues/875,"<!-- DO NOT DELETE 
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->

### [READ] Step 1: Are you in the right place?

Issues filed here should be about bugs in __the code in this repository__. 
If you have a general question, need help debugging, or fall into some
other category use one of these other channels:

  * For general technical questions, post a question on [StackOverflow](http://stackoverflow.com/)
    with the firebase tag.
  * For general Firebase discussion, use the [firebase-talk](https://groups.google.com/forum/#!forum/firebase-talk)
    google group.
  * For help troubleshooting your application that does not fall under one
    of the above categories, reach out to the personalized
    [Firebase support channel](https://firebase.google.com/support/).

### [REQUIRED] Step 2: Describe your environment

  * Android Studio version: 3.5
  * Firebase Component: Firestore (Database, Firestore, Storage, Functions, etc)
  * Component version: 21.1.1

### [REQUIRED] Step 3: Describe the problem

Firestore is crashing sporadically in production.  I'm seeing the following stack traces together in Crashlytics.

```
Fatal Exception: java.lang.RuntimeException: Internal error in Cloud Firestore (21.1.1).
       at com.google.firebase.firestore.util.AsyncQueue.lambda$panic$3(AsyncQueue.java:529)
       at com.google.firebase.firestore.util.AsyncQueue$$Lambda$3.run(AsyncQueue.java:2000)
       at android.os.Handler.handleCallback(Handler.java:873)
       at android.os.Handler.dispatchMessage(Handler.java:99)
       at android.os.Looper.loop(Looper.java:214)
       at android.app.ActivityThread.main(ActivityThread.java:7073)
       at java.lang.reflect.Method.invoke(Method.java)
       at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)
       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:965)
```

```
com.google.firebase.firestore.core.SyncEngine.handleCredentialChange (SyncEngine.java:599)
com.google.firebase.firestore.core.FirestoreClient.lambda$new$0 (FirestoreClient.java:105)
com.google.firebase.firestore.core.FirestoreClient$$Lambda$15.run (FirestoreClient.java:3599)
com.google.firebase.firestore.util.AsyncQueue.lambda$enqueue$2 (AsyncQueue.java:431)
com.google.firebase.firestore.util.AsyncQueue$$Lambda$2.call (AsyncQueue.java:2000)
com.google.firebase.firestore.util.AsyncQueue$SynchronizedShutdownAwareExecutor.lambda$executeAndReportResult$1 (AsyncQueue.java:317)
com.google.firebase.firestore.util.AsyncQueue$SynchronizedShutdownAwareExecutor$$Lambda$2.run (AsyncQueue.java:2317)
java.util.concurrent.Executors$RunnableAdapter.call (Executors.java:459)
java.util.concurrent.FutureTask.run (FutureTask.java:266)
java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run (ScheduledThreadPoolExecutor.java:301)
java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1167)
java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:641)
com.google.firebase.firestore.util.AsyncQueue$SynchronizedShutdownAwareExecutor$DelayedStartFactory.run (AsyncQueue.java:224)
java.lang.Thread.run (Thread.java:764)
```

#### Steps to reproduce:

This is happening in production and being reported back to my via Crashlytics.","Can you double check? It would be very helpful if you could share the exception that occurred in `SyncEngine.handleCredentialChange (SyncEngine.java:599)`? Thank you?

","It says it is an NullPointerException, but then its an obfuscated class name in my package namespace.

""Attempt to read from field 'com.me.kG com.me.lj.ᐝ' on a null object reference"""
firebase/firebase-android-sdk,https://github.com/firebase/firebase-android-sdk/issues/835,"<!-- DO NOT DELETE 
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
### [REQUIRED] Step 2: Describe your environment

  * Android Studio version: 3.5
  * Firebase Component: Remote config
  * Component version: 19.0.1

### [REQUIRED] Step 3: Describe the problem

#### Steps to reproduce:
Try fetch data from remote config no one of listeners will be called
The code inside a module called data.
and firebase initialization inside the app module
keep in mind the firebase real-time database working fine


#### Relevant Code:

```
firebaseRemoteConfig.fetch(0)
                .addOnCompleteListener {
                    Log.e("""", """")
                    // Not called, i have waited 2 minutes
                }
                .addOnSuccessListener {
                    Log.e("""", """")
                    // Not called, i have waited 2 minutes
                }
                .addOnFailureListener {
                    Log.e("""", """")
                    // Not called, i have waited 2 minutes
                }
                .addOnCanceledListener {
                    Log.e("""", """")
                    // Not called, i have waited 2 minutes
                }
```","Could you try to update to the latest version and see if the issue persists?

Thanks.
",
firebase/firebase-android-sdk,https://github.com/firebase/firebase-android-sdk/issues/292,"<!-- DO NOT DELETE 
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->

### [READ] Step 1: Are you in the right place?

Issues filed here should be about bugs in __the code in this repository__. 
If you have a general question, need help debugging, or fall into some
other category use one of these other channels:

  * For general technical questions, post a question on [StackOverflow](http://stackoverflow.com/)
    with the firebase tag.
  * For general Firebase discussion, use the [firebase-talk](https://groups.google.com/forum/#!forum/firebase-talk)
    google group.
  * For help troubleshooting your application that does not fall under one
    of the above categories, reach out to the personalized
    [Firebase support channel](https://firebase.google.com/support/).

### [REQUIRED] Step 2: Describe your environment

  * Android Studio version: 3.3.2
  * Firebase Component: Firestore (Database, Firestore, Storage, Functions, etc)
  * Component version: 18.1.0

### [REQUIRED] Step 3: Describe the problem
firebase-firestore:18.1.0's POM file specifies an incorrect packaging type of its dependency, io.grpc:grpc-android. The artifact type of grpc-android should be ""aar"" instead of ""jar"". https://mvnrepository.com/artifact/io.grpc/grpc-android/1.18.0
```
<?xml version='1.0' encoding='UTF-8'?>
<project xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns=""http://maven.apache.org/POM/4.0.0"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
  <modelVersion>4.0.0</modelVersion>
  <groupId>com.google.firebase</groupId>
  <artifactId>firebase-firestore</artifactId>
  <version>18.1.0</version>
  <packaging>aar</packaging>
  <dependencies>
    <!-- redacted for clarity -->   
    <dependency>
      <groupId>io.grpc</groupId>
      <artifactId>grpc-android</artifactId>
      <version>1.16.1</version>
      <scope>compile</scope>
      <!-- The type SHOULD BE aar instead of jar -->
      <type>jar</type>
    </dependency>
    <!-- redacted for clarity -->   
  </dependencies>
  <name>firebase-firestore</name>
</project>
```
#### Steps to reproduce:

What happened? How can we make the problem occur?
This could be a description, log/console output, etc.

#### Relevant Code:

```
// TODO(you): code here to reproduce the problem
```",What problem does this lead to in practice for you?,"I'm using Bazel with [rules_jvm_external](https://github.com/bazelbuild/rules_jvm_external) to resolve maven dependencies.

Also see https://github.com/bazelbuild/rules_jvm_external/issues/70

Thank you!"
firebase/firebase-android-sdk,https://github.com/firebase/firebase-android-sdk/issues/208,"<!-- DO NOT DELETE 
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->

### [REQUIRED] Step 2: My environment

  * Android Studio version: 3.3
  * Firebase Component: Firestore
  * Component version: 17.1.5

### [REQUIRED] Step 3: Describe the problem
Some my app user get this crash during batch.commit() (HUAWEI VTR-L09 Android 8.0.0)

> Fatal Exception: java.lang.RuntimeException: Internal error in Firestore (0.6.6-dev).
>        at com.google.firebase.firestore.util.AsyncQueue.lambda$panic$5(com.google.firebase:firebase-firestore@@17.1.5:377)
>        at com.google.firebase.firestore.util.AsyncQueue$$Lambda$5.run(Unknown Source:2)
>        at android.os.Handler.handleCallback(Handler.java:808)
>        at android.os.Handler.dispatchMessage(Handler.java:101)
>        at android.os.Looper.loop(Looper.java:166)
>        at android.app.ActivityThread.main(ActivityThread.java:7523)
>        at java.lang.reflect.Method.invoke(Method.java)
>        at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:245)
>        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:921)

> Caused by java.lang.RuntimeException: java.lang.IllegalStateException: Couldn't read row 0, col 0 from CursorWindow.  Make sure the Cursor is initialized correctly before accessing data from it.
>        at com.google.firebase.firestore.util.AsyncQueue.enqueue(com.google.firebase:firebase-firestore@@17.1.5:288)
>        at com.google.firebase.firestore.util.AsyncQueue$$Lambda$3.run(Unknown Source:4)
>        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:457)
>        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:301)
>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)
>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)
>        at com.google.firebase.firestore.util.AsyncQueue$DelayedStartFactory.run(com.google.firebase:firebase-firestore@@17.1.5:203)
>        at java.lang.Thread.run(Thread.java:784)

> Caused by java.lang.IllegalStateException: Couldn't read row 0, col 0 from CursorWindow.  Make sure the Cursor is initialized correctly before accessing data from it.
>        at android.database.CursorWindow.nativeGetBlob(CursorWindow.java)
>        at android.database.CursorWindow.getBlob(CursorWindow.java:405)
>        at android.database.AbstractWindowedCursor.getBlob(AbstractWindowedCursor.java:45)
>        at com.google.firebase.firestore.local.SQLiteMutationQueue.lambda$getNextMutationBatchAfterBatchId$4(com.google.firebase:firebase-firestore@@17.1.5:248)
>        at com.google.firebase.firestore.local.SQLiteMutationQueue$$Lambda$5.apply(Unknown Source:4)
>        at com.google.firebase.firestore.local.SQLitePersistence$Query.firstValue(com.google.firebase:firebase-firestore@@17.1.5:442)
>        at com.google.firebase.firestore.local.SQLiteMutationQueue.getNextMutationBatchAfterBatchId(com.google.firebase:firebase-firestore@@17.1.5:248)
>        at com.google.firebase.firestore.local.LocalStore.getNextMutationBatch(com.google.firebase:firebase-firestore@@17.1.5:451)
>        at com.google.firebase.firestore.remote.RemoteStore.fillWritePipeline(com.google.firebase:firebase-firestore@@17.1.5:539)
>        at com.google.firebase.firestore.remote.RemoteStore.enableNetwork(com.google.firebase:firebase-firestore@@17.1.5:221)
>        at com.google.firebase.firestore.remote.RemoteStore.start(com.google.firebase:firebase-firestore@@17.1.5:252)
>        at com.google.firebase.firestore.core.FirestoreClient.initialize(com.google.firebase:firebase-firestore@@17.1.5:225)
>        at com.google.firebase.firestore.core.FirestoreClient.lambda$new$2(com.google.firebase:firebase-firestore@@17.1.5:108)
>        at com.google.firebase.firestore.core.FirestoreClient$$Lambda$2.run(Unknown Source:8)
>        at com.google.firebase.firestore.util.AsyncQueue.lambda$enqueue$4(com.google.firebase:firebase-firestore@@17.1.5:309)
>        at com.google.firebase.firestore.util.AsyncQueue$$Lambda$4.call(Unknown Source:2)
>        at com.google.firebase.firestore.util.AsyncQueue.enqueue(com.google.firebase:firebase-firestore@@17.1.5:285)
>        at com.google.firebase.firestore.util.AsyncQueue$$Lambda$3.run(Unknown Source:4)
>        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:457)
>        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
>        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:301)
>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)
>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)
>        at com.google.firebase.firestore.util.AsyncQueue$DelayedStartFactory.run(com.google.firebase:firebase-firestore@@17.1.5:203)
>        at java.lang.Thread.run(Thread.java:784)

#### Relevant Code:
Init Firestore
```
FirebaseFirestore db = FirebaseFirestore.getInstance();
            FirebaseFirestoreSettings settings = new FirebaseFirestoreSettings.Builder()
                    .setTimestampsInSnapshotsEnabled(true)
                    .build();
            db.setFirestoreSettings(settings);
```

```
if (realmTablesResult.size() > 0) {
            WriteBatch batch = db.batch();
            Gson gson = new Gson();
            List<HistoryTrainingTable> arrayListOfUnmanagedObjects = realm.copyFromRealm(realmTablesResult);
            for (HistoryTrainingTable historyTrainingTable : arrayListOfUnmanagedObjects) {
                FATrainingTableHistory historyItem = new FATrainingTableHistory();
                historyItem.id = historyTrainingTable.getId();
                historyItem.trainingDate = historyTrainingTable.getTrainingDate();
                historyItem.description = gson.toJson(historyTrainingTable);
                historyItem.bestTimeValue = historyTrainingTable.getBestTimeValue();
                historyItem.avgContractionTime = historyTrainingTable.getAvgContractionTime();

                DocumentReference nycRef = db.collection(""history/"" + userId + ""/userHistory/"").document(String.valueOf(historyTrainingTable.getId()));
                batch.set(nycRef, historyItem);
            }


            // Commit the batch
            batch.commit().addOnCompleteListener(new OnCompleteListener<Void>() {
                @Override
                public void onComplete(@NonNull Task<Void> task) {
                    Log.d(""myTag"", ""batch.commit() complete"");
                }
            });
        }

        db.collection(""history/""+userId+""/userHistory/"")
                .get()
```

```
public class FATrainingTableHistory {

    public String id;
    public String description;
    public int bestTimeValue;
    public Date trainingDate;
    public int avgContractionTime;
}
```",Do you think it's possible that you're storing very large data in the batch? The only time I've seen this kind of error is if the blob data is too large for SQLite to initialize.,"Thanks for your answer.
> Do you think it's possible that you're storing very large data in the batch? The only time I've seen this kind of error is if the blob data is too large for SQLite to initialize.

Yeah, as you see in code I try to sync user history in this place.

> In the short term, my advice is to avoid creating batches that large.

So how I could control batch size in this case? In other words what better way to store such big number of documents?"
firebase/firebase-android-sdk,https://github.com/firebase/firebase-android-sdk/issues/126,"<!-- DO NOT DELETE 
validate_template=true
template_path=.github/ISSUE_TEMPLATE/bug.md
-->
Environment:

  * Android Studio version: 3.1.4
  * Firebase Component: Performance
  * Component version: 16.1.2

Problem:

#### Steps to reproduce:

What happened? How can we make the problem occur?

I got this crash report on Crashlytics. The device is a Samsung Galaxy A3, Android version 6.0.1.

#### Relevant Code:

```
Fatal Exception: java.lang.NoClassDefFoundError: com.google.android.gms.d.f.gm
       at com.google.android.gms.internal.firebase-perf.zzc.zzc(Unknown Source:54)
       at com.google.firebase.perf.network.FirebasePerfOkHttpClient.zza(Unknown Source:49)
       at com.google.firebase.perf.network.zzg.onResponse(Unknown Source:22)
       at okhttp3.RealCall$AsyncCall.execute(RealCall.java:153)
       at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)
       at java.lang.Thread.run(Thread.java:818)
```

The obfuscation code is uploaded but it is not mapping correctly. I've followed this tutorial here but nothing has changed: https://firebase.google.com/docs/crashlytics/get-deobfuscated-reports","Would you be able to upgrade to 16.2.0 to see if this still persists?

Additionally, I would also recommend upgrading to Android Studio version 3.2.1 as we've noticed issues with code minifying when using version 3.1.x.

As for the obfuscated code - because we minify and obfuscate the library before we ship it out, those proguard maps are not available to third party developers right now, so it's working as intended!","@tejasd Thank you, I will do it."
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1707,"The following commit added ##updateOptions##

https://github.com/firebase/FirebaseUI-Android/commit/d7aec385c2bbb807b39b4c3c444f161f55be17fc

https://github.com/firebase/FirebaseUI-Android/commit/d7aec385c2bbb807b39b4c3c444f161f55be17fc#r35785637

But it's half done. For example, the ##FirestoreRecyclerAdapter## constructor isn't updated and tested.

https://github.com/firebase/FirebaseUI-Android/commit/d7aec385c2bbb807b39b4c3c444f161f55be17fc#diff-5e8b0d86c8d693eb2093b88e08e1e76f

<!-- DO NOT DELETE 
validate_template=false
template_path=.github/ISSUE_TEMPLATE.md
-->
#### Steps to reproduce:

import com.firebase.ui.firestore.FirestoreRecyclerAdapter
and updateOptions on it
  
#### Observed Results:

  * What happened?  This could be a description, `logcat` output, etc.
  * NullPointerException on line 105: https://github.com/firebase/FirebaseUI-Android/commit/d7aec385c2bbb807b39b4c3c444f161f55be17fc#r35785637
  
#### Expected Results:

  * What did you expect to happen?
  * Options being actually updated
  
#### Relevant Code:

  ```
messagesInChatAdapter.updateOptions(messagesInChatOptions as FirestoreRecyclerOptions<MessageModel>)
  ```
",Could you provide code?,"@PatilShreyas thanks much for the quick reply. It's a simple issue. 

There are two **FirestoreRecyclerAdapters** not one. One in **ui/firestore** directory and other in **ui/database**

You added **updateOptions** in both of them but forgot to change the constructor in one of them. In **ui/database/FirestoreRecyclerAdapter** _mOptions_ is updated.

But the same isn't done in **ui/firestore/FirestoreRecyclerAdapter**. See lines 38 and 39  https://github.com/firebase/FirebaseUI-Android/blob/d7aec385c2bbb807b39b4c3c444f161f55be17fc/firestore/src/main/java/com/firebase/ui/firestore/FirestoreRecyclerAdapter.java#L38

@PatilShreyas @samtstern Let me know if you need more details. I can give the code but this is more succinct way to get to the root of the issue."
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1686,"<!-- DO NOT DELETE 
validate_template=false
template_path=.github/ISSUE_TEMPLATE.md
-->
I just updated to FirebaseUI 6.0.2. Debug build works fine but release build crashes.

> java.lang.RuntimeException: Facebook provider cannot be configured without dependency. Did you forget to add 'com.facebook.android:facebook-login:VERSION' dependency?

I have already included facebook login in .gradle file:
```
    implementation 'com.firebaseui:firebase-ui-auth:6.0.2'
    implementation 'com.facebook.android:facebook-login:5.5.1'
```
I downgraded to FirebaseUI version 5 again to resolve the crashes. Do you have any solution for it? Should I add anything to progaurd?","Does this also happen if you use a 4.x version of the Facebook SDK?

On Sat, Sep 21, 2019, 3:59 AM zjamshidi <notifications@github.com> wrote:

> I just updated to version 6.0.2. debug build works fine but release build
> crashes.
>
> java.lang.RuntimeException: Facebook provider cannot be configured without
> dependency. Did you forget to add
> 'com.facebook.android:facebook-login:VERSION' dependency?
>
> I have already included facebook login in .gradle file:
>
>     implementation 'com.firebaseui:firebase-ui-auth:6.0.2'
>     implementation 'com.facebook.android:facebook-login:5.5.1'
>
> I downgrade it to Firebase version 5 again to resolve the crashes. Do you
> have any solution for it?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/firebase/FirebaseUI-Android/issues/1686?email_source=notifications&email_token=ACATB2RGCJGE3FZZ55OKKFLQKX5ARA5CNFSM4IY53H22YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HM2FZDA>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ACATB2XCCNKREPVVBODHVM3QKX5ARANCNFSM4IY53H2Q>
> .
>
","I tried the following dependecies:
```
    implementation 'com.firebaseui:firebase-ui-auth:6.0.2'
    implementation 'com.facebook.android:facebook-login:4.41.0'
```
and again got the crash:

> java.lang.RuntimeException: Facebook provider cannot be configured without dependency. Did you forget to add 'com.facebook.android:facebook-login:VERSION' dependency?

When I disabled the progaurd it works fine. Here is the progaurd's rules:
```
-keepattributes SourceFile,LineNumberTable

-renamesourcefileattribute SourceFile

-keepattributes *Annotation*

-keep class com.crashlytics.** { *; }
-dontwarn com.crashlytics.**

-keep class com.revenuecat.purchases.** { *; }
```
Should I add any thing to progaurd rules? 
"
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1643,"<!-- DO NOT DELETE 
validate_template=false
template_path=.github/ISSUE_TEMPLATE.md
-->


Device Info:
  * Android device: Nexus 6P
  * Android OS version: Marshmallow (23)
  * Firebase/Play Services SDK version: firebase:firebase-core:16.0.9, firebase:firebase-auth:17.0.0
  * FirebaseUI version: firebase-ui-auth:5.0.0
  

When I try to run it on Oreo and Pie the Firebase auth UI works perfectly fine but when using Marshmallow the app crashes. The error is Unable to start activity (com.firebase.ui.auth.ui.idp.AuthMethodPickerActivity)
Please look at the logs below

Logs:

```
    Process: com.idevelopstudio.looter, PID: 5532
    java.lang.RuntimeException: Unable to start activity ComponentInfo{com.idevelopstudio.looter/com.firebase.ui.auth.ui.idp.AuthMethodPickerActivity}: android.content.res.Resources$NotFoundException: Resource ID #0x7f080142
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2416)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476)
        at android.app.ActivityThread.-wrap11(ActivityThread.java)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:148)
        at android.app.ActivityThread.main(ActivityThread.java:5417)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)
     Caused by: android.content.res.Resources$NotFoundException: Resource ID #0x7f080142
        at android.content.res.Resources.getValue(Resources.java:1351)
        at android.content.res.Resources.getDrawable(Resources.java:804)
        at android.content.Context.getDrawable(Context.java:458)
        at com.android.internal.policy.PhoneWindow.generateLayout(PhoneWindow.java:3934)
        at com.android.internal.policy.PhoneWindow.installDecor(PhoneWindow.java:3981)
        at com.android.internal.policy.PhoneWindow.getDecorView(PhoneWindow.java:1969)
        at androidx.appcompat.app.AppCompatDelegateImpl.createSubDecor(AppCompatDelegateImpl.java:575)
        at androidx.appcompat.app.AppCompatDelegateImpl.ensureSubDecor(AppCompatDelegateImpl.java:518)
        at androidx.appcompat.app.AppCompatDelegateImpl.setContentView(AppCompatDelegateImpl.java:466)
        at androidx.appcompat.app.AppCompatActivity.setContentView(AppCompatActivity.java:141)
        at com.firebase.ui.auth.ui.idp.AuthMethodPickerActivity.onCreate(AuthMethodPickerActivity.java:97)
        at android.app.Activity.performCreate(Activity.java:6237)
        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1107)
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2369)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476) 
        at android.app.ActivityThread.-wrap11(ActivityThread.java) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:148) 
        at android.app.ActivityThread.main(ActivityThread.java:5417) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)
  ```
","Can you try with the sample app in this repo (run the `app` module) and see if you get a crash on your device?  If you don't get a crash then this means there's something else going wrong in your app.  Even though the crash is in FirebaseUI, it could be related to the other dependencies you have or how your app's own resources are being merged in,",
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1608,"Hi @samtstern 
I go through [FirestorePagingAdapter](https://github.com/firebase/FirebaseUI-Android/blob/master/firestore/src/main/java/com/firebase/ui/firestore/paging/FirestorePagingAdapter.java) and there is a method in it.

```java
public void retry() {
        FirestoreDataSource source = mDataSource.getValue();
        if (source == null) {
            Log.w(TAG, ""Called retry() when FirestoreDataSource is null!"");
            return;
        }

        source.retry();
    }
```
I observed that `source` always remains null. Every time it shows Log...
 _""Called retry() when FirestoreDataSource is null!""_. 

I also tested calling this method from [FirestorePagingActivity](https://github.com/firebase/FirebaseUI-Android/blob/master/app/src/main/java/com/firebase/uidemo/database/firestore/FirestorePagingActivity.java) after caught in error. Still, it failed.

I implemented this in our [FirebaseRecyclerPagingAdapter](https://github.com/firebase/FirebaseUI-Android/blob/version-4.4.0-dev/database/src/main/java/com/firebase/ui/database/paging/FirebaseRecyclerPagingAdapter.java) and it is running fine!
I did it by adding `Observer` for `DataSource` and it's running fine without null value.
",Does LiveData not hold values if nobody is observing?,"@samtstern  Yes.
I observed that while working on [`FirebaseRecyclerPagingAdaper`](https://github.com/firebase/FirebaseUI-Android/blob/version-4.4.0-dev/database/src/main/java/com/firebase/ui/database/paging/FirebaseRecyclerPagingAdapter.java).

I did an experiment:
- When I added this line 
 `mDataSource.observeForever(mDataSourceObserver)`
Then after calling `getValue()` on `mDataSource` doesn't returned a null value

- When I commented the code of `observeForever`
Then `mDataSource.getValue()` always returned a null value.

By observing this, maybe LiveData not hold values if nobody is observing"
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1555,"![7891877299955355863](https://user-images.githubusercontent.com/12398645/50184161-170e3580-02c9-11e9-9f90-af2acb8630b5.png)
",What version of other dependencies are you using?,
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1489,"So I've literally tried anything and everything I could think of to fix this.

I have my anon user that I'm trying to link/upgrade with an **existing** account, now this works if I try to link/upgrade it to an account that say, has an email & a phone number attached.

But the problem is, let's say I have said account above AND a Facebook account with the same email, those will not merge, it just returns the error. Now I'm not sure if this is intended behavior and if it is there's probably a better way to handle it than pass it as a ""DEVELOPER_ERROR"".

Accounts laid out:

""Facebook Provider"": ""abcd1234@gmail.com""
""Google & Phone Provider (Linked)"": ""abcd1234@gmail.com & +12345678900""

Works ONLY using Phone: Anon upgrade to -> ""Google & Phone Provider (Linked)""
Doesn't work: Anon upgrade to -> ""Facebook Provider""",Could you lay out the reproduction steps in order so that I can get this bug to happen?  Pretend I am very stupid and state the obvious parts too :-),"@samtstern Ya sorry! It's kinda hard to explain but I'll try my best!

First time users are logged in Anonymously. Then I have the login builder with the enable auto upgrade. 

Anonymous User trying to login:
-- Upgrading to NEW account (Works)
-- Upgrading to existing account (Google/Phone) works ONLY when using the Phone number.
-- Upgrading to existing account (Facebook w/ same email as above Google) doesn't work.

See photo below for the accounts, the only way I can upgrade an anon user to any of the 2 is by using the phone number.

<img width=""939"" alt=""screen shot 2018-10-18 at 12 24 59 pm"" src=""https://user-images.githubusercontent.com/5241478/47169697-304b3380-d2d2-11e8-993b-98e01f200448.png"">
"
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1434,"
### Describe your environment

  * Android device:  Nexus 5
  * Android OS version: 6
  * Google Play Services version: 12.8.74
  * Firebase/Play Services SDK version: firebase-auth:16.0.3, play-services-location:15.0.1
  * FirebaseUI version: 4.1.0
  
### Step 3: Describe the problem:

1. In Portrait mode 
      As in screenshot 1, the blank space is leaved if used two providers.

2. In Landscape mode
     As in screenshot 2, the blank space is leaved at the bottom of the logo and logo is not in vertical center.

#### Steps to reproduce:

  1. Use FirebaseUI using
startActivityForResult(
                AuthUI.getInstance()
                        .createSignInIntentBuilder()
                        .setAvailableProviders(providers)
                        .setLogo(R.mipmap.tb_logo)      // Set logo drawable
                        .setTheme(R.style.AppTheme)      // Set theme
                        .build(),
                RC_SIGN_IN);
  2. Run the app
  3. See in both orientations
  
#### Observed Results:

  * All is in screenshots
  
#### Expected Results:

  * What did you expect to happen?
In Portrait mode, if two providers are used the space should evenly distributed between the logo and buttons.

In Landscape mode, the logo should be placed in vertical center of the screen.
  
#### Relevant Code:
Just copy paste the following :

  // Choose authentication providers
       
       List<AuthUI.IdpConfig> providers = Arrays.asList(
                new AuthUI.IdpConfig.PhoneBuilder().build(),
                new AuthUI.IdpConfig.FacebookBuilder().build());

        startActivityForResult(
                AuthUI.getInstance()
                        .createSignInIntentBuilder()
                        .setAvailableProviders(providers)
                        .setLogo(R.mipmap.tb_logo)      // Set logo drawable
                        .setTheme(R.style.AppTheme)      // Set theme
                        .build(),
                RC_SIGN_IN);

![screenshot_1](https://user-images.githubusercontent.com/38163139/45026564-4ff90600-b05c-11e8-8fd4-c54e1d072f6a.png)
![screenshot_2](https://user-images.githubusercontent.com/38163139/45026577-56877d80-b05c-11e8-8167-9de1ed06a4da.png)
","What is the bug in portrait mode?  That looks correct to me.

Also you say this is ""Android version 6"" but from the look of the screenshots that device is running Android 4.x ... can you provide a screenshot from a device running Lollipop, Marshmallow, or higher?  I just want to see if this is Android version specific.",
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1210,"I am currently converting my Firebase UI components to Firestore UI components. When building the `FirestoreRecyclerAdapter` and manually call the `adapter.startListening()` or initialize it via `new FirestoreRecyclerOptions.Builder().setLifeCycleOwner()` I stumble on the following fatal exception.

    FATAL EXCEPTION: main
    Process: packagename, PID: 3129
    java.lang.NoSuchMethodError: No virtual method getDocument()Lcom/google/firebase/firestore/DocumentSnapshot; in class Lcom/google/firebase/firestore/DocumentChange; or its super classes (declaration of 'com.google.firebase.firestore.DocumentChange' appears in /data/app/packagename-yHh4aIRPAZwxxRYgunJivQ==/split_lib_dependencies_apk.apk)
    at com.firebase.ui.firestore.FirestoreArray.onDocumentAdded(FirestoreArray.java:98)
    at com.firebase.ui.firestore.FirestoreArray.onEvent(FirestoreArray.java:83)
    at com.firebase.ui.firestore.FirestoreArray.onEvent(FirestoreArray.java:21)
    at com.google.firebase.firestore.zzi.onEvent(Unknown Source:17)
    at com.google.android.gms.internal.zzeyn.zza(Unknown Source:6)
    at com.google.android.gms.internal.zzeyo.run(Unknown Source:6)
    at android.os.Handler.handleCallback(Handler.java:789)
    at android.os.Handler.dispatchMessage(Handler.java:98)
    at android.os.Looper.loop(Looper.java:164)
    at android.app.ActivityThread.main(ActivityThread.java:6809)
    at java.lang.reflect.Method.invoke(Native Method)
    at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240)
    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)

The error states that the class `DocumentSnapshot` doesn't contain a method `getDocument` which after checking is correct. However this is also how the docs states this implementation.

The adapter with query

    mRecyclerView = (RecyclerView) view;
                mRecyclerView.setLayoutManager(new LinearLayoutManager(context));
    
                Query query = mFirestore.collection(""spots"");
                FirestoreRecyclerOptions<SpotModel> options = new FirestoreRecyclerOptions.Builder<SpotModel>().setQuery(query, SpotModel.class).setLifecycleOwner(this).build();
    
                mAdapter = new FirestoreRecyclerAdapter<SpotModel, SpotHolder>(options) {
                    @Override
                    public SpotHolder onCreateViewHolder(ViewGroup parent, int viewType) {
                        View view = LayoutInflater.from(parent.getContext()).inflate(R.layout.card_spot, parent, false);
    
                        return new SpotHolder(view);
                    }
    
                    @Override
                    protected void onBindViewHolder(@NonNull SpotHolder holder, int position, @NonNull SpotModel model) {
                        holder.bind(model);
                    }
                };
    
                mRecyclerView.setAdapter(mAdapter);

FirebaseUI dependencies

    implementation 'com.firebaseui:firebase-ui-auth:3.2.2'
    implementation 'com.firebaseui:firebase-ui-database:3.2.2'
    implementation 'com.firebaseui:firebase-ui-firestore:3.2.2'

The adapter is being initialized in the `onCreateView` method of a fragment.",Could post the output of `./gradlew dependencies`?,"Full output:

Configure project :app
Could not find google-services.json while looking in [src/nullnull/debug, src/debug/nullnull, src/nullnull, src/debug, src/nullnullDebug]
registerResGeneratingTask is deprecated, use registerGeneratedFolders(FileCollection)
Could not find google-services.json while looking in [src/nullnull/release, src/release/nullnull, src/nullnull, src/release, src/nullnullRelease]
registerResGeneratingTask is deprecated, use registerGeneratedFolders(FileCollection)

> Task :dependencies

------------------------------------------------------------
Root project
------------------------------------------------------------

No configurations


BUILD SUCCESSFUL in 2s
1 actionable task: 1 executed

Double checked if google-services.json is missing but it's placed in the projects app folder."
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1175,"
  * Android device: N/A
  * Android OS version: minSDK 16
  * Google Play Services version: 11.8.0
  * Firebase/Play Services SDK version: 27
  * FirebaseUI version: 3.2.2
  
### Step 3: Describe the problem:

#### Steps to reproduce:

  1. Switch from Firebase UI 3.2.1 to 3.2.2 in the build.gradle files
  2. Run Assemble task that includes minifyEnabled true
  
#### Observed Results:

```
 Build fails with this exception:

Initializing...

Warning: com.firebase.ui.auth.provider.TwitterProvider: can't find referenced class retrofit2.Call
Warning: com.firebase.ui.auth.provider.TwitterProvider: can't find referenced class retrofit2.Call

Note: io.grpc.internal.zzbq: can't find dynamically referenced class javax.naming.directory.InitialDirContext
Note: io.grpc.internal.zzbq: can't find dynamically referenced class com.sun.jndi.dns.DnsContextFactory
Note: there were 2 unresolved dynamic references to classes or interfaces.
      You should check if you need to specify additional program jars.
      (http://proguard.sourceforge.net/manual/troubleshooting.html#dynamicalclass)

Warning: there were 2 unresolved references to classes or interfaces.
         You may need to add missing library jars or update their versions.
         If your code works fine without the missing classes, you can suppress
         the warnings with '-dontwarn' options.
         (http://proguard.sourceforge.net/manual/troubleshooting.html#unresolvedclass)

Warning: Exception while processing task java.io.IOException: Please correct the above warnings first.
:app:transformClassesAndResourcesWithProguardForRelease FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':app:transformClassesAndResourcesWithProguardForRelease'.
> Job failed, see logs for details

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org


Deprecated Gradle features were used in this build, making it incompatible with Gradle 5.0.
See https://docs.gradle.org/4.6/userguide/command_line_interface.html#sec:command_line_warnings

BUILD FAILED in 2m 9s

52 actionable tasks: 40 executed, 12 up-to-date
```

#### Expected Results:

Build leading to production APK
",Can you try that with my previous code?,@SUPERCILEX : With `-dontwarn com.firebase.ui.auth.provider.**` in my own proguard file the build is finishing successful.
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/1118,"  * Android device: Google Pixel
  * Android OS version: 8.1
  * Google Play Services version: 11.8.0
  * Firebase/Play Services SDK version: 11.8.0
  * FirebaseUI version: 3.2.0
  
After upgrading to version 3.2.0 Smartlock email picker is shown even though authentcation is set to phone or Facebook. After email picker has been closed, the correct flow follows.


  ```
       startActivityForResult(
                AuthUI.getInstance()
                        .createSignInIntentBuilder()
                        .setLogo(R.drawable.ic_happenings)
                        .setPrivacyPolicyUrl(getString(R.string.privacy_policy_link))
                        .setAvailableProviders(
                                Arrays.asList(
                                        new AuthUI.IdpConfig.PhoneBuilder().build()
                                ))
                        .build(),
                RC_SIGN_IN);
  ```
","Do you mean this picker?
![smartlock](https://user-images.githubusercontent.com/8466666/35286000-9a2281c4-0013-11e8-9df4-15951861e3f7.png)

That is shown when you have previously saved an account with FirebaseUI and allows you to log in with a single tap.  It's the intended behavior for now.

Or do you mean something else?",
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/904,"In Nov 2016 an [override to the Fabric apikey](https://github.com/firebase/FirebaseUI-Android/pull/396/files/ec40c413ced3268dadd9fda933a8ca4d2eef5182#diff-72b30eb5e208275c795ce7e9fb7275ae) was added to get around a Twitter auth issue.

Twitter auth is no longer part of Fabric and the override of this key to the string value causes issues with the Fabric SDK (namely that it cannot start up because the string value it finds isn't present).

I'd like to propose removing this value from the auth AndroidManifest.",Do we just need to remove those lines from the `AndroidManifest.xml` or is there more to it?  If so I am happy to do it or you can send a PR to the `version-2.3.1-dev` branch.,I'll send a PR. Just wanted an open issue to reference in the PR 👍 
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/759,"Greetings, I have implemented the new phone authentication feature and followed all of the required steps. However, after I submit my phone number I receive a dialog with the following message ""The custom token corresponds to a different audience"". Any help would be greatly appreciated as I intend on migrating from digits asap.",Can you show me a screenshot?,"@samtstern with FirebaseUI, I have enabled phone auth on  firebase console and also checked project settings and google-service.json

gradle
```
    compile 'com.google.firebase:firebase-core:11.0.1'
    compile 'com.google.firebase:firebase-messaging:11.0.1'
    compile 'com.google.firebase:firebase-auth:11.0.1'
    compile 'com.firebaseui:firebase-ui-auth:2.0.1'
```
manifest
```
<service
            android:name="".networking.push.FirebaseIDService"">
            <intent-filter>
                <action android:name=""com.google.firebase.INSTANCE_ID_EVENT""/>
            </intent-filter>
        </service>

        <service
            android:name="".networking.push.FirebaseService"">
            <intent-filter>
                <action android:name=""com.google.firebase.MESSAGING_EVENT""/>
            </intent-filter>
        </service>

        <meta-data
            android:name=""com.facebook.sdk.ApplicationId""
            android:value=""@string/facebook_app_id""
            tools:replace=""android:value""/>

        <meta-data
            android:name=""io.fabric.ApiKey""
            android:value=""hidden_for_this_comment""
            tools:replace=""android:value""/>

        <meta-data
            android:name=""com.google.android.gms.version""
            android:value=""@integer/google_play_services_version"" />

```
code

```
  startActivityForResult(
                            AuthUI.getInstance()
                                    .createSignInIntentBuilder()
                                    .setProviders(Arrays.asList(
                                            new AuthUI.IdpConfig.Builder(AuthUI.PHONE_VERIFICATION_PROVIDER).build()
                                    ))
                                    .setTheme(R.style.DigitsTheme)
                                    .build(),
                            FIREBASE_SIGN_IN);
```





![device-2017-06-17-021453](https://user-images.githubusercontent.com/13194727/27247591-cd387258-5302-11e7-938a-c52d0eaf45f7.png)

"
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/709,"### Step 2: Describe your environment

`version-2.0.0-dev`
  
### Step 3: Describe the problem:

#### Steps to reproduce:

  1. Email sign in, smartlock disabled
  2. Existing account
  3. Enter password
  
#### Observed Results:

  * Offered to save my password with SmartLock
  
#### Expected Results:

  * Don;'t offer to save
  
#### Relevant Code:

`none`",Maybe try again or clear the app data? It's probably some left over state or something.,@SUPERCILEX yeah I can't repro either ... maybe I was just tired and enabled smartlock by accident.
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/234,"Steps to reproduce:
1. Login using email, password mechanism. 
2. Use SmartLock to remember the login credentials.
3. Delete the user using the ""Delete account"" button
4. go back to the auth screen and try to login / signup again.
5. Get stuck at this blank screen

![screenshot_20160803-124040](https://cloud.githubusercontent.com/assets/73044/17357094/a6eac378-5978-11e6-8875-f1dac913788d.png)

![screenshot_20160803-124044](https://cloud.githubusercontent.com/assets/73044/17357093/a6dff1c8-5978-11e6-8651-a2a2e7e8e91e.png)

In logcat, I can see an error as follows

```
08-03 12:34:35.870 15352-15352/com.firebase.uidemo W/ChooseAccountActivity: Unsuccessful sign in with email and password
                                                                        com.google.firebase.auth.FirebaseAuthInvalidUserException: There is no user record corresponding to this identifier. The user may have been deleted.
                                                                            at com.google.android.gms.internal.zzafg.zzes(Unknown Source)
                                                                            at com.google.android.gms.internal.zzafd$zzg.zza(Unknown Source)
                                                                            at com.google.android.gms.internal.zzafo.zzet(Unknown Source)
                                                                            at com.google.android.gms.internal.zzafo$zza.onFailure(Unknown Source)
                                                                            at com.google.android.gms.internal.zzafj$zza.onTransact(Unknown Source)
                                                                            at android.os.Binder.execTransact(Binder.java:453)
```

There seems to be no way to get out of this scenario even by clearing the app cache etc. 
","Which 'delete account' button are you clicking in step 3 in your original report?
","Basically in the sample app, the screen after a successful login has a delete account button. I think the SmartLock implementation might need a little tweaking. If the account it expects to find is already deleted, then the error is probably not being handled correctly.

Here is the screenshot.

![screenshot_20160803-224343-2-480x483](https://cloud.githubusercontent.com/assets/73044/17374907/66360aaa-59cc-11e6-8e24-534455829340.png)
"
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/121,"I'm using the AuthUI to login to an app I'm migrating to the new Firebase. The old login worked fine but the new one always stops with facebook or google.

Call:
`startActivityForResult(
                        AuthUI.getInstance(FirebaseApp.getInstance())
                                .createSignInIntentBuilder()
                                .setProviders(
                                        AuthUI.EMAIL_PROVIDER,
                                        AuthUI.GOOGLE_PROVIDER,
                                        AuthUI.FACEBOOK_PROVIDER)
                                .build(),
                        RC_SIGN_IN);
`
The spinner spins forever and the Activity never finishes. Back doesn't do anything.
![2016-05-19 00 20 06](https://cloud.githubusercontent.com/assets/1415461/15379427/5c7e37a8-1d6d-11e6-87a9-91418c3894dd.png)

Using email works. 

I have setup FB app id & secret in the firebase console. The app has been migrated to the new firebase SDK.

There's no errors in console. 

Let me know if I can help you debug somehow to get more info to solve the situation. I know this might have too little info to track the issue.
","Do you see any errors in the advanced logs around the time you attempt this? If you wish to attempt to debug, the code for this activity is in AuthenticationMethodPicker. If you are physically at I/O, I'd love to meet and help you diagnose the issue in person. If not, we can continue to correspond here.
","Hey,
Unfortunately not in the IO this year :-(

I'm not quite sure what you mean by ""advanced logs""? Could you point me to some doc to where I can figure out how to access more logging / turn on more logging for this? 

Here's a video what's happening when I press the FB login:
https://youtu.be/aQ0W_GD47Kc

There seems to be a lot going on but somehow it hangs at the very end.

Interestingly, when I tried with Google again I get this message to the logcat:
`W/AuthMethodPicker: Firebase login unsuccessful`
The activity still doesn't finish though.

I keep seeing these errors in the log:
`E/DynamiteModule: Failed to load module descriptor class: Didn't find class ""com.google.android.gms.dynamite.descriptors.com.google.firebase.auth.ModuleDescriptor"" on path: DexPathList[`

But I'm not 100% if this is related or not.

I'm not able to see much from the console as there seems to be some issues with it right now. The auth part should be correct though (I double checked). For the database side I only see:
<img width=""1430"" alt=""screen shot 2016-05-19 at 14 11 30"" src=""https://cloud.githubusercontent.com/assets/1415461/15393115/c32664c2-1dcb-11e6-8a6d-6e175f7e43fb.png"">

Which makes me wonder if something failed in the import process from the old data.

Sorry, I know the information is very fragmented. I'm just not sure which is relevant and which isn't. Thank you for your help, much appreciated!
"
firebase/FirebaseUI-Android,https://github.com/firebase/FirebaseUI-Android/issues/66,"Is there a specific reason why you are not using the support library equivalents of DialogFragment, FragmentManager, etc...?
","Can you tell what using those would change?
","I just realized that you are setting minSdk 16, so I don't think people will run into actual issues. But just to be sure, I have created a pull request that makes use of the support DialogFragment and getSupportFragmentManager. See #67 
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2286,"**Describe the bug**
When I try to run `./refine build`, I get a 501 error when the build system attempts to contact `http://repo.maven.apache.org/`.  This appears to be related to Maven's HTTPS switchover on 2020-01-15 (https://blog.sonatype.com/central-repository-moving-to-https), which causes `http://` calls to be rejected.

**To Reproduce**
Steps to reproduce the behavior:
1. Clone the master repository
2. `./refine build`

**Current Results**
```[INFO] ------------------------------------------------------------------------
[INFO] Building OpenRefine 3.3-SNAPSHOT
[INFO] ------------------------------------------------------------------------
Downloading: http://repo.maven.apache.org/maven2/org/codehaus/mojo/build-helper-maven-plugin/1.8/build-helper-maven-plugin-1.8.pom
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO]
[INFO] OpenRefine ......................................... FAILURE [  3.014 s]
[INFO] OpenRefine - main .................................. SKIPPED
[INFO] OpenRefine - server ................................ SKIPPED
[INFO] OpenRefine - extensions ............................ SKIPPED
[INFO] OpenRefine - Jython extension ...................... SKIPPED
[INFO] OpenRefine - Wikidata extension .................... SKIPPED
[INFO] OpenRefine - Database extension .................... SKIPPED
[INFO] OpenRefine - Gdata extension ....................... SKIPPED
[INFO] OpenRefine - PC-axis extension ..................... SKIPPED
[INFO] OpenRefine - Phonetic clustering extension ......... SKIPPED
[INFO] OpenRefine - packaging ............................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3.927 s
[INFO] Finished at: 2020-01-15T12:02:00-05:00
[INFO] Final Memory: 7M/37M
[INFO] ------------------------------------------------------------------------
[ERROR] Plugin org.codehaus.mojo:build-helper-maven-plugin:1.8 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.codehaus.mojo:build-helper-maven-plugin:jar:1.8: Could not transfer artifact org.codehaus.mojo:build-helper-maven-plugin:pom:1.8 from/to central (http://repo.maven.apache.org/maven2): Failed to transfer file: http://repo.maven.apache.org/maven2/org/codehaus/mojo/build-helper-maven-plugin/1.8/build-helper-maven-plugin-1.8.pom. Return code is: 501 , ReasonPhrase:HTTPS Required. -> [Help 1]
```

**Expected behavior**
The build system is able to successfully contact the Maven repository and download necessary files.

**Desktop (please complete the following information):**
 - OS: macOS 10.14.6
 - Browser Version: n/a
 - JRE or JDK Version: openjdk 12.0.1 2019-04-16

**OpenRefine (please complete the following information):**
 - Version: 3.3-SNAPSHOT
","Could you also report the version of Maven that you are using?
I don't see how this could come from OpenRefine's own Maven configuration since we do not specify the source repository at all.",I'm using the version that the build process downloads (3.2.2); `which mvn` returns nothing for me.
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2194,"When pressing the Enter key in the Wikidata login form from the Wikidata extension, one would expect the form to be submitted, which currently does not happen.",Can I take this one?,@Jataki please!
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2168,"**Describe the bug**

When sending a property suggest request in the reconciliation dialog (on the right, ""Also use relevant details from other columns:""), OpenRefine sends the old Freebase default type identifier (`type/property`) to the suggest service, instead of the entity type selected (on the left, ""Reconcile each cell to an entity of one of these types:"").

**To Reproduce**

1. Add `console.log(""suggestOptions.type:"", suggestOptions.type);` in `standard-service-panel.js`, line 252 (after `if (type) {...}`)
2. Open Reconciliation dialog, select the Wikidata reconciliation service
4. In the area on the left (""Reconcile each cell to an entity of one of these types:""), change the type selection
5. Open your browser's web console, and check the ""suggestOptions.type"" output

**Current Results**

The `suggestOptions.type` is undefined, resulting in usage of the default type specified in `custom-suggest.js`, line 105 (`type/property`).

**Expected behavior**

The `suggestOptions.type` should be the type selected under ""Reconcile each cell to an entity of one of these types:"", like `Q5`.

**Desktop:**

- OS: Linux Mint 18.1 Cinnamon 64-bit
- Browser Version: Firefox 68.0.1 (64-bit)
- JRE or JDK Version: OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10)
- Version: tested in OpenRefine 3.2 and in master","Should we consider this as a bug fix or as a new feature to the reconciliation API? It seems that the code had some sort of Freebase-specific support for that indeed, so I guess we can treat that as a fix.

That reminds me of #201, which is also related to type restriction in suggest services. Do you think this was also supported in a Freebase-specific way before?","> So that would allow services to rely on the chosen type to suggest more relevant properties, if I understand correctly.

Yes, you can test that with the branch from #2169 using our GND reconciliation service: https://lobid.org/gnd/reconcile

It is called like this:

https://lobid.org/gnd/reconcile/suggest/property?prefix=Ort&type=Person
https://lobid.org/gnd/reconcile/suggest/property?prefix=Ort&type=CorporateBody
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2162,"**Describe the bug**
OpenRefine 3.2 return cluster with one-row count for key collision methods are impacted. 
The issue was introduced in the 3.2 release. 

**To Reproduce**
Create a project from clipboard
insert three line 
```
a
b
c
```
invoke clustering > key collision > fingerprint

**Current Results**
we see cluster with one-row count. It seems only the key collision methods are impacted. 

![clipboard - OpenRefine](https://user-images.githubusercontent.com/29434859/65213628-eab06100-da74-11e9-8f45-5457cce8f284.png)

**Expected behavior**
OpenRefine should show the message `No clusters were found with the selected method`

**Desktop (please complete the following information):**
 - OS: Ubuntu 16.04
 - Browser Chromium Version 76.0.3809.100
 - JRE or JDK Version:java version ""1.8.0_201""

**OpenRefine (please complete the following information):**
 - Version 3.2 

I tested with OpenRefine 3.1 and it behaves as expected (ie no cluster found)

",Can you check out the master branch and see if you still have the same problem?,
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2156,"Updating openrefine from 3.1 to 3.2, mataining old workspace makes the ui corrupted and unusable

Steps to reproduce the behavior:
1. Install openrefine 3.2
2. point the data direcotry to the previously used data dir
3. start open refine
4. Ui appears as in the screenshot
![Screenshot_2019-09-11 OpenRefine](https://user-images.githubusercontent.com/33548070/64709655-ee614800-d4b6-11e9-9b2e-f22aadc5a33d.png)
![Screenshot_2019-09-11 OpenRefine(2)](https://user-images.githubusercontent.com/33548070/64709659-f02b0b80-d4b6-11e9-9bfb-7ce4c4d181a3.png)
![Screenshot_2019-09-11 OpenRefine(1)](https://user-images.githubusercontent.com/33548070/64709661-f15c3880-d4b6-11e9-9348-e9611627d594.png)

 - OS: CentOS Linux 7
 - Browser Version:Firefox 69
 - JRE or JDK Version: 
openjdk version ""9.0.4""
OpenJDK Runtime Environment (build 9.0.4+11)
OpenJDK 64-Bit Server VM (build 9.0.4+11, mixed mode)

 - Version 3.2
",Can you see any error message either in the server console or in the browser console?,"We don't have any third party extension.

in the browser console i see this warning (even in 3.1)
```
Source map error: request failed with status 404
Resource URL: https://refine.diennea.lan/index-bundle.js
Source Map URL: jquery.contextMenu.min.js.map

```
and those errors

```
TypeError: project is nullindex-bundle.js:28144:7
    _renderProjects https://refine.diennea.lan/index-bundle.js:28144
    success https://refine.diennea.lan/index-bundle.js:28130
    fire https://refine.diennea.lan/index-bundle.js:3121
    fireWith https://refine.diennea.lan/index-bundle.js:3233
    done https://refine.diennea.lan/index-bundle.js:9277
    callback https://refine.diennea.lan/index-bundle.js:9687
    send https://refine.diennea.lan/index-bundle.js:9693
    ajax https://refine.diennea.lan/index-bundle.js:9178
    _fetchProjects https://refine.diennea.lan/index-bundle.js:28125
    _buildTagsAndFetchProjects https://refine.diennea.lan/index-bundle.js:28093
    OpenProjectUI https://refine.diennea.lan/index-bundle.js:28062
    renderActionArea https://refine.diennea.lan/index-bundle.js:27688
    <anonymous> https://refine.diennea.lan/index-bundle.js:27692
    fire https://refine.diennea.lan/index-bundle.js:3121
    fireWith https://refine.diennea.lan/index-bundle.js:3233
    ready https://refine.diennea.lan/index-bundle.js:3445
    completed https://refine.diennea.lan/index-bundle.js:3476
```

and

```
TypeError: Refine.actionAreas[i].ui is undefinedindex-bundle.js:27669:7
    resize https://refine.diennea.lan/index-bundle.js:27669
```"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2146,"**problem during connecting with database**

error:Cannot load connection class because of underlying exception: 'java.lang.NumberFormatException: For input string: ""18.136.56.185:3365""'.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'Create Project'
2. Click on 'Database'
3. Fill the Database field for connection(demo)""confidential data""
 'DB Name: project_sales
Table Name: data
Host: http:18.136.56.188
Username: dm_team2
Password: NA '
4. See error -popup

**Current Results**
<blockquote class=""imgur-embed-pub"" lang=""en"" data-id=""a/bxH445X"" data-context=""false"" ><a href=""//imgur.com/a/bxH445X"">error- open refine</a></blockquote><script async src=""//s.imgur.com/min/embed.js"" charset=""utf-8""></script>

**Screenshots**


**Desktop:**
 - OS: [Windows 10]64 bit
 - Browser Version: chrome 76
- java version ""1.8.0_221""
Java(TM) SE Runtime Environment (build 1.8.0_221-b11)
Java HotSpot(TM) Client VM (build 25.221-b11, mixed mode)

**open refine- Version 3.2 [55c921b]
",why add the http protocol to the host field?,
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2142,"**Describe the bug**
Text facets show incorrect text when compared to the original google sheet that was imported. 

**To Reproduce**
Steps to reproduce the behavior:
1. import from google 
2. text facet a column
3. text facet the next column
4. select item from first facet
5. corresponding item from the second facet is not on the same line as the first facet in the google sheet that was uploaded. 

**Current Results**
shows data that cannot be found in the imported spreadsheet at all.

**Expected behavior**
expected line to match google sheet contents.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: IOS Mojave 10.14.6
 - Browser Version:  Chrome 19
 - JRE or JDK Version:[output of ""java -version"" e.g. JRE 1.8.0_181]

**OpenRefine (please complete the following information):**
 - Version 3.2

**Datasets**
If you are allowed and are OK with making your data public, it would be awesome if you can include or attach the data causing the issue or a URL pointing to where the data is.
If you are concerned about keeping your data private, ping us on our [mailing list](https://groups.google.com/forum/#!forum/openrefine)

**Additional context**
Add any other context about the problem here.
","What sort of unexpected data do you see in the text facet? Could you share your dataset, maybe? Or provide screenshots which demonstrate the issue?",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2091,"**Describe the bug**
clean clone from master branch and starting OpenRefine's refine .bat file on Windows 10 causes Butterfly error.

**To Reproduce**
Steps to reproduce the behavior:
1. git clone
2. refine build
3. refine.bat
4. See the error

**Current Results**

**On browser:**

HTTP ERROR 500
Problem accessing /. Reason:

    Butterfly Error
Butterfly incurred in the following errors while initializing:
java.lang.Exception: Failed to initialize module wikidata [edu.mit.simile.butterfly.ButterflyModuleImpl]
	at edu.mit.simile.butterfly.Butterfly.initializeModule(Butterfly.java:478)
	at edu.mit.simile.butterfly.Butterfly.configure(Butterfly.java:451)
	at edu.mit.simile.butterfly.Butterfly.init(Butterfly.java:308)
	at org.mortbay.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:440)
	at org.mortbay.jetty.servlet.ServletHolder.doStart(ServletHolder.java:263)
	at com.google.refine.RefineServer.configure(Refine.java:291)
	at com.google.refine.RefineServer.init(Refine.java:203)
	at com.google.refine.Refine.init(Refine.java:109)
	at com.google.refine.Refine.main(Refine.java:103)
Caused by: org.mozilla.javascript.EvaluatorException: Can't find method com.google.refine.RefineServlet.cacheClass(object). (file:/C:/Users/THAD/OpenRefine/main/webapp/../../extensions/wikidata/module/MOD-INF/controller.js#16)
	at org.mozilla.javascript.DefaultErrorReporter.runtimeError(DefaultErrorReporter.java:77)
	at org.mozilla.javascript.Context.reportRuntimeError(Context.java:998)
	at org.mozilla.javascript.Context.reportRuntimeError(Context.java:1053)
	at org.mozilla.javascript.Context.reportRuntimeError1(Context.java:1016)
	at org.mozilla.javascript.NativeJavaMethod.call(NativeJavaMethod.java:144)
	at org.mozilla.javascript.optimizer.OptRuntime.call1(OptRuntime.java:32)
	at org.mozilla.javascript.gen.file__C__Users_THAD_OpenRefine_main_webapp_______extensions_wikidata_module_MOD_INF_controller_js_16._c_init_1(file:/C:/Users/THAD/OpenRefine/main/webapp/../../extensions/wikidata/module/MOD-INF/controller.js:16)
	at org.mozilla.javascript.gen.file__C__Users_THAD_OpenRefine_main_webapp_______extensions_wikidata_module_MOD_INF_controller_js_16.call(file:/C:/Users/THAD/OpenRefine/main/webapp/../../extensions/wikidata/module/MOD-INF/controller.js)
	at org.mozilla.javascript.ContextFactory.doTopCall(ContextFactory.java:405)
	at org.mozilla.javascript.ScriptRuntime.doTopCall(ScriptRuntime.java:3508)
	at org.mozilla.javascript.gen.file__C__Users_THAD_OpenRefine_main_webapp_______extensions_wikidata_module_MOD_INF_controller_js_16.call(file:/C:/Users/THAD/OpenRefine/main/webapp/../../extensions/wikidata/module/MOD-INF/controller.js)
	at edu.mit.simile.butterfly.ButterflyModuleImpl.scriptInit(ButterflyModuleImpl.java:636)
	at edu.mit.simile.butterfly.ButterflyModuleImpl.init(ButterflyModuleImpl.java:94)
	at edu.mit.simile.butterfly.Butterfly.initializeModule(Butterfly.java:476)
	... 8 more

**on console:**

```shell
C:\Users\THAD\OpenRefine>""C:\Program Files\Java\jdk1.8.0_191\bin\java.exe"" -cp ""server\classes;server\target\lib\*""   -Xms1400M -Xmx1400M -Drefine.memory=1400M -Drefine.max_form_content_size=1048576 -Drefine.port=3333 -Drefine.host=127.0.0.1 -Drefine.webapp=main\webapp -Djava.library.path=server\target\lib\native\windows com.google.refine.Refine
09:03:56.466 [            refine_server] Starting Server bound to '127.0.0.1:3333' (0ms)
09:03:56.466 [            refine_server] refine.memory size: 1400M JVM Max heap: 1407188992 (0ms)
09:03:56.473 [            refine_server] Initializing context: '/' from 'C:\Users\THAD\OpenRefine\main\webapp' (7ms)
09:03:56.836 [            refine_server] Failed to use jdatapath to detect user data path: resorting to environment variables (363ms)
09:03:56.837 [            refine_server] Creating new workspace directory C:\Users\THAD\AppData\Roaming\OpenRefine (1ms)
09:03:56.838 [            refine_server] Failed to use jdatapath to detect user data path: resorting to environment variables (1ms)
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/C:/Users/THAD/OpenRefine/server/target/lib/slf4j-log4j12-1.7.18.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/C:/Users/THAD/OpenRefine/main/webapp/WEB-INF/lib/slf4j-log4j12-1.7.18.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
09:03:56.955 [                   refine] Starting OpenRefine 3.2-beta [6616d01]... (117ms)
09:03:56.955 [                   refine] initializing FileProjectManager with dir (0ms)
09:03:56.956 [                   refine] C:\Users\THAD\AppData\Roaming\OpenRefine (1ms)
09:03:56.960 [       FileProjectManager] Failed to load workspace from any attempted alternatives. (4ms)
```

**Desktop (please complete the following information):**
 - OS: Windows 10
 - Browser Version: Firefox
 - JRE or JDK Version: jdk1.8.0_191

**OpenRefine (please complete the following information):**
 - Version:  OpenRefine 3.2-Beta from master

","Can you double-check the clone is really clean with `refine.bat clean` and compile again?

Can you try checking out the 3.2-beta tag (`git checkout 3.2-beta`), `refine.bat clean` and `refine.bat build` and `refine.bat`?

Is the 3.2-beta compiled version (available at https://github.com/OpenRefine/OpenRefine/releases/download/3.2-beta/openrefine-win-3.2-beta.zip) working for you?","​A brand new fresh clone into a different directory fixed it.  Stupid git indexing , when will they ever fix that !
I even did a `git reset --hard @{u}` and it still didn't update all the necessary files that it should have.  This might be a Windows Git bug lurking I'm sure.  That `git reset` command has always worked for me in the past, and even helped @ostephens get unstuck once before as well when I told him to do that same thing.  For some reason, its not working out so well in my case.  Oh well, the fresh new clone did the trick however!

Thanks @wetneb !​ 
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2086,"**Describe the bug**

```
17:33:49.314 [                   refine] POST /command/core/preview-expression (1280ms)
17:33:53.149 [                   refine] POST /command/core/log-expression (3835ms)
17:33:53.149 [                  command] Exception caught (0ms)
java.lang.NullPointerException
	at com.google.refine.commands.expr.LogExpressionCommand.doPost(LogExpressionCommand.java:56)
	at com.google.refine.RefineServlet.service(RefineServlet.java:189)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)
	at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
	at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:938)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:755)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:835)
```

This happens when creating a new column or new facet from an expression.

**OpenRefine (please complete the following information):**
 - master branch

",would like to be clear here.. is this a pre 3.1 beta issue ?  what versions of OpenRefine does this possibly affect...just so we get that noted here.,"As mentioned above this is happening on the master branch at the moment, so post 3.1 beta."
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/2068,"**Describe the bug**
Operation type can be added more than once to JSON serialization, as in the following example:
```
{""op"":""core/recon"",
""engineConfig"":{""facets"":[],""mode"":""row-based""},""columnName"":""institution"",""config"":{""mode"":""standard-service"",""service"":""https://reconcile.ror.org/reconcile"",""identifierSpace"":""http://ror.org/organization"",""schemaSpace"":""http://ror.org/ns/type.object.id"",""type"":{""id"":""/ror/organization"",""name"":""/ror/organization""},""autoMatch"":true,""columnDetails"":[],""limit"":0},
""description"":""Reconcile cells in column institution to type /ror/organization"",
""op"":""core/recon""
}
```
This is deserialized correctly by the current Jackson code but not by the previous org.json code. This makes it impossible to open projects made with OpenRefine 3.2-beta with 3.1.",Didn't we have an issue about this issue before?  Reference # please? or am I remembering things wrong about an issue with not opening projects with 3.1 versus this issue with not opening projects with 3.2?,"Not sure, we might have had similar issue on other classes. It's clearly worth fixing before 3.2 in any case."
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1936,"**Describe the bug**
Some changes of a project have disappeared when I closed and reopened the project. Before closing it I exported the project and in the history folder there are all the changes. But even re-importing the project I can't see them on screen. 

See: https://groups.google.com/forum/#!topic/openrefine/Pw1Bk6eV9hY

**To Reproduce**
It seems that the bug could be reproduced using a reconciliator as the Library of Congress Conciliator or the Geonames conciliator. But it's a strange behaviour that I never encountered before.

**Desktop (please complete the following information):**
 - OS:  Ubuntu 18.04
 - Browser Version: Firefox 64
 - JRE or JDK Version: 1.8.0_151

**OpenRefine (please complete the following information):**
 - Version: OpenRefine 3.1

","Could it be related to this bug?

```
18:06:34.541 [           ProjectManager] Saving some modified projects ... (300022ms)
java.lang.NullPointerException
        at com.google.refine.operations.recon.ReconOperation.getBriefDescription(ReconOperation.java:107)
        at com.google.refine.operations.recon.ReconOperation.write(ReconOperation.java:116)
        at com.google.refine.history.HistoryEntry.write(HistoryEntry.java:115)
        at com.google.refine.io.FileHistoryEntryManager.save(FileHistoryEntryManager.java:69)
        at com.google.refine.history.HistoryEntry.save(HistoryEntry.java:121)
        at com.google.refine.history.History.save(History.java:297)
        at com.google.refine.model.Project.saveToWriter(Project.java:156)
        at com.google.refine.model.Project.saveToOutputStream(Project.java:138)
        at com.google.refine.io.ProjectUtilities.saveToFile(ProjectUtilities.java:103)
        at com.google.refine.io.ProjectUtilities.save(ProjectUtilities.java:66)
        at com.google.refine.io.FileProjectManager.saveProject(FileProjectManager.java:254)
        at com.google.refine.ProjectManager.saveProjects(ProjectManager.java:316)
        at com.google.refine.ProjectManager.save(ProjectManager.java:231)
        at com.google.refine.RefineServlet$AutoSaveTimerTask.run(RefineServlet.java:92)
        at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
        at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
```",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1895,"**Describe the bug**
If you add a column using ""Add column from reconciled values"", the new column contains values that are reconciled (at the cell level) but the whole column does not appear as reconciled and so cannot be used as a reconciled column in a Wikidata schema until it has been reconciled again.

**To Reproduce**
Reconcile a column with Wikidata
1. Use ""Add column from reconciled values"" to add a new column
2. Note new column contains reconciled values but there is no bar at the top showing the column itself is reconciled
3. Try using column in a wikidata schema where the schema expects a reconciled value

**Current Results**
The column does not appear to be reconciled even though each value in the column is reconciled

**Expected behavior**
The column should be reconciled and be usable in wikidata schema
",Would you have an example project to reproduce this maybe?,
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1866,"**Describe the bug**
Under some circumstances closing a Facet does not refresh the list of rows displayed in the data table

**To Reproduce**
Steps to reproduce the behavior:
1. Create a text facet and select a value to get a subset of rows
2. Remove the rows from the project (""All->Edit Rows->Remove all matching rows"")
3. See no rows now appear (expected)
4. Close the facet by clicking the 'cross' at the top left of the facet panel
5. Note that still no rows appear even though you've removed the facet and there are still rows in the project

**Current Results**
The data  table was not refreshed to show the remaining rows in the project after the facet was removed

**Expected behavior**
The data table should refresh to show all the rows remaining the project

**Screenshots**
![screen shot 2018-11-27 at 09 31 03](https://user-images.githubusercontent.com/576174/49072080-56e08080-f227-11e8-994a-aac9c5267a70.png)

remove the filtered rows - note you can see in the facet there is still one row remaining

![screen shot 2018-11-27 at 09 31 14](https://user-images.githubusercontent.com/576174/49072092-5fd15200-f227-11e8-9bba-f03ff365bf8d.png)

Close the facet with the cross at the top left - still no rows display

![screen shot 2018-11-27 at 09 31 21](https://user-images.githubusercontent.com/576174/49072108-6cee4100-f227-11e8-83b4-9ee8e4217acf.png)

**OpenRefine (please complete the following information):**
 - 3.1 Beta

**Datasets**
If you are allowed and are OK with making your data public, it would be awesome if you can include or attach the data causing the issue or a URL pointing to where the data is.
If you are concerned about keeping your data private, ping us on our [mailing list](https://groups.google.com/forum/#!forum/openrefine)

**Additional context**
Add any other context about the problem here.
",Could that be browser-dependent? ,No JS Console errors. Happens on both Safari and Chrome. Not tested on Ff yet - can do later.
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1821,"**Describe the bug**
I have doubt on the get-rows & get-models api because initially the get-rows and get-models return the same number of count but after splitting the column into multiple column the get-rows and get-models return the different number of count. I mean to say i have dataset where initially number of column is 34 and get-rows return 34 records for each rows that fine but after splitting the column the get-models returning 36 column count which is correct but get-rows is returning 35 records for each rows, so because of that there is mismatch happening the dataset.

**To Reproduce**
Steps to reproduce the behavior:
1. Load the file 
2. check the get-models api and note the number of column count
3. check the get-rows api and note the number of records count for each rows
4. click on drop down menu select edit column
5. click on splitting column into several column option
6. split any column
7. After splitting now check the get-model api and note the number of column count
8. check the get-rows api and note the number of records count for each rows

**Expected behavior**
I was expecting as the initially get-models api returning the same number of column count and as well as get-rows api returning the same record count for each row which is correct and even after splitting the column also the api should return same number of row & column count, so that there should not be any mismatch in dataset. I dont 'know how open refine team is managing that as i can see there is difference in count.

**Screenshots**
I am sharing a [video link](https://drive.google.com/file/d/1qo1o65Y1ocxMvli5dW7CkOm7gBrOLbsw/view?usp=sharing) for better understand what i want to say.

Please help out on the above scenario. If i am doing any mistake then correct me.

Thanks

","Could you maybe minimize your dataset to make the bug reproducible on a small example, or share your entire project with us?

In the meantime I am marking this as not reproducible but feel free to come back with more details.",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1740,"hello every one!
i can use version 2.8 in my computer but cannot use the new version. it is my computer or the new version's problem. i want to use the new version~~
",What exactly do you get when trying to launch the new version?,"  web site http://127.0.0.1:3333/ cannot be opened after run the new version openrefine.exe.
stop at ""receiving method for GET""
win 10
java version 8"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1717,"**Describe the bug**
A clear and concise description of what the bug is.
When OpenRefine is running, my browser at http://127.0.0.1:3333/. However, nothing is on the web page except an icon

**Screenshots**
If applicable, add screenshots to help explain your problem.
![image](https://user-images.githubusercontent.com/42724736/44634755-e8f89480-a96b-11e8-8a7d-b677d3220e81.png)
![image](https://user-images.githubusercontent.com/42724736/44634756-eeee7580-a96b-11e8-9c1e-15411736265a.png)

**Desktop (please complete the following information):**
 - OS: Windows
 - Browser: Chrome

**OpenRefine (please complete the following information):**
 - Version: OpenRefine 3.0
",Can you open the javascript console in your browser and check if there are any errors there?,"Thx for your reply. Here is the console. Can you please help me to fix these error?
![image](https://user-images.githubusercontent.com/42724736/44856857-7e31ac80-ac3c-11e8-927e-c56e7b9cba12.png)
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1690,"**Describe the bug**
When extracting the JSON from a project, I should be able to select only part of the operation using the select option. This option does not work at least since OpenRefine 2.8

No error shown in the terminal  (in the log I create a project and apply two operations)

```
21:56:27.155 [                   refine] POST /command/core/importing-controller (21361ms)
21:56:28.170 [                   refine] POST /command/core/get-importing-job-status (1015ms)
21:56:28.176 [                   refine] POST /command/core/cancel-importing-job (6ms)
21:56:29.270 [                   refine] POST /command/core/load-language (1094ms)
21:56:29.304 [                   refine] GET /command/core/get-preference (34ms)
21:56:29.316 [                   refine] POST /command/core/load-language (12ms)
21:56:29.330 [                   refine] POST /command/core/load-language (14ms)
21:56:29.343 [                   refine] POST /command/core/load-language (13ms)
21:56:29.534 [                   refine] GET /command/core/get-project-metadata (191ms)
21:56:29.563 [                   refine] GET /command/core/get-models (29ms)
21:56:29.780 [                   refine] GET /command/core/get-history (217ms)
21:56:29.781 [                   refine] POST /command/core/get-rows (1ms)
21:56:30.029 [                   refine] GET /command/core/get-history (248ms)
21:56:33.728 [                   refine] POST /command/core/apply-operations (3699ms)
21:56:33.830 [                   refine] GET /command/core/get-history (102ms)
21:56:33.860 [                   refine] GET /command/core/get-project-metadata (30ms)
21:56:33.876 [                   refine] GET /command/core/get-models (16ms)
21:56:33.891 [                   refine] POST /command/core/get-rows (15ms)
21:56:34.032 [                   refine] POST /command/core/compute-facets (141ms)
21:56:35.311 [                   refine] GET /command/core/get-operations (1279ms)
21:58:19.139 [           ProjectManager] Saving some modified projects ... (103828ms)
21:58:19.147 [        project_utilities] Saved project '1898382528686' (8ms)

```

**To Reproduce**
Steps to reproduce the behavior:
1. Create a project
2. Perform a couple of transforms operation
3. Go to `Undo/Redo` and then select `Extract`
4. Click to select, unselect some steps
5. The Json on the right panel should update based on the steps (un)selected. It does not

**Screenshots**
![awesomescreenshot-2018-08-01t01-57-11-983z](https://user-images.githubusercontent.com/2589584/43496764-0e66dc36-950d-11e8-88a6-32d7382eaa28.gif)

**Desktop:**
 - OS: ubuntu 16.04
 - Browser Chromium


**OpenRefine :**
 - Version OpenRefine2.8 and 3.0RC1

","Can you check the Browser console ?

Works fine for me on OpenRefine Win 3.0 Beta and RC1 and Master(trunk) in Firefox and Chrome latest.  Must be something with your project, special special :)",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1689,"**Describe the bug**

A column that contains numbers and null values can be sorted as a number column, but not if it contains empty strings.

**Current Results**

```
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number
        at com.google.refine.sorting.NumberCriterion$1.compareKeys(NumberCriterion.java:74)
        at com.google.refine.sorting.BaseSorter$ComparatorWrapper.compare(BaseSorter.java:101)
        at com.google.refine.sorting.BaseSorter.compare(BaseSorter.java:169)
        at com.google.refine.sorting.SortingRowVisitor$1.compare(SortingRowVisitor.java:85)
        at com.google.refine.sorting.SortingRowVisitor$1.compare(SortingRowVisitor.java:75)
        at java.util.TimSort.countRunAndMakeAscending(Unknown Source)
        at java.util.TimSort.sort(Unknown Source)
        at java.util.Arrays.sort(Unknown Source)
        at java.util.ArrayList.sort(Unknown Source)
        at java.util.Collections.sort(Unknown Source)
        at com.google.refine.sorting.SortingRowVisitor.end(SortingRowVisitor.java:75)
        at com.google.refine.browsing.util.ConjunctiveFilteredRows.accept(ConjunctiveFilteredRows.java:71)
        at com.google.refine.commands.row.GetRowsCommand.internalRespond(GetRowsCommand.java:146)
        at com.google.refine.commands.row.GetRowsCommand.doPost(GetRowsCommand.java:70)
        at com.google.refine.RefineServlet.service(RefineServlet.java:178)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:938)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:755)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
```

**Expected behavior**

Empty strings should behave like null.

**Desktop (please complete the following information):**
 - OS: Windows 10
 - Browser : Chrome

**OpenRefine (please complete the following information):**
OpenRefine 3.0 RC1

**Datasets**

[clipboard.openrefine.tar.gz](https://github.com/OpenRefine/OpenRefine/files/2240232/clipboard.openrefine.tar.gz)



","How do you wish to highlight to the user that ""Hey dude, actually, your column that you asked me to sort is not only numbers...you need to fix that first"" ?

My vote would be to have a popup warning and suggest to the user to FIRST run Facet by Null and Facet by Blank to inspect those rows in the column.

Recall that we also agreed that later we will add an import option (perhaps preference) to ""treat blank cells as null cells"" instead of ramming it down a users throat as we did prior to 3.0 all the way back to 1.0.  But before we add that option, we are waiting for Antonin's work and a nicer UI.  For now, we are kinda just getting by as much as we can...knowing that larger, cleaner, smarter ways of working in OpenRefine are coming.","@thadguidry @wetneb I will not meddle with the question of whether it is a bug or not. Let's say I understand both points of view. 

My 2cts to feed the reflexion: Martin's latest survey showed that the majority of users came from the worlds of library and journalism, not computer science. I've been both in my career, and I'm not sure I'll be able to explain, if anyone wonders in the Google group, why he/she manages to sort some columns and not others simply because some cells that he/she thinks are empty are not empty, but contains an empty string (and why any null cell on which you click on ""edit"" automatically becomes an empty string)."
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1665,"When reporting a bug please provide the following information to help reproduce the bug:

#### Version of OpenRefine used (Google Refine 2.6, OpenRefine2.8, an other distribution?):
Open Refine 3.0 beta

#### Operating Systems and version:
Windows 10 

#### Browser + version used - Please note that OpenRefine doesn't support Internet Explorer but works OK in most cases:

Chrome

#### Steps followed to create the issue:

1. Clone git repo
2. run refine.bat build
3. run refine.bat
4. Import a file or two
5. Wait around, and you'll recieve js alerts with the message ""Error contacting recon service: timeout : timeout - https://tools.wmflabs.org/openrefine-wikidata/en/api""


#### If you are allowed and are OK with making your data public, it would be awesome if you can include the data causing the issue or a URL pointing to where the data is (if your concerned about keeping your data private, ping us on our mailing list):

N/A

#### Current Results:
Javascript alert

#### Expected Results:
No javascript alert
","How is that useful to you ?  Give us more details on how you imagine what OpenRefine would show you, or do, if the Wikidata API times out.  Tell us how you want this designed, with step by step.  Tell us how ""fail more gracefully"" would look like to you in OpenRefine ?",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1657,"When reporting a bug please provide the following information to help reproduce the bug:

#### Version of OpenRefine used (Google Refine 2.6, OpenRefine2.8, an other distribution?):
Version 3 beta

#### Operating Systems and version:
Windows 10

#### Browser + version used - Please note that OpenRefine doesn't support Internet Explorer but works OK in most cases:
All

#### Steps followed to create the issue:
Click on ""All"", then ""Transform"", then ""OK""

#### If you are allowed and are OK with making your data public, it would be awesome if you can include the data causing the issue or a URL pointing to where the data is (if your concerned about keeping your data private, ping us on our mailing list):
Any dataset

#### Current Results:
![screenshot-127 0 0 1-3333-2018 06 19-12-04-13](https://user-images.githubusercontent.com/6286410/41591108-2252eb56-73b9-11e8-8b03-6e77a6828338.png)


#### Expected Results:
A column selection window labeld ""Select the columns to transform"", something like that.
",What the actual f***?!,
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1603,"When reporting a bug please provide the following information to help reproduce the bug:

#### Version of OpenRefine used (Google Refine 2.6, OpenRefine2.8, an other distribution?):
Version 2.8 [TRUNK]

#### Operating Systems and version:
Windows7

#### Browser + version used - Please note that OpenRefine doesn't support Internet Explorer but works OK in most cases:
Chrome

#### Steps followed to create the issue:
Import XLS data into two different projects attempting to 'make new column based on current' with cross reference to another project
`cell.cross(""lango_20180515 xlsx"",""Lango SN"").length()`

Note: data is automatically recognized as a number (shows as green) and appears with the 'x.xxxxExx' notation within a text facet.

#### If you are allowed and are OK with making your data public, it would be awesome if you can include the data causing the issue or a URL pointing to where the data is (if your concerned about keeping your data private, ping us on our mailing list):


#### Current Results:
GREF reports an error:
` Error: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.String`

#### Expected Results:
I expect numbers to be compared and cross reference, in the specifc GREL command I would expect an count of how many times the number is located in the other project.

![cell_cross_error](https://user-images.githubusercontent.com/236907/40078655-777b8f4e-5842-11e8-984e-a98ec515baa5.png)

","why you need cross function instead of just use the column in the same project?

Also, could you please paste the exception from the back end?","I am attempting to validate/cleanup data provided by a 3rd party. The data is from 2 sheets of a XLS which I have imported as separate projects, they have already (poorly) cross referenced it.

Not sure where I might find the 'backend' info, didn't see any log files under:
`C:\Users\swood\AppData\Roaming\OpenRefine`"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1549,"When reporting a bug please provide the following information to help reproduce the bug:

#### Version of OpenRefine used (Google Refine 2.6, OpenRefine2.8, an other distribution?):
OpenRefine 2.8

#### Operating Systems and version:
Windows 7 64bit

#### Browser + version used - Please note that OpenRefine doesn't support Internet Explorer but works OK in most cases:
Firefox 59.0.1 (64bit)

#### Steps followed to create the issue:
Open a large project in OpenRefine that has thousands of rows and about 10 columns.

#### If you are allowed and are OK with making your data public, it would be awesome if you can include the data causing the issue or a URL pointing to where the data is (if your concerned about keeping your data private, ping us on our mailing list):

#### Current Results:
Forever Spinner on UI

```
10:04:09.293 [            refine_server] Starting Server bound to '127.0.0.1:333
3' (0ms)
10:04:09.371 [            refine_server] Initializing context: '/' from 'C:\User
s\eguitha\Downloads\openrefine-2.8\webapp' (78ms)
10:04:13.458 [            refine_server] Failed to use jdatapath to detect user
data path: resorting to environment variables (4087ms)
10:04:13.458 [            refine_server] Failed to use jdatapath to detect user
data path: resorting to environment variables (0ms)
10:04:13.489 [                   refine] Starting OpenRefine 2.8 [TRUNK]... (31m
s)
10:04:20.860 [                   refine] POST /command/core/load-language (7371m
s)
10:04:20.906 [                   refine] GET /command/core/get-preference (46ms)

10:04:20.918 [                   refine] POST /command/core/load-language (12ms)

10:04:21.057 [                   refine] POST /command/core/get-importing-config
uration (139ms)
10:04:21.166 [                   refine] GET /command/core/get-all-project-metad
ata (109ms)
10:04:21.358 [                   refine] GET /command/core/get-languages (192ms)

10:04:21.400 [                   refine] GET /command/core/get-version (42ms)
10:04:34.966 [          org.mortbay.log] /favicon.ico (13566ms)
java.lang.IllegalStateException: Committed
        at org.mortbay.jetty.Response.resetBuffer(Response.java:1024)
        at javax.servlet.ServletResponseWrapper.resetBuffer(ServletResponseWrapp
er.java:202)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.resetBuffer(GzipFi
lter.java:310)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.sendError(GzipFilt
er.java:319)
        at edu.mit.simile.butterfly.Butterfly.error(Butterfly.java:1020)
        at edu.mit.simile.butterfly.Butterfly.service(Butterfly.java:528)
        at com.google.refine.RefineServlet.service(RefineServlet.java:200)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511
)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)

        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:3
88)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:1
82)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:7
65)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)

        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:1
52)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:54
2)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpCo
nnection.java:923)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.
java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
10:04:36.422 [                   refine] POST /command/core/load-language (1456m
s)
10:04:36.456 [                   refine] GET /command/core/get-preference (34ms)

10:04:36.473 [                   refine] POST /command/core/load-language (17ms)

10:04:36.551 [                   refine] GET /command/core/get-project-metadata
(78ms)
10:08:37.262 [          org.mortbay.log] Error for /command/core/get-project-met
adata (240711ms)
java.lang.OutOfMemoryError: GC overhead limit exceeded
        at com.fasterxml.jackson.core.JsonFactory._createParser(JsonFactory.java
:1351)
        at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:
906)
        at com.fasterxml.jackson.core.JsonFactory.createJsonParser(JsonFactory.j
ava:1108)
        at com.google.refine.model.Row.loadStreaming(Row.java:223)
        at com.google.refine.model.Row.load(Row.java:218)
        at com.google.refine.model.Project.loadFromReader(Project.java:224)
        at com.google.refine.model.Project.loadFromInputStream(Project.java:187)

        at com.google.refine.io.ProjectUtilities.loadFromFile(ProjectUtilities.j
ava:157)
        at com.google.refine.io.ProjectUtilities.load(ProjectUtilities.java:118)

        at com.google.refine.io.FileProjectManager.loadProject(FileProjectManage
r.java:231)
        at com.google.refine.ProjectManager.getProject(ProjectManager.java:482)
        at com.google.refine.commands.Command.getProject(Command.java:181)
        at com.google.refine.commands.project.GetProjectMetadataCommand.doGet(Ge
tProjectMetadataCommand.java:56)
        at com.google.refine.RefineServlet.service(RefineServlet.java:170)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511
)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)

        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:3
88)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:1
82)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:7
65)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)

        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:1
52)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:54
2)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpCo
nnection.java:923)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
10:12:49.460 [          org.mortbay.log] /favicon.ico (252198ms)
java.lang.IllegalStateException: Committed
        at org.mortbay.jetty.Response.resetBuffer(Response.java:1024)
        at javax.servlet.ServletResponseWrapper.resetBuffer(ServletResponseWrapp
er.java:202)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.resetBuffer(GzipFi
lter.java:310)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.sendError(GzipFilt
er.java:319)
        at edu.mit.simile.butterfly.Butterfly.error(Butterfly.java:1020)
        at edu.mit.simile.butterfly.Butterfly.service(Butterfly.java:528)
        at com.google.refine.RefineServlet.service(RefineServlet.java:200)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511
)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)

        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:3
88)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:1
82)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:7
65)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)

        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:1
52)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:54
2)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpCo
nnection.java:923)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.
java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
```

#### Expected Results:
An Error Message popup or banner on the UI saying ""Project could not be loaded (possible out of memory)"" at this stage 
```
10:08:37.262 [          org.mortbay.log] Error for /command/core/get-project-met
adata (240711ms)
java.lang.OutOfMemoryError: GC overhead limit exceeded
        at com.fasterxml.jackson.core.JsonFactory._createParser(JsonFactory.java
:1351)
        at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:
906)
        at com.fasterxml.jackson.core.JsonFactory.createJsonParser(JsonFactory.j
ava:1108)
        at com.google.refine.model.Row.loadStreaming(Row.java:223)
```
",Do you mind upload your project dump(Not just data)?,@jackyq2015 on my work laptop...will get for you on Monday.
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1543,"When reporting a bug please provide the following information to help reproduce the bug:

Version of OpenRefine used (Google Refine 2.6, OpenRefine2.8, an other distribution?):
-----
Trunk

Operating Systems and version:
-----
Windows 10

Browser + version used - Please note that OpenRefine doesn't support Internet Explorer but works OK in most cases:
-----
Firefox latest

Steps followed to create the issue:
-----
Checkout master
start OpenRefine
Open Firefox
Ensure you don't open Project, just stay on home page of OpenRefine
Click Refresh button on Firefox
Click Refresh button on Firefox again

If you are allowed and are OK with making your data public, it would be awesome if you can include the data causing the issue or a URL pointing to where the data is (if your concerned about keeping your data private, ping us on our mailing list):
-----

Current Results:
-----
```
08:50:15.749 [                   refine] GET /command/database/saved-connection (8ms)
08:50:15.769 [                   refine] GET /command/core/get-all-project-tags (20ms)
08:50:15.779 [                   refine] GET /command/core/get-all-project-metadata (10ms)
08:50:15.883 [                   refine] GET /command/core/get-languages (104ms)
08:50:15.902 [                   refine] GET /command/core/get-version (19ms)
08:50:50.915 [          org.mortbay.log] /favicon.ico (35013ms)
java.lang.IllegalStateException: Committed
        at org.mortbay.jetty.Response.resetBuffer(Response.java:1024)
        at javax.servlet.ServletResponseWrapper.resetBuffer(ServletResponseWrapper.java:202)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.resetBuffer(GzipFilter.java:310)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.sendError(GzipFilter.java:319)
        at edu.mit.simile.butterfly.Butterfly.error(Butterfly.java:1020)
        at edu.mit.simile.butterfly.Butterfly.service(Butterfly.java:528)
        at com.google.refine.RefineServlet.service(RefineServlet.java:201)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:923)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
08:50:51.009 [       database-extension] receiving request for styles/jquery.contextMenu.css (94ms)
08:50:51.015 [       database-extension] receiving request for styles/bootstrap.css (6ms)
08:50:51.015 [       database-extension] receiving method for GET (0ms)
08:50:51.015 [       database-extension] receiving method for GET (0ms)
08:50:51.023 [       database-extension] receiving request for styles/database-import.less (8ms)
08:50:51.024 [       database-extension] receiving request for styles/pure.css (1ms)
08:50:51.025 [       database-extension] receiving method for GET (1ms)
08:50:51.026 [       database-extension] receiving method for GET (1ms)
08:50:51.216 [                   refine] POST /command/core/load-language (190ms)
08:50:51.224 [                   refine] GET /command/core/get-preference (8ms)
08:50:51.232 [                   refine] POST /command/core/load-language (8ms)
08:50:51.236 [                   refine] POST /command/core/load-language (4ms)
08:50:51.283 [                   refine] POST /command/core/get-importing-configuration (47ms)
08:50:51.328 [       database-extension] receiving request for scripts/index/database-import-form.html (45ms)
08:50:51.328 [       database-extension] receiving method for GET (0ms)
08:50:51.335 [                   refine] GET /command/database/saved-connection (7ms)
08:50:51.350 [                   refine] GET /command/core/get-all-project-tags (15ms)
08:50:51.358 [                   refine] GET /command/core/get-all-project-metadata (8ms)
08:50:51.435 [                   refine] GET /command/core/get-languages (77ms)
08:50:51.446 [                   refine] GET /command/core/get-version (11ms)
08:50:55.228 [          org.mortbay.log] /favicon.ico (3782ms)
java.lang.IllegalStateException: Committed
        at org.mortbay.jetty.Response.resetBuffer(Response.java:1024)
        at javax.servlet.ServletResponseWrapper.resetBuffer(ServletResponseWrapper.java:202)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.resetBuffer(GzipFilter.java:310)
        at org.mortbay.servlet.GzipFilter$GZIPResponseWrapper.sendError(GzipFilter.java:319)
        at edu.mit.simile.butterfly.Butterfly.error(Butterfly.java:1020)
        at edu.mit.simile.butterfly.Butterfly.service(Butterfly.java:528)
        at com.google.refine.RefineServlet.service(RefineServlet.java:201)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:923)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
08:50:55.340 [       database-extension] receiving request for styles/jquery.contextMenu.css (112ms)
08:50:55.342 [       database-extension] receiving request for styles/bootstrap.css (2ms)
08:50:55.343 [       database-extension] receiving request for styles/pure.css (1ms)
08:50:55.343 [       database-extension] receiving request for styles/database-import.less (0ms)
08:50:55.345 [       database-extension] receiving method for GET (2ms)
08:50:55.346 [       database-extension] receiving method for GET (1ms)
08:50:55.348 [       database-extension] receiving method for GET (2ms)
08:50:55.349 [       database-extension] receiving method for GET (1ms)
08:50:55.518 [                   refine] POST /command/core/load-language (169ms)
08:50:55.526 [                   refine] GET /command/core/get-preference (8ms)
08:50:55.533 [                   refine] POST /command/core/load-language (7ms)
08:50:55.549 [                   refine] POST /command/core/load-language (16ms)
08:50:55.602 [                   refine] POST /command/core/get-importing-configuration (53ms)
08:50:55.655 [       database-extension] receiving request for scripts/index/database-import-form.html (53ms)
08:50:55.655 [       database-extension] receiving method for GET (0ms)
08:50:55.662 [                   refine] GET /command/database/saved-connection (7ms)
08:50:55.678 [                   refine] GET /command/core/get-all-project-tags (16ms)
08:50:55.687 [                   refine] GET /command/core/get-all-project-metadata (9ms)
08:50:55.768 [                   refine] GET /command/core/get-languages (81ms)
08:50:55.779 [                   refine] GET /command/core/get-version (11ms)
```
Expected Results:
-----
Happyness :)",what's your version of FF exactly?,"59
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1437,"Open Refine opens on the ""Create project"" view, but switches automatically after one second to the ""Open Project"" window. It's pretty annoying and causes many unintentional project openings.

![screencast](https://user-images.githubusercontent.com/6286410/35211119-6466a25e-ff55-11e7-8d31-48fd271d5830.gif)
",Does it happen in Firefox ?  Can you try to disable ALL Chrome extensions and try again ?,@thadguidry Nice catch. It seems that it is related to the Adblock+ extension  for Chrome. Thanks !
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1391,"```
java.lang.ArrayIndexOutOfBoundsException: 0
        at com.google.refine.importers.tree.XmlImportUtilities.findRecord(XmlImportUtilities.java:298)
        at com.google.refine.importers.tree.XmlImportUtilities.importTreeData(XmlImportUtilities.java:263)
        at com.google.refine.importers.tree.TreeImportingParserBase.parseOneFile(TreeImportingParserBase.java:222)
        at com.google.refine.importers.XmlImporter.parseOneFile(XmlImporter.java:202)
        at com.google.refine.importers.tree.TreeImportingParserBase.parseOneFile(TreeImportingParserBase.java:120)
        at com.google.refine.importers.tree.TreeImportingParserBase.parse(TreeImportingParserBase.java:86)
        at com.google.refine.importing.ImportingUtilities.previewParse(ImportingUtilities.java:956)
        at com.google.refine.importing.DefaultImportingController.doUpdateFormatAndOptions(DefaultImportingController.java:185)
        at com.google.refine.importing.DefaultImportingController.doPost(DefaultImportingController.java:93)
        at com.google.refine.commands.importing.ImportingControllerCommand.doPost(ImportingControllerCommand.java:62)
        at com.google.refine.RefineServlet.service(RefineServlet.java:177)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:938)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:755)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
16:11:30.539 [          org.mortbay.log] /command/core/importing-controller (1ms)

```",can you provide a sample xml file and the procedure you import the file?,This is the xml file [xml](https://drive.google.com/file/d/1ovhgPyPn6EpKpBfMwIihFWXdydbQza-R/view?usp=sharing ) it dosen't import completed 
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1386,"This is on the current Master branch with new Tags functionality implemented. None of my projects created on a pre-tags version of OR display in the Open Project screen. However, projects created with the Tags version of OR do display even if no tags assigned.

The 'All' option should display all projects, no matter whether any Tags metadata exists or not.
","could you please paste the console message while startup? I have no problem to show ""All"" projects. But I cannot add tags anymore. can somebody confirm?","No exceptions or issues flagged in the console. However, checking I can see that get-all-project-metadata is coming back with an empty list:

`{""projects"":{}}`"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1261,"Hello, 
I'm new with OpenRefine and I encountered a problem. 
I upload my JSON files and it work well but my JSON is somehow ""cut"" per comparison of the original file. I have more than 200 entry in the original file, and it generate only 16 rows in the csv sheet I want to work with. Do you ever had this problem? Is it a problem of syntax in the original file? 
Thank you very much. 
",can you provide a sample of the JSON file?,"Sure, here : 
```
{
  ""data"": [
    {
      ""created_time"": ""2017-05-31T15:53:45+0000"",
      ""from"": {
        ""name"": ""JJ Nina"",
        ""id"": ""10203499588585347""
      },
      ""message"": ""Orélie Orélie ... mdrrr j en peux plus 😂😂"",
      ""id"": ""1551460621555337_1551461834888549""
    },
    {
      ""created_time"": ""2017-05-31T15:55:03+0000"",
      ""from"": {
        ""name"": ""Emilie Duthoy"",
        ""id"": ""10203735457525161""
      },
      ""message"": ""\"" tu veux voir mon clitoris de 15cm ?\"""",
      ""id"": ""1551460621555337_1551462631555136""
    },
    {
      ""created_time"": ""2017-05-31T15:56:50+0000"",
      ""from"": {
        ""name"": ""Mi Stick"",
        ""id"": ""133169370361082""
      },
      ""message"": ""Trol Lex ça te rappelle qqn ? 😂😂"",
      ""id"": ""1551460621555337_1551464234888309""
    },
    {
      ""created_time"": ""2017-05-31T15:53:46+0000"",
      ""from"": {
        ""name"": ""Seb Seb"",
        ""id"": ""123755004648034""
      },
      ""message"": ""Mdr"",
      ""id"": ""1551460621555337_1551461858221880""
    }
  ]
}
```"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1252,"Hi,

I've placed a URL sitemap of my website and getting this error message. How can I fix it? Any idea?

![screenshot_1](https://user-images.githubusercontent.com/32128288/30639294-92ca5bf8-9dfe-11e7-8bb8-f07d0745cb4e.jpg)

Thanks in advance.",Could you share that URL with us?,"@wetneb yes, the URL is http://dumazahrada.eu/sitemap_index.xml"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1130,"Import .json file with some of the values being in Chinese. 
The records beneath the first record with Chinese values were not imported. 
","Do you have an example file that you can provide which demonstrates the problem? That would make it easier to debug.
","Since the issue report system does not support uploading .json, I change the file extension to .txt for upload.
I can only import 9 records (13 rows) of this file. It stopped import at the one with Chinese characters in parameter values using Google Refine v2.5

[20160423_210000_shop.txt](https://github.com/OpenRefine/OpenRefine/files/229279/20160423_210000_shop.txt)
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1123,"Hi,
Any help is appreciated.

I am having this error: ""Error: Form too large""

I tried many methods related to this error as mentioned in previous posts. At last, I followed the instructions/modifications posted earlier and which are connected to posts #908 & #971  (refine.max_form_content_size).

I am running windows with 48GB of rams and 2 Hexacore processors, and unfortunately even after applying the modifications, I am not able to get it to work.

I am not sure I am applying everything correctly. These are the steps:
1- Add ""REFINE_MAX_FORM_CONTENT_SIZE=5242880"" to refine.ini
2- Add the following below to refine.bat under :gotMemory
  ""+if not ""%REFINE_MAX_FORM_CONTENT_SIZE%"" == """" goto gotMaxFormContentSize
 +set REFINE_MAX_FORM_CONTENT_SIZE=1048576
 +:gotMaxFormContentSize
 +set OPTS=%OPTS% -   Drefine.max_form_content_size=%REFINE_MAX_FORM_CONTENT_SIZE%
 +""
3- Run openrefine.exe (diamond icon).

I understand that running openrefine.exe can override the new commands, but I have no idea how to run refine.bat and if I double-click it, a command window shows for milliseconds and then disappear.

Could you please advise on what is wrong with what I am doing?
Thanks a lot,
Ali
","Can you provide more context on what you are doing and what the environment is?

What version of OpenRefine? What version of Windows? What browser and version? Is this something you're trying to do interactively? If so, what menus, choices, etc are you selecting? If not, can you post the JSON for the script that you're pasting into OpenRefine's history window.

p.s. Anything you add to `refine.bat` has no effect if you don't actually run `refine.bat`
","Hi Tom,
Thanks a lot for your reply.

I am using OpenRefine 2.6 Beta1, Windows 7 x64, Chrome v48.

The error occurs when I try to cluster & edit a column (method: key collusion). Once I try to merge the data, this message pops up ""Error: Form too large 4467189>1048576"".

Apparently, it has to do with the 1MB limit which I am trying to change. I was happy to know that this parameter can be changed but I am not successful in doing that. 

Since refine.ini & refine.bat have to be altered, I need to run refine.bat, otherwise it has no effects as you stated.

I tried running refine.bat by double-clicking and it didn't work (command window shows for milliseconds and then disappears). If I try to run it from the command window, I get: The system cannot find the file refine.ini...etc. There is a link with instructions on how to set JAVA_HOME to point at JDK installation, but the site is down!

Could you please advise if the following is sufficient for overriding the 1MB form limit?

> Alter refine.ini & refine.bat as explained in my initial post, and then run refine.bat and not the executable openrefine.exe file.

If I am correct on that point, then all what I need to do is to learn how to run refine.bat.

Thanks again @tfmorris, Appreciate it.
Ali
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1120,"""Open Project"" doesn't shows the created project when running on Firefox. Firefox version: 43.0.4; OS: Elementaryos 0.3.2 (Ubuntu 14.04 LTS); Openrefine: 2.6-rc2. I'm temporarily using Chromium until this get fixed. 

**Firefox Screenshot**
![openrefine_firefox](https://cloud.githubusercontent.com/assets/1889828/12511983/2fa68922-c0f4-11e5-8fd3-e62463c37c4c.png)

**Chromium Screenshot**
![openrefine_chrome](https://cloud.githubusercontent.com/assets/1889828/12512045/9a2de678-c0f4-11e5-8f7e-23e1758265ab.png)
","Did you try with previous version of OpenRefine 2.6 like the rc1 or beta release? 
I've been using OpenRefine on ubuntu with Firefox without issue personally. 
","@magdmartin no, I haven’t tried it with previous version. Its my first time using Open Refine. On Firefox console I get this (which doesn't appear on Chromium):

![firefox1](https://cloud.githubusercontent.com/assets/1889828/12596892/12e1c7d2-c461-11e5-959a-2c489cca4333.png)

![firefox2](https://cloud.githubusercontent.com/assets/1889828/12596895/1a118ab0-c461-11e5-8bdb-ff236363d8cf.png)
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1078,"Not sure if Firefox is supported, but the UI is lacking text (isn't present in the DOM) in lots of areas. Here's a screenshot from the import page:

![screen shot 2015-10-01 at 16 18 11](https://cloud.githubusercontent.com/assets/582589/10224906/211c98be-6858-11e5-849a-5647070f50dc.png)
","Which version of OpenRefine are you using the 2.6beta or RC1?
This seems related to #871 
","I have Version 2.6-rc1 installed on my personal laptop, and it's fine, so it might be my work laptop. I'll check tomorrow.
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/1066,"i have problem with UTF-8 encoded files, Right after upload my file (text of URDU Language) converted to following text:

16    Ø§Ø·Ø§Ù„ÙˆÛŒ
7      Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ
19    Ø§ÙˆØ³ØªØ§Ø¦ÛŒ
","Can you tell us with Operating System and 
version of Refine are you using? That will help us to trouble shoot it.

Thank you
Martin

On 15-09-15 12:18 PM, Junaid Atari wrote:

> i have problem with UTF-8 encoded files, Right after upload my file 
> (text of URDU Language) converted to following text:
> 
> 16 Ø§Ø·Ø§Ù„ÙˆÛŒ
> 7 Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ
> 19 Ø§ÙˆØ³ØªØ§Ø¦ÛŒ
> 
> —
> Reply to this email directly or view it on GitHub 
> https://github.com/OpenRefine/OpenRefine/issues/1066.
",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/987,"I have a 6M rows file, and i do a text filter, and end up with only 8000 rows. 

If i try to cluster them, i still have to wait around 10-15 seconds, because it`s loading or processing the whole database.

I tried to export and load only the 8000 rows, and then, it only takes 500ms to compute the clusters.
","Does this only happen with the text filter or all types of facets?
",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/962,"The prompt for file selection on the Create Project tab says ""Locate an existing Refine project file,"" which is wrong.  It sounds like it got mixed up with a prompt for Import Project.

![openrefine-issue-962](https://cloud.githubusercontent.com/assets/82178/6760543/fe2f1024-cf1f-11e4-9eef-dc87abac7cc6.PNG)
","What version are you running? Mine(ver2.5 r2407) shows ""Locate one or more files on your computer to upload:""
","This appears to be fixed in the current development version (and rc1). 
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/956,"When open a project in firefox(windows 7), the left panel keep loading even the right panel is fully loaded. Under Chrome works fine!

Traced back to following commit by @DavidLeoni :
SHA-1: bf60360b26c76f39d41107654dfb4549813b79a6
- fixes language context in browser calls

Not sure it was caused by freebase or language context.
","What version of OpenRefine is this?  Are there any error messages logged on the Javascript console?
","Sorry forgot to mention that it works if it is deployed under windows 7 and access from 127.0.01. 

But if deploy under Linux and access from another windows 7  firefox, problem happens. There is no error log displayed on FF console.  It happens from the current master back to the the commit made by @DavidLeoni (maybe even more back but I have not tested more). But for the way of deployment, the following is good:

# good: [c68c1bb2b11a2c4894c0a7bbb7ec9b048a7367f4] Upgrade to Clojure 1.5.1 & switch to clojure-slim JAR - #792

I tried some bisect. But the result was confusing. I don't think it's correct. so I won't post here.
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/928,"I am using Refine 2.5[r2407].
log output:
com.google.gdata.util.ResourceNotFoundException: Not Found
<HTML>
<HEAD>
<TITLE>Not Found</TITLE>
</HEAD>
<BODY BGCOLOR=""#FFFFFF"" TEXT=""#000000"">

<H1>Not Found</H1>

<H2>Error 404</H2>

</BODY>
</HTML>

```
    at com.google.gdata.client.http.HttpGDataRequest.handleErrorResponse(HttpGDataRequest.java:587)
    at com.google.gdata.client.http.GoogleGDataRequest.handleErrorResponse(GoogleGDataRequest.java:563)
    at com.google.gdata.client.http.HttpGDataRequest.checkResponse(HttpGDataRequest.java:550)
    at com.google.gdata.client.http.HttpGDataRequest.execute(HttpGDataRequest.java:530)
    at com.google.gdata.client.http.GoogleGDataRequest.execute(GoogleGDataRequest.java:535)
    at com.google.refine.extension.gdata.GDataExtension.runFusionTablesSelect(GDataExtension.java:130)
    at com.google.refine.extension.gdata.GDataImportingController.listFusionTables(GDataImportingController.java:173)
    at com.google.refine.extension.gdata.GDataImportingController.doListDocuments(GDataImportingController.java:128)
    at com.google.refine.extension.gdata.GDataImportingController.doPost(GDataImportingController.java:98)
    at com.google.refine.commands.importing.ImportingControllerCommand.doPost(ImportingControllerCommand.java:62)
    at com.google.refine.RefineServlet.service(RefineServlet.java:177)
    at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)
    at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
    at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)
    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)
    at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)
    at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
    at org.mortbay.jetty.Server.handle(Server.java:326)
    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
    at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:923)
    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
    at java.lang.Thread.run(Unknown Source)
```

","Could you perhaps include a word or two about what you were trying to do (ie sequence of steps) and what the expected result was?
",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/910,"Hi,

I installed OpenRefine 2.6beta on a Windows7 machine. (I'm using Chrome)
When I try to create a project and upload data via URL nothing happens. The message on the screen says ""Uploading data"" and stops there.

This is what I get in the log window:
atus (1000ms)
09:35:06.305 [                   refine] POST /command/core/get-importing-job-st
atus (1001ms)
09:35:07.304 [                   refine] POST /command/core/get-importing-job-st
atus (999ms)
09:35:08.304 [                   refine] POST /command/core/get-importing-job-st
atus (1000ms)
09:35:09.304 [                   refine] POST /command/core/get-importing-job-st
atus (1000ms)
09:35:10.304 [                   refine] POST /command/core/get-importing-job-st
atus (1000ms)
09:35:11.305 [                   refine] POST /command/core/get-importing-job-st
atus (1001ms)
09:35:12.305 [                   refine] POST /command/core/get-importing-job-st
atus (1000ms)
09:35:13.132 [                   refine] POST /command/core/cancel-importing-job
 (827ms)
09:36:49.695 [..lient.DefaultHttpClient] I/O exception (java.net.SocketException
) caught when connecting to the target host: Malformed reply from SOCKS server (
96563ms)
09:36:49.695 [..lient.DefaultHttpClient] Retrying connect (0ms)
09:38:49.704 [..lient.DefaultHttpClient] I/O exception (java.net.SocketException
) caught when connecting to the target host: Malformed reply from SOCKS server (
120009ms)
09:38:49.704 [..lient.DefaultHttpClient] Retrying connect (0ms)
09:40:49.705 [..lient.DefaultHttpClient] I/O exception (java.net.SocketException
) caught when connecting to the target host: Malformed reply from SOCKS server (
120001ms)
09:40:49.705 [..lient.DefaultHttpClient] Retrying connect (0ms)

I previously installed version 2.5 and Upload data via URL worked fine. However, I had problems with reconciliation RDF using DBpedia, Europeana etc and I decided to install 2.6beta

Any help? Thanks
","What type of data resides at the URL that you are using?  Can you provide an example URL for us to test with?

The ""Malformed reply from SOCKS server"" seems suspicious to me.  Is there a proxy or firewall involved in the communication path?
","Hi,

Yes, I'm behind a proxy. I can access URL data if I start OpenRefine using ""refine /i IPaddress"" command. But still I cannot use RDF reconciliation services. When choosing any of them (dbpedia, freebase, ...) a pop-up window opens with the message 'Working' and stops there.

This is what I get:

```
    at org.mortbay.jetty.Server.handle(Server.java:326)
    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:54
```

2)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpCo
nnection.java:923)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.
java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
09:36:30.714 [                  command] Exception caught (50ms)
java.io.IOException: <html>
<head>
<meta http-equiv=""Content-Type"" content=""text/html; charset=ISO-8859-1""/>
<title>Error 500 com/ibm/icu/text/StringPrepParseException</title>
</head>
<body><h2>HTTP ERROR 500</h2>
<p>Problem accessing /extension/rdf-extension/services/dbpedia. Reason:

<pre>    com/ibm/icu/text/StringPrepParseException</pre></p><h3>Caused by:</h3><
pre>java.lang.NoClassDefFoundError: com/ibm/icu/text/StringPrepParseException
        at com.hp.hpl.jena.iri.impl.SchemeSpecification.&lt;init&gt;(SchemeSpeci
fication.java:68)
        at com.hp.hpl.jena.iri.ViolationCodes$Initialize.&lt;clinit&gt;(Violatio
nCodes.java:1360)
        at com.hp.hpl.jena.iri.IRIFactory.&lt;clinit&gt;(IRIFactory.java:111)
        at org.openjena.riot.system.PrefixMap.add(PrefixMap.java:54)
        at com.hp.hpl.jena.sparql.util.MappingRegistry.addPrefixMapping(MappingR
egistry.java:33)
        at com.hp.hpl.jena.query.ARQ.init(ARQ.java:438)
        at com.hp.hpl.jena.query.ARQ.&lt;clinit&gt;(ARQ.java:456)
        at com.hp.hpl.jena.sparql.engine.http.QueryEngineHTTP.&lt;init&gt;(Query
EngineHTTP.java:90)
        at com.hp.hpl.jena.sparql.engine.http.QueryEngineHTTP.&lt;init&gt;(Query
EngineHTTP.java:81)
        at org.deri.grefine.reconcile.rdf.executors.VirtuosoRemoteQueryExecutor.
sparql(VirtuosoRemoteQueryExecutor.java:20)
        at org.deri.grefine.reconcile.rdf.endpoints.QueryEndpointImpl.reconcileE
ntities(QueryEndpointImpl.java:38)
        at org.deri.grefine.reconcile.rdf.RdfReconciliationService.reconcile(Rdf
ReconciliationService.java:69)
        at org.deri.grefine.reconcile.model.AbstractReconciliationService.reconc
ile(AbstractReconciliationService.java:48)
        at org.deri.grefine.reconcile.ServiceRegistry.multiReconcile(ServiceRegi
stry.java:117)
        at org.deri.grefine.reconcile.GRefineServiceManager.multiReconcile(GRefi
neServiceManager.java:94)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.mozilla.javascript.MemberBox.invoke(MemberBox.java:161)
        at org.mozilla.javascript.NativeJavaMethod.call(NativeJavaMethod.java:24
7)
        at org.mozilla.javascript.optimizer.OptRuntime.call2(OptRuntime.java:76)
        at org.mozilla.javascript.gen.c6._c5(file:/C:/Users/U39306/AppData/Local
/OpenRefine/extensions/rdf-extension/MOD-INF/controller.js:204)
        at org.mozilla.javascript.gen.c6.call(file:/C:/Users/U39306/AppData/Loca
l/OpenRefine/extensions/rdf-extension/MOD-INF/controller.js)
        at org.mozilla.javascript.ContextFactory.doTopCall(ContextFactory.java:3
98)
        at org.mozilla.javascript.ScriptRuntime.doTopCall(ScriptRuntime.java:306
5)
        at org.mozilla.javascript.gen.c6.call(file:/C:/Users/U39306/AppData/Loca
l/OpenRefine/extensions/rdf-extension/MOD-INF/controller.js)
        at edu.mit.simile.butterfly.ButterflyModuleImpl$Controller.process(Butte
rflyModuleImpl.java:399)
        at edu.mit.simile.butterfly.ButterflyModuleImpl$Controller.run(Butterfly
ModuleImpl.java:377)
        at org.mozilla.javascript.Context.call(Context.java:515)
        at org.mozilla.javascript.ContextFactory.call(ContextFactory.java:507)
        at edu.mit.simile.butterfly.ButterflyModuleImpl.processScript(ButterflyM
oduleImpl.java:650)
        at edu.mit.simile.butterfly.ButterflyModuleImpl.process(ButterflyModuleI
mpl.java:427)
        at edu.mit.simile.butterfly.Butterfly.service(Butterfly.java:516)
        at com.google.refine.RefineServlet.service(RefineServlet.java:200)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511
)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
        at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:155)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:3
88)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:1
82)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:7
65)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:1
52)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:54
2)
        at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnectio
n.java:938)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:755)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.
java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.ClassNotFoundException: com.ibm.icu.text.StringPrepParseExc
eption
        at java.net.URLClassLoader$1.run(Unknown Source)
        at java.net.URLClassLoader$1.run(Unknown Source)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        at edu.mit.simile.butterfly.ButterflyClassLoader.loadClass(ButterflyClas
sLoader.java:65)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        ... 57 more
</pre>

<h3>Caused by:</h3><pre>java.lang.ClassNotFoundException: com.ibm.icu.text.Strin
gPrepParseException
        at java.net.URLClassLoader$1.run(Unknown Source)
        at java.net.URLClassLoader$1.run(Unknown Source)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        at edu.mit.simile.butterfly.ButterflyClassLoader.loadClass(ButterflyClas
sLoader.java:65)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        at com.hp.hpl.jena.iri.impl.SchemeSpecification.&lt;init&gt;(SchemeSpeci
fication.java:68)
        at com.hp.hpl.jena.iri.ViolationCodes$Initialize.&lt;clinit&gt;(Violatio
nCodes.java:1360)
        at com.hp.hpl.jena.iri.IRIFactory.&lt;clinit&gt;(IRIFactory.java:111)
        at org.openjena.riot.system.PrefixMap.add(PrefixMap.java:54)
        at com.hp.hpl.jena.sparql.util.MappingRegistry.addPrefixMapping(MappingR
egistry.java:33)
        at com.hp.hpl.jena.query.ARQ.init(ARQ.java:438)
        at com.hp.hpl.jena.query.ARQ.&lt;clinit&gt;(ARQ.java:456)
        at com.hp.hpl.jena.sparql.engine.http.QueryEngineHTTP.&lt;init&gt;(Query
EngineHTTP.java:90)
        at com.hp.hpl.jena.sparql.engine.http.QueryEngineHTTP.&lt;init&gt;(Query
EngineHTTP.java:81)
        at org.deri.grefine.reconcile.rdf.executors.VirtuosoRemoteQueryExecutor.
sparql(VirtuosoRemoteQueryExecutor.java:20)
        at org.deri.grefine.reconcile.rdf.endpoints.QueryEndpointImpl.reconcileE
ntities(QueryEndpointImpl.java:38)
        at org.deri.grefine.reconcile.rdf.RdfReconciliationService.reconcile(Rdf
ReconciliationService.java:69)
        at org.deri.grefine.reconcile.model.AbstractReconciliationService.reconc
ile(AbstractReconciliationService.java:48)
        at org.deri.grefine.reconcile.ServiceRegistry.multiReconcile(ServiceRegi
stry.java:117)
        at org.deri.grefine.reconcile.GRefineServiceManager.multiReconcile(GRefi
neServiceManager.java:94)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.mozilla.javascript.MemberBox.invoke(MemberBox.java:161)
        at org.mozilla.javascript.NativeJavaMethod.call(NativeJavaMethod.java:24
7)
        at org.mozilla.javascript.optimizer.OptRuntime.call2(OptRuntime.java:76)

```
    at org.mozilla.javascript.gen.c6._c5(file:/C:/Users/U39306/AppData/Local
```

/OpenRefine/extensions/rdf-extension/MOD-INF/controller.js:204)
        at org.mozilla.javascript.gen.c6.call(file:/C:/Users/U39306/AppData/Loca
l/OpenRefine/extensions/rdf-extension/MOD-INF/controller.js)
        at org.mozilla.javascript.ContextFactory.doTopCall(ContextFactory.java:3
98)
        at org.mozilla.javascript.ScriptRuntime.doTopCall(ScriptRuntime.java:306
5)
        at org.mozilla.javascript.gen.c6.call(file:/C:/Users/U39306/AppData/Loca
l/OpenRefine/extensions/rdf-extension/MOD-INF/controller.js)
        at edu.mit.simile.butterfly.ButterflyModuleImpl$Controller.process(Butte
rflyModuleImpl.java:399)
        at edu.mit.simile.butterfly.ButterflyModuleImpl$Controller.run(Butterfly
ModuleImpl.java:377)
        at org.mozilla.javascript.Context.call(Context.java:515)
        at org.mozilla.javascript.ContextFactory.call(ContextFactory.java:507)
        at edu.mit.simile.butterfly.ButterflyModuleImpl.processScript(ButterflyM
oduleImpl.java:650)
        at edu.mit.simile.butterfly.ButterflyModuleImpl.process(ButterflyModuleI
mpl.java:427)
        at edu.mit.simile.butterfly.Butterfly.service(Butterfly.java:516)
        at com.google.refine.RefineServlet.service(RefineServlet.java:200)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511
)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)

```
    at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:155)
    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
```

Handler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:3
88)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:1
82)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:7
65)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)

```
    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:1
```

52)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:54
2)
        at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnectio
n.java:938)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:755)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.
java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
</pre>
<hr /><i><small>Powered by Jetty://</small></i><br/>

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

</body>
</html>

```
    at com.google.refine.commands.recon.GuessTypesOfColumnCommand.guessTypes
```

(GuessTypesOfColumnCommand.java:189)
        at com.google.refine.commands.recon.GuessTypesOfColumnCommand.doPost(Gue
ssTypesOfColumnCommand.java:89)
        at com.google.refine.RefineServlet.service(RefineServlet.java:177)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511
)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1166)
        at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)

```
    at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
```

Handler.java:1157)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:3
88)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:1
82)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:7
65)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)

```
    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:1
```

52)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:54
2)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpCo
nnection.java:923)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.
java:228)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)

Thanks!!
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/834,"I can export to html but not to excel or odf spreadsheet.

HTTP ERROR 500

Problem accessing /command/core/export-rows/SAP-OUT.xls. Reason:

```
Invalid column index (256).  Allowable column range for BIFF8 is (0..255) or ('A'..'IV')
```

Caused by:

java.lang.IllegalArgumentException: Invalid column index (256).  Allowable column range for BIFF8 is (0..255) or ('A'..'IV')
    at org.apache.poi.hssf.usermodel.HSSFCell.checkBounds(HSSFCell.java:943)
    at org.apache.poi.hssf.usermodel.HSSFCell.<init>(HSSFCell.java:161)
    at org.apache.poi.hssf.usermodel.HSSFRow.createCell(HSSFRow.java:141)
    at org.apache.poi.hssf.usermodel.HSSFRow.createCell(HSSFRow.java:119)
    at org.apache.poi.hssf.usermodel.HSSFRow.createCell(HSSFRow.java:38)
    at com.google.refine.exporters.XlsExporter$1.addRow(XlsExporter.java:99)
    at com.google.refine.exporters.CustomizableTabularExporterUtilities$1.start(CustomizableTabularExporterUtilities.java:133)
    at com.google.refine.browsing.util.ConjunctiveFilteredRows.accept(ConjunctiveFilteredRows.java:59)
    at com.google.refine.exporters.CustomizableTabularExporterUtilities.exportRows(CustomizableTabularExporterUtilities.java:171)
    at com.google.refine.exporters.XlsExporter.export(XlsExporter.java:138)
    at com.google.refine.commands.project.ExportRowsCommand.doPost(ExportRowsCommand.java:107)
    at com.google.refine.RefineServlet.service(RefineServlet.java:177)
    at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)
    at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:81)
    at org.mortbay.servlet.GzipFilter.doFilter(GzipFilter.java:132)
    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)
    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)
    at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)
    at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)
    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
    at org.mortbay.jetty.Server.handle(Server.java:326)
    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
    at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:938)
    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:755)
    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218)
    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:724)
","How many columns does your project have?  It looks like these formats are limited to 256 columns and you're trying to output 257 or more.

We should handle the error better though and give the user explicit feedback about what the problem is.
",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/819,"Hi,

1) I'm learning how to use openrefine with a small dataset. I'm trying to split a column in two using a "" - "" sign but the new column just won't show up. I tried all the options (Split column, create new column based...). It is a single column dataset, imported from clipboard. What might be wrong?

2) I also cannot export. Export seems not to be working. Nothing happens when I click export and the option I want.

Thanks!
","What might be wrong?
> 
> 2) I also cannot export. Export seems not to be working. Nothing happens
> when I click export and the option I want.
> 
> Thanks!
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/OpenRefine/OpenRefine/issues/819
> .
","When I opened the project again, the columns were there. I'm using the last
version available for windows and it just automatically opens IE. When I
copy-paste the link into Chrome, everything works ok. I'm using windows 7,
IE 10 and Chrome is updated.

On Fri, Sep 27, 2013 at 6:49 PM, Tom Morris notifications@github.comwrote:

> The mailing list https://groups.google.com/forum/#!forum/openrefine is a
> better place to ask questions. In addition to the configuration information
> Martin asked for, we also need to know what version of OpenRefine you are
> using.
> 
> The most likely cause of the problem 1 is that the separator isn't what
> you think it is (e.g. an em dash instead of a hyphen). Try cutting and
> pasting the single separator character to make sure you've got it right.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/OpenRefine/OpenRefine/issues/819#issuecomment-25255343
> .

## 

_Dr. Shlomo Blum_
_Dept. of Bacteriology_
_Kimron Veterinary Inst._
_POB 12_
_Bet Dagan, 50250_
_Israel_
_Tel.: 972-3-9681680_
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/797,"After reconciling some data with Freebase, using Open Refine 2.6,  I am trying to ""Add column from Freebase"", and that option is not present.
I have tried both the OSX and Linux installs, and they both have the same problem. Thanks

![nmi7j](https://f.cloud.github.com/assets/3156487/1063524/3f3a6860-12c6-11e3-8635-00e7b3405db9.png)
","Do you have a Freebase pulldown menu in the Extensions: bar (underneath the Export & Help buttons in the upper right)?
","In my mac, no errors in the console.
No Freebase pulldown menu.
When I open Open Refine, I have to manually input 127.0.1:3333 to access
refine..

Thanks for your help, and if there is anything else I can do, please, let me
know.

Cheers

From:  Tom Morris notifications@github.com
Reply-To:  OpenRefine/OpenRefine
<reply+i-18832607-f49da4158a6ae40e85023c1655605a410ea464ed-3156487@reply.git
hub.com>
Date:  Sunday, September 1, 2013 3:49 PM
To:  OpenRefine/OpenRefine OpenRefine@noreply.github.com
Cc:  Luis M Sánchez lmsanch@gmail.com
Subject:  Re: [OpenRefine] Add column from freebase not available  (#797)

Are there any error messages output on the console/terminal? Do you have a
Freebase pulldown menu in the Extensions: bar (underneath the Export & Help
buttons in the upper right)?

‹
Reply to this email directly or view it on GitHub
https://github.com/OpenRefine/OpenRefine/issues/797#issuecomment-23631746
.
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/782,"Hi *,

I have an column of type integer and I want to transform a string, but the value 21358081 transform it in scientific notation, ie what makes 2.1358081E7.

Obviously I want to get the string: 21358081

The changes I did in two ways and the result is the same (scientific notation):
1. Edit Cells --> Common Transforms --> To text
2. Edit Columns --> Add column based  on this column, and, my expression (GREL) is value.toString()

Can you help me?

Thanks
","Can you provide an example project which has the values that you're trying to convert?  I suspect that perhaps they're floating point numbers (which will get formatted as you describe), not integers.
","Hi, thanks for you reply.

The column represents ID values ​​of a person and I want to export to xml, but when I Export --> Templating... makes me an ID number in scientific notation (two ways in last message).

The Google Refine version that I have is:
Version 2.5 [r2407]

Thanks again,
Jose
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/764,"CSVs which have embedded newlines in cells (ie multiline cells) confuse the separator guesser and it ends up not being confident enough in its guess.  This is due to treating each line independently, without taking into account quotes.
","What is the new behavior now? Does Refine include the line break in the cell? 
","It always included the line break.  The only difference is that the
separator is guessed correctly saving the user having to specify it
manually.

On Sat, Aug 3, 2013 at 12:22 PM, magdmartin notifications@github.comwrote:

> What is the new behavior now? Does Refine include the line break in the
> cell?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/OpenRefine/OpenRefine/issues/764#issuecomment-22057233
> .
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/725,"When working with a workflow where Row (B) is sorted and contains no blanks, then Row (A) is sorted and does contain blanks, the result is correct, with basically a record style layout; but when selecting Sort -> Reorder rows permanently, the sorting on screen is lost and it seems to sort out of order, sorting only by the first sort selector.

","Can you provide a simple example with a few rows/columns and a step-by-step to make sure that we can reproduce the behavior that you're seeing?
","Switching to row mode did not seem to address the issue. I will work on getting a repro setup.
"
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/713,"I have a spreadsheet that has a couple thousadn rows spread out over maybe 20 worksheets.  If I just try to import one or two it works fine but if I try to import all of them the import always hangs (twice I let it run for over an hour).

I can provide the spreadsheet.  Also I used some simple perl code (yeah I'm that old :^) to convert the mutli worksheet thing into a single worksheet and that imports into refine just fine.

","What format is the spreadsheet in? (e.g. Excel 97, OpenOffice, etc) What
version of Refine are you using?

If you can put the spreadsheet somewhere accessible (or email it to me on
gmail - same name), I'll take a look.

On Mon, Apr 29, 2013 at 9:22 PM, biofool notifications@github.com wrote:

> I have a spreadsheet that has a couple thousadn rows spread out over maybe
> 20 worksheets. If I just try to import one or two it works fine but if I
> try to import all of them the import always hangs (twice I let it run for
> over an hour).
> 
> I can provide the spreadsheet. Also I used some simple perl code (yeah I'm
> that old :^) to convert the mutli worksheet thing into a single worksheet
> and that imports into refine just fine.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/OpenRefine/OpenRefine/issues/713
> .
",
OpenRefine/OpenRefine,https://github.com/OpenRefine/OpenRefine/issues/670,"Good morning. My company recently switched to Windows 7, went to re-install Google Refine, and it's blowing up when I try importing data.

Get the following error message in a dialog box:

""Error uploading data.import-temp\1359403483710\raw-data\ccdr_contributions_export.txt (The system cannot find the path specified)""

Anyone have a hunch what's causing this problem? Have never encountered it before. Screenshot is attached.
![googlerefine_error](https://f.cloud.github.com/assets/3418326/107448/15dad7d2-6a2b-11e2-84ea-c0d5ab9ad3df.jpg)

Thanks.
","What was the type of the source file? ie was it plain text or in some type of zip or archive? Local or URL?

There were a few problems fixed with various things in this area. See #587, #544, #599 (found by searching for import-temp in bug database)

Does %TEMP% point somewhere reasonable?  Do you have write access to it?
","Good advice -- Turns out that I didn't have the necessary access. Problem fixed.
"
socketio/socket.io-client-java,https://github.com/socketio/socket.io-client-java/issues/172,"The js manager code:

``` javascript
if (~this.readyState.indexOf('open')) return this;  // this works for open and openning
```

Our code:

``` java
if(Manager.this.readyState != Manager.ReadyState.OPEN) { // Only works for open
```
","Will this problem be fixed in the nearest future?
","Thanks @nkzawa, that'll be great. Will close this once it is released. 

BTW, we are using this lib in production, so I am doing active trouble shooting and trying to clean the issue list. 30+ open issue is bit scary. And you are the one with full knowledge to do this, could you please go through them and close the ones not valid anymore?
"
mockito/mockito,https://github.com/mockito/mockito/issues/984,"Found out at https://github.com/mockito/mockito/pull/980#issuecomment-285124740
This was initially fixed in #493, but I think the adoption of the new mockito-release-tools repository introduced this regression. All pull requests now have a failing status as CodeCov is unable to provide any feedback.

Commits should instead of `[ci skip]` use `[ci skip-release]`. Therefore Travis will kick off, but the release mechanism is not triggered.","Do you advocate to use ""ci skip release"" in place of ""ci skip"" for mockito project in general?",Asked upstream: https://github.com/codecov/support/issues/355#issuecomment-292707657
mockito/mockito,https://github.com/mockito/mockito/issues/963,"Hi,

We migrated to Mockito 2.x not so long ago and we came across a test that used to works back in Mockito 2.1.0 and no longer works with the latest 2.x version (2.7.11).

Here is the SSCCE to replicate the issue:

```
package com.some.company;

import static org.junit.Assert.*;

import java.beans.BeanInfo;
import java.beans.IntrospectionException;
import java.beans.Introspector;
import java.beans.PropertyDescriptor;
import java.util.HashMap;
import java.util.Map;

import org.junit.Test;
import org.mockito.Mockito;

public class Mockito2Issue
{
	public class SomeClass
	{
		String property;

		public String getAProperty()
		{
			return property;
		}

		protected String getNotAProperty()
		{
			return ""abc"";
		}
	}

	@Test
	public void testMockBug() throws IntrospectionException
	{
		SomeClass someClassMock = Mockito.mock(SomeClass.class);

		BeanInfo info = Introspector.getBeanInfo(someClassMock.getClass());

		Map<String, PropertyDescriptor> mockPropertyDescriptors = new HashMap<>();
		for (PropertyDescriptor propertyDescriptor : info.getPropertyDescriptors())
		{
			mockPropertyDescriptors.put(propertyDescriptor.getName(), propertyDescriptor);
		}

		assertTrue(mockPropertyDescriptors.containsKey(""AProperty""));
		assertFalse(mockPropertyDescriptors.containsKey(""notAProperty""));
	}

	@Test
	public void testSpyBug() throws IntrospectionException
	{
		SomeClass someClassSpy = Mockito.spy(new SomeClass());

		BeanInfo info = Introspector.getBeanInfo(someClassSpy.getClass());

		Map<String, PropertyDescriptor> spyPropertyDescriptors = new HashMap<>();
		for (PropertyDescriptor propertyDescriptor : info.getPropertyDescriptors())
		{
			spyPropertyDescriptors.put(propertyDescriptor.getName(), propertyDescriptor);
		}

		assertTrue(spyPropertyDescriptors.containsKey(""AProperty""));
		assertFalse(spyPropertyDescriptors.containsKey(""notAProperty""));
	}
}
```

**Before (1.10.19):**
Used to works

**After (2.7.11)**
Both tests fail on `assertFalse(mockPropertyDescriptors.containsKey(""notAProperty""));`

It seems that although the `getNotAProperty` method is `protected`, the most recent version of Mockito 2.x consider this as valid property getter, but not the very first 2.x stable release (2.1.0).

Can you take a look at this?


Environment details:

Component | Version
--------- | ------
OS | Ubuntu 16.10
Java | Oracle Java(TM) SE Runtime Environment (build 1.8.0_101-b13)
Eclipse | Neon.2
JUnit | 4.8.2
Mockito | 2.1.0 (before), 2.7.11 (after)","What do you think @TimvdLippe, @bric3, @szczepiq?",Thanks for the quick response and fix!
mockito/mockito,https://github.com/mockito/mockito/issues/871,"Example build: https://travis-ci.org/mockito/mockito/jobs/188911380

Seems that this does not affect core developers, as my build has been succesful: https://travis-ci.org/mockito/mockito/builds/188321204 as well as those in #865 and #859",Can't we just disable the checks if the repo is not mockito/mockito ?,Pull requests always have `mockito/mockito` as repository?
mockito/mockito,https://github.com/mockito/mockito/issues/457,"``` java
import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.is;
import static org.mockito.AdditionalMatchers.leq;
import static org.mockito.Matchers.eq;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.when;

import org.junit.Test;

public class BlahTest
{
    @Test
    public void test()
    {
        final BoolResult mockBoolResult = mock(BoolResult.class);

        when(mockBoolResult.getResult(eq(5))).thenReturn(true);  // Succeeds as expected
        when(mockBoolResult.getResult(leq(5))).thenReturn(true); // Fails with an NPE - as of v2.0.64 - unexpected!

        assertThat(mockBoolResult.getResult(null), is(false));
    }

    interface BoolResult
    {
        boolean getResult(Integer value);
    }
}
```
","Did you found more Matcher that misbehave like that?
",
mockito/mockito,https://github.com/mockito/mockito/issues/383,"Hi,

The current Mockito JAR is not a valid OSGi-bundle because it uses an illegal version for exporting its packages. I get the following error when I run my PAX-EXAM tests with the latest Mockito version:

org.ops4j.pax.exam.TestContainerException: Problem starting test container.
Caused by: org.osgi.framework.BundleException: Could not create bundle object.
Caused by: java.lang.IllegalArgumentException: invalid version ""2.0.44-beta"": non-numeric ""44-beta""
Caused by: java.lang.NumberFormatException: For input string: ""44-beta""

The version should be **2.0.44.beta** (with a dot instead a dash). This is since 2.0.28-beta, the last valid bundle was 2.0.27-beta.
","Can you help us out? If you build locally a regular version, e.g. 2.1.0 or something (version can be changed in 'version.properties' file), you can test it out locally and let us know.

I think I will not change the -beta notation now but I take the feedback will update the automation after 2.x final release.

THANKS for reporting!
",
mockito/mockito,https://github.com/mockito/mockito/issues/299,"I get memory leaks in my project whenever I use Mockito. I have a hunch this is because Mockito uses the wrong classloader, but I'm not quite sure. Please see the sample project I made to reproduce this:

https://github.com/benmccann/play-mockito-bug
","Do you have a chance to debug this problem? We don't use sbt and I'm not sure when can we take a look at this problem.
","I'm willing to put in some effort, but I'm afraid that I might have some difficulty finding the problem and could really use some help

I'm using 1.10.19. I tested with 2.0.31-beta also and it appears there as well.
"
mockito/mockito,https://github.com/mockito/mockito/issues/220,"No test failures when using 2.0.8-beta, but when incrementing to 2.0.9-beta, the following error occurs:

```
org.mockito.exceptions.base.MockitoException: Unable to initialize @Spy annotated field 'monitorTaskScheduler'.
Unable to create mock instance of type 'MonitorTaskScheduler'
    at net.project.dash.monitor.MonitorTaskScheduler$MockitoMock$1184625981.getExecutorService(Unknown Source)
    at net.project.dash.monitor.MonitorTaskScheduler.<init>(MonitorTaskScheduler.java:39)
    at net.project.dash.monitor.MonitorTaskScheduler$MockitoMock$1184625981.<init>(Unknown Source)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
    at org.mockito.internal.creation.instance.ConstructorInstantiator.invokeConstructor(ConstructorInstantiator.java:42)
    at org.mockito.internal.creation.instance.ConstructorInstantiator.noArgConstructor(ConstructorInstantiator.java:66)
    at org.mockito.internal.creation.instance.ConstructorInstantiator.newInstance(ConstructorInstantiator.java:17)
    at org.mockito.internal.creation.bytebuddy.ByteBuddyMockMaker.createMock(ByteBuddyMockMaker.java:27)
    at org.mockito.internal.util.MockUtil.createMock(MockUtil.java:33)
    at org.mockito.internal.MockitoCore.mock(MockitoCore.java:59)
    at org.mockito.Mockito.mock(Mockito.java:1284)
    at org.mockito.internal.configuration.SpyAnnotationEngine.newSpyInstance(SpyAnnotationEngine.java:117)
    at org.mockito.internal.configuration.SpyAnnotationEngine.process(SpyAnnotationEngine.java:67)
    at org.mockito.internal.configuration.InjectingAnnotationEngine.processIndependentAnnotations(InjectingAnnotationEngine.java:73)
    at org.mockito.internal.configuration.InjectingAnnotationEngine.process(InjectingAnnotationEngine.java:55)
    at org.mockito.MockitoAnnotations.initMocks(MockitoAnnotations.java:108)
    at net.project.dash.monitor.MonitorTaskSchedulerTest.setUp(MonitorTaskSchedulerTest.java:38)
```

Relevant code (MonitorTaskSchedulerTest.java)

``` java
@Spy
MonitorTaskScheduler monitorTaskScheduler;

@Before
public void setUp()
{
    MockitoAnnotations.initMocks(this);
}
```

Relevant code (MonitorTaskScheduler.java)

``` java
public class MonitorTaskScheduler
{
    public MonitorTaskScheduler()
    {
        this.futureToTaskMap = new ConcurrentHashMap<>();
    }
}
```
","Can you try with 2.0.11-beta ?
","Same problem with 2.0.11-beta (in fact, I started with that version, and then decremented one by one till the problem was gone).
"
mockito/mockito,https://github.com/mockito/mockito/issues/133,"I have encountered issue with Mockito (I have tested this on 1.10.14) and usage of different classloaders - running tests in SBT 0,13.

I have got empty class _TestClass_ and following test:

``` Java
    @Test
    public void runTest() {
        Mockito.spy(new TestClass(){

        });
    }
```

This test fails with following: 

```
Caused by: org.mockito.cglib.core.CodeGenerationException: java.lang.reflect.InvocationTargetException-->null
[error]     at org.mockito.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:238)
[error]     at org.mockito.cglib.proxy.Enhancer.createHelper(Enhancer.java:378)
[error]     at org.mockito.cglib.proxy.Enhancer.createClass(Enhancer.java:318)
[error]     at org.mockito.internal.creation.cglib.ClassImposterizer.createProxyClass(ClassImposterizer.java:123)
[error]     at org.mockito.internal.creation.cglib.ClassImposterizer.imposterise(ClassImposterizer.java:57)
[error]     at org.mockito.internal.creation.cglib.ClassImposterizer.imposterise(ClassImposterizer.java:49)
[error]     at org.mockito.internal.creation.cglib.CglibMockMaker.createMock(CglibMockMaker.java:24)
[error]     at org.mockito.internal.util.MockUtil.createMock(MockUtil.java:33)
[error]     at org.mockito.internal.MockitoCore.mock(MockitoCore.java:59)
[error]     at org.mockito.Mockito.spy(Mockito.java:1367)
[error]     ... 56 more
[error] Caused by: java.lang.reflect.InvocationTargetException
[error]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error]     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
[error]     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error]     at java.lang.reflect.Method.invoke(Method.java:606)
[error]     at org.mockito.cglib.core.ReflectUtils.defineClass(ReflectUtils.java:385)
[error]     at org.mockito.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:220)
[error]     ... 65 more
[error] Caused by: java.lang.IllegalAccessError: class TestMock$1$$EnhancerByMockitoWithCGLIB$$7c797c20 cannot access its superclass TestMock$1
[error]     at java.lang.ClassLoader.defineClass1(Native Method)
[error]     at java.lang.ClassLoader.defineClass(ClassLoader.java:800)
```

Looks like there is class loader issue - in sbt, the default classloader is the one for the sbt launcher, but you are ""run"" in a sub classloader.

Following calls give different result: _Thread.currentThread().getContextClassLoader().getClass();_ and _TestClass.class.getClassLoader().getClass();_ 
The second one is the parent of the first one.

Of course there is no issue running this piece of code in IDE, but in my opinion this is Mockito's problem, something which could be improved. 

Is it possible to have this fixed in Mockito? I would say so because changing current classloader to the one used to load the class solves the issue. 
","Can you propose a fix to this problem?
","I was looking into and can propose two solution (if you like any of them please let me know I will write the code, unit tests and create pull request).

The fix could be implemented in **org.mockito.internal.creation.cglibClassImposterizer** class. 
- My first suggestion is to try again class creation in catch block using different class loader. 

When creation of requested class fails, code could try again using class loader of the requested type. So something like:

``` Java
        try {
            return enhancer.createClass(); 
        } catch (CodeGenerationException e) {
             if (currentClassLoaderIsDifferent()) {
               enhancer.setClassLoader(mockedType.getClassLoader());
               return enhancer.createClass();
             }
             //error handling continues 
       }
```

I believe this solution is safe, fixes this edge case.
- I was thinking about changing the current class loader to one used to load the class for the time of class creation. This could be more dangerous solution, but I believe it should fix those classloader issues (in the end if we are mocking class A, why not run the code in same classloader?). I believe they may be some permission issues, but I didn't encounter them with my tests, but we could be prepared for that. Something like: 

``` Java
Thread currentThread = Thread.currentThread();
ClassLoader previous = currentThread.getContextClassLoader();
Thread.currentThread().setClassLoader(mockedType.getClassLoader());
T imposterisedClass = imposterise(args);
Thread.currentThread().setClassLoader(previous);
return imposterisedClass;
```

I investigated other possibility (SearchingClassLoader), but unfortunately I don't see solution using it. The problem is creation of SearchingClassLoader already causes the access issues and defineClass is final in Java... If it wouldn't we could pass the call to parent and everything would be working. 
To be fair I think the proper solution should be implemented in cglib library - they should not use reflection to hack the defineClass in my opinion they should ask for class creation interface, where we could simply proxy our call to different class loaders (defineClass is protected)... But I guess noone expended those can of issues at the point of library creation :( 

What do you think about it? Is any of my solution viable? Or would you like me to try something else? 
"
mockito/mockito,https://github.com/mockito/mockito/issues/110,"To reproduce attempt unzipping the jar file.
","Could you confirm or provide more detailed description?
","Correct. It seems to be fixed. Thanks for looking into it!
"
mockito/mockito,https://github.com/mockito/mockito/issues/99,"I am just migrating from mockito 1.9.5 to 1.10.5

The following code runs fine with version 1.9.5. but breaks now:

``` java

  @Test
  public void test() {
    ToBeMocked mock = mock(ToBeMocked.class, RETURNS_DEEP_STUBS);
    assertThat(mock.getSomething()).isNotNull();
  }

  public static class ToBeMocked {

    NotSerializableReturnValue field1;

    public ToBeMocked(NotSerializableReturnValue field1) {
      this.field1 = field1;
    }

    public NotSerializableReturnValue getSomething() {
      return field1;
    }
  }

  public static class NotSerializableReturnValue {

    String field1 = """";

    public NotSerializableReturnValue(String field1) {
      this.field1 = field1;
    }

    public String getSomething2() {
      return field1;
    }
  }
```

org.mockito.exceptions.base.MockitoException: 
You are using the setting 'withSettings().serializable()' however the type you are trying to mock 'NotSerializableReturnValue'
do not implement Serializable AND do not have a no-arg constructor.
","Can you update your code and add Serializable / default constructor?
","@szczepiq Hi, for one occurence I was able to implement a default constructor. For another occurence, it did not feel sensible to add a default constructor. I changed this and mocked all used method calls manually. For me it's ok now. 
btw: Thank you very much for sharing and caring for mockito!
"
junit-team/junit4,https://github.com/junit-team/junit4/issues/1475,"For Debugging Purpose, one may write many test cases.. which may not have asserts but may be required for breakpoints based debugging. 

It would be nice to have annotation @DebugTest in parallel to @Test. This is a clear indication that, such test code is meant for minimum viable tests to trace any exceptions in the main code","What behavior would JUnit have for `@DebugTest` vs. `@Test`?

Is there a reason why you couldn't define your own `@DebugTest` annotation?",
junit-team/junit4,https://github.com/junit-team/junit4/issues/1370,"I used JUnit 4 to test method that works with Apache Storm and Elasticsearch. 
When tested method throws an exception Unrooted Tests appears at JUnit console of Eclipse.
When tested method works correctly, JUnit is correct.
","Could you give some steps to reproduce, including a sample failed test? Does it require Apache Storm and Elasticsearch to reproduce?
","@kcooney , Unrooted Tests still happen without Apache Storm and Elasticsearch.
It happens with sample code like following.

```
// Target class
package mypackage;

public class MyClass {
  public Object throwExcep() throws Exception {
    throw new Exception();
  }
}
```

and JUnit method ,

```
 @Test//(expected = Exception.class)
 public void test_5tth_notexistedcluster() throws Exception {
   MyClass myClass = new MyClass();
   myClass.throwExcep();
 }
```

I added my environment information.
Project type : Maven project
Eclipse : Mars.1 Release (4.5.1)
Platform : Windows 10
"
junit-team/junit4,https://github.com/junit-team/junit4/issues/1334,"Multiple issues here:
1. When the test fails _and_ closing the resource fails, the test failure is lost: only the exception coming from the after() method is propagated.
2. In case there are multiple (ExternalResource) rules in place, and (closing) one fails, then all of the subsequent resources will _not_ be closed (without even trying to!).

This was not the case when encapsulating the tear down logic in multiple `@After` methods: RunAfters runs all of the After methods regardless of the result of each, and throws a MultipleFailureException in case more than one thing (test method and/or after logic) goes wrong.

I'm working on a fix for 1 for now, which is an easy one.
","Can you please open a separate issue for point 2?
",
junit-team/junit4,https://github.com/junit-team/junit4/issues/1320,"With a quite straightforward testclass annotated 
@RunWith(Suite.class)
@SuiteClasses({
    XMSectionTest.Basic.class
})
public class XMSectionTest {
...

I obtain for Request.classes(testClass).getRunner().getDescription() the value null, 
whereas for Request.aClass(testClass).getRunner().getDescription() 
I obtain eu.simuline.arithmetics.left2right.XMSectionTest 
Hm,.... the first seems a bug to me, 
whereas the second one.. seems to me at least uncomfortable, 
because I think the description shall reflect the structure of the request and not its origin. 
","Why would the second be ""uncomfortable""?
",
junit-team/junit4,https://github.com/junit-team/junit4/issues/1236,"I can see the fact that after() isn't called when some fail happens in one of the test methods.

for example:

``` java
/**
 * Created by aieremenko on 1/27/16.
 */
public class TestExternalResourceRule {
    @ClassRule
    public static ExternalResource externalResource = new ExternalResource() {
        NodeJsServer server = new NodeJsServer();

        @Override
        protected void before() throws Throwable {
            server.start();
        }

        @Override
        protected void after() {
            server.stop();
        }
    };

    @Test
    public void getBarryPathShouldReturnBarrysMsg() throws IOException {
        //some fail stuff
    }
}
```

In case of error my server is still being run after test finished.
","What exception is your test throwing? What version of JUnit? Is this the only test method? Does your test use `@RunWith`? Does this happen when it is run in an IDE, Maven/gradle and/or something else?
",
junit-team/junit4,https://github.com/junit-team/junit4/issues/1213,"If you perform actions which cause permission checks with the security manager (and you're doing some action which is not exploitable by the caller), then you're supposed to use doPrivileged.

`BaseTestRunner` in JUnit has this:

```
    private static File getPreferencesFile() {
        String home = System.getProperty(""user.home"");  // <- not using doPrivileged
        return new File(home, ""junit.properties"");
    }
```

When running our test suite with the security manager enabled, we get a failure:

```
Caused by: java.security.AccessControlException: access denied (""java.util.PropertyPermission"" ""user.home"" ""read"")
    at java.security.AccessControlContext.checkPermission(AccessControlContext.java:457)
    at java.security.AccessController.checkPermission(AccessController.java:884)
    at java.lang.SecurityManager.checkPermission(SecurityManager.java:549)
    at java.lang.SecurityManager.checkPropertyAccess(SecurityManager.java:1294)
    at java.lang.System.getProperty(System.java:717)
    at junit.runner.BaseTestRunner.getPreferencesFile(BaseTestRunner.java:225)
    at junit.runner.BaseTestRunner.readPreferences(BaseTestRunner.java:232)
    at junit.runner.BaseTestRunner.getPreferences(BaseTestRunner.java:51)
    at junit.runner.BaseTestRunner.getPreference(BaseTestRunner.java:246)
    at junit.runner.BaseTestRunner.getPreference(BaseTestRunner.java:250)
    at junit.runner.BaseTestRunner.<clinit>(BaseTestRunner.java:324)
```

This occurs irrespective of the fact that our security policy allows reading any system property, because something further down the stack, i.e. something inside IDEA's JUnit launcher (perhaps some dynamically-generated bytecode?) is ""completely"" untrustworthy and thus even the ""grant to all code sources"" section of the policy does not apply to it.

At the moment, our workaround for this is to give AllPermission to the IDEA installation, but this is not really satisfactory because every developer tends to install it in a different location depending on their own conventions, what platform they're on, whether they have admin access on the box, etc.

If JUnit would add a doPrivileged block here (and to any other place where it seems appropriate) then we wouldn't have to do this and our rule which says JUnit is completely trusted would be sufficient.
","Why are you wanting all of your tests (and apparently IDEA) to run in a security manager?
","In the case of our own code and our own tests, we already use `doPrivileged` in any locations which I'm aware of. But even if we weren't, we give our own code permission to read any system property.

Actually, we give JUnit the permission to read any system property as well, but _because it isn't using `doPrivileged`_, callers further down the stack get checked as well, and apparently no matter what we put into the security policy, those ones can't be marked as trusted.

We use the security manager to stop code (both libraries and our own code (since this is a testing framework, it seems reasonable to get extra checking for free where possible!) doing various things we don't want them to do, but mostly to stop them writing data outside of where we tell them to or exiting the JVM (yeah, it has actually happened before...) The former could theoretically be done by writing a custom NIO2 filesystem which wraps the real filesystem, but it would be a lot of work to make it support absolutely everything the real one supports. The latter is impossible to do any other way, at least as far as I am aware.
"
junit-team/junit4,https://github.com/junit-team/junit4/issues/1178,"When assertArrayEquals (at least for Boolean[]) fails the assert, it throws a null pointer exception looking for a message.  This is, of course, when using the prototype that has no message.  You'll still get the line number for the failure, you'll still probably just debug focused test method, and be on your merry way, but just technically it's not quite the best/correct behavior.

Thanks!

Update: this is for 4.12
","Can you please provide a test case to illustrate your problem?
","```
@Test
public void testJunit() {
    assertArrayEquals(new Boolean[]{true}, new Boolean[]{false});
}
```

On Tue, Jul 7, 2015 at 12:27 PM, Marc Philipp notifications@github.com
wrote:

> Can you please provide a test case to illustrate your problem?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/junit-team/junit/issues/1178#issuecomment-119293354.
"
junit-team/junit4,https://github.com/junit-team/junit4/issues/1073,"The signature of that method is `expectCause(Matcher<? extends Throwable> expectedCause)`.  This accepts `Matcher<RuntimeException>`, but possibly passes it other types such as `IOException`, resulting in heap pollution.

On the other hand, it forbids `Matcher<Object>`, even though that would be completely type-safe.

The type should be `Matcher<? super Throwable>` instead.
","Can you give an example of code that compiles that uses `expectCause` with a standard Hamcrest matchers/APIs)which results in a problematic exception?

It's true that developers would get a compile time error with the current API when trying to pass a `Matcher<Object>`) (for instance, if the developer used `nullValue()` or passed an Object to `isSame()` or `equalTo()`) but it sounds rare and avoidable.

I can see someone passing a subclass of `Throwable` to `equalTo()` (which is quite reasonable) and your proposed change would make that a compile time error.
","Ah you're right that `ClassCastException`s shouldn't happen, I forgot that the matcher interface accepts `Object` instead of `T`.  It's still wrong IMO taking PECS into account (producer extends, consumer super), but not going to cause heap pollution after all.

And yeah, my suggestion would break `expectCause(equalTo(e))` so I guess that's not tenable.  Is there a use for the wildcard bound at all?  There's already `expect(Matcher<?>)`, so maybe `expectCause(Matcher<?>)` would make sense.

I only noticed this by trying `expectCause(instanceOf(IllegalStateException.class))`, which was easily fixed by using `any(...)` instead.  So maybe no change is really necessary.
"
junit-team/junit4,https://github.com/junit-team/junit4/issues/350,"I believe this is a regression. I was investigating an issue I was having where a test would fail on a build server but pass locally when I realised I was using 4.9 locally and 4.10 on the server. It was complaining the my @Rule field ""must implement MethodRule"" and I started to suspect a regression, especially since MethodRule is supposedly deprecated. This field was implementing TestRule which should've worked ( as far as I understant rules). As such I decided to test this using the example code from http://kentbeck.github.com/junit/javadoc/latest/org/junit/rules/RuleChain.html

Which I updated to be compilable (the example is missing some parentheses for example, could someone update that as well with this fragment?) which gave me the same error. So either there is a regression, or the example is wrong, or I am stupid and missing something: those are all equally possible.

```
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.RuleChain;
import org.junit.rules.TestRule;
import org.junit.runner.Description;
import org.junit.runners.model.Statement;
import static org.junit.Assert.assertTrue;


public class UseRuleChain {
    @Rule
    public TestRule chain= RuleChain
                           .outerRule(new LoggingRule(""outer rule""))
                           .around(new LoggingRule(""middle rule""))
                           .around(new LoggingRule(""inner rule""));

    @Test
    public void example() {
            assertTrue(true);
    }

    static class LoggingRule implements TestRule{
        String s;
        public LoggingRule( String s ){
            this.s = s;
        }

        @Override
        public Statement apply( Statement arg0, Description arg1 ){
            System.out.println( this.s );
            return arg0;
        }
    }
}
```
","Can you paste in the stack trace?  (Or, if sensitive, only the lines produced inside JUnit?)  Many thanks!
","So I couldn't get the full trace, so I tried to do it from the command line where it worked. Long story short: seems like the issue was caused by another .jar which had an older version of  JUnit bundled included and when adding 4.10 it went after that jar so basically classpath issue... embarassing. (**-_-**)

That said, I still think the code example in RuleChain should be replaced with my snippet since it is actually compilable and runnable.
"
junit-team/junit4,https://github.com/junit-team/junit4/issues/295,"http://junit.sourceforge.net/javadoc/org/junit/runner/Result.html

This doc says:

   A Result collects and summarizes information from running
   multiple tests. Since tests are expected to run correctly, successful
   tests are only noted in the count of tests that ran. 

Should this be, instead, this?

   A Result collects and summarizes information from running
   multiple tests. Since tests are expected to run correctly, only successful
   tests are noted in the count of tests that ran. 

That seems to be clearer.
","How about this?

A Result collects and summarizes information from running multiple tests.  All tests are counted--additional information is collected from tests that fail.
","That makes much, much more sense. I see how the original could be interpreted correctly. This last suggestion is much more clear.
"
junit-team/junit4,https://github.com/junit-team/junit4/issues/220,"AllMembersSupplier.getValueSources does not pass 'sig' to addMultiPointMethods and therefore does not filter by parameter signature type.. Thus if you have

@DataPoint public static int x = 5;
@DataPoints public static String[] generateStrings() { .. }
@Theory public void test(String s, int y) { .. }

You'll get a parameter mismatch, because generateStrings is forced to match against 'int y'.

Currently dataPointsMethod does not provide a signature analysis tool for proper efficient filtering, BUT you can just execute the method and check the returned data-type.

I'll provide a pull request shortly with my temporary hack
","Could you give that a go, rather than the hack?  Thanks.
","Ok, take a look again.
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/1719,"<!-- BUG REPORT FORM -->

##Summary
Hello MyBatis, here is a bug for inserting objects of List which overrides hashcode method and the key uses as hashcode identifier (like id) is null.

Person overrides hashcode by id , id is null, insert List<Person> in mybatis leads to NullPointerException because dinstinct compare with id which is null.

## MyBatis version
3.5.1

## Database vendor and version
5.7.1

## Test case or example project
___________________________
Person.java

```java
public class Person {
    private Integer id;
    private String name;
    private Integer age;
    private String email;

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || getClass() != o.getClass()) {
            return false;
        }

        Person baseModel = (Person) o;

        return id.equals(baseModel.id);
    }

    @Override
    public int hashCode() {
        return id.hashCode();
    }
}
```
__________________________________
insertService.java
```java
 public void insertPersons(){
        String userName = ""test"";
        int age = 18;
        String mobilePhone = ""18000000000@test.com"";
        Person person = new Person();
        person.setAge(age);
        person.setName(userName);
        person.setEmail(mobilePhone);
        List<Person> personList = new ArrayList<>();
        personList.add(person);
        try{
           mapper.insertBatch(personList);
        }catch (Exception e){
            e.printStackTrace();
        }finally {
            System.out.println(person);
        }
    }
```
____________________________________
mapper.xml

```xml
<insert id=""insertBatch"" useGeneratedKeys=""true""
    keyProperty=""id"" parameterType=""test.Person"">
  INSERT INTO user (`name`, age, email) VALUES
    <foreach collection=""list"" item=""person"" separator="","">
      (#{person.name}, #{person.age}, #{person.email})
    </foreach>
</insert>
```

## Steps to reproduce

While we request insertBatch, mybatis will throw a 'java.lang.NullPointerException' exception. because in src/main/java/org/apache/ibatis/executor/keygen/Jdbc3KeyGenerator.java line 174,  it uses paramMap.values().stream().distinct().count() == 1 to adjust whether the count of params is 1, but the method distinct() of stream in jdk8 uses hashcode of object to do distinct, when the object overrides hashcode method with the hashcode of id, and the insert operation doesn't have any content in field id, the exception then occrupt.

But in mybatis before version 3.4.6(I have ensured), this never happened, because Jdbc3KeyGenerator in mybatis 3.4.6 didn't use distinct() method  to adjust the count of param. 

Anyway, in most cases, we will use  this logic to insert batch datas ,hope you can fix this bug in the future.


## Expected result
true

## Actual result
java.lang.NullPointerException


You can contact me by 346736752@qq.com. Thank you!","Could you add a full stack trace?
An executable demo project (like [these](https://github.com/harawata/mybatis-issues)) is even better. ;)
And please use three ticks `` ` `` for code blocks. See the [guide](https://guides.github.com/features/mastering-markdown/#GitHub-flavored-markdown) for syntax highlighting, etc..
","Here is a demo project to reproduce it,  https://github.com/WeiYang1005/mybatis-issue ."
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/1590,"## MyBatis version
3.3.0+ 
(example and lines below are based on the 3.5.1)

## Database vendor and version
PostgreSQL 9.6 or H2 1.4

## Steps to reproduce
1. Have an association in a mapper based on a composite key 
2. Use any request using the resultMap

Mapper example: 
```
<mapper namespace=""my.package.VariableMapper"">
	<resultMap id=""BaseResultMap"" type=""VariableImpl"">
		<id column=""va_process_id"" property=""processId"" jdbcType=""INTEGER"" />
		<id column=""va_variable_id"" property=""variableId"" jdbcType=""VARCHAR"" />
		[...]
	</resultMap>
	
	<resultMap id=""CompleteResultMap"" type=""VariableImpl"" extends=""BaseResultMap"">
		<association property=""linkedVariable"" column=""{processId=lv_va_process_id,variableId=lv_va_variable_id}""
			javaType=""VariableImpl"" resultMap=""my.package.VariableMapper.BaseResultMap"" columnPrefix=""lv_""/>
		[...]
	</resultMap>
[...]
</mapper>
```

## Expected result
The request done, as in 3.2.8-

## Actual result
NPE on DefaultResultSetHandler L472 with typeHandler as null

```
Cause: java.lang.NullPointerException
	at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:149)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:76)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:87)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:58)
	at com.sun.proxy.$Proxy44.selectById(Unknown Source)
	[...]
Caused by: java.lang.NullPointerException
	at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getPropertyMappingValue(DefaultResultSetHandler.java:472)
	at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.applyPropertyMappings(DefaultResultSetHandler.java:441)
	at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getRowValue(DefaultResultSetHandler.java:905)
	at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValuesForNestedResultMap(DefaultResultSetHandler.java:870)
	at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValues(DefaultResultSetHandler.java:326)
	at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSet(DefaultResultSetHandler.java:301)
	at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSets(DefaultResultSetHandler.java:194)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:65)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79)
	at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63)
	at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324)
	at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109)
	at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147)
	... 36 more
```

The problem seems to comes from this commit : https://github.com/mybatis/mybatis-3/commit/9d2913543adf5ac3c09c7ebe42ac86d2fbd92dda
where those three lines were deleted : 
`    if (composites.size() > 0) {
      column = null;
    }`
In case of composite column, the value of this property is then keept instead of removed and the treatment is done as it was a simple column and not a composite one so the typeHandler is null as there is no real data behind this propertyMapping.


Best regards,

Nicolas","Could you provide a [test case](https://github.com/mybatis/mybatis-3/wiki/Unit-Test) or [demo project](https://github.com/harawata/mybatis-issues) using a minimum set of tables and columns?
We need to add a test case to avoid future regression.","No problem. 

Here is a test case to reproduce the issue : https://github.com/nboissel/mybatis-issues/commit/5de4a0d9bf089d9b4e597a730180f9cc4350435c

It works fine with 3.2.8 but throw a NPE using any 3.5.1 version.

Best regards,

Nicolas"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/1177,"MyBatis version
3.4.5

For example：
```java
TypeHandlerRegistry tr = ...
tr.register(Address.class, TypeHandlers.jsonPOJO(Address.class));
tr.hasTypeHandler(Address.class);  // which return true
```
but
```java
TypeHandlerRegistry tr = ...
tr.hasTypeHandler(Address.class);
tr.register(Address.class, TypeHandlers.jsonPOJO(Address.class));
tr.hasTypeHandler(Address.class); // which return false
```

Where the question is coming.
In `org.apache.ibatis.type.TypeHandlerRegistry`, `NULL_TYPE_HANDLER_MAP` is used for representing no handler at all.
```java
  private Map<JdbcType, TypeHandler<?>> getJdbcHandlerMap(Type type) {
    TYPE_HANDLER_MAP.put(type, jdbcHandlerMap == null ? 
                     NULL_TYPE_HANDLER_MAP : jdbcHandlerMap); 
    return jdbcHandlerMap;
  }
```
And with the following code:
```java
  private void register(Type javaType, JdbcType jdbcType, TypeHandler<?> handler) {
    if (javaType != null) {
      Map<JdbcType, TypeHandler<?>> map = TYPE_HANDLER_MAP.get(javaType);

      // here
      if (map == null) { 
        map = new HashMap<JdbcType, TypeHandler<?>>();
        TYPE_HANDLER_MAP.put(javaType, map);
      }
      map.put(jdbcType, handler);
    }
    ALL_TYPE_HANDLERS_MAP.put(handler.getClass(), handler);
  }
```
The code `if (map == null)` uses `null` represent an empty map instead of using `NULL_TYPE_HANDLER_MAP` along with, which will make all handlers cannot be registered.",When we can expect release? 3.4.6 seems to be completed?,
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/929,"OgnlRuntime writes this error to system.err:

`Two methods with same method signature but not providing classes assignable? ""public abstract boolean java.util.List.isEmpty()"" and ""public boolean java.util.AbstractCollection.isEmpty()"" please report!`

This condition in my mapper causes the problem:
`<if test=""conditions != null &amp;&amp; !conditions.isEmpty()"">`

`conditions` variable is an `java.util.Collections.singletonList()`. When I change this variable to `ArrayList`, error disapears.","What do you think ?
",
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/906,"Groovy object properties follow the javabean spec for boolean, which allows for both a get* and an is* method to appear on the same object. Mybatis complains this doesn't follow the javabean spec which isn't entirely true.  I know you can use Boolean to get around the get/is issue or define your own getter which stops groovy from building the pair, but the strange part is that this field is not even used by mybatis, its just a helper boolean internal to the object, but mybatis still validates the entire object whether the field is used or not in a resultmap.

could this rule be relaxed to allow the official javabean spec to not throw an error?

from oracle:

8.3.2 Boolean properties
In addition, for boolean properties, we allow a getter method to match the pattern:
public boolean is<PropertyName>();
This “is<PropertyName>” method may be provided instead of a “get<PropertyName>” method,
or it may be provided in **addition** to a “get<PropertyName>” method.
In either case, if the “is<PropertyName>” method is present for a boolean property then we will
use the “is<PropertyName>” method to read the property value.

heres the code in question that throws the error on a valid javabean.

```
private void resolveGetterConflicts(Map<String, List<Method>> conflictingGetters) {
    for (String propName : conflictingGetters.keySet()) {
      List<Method> getters = conflictingGetters.get(propName);
      Iterator<Method> iterator = getters.iterator();
      Method firstMethod = iterator.next();
      if (getters.size() == 1) {
        addGetMethod(propName, firstMethod);
      } else {
        Method getter = firstMethod;
        Class<?> getterType = firstMethod.getReturnType();
        while (iterator.hasNext()) {
          Method method = iterator.next();
          Class<?> methodType = method.getReturnType();
          if (methodType.equals(getterType)) {
            throw new ReflectionException(""Illegal overloaded getter method with ambiguous type for property ""
                + propName + "" in class "" + firstMethod.getDeclaringClass()
                + "".  This breaks the JavaBeans "" + ""specification and can cause unpredictable results."");
          } else if (methodType.isAssignableFrom(getterType)) {
            // OK getter type is descendant
          } else if (getterType.isAssignableFrom(methodType)) {
            getter = method;
            getterType = methodType;
          } else {
            throw new ReflectionException(""Illegal overloaded getter method with ambiguous type for property ""
                + propName + "" in class "" + firstMethod.getDeclaringClass()
                + "".  This breaks the JavaBeans "" + ""specification and can cause unpredictable results."");
          }
        }
        addGetMethod(propName, getter);
      }
    }
  }
```","Could you try the latest [3.4.3-SNAPSHOT](https://github.com/mybatis/mybatis-3/wiki/Maven) with a Groovy class?

For future reference, here is the stack trace:

```
org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property boolProp in class class com.example.SomeBean.  This breaks the JavaBeans specification and can cause unpredictable results.
  at org.apache.ibatis.reflection.Reflector.resolveGetterConflicts(Reflector.java:130)
  at org.apache.ibatis.reflection.Reflector.addGetMethods(Reflector.java:113)
  at org.apache.ibatis.reflection.Reflector.<init>(Reflector.java:65)
  at org.apache.ibatis.reflection.DefaultReflectorFactory.findForClass(DefaultReflectorFactory.java:44)
  at org.apache.ibatis.reflection.ReflectorTest.shouldAllowTwoBooleanGetters(ReflectorTest.java:211)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:498)
  at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
  at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
  at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
  at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
  at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:239)
  at org.junit.rules.RunRules.evaluate(RunRules.java:20)
  at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
  at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
  at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
  at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
  at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
  at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
  at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
  at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
  at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
```
",I re-tested with the snapshot and it is working now. Thank you for the quick response! I am now able to remove a ton of useless is* methods on my groovy objects.
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/902,"<!-- BUG REPORT FORM -->

## MyBatis version
3.4.2

## Database vendor and version
PostgreSQL 9.6.1
## Test case or example project

```java
interface TicketMapper {
    @Options(flushCache = Options.FlushCachePolicy.TRUE, useGeneratedKeys=true) // Set keyProperty as the Java variable name and keyColumn as the column name in the database.
    @Insert(""INSERT INTO tickets (apikey, ticket) VALUES (#{apikey},#{ticket})"")
    public void insertTicket(final TicketTO ticket) throws RecordAlreadyExists;
   }
```

```sql
-- Tickets für die WebSocket-Anmeldung
CREATE TABLE tickets (
  ID SERIAL PRIMARY KEY,
  crdate    TIMESTAMP DEFAULT LOCALTIMESTAMP,

	-- apikey - ist in diesem Fall ein WebToken
	apikey     VARCHAR(2048)	not null,

  -- das eigentliche Ticket, eine UUID
  ticket    VARCHAR(36)	not null
);
```

```java
public class TicketTO {

    /** Verweis auf den User */
    private          String   apikey;
    private          String   ticket;
    private DateTime crdate;

    public String getAppID() {  ...  }

    public String getTicket() { ...}

    public void setTicket(final String ticket) { ... }

    public DateTime getCrdate() { ... }

    public void setCrdate(final String crdate) { ... }
}
````

This line produces to above error:
```java
getSession().getMapper(TicketMapper.class).insertTicket(ticket);
```

It's true that TicketTO has no ""id"" but this should be valid!
It works with 3.4.1 but fails with 3.4.2
","Could you please create a demo project including the configuration so that we can reproduce the issue quickly and reliably?
Here are some skeleton projects : https://github.com/harawata/mybatis-issues
Thank you!",
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/900,"<!--
Thank you for your contribution!
请将您的问题发送到邮件列表 https://groups.google.com/group/mybatis-user

Question?
======================
Please use the mailing list. http://groups.google.com/group/mybatis-user
Questions on this tracker will be closed without comment.

Bug report?
======================
Please fill out the BUG REPORT FORM below.

To fix a bug, we need to reproduce it first.
And we spend a lot of time just trying to reproduce the reported problem, so please consider creating a failing test case or an example project.

- How to create a test case : https://github.com/mybatis/mybatis-3/wiki/Unit-Test
- How to create a good example : http://sscce.org
- How to upload your project to GitHub: https://help.github.com/articles/adding-an-existing-project-to-github-using-the-command-line/

Feature request?
=======================
- Please delete the BUG REPORT FORM below and describe the feature.
- It is a good idea to discuss your changes on the mailing list to get feedback from the community. http://groups.google.com/group/mybatis-user
- If you have a patch with unit tests, send a pull request. Please see the wiki page : https://github.com/mybatis/mybatis-3/wiki/Contribute
-->

<!-- BUG REPORT FORM -->

## MyBatis version
3.4.2

## Database vendor and version

## Test case or example project

## Steps to reproduce

The mybatis-3.4.2 released at Jan 2017 was compiled by Java 8. I think it should be complied by Java 6 unless the java that mybatis supports is upgraded to java 8.

1. Make a sample code for my batis
2. Run it with mybatis-3.4.2.jar by java 6

## Expected result

These must be no error used in java 6

## Actual result

java.lang.UnsupportedClassVersionError happens.

java.lang.UnsupportedClassVersionError: org/apache/ibatis/io/Resources : Unsupported major.minor version 52.0 (unable to load class org.apache.ibatis.io.Resources)
	at org.apache.catalina.loader.WebappClassLoaderBase.findClassInternal(WebappClassLoaderBase.java:2271)
	at org.apache.catalina.loader.WebappClassLoaderBase.findClass(WebappClassLoaderBase.java:811)
	at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1254)
	at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1119)

## Status

**We has been replaced already the .zip archive with the valid one.**
(https://github.com/mybatis/mybatis-3/releases/tag/mybatis-3.4.2)
",Can you provide any more info on what you did specifically to result in this?,"Hi,

Here are the steps I did.

1. I downloadedmybatis-3.4.2.zip <https://github.com/mybatis/mybatis-3/releases/download/mybatis-3.4.2/mybatis-3.4.2.zip> from https://github.com/mybatis/mybatis-3/releases <https://github.com/mybatis/mybatis-3/releases>.
2. I unzipped the zip.
3. I extracted mybatis-3.4.2.jar to jar folder.
4. I ran the following command and it said it was a Java 8 class.

Z:\Downloads\mybatis-3.4.2\jar\org\apache\ibatis\io>javap -v Resources.class | findstr version
  minor version: 0
  major version: 52

But when I did same thing with mybatis-3.4.3-20170117.233125-7.jar <https://oss.sonatype.org/content/repositories/snapshots/org/mybatis/mybatis/3.4.3-SNAPSHOT/mybatis-3.4.3-20170117.233125-7.jar> from https://oss.sonatype.org/content/repositories/snapshots/org/mybatis/mybatis/3.4.3-SNAPSHOT/ <https://oss.sonatype.org/content/repositories/snapshots/org/mybatis/mybatis/3.4.3-SNAPSHOT/>
It said it was a Java 6 class.

Z:\Downloads\mybatis-3.4.3\jar\org\apache\ibatis\io>javap -v Resources.class | findstr version
  minor version: 0
  major version: 50

The both have same target and source JDK 1.6 

	X-Compile-Target-JDK: 1.6
	X-Compile-Source-JDK: 1.6

But the build Jdk is different.

mybatis-3.4.2.jar was built by JDK 1.8.0_111

	X-Compile-Target-JDK: 1.6
	X-Compile-Source-JDK: 1.6
	Created-By: Apache Maven Bundle Plugin
	Build-Jdk: 1.8.0_111

and mybatis-3.4.3-20170117.233125-7.jar was built by JDK 1.8.0_31

	X-Compile-Target-JDK: 1.6
	X-Compile-Source-JDK: 1.6
	Created-By: Apache Maven Bundle Plugin
	Build-Jdk: 1.8.0_31

I guess there are some changes on JDK 1.8.0_111 and it caused the issue.

Thank you,
JB.


> On Jan 18, 2017, at 10:20 PM, Jeremy Landis <notifications@github.com> wrote:
> 
> The manifest says it all...it's designed from the parent to log in the manifest what jdk version it is targetting. Plus as others noted, we are only using various jdks for testing purposes.
> 
> From manifest off maven central....
> 
> X-Compile-Target-JDK: 1.6
> X-Compile-Source-JDK: 1.6
> 
> So it is definitely compiled with java 6. So I'm curious as to how that error was even encountered. For one that would mean adding at least property values to switch the compiler to use java 8. The profiles don't matter at all in this case as that is for test only. Can you provide any more info on what you did specifically to result in this?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/mybatis/mybatis-3/issues/900#issuecomment-273671684>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ARGsUrbd1dF3y_gLc-vbgiMyP3Se8ax0ks5rTtZ5gaJpZM4LnZ7o>.
> 

"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/706,"## MyBatis version

3.4.0

Mybatis 3.4.0 use shade to integrate javassist and ognl with relocation.

But when deploy war which has mybatis-3.4.0.jar to IBM's Websphere Application Server 8.5.5.9 (Java 7), the war cannot start because of the relocation of javassist.

Then I create a mybatis-3.4.0.jar without javassist and a independent javassist jar put it to my war. And deploy it to IBM's Websphere Application Server, everything is right.
","Can you please add some more information about the error? For example the error shown in the log during startup?

Looks the same error that the one reported here:
https://groups.google.com/forum/#!topic/mybatis-user/ZhI4cPe7cq8

You will find a workaround there:

""Well you are right the issue was around javassist pkg in the mybatis jar file. I just got around the issue by adding the the following entries in META-INFMANIFEST.MF now the app starts up fine with no issues.

Manifest-Version: 1.0
Ignore-Scanning-Archives: WEB-INF/lib/mybatis-3.4.0.jar
Ignore-Scanning-Packages:  org.apache.ibatis.javassist""

Anyway we should need to find the root cause for this. I will open an issue in the shade tracker.
","https://groups.google.com/forum/#!topic/mybatis-user/ZhI4cPe7cq8
The above is exactly the same one that I met.
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/661,"<!--
Thank you for your contribution!

Question?
======================
Please use the mailing list. http://groups.google.com/group/mybatis-user
Questions on this tracker will be closed without comment.

Bug report?
======================
Please fill out the BUG REPORT FORM below.

To fix a bug, we need to reproduce it first.
And we spend a lot of time just trying to reproduce the reported problem, so please consider creating a failing test case or an example project.

- How to create a test case : https://github.com/mybatis/mybatis-3/wiki/Unit-Test
- How to create a good example : http://sscce.org
- How to upload your project to GitHub: https://help.github.com/articles/adding-an-existing-project-to-github-using-the-command-line/

Feature request?
=======================
- Please delete the BUG REPORT FORM below and describe the feature.
- It is a good idea to discuss your changes on the mailing list to get feedback from the community. http://groups.google.com/group/mybatis-user
- If you have a patch with unit tests, send a pull request. Please see the wiki page : https://github.com/mybatis/mybatis-3/wiki/Contribute
-->

<!-- BUG REPORT FORM -->
## MyBatis version

3.4.0
## Database vendor and version

Any
## Test case or example project

N/A
## Steps to reproduce

At first, i add method in `BoundBlogMapper` as follow:

``` java
  @Select({
          ""SELECT *"",
          ""FROM blog"",
          ""ORDER BY id""
  })
  Cursor<Blog> selectCursorBlogs();
```

At second, i add test method in `BindingTest` as follow:

``` java
  @Test
  public void shouldExecuteWithCursorAndRowBounds() {
    SqlSession session = sqlSessionFactory.openSession();
    try {
      BoundBlogMapper mapper = session.getMapper(BoundBlogMapper.class);
      Cursor<Blog> blogs = mapper.selectCursorBlogs();
      for (Blog b :blogs) {
        System.out.println(b);
      }
    } finally {
      session.close();
    }
  }
```
## Expected result

```
Blog: 1 : Jim Business (null)
Blog: 2 : Bally Slog (null)
```
## Actual result

```
org.apache.ibatis.reflection.ReflectionException: Error instantiating interface org.apache.ibatis.cursor.Cursor with invalid types () or values (). Cause: java.lang.NoSuchMethodException: org.apache.ibatis.cursor.Cursor.<init>()

    at org.apache.ibatis.reflection.factory.DefaultObjectFactory.instantiateClass(DefaultObjectFactory.java:90)
    at org.apache.ibatis.reflection.factory.DefaultObjectFactory.create(DefaultObjectFactory.java:50)
    at org.apache.ibatis.reflection.factory.DefaultObjectFactory.create(DefaultObjectFactory.java:42)
    at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createResultObject(DefaultResultSetHandler.java:594)
    at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createResultObject(DefaultResultSetHandler.java:571)
    at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getRowValue(DefaultResultSetHandler.java:380)
    at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValuesForSimpleResultMap(DefaultResultSetHandler.java:339)
    at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValues(DefaultResultSetHandler.java:314)
    at org.apache.ibatis.cursor.defaults.DefaultCursor.fetchNextObjectFromDatabase(DefaultCursor.java:142)
    at org.apache.ibatis.cursor.defaults.DefaultCursor.fetchNextUsingRowBound(DefaultCursor.java:128)
    at org.apache.ibatis.cursor.defaults.DefaultCursor$CursorIterator.hasNext(DefaultCursor.java:199)
    at org.apache.ibatis.binding.BindingTest.shouldExecuteWithCursorAndRowBounds(BindingTest.java:774)
...
Caused by: java.lang.NoSuchMethodException: org.apache.ibatis.cursor.Cursor.<init>()
    at java.lang.Class.getConstructor0(Class.java:3082)
    at java.lang.Class.getDeclaredConstructor(Class.java:2178)
    at org.apache.ibatis.reflection.factory.DefaultObjectFactory.instantiateClass(DefaultObjectFactory.java:62)
```
","What do you think ?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly or view it on GitHub
> https://github.com/mybatis/mybatis-3/issues/661#issuecomment-213769727
","please add milestone!!
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/526,"When I try and use foreignColumns with multiple comma separated keys I get the following error.
'There should be the same number of columns and foreignColumns in property customFields'

I've spent hours trying to get this to work and then found this in the source which may be related.

Could be related to this statement in MapperBuilderAssistant.buildResultMapping

```
List<ResultMapping> composites = parseCompositeColumnName(column);
if (composites.size() > 0) {
  column = null;
}
```
","Can you post the stacktrace?
","I don't have the stackctrace. The exception is thrown in ResultMapping.validate below. The bug is probably caused when the variable column is set to null in MapperBuildAssistant shown above.

Thanks

```
private void validate() {
...
    if (numColums != numForeignColumns) {
      throw new IllegalStateException(""There should be the same number of columns and foreignColumns in property "" + resultMapping.property);
    }
  }
}
```
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/259,"Associations don't work when a resultMap has an <association .../> element and the property associated with the assocation is a primitive array (e.g. int[]) and the sub-select's resultType is of type int.

MyBatis has the result correctly returned in a int[], but the code fails because it tries to cast that result into an Object [].

The only way I could get this to work was to change the setter of my property to take an Integer[] instead of an int[].

This used to work in MyBatis 2.
","Could you provide a [test case](/mybatis/mybatis-3/wiki/Unit-Test) ?
","Kind of tight for time, though I do appreciate the scaffolding for unit testing that you provided.

I do think though that my description of the problem is complete enough such that you should be able to take one of your unit tests and reproduce this.
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/215,"mapper : 

``` xml
<resultMap id=""user"" type=""User"">
  <id property=""id"" column=""id""/>
  <result property=""name"" column=""name""/>
  <association property=""superior"" resultMap=""user"" columnPrefix=""superior_"" />
</resultMap>

<select id=""find"" parameterType=""long"" resultMap=""user"">
  select 1 as id, 'a' as name, 2 as superior_id , 'b' as superior_name from dual
</select>
```

java :

``` java
User user = dao.find(1L);
System.out.println(""user.id : "" + user.getId());
System.out.println(""user.name : "" + user.getName());
System.out.println(""user.superior.id : "" + user.getSuperior().getId());
System.out.println(""user.superior.name : "" + user.getSuperior().getName());
```

result :

```
[DEBUG] ==>  Preparing: select 1 as id, 'a' as name, 2 as superior_id , 'b' as superior_name from dual  [org.ufox.demo.dao.UserDao.find] 
[DEBUG] ==> Parameters:  [org.ufox.demo.dao.UserDao.find] 
[DEBUG] <==      Total: 1 [org.ufox.demo.dao.UserDao.find] 
user.id : 1
user.name : a
user.superior.id : 1
user.superior.name : a
```
","Can you please submit a [test](https://github.com/mybatis/mybatis-3/wiki/Unit-Test)?
",
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/165,"When trying to register custom `TypeHandler`s for both primitive and wrapper types(e.g. `int` and `Integer`) with `TypeHandlerRegistry`, in case of primitive-then-wrapper order latter overrides former one.
Test to reproduce:

``` java
package org.apache.ibatis.type;

import org.junit.Test;

import java.sql.CallableStatement;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;

import static org.junit.Assert.assertSame;

public class PairedTypeHandlersTest {

  private TypeHandlerRegistry typeHandlerRegistry = new TypeHandlerRegistry();

  @Test
  public void registerWrapperHandlerBeforePrimitive() {
    TypeHandler<Integer> wrapperHandler = new IntegerTypeHandler();
    TypeHandler<Integer> primitiveHandler = new IntTypeHandler();

    typeHandlerRegistry.register(wrapperHandler);
    typeHandlerRegistry.register(primitiveHandler);

    assertSame(wrapperHandler, typeHandlerRegistry.getTypeHandler(Integer.class));
    assertSame(primitiveHandler, typeHandlerRegistry.getTypeHandler(int.class));
  }

  @Test
  public void registerPrimitiveHandlerBeforeWrapper() {
    TypeHandler<Integer> wrapperHandler = new IntegerTypeHandler();
    TypeHandler<Integer> primitiveHandler = new IntTypeHandler();

    typeHandlerRegistry.register(primitiveHandler);
    typeHandlerRegistry.register(wrapperHandler);

    assertSame(wrapperHandler, typeHandlerRegistry.getTypeHandler(Integer.class));
    assertSame(primitiveHandler, typeHandlerRegistry.getTypeHandler(int.class));
  }

  @MappedTypes(int.class)
  static class IntTypeHandler implements TypeHandler<Integer> {
    // skipped as not important
  }

  @MappedTypes(Integer.class)
  static class IntegerTypeHandler implements TypeHandler<Integer> {
    // skipped as not important
  }
}
```

Test `registerPrimitiveHandlerBeforeWrapper` fails, however `registerWrapperHandlerBeforePrimitive` doesn't.
","Why you need that?
",
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/135,"If a TypeHandler for the Map class is registered, it gets invoked inappropriately when a mapper method uses multiple parameters. 

For example, a TypeHandler:

``` Java
@MappedTypes(Map.class)
public class LabelsTypeHandler implements TypeHandler<Map<String, Object>> { ... }
```

Then these methods in the mapper interface:

``` Java
@Select(""SELECT #{myId};"")
int echoSingle(@Param(""myId"") long myId);
@Select(""SELECT #{myId};"")
int echoMulti(@Param(""myId"") long myId, @Param(""yourId"") int yourId);
```

The first method, with just one parameter, succeeds, while the second method fails with a stack trace that ends with:

``` Java
### Error querying database.  Cause: java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map
### The error may exist in org/example/persistence/SomeMapper.java (best guess)
### The error may involve org.example.persistence.SomeMapper.echoMulti-Inline
### The error occurred while setting parameters
### SQL: SELECT ?;
### Cause: java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map
    at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:23)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:107)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:98)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:62)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:358)
    ... 35 more
Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map
    at org.example.typehandler.LabelsTypeHandler.setParameter(LabelsTypeHandler.java:1)
    at org.apache.ibatis.scripting.defaults.DefaultParameterHandler.setParameters(DefaultParameterHandler.java:77)
    at org.apache.ibatis.executor.statement.PreparedStatementHandler.parameterize(PreparedStatementHandler.java:77)
    at org.apache.ibatis.executor.statement.RoutingStatementHandler.parameterize(RoutingStatementHandler.java:58)
    at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:71)
    at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:56)
    at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:259)
    at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:132)
    at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:115)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:104)
    ... 42 more

```
","Can you create a repo with a failing test? That will be really helpful.
","Wow, cool!
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/125,"Hi guys,

Our team is trying to use MyBatis instead of Hibernate on one of our projects and we picked up an intereseting bug.

We are using legacy DB (no way we can change it's structure) and almost all primary keys are VARBINARY.

The problem that we faced is ""Nested Results for Collection"" will not work properly when primary key is mapped to array field (VARBINARY gets mapped to byte[] in value object)

We've created a small project with unit tests that explain problem properly. Please find it here: 
https://github.com/ekravchenko/testingzone/tree/master/mybatis.collection.mapping.bug

Please consider the following example. Let's say we have PersonVO:
![image](https://f.cloud.github.com/assets/3638230/1914772/299c41de-7d5d-11e3-8622-a024b8be810f.png)

ChildVO is very simple:
![image](https://f.cloud.github.com/assets/3638230/1914784/3e2e51d2-7d5d-11e3-915a-3389ac2c22ee.png)

When the following result map is applied - collection mapping works as expected. 
![image](https://f.cloud.github.com/assets/3638230/1914788/5568c652-7d5d-11e3-836f-c11386bf2e6d.png)

We will get 3 person items with collections of child items properly populated

However when we try same query with different result map where <b>id</b> is mapped to byte[]:
![image](https://f.cloud.github.com/assets/3638230/1914795/8a5b730a-7d5d-11e3-847f-3ede006762b1.png)

The test will not pass and we will get duplicates (7 person items instead of 3)

Bug can be reproduced using version 3.2.3 and the latest SNAPSHOT as well.

Thanks,
Yevgen Kravchenko
","Does that solve this one?
","The test CacheKeyTest.shouldTestCacheKeysWithBinaryArrays is green so I'm pretty sure fix should be fine. However I'll double check on a sample application. Will let you know
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/68,"I recently decided to move my project's MyBatis version to 3.2.2 from 3.1.1
My project also uses `mybatis-spring` (version 1.2.0), alongwith `mybatis-hazelcast` (version 1.0.1).

But now, when I start my Tomcat, it never completely starts up. The logs show a huge number of MyBatis stuff, which keeps on repeating itself. The class `org.apache.ibatis.io.ResolverUtil` keeps on checking the domain classes and mapper classes.

If I revert the mybatis version to 3.1.1, then Tomcat starts up fine.

As there is no exception stack, I can't even be sure of what's going wrong. 
","Can you post the log?
","I've pasted the log [here](http://pastebin.com/YTSFW17A) — it's quite verbose, but you'll see how mybatis keeps reloading all the files.
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/61,"Since I upgraded to mybatis 3.2.2, one of my sql is failing. It used to work prior to upgrading to 3.2.2. 

To reproduce this issue, make a slight modification to the src\test\java\org\apache\ibatis\submitted\basetest\Mapper.xml file to ""getUser"" Select statement:

```
<select id=""getUser"" parameterType=""java.lang.String"" resultType=""org.apache.ibatis.submitted.basetest.User"">
        select * from users 
       <if test=""value not in {null, ''}"">
       where name = #{value}
      </if>
</select>
```

Once the above change is made, in BaseTest.java, line 57 is changed to:
`final User user = mapper.getUser(""User1"");`

When you run the test, you will now get the following error that did not used to occur before the upgrade to 3.2.2:

```
Type handler was null on parameter mapping for property 'value'. It was either not specified and/or could not be found for the javaType / jdbcType combination specified.
```
","Can you please try it?

http://code.google.com/p/mybatis/downloads/list?can=3&q=Product%3DMyBatis
","The snapshot fixed the issue. Thank you !
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/58," private Connection doGetConnection(String username, String password) throws SQLException {
    Properties props = new Properties(driverProperties);

props not a copy of driverProperties
","why not?
",
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/40,"If you have a trailing space in the alias attribute of a typeAlias definition, like this:

```
<typeAliases>
  <typeAlias alias=""User ""  type=""com.example.domain.User"" />
</typeAliases>
```

at runtime you get an exception like this:

```
java.lang.IllegalArgumentException: Result Maps collection already contains value for com.example.persistence.UserMapper.mapper_resultMap[xxx]_association[xxx]
```

where the map and association referenced in the exception are ones defined in your mapper.

Removing the trailing space fixes the problem, but it took a long time to track down. 
","Can you post your resultmap? When using that in the default test I get an expected result

``` java
org.apache.ibatis.exceptions.PersistenceException: 
### Error building SqlSession.
### The error may exist in org/apache/ibatis/submitted/basetest/Mapper.xml
### Cause: org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.builder.BuilderException: Error parsing Mapper XML. Cause: org.apache.ibatis.builder.BuilderException: Error resolving class. Cause: org.apache.ibatis.type.TypeException: Could not resolve type alias 'user'.  Cause: java.lang.ClassNotFoundException: Cannot find class: user
    at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:23)
    at org.apache.ibatis.session.SqlSessionFactoryBuilder.build(SqlSessionFactoryBuilder.java:51)
    at org.apache.ibatis.session.SqlSessionFactoryBuilder.build(SqlSessionFactoryBuilder.java:35)
    at org.apache.ibatis.submitted.basetest.BaseTest.setUp(BaseTest.java:38)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:601)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
    at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: org.apache.ibatis.builder.BuilderException: Error parsing Mapper XML. Cause: org.apache.ibatis.builder.BuilderException: Error resolving class. Cause: org.apache.ibatis.type.TypeException: Could not resolve type alias 'user'.  Cause: java.lang.ClassNotFoundException: Cannot find class: user
    at org.apache.ibatis.builder.xml.XMLConfigBuilder.parseConfiguration(XMLConfigBuilder.java:106)
    at org.apache.ibatis.builder.xml.XMLConfigBuilder.parse(XMLConfigBuilder.java:89)
    at org.apache.ibatis.session.SqlSessionFactoryBuilder.build(SqlSessionFactoryBuilder.java:49)
    ... 17 more
Caused by: org.apache.ibatis.builder.BuilderException: Error parsing Mapper XML. Cause: org.apache.ibatis.builder.BuilderException: Error resolving class. Cause: org.apache.ibatis.type.TypeException: Could not resolve type alias 'user'.  Cause: java.lang.ClassNotFoundException: Cannot find class: user
    at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java:114)
    at org.apache.ibatis.builder.xml.XMLMapperBuilder.parse(XMLMapperBuilder.java:89)
    at org.apache.ibatis.builder.annotation.MapperAnnotationBuilder.loadXmlResource(MapperAnnotationBuilder.java:159)
    at org.apache.ibatis.builder.annotation.MapperAnnotationBuilder.parse(MapperAnnotationBuilder.java:113)
    at org.apache.ibatis.binding.MapperRegistry.addMapper(MapperRegistry.java:66)
    at org.apache.ibatis.session.Configuration.addMapper(Configuration.java:650)
    at org.apache.ibatis.builder.xml.XMLConfigBuilder.mapperElement(XMLConfigBuilder.java:326)
    at org.apache.ibatis.builder.xml.XMLConfigBuilder.parseConfiguration(XMLConfigBuilder.java:104)
    ... 19 more
Caused by: org.apache.ibatis.builder.BuilderException: Error resolving class. Cause: org.apache.ibatis.type.TypeException: Could not resolve type alias 'user'.  Cause: java.lang.ClassNotFoundException: Cannot find class: user
    at org.apache.ibatis.builder.BaseBuilder.resolveClass(BaseBuilder.java:100)
    at org.apache.ibatis.builder.xml.XMLStatementBuilder.parseStatementNode(XMLStatementBuilder.java:69)
    at org.apache.ibatis.builder.xml.XMLMapperBuilder.buildStatementFromContext(XMLMapperBuilder.java:129)
    at org.apache.ibatis.builder.xml.XMLMapperBuilder.buildStatementFromContext(XMLMapperBuilder.java:122)
    at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java:112)
    ... 26 more
Caused by: org.apache.ibatis.type.TypeException: Could not resolve type alias 'user'.  Cause: java.lang.ClassNotFoundException: Cannot find class: user
    at org.apache.ibatis.type.TypeAliasRegistry.resolveAlias(TypeAliasRegistry.java:114)
    at org.apache.ibatis.builder.BaseBuilder.resolveAlias(BaseBuilder.java:127)
    at org.apache.ibatis.builder.BaseBuilder.resolveClass(BaseBuilder.java:98)
    ... 30 more
Caused by: java.lang.ClassNotFoundException: Cannot find class: user
    at org.apache.ibatis.io.ClassLoaderWrapper.classForName(ClassLoaderWrapper.java:188)
    at org.apache.ibatis.io.ClassLoaderWrapper.classForName(ClassLoaderWrapper.java:87)
    at org.apache.ibatis.io.Resources.classForName(Resources.java:254)
    at org.apache.ibatis.type.TypeAliasRegistry.resolveAlias(TypeAliasRegistry.java:110)
    ... 32 more
```
","Here is a sample resultmap:

```
<resultMap id=""caseMap"" type=""Case"">
  <id property=""id"" column=""case_id"" javaType=""int"" jdbcType=""INTEGER""/>
  <result property=""comment""  column=""case_comment"" javaType=""String""/>
</resultMap>

<resultMap id=""patientMap"" type=""Patient"">
  <id property=""id"" column=""pat_id"" javaType=""int"" jdbcType=""INTEGER""/>
  <result property=""firstName"" column=""pat_first""  javaType=""String""/>
  <result property=""lastName""  column=""pat_last""   javaType=""String""/>
</resultMap>
```

The Patient alias is the one with the trailing space in the alias definition. If I reference the patientMap via an association in caseMap, I get the same exception as you. I get the IllegalArgumentException exception when the patientMap isn't referenced. 
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/39,"I ran into a bug in which I expected a result set of about 3600 rows and get 1.  The row I get back is the last row of the result set I see in Oracle SQL Developer.   I've traced the issue to handleRowValues() in NestedResultSetHandler.  Based on tracing thru that code in the debugger the row value gets set by the line:

```
rowValue = getRowValue(rs, discriminatedResultMap, rowKey, rowKey, null, resultColumnCache, partialObject);
```

but then nothing actually happens with the value.  It would appear that the if statement right after should be within the bracket directly above it (existing source below):

```
while (shouldProcessMoreRows(rs, resultContext, rowBounds)) {
  final ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rs, resultMap, null);
  final CacheKey rowKey = createRowKey(discriminatedResultMap, rs, null, resultColumnCache);
  Object partialObject = objectCache.get(rowKey);
  if (partialObject == null && rowValue != null) { // issue #542 delay calling ResultHandler until object ends
    if (mappedStatement.isResultOrdered()) objectCache.clear(); // issue #577 clear memory if ordered
    callResultHandler(resultHandler, resultContext, rowValue);
  } 
  rowValue = getRowValue(rs, discriminatedResultMap, rowKey, rowKey, null, resultColumnCache, partialObject);
}
if (rowValue != null) callResultHandler(resultHandler, resultContext, rowValue);
```

In the 3.1.1 release the rowValue is bieng put into another collection:

```
while (shouldProcessMoreRows(rs, resultContext, rowBounds)) {
  final ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rs, resultMap, null);
  final CacheKey rowKey = createRowKey(discriminatedResultMap, rs, null, resultColumnCache);
  final boolean knownValue = objectCache.containsKey(rowKey);
  Object rowValue = getRowValue(rs, discriminatedResultMap, rowKey, resultColumnCache);
  if (!knownValue) {
    resultContext.nextResultObject(rowValue);
    resultHandler.handleResult(resultContext);
  }
}
```

**EDIT**: maybe not quite that simple as I didn't look at the source enough before posting.  Based on more debugging the callResultHandler inside the if statement (thats inside the while loop) is never getting called.  That would explain why i am only seeing the last row of the resultset in the returned collection.  its being put in there by the second if.
","Can you try with 3.2.2 and tell the results?
","Actually the code I posted above is from 3.2.1.  I tried 3.2.2 and 3.2.3 snapshot with the same results before entering this bug.  I had to roll back to 3.1.1 for the time being.
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/9,"I run into an issue where I mapped a result in a resultMap to Joda's DateTime but didn't register a TypeHandler. Rather than failing with a new error message, it looks like the org.apache.ibatis.executor.resultset.FastResultSetHandler class is returning null in the getPropertyMappingValue method (somewhere near line 316). 

This code should be more like this:

``` java
  protected Object getPropertyMappingValue(ResultSet rs, MetaObject metaResultObject, ResultMapping propertyMapping, ResultLoaderMap lazyLoader, String columnPrefix) throws SQLException {
    final TypeHandler<?> typeHandler = propertyMapping.getTypeHandler();
    if (propertyMapping.getNestedQueryId() != null) {
      return getNestedQueryMappingValue(rs, metaResultObject, propertyMapping, lazyLoader, columnPrefix);
    } else if (typeHandler != null) {
      final String column = prependPrefix(propertyMapping.getColumn(), columnPrefix);
      return typeHandler.getResult(rs, column);
    }
    throw new TypeHandlerException(""Unknown type "" + propertyMapping.getJavaType() + "". You need to register a TypeHandler for this type for MyBatis to correctly convert the result."");
  }
```

Instead, it looks like this (notice the return null at the end):

``` java

  protected Object getPropertyMappingValue(ResultSet rs, MetaObject metaResultObject, ResultMapping propertyMapping, ResultLoaderMap lazyLoader, String columnPrefix) throws SQLException {
    final TypeHandler<?> typeHandler = propertyMapping.getTypeHandler();
    if (propertyMapping.getNestedQueryId() != null) {
      return getNestedQueryMappingValue(rs, metaResultObject, propertyMapping, lazyLoader, columnPrefix);
    } else if (typeHandler != null) {
      final String column = prependPrefix(propertyMapping.getColumn(), columnPrefix);
      return typeHandler.getResult(rs, column);
    }
    return null;
  }
```
","Would it not be better to ensure that you have a type handler for every type that you've trying to retrieve?
",
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/6,"Following situation:

In package 'com.example.beans'
there are two classes:

``` java
package com.example.beans;

class A {
  public static enum State {
    ON,
    OFF
  }
}
```

``` java
package com.example.beans;

class B {
  public static enum State {
    FRESH,
    ROTTEN
  }
}
```

In the mybatis configuration xml file:

``` xml
<typeAliases>
  <package name=""com.example.beans"" />
</typeAliases>
```

This leads to following exception:

[..]
org.apache.ibatis.type.TypeException: The alias 'State' is already mapped to the value 'com.example.beans.A$State'.
    at org.apache.ibatis.type.TypeAliasRegistry.registerAlias(TypeAliasRegistry.java:146)
[..]

A solution for me (no idea what sideeffects this may cause) is to replace line 127 in TypeAliasRegistry.java

``` java
if (!type.isAnonymousClass() && !type.isInterface()) {
```

with

``` java
if (!type.isAnonymousClass() && !type.isInterface()  && !type.isEnum()) {
```
","Why not mention @Alias in the error message?  That would give users a head start on fixing the problem.
","Thumbs up for paulkrause88, @Alias does the job perfectly for me.

Genrally, I think the best way would be to make ignoring member classes an option, like this:

``` xml
<typeAliases>
  <package name=""com.example.beans""  mapMemberClasses=""false""/>
</typeAliases>
```

And perhaps a depth-parameter to configure recursive mapping of subpackages?
That way one could resemble the behavior of earlier mybatis by configuration:

``` xml
<typeAliases>
  <package name=""com.example.beans""  mapMemberClasses=""false"" depth=""0""/>
</typeAliases>
```
"
mybatis/mybatis-3,https://github.com/mybatis/mybatis-3/issues/3,"Reported by mgbckr, Today (6 hours ago)
What version of the MyBatis are you using?
MyBatis 3.2.0, MyBatis-Spring 1.2.0

Please describe the problem.  Unit tests are best!
When I use the ""less than"" sign ""<"" in a Select annotations, I get an exception is thrown when initializing the application context. If I use ""&lt;"" it works. In previous MyBatis versions using ""<"" was working. I think it is counter-intuitive to be forced to use XML entities in Java code if not explicitly documented. 

What is the expected output? What do you see instead?
No exception :)

Can you provide stack trace, logs, error messages that are displayed?
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mapper' defined in file [/media/data/Projects/EveryAware/workspaces/development/mybatis-invalid-annotation2/target/classes/de/fstyle/test/mybatis/invalid/annotation/mapper/Mapper.class]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: org.apache.ibatis.builder.BuilderException: Could not find value method on SQL annotation.  Cause: org.apache.ibatis.builder.BuilderException: Error creating document instance.  Cause: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 38; The content of elements must consist of well-formed character data or markup.
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1486)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:524)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)
    at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)
    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)
    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)
    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:608)
    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)
    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)
    at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)
    at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:83)
    at de.fstyle.test.mybatis.invalid.annotation.InvalidAnnotationTest.test(InvalidAnnotationTest.java:17)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:616)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
    at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: java.lang.IllegalArgumentException: org.apache.ibatis.builder.BuilderException: Could not find value method on SQL annotation.  Cause: org.apache.ibatis.builder.BuilderException: Error creating document instance.  Cause: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 38; The content of elements must consist of well-formed character data or markup.
    at org.mybatis.spring.mapper.MapperFactoryBean.checkDaoConfig(MapperFactoryBean.java:98)
    at org.springframework.dao.support.DaoSupport.afterPropertiesSet(DaoSupport.java:44)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1545)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1483)
    ... 35 more
Caused by: org.apache.ibatis.builder.BuilderException: Could not find value method on SQL annotation.  Cause: org.apache.ibatis.builder.BuilderException: Error creating document instance.  Cause: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 38; The content of elements must consist of well-formed character data or markup.
    at org.apache.ibatis.builder.annotation.MapperAnnotationBuilder.getSqlSourceFromAnnotations(MapperAnnotationBuilder.java:399)
    at org.apache.ibatis.builder.annotation.MapperAnnotationBuilder.parseStatement(MapperAnnotationBuilder.java:241)
    at org.apache.ibatis.builder.annotation.MapperAnnotationBuilder.parse(MapperAnnotationBuilder.java:120)
    at org.apache.ibatis.binding.MapperRegistry.addMapper(MapperRegistry.java:62)
    at org.apache.ibatis.session.Configuration.addMapper(Configuration.java:628)
    at org.mybatis.spring.mapper.MapperFactoryBean.checkDaoConfig(MapperFactoryBean.java:95)
    ... 38 more
Caused by: org.apache.ibatis.builder.BuilderException: Error creating document instance.  Cause: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 38; The content of elements must consist of well-formed character data or markup.
    at org.apache.ibatis.parsing.XPathParser.createDocument(XPathParser.java:253)
    at org.apache.ibatis.parsing.XPathParser.<init>(XPathParser.java:112)
    at org.apache.ibatis.scripting.xmltags.XMLScriptBuilder.<init>(XMLScriptBuilder.java:44)
    at org.apache.ibatis.scripting.xmltags.XMLLanguageDriver.createSqlSource(XMLLanguageDriver.java:39)
    at org.apache.ibatis.builder.annotation.MapperAnnotationBuilder.buildSqlSourceFromStrings(MapperAnnotationBuilder.java:409)
    at org.apache.ibatis.builder.annotation.MapperAnnotationBuilder.getSqlSourceFromAnnotations(MapperAnnotationBuilder.java:392)
    ... 43 more
Caused by: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 38; The content of elements must consist of well-formed character data or markup.
    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)
    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)
    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:391)
    at com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1404)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.startOfMarkup(XMLDocumentFragmentScannerImpl.java:2583)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2680)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:625)
    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:488)
    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:819)
    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:748)
    at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:123)
    at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:239)
    at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:288)
    at org.apache.ibatis.parsing.XPathParser.createDocument(XPathParser.java:251)
    ... 48 more

Please provide any additional information below.
See: https://code.google.com/p/fstyle-test/source/browse/#git%2Fbug%2Fmybatis-invalid-annotation
","which commit closes that issue? it would be better using one of github aliases in commit messages such as the ones below

fixes #xxx
fixed #xxx
fix #xxx
closes #xxx
close #xxx
closed #xxx
","Hi Simo!

I will commit the fix soon (hopefully in some minutes). Github recognizes
the comment and adds it automatically to the issue.
"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/10328,"### Description of the problem / feature request:

Bazel 1.2.1 with Xcode CLT is broken.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

This works:
```
philwo@takaramono:src/bazel ‹master›$ sudo xcode-select -s /Applications/Xcode.app

philwo@takaramono:src/bazel ‹master›$ xcode-select -p
/Applications/Xcode.app/Contents/Developer

philwo@takaramono:src/bazel ‹master›$ gcc --version
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/4.2.1
Apple clang version 11.0.0 (clang-1100.0.33.12)
Target: x86_64-apple-darwin19.0.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

philwo@takaramono:src/bazel ‹master›$ bazel clean && bazel shutdown && bazel build //src:bazel
```

This fails:
```
philwo@takaramono:src/bazel ‹master›$ sudo xcode-select -s /Library/Developer/CommandLineTools 

philwo@takaramono:src/bazel ‹master›$ xcode-select -p
/Library/Developer/CommandLineTools

philwo@takaramono:src/bazel ‹master›$ gcc --version
Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1
Apple clang version 11.0.0 (clang-1100.0.33.12)
Target: x86_64-apple-darwin19.0.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

philwo@takaramono:src/bazel ‹master›$ bazel clean && bazel shutdown && bazel build //src:bazel
INFO: Starting clean.
Starting local Bazel server and connecting to it...
DEBUG: /private/var/tmp/_bazel_philwo/7a01905b4627ca044e5e3f5ad5b14d26/external/bazel_toolchains/rules/rbe_repo/checked_in.bzl:103:9: rbe_ubuntu1804_java11 not using checked in configs as detect_java_home was set to True 
DEBUG: /private/var/tmp/_bazel_philwo/7a01905b4627ca044e5e3f5ad5b14d26/external/bazel_toolchains/rules/rbe_repo/checked_in.bzl:103:9: rbe_ubuntu1604_java8 not using checked in configs as detect_java_home was set to True 
ERROR: /private/var/tmp/_bazel_philwo/7a01905b4627ca044e5e3f5ad5b14d26/external/local_config_cc/BUILD:63:5: in apple_cc_toolchain rule @local_config_cc//:cc-compiler-darwin_x86_64: Xcode version must be specified to use an Apple CROSSTOOL. If your Xcode version has changed recently, verify that ""xcode-select -p"" is correct and then try: ""bazel shutdown"" to re-run Xcode configuration
ERROR: Analysis of target '//src:bazel' failed; build aborted: Analysis of target '@local_config_cc//:cc-compiler-darwin_x86_64' failed; build aborted
INFO: Elapsed time: 2.411s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (130 packages loaded, 1028 targets configured)
    currently loading: third_party/protobuf/3.6.1
```

### What operating system are you running Bazel on?

macOS 10.15.1

### What's the output of `bazel info release`?

release 1.2.1
","Can you repro with --expunge? If not, I'd close this issue as WAI.

Since Bazel external repositories are not recomputed with bazel clean, cc_configure will not try to re-detect Xcode and will result in the failure you observe. --expunge will also clear repositories, will force cc_configure, and should build correctly.

Recently we added bazel reconfigure command, that should fix this as well (but I haven't tried it yet).",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/10276,"### Description of the problem:

Bazel seems to compile a dependency with the wrong configuration.
This happens if a binary depends on more then one different binaries, that implement transitions, through runfiles.

Scenario description:

Two binary rules that define a configuration transition for copts. (Referred to as `a` and `b`)

Two library rules defining the same file as srcs. `a` and `b` depend on and compile differently via transitions. (Referred to as `c_a` and `c_b`)

`c_a` Has header.h in hdrs, `c_b` doesn't.

One binary rule that depends on the executables of `a` and `b` as runfiles. (Referred to as d)
```
       /-> c_a  -> a \
code.c                 -- runfiles--> d
       \-> c_b  -> b /
```

```cpp
// code.c
#ifdef FLAGA
#include header.h
#endif

#ifdef FLAGB
// No Include
#endif
```

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

I set up a minimal example here: https://github.com/FaBrand/bazel_runfiles_transitions 

### What operating system are you running Bazel on?

Windows 10 Enterprise / WSL1 - Ubuntu

### What's the output of `bazel info release`?

release 1.1.0

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

```
https://github.com/FaBrand/bazel_runfiles_transitions.git
8822e7ba31477013d30cf3f1c12e0d3f2f20c112
8822e7ba31477013d30cf3f1c12e0d3f2f20c112
```

###  Have you found anything relevant by searching the web?

Unfortunately not

### Any other information, logs, or outputs that you want to share?

All information should be available here:

",Can you clarify the explicit build errors you see?,"@gregestren I checked again, and with version `1.2.0` everything seems to work just fine.
Seems like i just missed the release of the newer version by a few hours when reporting 🙈 
So i guess it is not relevant anymore as it works in the latest release.

(with using bazelisk)
with `1.1.0` i get (as expected):
```
$ USE_BAZEL_VERSION=1.1.0 bazel run consumer
[...]
ERROR: /bazel_runfiles_transitions/BUILD:17:1: C++ compilation of rule '//:library_b' failed (Exit 1) gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -MD -MF ... (remaining 17 argument(s) skipped)

Use --sandbox_debug to see verbose messages from the sandbox
code.c:3:10: fatal error: include/header.h: No such file or directory
 #include ""include/header.h""
          ^~~~~~~~~~~~~~~~~~
compilation terminated.
Target //:consumer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 10.482s, Critical Path: 0.21s
```

with `1.2.0`
```
$ USE_BAZEL_VERSION=1.2.0 bazel run consumer
Target //:consumer up-to-date:
  bazel-bin/consumer
INFO: Elapsed time: 5.390s, Critical Path: 0.07s
INFO: 0 processes.
INFO: Build completed successfully, 4 total actions
INFO: Build completed successfully, 4 total actions
Hello Bazel
Hello Bazel
```"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/10149,"### Description of the problem / feature request:

When the build is too slow and you're trying to debug it using 

```
$ time bazel build --experimental_generate_json_trace_profile --experimental_profile_cpu_usage --profile trace-profile.json //:target
```

I get
```
INFO: Elapsed time: 81983.972s, Critical Path: 2056.42s
INFO: 9202 processes: 8703 darwin-fake-sandbox, 499 local.
INFO: Build completed successfully, 11954 total actions
Internal error thrown during build. Printing stack trace: java.lang.IllegalStateException: startTime was -50421716336292
	at com.google.common.base.Preconditions.checkState(Preconditions.java:573)
	at com.google.devtools.build.lib.profiler.Profiler.logTask(Profiler.java:687)
	at com.google.devtools.build.lib.profiler.Profiler.logEventAtTime(Profiler.java:782)
	at com.google.devtools.build.lib.profiler.CollectLocalCpuUsage.logCollectedData(CollectLocalCpuUsage.java:73)
	at com.google.devtools.build.lib.profiler.Profiler.stop(Profiler.java:635)
	at com.google.devtools.build.lib.runtime.BlazeRuntime.afterCommand(BlazeRuntime.java:643)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:526)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:192)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:573)
	at com.google.devtools.build.lib.server.GrpcServerImpl.lambda$run$2(GrpcServerImpl.java:624)
	at java.base/java.lang.Thread.run(Unknown Source)
java.lang.IllegalStateException: startTime was -50421716336292
	at com.google.common.base.Preconditions.checkState(Preconditions.java:573)
	at com.google.devtools.build.lib.profiler.Profiler.logTask(Profiler.java:687)
	at com.google.devtools.build.lib.profiler.Profiler.logEventAtTime(Profiler.java:782)
	at com.google.devtools.build.lib.profiler.CollectLocalCpuUsage.logCollectedData(CollectLocalCpuUsage.java:73)
	at com.google.devtools.build.lib.profiler.Profiler.stop(Profiler.java:635)
	at com.google.devtools.build.lib.runtime.BlazeRuntime.afterCommand(BlazeRuntime.java:643)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:526)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:192)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:573)
	at com.google.devtools.build.lib.server.GrpcServerImpl.lambda$run$2(GrpcServerImpl.java:624)
	at java.base/java.lang.Thread.run(Unknown Source)
WARNING: Waiting for server process to terminate (waited 5 seconds, waiting at most 60)
/Users/obonilla/o/bazel/bazel-bin/src/bazel build   --spawn_strategy=sandboxe  2.86s user 1.76s system 0% cpu 22:46:29.41 total
```

### Feature requests: what underlying problem are you trying to solve with this feature?

I was trying to figure out why the build is so slow.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

Not sure how to repro other than have a build that is about 22 hours long and try to generate a trace profile.

### What operating system are you running Bazel on?

```
% sw_vers
ProductName:	Mac OS X
ProductVersion:	10.15.1
BuildVersion:	19B88
```

### What's the output of `bazel info release`?

```
$ bazel info release
WARNING: Waiting for server process to terminate (waited 5 seconds, waiting at most 60)
Starting local Bazel server and connecting to it...
INFO: Invocation ID: 28ae6faa-8a0f-4903-9b06-ce89de1d6b8e
release 0.29.1
```",Did you have time to try again?,Sorry no. After upgrading the OS and Xcode the build stopped being that slow. We can close this issue and I’ll reopen if I see it again. I hope I never have to deal with a build so slow it overflows an integer though. :-)
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/10038,"https://buildkite.com/bazel/bazel-at-head-plus-downstream/builds/1238#4455603b-b8b0-46a2-98a0-6fae47c3c82a

This happened before, which was fixed by [updating the cache poison key](https://github.com/bazelbuild/continuous-integration/commit/2e04e41a934a64e69473d2e80899d8c11958083f), but I think it's better to figure out the underlying problem. ",What makes you think it's cache poisoning?,"Because I tried to reproduce on a VM and I can only reproduce with remote caching. The same failure happened before, it was green for a while after I updated the cache key https://github.com/bazelbuild/continuous-integration/commit/2e04e41a934a64e69473d2e80899d8c11958083f, now it appears again."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/9172,"

If you try to share cache between two projects with different workspace name, when the cache is hit for a C++ compilation, the header check will fail because the header paths printed by MSVC's `/showInclude` option are absolute paths, which contains the workspace name.

You can reproduce with:
https://github.com/meteorcloudy/my_tests/tree/master/cpp_cache_with_different_workspace_name

```
$ cd A
$ bazel build --disk_cache=C:/src/tmp/bazel_disk_cache :hello
$ cd ../B
$ bazel build --disk_cache=C:/src/tmp/bazel_disk_cache :hello
Starting local Bazel server and connecting to it...
INFO: Invocation ID: e98dabd3-b255-4c34-86e5-ab5070b346f3
INFO: Analyzed target //:hello (13 packages loaded, 72 targets configured).
INFO: Found 1 target...
ERROR: C:/tools/msys64/home/pcloudy/workspace/my_tests/cpp_cache_with_different_workspace_name/b/BUILD:1:1: undeclared inclusion(s) in rule '//:hello':
this rule is missing dependency declarations for the following files included by 'hello.cc':
  'C:/users/pcloudy/_bazel_pcloudy/7tppxn5m/execroot/a/hello.h'
Target //:hello failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 10.570s, Critical Path: 0.09s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
```

Note the error message when we build //:hello in B,
**'C:/users/pcloudy/_bazel_pcloudy/7tppxn5m/execroot/a/hello.h'** is from project A.

This is the root cause of https://buildkite.com/bazel/bazel-federation/builds/19#ee3795da-1088-4c27-b81e-2636e30e3587

FYI @fweikert @laszlocsomor ",Why wouldn't we?,"> Why wouldn't we? 

Exactly, I don't have any good reason to object it.
Then, I might know how to fix this, will send a change today."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/9115,"> ATTENTION! Please read and follow:
> - if this is a _question_ about how to build / test / query / deploy using Bazel, or a _discussion starter_, send it to bazel-discuss@googlegroups.com
> - if this is a _bug_ or _feature request_, fill the form below as best as you can.

### Description of the problem / feature request:

Attempting to run `~/Downloads/bazel-0.29.0rc4-darwin-x86_64 build //google/cloud/bigtable:bigtable_client  --incompatible_depset_is_not_iterable=false` at https://github.com/googleapis/google-cloud-cpp/tree/5ad364581ed52ce457a2f79449964063e96242c6 results in

```
ERROR: /private/var/tmp/_bazel_jedmonds/22048c7097941053f1f6c951591631cf/external/com_google_googleapis/google/longrunning/BUILD.bazel:107:1: Action external/com_google_googleapis/google/longrunning/operations.grpc.pb.h failed (Exit 1) protoc failed: error executing command 
  (cd /private/var/tmp/_bazel_jedmonds/22048c7097941053f1f6c951591631cf/sandbox/darwin-sandbox/402/execroot/com_github_googleapis_google_cloud_cpp && \
  exec env - \
  bazel-out/host/bin/external/com_google_protobuf/protoc '--plugin=protoc-gen-PLUGIN=bazel-out/host/bin/external/com_github_grpc_grpc/grpc_cpp_plugin' '--PLUGIN_out=:bazel-out/darwin-fastbuild/bin/external/com_google_googleapis' '--proto_path=external/com_google_googleapis' '--proto_path=external/com_google_googleapis' '--proto_path=external/com_google_googleapis' '--proto_path=bazel-out/darwin-fastbuild/bin/external/com_google_protobuf' '--proto_path=external/com_google_googleapis' '--proto_path=bazel-out/darwin-fastbuild/bin/external/com_google_protobuf' '--proto_path=bazel-out/darwin-fastbuild/bin/external/com_google_protobuf' '--proto_path=bazel-out/darwin-fastbuild/bin/external/com_google_protobuf' '--proto_path=bazel-out/darwin-fastbuild/bin/external/com_google_googleapis/external/com_google_googleapis' external/com_google_googleapis/google/longrunning/operations.proto)
Execution platform: @bazel_tools//platforms:host_platform

Use --sandbox_debug to see verbose messages from the sandbox
bazel-out/darwin-fastbuild/bin/external/com_google_googleapis/external/com_google_googleapis: warning: directory does not exist.
google/protobuf/descriptor.proto: File not found.
google/api/annotations.proto: Import ""google/protobuf/descriptor.proto"" was not found or had errors.
google/api/annotations.proto:28:8: ""google.protobuf.MethodOptions"" is not defined.
google/protobuf/any.proto: File not found.
google/protobuf/duration.proto: File not found.
google/protobuf/empty.proto: File not found.
google/rpc/status.proto: Import ""google/protobuf/any.proto"" was not found or had errors.
google/rpc/status.proto:93:12: ""google.protobuf.Any"" is not defined.
google/longrunning/operations.proto: Import ""google/api/annotations.proto"" was not found or had errors.
google/longrunning/operations.proto: Import ""google/protobuf/any.proto"" was not found or had errors.
google/longrunning/operations.proto: Import ""google/protobuf/duration.proto"" was not found or had errors.
google/longrunning/operations.proto: Import ""google/protobuf/empty.proto"" was not found or had errors.
google/longrunning/operations.proto: Import ""google/rpc/status.proto"" was not found or had errors.
google/longrunning/operations.proto: Import ""google/protobuf/descriptor.proto"" was not found or had errors.
google/longrunning/operations.proto:132:3: ""google.protobuf.Any"" is not defined.
google/longrunning/operations.proto:144:5: ""google.rpc.Status"" is not defined.
google/longrunning/operations.proto:154:5: ""google.protobuf.Any"" is not defined.
google/longrunning/operations.proto:208:3: ""google.protobuf.Duration"" is not defined.
google/longrunning/operations.proto:35:8: ""google.protobuf.MethodOptions"" is not defined.
google/longrunning/operations.proto:84:56: ""google.protobuf.Empty"" is not defined.
google/longrunning/operations.proto:100:56: ""google.protobuf.Empty"" is not defined.
Target //google/cloud/bigtable:bigtable_client failed to build
INFO: Elapsed time: 0.547s, Critical Path: 0.10s
INFO: 2 processes: 2 darwin-sandbox.
FAILED: Build did NOT complete successfully
```

Bazel 0.28.0 succeeds

### Feature requests: what underlying problem are you trying to solve with this feature?

> Replace this line with your answer.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

Clone https://github.com/googleapis/google-cloud-cpp @ 5ad364581ed52ce457a2f79449964063e96242c6

Run `~/Downloads/bazel-0.29.0rc4-darwin-x86_64 build //google/cloud/bigtable:bigtable_client  --incompatible_depset_is_not_iterable=false`

### What operating system are you running Bazel on?

OSX

### What's the output of `bazel info release`?

release 0.29.0rc4

### If `bazel info release` returns ""development version"" or ""(@non-git)"", tell us how you built Bazel.

> Replace this line with your answer.

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

https://github.com/googleapis/google-cloud-cpp.git
5ad364581ed52ce457a2f79449964063e96242c6
5ad364581ed52ce457a2f79449964063e96242c6

###  Have you found anything relevant by searching the web?

### Any other information, logs, or outputs that you want to share?
",Which one do you prefer?,Would we have to bump the grpc version in google-cloud-cpp?
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/9112,"### Description of the problem / feature request:

Tab completions with empty results still return a null element, preventing fall-through to other bash completion mechanisms.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

In your bash shell, `complete -o nospace -o default -F _bazel__complete`.

Now try to open a local file using tab completion.

    touch test
    vi tes<TAB>

Completion will not work.

### What operating system are you running Bazel on?

Linux.

### What's the output of `bazel info release`?

release 0.28.1

### Any other information, logs, or outputs that you want to share?

See #9111 for further treatment and a fix.","How to repro though? I built `//scripts:bash_completion`, sourced the result, but `complete -o nospace -o default -F _bazel__complete` fails: `complete` requires one more argument, the name of the command it activates on (e.g. `bazel`).",@laszlocsomor I didn't have this issue. I could set a `complete` default by omitting the last argument. Maybe it's different on your system?
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/9007,"if I clone bazel at HEAD and try to ""bazel sync"" I get a failure, looks like:

```
ERROR: An error occurred during the fetch of repository 'rbe_ubuntu1604_java8':
   Traceback (most recent call last):
File ""[redacted]/rbe_repo.bzl"", line 449
    validate_host(ctx)
File ""[redacted]/external/bazel_toolchains/rules/rbe_repo/util.bzl"", line 152, in validate_host
    fail(""Cannot run rbe_autoconfig as 'd..."")
Cannot run rbe_autoconfig as 'docker' was not found on the path and environment variable DOCKER_PATH was not set. rbe_autoconfig attempts to pull a docker container if a toolchain config was not found for the version of Bazel (selected via attr or implicitly identified). If you do not want rbe_autoconfig to ever attempt to pull a docker container, please use attr 'use_checked_in_confs = ""Force""'.
```

I believe this is a recent regression, though it doesn't look like we updated the bazel->bazel_toolchains dependency *that* recently. Any ideas what's going on here?",Do you have `docker` on your path? When was the last time `bazel sync` worked for you?,"I do not have docker on my path (and I'm not sure I ever did).

I thought it worked last week, but I still have this breakage when I reset back to the beginning of last week.

I arbitrarily reset to 5d72d4ea54fdcb6e963cacb7181fda847e01bc50 (commit from late June) and retried, and ran into no issues.

Do we require that users download docker to contribute to bazel?

"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8974,"It seems like currently if bazel fails to download something from the WORKSPACE that has multiple URLs defined, it doesn't always fallback to the other URL. For example I hit this error:

```
Starting local Bazel server and connecting to it...
 - /root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl:93:5
 - /root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl:261:13
 - /tmp/share/code/WORKSPACE:83:1
ERROR: An error occurred during the fetch of repository 'go_sdk':
   Traceback (most recent call last):
	File ""/root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl"", line 78
		_remote_sdk(ctx, [url.format(filename) for url...], <2 more arguments>)
	File ""/root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl"", line 149, in _remote_sdk
		ctx.download(url = urls, sha256 = sha256, output ..."")
java.io.IOException: Error downloading [https://dl.google.com/go/go1.12.7.linux-amd64.tar.gz] to /root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/go_sdk/go_sdk.tar.gz: Read timed out
ERROR: While resolving toolchains for target @com_github_bazelbuild_buildtools//buildifier:buildifier: invalid registered toolchain '@go_sdk//:go_android_amd64': no such package '@go_sdk//': Traceback (most recent call last):
	File ""/root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl"", line 78
		_remote_sdk(ctx, [url.format(filename) for url...], <2 more arguments>)
	File ""/root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl"", line 149, in _remote_sdk
		ctx.download(url = urls, sha256 = sha256, output ..."")
java.io.IOException: Error downloading [https://dl.google.com/go/go1.12.7.linux-amd64.tar.gz] to /root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/go_sdk/go_sdk.tar.gz: Read timed out
ERROR: Analysis of target '//:buildifier.check' failed; build aborted: invalid registered toolchain '@go_sdk//:go_android_amd64': no such package '@go_sdk//': Traceback (most recent call last):
	File ""/root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl"", line 78
		_remote_sdk(ctx, [url.format(filename) for url...], <2 more arguments>)
	File ""/root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/io_bazel_rules_go/go/private/sdk.bzl"", line 149, in _remote_sdk
		ctx.download(url = urls, sha256 = sha256, output ..."")
java.io.IOException: Error downloading [https://dl.google.com/go/go1.12.7.linux-amd64.tar.gz] to /root/.cache/bazel/_bazel_root/c99f8fb4c845b3aae6d69f1a3c75aa35/external/go_sdk/go_sdk.tar.gz: Read timed out
ERROR: Build failed. Not running target
```

When my WORKSPACE contained:

```
http_archive(
    name = ""io_bazel_rules_go"",
    sha256 = ""8df59f11fb697743cbb3f26cfb8750395f30471e9eabde0d174c3aebc7a1cd39"",
    urls = [
        ""https://storage.googleapis.com/bazel-mirror/github.com/bazelbuild/rules_go/releases/download/0.19.1/rules_go-0.19.1.tar.gz"",
        ""https://github.com/bazelbuild/rules_go/releases/download/0.19.1/rules_go-0.19.1.tar.gz"",
    ],
)
```

I would have expected this to fallback to the GitHub URL before failing.

### What's the output of `bazel info release`?

release 0.28.0","Would it be ok to open a separate issue to outline the `HttpUrlConnection` → `Netty` migration details and track its progress?

---

Can you please consider #9015 and #9008 in the mean time as they significantly improve resiliency of repository downloads? 😊 ",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8906,"> ATTENTION! Please read and follow:
> - if this is a _question_ about how to build / test / query / deploy using Bazel, ask it on StackOverflow instead: https://stackoverflow.com/questions/tagged/bazel
> - if this is a _discussion starter_, send it to bazel-discuss@googlegroups.com
> - if this is a _bug_ or _feature request_, fill the form below as best as you can.

### Description of the problem / feature request:

I can't upgrade to 0.24.1

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

```sudo apt-get install --only-upgrade bazel```

### What operating system are you running Bazel on?

ubuntu 18.04

### What's the output of `bazel info release`?

release 0.18.1

###  Have you found anything relevant by searching the web?

https://docs.bazel.build/versions/master/install-ubuntu.html
https://github.com/bazelbuild/bazel/issues/5714

### Any other information, logs, or outputs that you want to share?

It seems that I have bazel 0.18.1 installed on my gpu but when I try to upgrade it, 
```Skipping bazel, it is not installed and only upgrades are requested.```
message pops up. 

Will appreciate any help, thanks.

",What are your repositories for `apt-get`? Be aware that Bazel is not in Debian nor in Ubuntu.,Looks like Bazel is not included in the repository as you mentioned. Should I do apt-add?
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8804,"### Description of the problem / feature request:

There is a bug when adding a `defines` attribute to a `cc_library` or `cc_binary`. It does not add the define at compile time in some instances.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

On windows, create an empty WORKSPACE file, a BUILD file with this content:

```
cc_library(
    name = 'foo',     
    srcs=['main.cpp'],
    defines=['SECRETSAUCE']
)
```
and a main.cpp file with this content: `int main() { return 0; }`

finally create a CROSSTOOL file.

Build like so: `bazel build :foo -s +crosstool params`

Output doesn't include `/DSECRETSAUCE`:

```
C:/Program Files (x86)/Microsoft Visual Studio/2017/BuildTools/VC/Tools/MSVC/14.12.25827/bin/Hostx64/x64/cl.exe /c main.cpp /Fobazel-out/x64_windows-fastbuild/bin/_objs/foo/main.o /nologo /I. /Ibazel-out/x64_windows-fastbuild/bin /showIncludes /MT /WX /EHsc /DNOMINMAX /D_ENABLE_ATOMIC_ALIGNMENT_FIX /Od
```

Running this without a CROSSTOOL file works as expected.

### What operating system are you running Bazel on?

Win10

### What's the output of `bazel info release`?

release 0.27.1

###  Have you found anything relevant by searching the web?

No
",Do you define the [preprocessor_defines](https://source.bazel.build/bazel/+/master:tools/cpp/windows_cc_toolchain_config.bzl;l=641) feature in your cc_toolchain_config rule? ,"I have this in the toolchain (I think it was generated automatically from the migration scripts going from old CROSSTOOL files):

```
preprocessor_defines_feature = feature(                                                                                                                                         
        name = ""preprocessor_defines"",                                                                                                                                              
        flag_sets = [                                                                                                                                                               
            flag_set(                                                                                                                                                               
                actions = [                                                                                                                                                         
                    ACTION_NAMES.preprocess_assemble,                                                                                                                               
                    ACTION_NAMES.c_compile,                                                                                                                                         
                    ACTION_NAMES.cpp_compile,                                                                                                                                       
                    ACTION_NAMES.cpp_header_parsing,                                                                                                                                
                    ""c++-header-preprocessing"",                                                                                                                                     
                    ACTION_NAMES.cpp_module_compile,                                                                                                                                
                ],                                                                                                                                                                  
                flag_groups = [                                                                                                                                                     
                    flag_group(                                                                                                                                                     
                        flags = [""/D%{preprocessor_defines}""],                                                                                                                      
                        iterate_over = ""preprocessor_defines"",                                                                                                                      
                    ),                                                                                                                                                              
                ],                                                                                                                                                                  
            ),                                                                                                                                                                      
        ],                                                                                                                                                                          
    )
```

I would still like to be able to add a define for a specific target in a BUILD file though"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8707,"```
cc_binary(
  name = ""foo.dll"",
  srcs = [""foo.cc""],
)
```
In a normal case, building `//foo.dll` will only generate one output artifact `foo.dll` in the default output group.

When the cc_binary depends on an dll, for example:
```
cc_import(
  name = ""bar"",
  shared_library = ""bar.dll"",
  interface_library = ""bar.lib"",
)

cc_binary(
  name = ""foo.dll"",
  srcs = [""foo.cc""],
  deps = [""//:bar""],
)
```
In this case, Bazel uses `bar.lib` at `foo.dll`'s linking time and copies `bar.dll` to the directory of `foo.dll` in order to make it available at runtime. But, Bazel also adds `bar.dll` to the default output group of `foo.dll`, which is problematic because when users try to reference `foo.dll` via `//bar:foo.dll`, it actually have more than one output artifact. This could be very confusing and there is no good way to distinguish the main output (`foo.dll`) from its dll dependencies (`bar.dll`).

One way to solve this is to add all DLL dependencies to a separate output group (eg. `runtime_dynamic_libraries`) and make sure the default output group of a cc_binary will always have a single artifact.
",What release do you expect this fix will make it into?,This will be in next month's release (0.28.0) ;)
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8673,"
### Description of the problem / feature request:

When BES is used in conjunction with remote-execution, output artifacts tagged `no-remote` and `no-cache` are uploaded to the CAS. When these outputs are large in size, this can result in significant performance penalties.

More concretely, we have seen significant performance penalities when BES is used in conjunction with RE, but *not* when each was used in isolation.

It would be beneficial to introduce a bazel command line flag which would disable BES artifact upload for output artifacts corresponding to targets that are marked `no-remote` and `no-cache`. The paths for output files corresponding to these targets should be local (or none at all) and not bytestream:/// pathnames.

### What operating system are you running Bazel on?

macOS 10.14.x

### What's the output of `bazel info release`?

release 0.25.3

###  Have you found anything relevant by searching the web?

https://github.com/bazelbuild/bazel/issues/8249 refers to how file URIs are automatically translated to bytestream:/// paths in remote execution/remote cache contexts
",What rules were you using for those tagged targets?,"> Interesting. Are you suggesting that we should not reference these files at all then in the BEP?

I think so. We should not reference them with bytesream paths if that results them being uploaded to the CAS."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8636,"When playing around with remote execution platform selection, I'm hitting toolchain resolution error with bazel 0.26.1

In .bazelrc, I'm setting:
build:remote --incompatible_enable_cc_toolchain_resolution
build:remote --extra_toolchains=@rbe_default//config:cc-toolchain
build:remote --extra_execution_platforms=//:plain_platform,@rbe_default//config:platform
build:remote --host_platform=//:plain_platform
build:remote --platforms=@rbe_default//config:platform

Where :plain_platform does not implement the appropriate constraint_values to satisfy the cc_toolchain and it also uses a docker image that does not contain clang.

platform(
    name = ""plain_platform"",
    remote_execution_properties = """"""
        properties: {
          name: ""container-image""
          value:""docker://gcr.io/gcp-runtimes/ubuntu_16_0_4@sha256:096632d8fb3e78fbd58ae6a2b25ed46020dc70e65d89bca774af6f7b2de6898c""
        }
        properties {
           name: ""OSFamily""
           value:  ""Linux""
        }
        """""",
)

My BUILD file defines a cc_library and a genrule which uses that cc_library as a tool.

cc_library(
    name = ""hello-world-lib"",
    srcs = [""hello-world-lib.cc""],
    hdrs = [""hello-world-lib.h""],
)

genrule(
    name = ""echo"",
    outs = [""echo.txt""],
    cmd = ""echo $(locations :hello-world-lib) > $@"",
    tools = [
        "":hello-world-lib"",
    ],
)

Building :hello-world-lib correctly chooses the platform @rbe_default//config:platform, and just works.
However, building :echo fails with the following errors:

$ bazel build --config=remote --noremote_accept_cached  :echo 
...
ERROR: While resolving toolchains for target //:hello-world-lib: no matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type
ERROR: Analysis of target '//:echo' failed; build aborted: no matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type
...

I don't think :echo should need a cc toolchain. I believe it should be able to choose //:plain_platform. But if I'm wrong and it does need a cc toolchain, it should be able to choose @rbe_default//config:platform as well. Instead it does neither and just fails.

Note that the error does not reproduce if --host_platform=@rbe_default//config:platform.
It also does not reproduce if :echo does not use the cc_library as a tool.
","Can you create a plain git repository with this example that I can clone and test? I'd like to be verifying as close as possible to what you are using.

The cc toolchain dependency was removed from genrule a few releases ago, and shouldn't still exist, so that's confusing.

I'll investigate this as I can.","Just to be clear, I intentionally set up //:plain_platform to *not* support the cc_toolchain by not having clang in its docker image and by not specifying the constraint_values. I also intentionally put it first in the order of platforms to be considered. This was by design, in order to get different targets to use different platforms. I realize that if I give @rbe_default//config:platform a higher priority the bug does not reproduce.

What I expected to happen was that bazel would select @rbe_default//config:platform for the cc_library target and //:plain_platform for the genrule target. I'm still not clear why //:plain_platform could not be used for the genrule target. In other words, why does the genrule target require a cc_toolchain?

And a secondary question is this: if bazel *does* have a valid reason to decide that the genrule target needs the platform to be compatible with the cc_toolchain (presumably due to its tools dependency), the fact that //:plain_platform does not have the appropriate constraint_values, should have ruled out that platform and as a result bazel *should* have used @rbe_default//config:platform instead. But that did not happen.
"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8608,"When bazel (0.26.1) chooses what remote execution platform to use (and as a consequence what toolchains to use) for a particular target, it seems to follow the following order of precedence:
* --extra_execution_platforms (in the order specified in .bazelrc)
* --extra_execution_platforms (in the order specified in the bazel command line flag)
* register_execution_platforms (in the order specified in WORKSPACE)
* --host_platform

However, if said target does not define a toolchain type (I saw this for genrule), then the platform specified in --host_platform is used first, and the order of precedence is:
* --host_platform
* --extra_execution_platforms (in the order specified in .bazelrc)
* --extra_execution_platforms (in the order specified in the bazel command line flag)
* register_execution_platforms (in the order specified in WORKSPACE)

This behaviour is inconsistent. The first ordering seems to be the one we want.
","Wouldn't one want to always want for the command line flag to override everything else, including .bazelrc?",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8517,"On Bazel@HEAD (b2fac7457a673a13427861aabb323a32b74e07ce) I'm seeing false positive reported on Gerrit Code Review repository (stable-2.14 branch):

```
$ b10 build --incompatible_disallow_empty_glob=true plugins/replication
INFO: Invocation ID: 72331e2c-6ce4-4253-9f8b-78ce226e0e77
DEBUG: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/bazel_toolchains/rules/version_check.bzl:45:9: 
Current running Bazel is not a release version and one was not defined explicitly in rbe_autoconfig target. Falling back to '0.25.2'
DEBUG: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/bazel_toolchains/rules/version_check.bzl:45:9: 
Current running Bazel is not a release version and one was not defined explicitly in rbe_autoconfig target. Falling back to '0.25.2'
DEBUG: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/bazel_skylib/lib/versions.bzl:96:13: Current Bazel is not a release version; cannot check for compatibility. Make sure that you are running at least Bazel 0.25.0.
ERROR: /home/davido/projects/gerrit2/plugins/replication/BUILD:6:12: Traceback (most recent call last):
	File ""/home/davido/projects/gerrit2/plugins/replication/BUILD"", line 4
		gerrit_plugin(name = ""replication"", srcs = glob(...""]), <3 more arguments>)
	File ""/home/davido/projects/gerrit2/plugins/replication/BUILD"", line 6, in gerrit_plugin
		glob([""src/main/java/**/*.java""])
all files in the glob have been excluded, but allow_empty is set to False.
ERROR: /home/davido/projects/gerrit2/plugins/replication/BUILD:23:12: Traceback (most recent call last):
	File ""/home/davido/projects/gerrit2/plugins/replication/BUILD"", line 21
		junit_tests(name = ""replication_tests"", srcs =...""]), <3 more arguments>)
	File ""/home/davido/projects/gerrit2/plugins/replication/BUILD"", line 23, in junit_tests
		glob([""src/test/java/**/*Test.java""])
all files in the glob have been excluded, but allow_empty is set to False.
ERROR: /home/davido/projects/gerrit2/plugins/replication/BUILD:37:12: Traceback (most recent call last):
	File ""/home/davido/projects/gerrit2/plugins/replication/BUILD"", line 34
		java_library(name = ""replication_util"", testonl..., <2 more arguments>)
	File ""/home/davido/projects/gerrit2/plugins/replication/BUILD"", line 37, in java_library
		glob([""src/test/java/**/*.java""], exclu...""])
all files in the glob have been excluded, but allow_empty is set to False.
ERROR: Skipping 'plugins/replication': no such target '//plugins/replication:replication': target 'replication' not declared in package 'plugins/replication' defined by /home/davido/projects/gerrit2/plugins/replication/BUILD
WARNING: Target pattern parsing failed.
ERROR: no such target '//plugins/replication:replication': target 'replication' not declared in package 'plugins/replication' defined by /home/davido/projects/gerrit2/plugins/replication/BUILD
INFO: Elapsed time: 0.083s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```

This flag is tracked [here](https://github.com/bazelbuild/bazel/issues/8195).","Can you do `print(glob([""src/main/java/**/*.java""]))` and confirm it contains files (with `--incompatible_disallow_empty_glob=false`)?","I added `print` statement, but I cannot reproduce it any more, as I see reports in Bazel itself:

```
$ b10 build --incompatible_disallow_empty_glob=true plugins/replication
Starting local Bazel server and connecting to it...
INFO: Invocation ID: 5c02393d-07ee-4019-958e-d37907bd2ac5
DEBUG: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/bazel_toolchains/rules/version_check.bzl:45:9: 
Current running Bazel is not a release version and one was not defined explicitly in rbe_autoconfig target. Falling back to '0.25.2'
DEBUG: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/bazel_toolchains/rules/version_check.bzl:45:9: 
Current running Bazel is not a release version and one was not defined explicitly in rbe_autoconfig target. Falling back to '0.25.2'
DEBUG: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/bazel_skylib/lib/versions.bzl:96:13: Current Bazel is not a release version; cannot check for compatibility. Make sure that you are running at least Bazel 0.25.0.
DEBUG: /home/davido/projects/gerrit2/plugins/replication/BUILD:6:12: [""src/main/java/com/googlesource/gerrit/plugins/replication/AutoReloadConfigDecorator.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/AutoReloadSecureCredentialsFactoryDecorator.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/CredentialsFactory.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/Destination.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/DestinationConfiguration.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/DestinationFactory.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/Init.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ListCommand.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/OnStartStop.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/PushAll.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/PushOne.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/PushResultProcessing.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/RefReplicatedEvent.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/RefReplicationDoneEvent.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/RemoteSiteUser.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationConfig.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationFileBasedConfig.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationFilter.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationLogFile.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationMetrics.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationModule.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationQueue.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationScheduledEvent.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationSshSessionFactoryProvider.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationState.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationStateListener.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/ReplicationStateLogger.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/SecureCredentialsFactory.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/SecureCredentialsProvider.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/SshModule.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/StartCommand.java"", ""src/main/java/com/googlesource/gerrit/plugins/replication/StartReplicationCapability.java""]
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:100:12: Traceback (most recent call last):
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 97
		filegroup(name = ""extdir"", deprecation = DEP..., ...""]))
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 100, in filegroup
		glob([""jre/lib/ext/*.jar""])
glob pattern 'jre/lib/ext/*.jar' didn't match anything, but allow_empty is set to False.
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:106:12: Traceback (most recent call last):
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 103
		filegroup(name = ""extclasspath"", deprecation..., ...""]))
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 106, in filegroup
		glob([""jre/lib/ext/*.jar""])
glob pattern 'jre/lib/ext/*.jar' didn't match anything, but allow_empty is set to False.
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:115:21: Traceback (most recent call last):
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 109
		filegroup(name = ""jre-bin"", srcs = select({""...""])}), ...)
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 111, in filegroup
		select({"":windows"": glob([""jre/bin/**""]...""])})
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 115, in select
		glob([""jre/bin/**""], exclude = [""jre/bi...""])
glob pattern 'jre/bin/**' didn't match anything, but allow_empty is set to False.
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:123:12: Traceback (most recent call last):
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 121
		filegroup(name = ""jre-lib"", srcs = glob([""jr...""]))
	File ""/home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel"", line 123, in filegroup
		glob([""jre/lib/**""])
glob pattern 'jre/lib/**' didn't match anything, but allow_empty is set to False.
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:131:1: Target '@remotejdk11_linux//:jre-bin' contains an error and its package is in error and referenced by '@remotejdk11_linux//:jre-default'
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:131:1: Target '@remotejdk11_linux//:jre-lib' contains an error and its package is in error and referenced by '@remotejdk11_linux//:jre-default'
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:166:1: Target '@remotejdk11_linux//:jdk-bin' contains an error and its package is in error and referenced by '@remotejdk11_linux//:jdk'
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:166:1: Target '@remotejdk11_linux//:jdk-include' contains an error and its package is in error and referenced by '@remotejdk11_linux//:jdk'
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:166:1: Target '@remotejdk11_linux//:jdk-lib' contains an error and its package is in error and referenced by '@remotejdk11_linux//:jdk'
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/remotejdk11_linux/BUILD.bazel:166:1: Target '@remotejdk11_linux//:jre-default' contains an error and its package is in error and referenced by '@remotejdk11_linux//:jdk'
ERROR: /home/davido/.cache/bazel/_bazel_davido/5c01f4f713b675540b8b424c5c647f63/external/bazel_tools/tools/jdk/BUILD:492:1: Target '@remotejdk11_linux//:jdk' contains an error and its package is in error and referenced by '@bazel_tools//tools/jdk:remote_jdk11'
ERROR: Analysis of target '//plugins/replication:replication' failed; build aborted: Analysis failed
INFO: Elapsed time: 55.523s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (76 packages loaded, 1627 targets configured)
    Fetching @user; fetching 46s
    Fetching @dev; fetching 46s
    Fetching @lucene-core; fetching 39s
    Fetching @jgit-lib; fetching 22s
    Fetching @guava; fetching 20s
    Fetching @soy; fetching 9s
    Fetching @grappa; fetching
```"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8479,"### Description of the problem / feature request:

If I build `bazel` from HEAD (57363813d3c72129c61c35a2b03c3033b62cb49d), then that version of bazel cannot compile bazel on OS X.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

See https://github.com/bazelbuild/bazel/issues/7397 for more info -- about once daily I pull and build bazel, then try to build bazel again with the built binary before I upgrade my local install.

Key difference in my setup from Bazel CI for OS X I only have the command-line tools installed, and not the XCode IDE:

> [..] On our CI we use mac workers that have xcode installed (so we can also test objc stuff). It seems that you only have CLT installed [...]

https://github.com/bazelbuild/bazel/issues/7397#issuecomment-463107338

### What operating system are you running Bazel on?

macOS 10.14.5

### If `bazel info release` returns ""development version"" or ""(@non-git)"", tell us how you built Bazel.

    git pull && bazel build //src:bazel && cp -f $(bazel info bazel-bin)/src/bazel ~/bin/bazel-head && bazel-head build //src:bazel && cp -f ~/bin/bazel-head ~/bin/bazel

I have `bazel-0.25.2` in /usr/local/bin/bazel, and latest bazel that worked from head in `~/bin/bazel` (~last Friday HEAD). I have tried the above command with both.

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

```
git@github.com:bazelbuild/bazel.git
57363813d3c72129c61c35a2b03c3033b62cb49d
57363813d3c72129c61c35a2b03c3033b62cb49d
```

###  Have you found anything relevant by searching the web?

Just my series of issues finding problems in Bazel with my common setup that is not tested in your CI :)

* https://github.com/bazelbuild/bazel/issues/7397
* https://github.com/bazelbuild/bazel/issues/7575

If you make `XCode` an official requirement for developing on Mac, I'll happily install it. I figured for now I'm a useful canary?",Can you post the specific log for this failure? (I'm assuming it's not exactly the same as last time?),"Thanks @keith -- sorry, was too busy making sure I filled all the fields in and starting `git bisect` to .. fill all the fields in.

```
ERROR: /private/var/tmp/_bazel_dhalperin/84f5772a14c30e3cb841f904746049ac/external/bazel_tools/src/main/cpp/util/BUILD:174:1: Target '@bazel_tools//src/main/cpp/util:blaze_exit_code' depends on toolchain '@local_config_cc//:cc-compiler-darwin_x86_64', which cannot be found: no such target '@local_config_cc//:cc-compiler-darwin_x86_64': target 'cc-compiler-darwin_x86_64' not declared in package '' defined by /private/var/tmp/_bazel_dhalperin/84f5772a14c30e3cb841f904746049ac/external/local_config_cc/BUILD'
ERROR: /private/var/tmp/_bazel_dhalperin/84f5772a14c30e3cb841f904746049ac/external/bazel_tools/src/main/cpp/util/BUILD:36:1: Target '@bazel_tools//src/main/cpp/util:filesystem' depends on toolchain '@local_config_cc//:cc-compiler-darwin_x86_64', which cannot be found: no such target '@local_config_cc//:cc-compiler-darwin_x86_64': target 'cc-compiler-darwin_x86_64' not declared in package '' defined by /private/var/tmp/_bazel_dhalperin/84f5772a14c30e3cb841f904746049ac/external/local_config_cc/BUILD'
```"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8422,"### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

```bash
git clone https://github.com/bazelbuild/examples.git
cd cpp-tutorial/stage1
bazel build //...
```

Error:
```
Starting local Bazel server and connecting to it...
INFO: Analyzed target //main:hello-world (11 packages loaded, 122 targets configured).
INFO: Found 1 target...
ERROR: /Users/soonhok/work/examples/cpp-tutorial/stage1/main/BUILD:1:1: C++ compilation of rule '//main:hello-world' failed: I/O exception during sandboxed execution: Running '/var/tmp/_bazel_soonhok/install/1a037b6c0d8096293d1eecfde6528fbd/_embedded_binaries/xcode-locator 9.2.0.9C40b' failed.
Process terminated by signal 6
stdout:
stderr: 2019-05-21 14:03:01.688 xcode-locator[938:9684] Found bundle com.apple.dt.Xcode in file:///Applications/Xcode.app/; contents on disk: (
    ""file:///Applications/Xcode.app/Contents/""
)
2019-05-21 14:03:01.691 xcode-locator[938:9684] Version strings for file:///Applications/Xcode.app/: short=9.2, expanded=9.2.0
2019-05-21 14:03:01.691 xcode-locator[938:9684] -[__NSPlaceholderDictionary initWithContentsOfURL:error:]: unrecognized selector sent to instance 0x7fb1a3d01ee0
2019-05-21 14:03:01.692 xcode-locator[938:9684] *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[__NSPlaceholderDictionary initWithContentsOfURL:error:]: unrecognized selector sent to instance 0x7fb1a3d01ee0'
*** First throw call stack:
(
	0   CoreFoundation                      0x00007fffb2dd065b __exceptionPreprocess + 171
	1   libobjc.A.dylib                     0x00007fffc7c0f48d objc_exception_throw + 48
	2   CoreFoundation                      0x00007fffb2e522d4 -[NSObject(NSObject) doesNotRecognizeSelector:] + 132
	3   CoreFoundation                      0x00007fffb2d41cf5 ___forwarding___ + 1061
	4   CoreFoundation                      0x00007fffb2d41848 _CF_forwarding_prep_0 + 120
	5   xcode-locator                       0x0000000107b74c1c FindXcodes + 1692
	6   xcode-locator                       0x0000000107b73c01 main + 289
	7   libdyld.dylib                       0x00000001083d8235 start + 1
	8   ???                                 0x0000000000000002 0x0 + 2
)
libc++abi.dylib: terminating with uncaught exception of type NSException
Target //main:hello-world failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 17.985s, Critical Path: 0.12s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
```

### What operating system are you running Bazel on?

macOS 10.12.6 (16G2016)

### What's the output of `bazel info release`?

```
release 0.25.2
```

### Any other information, logs, or outputs that you want to share?

Xcode version: 9.2 (9C40b)
",Can you try with the current 0.26.0 RC build? Found here https://releases.bazel.build/0.26.0/rc12/index.html,"I've tried it but it didn't work:

Error message:
```
Starting local Bazel server and connecting to it...
INFO: Analyzed target //main:hello-world (11 packages loaded, 123 targets configured).
INFO: Found 1 target...
ERROR: /Users/soonhok/work/examples/cpp-tutorial/stage1/main/BUILD:1:1: C++ compilation of rule '//main:hello-world' failed: I/O exception during sandboxed execution: Running '/var/tmp/_bazel_soonhok/install/54a04d78acda2a8e5a7014da4e4d54ea/_embedded_binaries/xcode-locator 9.2.0.9C40b' failed.
Process terminated by signal 6
stdout:
stderr: 2019-05-21 14:53:15.131 xcode-locator[16168:46166] Found bundle com.apple.dt.Xcode in file:///Applications/Xcode.app/; contents on disk: (
    ""file:///Applications/Xcode.app/Contents/""
)
2019-05-21 14:53:15.133 xcode-locator[16168:46166] Version strings for file:///Applications/Xcode.app/: short=9.2, expanded=9.2.0
2019-05-21 14:53:15.134 xcode-locator[16168:46166] -[__NSPlaceholderDictionary initWithContentsOfURL:error:]: unrecognized selector sent to instance 0x7faae0c02200
2019-05-21 14:53:15.134 xcode-locator[16168:46166] *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[__NSPlaceholderDictionary initWithContentsOfURL:error:]: unrecognized selector sent to instance 0x7faae0c02200'
*** First throw call stack:
(
	0   CoreFoundation                      0x00007fffb2dd065b __exceptionPreprocess + 171
	1   libobjc.A.dylib                     0x00007fffc7c0f48d objc_exception_throw + 48
	2   CoreFoundation                      0x00007fffb2e522d4 -[NSObject(NSObject) doesNotRecognizeSelector:] + 132
	3   CoreFoundation                      0x00007fffb2d41cf5 ___forwarding___ + 1061
	4   CoreFoundation                      0x00007fffb2d41848 _CF_forwarding_prep_0 + 120
	5   xcode-locator                       0x0000000104e01c1c FindXcodes + 1692
	6   xcode-locator                       0x0000000104e00c01 main + 289
	7   libdyld.dylib                       0x0000000105663235 start + 1
)
libc++abi.dylib: terminating with uncaught exception of type NSException
Target //main:hello-world failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 7.473s, Critical Path: 0.08s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
```

Bazel version:
```
> bazel version

Build label: 0.26.0rc12
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue May 21 09:59:36 2019 (1558432776)
Build timestamp: 1558432776
Build timestamp as int: 1558432776
```"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8336,"### Description of the problem / feature request:

If the `zip` command from the following blurb fails for any reason, `outputs.zip` is not created and the user has no idea why.

https://github.com/bazelbuild/bazel/blob/c797411e53afd11b3aa6122de80f791ea75bb03c/tools/test/test-setup.sh#L355-L361

This can happen if --
* `zip` isn't installed on the test system;
* the version of `zip` is too old and chokes on `--` (stop laughing);
* any other error occurs.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

```console
$ touch WORKSPACE
$ cat > BUILD.bazel <<EOF
sh_test(name = ""foo_test"", srcs = [""foo_test.sh""])
EOF
$ cat > foo_test.sh <<""EOF""
#!/bin/bash
touch $TEST_UNDECLARED_OUTPUTS_DIR/foo
EOF
$ cat > zip <<EOF
#!/bin/bash
exit 1
EOF
$ chmod +x foo_test.sh zip
$ bazel test :foo_test --test_env=PATH=$PWD:/bin:/usr/bin
```
Observe that the test succeeds and `bazel-testlogs/foo_test/test.outputs_manifest` exists, but `.../test.outputs/outputs.zip` is missing.

### What operating system are you running Bazel on?

- CentOS 6.6
- Debian 7.1

### What's the output of `bazel info release`?

`release 0.24.1+vmware`

### If `bazel info release` returns ""development version"" or ""(@non-git)"", tell us how you built Bazel.

n/a

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

n/a

###  Have you found anything relevant by searching the web?

No.

### Any other information, logs, or outputs that you want to share?

No.
",How does that sound?,"> Currently I'm not planning to work on `test-setup.sh`, but I could quick-fix this (e.g. display warning message, ignore error). That'd let the test succeed -- failing to zip up the undeclared outputs is arguably a nuisance but no fatal flaw. How does that sound?

Sounds good to me. :)"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8324,"### Description of the problem / feature request:

The ""baseline_coverage.dat"" file created by ""bazel coverage"" does not appear to be a valid lcov coverage file. It contains only ""SF:"" tags, but at least ""DA:"" tags are also required.

### Feature requests: what underlying problem are you trying to solve with this feature?

I am trying to generate an html coverage report. Baseline files are required in order to ensure that files that have zero coverage (and therefore don't generate a gcda file) still show up in the report.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

#### First demonstrate that baseline_coverage.dat is broken:
```
$ cat mypackage/BUILD 
cc_library(
    name=""my_lib"",
    srcs=[""lib.c""],
    hdrs=[""lib.h""],
)

cc_test(
    name=""my_test"",
    srcs=[""test.c""],
    deps=["":my_lib""],
)

$ bazel coverage //mypackage:my_test
//mypackage:my_test                                                      PASSED in 0.5s

$ cat bazel-testlogs/mypackage/my_test/baseline_coverage.dat 
SF:mypackage/lib.c
end_of_record
SF:mypackage/lib.h
end_of_record

$ lcov --list bazel-testlogs/mypackage/my_test/baseline_coverage.dat 
Reading tracefile bazel-testlogs/mypackage/my_test/baseline_coverage.dat
lcov: ERROR: no valid records found in tracefile bazel-testlogs/mypackage/my_test/baseline_coverage.dat

$ genhtml bazel-testlogs/mypackage/my_test/baseline_coverage.dat 
Reading data file bazel-testlogs/mypackage/my_test/baseline_coverage.dat
Resolved relative source file path ""mypackage/lib.c"" with CWD to ""/src/apollo/mypackage/lib.c"".
genhtml: ERROR: no valid records found in tracefile bazel-testlogs/mypackage/my_test/baseline_coverage.dat
```

#### Now show what a working baseline file should look like:
```
$ lcov --capture --initial --directory bazel-bin/mypackage/ --output-file baseline_working.dat
Capturing coverage data from bazel-bin/mypackage/
Found gcov version: 4.8.4
Scanning bazel-bin/mypackage/ for .gcno files ...
Found 2 graph files in bazel-bin/mypackage/
Processing my_test/test.gcno
Processing my_lib/lib.gcno
Finished .info-file creation

$ cat baseline_working.dat 
TN:
SF:/src/workspace/mypackage/test.c
FN:3,main
FNDA:0,main
FNF:1
FNH:0
DA:3,0
DA:4,0
DA:5,0
DA:7,0
DA:9,0
LF:5
LH:0
end_of_record
TN:
SF:/src/workspace/mypackage/lib.c
FN:3,fib
FNDA:0,fib
FNF:1
FNH:0
DA:3,0
DA:4,0
DA:5,0
DA:6,0
DA:7,0
DA:9,0
DA:11,0
LF:7
LH:0
end_of_record

$ lcov --list baseline_working.dat 
Reading tracefile baseline_working.dat
            |Lines       |Functions  |Branches    
Filename    |Rate     Num|Rate    Num|Rate     Num
==================================================
[/src/workspace/mypackage/]
lib.c       | 0.0%      7| 0.0%     1|    -      0
test.c      | 0.0%      5| 0.0%     1|    -      0
==================================================
      Total:| 0.0%     12| 0.0%     2|    -      0

$ genhtml --output-directory coverage baseline_working.dat 
Reading data file baseline_working.dat
Found 2 entries.
Found common filename prefix ""/src/workspace""
Writing .css and .png files.
Generating output.
Processing file mypackage/lib.c
Processing file mypackage/test.c
Writing directory view page.
Overall coverage rate:
  lines......: 0.0% (0 of 12 lines)
  functions..: 0.0% (0 of 2 functions)
```
### What operating system are you running Bazel on?

Ubuntu 14.04

### What's the output of `bazel info release`?

release 0.25.0

### Any other information, logs, or outputs that you want to share?

I'm not totally clear on the purpose of the baseline_coverage.dat file if the current contents are expected to be correct. How should I use this file when generating a coverage report?","Can you describe why you're generating html report from baseline coverage and how does it fit into your computing coverage workflow? 

In theory the users shouldn't parse the baseline report themselves, but leave it up to bazel to deal with it in the final coverage report. I'll close this as a duplicate of #5716.","@iirina 

This issue should not be closed. The file format is invalid as a baseline file for any lcov tools that expect a baseline file that I know of. The main usage of baseline files is with the ""--baseline-file"" option to ""genhtml"". My example above was simplified, but you will see that even conventional baseline-file usage fails with the same error. For example, from above:

```
$ bazel coverage //mypackage:my_test
//mypackage:my_test                                                      PASSED in 0.5s

# Let's try to generate a real coverage report
$ genhtml --baseline-file bazel-testlogs/mypackage/my_test/baseline_coverage.dat bazel-testlogs/mypackage/my_test/coverage.dat

Reading data file bazel-testlogs/mypackage/my_test/coverage.dat
Reading baseline file bazel-testlogs/mypackage/my_test/baseline_coverage.dat
Reading data file bazel-testlogs/mypackage/my_test/baseline_coverage.dat
genhtml: ERROR: no valid records found in tracefile baseline_coverage.dat
```

The primary purpose of baseline files that I know of is to get a ""0 coverage"" report. If you have files that are not invoked by any test, then they won't show up in the coverage.dat file. When you generate an html report, these files won't even show up at all, and the reported coverage % will be artificially high. Including ""--baseline-file"" (or just passing baseline_coverage.dat as another coverage file) allows genhtml to include all files and produce the proper report. Not including a baseline is a particularly insidious mistake because it hides the thing that you often care about the most: ""which files are not covered at all""?

From the lcov man page:

> --initial
>               Capture initial zero coverage data.
> 
>               Run lcov with -c and this option on the directories containing .bb, .bbg or .gcno files before running any test case. The result is a ""baseline"" coverage data file that contains  zero  coverage  for  every
>               instrumented  line.   **Combine this data file (using lcov -a) with coverage data files captured after a test run to ensure that the percentage of total lines covered is correct even when not all source code
>               files were loaded during the test.**
> ```"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8288,"Bazel supports finding packages in multiple paths. 
https://docs.bazel.build/versions/master/user-manual.html#flag--package_path 
This is currently broken at HEAD.

Note that this is a different issue as b/132327507 which is already fixed by 9835cb4135503768cdf1161746b95d7969ccb938

Culprit: 9c5b310257ca5c85ae261a43187d0b949319a514

To reproduce with https://github.com/meteorcloudy/my_tests/tree/master/multiple_package_path_test

```
$ bazel-9c5b310257ca5c85ae261a43187d0b949319a514 build //... --package_path ../buildfiles
Starting local Bazel server and connecting to it...
INFO: Reading 'startup' options from c:\users\pcloudy\.bazelrc: --output_user_root=C:/src/tmp
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=320
INFO: Options provided by the client:
  'build' options: --python_path=C:/Python36/python.exe
INFO: Reading rc options for 'build' from c:\users\pcloudy\.bazelrc:
  'build' options: --curses=yes --color=yes --verbose_failures --announce_rc
Internal error thrown during build. Printing stack trace: java.lang.IllegalStateException: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2149)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2119)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getPlatformMappingValue(SkyframeExecutor.java:2071)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getConfigurations(SkyframeExecutor.java:1900)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.createConfigurations(SkyframeExecutor.java:1486)
        at com.google.devtools.build.lib.analysis.BuildView.update(BuildView.java:245)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.runAnalysisPhase(AnalysisPhaseRunner.java:198)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:110)
        at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:145)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:272)
        at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:97)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:498)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:206)
        at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:749)
        at com.google.devtools.build.lib.server.GrpcServerImpl.access$1600(GrpcServerImpl.java:103)
        at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:818)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:527)
        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:387)
        ... 3 more
Caused by: java.lang.NullPointerException
        at com.google.devtools.build.lib.skyframe.PlatformMappingFunction.compute(PlatformMappingFunction.java:64)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:450)
        ... 4 more

INFO: Elapsed time: 2.075s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (2 packages loaded)
Internal error thrown during build. Printing stack trace: java.lang.IllegalStateException: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2149)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2119)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getPlatformMappingValue(SkyframeExecutor.java:2071)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getConfigurations(SkyframeExecutor.java:1900)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.createConfigurations(SkyframeExecutor.java:1486)
        at com.google.devtools.build.lib.analysis.BuildView.update(BuildView.java:245)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.runAnalysisPhase(AnalysisPhaseRunner.java:198)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:110)
        at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:145)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:272)
        at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:97)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:498)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:206)
        at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:749)
        at com.google.devtools.build.lib.server.GrpcServerImpl.access$1600(GrpcServerImpl.java:103)
        at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:818)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:527)
        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:387)
        ... 3 more
Caused by: java.lang.NullPointerException
        at com.google.devtools.build.lib.skyframe.PlatformMappingFunction.compute(PlatformMappingFunction.java:64)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:450)
        ... 4 more
java.lang.IllegalStateException: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2149)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2119)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getPlatformMappingValue(SkyframeExecutor.java:2071)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getConfigurations(SkyframeExecutor.java:1900)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.createConfigurations(SkyframeExecutor.java:1486)
        at com.google.devtools.build.lib.analysis.BuildView.update(BuildView.java:245)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.runAnalysisPhase(AnalysisPhaseRunner.java:198)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:110)
        at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:145)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:272)
        at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:97)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:498)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:206)
        at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:749)
        at com.google.devtools.build.lib.server.GrpcServerImpl.access$1600(GrpcServerImpl.java:103)
        at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:818)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:527)
        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:387)
        ... 3 more
Caused by: java.lang.NullPointerException
        at com.google.devtools.build.lib.skyframe.PlatformMappingFunction.compute(PlatformMappingFunction.java:64)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:450)
        ... 4 more
java.lang.IllegalStateException: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2149)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.evaluateSkyKeys(SkyframeExecutor.java:2119)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getPlatformMappingValue(SkyframeExecutor.java:2071)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.getConfigurations(SkyframeExecutor.java:1900)
        at com.google.devtools.build.lib.skyframe.SkyframeExecutor.createConfigurations(SkyframeExecutor.java:1486)
        at com.google.devtools.build.lib.analysis.BuildView.update(BuildView.java:245)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.runAnalysisPhase(AnalysisPhaseRunner.java:198)
        at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:110)
        at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:145)
        at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:272)
        at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:97)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:498)
        at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:206)
        at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:749)
        at com.google.devtools.build.lib.server.GrpcServerImpl.access$1600(GrpcServerImpl.java:103)
        at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:818)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.RuntimeException: Unrecoverable error while evaluating node 'PlatformMappingValue.Key{path=platform_mappings, wasExplicitlySetByUser=false}' (requested by nodes )
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:527)
        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:387)
        ... 3 more
Caused by: java.lang.NullPointerException
        at com.google.devtools.build.lib.skyframe.PlatformMappingFunction.compute(PlatformMappingFunction.java:64)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:450)
FAILED: Build did NOT complete successfully (2 packages loaded)
```
","Should this flag be package-path aware, or should it just look at the first entry? Either should work.","No matter this is a bug or not, it is definitely an incompatible change, because the above example works with Bazel built before 9c5b310"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8231,"Example is here: https://github.com/excitoon/bazel-issues/tree/master/processbuilder-on-windows

On Windows, `ProcessBuilder` does not make a good job joining list of arguments into correct command line.
If one passes backslashes inside of an argument of `ctx.execute`, then these will be spoiled:

```
> bazel build @some_name//:some_file.txt
DEBUG: C:/users/chebotarev_v/documents/src/bazel-issues/processbuilder-on-windows/some_rule.bzl:7:3: \\two\\two\\\thr
ee\\\\four\one
DEBUG: C:/users/chebotarev_v/documents/src/bazel-issues/processbuilder-on-windows/some_rule.bzl:13:3: \\\two\\\two\\\
\\three\\\\\\\four\one
```

Real command line (from Task Manager):

```
""python3"" test.py \\\two\\\two\\\\\three\\\\\\\four\one
```

Look how two backslashes convert to three, three to five, four to seven, by `2*N-1` formula.

See also: https://stackoverflow.com/questions/34402429/processbuilder-does-something-to-my-command-line-arguments-on-windows .

","Does it repro with Bazel 0.25.0, or with 0.24.0 and the `--incompatible_windows_escape_jvm_flags` *startup* flag? (i.e. it goes between `bazel` and `build`)","Yeah, that was #7454 ."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/8052,"### Description of the problem / feature request:

Using bazel 0.25.0rc2 with the new remote + disk cache feature https://github.com/bazelbuild/bazel/pull/7512 the cache requests to the remote server are prefixed with `ac_` when they should be the sha of the object being requested.

If the remote cache you're using validates this, it can result in a cache miss when it shouldn't.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

```
bazel build some-target --remote_http_cache=http://some.remote.cache --disk_cache=/some/disk/cache
```

Where the remote cache is https://github.com/buchgr/bazel-remote

In this case you get many warnings:

```
WARNING: Reading from Remote Cache:
400 Bad Request
Resource name must be a SHA256 hash in hex. Got '/cas/ac_2d1692c6da631a61480bd32a3d8ab8234bf9e5dcd3c3cfa78d388578e2a8b3cf'.
```

Since the cache is validating the format of the keys.

### What operating system are you running Bazel on?

macOS

### What's the output of `bazel info release`?

release 0.25.0rc2

###  Have you found anything relevant by searching the web?

The warning is coming from this logic: https://github.com/buchgr/bazel-remote/blob/8811a77bfd9f8a35e4c23e758c9c585edb76283d/server/http.go#L62-L67",What do you think of that approach?,@buchgr any thoughts here? It would be nice if we could get a fix in for 0.26.0 if possible
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7880,"### Description of the problem / feature request:

I always get confused that build errors seem to immediately kill other actions immediately, but Ctrl+C does not seem to do this (they all build to completion).

### Feature requests: what underlying problem are you trying to solve with this feature?

Is it possible to have Ctrl+C kill the other actions (safely) more quickly, without having to murder the server?

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

We have a large C++ project [[link](https://drake.mit.edu/)], with some build targets that (regrettably) take >45s to finish building.

If there's a build error, it appears that other actions are immediately terminated.

However, if I try to Ctrl+C the build process, it waits until the other objects have been completed (which could be a waste if I have to change upstream components). I'd prefer not to Ctrl+C 3 times, as it takes time for the server to spin up.

If it's useful, I can see if I can create a minimal reproduction; I'd probably first try to make some `genrule`s that artificially pause. 

### What operating system are you running Bazel on?

Ubuntu 18.04

### What's the output of `bazel info release`?

```
release 0.23.1
```

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

```
https://github.com/RobotLocomotion/drake.git  # Upstream, rather
63e8bf5d046841d5f8aad0f6b079f2c43f1fe712
63e8bf5d046841d5f8aad0f6b079f2c43f1fe712
```

###  Have you found anything relevant by searching the web?

Only #614. However, it's unclear if this feature request falls immediately under that purview; I'm only using local workers.

In this issue, it mentions that the workers should quit gracefully to prevent artifact corruption, which makes sense. However, it's odd that build errors seem to take an alternate mode of invalidation that permits earlier exit on the build actions?

### Any other information, logs, or outputs that you want to share?

Nah, not at the moment.","Which ones? If you do, #614 is indeed relevant because, when you hit Ctrl+C, Bazel is currently unable to tell those workers to stop what they are doing.",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7721,"### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

When using this build file:
```python
cc_library(
    name = ""a"",
    srcs = [""NONEXISTANT.c""],
)

objc_library(
    name = ""b"",
    deps = [
        "":a"",
    ],
)

cc_test(
    name = ""d"",
    deps = ["":b""],
)
```

And running:
```
$ bazel build //:d
```

Bazel will NPE with the following stack trace:
```
Internal error thrown during build. Printing stack trace: java.lang.RuntimeException: Unrecoverable error while evaluating node '//:d BuildConfigurationValue.Key[8ba79ecc9568c596b3045ac063bab52f] false' (requested by nodes )
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:877)
	at com.google.devtools.build.lib.vfs.PathFragment.startsWith(PathFragment.java:295)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:245)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
	at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:880)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:735)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:451)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:355)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:791)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:446)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:36)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:25)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:324)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:204)
	at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:764)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:797)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:338)
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:438)
	... 7 more

INFO: Elapsed time: 0.172s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded, 3 targets configured)
Internal error thrown during build. Printing stack trace: java.lang.RuntimeException: Unrecoverable error while evaluating node '//:d BuildConfigurationValue.Key[8ba79ecc9568c596b3045ac063bab52f] false' (requested by nodes )
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:877)
	at com.google.devtools.build.lib.vfs.PathFragment.startsWith(PathFragment.java:295)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:245)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
	at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:880)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:735)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:451)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:355)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:791)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:446)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:36)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:25)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:324)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:204)
	at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:764)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:797)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:338)
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:438)
	... 7 more
java.lang.RuntimeException: Unrecoverable error while evaluating node '//:d BuildConfigurationValue.Key[8ba79ecc9568c596b3045ac063bab52f] false' (requested by nodes )
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:877)
	at com.google.devtools.build.lib.vfs.PathFragment.startsWith(PathFragment.java:295)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:245)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
	at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:880)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:735)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:451)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:355)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:791)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:446)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:36)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:25)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:324)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:204)
	at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:764)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:797)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:338)
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:438)
	... 7 more
java.lang.RuntimeException: Unrecoverable error while evaluating node '//:d BuildConfigurationValue.Key[8ba79ecc9568c596b3045ac063bab52f] false' (requested by nodes )
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
Caused by: java.lang.NullPointerException
	at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:877)
	at com.google.devtools.build.lib.vfs.PathFragment.startsWith(PathFragment.java:295)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:245)
	at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
	at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:880)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:735)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:451)
	at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:355)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:791)
	at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:446)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:36)
	at com.google.devtools.build.lib.rules.cpp.CcTest.create(CcTest.java:25)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:324)
	at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:204)
	at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:764)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:797)
	at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:338)
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:438)
FAILED: Build did NOT complete successfully (1 packages loaded, 3 targets configured)
```

### What operating system are you running Bazel on?

macOS

### What's the output of `bazel info release`?

```
release 0.23.1
```",Can anyone check whether it's a recent regression? (try with 0.22),
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7720,"### Description of the problem / feature request:

launcher.cc gets called with wrong command line, using default windows path containing backslashes instead of slashes. as it is run in msys, the path gets shorten because the backslash is interpreted. Only happens on windows with msys2 command

also it runs the program as a command line, not calling the .exe and passing the rest as a argument

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

> LAUNCHER ERROR: Cannot launch process: ""python.exe"" 
> C:\users\XXX\_bazel_XXX\ge7islmr\execroot\bazel-
> out\host\bin\platform\bazel\tools\generator.zip bazel-out/x64_windows-fastbuild/generator.h 
> Reason: (error: 2): File not found.

when running the command seperately it the problem is visible:
> $ ""python.exe"" C:\users\XXX\_bazel_XXX\ge7islmr\execroot\bazel-out\host\bin\platform\bazel\tools\generator.zip bazel-out/x64_windows-fastbuild/generator.h

> C:\bazel\Python3\python.exe: can't open file 'C:usersXXX_bazel_XXXge7islmrexecrootbazel-outhostbinplatformbazeltoolsgenerator.zip': [Errno 2] No such file or directory

### Fix-Idea:
in launcher.cc file try to replace '\\' (github even did it so too, i needed double-backslashes to unescape) ) in Cmdline.cmdline with '/' before executing the command or somewhere on around it.

### What operating system are you running Bazel on?

Windows 7 x64 
Bazel 0.23.2 release
",How can we repro?,"i just found out you can bypass the problem by adding commandline to bazel:
>--python_path=""c:/bazel/Python3/python.exe""

so apparently the default (>where python) doesnt work"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7637,"When I cross compile the example using qnx ,  Bazel does not produce shared libraries. Instead, in the bazel-bin directory, there are only static libraries,(.a), not any dynamic libraries(.so). If I do not use cross compile , I can produce dynamic libraries.","Can you share the full Bazel command? A repro repo?
4) What does it mean to cross-compile in your case? Which C++ toolchain do you use? What is the value of `--crosstool_top` and `--cpu` and `--compiler` Bazel options?
5) If you use Bazel's autoconfigured C++ toolchain, what compilers do you have installed, what environment variables do you set? Do you set `CC`?","HI sorry to reply late, I run bazel on 
1.x86_64 platform, and the 
2.  version is 0.22.0. 
3. the example is at 
      ` https://github.com/bazelbuild/examples/tree/master/cpp-tutorial/stage3`
   and I follow the instruction at 
  `https://github.com/bazelbuild/bazel/wiki/Building-with-a-custom-toolchain/581fe11cea8396ce125c879db9160d8368a5957e`
      
4. the target cpu is aarch64,  and the system is qnx
5. I find the the solution: We need add ` linking_mode_flags { mode: DYNAMIC }` to the CROSSTOOL file

There is another  proble here, If I use  bazel version 0.5.3, I report some error in   CROSSTOOL file, for example:
` java.io.IOException: Could not read the crosstool configuration file 'CROSSTOOL file 
   /home/dabin/Documents/qnx-compiler/CROSSTOOL', because of an 
   incomplete protocol buffer (Message missing required fields: default_target_cpu).`

When I add default_target_cpu:""aarch64""

I report error 
`Could not read the crosstool configuration file 'CROSSTOOL file /home/dabin/qnx-compiler/CROSSTOOL', because of a parser error (9:3: Input contains unknown fields and/or extensions:
9:3:	com.google.devtools.build.lib.view.config.crosstool.CToolchain.default_target_cpu).`





"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7504,"> ATTENTION! Please read and follow:
> - if this is a _question_ about how to build / test / query / deploy using Bazel, ask it on StackOverflow instead: https://stackoverflow.com/questions/tagged/bazel
> - if this is a _discussion starter_, send it to bazel-discuss@googlegroups.com
> - if this is a _bug_ or _feature request_, fill the form below as best as you can.

### Description of the problem / feature request:

> I tried to build/compile tensorflow using the command ``$ bazel build -c opt contrib/model_pruning:strip_pruning_vars
``
> I get the following message:
> C:\Users\chhn\Desktop\Tensorflow\tensorflow>bazel build -c opt contrib/model_pruning:strip_pruning_vars

> Extracting Bazel installation...
> Starting local Bazel server and connecting to it...
> INFO: Invocation ID: ad8a559f-f40a-424c-8968-8c3616e76a03
> Internal error thrown during build. Printing stack trace: java.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorflow/python:gen_boosted_trees_ops_py_wrappers_cc BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true' (requested by nodes '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true', '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[a46389e7efd2cfd6bf7ec804c025d95e] false')
>         at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:514)
>         at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
>         at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.localPopAndExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
> Caused by: java.lang.IllegalStateException
>         at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addDynamicInputLinkOptions(LibrariesToLinkCollector.java:293)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:258)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
>         at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:826)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:716)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:441)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:357)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:720)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:416)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:242)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:75)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:323)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:207)
>         at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:758)
>         at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:780)
>         at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:326)
>         at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:437)
>         ... 6 more
> 
> INFO: Elapsed time: 189.324s
> INFO: 0 processes.
> FAILED: Build did NOT complete successfully (159 packages loaded, 7515 targets configured)
>     Fetching @swig; fetching 109s
>     Fetching @grpc; fetching 37s
>     Fetching @png_archive; fetching 12s
> Internal error thrown during build. Printing stack trace: java.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorflow/python:gen_boosted_trees_ops_py_wrappers_cc BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true' (requested by nodes '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true', '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[a46389e7efd2cfd6bf7ec804c025d95e] false')
>         at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:514)
>         at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
>         at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.localPopAndExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
> Caused by: java.lang.IllegalStateException
>         at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addDynamicInputLinkOptions(LibrariesToLinkCollector.java:293)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:258)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
>         at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:826)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:716)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:441)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:357)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:720)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:416)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:242)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:75)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:323)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:207)
>         at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:758)
>         at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:780)
>         at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:326)
>         at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:437)
>         ... 6 more
> java.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorflow/python:gen_boosted_trees_ops_py_wrappers_cc BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true' (requested by nodes '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true', '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[a46389e7efd2cfd6bf7ec804c025d95e] false')
>         at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:514)
>         at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
>         at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.localPopAndExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
> Caused by: java.lang.IllegalStateException
>         at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addDynamicInputLinkOptions(LibrariesToLinkCollector.java:293)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:258)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
>         at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:826)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:716)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:441)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:357)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:720)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:416)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:242)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:75)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:323)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:207)
>         at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:758)
>         at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:780)
>         at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:326)
>         at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:437) ... 6 more
> java.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorflow/python:gen_boosted_trees_ops_py_wrappers_cc BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true' (requested by nodes '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[fa716c1f3ad995922675f9480f09004e] true', '//tensorflow/python:boosted_trees_ops_pygenrule BuildConfigurationValue.Key[a46389e7efd2cfd6bf7ec804c025d95e] false')
>         at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:514)
>         at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
>         at java.base/java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.localPopAndExec(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)
>         at java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)
> Caused by: java.lang.IllegalStateException
>         at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addDynamicInputLinkOptions(LibrariesToLinkCollector.java:293)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:258)
>         at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)
>         at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:826)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createDynamicLibrary(CcLinkingHelper.java:716)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.createCcLinkActions(CcLinkingHelper.java:441)
>         at com.google.devtools.build.lib.rules.cpp.CcLinkingHelper.link(CcLinkingHelper.java:357)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.createTransitiveLinkingActions(CcBinary.java:720)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:416)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:242)
>         at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:75)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:323)
>         at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:207)
>         at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:758)
> FAILED: Build did NOT complete successfully (159 packages loaded, 7515 targets configured)
>     Fetching @swig; fetching 109s
>     Fetching @grpc; fetching 37s
>     Fetching @png_archive; fetching 12s

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

> Get the latest version of Tensorflow and Bazel on Windows 64-Bit. Try to build bazel.

### What operating system are you running Bazel on?

> Windows 10 64-Bit

### What's the output of `bazel info release`?

> ``INFO: Invocation ID: 05684888-9867-4168-86d7-4549771b3ba2
release 0.22.0``

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

> Not built using git

###  Have you found anything relevant by searching the web?

> Nope

### Any other information, logs, or outputs that you want to share?

> I ran ``bazel clean`` before building
> Environmental variables has been set.
> Using jre1.8.0_161
> Python 3.5
> Also tried earlier versions of bazel (0.12, 0.18, 0.22)","Did you run `python ./configure.py`? Did you specify any non-default value?
1. Which commit or branch of TensorFlow do you have checked out? Mine is https://github.com/tensorflow/tensorflow/commit/00afc7bb81d6d36a0f619c08c011abe08965a25b.
1. How did you set your PATH? I did this:
   ```
   set PATH=c:\Python37;c:\Python37\Scripts;c:\msys64\usr\bin;c:\src\bazel-releases\current;c:\Windows\System32
   ```
1. Do you have the `BAZEL_SH`, and either the `BAZEL_VC` or the `BAZEL_VS` environment variables set up? What's their value? (Run `set BAZEL_` in cmd.exe to print all envvars whose name starts with ""BAZEL_"").","@laszlocsomor thanks for the help. I tried the commit of Tensorflow you put there and I got further I believe.

To answer your questions: 

* Did you run `python ./configure.py`? Did you specify any non-default value?

I used default values when available, disabled support for the others without default values.

* Which commit or branch of TensorFlow do you have checked out? Mine is [tensorflow/tensorflow@00afc7b](https://github.com/tensorflow/tensorflow/commit/00afc7bb81d6d36a0f619c08c011abe08965a25b).

I am now using this commit.

* How did you set your PATH? I did this:
  ```
  set PATH=c:\Python37;c:\Python37\Scripts;c:\msys64\usr\bin;c:\src\bazel-releases\current;c:\Windows\System32
  ```

I set the paths using the environmental variables interface for Windows. So I have the relevants paths in 'Path': C:\Users\chhn\AppData\Local\Continuum\anaconda3, C:\bazel, C:\msys32\usr\bin

* Do you have the `BAZEL_SH`, and either the `BAZEL_VC` or the `BAZEL_VS` environment variables set up? What's their value? (Run `set BAZEL_` in cmd.exe to print all envvars whose name starts with ""BAZEL_"").

set BAZEL_
BAZEL_SH=C:\msys32\usr\bin\bash.exe
BAZEL_VC=C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\VC
BAZEL_VS=C:\Program Files (x86)\Microsoft Visual Studio\2017


I should say that I followed the instructions from msys after installation, updated and upgraded with a restart of the terminal inbetween.

My error code now with using the new commit is:

``C:\Users\chhn\Desktop\tensorflow\tensorflow>bazel build -c opt contrib/model_pruning:strip_pruning_vars
Starting local Bazel server and connecting to it...
INFO: Invocation ID: 111afa41-eb2f-4e96-9fd5-26c9b4898612
DEBUG: C:/users/chhn/_bazel_chhn/x3deuiqq/external/build_bazel_rules_apple/apple/repositories.bzl:35:5:
WARNING: `build_bazel_rules_apple` depends on `bazel_skylib` loaded from https://github.com/bazelbuild/bazel-skylib.git (tag 0.6.0), but we have detected it already loaded into your workspace from None (tag None). You may run into compatibility issues. To silence this warning, pass `ignore_version_differences = True` to `apple_rules_dependencies()`.

ERROR: C:/users/chhn/desktop/tensorflow/tensorflow/core/platform/default/build_config/BUILD:222:1: no such package '@png_archive//': Traceback (most recent call last):
        File ""C:/users/chhn/desktop/tensorflow/third_party/repo.bzl"", line 106
                _apply_patch(ctx, ctx.attr.patch_file)
        File ""C:/users/chhn/desktop/tensorflow/third_party/repo.bzl"", line 73, in _apply_patch
                _execute_and_check_ret_code(ctx, cmd)
        File ""C:/users/chhn/desktop/tensorflow/third_party/repo.bzl"", line 52, in _execute_and_check_ret_code
                fail(""Non-zero return code({1}) when ...))
Non-zero return code(127) when executing 'C:\msys32\usr\bin\bash.exe -l -c ""patch"" ""-p1"" ""-d"" ""C:/users/chhn/_bazel_chhn/x3deuiqq/external/png_archive"" ""-i"" ""C:/users/chhn/desktop/tensorflow/third_party/png_fix_rpi.patch""':
Stdout:
Stderr: /usr/bin/bash: patch: command not found
 and referenced by '//tensorflow/core/platform/default/build_config:png'
ERROR: Analysis of target '//tensorflow/contrib/model_pruning:strip_pruning_vars' failed; build aborted: Analysis failed
INFO: Elapsed time: 47.051s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (182 packages loaded, 6586 targets configured)
    Fetching @swig; fetching 26s
    Fetching @eigen_archive; fetching 23s
    Fetching @grpc; fetching 13s
    Fetching @png_archive; fetching 10s``"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7476,"### Description of the problem / feature request:

In remote execution mode, Bazel allow specifying two separate remote execution service end-points:
* `--remote_executor`: mandatory, for the main execution service.
* `--remote_cache`: optional, for a separate CAS and action-cache service (if not hosted at `--remote_executor`).

In order to determine client/server compatibility, Bazel's first gRPC call to the remote service is [`GetCapabilities()`](https://github.com/bazelbuild/remote-apis/blob/master/build/bazel/remote/execution/v2/remote_execution.proto#L336) in order to retrieve [`ServerCapabilities`](https://github.com/bazelbuild/remote-apis/blob/master/build/bazel/remote/execution/v2/remote_execution.proto#L1302). This message contains, among other informations,  `ExecutionCapabilities` and `CacheCapabilities`.

Currently, if both `--remote_executor` and `--remote_cache` are set, it seems like Bazel is only querying `ServerCapabilities` at the `--remote_executor` end-point and determines compatibility using both `ExecutionCapabilities` and `CacheCapabilities` from that message.

This is a bit surprising, and, even if the REAPI specification does not mention anything regarding this, expected logic in that situation, I believe, would have been to query capabilities from the two end-point services and use `ExecutionCapabilities` from `--remote_executor` and `CacheCapabilities` from `--remote_cache`.

### What operating system are you running Bazel on?

Debian Linux testing.

### What's the output of `bazel info release`?

```
release 0.22.0- (@non-git)
```

### Any other information, logs, or outputs that you want to share?

I'll fill a bug against the REAPI for better documentation about the expected behaviour once that behaviour is determined and agreed.",Do you recall why @ola-rozenfeld? ,"> Yes, let's continue this discussion in the remote-apis repository.

I've opened https://github.com/bazelbuild/remote-apis/issues/61 for this."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7459,"### Description of the problem / feature request:

Running bazel in our ci we just got the following exception:

```
16:02:58) INFO: Analysed 39 targets (9 packages loaded, 34497 targets configured).
(16:02:58) INFO: Found 39 targets and 0 test targets...
Internal error thrown during build. Printing stack trace: java.lang.RuntimeException: Unrecoverable error while evaluating node 'ActionLookupData{actionLookupKey=//indexpage:nuxt-build BuildConfigurationValue.Key[317b3efaf55464f525c3f2455114fd89] false, actionIndex=0}' (requested by nodes 'File:[[<execution_root>]bazel-out/k8-fastbuild/bin]indexpage/.nuxt')
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsupportedOperationException: unsupported message type: DownloadCommand (expected: ByteBuf, FileRegion)
	at io.netty.channel.nio.AbstractNioByteChannel.filterOutboundMessage(AbstractNioByteChannel.java:270)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:877)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:831)
	at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1041)
	at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:300)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$3(HttpBlobStore.java:417)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:163)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:34)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:409)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:377)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache.downloadBlob(SimpleBlobStoreActionCache.java:231)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadFile(AbstractRemoteActionCache.java:388)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$4(AbstractRemoteActionCache.java:352)
	at io.grpc.Context.call(Context.java:570)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$5(AbstractRemoteActionCache.java:352)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:266)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:256)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadDirectory(AbstractRemoteActionCache.java:351)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.access$000(AbstractRemoteActionCache.java:65)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:187)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:177)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.AbstractCatchingFuture.run(AbstractCatchingFuture.java:93)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:134)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:131)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:241)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:232)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$2(HttpBlobStore.java:422)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:95)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:76)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:71)
	at com.google.devtools.build.lib.remote.blobstore.http.AbstractHttpHandler.succeedAndResetUserPromise(AbstractHttpHandler.java:55)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.succeedAndReset(HttpDownloadHandler.java:168)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:109)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:41)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more

(16:03:04) INFO: Elapsed time: 10.413s, Critical Path: 2.92s
(16:03:04) INFO: 65 processes: 39 remote cache hit, 26 processwrapper-sandbox.
Internal error thrown during build. Printing stack trace: java.lang.RuntimeException: Unrecoverable error while evaluating node 'ActionLookupData{actionLookupKey=//indexpage:nuxt-build BuildConfigurationValue.Key[317b3efaf55464f525c3f2455114fd89] false, actionIndex=0}' (requested by nodes 'File:[[<execution_root>]bazel-out/k8-fastbuild/bin]indexpage/.nuxt')
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsupportedOperationException: unsupported message type: DownloadCommand (expected: ByteBuf, FileRegion)
	at io.netty.channel.nio.AbstractNioByteChannel.filterOutboundMessage(AbstractNioByteChannel.java:270)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:877)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:831)
	at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1041)
	at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:300)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$3(HttpBlobStore.java:417)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:163)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:34)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:409)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:377)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache.downloadBlob(SimpleBlobStoreActionCache.java:231)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadFile(AbstractRemoteActionCache.java:388)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$4(AbstractRemoteActionCache.java:352)
	at io.grpc.Context.call(Context.java:570)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$5(AbstractRemoteActionCache.java:352)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:266)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:256)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadDirectory(AbstractRemoteActionCache.java:351)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.access$000(AbstractRemoteActionCache.java:65)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:187)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:177)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.AbstractCatchingFuture.run(AbstractCatchingFuture.java:93)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:134)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:131)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:241)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:232)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$2(HttpBlobStore.java:422)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:95)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:76)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:71)
	at com.google.devtools.build.lib.remote.blobstore.http.AbstractHttpHandler.succeedAndResetUserPromise(AbstractHttpHandler.java:55)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.succeedAndReset(HttpDownloadHandler.java:168)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:109)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:41)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
java.lang.RuntimeException: Unrecoverable error while evaluating node 'ActionLookupData{actionLookupKey=//indexpage:nuxt-build BuildConfigurationValue.Key[317b3efaf55464f525c3f2455114fd89] false, actionIndex=0}' (requested by nodes 'File:[[<execution_root>]bazel-out/k8-fastbuild/bin]indexpage/.nuxt')
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsupportedOperationException: unsupported message type: DownloadCommand (expected: ByteBuf, FileRegion)
	at io.netty.channel.nio.AbstractNioByteChannel.filterOutboundMessage(AbstractNioByteChannel.java:270)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:877)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:831)
	at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1041)
	at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:300)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$3(HttpBlobStore.java:417)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:163)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:34)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:409)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:377)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache.downloadBlob(SimpleBlobStoreActionCache.java:231)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadFile(AbstractRemoteActionCache.java:388)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$4(AbstractRemoteActionCache.java:352)
	at io.grpc.Context.call(Context.java:570)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$5(AbstractRemoteActionCache.java:352)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:266)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:256)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadDirectory(AbstractRemoteActionCache.java:351)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.access$000(AbstractRemoteActionCache.java:65)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:187)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:177)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.AbstractCatchingFuture.run(AbstractCatchingFuture.java:93)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:134)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:131)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:241)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:232)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$2(HttpBlobStore.java:422)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:95)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:76)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:71)
	at com.google.devtools.build.lib.remote.blobstore.http.AbstractHttpHandler.succeedAndResetUserPromise(AbstractHttpHandler.java:55)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.succeedAndReset(HttpDownloadHandler.java:168)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:109)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:41)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
java.lang.RuntimeException: Unrecoverable error while evaluating node 'ActionLookupData{actionLookupKey=//indexpage:nuxt-build BuildConfigurationValue.Key[317b3efaf55464f525c3f2455114fd89] false, actionIndex=0}' (requested by nodes 'File:[[<execution_root>]bazel-out/k8-fastbuild/bin]indexpage/.nuxt')
	at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:515)
	at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsupportedOperationException: unsupported message type: DownloadCommand (expected: ByteBuf, FileRegion)
	at io.netty.channel.nio.AbstractNioByteChannel.filterOutboundMessage(AbstractNioByteChannel.java:270)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:877)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:804)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:831)
	at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1041)
	at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:300)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$3(HttpBlobStore.java:417)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:163)
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:34)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:409)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.get(HttpBlobStore.java:377)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache.downloadBlob(SimpleBlobStoreActionCache.java:231)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadFile(AbstractRemoteActionCache.java:388)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$4(AbstractRemoteActionCache.java:352)
	at io.grpc.Context.call(Context.java:570)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.lambda$downloadDirectory$5(AbstractRemoteActionCache.java:352)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:266)
	at com.google.devtools.build.lib.remote.Retrier.executeAsync(Retrier.java:256)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.downloadDirectory(AbstractRemoteActionCache.java:351)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache.access$000(AbstractRemoteActionCache.java:65)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:187)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$2.onSuccess(AbstractRemoteActionCache.java:177)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.AbstractCatchingFuture.run(AbstractCatchingFuture.java:93)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:134)
	at com.google.devtools.build.lib.remote.AbstractRemoteActionCache$1.onSuccess(AbstractRemoteActionCache.java:131)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:241)
	at com.google.devtools.build.lib.remote.SimpleBlobStoreActionCache$1.onSuccess(SimpleBlobStoreActionCache.java:232)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1355)
	at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)
	at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:689)
	at com.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpBlobStore.lambda$get$2(HttpBlobStore.java:422)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:95)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:76)
	at io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:71)
	at com.google.devtools.build.lib.remote.blobstore.http.AbstractHttpHandler.succeedAndResetUserPromise(AbstractHttpHandler.java:55)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.succeedAndReset(HttpDownloadHandler.java:168)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:109)
	at com.google.devtools.build.lib.remote.blobstore.http.HttpDownloadHandler.channelRead0(HttpDownloadHandler.java:41)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	... 1 more
Exited with code 37
```

We are using a remote cache in ci via https://github.com/notnoopci/bazel-remote-proxy. The file that is being talked about in the exception: `File:[[<execution_root>]bazel-out/k8-fastbuild/bin]indexpage/.nuxt')` is a directory that is created by a rule via `actions.declare_directory(...)`

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

Not sure how to reproduce as this only happened once so far but we where running a normal `bazel test //:target1 //:target2 ...` command which also worked again on ci rerun.

### What operating system are you running Bazel on?

in ci it runs in a debian strech docker image

### What's the output of `bazel info release`?

`release 0.23.0rc1`

###  Have you found anything relevant by searching the web?

No
","What's the state of this? Without more information, I'll assume it's not a release blocker.",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7410,"This was reported to me by a fellow Googler.

### Description of the problem / feature request:

When running on Debian Buster with Bash 5, the test-setup script always generates a test.xml with an error about SIGCHLD:
```
  <testsuite name=""simple_script_test"" tests=""1"" failures=""0"" errors=""1"">
    <testcase name=""simple_script_test"" status=""run"" duration=""0"" time=""0""><error message=""Terminated by signal SIGCHLD""></error></testcase>
    <system-out><![CDATA[]]></system-out>
  </testsuite>
```

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

```
WORKSPACE:
-----
workspace(name=""sh_test_recreate"")
-----
BUILD:
-----
sh_test(
  name = ""simple_script_test"",
  srcs = [""simple_script.sh""],
)
-----
simple_script.sh:
-----
#!/bin/bash

exit 0
-----
```

### What operating system are you running Bazel on?

Debian Buster

### What's the output of `bazel info release`?

0.22.0

###  Have you found anything relevant by searching the web?

No.",Would that be acceptable for patching earlier releases?,"Yes, that sounds good. Do you want to send a PR?"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7376,"### Description of the problem / feature request:

`bazel` installed via Chocolatey does not declare dependency on VC Redist

### Feature requests: what underlying problem are you trying to solve with this feature?

I'm trying to use `bazel` to build code on Windows instance on GCE (specifically `windows-2019/windows-cloud`)

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

`choco install bazel`
`bazel version` => {
    `cmd` -> prints out empty string
    `bash` on `msys2` -> prints out `C:/ProgramData/chocolatey/bin/bazel.exe: error while loading shared libraries: ?: cannot open shared object file: No such file or directory`
}

### What operating system are you running Bazel on?

Windows Server 2019

### What's the output of `bazel info release`?

```
$ bazel version                                                                                                                                           
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".                            
INFO: Invocation ID: aa5a2fea-ff69-4f76-b963-f7fb4f427831                                                                                                 
Build label: 0.22.0                                                                                                                                       
Build target: bazel-out/x64_windows-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar                                      
Build time: Mon Jan 28 12:59:27 2019 (1548680367)                                                                                                         
Build timestamp: 1548680367                                                                                                                               
Build timestamp as int: 1548680367 
```


###  Have you found anything relevant by searching the web?

Related: #5254

### Any other information, logs, or outputs that you want to share?

`choco install -y vcredist2015` should be ran to be able to use `bazel`
it should be either automatically installed or at least advised
",Can you work around it until the package is updated?,"@RNabel @laszlocsomor thank you! 

>Can you work around it until the package is updated?

Yes, using the hint I posted in `Any other information, logs, or outputs that you want to share?` in issue description"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7275,"### Description of the problem / feature request:

When using the `--experimental_remap_main_repo` flag, some providers defined in repository are not able to be found in their targets. It would appear something about the remapping is messing up provider key lookup, or provider identity.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

1. `git clone https://github.com/bazelbuild/rules_swift.git`
2. `bazel build //... --experimental_remap_main_repo`
3. Observe that the build fails with the following error (or one similar):

    ```
    ERROR: /Users/allevato/Source/rules_swift/examples/xplatform/hello_world/BUILD:5:1:
    in (an implicit dependency) attribute of swift_binary rule //examples/xplatform/hello_world:hello_world:
    '@build_bazel_rules_swift_local_config//:toolchain' does not have mandatory providers: 'SwiftToolchainInfo'
    ERROR: Analysis of target '//examples/xplatform/hello_world:hello_world' failed;
    build aborted: Analysis of target '//examples/xplatform/hello_world:hello_world' failed;
    build aborted
    ```

4. `bazel clean`
5. `bazel build //...`
6. Observe that the build succeeds.

I can also insert `print` statements into the toolchain rule and the binary rule to verify that:

1. The provider _does indeed_ return a `SwiftToolchainInfo` as expected
2. The toolchain target when accessed from the binary rule _does indeed_ list `SwiftToolchainInfo` in its keys

But, apparently they aren't matching in terms of provider lookup.

### What operating system are you running Bazel on?

macOS 10.13.6 (High Sierra)

### What's the output of `bazel info release`?

`release 0.21.0`
",Could you give this a try with that release?,"It looks like it may be fixed; I can't produce the same error when using the flag with rules_swift on 0.22, so I'll close this. Thanks!"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7206,"### Description of the problem / feature request:

`--watchfs` ignores changes on volumes in Linux docker under a Windows host

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

On a Windows machine with bazel 0.21, docker and git, follow these commands:

- `git clone https://github.com/filipesilva/bazel-windows-docker-volume`
- `cd bazel-windows-docker-volume`
- `bazel test //:test --watchfs`
- delete contents of `BUILD.bazel`
- `bazel test //:test --watchfs`
- you should get an error:
```
INFO: Invocation ID: c1866380-8396-424d-a5ef-d2f2bbdee2db
ERROR: Skipping '//:test': no such target '//:test': target 'test' not declared in package '' defined by D:/sandbox/bazel-windows-docker-volume/BUILD.bazel
ERROR: no such target '//:test': target 'test' not declared in package '' defined by D:/sandbox/bazel-windows-docker-volume/BUILD.bazel
INFO: Elapsed time: 0.991s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded)
FAILED: Build did NOT complete successfully (1 packages loaded)
```

Now do the same under a Linux container with a mounted volume:
- restore the contents of `BUILD.bazel`
- `docker run -it --rm -v $(pwd -W):/src debian:jessie` 
  - note: depending on your shell you might have to replace `$(pwd -W)` with the path to the current directory manually
- `cd /src`
- `./install-bazel.sh` (this scripts follows the [Ubuntu instructions](https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu))
- `bazel test //:test --watchfs`
- delete contents of `BUILD.bazel`
- `bazel test //:test --watchfs` (no error)
- `bazel test //:test` (error)

### What operating system are you running Bazel on?

Windows 10 1809

### What's the output of `bazel info release`?

release 0.21.0

###  Have you found anything relevant by searching the web?

Found a couple of issues here about --watchfs, but nothing seemed to be related to windows or indicate it stopped finding changes.
",Do you know how this happens? Are they copied elsewhere?,"Heya @jmmv. I don't know a lot about the Docker internals but will tell you whatever I can.

When using the `-v $(pwd -W):/src` flag on docker, I am saying ""I want the contents of the current directory ( given by `$(pwd -W`) to be mounted under docker at `/src`"".

I was calling this volume because it uses the `-v` flag, but it looks like the correct name is ""bind mount"": https://docs.docker.com/storage/bind-mounts/

The sources are definitely on windows (the host) in this case, in the current directory. I just checked and it is indeed a NTFS drive.

The sources are being exposed inside the running docker container. As far as I know they aren't copied anywhere. Changes that I do in the host are reflected in the container, and vice versa. I don't know the details of how Docker accomplishes this.

I think there is a bug in Bazel's `--watchfs` because:
- the files do change inside the container, 
- file changes are not recognized with `--watchfs`
- file changes are recognized with without `--watchfs`"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7119,"### Description of the problem / feature request:

Tests are currently unable to respond to signals unless `--experimental_split_xml_generation` is  used.
To ensure all `test.xml` logs are written, [`test-setup.sh`](https://github.com/bazelbuild/bazel/blob/master/tools/test/test-setup.sh) traps all signals to write this file with the contents of stdout, exit code, etc. This is similar to #6338 in that we do not properly propagate signals to the child test process. 

### Feature requests: what underlying problem are you trying to solve with this feature?

I have a test rule that starts some services prior to running tests. These services run in Docker containers under Docker for Mac, which is actually a separate Linux VM. As a result, the containers need to be explicitly shutdown, which is only possible by handling this signal.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

Here's a simple test rule to repro:
```file=defs.bzl
TEST_SCRIPT = """"""#!/bin/bash
echo ""Running tests""

function cleanup() {
    echo ""Cleaning up""
    exit 1
}

trap ""cleanup"" SIGTERM

sleep 10
exit 1
""""""

def impl(ctx):
    ctx.actions.write(output = ctx.outputs.executable, content = TEST_SCRIPT)

my_test = rule(implementation = impl, test = True)
```

Running as `bazel test //:test --test_output=streamed --test_timeout=1 --local_sigkill_grace_seconds=3` we do not clean up; with `--experimental_split_xml_generation` we do 🙂 

### What operating system are you running Bazel on?

macOS 10.14

### What's the output of `bazel info release`?

```Build label: 0.21.0
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 19 12:57:09 2018 (1545224229)
Build timestamp: 1545224229
Build timestamp as int: 1545224229
```

### Any other information, logs, or outputs that you want to share?

I asked about this in #general on the Bazel Slack, it was suggested that I create this as I'm somewhat relying on an implementation detail :)","What would it take to take this feature out of experimental, enable it by default, and remove the `test.xml` generation from the setup script?",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7090,"> ATTENTION! Please read and follow:
> - if this is a _question_ about how to build / test / query / deploy using Bazel, ask it on StackOverflow instead: https://stackoverflow.com/questions/tagged/bazel
> - if this is a _discussion starter_, send it to bazel-discuss@googlegroups.com
> - if this is a _bug_ or _feature request_, fill the form below as best as you can.

### Description of the problem / feature request:
Copybara (https://github.com/google/copybara) uses Starlark as embed language. We depend on master HEAD code and update from time to time. Latest update fails with: 

java/com/google/copybara/config/SkylarkParser.java:276: error: [strict] Using type com.google.devtools.build.lib.syntax.SkylarkSemantics from an indirect dependency (TOOL_INFO: ""@io_bazel//src/main/java/com/google/devtools/build/lib:skylark_semantics""). See command below **
        .setSemantics(SkylarkSemantics.DEFAULT_SEMANTICS)
                      ^
If I try to fix it by depending on    @io_bazel//src/main/java/com/google/devtools/build/lib:skylark_semantics, I get the following error: 

ERROR: /Users/malcon/dev/copybara/third_party/BUILD:137:1: in java_library rule //third_party:skylark-lang: target '@io_bazel//src/main/java/com/google/devtools/build/lib:skylark_semantics' is not visible from target '//third_party:skylark-lang'. Check the visibility declaration of the former target if you think the dependency is legitimate


IIUC visibility for skylark_semantics has to be the same as skylark-lang.
","Did you update recently? It's probably broken since https://github.com/bazelbuild/bazel/commit/507b00f7ec3145e817b200db571b8bd93b40c330. 

Try using `useDefaultSemantics()` instead of `setSemantics()`. It's probably better than making skylark_semantics public (unless someone needs it).","Done. It worked!

Thanks!"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/7035,"After successfully compile bazel-0.19.2-dist on mips64 cpu. Install bazel.
But while compile envoy with bazel, error found:

ERROR: No toolchain found for cpu 'mips64'. Valid cpus from default_toolchain entries are: [
]. Valid toolchains are: [
  local_linux: --cpu='mips64' --compiler='compiler',
  stub_armeabi-v7a: --cpu='armeabi-v7a' --compiler='compiler',
  local: --cpu='piii' --compiler='compiler',
  msys_x64_mingw: --cpu='x64_windows' --compiler='mingw-gcc',
  msvc_x64: --cpu='x64_windows' --compiler='msvc-cl',
]
INFO: Elapsed time: 0.601s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)","Can you try again with Bazel 0.21 and if it still fails, with Bazel built at head? I think it should work now.",It works.
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6665,"### Description of the problem / feature request:
Bazel 0.19.1 was released with a bug fixed by https://github.com/bazelbuild/bazel/commit/6bc452874ddff69cbf7f66186238032283f1195f
(https://github.com/bazelbuild/bazel-toolchains/issues/198)

Bazel 0.19.0 does not have that bug.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

Use bazel-toolchains repo
Try to run this target:
https://github.com/bazelbuild/bazel-toolchains/blob/master/tests/config/BUILD#L70
modify the value of the bazel_version target to point to 0.19.1
bazel_version = ""0.19.1"",

Try with version 0.19.0 to see it pass (see https://github.com/bazelbuild/bazel-toolchains/pull/237)

### What operating system are you running Bazel on?

Linux - an ubuntu16_04 docker container

### What's the output of `bazel info release`?

Bazel 0.19.1

@mhlopko fyi as he authored the commit that was not included in the 0.19.1 release
","What are the ramifications? Any build with bazel 0.19.1 and
bazel-toolchains at HEAD fails? Any version of bazel-toolchains fails?
On Mon, 12 Nov 2018 at 22:37 Nicolas Lopez <notifications@github.com> wrote:

> Description of the problem / feature request:
>
> Bazel 0.19.1 was released with a bug fixed by 6bc4528
> <https://github.com/bazelbuild/bazel/commit/6bc452874ddff69cbf7f66186238032283f1195f>
> (bazelbuild/bazel-toolchains#198
> <https://github.com/bazelbuild/bazel-toolchains/issues/198>)
>
> Bazel 0.19.0 does not have that bug.
> Bugs: what's the simplest, easiest way to reproduce this bug? Please
> provide a minimal example if possible.
>
> Use bazel-toolchains repo
> Try to run this target:
>
> https://github.com/bazelbuild/bazel-toolchains/blob/master/tests/config/BUILD#L70
> modify the value of the bazel_version target to point to 0.19.1
> bazel_version = ""0.19.1"",
>
> Try with version 0.19.0 to see it pass (see
> bazelbuild/bazel-toolchains#237
> <https://github.com/bazelbuild/bazel-toolchains/pull/237>)
> What operating system are you running Bazel on?
>
> Linux - an ubuntu16_04 docker container
> What's the output of bazel info release?
>
> Bazel 0.19.1
>
> @mhlopko <https://github.com/mhlopko> fyi as he authored the commit that
> was not included in the 0.19.1 release
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/bazelbuild/bazel/issues/6665>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABUIF0RWMIHdElytMu0eof6-jv9tsSHyks5uudwQgaJpZM4YaZLy>
> .
>
",There should be no ramifications for remote exec users. This will only impact our internal process to produce a toolchain configs that works with RBE for Bazel 0.19.1 (but the ones for 0.19.0 work well with 0.19.1).
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6662,"### Description of the problem / feature request:

C++ builds fail with:

```
ERROR: The label '@bazel_tools//tools/cpp:cc-compiler-local-k8' is not a cc_toolchain rule
```

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

On Linux/amd64, in an otherwise empty workspace with an empty WORKSPACE file, run:

```
bazel build --crosstool_top=@bazel_tools//tools/cpp:default-toolchain //...
```

### What operating system are you running Bazel on?

Linux (Debian variant)

### What's the output of `bazel info release`?

```
release 0.19.1
```

###  Have you found anything relevant by searching the web?

In the file https://github.com/bazelbuild/bazel/blob/0.19.1/tools/cpp/BUILD:

On the 0.19.0 tag, [this line](https://github.com/bazelbuild/bazel/blob/f0c844c77a2406518c4e75c49188390d5e281d3d/tools/cpp/BUILD#L100) refers to `cc-compiler-local`, a `cc_toolchain` rule that exists.

On the 0.19.1 tag, [this line](https://github.com/bazelbuild/bazel/blob/eb2af0f699350ad187048bf814a95af23f562c77/tools/cpp/BUILD#L100) refers to `cc-compiler-local-k8`, a `cc_toolchain` rule that does not exist.

This appears to be the cause of the issue, although I am not sure why this was changed.","Could the following output have the same underlying cause?
...`in cc_toolchain rule @local_config_cc//:cc-compiler-k8: Error while selecting cc_toolchain: Toolchain identifier 'local' was not found, valid identifiers are`...
This break occurs at 0.19.1. I've been unable to determine if it also occurs at 0.19, but 0.18 was definitely working. Note that this still breaks even if all backward breaking flags that were flipped in 0.19 are set to false.

edit: If this is irrelevant, I can delete this comment and file a separate issue.",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6651,"Exception stack trace:
```
Caused by: java.lang.IllegalStateException: ""bazel.windows_unix_root"" JVM flag is not set. Use the --host_jvm_args flag. For example: ""--host_jvm_args=-Dbazel.windows_unix_root=c:/tools/msys64"".
        at com.google.devtools.build.lib.util.DependencySet$WindowsPath.getUnixRoot(DependencySet.java:285)
        at com.google.devtools.build.lib.util.DependencySet$WindowsPath.translateWindowsPath(DependencySet.java:269)
        at com.google.devtools.build.lib.util.DependencySet$WindowsPath.access$000(DependencySet.java:254)
        at com.google.devtools.build.lib.util.DependencySet.translatePath(DependencySet.java:112)
        at com.google.devtools.build.lib.util.DependencySet.addDependency(DependencySet.java:103)
        at com.google.devtools.build.lib.util.DependencySet.process(DependencySet.java:154)
        at com.google.devtools.build.lib.util.DependencySet.read(DependencySet.java:121)
        at com.google.devtools.build.lib.rules.cpp.CppCompileAction.processDepset(CppCompileAction.java:1277)
        at com.google.devtools.build.lib.rules.cpp.CppCompileAction.discoverInputsFromDotdFiles(CppCompileAction.java:1249)
        at com.google.devtools.build.lib.rules.cpp.CppCompileAction.execute(CppCompileAction.java:1188)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.executeActionTask(SkyframeActionExecutor.java:941)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.prepareScheduleExecuteAndCompleteAction(SkyframeActionExecutor.java:872)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.access$900(SkyframeActionExecutor.java:114)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.call(SkyframeActionExecutor.java:731)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.call(SkyframeActionExecutor.java:685)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.executeAction(SkyframeActionExecutor.java:426)
        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.checkCacheAndExecuteIfNeeded(ActionExecutionFunction.java:490)
        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.compute(ActionExecutionFunction.java:208)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:363)
        ... 4 more
```","Do you have a repro?

I can build cc_* targets with `--compiler=msys-gcc` with Bazel 0.20.0",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6551,"### Description of the problem / feature request:
bazel fails reading/writing to remote-cache
```
WARNING: Error reading from the remote cache:
SSLEngine closed already
WARNING: Error writing to the remote cache:
SSLEngine closed already
```
the certificate is valid, and issued by DigiCert, it uses `TLS 1.2` and `ECDSA`. The certificate is able to be verified with every up to date browser. 

### Feature requests: what underlying problem are you trying to solve with this feature?
Ship bazel with a more up to date trust store or provide a simpler way to use one

As the homogeny of operating systems becoming more and more prevalent, what would be great is if bazel just worked™. It would be a major pain if we'd have to go and package it for debian, archlinux, fedora, macos, windows and so on...

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

`bazel build --remote_http_cache=https://cache.sevki.net/ ....`
I've deployed this as an example, I'm not using this in production or anything, just wanted to share this as a quick repro step. 

### What operating system are you running Bazel on?
`Linux 4.18.16-arch1-1-ARCH`

### What's the output of `bazel info release`?
`release 0.19.0- (@non-git)`

### If `bazel info release` returns ""development version"" or ""(@non-git)"", tell us how you built Bazel.
`pacman -S bazel`


###  Have you found anything relevant by searching the web?
- https://github.com/bazelbuild/bazel/issues/5741 this points to the next issue as a solution
- https://groups.google.com/forum/#!topic/bazel-discuss/13uPDObyfQg this solution doesn't work for me

","Can you please try with an official Bazel release? Bazel doesn't ship with a truststore but uses what's provided by it's JVM. Presumably arch linux ships its own JVM and truststore?

Thanks!","I tried using it with the oficial deb too. 
Arch is also using an official release. https://git.archlinux.org/svntogit/community.git/tree/trunk/PKGBUILD?h=packages/bazel#n15"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6503,"

### Description of the problem / feature request:

I have tried to install bazel multiple times following these steps:
 1)sudo apt-get install pkg-config zip g++ zlib1g-dev unzip python  
2)downloading https://github.com/bazelbuild/bazel/releases/download/0.18.0/bazel-0.18.0-installer-darwin-x86_64.sh 
3) chmod +x bazel-0.18.0-installer-linux-x86_64.sh
./bazel-0.18.0-installer-linux-x86_64.sh --user  
4)export PATH=""$PATH:$HOME/bin

bazel version outputs  following error
/home/ai/bin/bazel: line 88: /home/ai/.bazel/bin/bazel-real: cannot execute binary file: Exec format error
/home/ai/bin/bazel: line 88: /home/ai/.bazel/bin/bazel-real: Success

### Feature requests: what underlying problem are you trying to solve with this feature?

I would like to use bazel for testing

### What operating system are you running Bazel on?

Linux ai-VirtualBox 4.15.0-36-generic #39-Ubuntu SMP Mon Sep 24 16:19:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

### What's the output of `bazel info release`?

/home/ai/bin/bazel: line 88: /home/ai/.bazel/bin/bazel-real: cannot execute binary file: Exec format error
/home/ai/bin/bazel: line 88: /home/ai/.bazel/bin/bazel-real: Success


","Can you verify that you really used https://github.com/bazelbuild/bazel/releases/download/0.18.0/bazel-0.18.0-installer-darwin-x86_64.sh on a Linux box?
That will certainly not work. The executable would be for Mach, not Linux. 
The instructions for install on Linux are here
https://docs.bazel.build/versions/master/install-ubuntu.html",thank you!
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6473,"How to reproduce
BUILD:
```
genrule(
    name = ""gen"",
    outs = [""hello""],
    cmd = ""touch $@"",
    tools = ["":mytool""],
)

genrule(
    name = ""mytool"",
    outs = [""tool""],
    cmd = ""touch $@"",
)
```

Run `bazel build //:gen -s --action_env HAHA=123`
```
pcloudy@pcloudy0-w MSYS ~/workspace/my_tests/genrule_tmp_test
$ bazel build //:gen -s --action_env HAHA=123
INFO: Build options have changed, discarding analysis cache.
INFO: Analysed target //:gen (1 packages loaded).
INFO: Found 1 target...
SUBCOMMAND: # //:mytool [action 'Executing genrule //:mytool [for host]']
cd C:/users/pcloudy/_bazel_pcloudy/j7l3crzt/execroot/__main__
  SET PATH=c:\tools\msys64\usr\bin;c:\tools\msys64\bin;C:\Program Files\CMake\bin;C:\Python36;C:\tools\msys64\home\pcloudy\bin;C:\Program Files\Java\jdk1.8.0_77\bin;C:\tools\msys64\usr\local\bin;C:\tools\msys64\usr\bin;C:\tools\msys64\usr\bin;C:\tools\msys64\opt\bin;C:\Windows\System32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\tools\msys64\usr\bin\site_perl;C:\tools\msys64\usr\bin\vendor_perl;C:\tools\msys64\usr\bin\core_perl
  c:/tools/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; touch bazel-out/host/genfiles/tool
SUBCOMMAND: # //:gen [action 'Executing genrule //:gen']
cd C:/users/pcloudy/_bazel_pcloudy/j7l3crzt/execroot/__main__
  SET HAHA=123
    SET PATH=c:\tools\msys64\usr\bin;c:\tools\msys64\bin;C:\Program Files\CMake\bin;C:\Python36;C:\tools\msys64\home\pcloudy\bin;C:\Program Files\Java\jdk1.8.0_77\bin;C:\tools\msys64\usr\local\bin;C:\tools\msys64\usr\bin;C:\tools\msys64\usr\bin;C:\tools\msys64\opt\bin;C:\Windows\System32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\tools\msys64\usr\bin\site_perl;C:\tools\msys64\usr\bin\vendor_perl;C:\tools\msys64\usr\bin\core_perl
  c:/tools/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; touch bazel-out/x64_windows-fastbuild/genfiles/hello
Target //:gen up-to-date:
  C:/users/pcloudy/_bazel_pcloudy/j7l3crzt/execroot/__main__/bazel-out/x64_windows-fastbuild/genfiles/hello
INFO: Elapsed time: 1.004s, Critical Path: 0.49s
INFO: 2 processes: 2 local.
INFO: Build completed successfully, 3 total actions
```

This is not a Windows specific issue, also happens on Linux.
Related TensorFlow issue: https://github.com/tensorflow/tensorflow/issues/22395#issuecomment-431181667

Workaround: add `--distinct_host_configuration=false` option",Maybe we should add a --host_action_env flag?,
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6460,"When a tree artifact is changed between two Bazel invocations, Bazel does not recognize the change and does not re-run the action generating the tree artifact. Reproduction in logical steps:
 1. Create an action that emits a tree artifact and another one that depends on the tree artifact
 2. Build the outputs of the second action
 3. Change the tree artifact outside of Bazel
 4. Re-run the build in (2)
 5. Observe that the tree artifact does not get rebuilt

This is in contrast with regular files whose changes do get detected. More detailed reproduction:

```
cat > rule.bzl <<'EOF'
def _dirimpl(ctx):
    out = ctx.actions.declare_directory(ctx.label.name)
    ctx.actions.run_shell(
        outputs = [out],
        inputs = [],
        command = ""; "".join([
            ""O=\""%s\"""",
            ""echo RAN"",
            ""mkdir -p \""$O/a\"""",
            ""mkdir -p \""$O/b\"""",
            ""echo 1 > \""$O/a/one\"""",
            ""echo 2 > \""$O/b/two\"""",
        ]) % out.path,
    )
    return DefaultInfo(files = depset([out]))

def _fileimpl(ctx):
    out = ctx.actions.declare_file(ctx.label.name)
    ctx.actions.run_shell(
        outputs = [out],
        inputs = [],
        command = ""; "".join([
            ""O=\""%s\"""",
            ""echo 2 > \""$O\"""",
        ]) % out.path,
    )
    return DefaultInfo(files = depset([out]))

dirrule = rule(implementation = _dirimpl, attrs = {})
filerule = rule(implementation = _fileimpl, attrs = {})
EOF

cat > BUILD <<'EOF'
load("":rule.bzl"", ""dirrule"", ""filerule"")

dirrule(name = ""dr"")

filerule(name = ""fr"")

genrule(
    name = ""gdr"",
    srcs = ["":dr""],
    outs = [""gdro""],
    cmd = ""; "".join([
        ""I=$(location :dr)"",
        ""cat $$I/a/one >> $@"",
        ""cat $$I/b/two >> $@"",
        ""cat $$I/a/one $$I/b/two"",
    ]),
)

genrule(
    name = ""gfr"",
    srcs = ["":fr""],
    outs = [""gfro""],
    cmd = ""; "".join([
        ""I=$(location :fr)"",
        ""cat $$I >> $@"",
        ""cat $$I"",
    ]),
)
EOF

touch WORKSPACE
bazel build :gdr
chmod u+w bazel-bin/dr/a/one
echo bad > bazel-bin/dr/a/one
bazel build :gdr  # Observe that nothing gets rebuilt
# If the same is done to :gfr and bazel-bin/fr, :gfr *does* get rebuilt
```","Can you confirm what the contents of ""bazel-bin/dr/a/one"" after you ""echo bad"" it? I had to chmod the file writable before that would succeed, so if that was not actually overwriting the file in question, the null rebuild is WAI.","Uh, my bad. Probably. I updated the script (I indeed omitted the `chmod u+w` part and single quotes around `EOF`s) and I can't reproduce it anymore. It's probably an ID10T issue on my side. Sorry for wasting your time."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6457,"### Description of the problem / feature request:

Bazel doesn't store java tests in remote cache.

### Feature requests: what underlying problem are you trying to solve with this feature?

I want to share test results across different machines.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

BUILD.bazel:
```
java_test(
    name = ""java_test"",
    size = ""small"",
    test_class = ""AllTests"",
    srcs = [
        ""src/AllTests.java"",
    ],
)

py_test(
    name = ""python_test"",
    srcs = [
        ""src/python_test.py""
    ],
)
```

After running tests on the first machine, tests shound't run on the second. Only python tests are cached:
```
$ bazel test --remote_http_cache=http://10.0.0.1:8080 --remote_upload_local_results=false //...
Starting local Bazel server and connecting to it...
........
INFO: Analysed 2 targets (20 packages loaded).
INFO: Found 2 test targets...
INFO: Elapsed time: 3.890s, Critical Path: 0.58s
INFO: 3 processes: 2 remote cache hit, 1 linux-sandbox.
INFO: Build completed successfully, 11 total actions
//:python_test                                                  (cached) PASSED in 0.1s
//:java_test                                                             PASSED in 0.3s

Executed 1 out of 2 tests: 2 tests pass.
INFO: Build completed successfully, 11 total actions
```

### What operating system are you running Bazel on?

`Ubuntu 18.04.1`

### What's the output of `bazel info release`?

`release 0.15.2`",How do you know it contains this action?,"@regisd I use two machines. First is uploading actions to remote cache, second (with `--remote_upload_local_results=false`) should reuse cached results from the first one. 

> What cache system are you using?

I tried nginx with webdav support and buchgr/bazel-remote-cache docker image.

> Can you share the logs when you run bazel test on this example?

Logs from docker container:
```
2018/10/24 11:49:32  GET 200      10.10.10.6 /ac/254b20368197353aa7aac92c1c52cc2f806ac2a2ae8402f4b67b00e1cb65fdf7
2018/10/24 11:49:32  GET 200      10.10.10.6 /cas/0073aca471c77580d2f1775efb0edafd12276a4248d2fb49d7b6c86556653e0c
2018/10/24 11:49:32  GET 200      10.10.10.6 /cas/84259478d31123aa36cf854a1a90baa4697d474cbc4bfa163fd4a29e0fd2d9d4
2018/10/24 11:49:33  GET 200      10.10.10.6 /ac/4f3fc3cc726ae738f384eecabb133c8964ceefe48d88250c2c6c94895097cd5b
2018/10/24 11:49:33  GET 200      10.10.10.6 /cas/eb55de67277a687f4e48eacaa6889cee9be14ae607a7739ae0a6a0ea5c83a530
2018/10/24 11:49:33  GET 200      10.10.10.6 /cas/e910235f479ef8e25dd60c50a2286d83915e4cf5c52dfdd9734f22f6f4a8f63d
2018/10/24 11:49:33  GET 200      10.10.10.6 /cas/59ce4142794225a1f38b79029bea63cf7ba3eea56a02a561edc034984264e6df
2018/10/24 11:49:33  GET 404      10.10.10.6 /ac/07b180db1e8512c2b7c9b6a9e76effab6b6e09fc91db73d96045fdc2f23d7dd9
```

The hash of last action (07b180db1e8512c2b7c9b6a9e76effab6b6e09fc91db73d96045fdc2f23d7dd9) on the second machine is differ from the first one. Versions of bazel and JDK don't differ. So I just want to find the difference between tho hosts.."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6389,"https://buildkite.com/bazel/bazel-with-downstream-projects-bazel/builds/501#da3c2ee9-5c1d-4863-85bc-10a63dc700d0

```

ERROR: /var/lib/buildkite-agent/.cache/bazel/_bazel_buildkite-agent/4e6a7dba926d8a5f2273fc776c7a457f/external/bazel_tools/tools/jdk/BUILD:197:1: Couldn't build file external/bazel_tools/tools/jdk/platformclasspath_classes: SkylarkAction external/bazel_tools/tools/jdk/platformclasspath_classes failed (Exit 2)
--
  | javac: directory not found: bazel-out/k8-fastbuild/bin/external/bazel_tools/tools/jdk/platformclasspath_classes
  | Usage: javac <options> <source files>
  | use -help for a list of possible options


```

Possible cause:  https://github.com/bazelbuild/bazel/commit/72ef398c3b1a701316367a1790215a52d6babd29

@cushon Since the error message is related to java, so I guess it might be 72ef398c3b1a701316367a1790215a52d6babd29 that broke it.
Can you help confirm this?

The culprit should be between dce9c45b18f6ca163a11645b8d8e555dd6113fb1 and 72ef398c3b1a701316367a1790215a52d6babd29","Can someone confirm that the bug still occurs with `--strategy=remote` using the minimal repro? (or point me at documentation to do that?)
https://github.com/bazelbuild/bazel/issues/6262#issue-364306498",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6308,"https://buildkite.com/bazel/google-bazel-presubmit/builds/9914#140dc6c6-0034-485a-bf8d-6ba99f457241

```
ERROR: /Users/buildkite/builds/buildkite-imacpro-4-1/bazel/google-bazel-presubmit/src/test/java/com/google/devtools/build/lib/BUILD:1537:1: Couldn't build file src/test/java/com/google/devtools/build/lib/rules-tests.jar: Building src/test/java/com/google/devtools/build/lib/rules-tests.jar (3 source files) and running annotation processors (AutoAnnotationProcessor, AutoValueProcessor) failed: Unexpected IO error.: Exhaused retry attempts (0)
```

What subsystem has exhausted the retries here? What did it try in the first place? 0 attempts? Really?",Did that include https://github.com/bazelbuild/bazel/commit/bf6a63d64a010f4c363d218e3ec54dc4dc9d8f34 ?,
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6260,"Currently if you build an iOS target that has resources (storyboards or asset catalogs in my testing) bazel will end up caching a file for the null sha `e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855`. With remote caches this results in failed builds if you accept this file in your cache.

You can reproduce this with one of the sample projects in [rules_apple](https://github.com/bazelbuild/rules_apple):

```
bazel build //examples/ios/HelloWorld --disk_cache=cache
ls cache | grep e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
```

Here you should see a match. If you remove all the resources portions of this BUILD file, this is no longer the case. After applying this diff:

```patch
diff --git i/examples/ios/HelloWorld/BUILD w/examples/ios/HelloWorld/BUILD
index 7f9385d..a3c4753 100644
--- i/examples/ios/HelloWorld/BUILD
+++ w/examples/ios/HelloWorld/BUILD
@@ -15,9 +15,6 @@ objc_library(
         ""Sources/AppDelegate.m"",
         ""Sources/main.m"",
     ],
-    resources = [
-        ""Resources/Main.storyboard"",
-    ],
 )
 
 apple_bundle_version(
@@ -27,14 +24,12 @@ apple_bundle_version(
 
 ios_application(
     name = ""HelloWorld"",
-    app_icons = [""//examples/resources:PhoneAppIcon.xcassets""],
     bundle_id = ""com.example.hello-world"",
     families = [
         ""iphone"",
         ""ipad"",
     ],
     infoplists = ["":Info.plist""],
-    launch_storyboard = ""//examples/resources:Launch.storyboard"",
     minimum_os_version = ""8.0"",
     version = "":HelloWorldVersion"",
     deps = ["":Sources""],
```

And running:

```
rm -rf cache
bazel clean
bazel build //examples/ios/HelloWorld --disk_cache=cache
ls cache | grep e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
```

You should no longer see any matches. I see a few other references to `e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855` in other bazel issues, but none specifically talking about whether or not it is a problem. It seems like a few remote cache implementations work around this by not caching files that are empty (which seem to only happen for us when the key is also this sha). I can't find the exact rule that causes this with `aquery`, but I'd love to know if this is considered an issue, or if we should work around this in our remote cache.

### What operating system are you running Bazel on?

macOS

### What's the output of `bazel info release`?

0.17.1

I migrated this issue from here https://github.com/bazelbuild/rules_apple/issues/228","Can you please expand on ""with remote caches this results in failed builds if you accept this file in your cache"" - what exactly you are doing, how it breaks, how you determined that null hash is at fault?",">  what exactly you are doing, how it breaks

When I try to `bazel build` using the cache after having built once and accepting this file on the cache side, the build actually fails.

>  how you determined that null hash is at fault?

Just based on the difference that if I stop saving keys for that sha from the cache, the builds no longer fail"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6182,"> ATTENTION! Please read and follow:
> - if this is a _question_ about how to build / test / query / deploy using Bazel, ask it on StackOverflow instead: https://stackoverflow.com/questions/tagged/bazel
> - if this is a _discussion starter_, send it to bazel-discuss@googlegroups.com
> - if this is a _bug_ or _feature request_, fill the form below as best as you can.

### Description of the problem / feature request:

bazel builds using gcr.io/cloud-builders/bazel failing with null pointer exception.

````
Step #3: Caused by: java.lang.NullPointerException
Step #3: 	at com.google.devtools.build.lib.rules.objc.CompilationSupport.getFeatureConfiguration(CompilationSupport.java:560)
Step #3: 	at com.google.devtools.build.lib.rules.objc.CompilationSupport.compile(CompilationSupport.java:319)
Step #3: 	at com.google.devtools.build.lib.rules.objc.CompilationSupport.ccCompileAndLink(CompilationSupport.java:396)
````

[Full stack trace](https://gist.github.com/hildrum/79ba0ad703129b63d5a7514bc77d2798)

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

`gcloud builds submit --config=config.yaml --no-source`
where config.yaml is:
````
steps:
- name: 'gcr.io/cloud-builders/git'
  args: ['clone', '--recursive', 'https://bazel.googlesource.com/bazel']
  dir: '/workspace/'
- name: 'gcr.io/cloud-builders/git'
  args: ['fetch', 'https://bazel.googlesource.com/bazel', '4d8aaf9c6c1bbd485e520b8ff56d3489d093b300']
  dir: '/workspace/bazel'
- name: 'gcr.io/cloud-builders/git'
  args: ['reset', '--hard', '4d8aaf9c6c1bbd485e520b8ff56d3489d093b300']
  dir: '/workspace/bazel'
- name: 'gcr.io/cloud-builders/bazel'
  args: ['-c', 'bazel --host_jvm_args=-Dbazel.DigestFunction=SHA256 build --auth_enabled --tls_enabled --verbose_failures --keep_going -- ... -//kythe/... || 
true']
  dir: '/workspace/bazel'
  entrypoint: 'bash'
````

### What operating system are you running Bazel on?

Running via cloud build, so Ubunto

### What's the output of `bazel info release`?

That's not easy to run the way I'm running this.

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

That's not easy to get the way I'm running this.

###  Have you found anything relevant by searching the web?

No.

### Any other information, logs, or outputs that you want to share?

Problem started between Sept. 16th 2pm and Sept. 17th 2pm.  My bazel builds of tensorflow are also failing at the same point: ([tensorflow config file](https://gist.github.com/hildrum/a8dc3e71dcb77790b1eca76f90ad74fc)).  

My builds of kubernetes (configured the same way, with [kubernetes config file](https://gist.github.com/hildrum/4353ec706b358eba5938ace295fe2d4b)) are successful.

",Can you provide us with a series of `git clone` steps and `bazel build` commands that reproduce the problem?,"The problem seems to be with the bazel in the docker image gcr.io/cloud-builders/bazel.  That version of bazel is release 0.17.1.   (Found by adding a build step that does `bazel info release`.) 

As it happens, 0.17.1 is what I have installed on my local machine, so I can easily provide reproduction instructions that don't use cloud build.
````
git clone https://github.com/bazelbuild/bazel.git
cd bazel
bazel build ... --keep_going
````

If it's confusing that bazel is both the build system and the thing being built, use tensorflow as your reproduction example:
````
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
bazel build ... --keep_going
````"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/6158,"### Description of the problem / feature request:

The following program hard crashes bazel:
Source from: https://github.com/endobson/yaspl2/tree/broken-filetype
```
$ ~/proj/bazel/bazel-bin/src/bazel test //... --incompatible_disallow_filetype
Starting local Bazel server and connecting to it...
Loading: 
Loading: 0 packages loaded
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:7:24: FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:8:23: FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:231:17: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 228
		attr.label(mandatory = True, single_file = Tr..., ...)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 231, in attr.label
		racket_src_file_type
name 'racket_src_file_type' is not defined
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:252:17: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 251
		attr.label_list(allow_files = racket_src_file_ty..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 252, in attr.label_list
		racket_src_file_type
name 'racket_src_file_type' is not defined
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:282:17: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 281
		attr.label_list(allow_files = racket_src_file_ty..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 282, in attr.label_list
		racket_src_file_type
name 'racket_src_file_type' is not defined
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:315:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 311
		rule(implementation = _bin_impl, test =..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 315, in rule
		_racket_bin_attrs
name '_racket_bin_attrs' is not defined (did you mean '_racket_bundle_attrs'?)
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:321:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 318
		rule(implementation = _bin_impl, execut..., ...)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 321, in rule
		_racket_bin_attrs
name '_racket_bin_attrs' is not defined (did you mean '_racket_bundle_attrs'?)
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:329:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 324
		rule(implementation = _lib_impl, output...""}, ...)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 329, in rule
		_racket_lib_attrs
name '_racket_lib_attrs' is not defined
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:337:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 332
		rule(implementation = _bootstrap_lib_..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 337, in rule
		_racket_bootstrap_lib_attrs
name '_racket_bootstrap_lib_attrs' is not defined
ERROR: error loading package 'bootstrap': Extension file 'racket.bzl' has errors
ERROR: /Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl:33:19: Traceback (most recent call last):
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 25
		rule(implementation = _bin_impl, output...""}, <2 more arguments>)
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 32, in rule
		attr.label_list(allow_files = FileType(["".prim""]..., <2 more arguments>)
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 33, in attr.label_list
		FileType(["".prim""])
FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: /Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl:71:19: Traceback (most recent call last):
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 64
		rule(implementation = _lib_impl, output...""}, ..."")})
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 70, in rule
		attr.label_list(allow_files = FileType(["".prim""]..., <2 more arguments>)
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 71, in attr.label_list
		FileType(["".prim""])
FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: error loading package 'libraries/yaspl/runtime': Extension file 'libraries/prim-language/prim-language.bzl' has errors
ERROR: error loading package 'tools': Extension file 'racket.bzl' has errors
ERROR: error loading package 'libraries/prim-language/examples': Extension file 'libraries/prim-language/prim-language.bzl' has errors
Internal error thrown during build. Printing stack trace: java.lang.IllegalStateException
	at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
	at com.google.devtools.build.lib.skyframe.SkyframeExecutor.loadTargetPatterns(SkyframeExecutor.java:2286)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.evaluateTargetPatterns(AnalysisPhaseRunner.java:170)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:85)
	at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:143)
	at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:253)
	at com.google.devtools.build.lib.runtime.commands.TestCommand.doTest(TestCommand.java:126)
	at com.google.devtools.build.lib.runtime.commands.TestCommand.exec(TestCommand.java:106)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:484)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:204)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:870)
	at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:111)
	at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:939)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

INFO: Elapsed time: 1.206s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (12 packages loaded)
java.lang.IllegalStateException
	at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
	at com.google.devtools.build.lib.skyframe.SkyframeExecutor.loadTargetPatterns(SkyframeExecutor.java:2286)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.evaluateTargetPatterns(AnalysisPhaseRunner.java:170)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:85)
	at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:143)
	at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:253)
	at com.google.devtools.build.lib.runtime.commands.TestCommand.doTest(TestCommand.java:126)
	at com.google.devtools.build.lib.runtime.commands.TestCommand.exec(TestCommand.java:106)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:484)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:204)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:870)
	at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:111)
	at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:939)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
java.lang.IllegalStateException
	at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
	at com.google.devtools.build.lib.skyframe.SkyframeExecutor.loadTargetPatterns(SkyframeExecutor.java:2286)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.evaluateTargetPatterns(AnalysisPhaseRunner.java:170)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:85)
	at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:143)
	at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:253)
	at com.google.devtools.build.lib.runtime.commands.TestCommand.doTest(TestCommand.java:126)
	at com.google.devtools.build.lib.runtime.commands.TestCommand.exec(TestCommand.java:106)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:484)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:204)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:870)
	at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:111)
	at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:939)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
FAILED: Build did NOT complete successfully (12 packages loaded)
```

### What operating system are you running Bazel on?

macOS 

### What's the output of `bazel info release`?

development version

### If `bazel info release` returns ""development version"" or ""(@non-git)"", tell us how you built Bazel.

From tip of master

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

https://github.com/bazelbuild/bazel.git
eb817074c25ec49585152e9f01ff37dad8e03094
eb817074c25ec49585152e9f01ff37dad8e03094
","Can you tell me if you can reproduce the crash with Bazel 0.18?
If so, does it crash also with `bazel build --nobuild //... --incompatible_disallow_filetype`?","The missing input file is because you need need to prebuild the compiler via `scripts/prebuild-binaries.sh` or build with `--define yaspl_bootstrap=true` to actually build the main compiler using the bootstrap compiler. My bad for missing that in the instructions.

It looks like it is still broken with 0.18.0.

```
$ ~/proj/bazel-release/bazel-0.18.0-darwin-x86_64  build --nobuild //... --incompatible_disallow_filetype --define yaspl_bootstrap=true

Starting local Bazel server and connecting to it...
Loading: 
Loading: 0 packages loaded
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:7:24: FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:8:23: FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:231:17: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 228
		attr.label(mandatory = True, single_file = Tr..., ...)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 231, in attr.label
		racket_src_file_type
name 'racket_src_file_type' is not defined
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:252:17: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 251
		attr.label_list(allow_files = racket_src_file_ty..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 252, in attr.label_list
		racket_src_file_type
name 'racket_src_file_type' is not defined
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:282:17: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 281
		attr.label_list(allow_files = racket_src_file_ty..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 282, in attr.label_list
		racket_src_file_type
name 'racket_src_file_type' is not defined
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:315:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 311
		rule(implementation = _bin_impl, test =..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 315, in rule
		_racket_bin_attrs
name '_racket_bin_attrs' is not defined (did you mean '_racket_bundle_attrs'?)
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:321:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 318
		rule(implementation = _bin_impl, execut..., ...)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 321, in rule
		_racket_bin_attrs
name '_racket_bin_attrs' is not defined (did you mean '_racket_bundle_attrs'?)
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:329:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 324
		rule(implementation = _lib_impl, output...""}, ...)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 329, in rule
		_racket_lib_attrs
name '_racket_lib_attrs' is not defined
ERROR: /Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl:33:19: Traceback (most recent call last):
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 25
		rule(implementation = _bin_impl, output...""}, <2 more arguments>)
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 32, in rule
		attr.label_list(allow_files = FileType(["".prim""]..., <2 more arguments>)
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 33, in attr.label_list
		FileType(["".prim""])
FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: /Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl:71:19: Traceback (most recent call last):
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 64
		rule(implementation = _lib_impl, output...""}, ..."")})
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 70, in rule
		attr.label_list(allow_files = FileType(["".prim""]..., <2 more arguments>)
	File ""/Users/endobson/proj/racket/yaspl2/libraries/prim-language/prim-language.bzl"", line 71, in attr.label_list
		FileType(["".prim""])
FileType function is not available. You may use a list of strings instead. You can temporarily reenable the function by passing the flag --incompatible_disallow_filetype=false
ERROR: /private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl:337:11: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 332
		rule(implementation = _bootstrap_lib_..., <2 more arguments>)
	File ""/private/var/tmp/_bazel_endobson/f851d7f6c7010ae7d7a3db153bed36de/external/minimal_racket/racket.bzl"", line 337, in rule
		_racket_bootstrap_lib_attrs
name '_racket_bootstrap_lib_attrs' is not defined
ERROR: error loading package 'bootstrap': Extension file 'racket.bzl' has errors
ERROR: error loading package 'tools': Extension file 'racket.bzl' has errors
ERROR: error loading package 'libraries/prim-language/examples': Extension file 'libraries/prim-language/prim-language.bzl' has errors
ERROR: error loading package 'libraries/yaspl/runtime': Extension file 'libraries/prim-language/prim-language.bzl' has errors
Internal error thrown during build. Printing stack trace: java.lang.IllegalStateException
	at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
	at com.google.devtools.build.lib.skyframe.SkyframeExecutor.loadTargetPatterns(SkyframeExecutor.java:2286)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.evaluateTargetPatterns(AnalysisPhaseRunner.java:170)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:85)
	at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:143)
	at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:253)
	at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:83)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:484)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:204)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:870)
	at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:111)
	at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:939)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)

INFO: Elapsed time: 1.174s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (12 packages loaded)
java.lang.IllegalStateException
	at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
	at com.google.devtools.build.lib.skyframe.SkyframeExecutor.loadTargetPatterns(SkyframeExecutor.java:2286)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.evaluateTargetPatterns(AnalysisPhaseRunner.java:170)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:85)
	at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:143)
	at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:253)
	at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:83)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:484)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:204)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:870)
	at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:111)
	at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:939)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
java.lang.IllegalStateException
	at com.google.common.base.Preconditions.checkState(Preconditions.java:491)
	at com.google.devtools.build.lib.skyframe.SkyframeExecutor.loadTargetPatterns(SkyframeExecutor.java:2286)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.evaluateTargetPatterns(AnalysisPhaseRunner.java:170)
	at com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:85)
	at com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:143)
	at com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:253)
	at com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:83)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:484)
	at com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:204)
	at com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:870)
	at com.google.devtools.build.lib.server.GrpcServerImpl.access$2100(GrpcServerImpl.java:111)
	at com.google.devtools.build.lib.server.GrpcServerImpl$2.lambda$run$0(GrpcServerImpl.java:939)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
FAILED: Build did NOT complete successfully (12 packages loaded)
```
"
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/5966,"### Description of the problem / feature request:

I am building Tensorflow using Bazel on Windows, the compiler is VS2015(msvc), I want to pass some custom compile options using --copt, but it does't work. However, --linkopt options can be passed to bazel command and take effect.

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.
Executing the following bazel command, and I got the warning:
bazel --output_user_root=${TMPDIR} build **-c dbg --copt=/Ob2** --copt=/arch:AVX -s --strip=never --linkopt=/DEBUG:NONE tensorflow:libtensorflow.so

cl : Command line warning D9024 : unrecognized source file type 'C:/tools/msys64/Ob2', object file assumed
cl : Command line warning D9027 : source file 'C:/tools/msys64/Ob2' ignored

Is there any way for me to pass custom msvc compile options to bazel? 

By the way, when I build on debug mode, bazel seems to hava default link options with /DEBUG:FULL /INCREMENTAL:NO, but I want the --linkopt=/DEBUG:NONE, although it can be passed to bazel command, but my option added seems to be overwritten by the default link option of dbg, how can I solve this problem?

### What operating system are you running Bazel on?

Windows 10 64bit

### What's the output of `bazel info release`?
release 0.15.2","Why do you need to build in dbg mode if you don't want the pdb file?
If you build in opt mode with `-c opt`, it will use `/DEBUG:NONE`.",
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/5907,"When I use Bazel 0.15.2 to rebuild Bazel I got this error sometimes:
```
ERROR: C:/tools/msys64/home/pcloudy/workspace/bazel/src/main/java/com/google/devtools/build/skyframe/BUILD:25:1: Building src/main/java/com/google/devtools/build/skyframe/libskyframe.jar (72 source files) and running annotation processors (AutoCodecProcessor, OptionProcessor) failed (Exit 1): java.exe failed: error executing command
  cd C:/users/pcloudy/_bazel_pcloudy/3uxo2r6v/execroot/io_bazel
  SET LC_CTYPE=en_US.UTF-8
  external/embedded_jdk/bin/java.exe -Xbootclasspath/p:external/bazel_tools/third_party/java/jdk/langtools/javac-9+181-r4173-1.jar -jar external/bazel_tools/tools/jdk/JavaBuilder_deploy.jar @bazel-out/x64_windows-fastbuild/bin/src/main/java/com/google/devtools/build/skyframe/libskyframe.jar-2.params
java.io.IOException: Cannot clean 'bazel-out\x64_windows-fastbuild\bin\src\main\java\com\google\devtools\build\skyframe\_javac\skyframe\libskyframe_classes'
        at com.google.devtools.build.buildjar.SimpleJavaLibraryBuilder.cleanupDirectory(SimpleJavaLibraryBuilder.java:91)
        at com.google.devtools.build.buildjar.SimpleJavaLibraryBuilder.prepareSourceCompilation(SimpleJavaLibraryBuilder.java:53)
        at com.google.devtools.build.buildjar.SimpleJavaLibraryBuilder.compileJavaLibrary(SimpleJavaLibraryBuilder.java:113)
        at com.google.devtools.build.buildjar.SimpleJavaLibraryBuilder.run(SimpleJavaLibraryBuilder.java:132)
        at com.google.devtools.build.buildjar.BazelJavaBuilder.processRequest(BazelJavaBuilder.java:105)
        at com.google.devtools.build.buildjar.BazelJavaBuilder.runPersistentWorker(BazelJavaBuilder.java:67)
        at com.google.devtools.build.buildjar.BazelJavaBuilder.main(BazelJavaBuilder.java:45)
Caused by: java.nio.file.DirectoryNotEmptyException: bazel-out\x64_windows-fastbuild\bin\src\main\java\com\google\devtools\build\skyframe\_javac\skyframe\libskyframe_classes\com\google\devtools\build
        at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:266)
        at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)
        at java.nio.file.Files.delete(Files.java:1126)
        at com.google.devtools.build.buildjar.SimpleJavaLibraryBuilder$1.postVisitDirectory(SimpleJavaLibraryBuilder.java:85)
        at com.google.devtools.build.buildjar.SimpleJavaLibraryBuilder$1.postVisitDirectory(SimpleJavaLibraryBuilder.java:73)
        at java.nio.file.Files.walkFileTree(Files.java:2688)
        at java.nio.file.Files.walkFileTree(Files.java:2742)
        at com.google.devtools.build.buildjar.SimpleJavaLibraryBuilder.cleanupDirectory(SimpleJavaLibraryBuilder.java:71)
        ... 6 more
Target //src:bazel failed to build
INFO: Elapsed time: 36.284s, Critical Path: 14.20s
INFO: 44 processes: 23 local, 21 worker.
FAILED: Build did NOT complete successfully

pcloudy@pcloudy0-w MSYS ~/workspace/bazel
$ bazel clean
Starting local Bazel server and connecting to it...
INFO: Starting clean.
ERROR: C:/users/pcloudy/_bazel_pcloudy/3uxo2r6v/execroot/io_bazel/bazel-out/x64_windows-fastbuild/bin/src/main/java/com/google/devtools/build/lib/remote/blobstore/_javac/blobstore/libblobstore_classes/com/google (Directory not empty)

pcloudy@pcloudy0-w MSYS ~/workspace/bazel
$ ls /c/users/pcloudy/_bazel_pcloudy/3uxo2r6v/execroot/io_bazel/bazel-out/x64_windows-fastbuild/bin/src/main/java/com/google/devtools/build/lib/remote/blobstore/_javac/blobstore/libblobstore_classes/com/google

pcloudy@pcloudy0-w MSYS ~/workspace/bazel
$ bazel clean
INFO: Starting clean.
ERROR: C:/users/pcloudy/_bazel_pcloudy/3uxo2r6v/execroot/io_bazel/bazel-out/x64_windows-fastbuild (Directory not empty)

pcloudy@pcloudy0-w MSYS ~/workspace/bazel
$ bazel clean
INFO: Starting clean.
```

FYI @laszlocsomor ",Does `bazel clean` eventually succeed?,"Yes, it took me three times although."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/5861,"### Description of the problem / feature request:
A fresh copy from master and I am unable to build it.

```
$ bazel build //src:bazel
Starting local Bazel server and connecting to it...
...........
ERROR: /home/stig/.cache/bazel/_bazel_stig/6ca3e3526b8a3784d87f5ed89cfd92bb/external/openjdk_linux/file/BUILD.bazel:2:1: @openjdk_linux//file:file: invalid label 'zulu10.2%2B3-jdk10.0.1-linux_x64-allmodules.tar.gz' in element 0 of attribute 'srcs' in 'filegroup' rule: invalid target name 'zulu10.2%2B3-jdk10.0.1-linux_x64-allmodules.tar.gz': target names may not contain '%'
ERROR: /home/stig/projects/bazel/bazel/src/BUILD:195:1: Target '@openjdk_linux//file:file' contains an error and its package is in error and referenced by '//src:embedded_jdk'
ERROR: Analysis of target '//src:bazel' failed; build aborted: Loading failed
INFO: Elapsed time: 10.529s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (53 packages loaded)
```

### What operating system are you running Bazel on?

Mageia 7 (dev.0) x86_64

### What's the output of `bazel info release`?

```
$ bazel info release
development version
```

### If `bazel info release` returns ""development version"" or ""(@non-git)"", tell us how you built Bazel.

I built the last version from git over a month ago since I've been without internet connection after moving to a new place.

### What's the output of `git remote get-url origin ; git rev-parse master ; git rev-parse HEAD` ?

```
$ git remote get-url origin ; git rev-parse master ; git rev-parse HEAD
https://github.com/bazelbuild/bazel
50af3b73ad40f37ee9f6be989d630d7ae32b4767
50af3b73ad40f37ee9f6be989d630d7ae32b4767
```

",Do you know the commit from which you built your current bazel version?,"Hi.

It's the commit mentioned in the last answer."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/5764,"### Description of the problem / feature request:

When attempting to build Tensorflow version 1.9.0 with Bazel version 0.15.2 on macOS 10.13.6, I receive the following error:

```
ERROR: No default_toolchain found for cpu 'darwin'. Valid cpus are: [
  k8,
  local,
  armeabi-v7a,
  x64_windows,
  x64_windows_msvc,
  x64_windows_msys,
  s390x,
  ios_x86_64,
]
```

Strangely, `darwin` is considered a ""CPU."" More strangely, it's not in the list of supported CPUs! I'm building with this configuration:

```
        # Disable Google Cloud Platform
        export TF_NEED_GCP=0
        # Disable AWS
        export TF_NEED_AWS=0
        # Disable Kafka
        export TF_NEED_KAFKA=0
        # Disable GDR
        export TF_NEED_GDR=0
        # Disable VERBS
        export TF_NEED_VERBS=0
        # Disable OpenCL
        export TF_NEED_OPENCL=0
        # Disable OpenCL SYCL
        export TF_NEED_OPENCL_SYCL=0
        # Disable TensorRT
        export TF_NEED_TENSORRT=0
        # Disable HDFS
        export TF_NEED_HDFS=0
        # Disable XLA
        export TF_ENABLE_XLA=0
        # Disable MPI
        export TF_NEED_MPI=0
        # Disable CUDA
        export TF_NEED_CUDA=0

```

I'm working within the context of a Nix derivation (https://nixos.org/nix/). I'm interested in understanding how Bazel gets this list of ""valid CPUs;"" this same Nix derivation builds TF correctly on Linux, and I'm able to build Bazel itself just fine on macOS. Apologies for the noise if this has nothing to do with Bazel and everything to do with TF's build system.

### What operating system are you running Bazel on?

macOS 10.13.6","Do you have xcode installed? Does `bazel clean --expunge` change anything? Can you upload an archive with files from

    bazel info | grep output_base | awk '{print $2}'`/external/local_config_cc`

Thanks!","Yes, I do have xcode installed, along with the command line tools.

Running `bazel clean --expunge` first doesn't change the output.

The requested archive is attached.

[local_config_cc.zip](https://github.com/bazelbuild/bazel/files/2264757/local_config_cc.zip)

Still curious about how this list gets generated; the docs don't have too much to say about it, but perhaps I'm missing something..."
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/5583,"Passing in a `build_file_contents` causes a debug message from `http_archive` (line 48).  This is used in the Kotlin rules. Is this line still meant to be in there ? 

",What is the debug message you're seeing?,Aah yes. I'm on 0.14.1 at the moment. Thanks !
bazelbuild/bazel,https://github.com/bazelbuild/bazel/issues/5507,"### Description of the problem / feature request:

Build stamp for cpp is not updated even if the binary is recompiled

### Bugs: what's the simplest, easiest way to reproduce this bug? Please provide a minimal example if possible.

```
~/bazeltest (master) $ cat stamp.cc 

extern const char build_scm_revision[];

const char build_scm_revision[] = BUILD_SCM_REVISION;
~/bazeltest (master) $ cat BUILD 
cc_library(
    name = ""stamp"",
    linkstamp = ""stamp.cc""
)

cc_binary(
    name = ""main"",
    srcs = [""main.cc""],
    deps = ["":stamp""],
)
~/bazeltest (master) $ cat main.cc 
#include <stdio.h>

extern const char build_scm_revision[];

int main() {
  printf(""%s\n"", build_scm_revision);
}

~/bazeltest (master) $ cat workspace_status 
echo BUILD_SCM_REVISION  $(git rev-parse HEAD)

~/bazeltest (master) $ bazel  --bazelrc=/dev/null build :main --stamp --workspace_status_command=./workspace_status
INFO: Analysed target //:main (0 packages loaded).
INFO: Found 1 target...
Target //:main up-to-date:
  bazel-bin/main
INFO: Elapsed time: 0.374s, Critical Path: 0.10s
INFO: Build completed successfully, 4 total actions                                                                                                                                                                                
~/bazeltest (master) $ bazel-bin/main                                                                                                                                                                                                                                              
7afdc5db5bdc0f2b99d8d81decaab36828408fbc
```

Then change main.cc to `printf(""Changed %s\n"", build_scm_revision)`, push a commit
```
~/bazeltest (master) $ git rev-parse HEAD
0eca28585c24282ec4b3e326e7fbf5224dc8841e
~/bazeltest (master) $ bazel --bazelrc=/dev/null build :main --stamp --workspace_status_command=./workspace_status 
INFO: Analysed target //:main (0 packages loaded).
INFO: Found 1 target...
Target //:main up-to-date:
  bazel-bin/main
INFO: Elapsed time: 0.187s, Critical Path: 0.01s
INFO: Build completed successfully, 2 total actions
~/bazeltest (master) $ bazel-bin/main
changed 7afdc5db5bdc0f2b99d8d81decaab36828408fbc
```

Expecting new compiled binary has build_scm_revision `0eca28585c24282ec4b3e326e7fbf5224dc8841e`
### What operating system are you running Bazel on?
Linux ubuntu  4.4.0-109-generic

### What's the output of `bazel info release`?

release 0.11.0
","Did you try to 0.15? Link stamps were definitely broken a few months ago, but I think that's all been fixed now.","Thanks, updating version works for me.

BTW, is it possible to force restamp the binary if the head commit changes, even if all dependency is unchanged?
AFIK go rule is using STABLE_BUILD_SCM_REVISION instead of BUILD_SCM_REVISION which can force restamp, can cc_binary configured in this way as well?"
orhanobut/logger,https://github.com/orhanobut/logger/issues/129,"A Long can be `null`:

````java
Long createdAt = null;
Logger.d(createdAt);
````
![screen shot 2017-06-06 at 5 28 28 pm](https://cloud.githubusercontent.com/assets/1480617/26818342/99f8b1a0-4add-11e7-95e7-ae029e77b1d3.png)


Previous work on nullable debug values is in #121.






",Which version are you using?,"Thank you @orhanobut for looking into this - I am using the latest.

````
compile 'com.orhanobut:logger:2.1.0'
````

![screen shot 2017-06-06 at 8 04 43 pm](https://cloud.githubusercontent.com/assets/1480617/26824108/67564026-4af3-11e7-8acf-69e01ed1a758.png)"
orhanobut/logger,https://github.com/orhanobut/logger/issues/36,"I'm getting an issue where, because a lot my classes extend some base class, most of my logs from Logger are reported with the base class name, which is not very helpful.

Please let me know if there's any easy way around this
","Can you show the output and the place that you use logger? Current class should be printed regardless of the super class.
",
orhanobut/logger,https://github.com/orhanobut/logger/issues/17,"I updated to 1.5, in our gradle files (since we need the stack-trace crash fix), but it does not recognise the classes from the library.

Even if I put the `.aar` locally in the project it does not work.

1.4 works perfectly, something wrong with the build that were uploaded to mavenCentral?
","can you clean and sync the gradle again? 1.5 is in maven it seems. https://oss.sonatype.org/content/repositories/releases/com/orhanobut/logger/1.5/
","Yeah, I know, I even downloaded that `.aar` and tried it locally, still nothing, can't recognise the `Logger` class (or `LogLevel`)
"
realm/realm-java,https://github.com/realm/realm-java/issues/6082,"<!---

**Questions**: If you have questions about how to use Realm, ask on
[StackOverflow](http://stackoverflow.com/questions/ask?tags=realm).
We monitor the `realm` tag.

**Feature Request**: Just fill in the first two sections below.

**Bugs**: To help you as fast as possible with an issue please describe your issue
and the steps you have taken to reproduce it in as many details as possible.

-->

#### Goal

On realm-gradle-plugin:5.3.0, the gradle seems to work fine but as I upgrade to realm-gradle-plugin:5.4.0, the build creation is failing.
#### Expected Results

> ?

#### Actual Results

>  org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':sdk:transformClassesWithRealmTransformerForDebug'.
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:100)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:70)
        at org.gradle.api.internal.tasks.execution.OutputDirectoryCreatingTaskExecuter.execute(OutputDirectoryCreatingTaskExecuter.java:51)
        at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62)
        at org.gradle.api.internal.tasks.execution.ResolveTaskOutputCachingStateExecuter.execute(ResolveTaskOutputCachingStateExecuter.java:54)
        at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:60)
        at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:97)
        at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:87)
        at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:52)
        at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)
        at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54)
        at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)
        at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34)
        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.run(DefaultTaskGraphExecuter.java:248)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:199)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:110)
        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:241)
        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:230)
        at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.processTask(DefaultTaskPlanExecutor.java:123)
        at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.access$200(DefaultTaskPlanExecutor.java:79)
        at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:104)
        at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:98)
        at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.execute(DefaultTaskExecutionPlan.java:626)
        at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.executeWithTask(DefaultTaskExecutionPlan.java:581)
        at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.run(DefaultTaskPlanExecutor.java:98)
        at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)
        at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)
        at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)
Caused by: java.lang.NullPointerException
        at io.realm.transformer.Utils.getTargetSdk(Utils.java:67)
        at io.realm.transformer.RealmTransformer.sendAnalytics(RealmTransformer.kt:154)
        at io.realm.transformer.RealmTransformer.exitTransform(RealmTransformer.kt:116)
        at io.realm.transformer.RealmTransformer.transform(RealmTransformer.kt:111)
        at com.android.build.api.transform.Transform.transform(Transform.java:288)
        at com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:221)
        at com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:217)
        at com.android.builder.profile.ThreadRecorder.record(ThreadRecorder.java:102)
        at com.android.build.gradle.internal.pipeline.TransformTask.transform(TransformTask.java:212)
        at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73)
        at org.gradle.api.internal.project.taskfactory.IncrementalTaskAction.doExecute(IncrementalTaskAction.java:46)
        at org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:39)
        at org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:26)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$1.run(ExecuteActionsTaskExecuter.java:121)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:199)
        at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:110)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:110)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:92)
        ... 29 more
#### Steps & Code to Reproduce

> Describe your current debugging efforts.

#### Code Sample

```java

> Your code here. Bigger samples should ideally be as separate Android Studio project, 
> in gists/repositories or privately at help@realm.io)

```

#### Version of Realm and tooling
Realm version(s): ?

Realm sync feature enabled: yes/no

Android Studio version: 3.1.3

Which Android version and device:  
",can you share your Gradle config?,"At project level:
    dependencies {
        classpath 'com.android.tools.build:gradle:3.1.3'
        classpath ""io.realm:realm-gradle-plugin:5.3.0""
    }
At app level:
apply plugin: 'realm-android'

This is building fine. When I change 5.3.0 to 5.4.0, the build error comes about."
realm/realm-java,https://github.com/realm/realm-java/issues/4787,"My app comes with a pre-populated realm file which is stored in res/raw directory. Gradle was working just fine until i decided to open the realm file using realm browser. Now gradle gets stuck at :app:mergeDebugResources.

Usually I would edit the realm file from another directory outside the project directory and copy it over to res/raw directory when I'm done. But this time I opened the realm file stored in the res/raw directory in the project directory.

This is the second time this has happened to me. The first time I had to completely restart the project from scratch and copy code over. Downloading an older commit from GitHub didn't work either.

Has anyone else experienced this? Any fixes?",What is your Realm version?,
realm/realm-java,https://github.com/realm/realm-java/issues/4615,"
```
Compiling with JDK Java compiler API.
Note: Processing class User
Note: Creating DefaultRealmModule
An exception has occurred in the compiler (1.8.0_11). Please file a bug at the Java Developer Connection (http://java.sun.com/webapps/bugreport)  after checking the Bug Parade for duplicates. Include your program and the following diagnostic in your report.  Thank you.
com.sun.tools.javac.code.Symbol$CompletionFailure: class file for rx.Observable not found
:app:compileDebugJavaWithJavac FAILED
:app:compileDebugJavaWithJavac (Thread[Daemon worker Thread 5,5,main]) completed. Took 15.912 secs.

FAILURE: Build failed with an exception.
```
**User class**
```
public class User extends RealmObject {
   @PrimaryKey
   private long id;
   private String username;
}
```
In my Application class, onCreate method.
```
Realm.init(this);
```

Im not able to use the realm java for android. Im not sure if there is conflict between the realm and java 8. Do i need to use different java version?


Realm version(s): 3.1.4

Realm sync feature enabled: no

Android Studio version: 2.3.1

Which Android version and device: Any device
",Can you get us something that will let us see it happen?,
realm/realm-java,https://github.com/realm/realm-java/issues/4328,"there is issue with OrderedRealmCollectionChangeListener and RealmList, when i am adding new item/remove item  to/from the RealmList on the same thread using executeTransaction it take time until the OrderedRealmCollectionChangeListener (that was added to the same list for another instance of the realm list it is ok) get notification about the change, 

from what i checked it is around 10-50 mills, the problem is that the realmList is affected Immediately or after some delay but before the OrderedRealmCollectionChangeListener , so mean while if i am using tools like RecyclerViewAdapter and try to get the list according to the RealmList notification i may access some items that already been deleted, or i can get different items from what the adapter excepted,

realm version in use: 3.0.0",May I know what is your use case for this problem? Is it about drag & drop for RecyclerView?,
jfeinstein10/SlidingMenu,https://github.com/jfeinstein10/SlidingMenu/issues/6,"Would it be possible to provide full Window (including ActionBar) sliding without forking and changing ActionBarSherlock?  This would make integration with existing projects much easier, and will make SlidingMenu significantly easier to maintain.  Currently it points to ABS 4.0.1, which doesn't support Android Jelly Bean.  Maintaining SlidingMenu's custom fork of ABS could get tedious.
","Maybe you should get in touch with Jake Wharton about this?
",
jfeinstein10/SlidingMenu,https://github.com/jfeinstein10/SlidingMenu/issues/2,"Hi! Thanks for great lib! We're using SlidingMenu to build our complex app. When app runs on Galaxy Nexus (stock Android 4.0.4 ROM) menu scrolls very very slow. On other devices (Samsung Galaxy SII, HTC Sensation, LG Optimus One) and emulators with Android 2.2, 2.3.x, 4.1 menu works good. Only Galaxy Nexus has a menu scrolling problem
","Could you send me some more details about this? Are both the above and behind view scrolling slowly? The best thing would be to post a video. Hopefully we can iron this out soon.
","Could you give me you email or send me empty email to gshockv@gmail.com and I'll send screenshots of my layouts (above and behind views)
"
android/plaid,https://github.com/android/plaid/issues/516,"Run the application Click on the item to flash directly  Didn't find class ""io.plaidapp.dribbble.ui.shot.ShotActivity"" ","Did you build this with Android Studio or via the command line? If using AS, please note the minimum supported version is 3.2 (RC3 is available in the beta channel).","well, thanks for your reminder,  My As version is 3.0, this issue could close"
chrisbanes/PhotoView,https://github.com/chrisbanes/PhotoView/issues/243,"it's a new transition animation in Android 5.0. but `PhotoView` will get wrong size when play animation like 
![hhlyt](https://cloud.githubusercontent.com/assets/1080103/6141860/bb14e530-b1e6-11e4-8a21-802256f9d65b.gif)
","Does anyone have an idea?
",
chrisbanes/PhotoView,https://github.com/chrisbanes/PhotoView/issues/126,"FroyoGestureDetector

```
            public boolean onScale(ScaleGestureDetector detector) {
                float scaleFactor = detector.getScaleFactor();

                if(Float.isNaN(scaleFactor) || Float.isInfinite(scaleFactor))
                    return false;
                mListener.onScale(detector.getScaleFactor(),
                        detector.getFocusX(), detector.getFocusY());
                return true;
            }
```
","Can you add some use-case for which is this useful?
Thanks
","Oh ，I am sorry . I just see it now. When I  scale it smaller ,it becomes black . I find  ""scaleFactor"" is Nan. So I add

---

 if(Float.isNaN(scaleFactor) || Float.isInfinite(scaleFactor))
                    return false;   

---
"
chrisbanes/PhotoView,https://github.com/chrisbanes/PhotoView/issues/82,"09-19 17:02:59.664: E/AndroidRuntime(11277): java.lang.ArrayIndexOutOfBoundsException
","How can I get the 1.2.2 version?
> 
> —
> Reply to this email directly or view it on GitHub.
","""That's why I asked you to test it.""
So, where is the dev version to get?
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/1607,"(`[x]` becomes a filled in checkbox, `[ ]` is an empty one)

- [x] I have verified there are [no duplicate active or recent bugs, questions, or requests](https://github.com/afollestad/material-dialogs/issues?q=is%3Aissue+is%3Aclosed)
- [x] I understand that versions below 2.0.0 will no longer be supported for updates.
- [x] I have given my issue a non-generic title.
- [x] I have [read over the documentation](https://github.com/afollestad/material-dialogs/blob/master/README.md) (before asking questions on how to do something).

---

###### Include the following:

 - Material Dialogs version: `2.0.0-alpha10`

Also, please wrap your code with correct syntax highlighting (not just indents).

```kotlin
val dialog = MaterialDialog(this)
            .customView(view = dialogTrainerChange, false)
            .show()
```
 
---

Thanks for your fully convenient library :) 
Recently I try to migrate from `0.9.6.0` to `2.00-alpha` because of proguard issue of previous version. but when I access extension function `customView` of new version, AS says `cannot find declaration to go to`( It's same for all of other extension functions).

My project is in Kotlin version `1.2.70`, AndroidX, gradle `3.2.0-rc03`, tested in AS `3.2-RC02`. I have tried many things like `invalidate and restart`, `rearrange library with restart`, update `AS version`,  `Kotlin version`, `gradle version`.. but I can't figure it out why it happens.

 Any Advise for me? ;(


",Can you try 2.0.0-alpha09? It doesn't have AndroidX but another recent issue has the same problem with 10. ,It resolved. Thanks!
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/1601,"I tried
`implementation 'com.afollestad.material-dialogs:core:2.0.0-alpha09'`
And with 
`maven { url ""https://dl.bintray.com/drummer-aidan/maven/"" }`

Android resource linking failed
Output:  ...\aaa\app\build\intermediates\incremental\mergeDebugResources\merged.dir\values-v28\values-v28.xml:7: error: resource android:attr/dialogCornerRadius not found.
...\aaa\app\build\intermediates\incremental\mergeDebugResources\merged.dir\values-v28\values-v28.xml:11: error: resource android:attr/dialogCornerRadius not found.
...\aaa\app\build\intermediates\incremental\mergeDebugResources\merged.dir\values\values.xml:2008: error: resource android:attr/fontVariationSettings not found.
...\aaa\app\build\intermediates\incremental\mergeDebugResources\merged.dir\values\values.xml:2009: error: resource android:attr/ttcIndex not found.
error: failed linking references.

Command: C:\Users\ricardo\.gradle\caches\transforms-1\files-1.1\aapt2-3.2.0-rc03-4818971-windows.jar\abf80ee89b0310285cdc1df80d21c2e2\aapt2-3.2.0-rc03-4818971-windows\aapt2.exe link -I\
        I:\android.sdk\platforms\android-27\android.jar\
        --manifest\
        ...\aaa\app\build\intermediates\merged_manifests\debug\processDebugManifest\merged\AndroidManifest.xml\
        -o\
        ...\aaa\app\build\intermediates\processed_res\debug\processDebugResources\out\resources-debug.ap_\
        -R\
        @...\aaa\app\build\intermediates\incremental\processDebugResources\resources-list-for-resources-debug.ap_.txt\
        --auto-add-overlay\
        --java\
        ...\aaa\app\build\generated\not_namespaced_r_class_sources\debug\processDebugResources\r\
        --custom-package\
        com.bbb.aaa\
        -0\
        apk\
        --output-text-symbols\
        ...\aaa\app\build\intermediates\symbols\debug\R.txt\
        --no-version-vectors
Daemon:  AAPT2 aapt2-3.2.0-rc03-4818971-windows Daemon #0
",Why was this closed? Is there a fix? I have the same issue.,
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/1304,"Hi,

This is awesome and thank you for your creativity and open source. 

I have a doubt. Is you having any spinner with this library? Normal spinner is isn't good, Or can you suggest any Material library for spinner?
",What do you mean by adapting with it?,
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/1272,"I am getting a crash due to this library for several of my users. Here is the complete stack trace I get in CrshAnalytics.

```
Fatal Exception: java.lang.ArrayIndexOutOfBoundsException: length=125; index=-1
       at android.text.StaticLayout.calculateEllipsis(StaticLayout.java:740)
       at android.text.StaticLayout.out(StaticLayout.java:704)
       at android.text.StaticLayout.generate(StaticLayout.java:410)
       at android.text.StaticLayout.(StaticLayout.java)
       at android.widget.TextView.makeSingleLayout(TextView.java:6299)
       at android.widget.TextView.makeNewLayout(TextView.java:6156)
       at android.widget.TextView.onMeasure(TextView.java:6513)
       at android.view.View.measure(View.java:16820)
       at android.widget.RelativeLayout.measureChildHorizontal(RelativeLayout.java:719)
       at android.widget.RelativeLayout.onMeasure(RelativeLayout.java:455)
       at android.view.View.measure(View.java:16820)
       at android.support.v7.widget.RecyclerView$LayoutManager.measureChildWithMargins(SourceFile:8456)
       at android.support.v7.widget.LinearLayoutManager.layoutChunk(SourceFile:1551)
       at android.support.v7.widget.LinearLayoutManager.fill(SourceFile:1488)
       at android.support.v7.widget.LinearLayoutManager.onLayoutChildren(SourceFile:585)
       at android.support.v7.widget.RecyclerView.dispatchLayoutStep2(SourceFile:3506)
       at android.support.v7.widget.RecyclerView.onMeasure(SourceFile:2969)
       at android.view.View.measure(View.java:16820)
       at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5156)
       at android.widget.FrameLayout.onMeasure(FrameLayout.java:310)
       at android.view.View.measure(View.java:16820)
       at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5156)
       at android.widget.LinearLayout.measureChildBeforeLayout(LinearLayout.java:1404)
       at android.widget.LinearLayout.measureVertical(LinearLayout.java:695)
       at android.widget.LinearLayout.onMeasure(LinearLayout.java:588)
       at android.view.View.measure(View.java:16820)
       at com.afollestad.materialdialogs.internal.MDRootLayout.onMeasure(SourceFile:207)
       at android.view.View.measure(View.java:16820)
       at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5156)
       at android.widget.FrameLayout.onMeasure(FrameLayout.java:310)
       at android.view.View.measure(View.java:16820)
       at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5156)
       at android.widget.LinearLayout.measureChildBeforeLayout(LinearLayout.java:1404)
       at android.widget.LinearLayout.measureVertical(LinearLayout.java:695)
       at android.widget.LinearLayout.onMeasure(LinearLayout.java:588)
       at android.view.View.measure(View.java:16820)
       at android.view.ViewGroup.measureChildWithMargins(ViewGroup.java:5156)
       at android.widget.FrameLayout.onMeasure(FrameLayout.java:310)
       at com.android.internal.policy.impl.PhoneWindow$DecorView.onMeasure(PhoneWindow.java:2294)
       at android.view.View.measure(View.java:16820)
       at android.view.ViewRootImpl.performMeasure(ViewRootImpl.java:1969)
       at android.view.ViewRootImpl.measureHierarchy(ViewRootImpl.java:1162)
       at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:1348)
       at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1049)
       at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:5899)
       at android.view.Choreographer$CallbackRecord.run(Choreographer.java:771)
       at android.view.Choreographer.doCallbacks(Choreographer.java:574)
       at android.view.Choreographer.doFrame(Choreographer.java:544)
       at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:757)
       at android.os.Handler.handleCallback(Handler.java:733)
       at android.os.Handler.dispatchMessage(Handler.java:95)
       at android.os.Looper.loop(Looper.java:149)
       at android.app.ActivityThread.main(ActivityThread.java:5268)
       at java.lang.reflect.Method.invokeNative(Method.java)
       at java.lang.reflect.Method.invoke(Method.java:515)
       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:793)
       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:609)
       at dalvik.system.NativeStart.main(NativeStart.java)
```

Initially, I used to ignore this crash as it didn't happen for many users, but now it has started becoming more frequent. I am already on the latest version of this library.

Any idea on what is wrong here? ","What devices? Samsung devices?

Unfortunately there isn't anything here that makes the cause obvious.","According to CrashAnalytics, these are some of the devices having the issue.

1) ASUS_Z007
2) Lenovo A5500-HV
3) LG-K332
4) Lenovo A6020a40
5) LG-D802
6) HUAWEI Y560-L01
7) Redmi Note 3
8) Lenovo S856

and many more. "
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/1188,"I use this lib in my app from api level 14 to up but in 14 level devices, there is some break line between texts of item and string splite and rest of work goes to next line. in both single choice and multi choice . 
ps: when I scroll the bug disapeard :|
","can you help me what to do to solve it? please answer me because my application is going to publish
",
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/965,"For v.0.8.5.5, at compile time, I get:

> Error:(5, 5) uses-sdk:minSdkVersion 8 cannot be smaller than version 14 declared in library >>[..]/applover-android/library/build/intermediates/exploded-aar/me.zhanghai.android.materialprogressbar/library/1.1.4/AndroidManifest.xml

Is there still a way to keep the minSdkVersion to 8?
","Would someone be willing to dig into that?
",
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/878,"After importing modules core and commons to work on a new pull request, attempting to use any MaterialPreference causes a rendering problem in the xml:

android.view.InflateException: <merge /> can be used only with a valid ViewGroup root and attachToRoot=true

I've imported material-dialogs before and it worked fine so I'm not sure why it's not working now.
","Can you comment with the actual stack trace so I can find the line number?
","Well when I loaded it up this morning it began working fine and I've been unable to reproduce the issue. The error must have been on my end so I'm closing this issue for now.
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/822,"Hi, im trying to compile the lib and got the **following error:**

```
Information:Gradle tasks [:DoToDoSenderApp:assembleDebug]
Error:A problem occurred configuring project ':DoToDoSenderApp'.
> Could not resolve all dependencies for configuration ':DoToDoSenderApp:_debugCompile'.
> Could not find com.github.afollestad.material-dialogs:core:0.8.5.0.
Searched in the following locations:
https://jcenter.bintray.com/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.pom
https://jcenter.bintray.com/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.aar
https://repo1.maven.org/maven2/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.pom
https://repo1.maven.org/maven2/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.aar
file:/C:/Users/Joying/AppData/Local/Android/sdk/extras/android/m2repository/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.pom
file:/C:/Users/Joying/AppData/Local/Android/sdk/extras/android/m2repository/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.aar
file:/C:/Users/Joying/AppData/Local/Android/sdk/extras/google/m2repository/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.pom
file:/C:/Users/Joying/AppData/Local/Android/sdk/extras/google/m2repository/com/github/afollestad/material-dialogs/core/0.8.5.0/core-0.8.5.0.aar
Required by:
DoToDo_as:DoToDoSenderApp:unspecified > DoToDo_as:DoToDoEssentials:unspecified
Information:BUILD FAILED
Information:Total time: 2.98 secs
Information:1 error
Information:0 warnings
Information:See complete output in console
```

This is **my gradle file:**

```
apply plugin: 'com.android.library'

android {
compileSdkVersion 23
buildToolsVersion ""23.0.1""

defaultConfig {
    minSdkVersion 19
    targetSdkVersion 22
    versionCode 1
    versionName ""1.0""
    multiDexEnabled true
}
buildTypes {
    release {
    minifyEnabled false
    proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
    }
}
}
repositories {
mavenCentral()
maven { url ""https://jitpack.io"" }
}

dependencies {

compile 'com.android.support:appcompat-v7:23.+' //appcompat for navigation drawer
compile 'com.android.support:design:23.+' //views
compile 'com.android.support:support-v13:23.+' //views


compile 'com.google.android.gms:play-services-gcm:8.1.0' //google gcm pushes
compile 'com.google.android.gms:play-services-location:8.1.0' //google location functions
compile 'com.google.android.gms:play-services-maps:8.1.0' //google maps


compile 'com.facebook.android:facebook-android-sdk:4.6.0' //facebook lib
compile 'de.hdodenhof:circleimageview:2.0.0' //circle image view
compile 'com.squareup.picasso:picasso:2.5.2' //image downloader lib
compile 'com.google.code.gson:gson:2.4' //gson for serialization
compile 'com.squareup.okio:okio:1.6.0'  //okhttp dependency
compile 'com.squareup.okhttp:okhttp:2.5.0'   //networking lib
compile 'com.googlecode.libphonenumber:libphonenumber:5.5' //phone number library


compile('com.github.afollestad.material-dialogs:core:0.8.5.0@aar') {
    transitive = true
}


compile fileTree(dir: 'libs', include: ['*.jar'])
}
```

**I have added**

```
maven { url ""https://jitpack.io"" } 
```

**as well as**

```
compile('com.github.afollestad.material-dialogs:core:0.8.5.0@aar') {
    transitive = true
}
```

(Gradle is in online mode)

What m i missin here, can you help me out?
","Do you realize there was literally just two duplicate issues with the same problem?
","At the time i posted there was 0 duplicates, and now also zero topics open about this problem.
I will report to jitpack.
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/775,"We have a style to our Toolbar and I'm not able to style the tool bar so it matches. 
if there is answer please reply here:
http://stackoverflow.com/questions/33130136/custom-actionmode-bar-and-material-dialog-show-different
","Do you remember, @plusCubed?
","Thanks for the tip it worked from v19 up @afollestad  and @plusCubed 
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/697,"I don't think setting up gradle with commons module works.

``` java
dependencies {
    compile 'com.afollestad.material-dialogs:commons:0.8.0.0@aar'
}
```
","How did you guys figure this out? I can't get this to work...
",
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/628,"Ever since I updated from an older version (0.6.7.4) to the newest one in gradle (0.7.6.0), I've been getting a problem launching a dialog with my custom view. It works fine on the old version, and the minute I update my gradle, the dialog refuses to display and my app freezes.

Here is the code I'm using to inflate and launch the dialog:

``` Java
final View dialogView = getLayoutInflater().inflate(R.layout.customview, 
    (ViewGroup) v.getParent(), false);
final MaterialDialog mdb = new MaterialDialog.Builder(getActivity())
                    .customView(dialogView, false)
                    .negativeText(R.string.dialog_cancel)
                    .cancelable(false)
                    .title(dialogTitle)
                    .build();
// Some code here to initialize elements
mdb.show();
```

And this is the stacktrace:

``` Java
07-25 16:36:26.667  16334-16334/com.mrkhozam.myapp W/System.err﹕ java.lang.NullPointerException: Attempt to invoke virtual method 'int android.support.v7.widget.RecyclerView$Adapter.getItemCount()' on a null object reference
07-25 16:36:26.668  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.afollestad.materialdialogs.internal.MDRootLayout.canRecyclerViewScroll(MDRootLayout.java:489)
07-25 16:36:26.669  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.afollestad.materialdialogs.internal.MDRootLayout.setUpDividersVisibility(MDRootLayout.java:412)
07-25 16:36:26.669  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.afollestad.materialdialogs.internal.MDRootLayout.setUpDividersVisibility(MDRootLayout.java:419)
07-25 16:36:26.669  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.afollestad.materialdialogs.internal.MDRootLayout.setUpDividersVisibility(MDRootLayout.java:422)
07-25 16:36:26.670  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.afollestad.materialdialogs.internal.MDRootLayout.setUpDividersVisibility(MDRootLayout.java:419)
07-25 16:36:26.670  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.afollestad.materialdialogs.internal.MDRootLayout.onLayout(MDRootLayout.java:343)
07-25 16:36:26.670  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.View.layout(View.java:15678)
07-25 16:36:26.670  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewGroup.layout(ViewGroup.java:5039)
07-25 16:36:26.670  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.widget.FrameLayout.layoutChildren(FrameLayout.java:579)
07-25 16:36:26.675  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.widget.FrameLayout.onLayout(FrameLayout.java:514)
07-25 16:36:26.675  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.View.layout(View.java:15678)
07-25 16:36:26.675  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewGroup.layout(ViewGroup.java:5039)
07-25 16:36:26.676  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.widget.LinearLayout.setChildFrame(LinearLayout.java:1703)
07-25 16:36:26.676  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.widget.LinearLayout.layoutVertical(LinearLayout.java:1557)
07-25 16:36:26.676  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.widget.LinearLayout.onLayout(LinearLayout.java:1466)
07-25 16:36:26.678  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.View.layout(View.java:15678)
07-25 16:36:26.678  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewGroup.layout(ViewGroup.java:5039)
07-25 16:36:26.678  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.widget.FrameLayout.layoutChildren(FrameLayout.java:579)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.widget.FrameLayout.onLayout(FrameLayout.java:514)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.View.layout(View.java:15678)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewGroup.layout(ViewGroup.java:5039)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewRootImpl.performLayout(ViewRootImpl.java:2086)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:1843)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1061)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:5891)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.Choreographer$CallbackRecord.run(Choreographer.java:767)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.Choreographer.doCallbacks(Choreographer.java:580)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.Choreographer.doFrame(Choreographer.java:550)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:753)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.os.Handler.handleCallback(Handler.java:739)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.os.Handler.dispatchMessage(Handler.java:95)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.os.Looper.loop(Looper.java:135)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at android.app.ActivityThread.main(ActivityThread.java:5289)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at java.lang.reflect.Method.invoke(Native Method)
07-25 16:36:26.679  16334-16334/com.mrkhozam.myapp W/System.err﹕ at java.lang.reflect.Method.invoke(Method.java:372)
07-25 16:36:26.682  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:904)
07-25 16:36:26.682  16334-16334/com.mrkhozam.myapp W/System.err﹕ at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:699)
```

It's possible that something in the updated API version has a bug with RecyclerView?

Thank you for this brilliant mod.
","Does your custom layout have a RecyclerView in it? It looks like the library is trying to check if your RecyclerView is empty or not but there's no adapter attached to it. 
","My mistake about the latest version. I just updated gradle with it, but it still produces the same error.

After seeing your insight, I tried setting an empty adapter (which is weird because I still set the dataset object to null) right after initializing the RecyclerView, like so:

``` Java
mRecyclerViewMyList = (RecyclerView) dialogView.findViewById(R.id.mylist);
mRecyclerViewMyList.setLayoutManager(new LinearLayoutManager(getActivity()));
mAdapterMyList = new MyListAdapter(null, R.layout.mylist_row, getActivity());
```

And sure enough, this solved the problem. I apologize for the bother, but I never thought I had to set an adapter right after I inflate a RecyclerView. Usually since I have multiple conditions to check before doing so, I never set an empty adapter.
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/616,"Hey! Your Material Dialog is working awesome, but I just need a little help. I am trying to get the text from my EditText within a custom layout I use for the dialog, butI keep getting the following error:
    java.lang.NullPointerException: Attempt to invoke virtual method 'android.text.Editable android.widget.EditText.getText()' on a null object reference
            at owensetiawan.friendlymatch.todolist.MainActivity$1.onPositive(MainActivity.java:94)
            at com.afollestad.materialdialogs.MaterialDialog.onClick(MaterialDialog.java:321)
This is my dialog code:
public void addNote(View view) {
        EditText editTitle, editContent;

```
    taskTitleText = """";
    taskContentText = """";
    // Creates dialog for creating a new task
    MaterialDialog dialog = new MaterialDialog.Builder(this)
            .title(""Add Note"")
            .customView(R.layout.activity_add_screen, false)
            .positiveText(""Create"")
            .negativeText(""Can't remember"")
            .callback(new MaterialDialog.ButtonCallback() {
                @Override
                public void onPositive(MaterialDialog dialog) {


                    // Creates a new Info item for the note
                    Info dialogInfo = new Info();
                    dialogInfo.setTitle(taskTitleText);
                    dialogInfo.setContent(taskContentText);

                    tasks.add(dialogInfo);
                    adapter.notifyDataSetChanged();
                }
            })
            .build();

    editTitle = (EditText)dialog.getCustomView().findViewById(R.id.noteTitle);
    editContent = (EditText)dialog.getCustomView().findViewById(R.id.noteContent);

    editTitle.addTextChangedListener(new TextWatcher() {
        @Override
        public void beforeTextChanged(CharSequence s, int start, int count, int after) {
        }

        @Override
        public void onTextChanged(CharSequence s, int start, int before, int count) {
            taskTitleText = s.toString();
            positiveButton.setEnabled(taskTitleText.trim().length() > 0);
        }

        @Override
        public void afterTextChanged(Editable s) {
        }
    });
    editContent.addTextChangedListener(new TextWatcher() {
        @Override
        public void beforeTextChanged(CharSequence s, int start, int count, int after) {
        }

        @Override
        public void onTextChanged(CharSequence s, int start, int before, int count) {
            taskContentText = s.toString();
            positiveButton.setEnabled(true);
        }

        @Override
        public void afterTextChanged(Editable s) {
        }
    });

    // To access your database, instantiate your subclass of SQLiteOpenHelper:
    TaskDBHelper dbHelper = new TaskDBHelper(MainActivity.this);
    // Gets the data repository in write mode
    SQLiteDatabase db = dbHelper.getWritableDatabase();
    ContentValues contentValues = new ContentValues();
    contentValues.put(TaskContract.Columns.NOTE_TITLE, taskTitleText);
    contentValues.put(TaskContract.Columns.NOTE_CONTENT, taskContentText);

    db.insertWithOnConflict(TaskContract.TABLE, null, contentValues, SQLiteDatabase.CONFLICT_IGNORE);

    updateUI();
    dialog.show();
    positiveButton.setEnabled(false);
}
```

Any help would be awesome!
","Why are you creating a Dialog Into instance?
",
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/569,"The progressbar widget does not move at all when I set .progress(true, 0) it just shows the widget. Is there anyway to resolve this right now? I can change my accentColor fine but cannot seem to get indeterminate to work, do I have to set the animation myself?
","What Android version?
","5.1.1 Nexus 6, it just sits there and does nothing, very strange. I was thinking it may be the device if anything but not sure how to resolve the issue.
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/482,"When using a custom view combined with items, I get a crash. Without the customView everything is fine.

``` java
    new MaterialDialog.Builder(getActivity())
        .title(R.string.pref_support_title)
        .items(R.array.pref_support_values)
        .customView(new EditText(getActivity()), true)
        .show();
```

``` groovy
    java.lang.NullPointerException: Attempt to invoke virtual method 'void  android.widget.ListView.setAdapter(android.widget.ListAdapter)' on a null object reference
            at com.afollestad.materialdialogs.MaterialDialog.invalidateList(MaterialDialog.java:146)
            at com.afollestad.materialdialogs.DialogInit.init(DialogInit.java:330)
            at com.afollestad.materialdialogs.MaterialDialog.<init>(MaterialDialog.java:84)
            at com.afollestad.materialdialogs.MaterialDialog$Builder.build(MaterialDialog.java:1031)
            at com.afollestad.materialdialogs.MaterialDialog$Builder.show(MaterialDialog.java:1035)
            at de.ph1b.audiobook.fragment.SettingsFragment$2.onPreferenceClick(SettingsFragment.java:109)
            at android.preference.Preference.performClick(Preference.java:985)
            at android.preference.PreferenceScreen.onItemClick(PreferenceScreen.java:214)
            at android.widget.AdapterView.performItemClick(AdapterView.java:305)
            at android.widget.AbsListView.performItemClick(AbsListView.java:1148)
            at android.widget.AbsListView$PerformClick.run(AbsListView.java:3059)
            at android.widget.AbsListView$3.run(AbsListView.java:3866)
            at android.os.Handler.handleCallback(Handler.java:739)
            at android.os.Handler.dispatchMessage(Handler.java:95)
            at android.os.Looper.loop(Looper.java:135)
            at android.app.ActivityThread.main(ActivityThread.java:5293)
            at java.lang.reflect.Method.invoke(Native Method)
            at java.lang.reflect.Method.invoke(Method.java:372)
            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:904)
            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:699)
```
","Why?
","Thats a placeholder. I always make a stub to see if the base works. (which didn't ;-)
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/399,"This can be seen by scrolling the Custom View demo - even though it's a Light dialog, the overscroll effects are white instead of gray (it thinks it has a dark theme). After messing around a bit, it seems to be caused by the android.app.Dialog superclass creating a new ContextThemeWrapper not using the MD_Dark or MD_Light theme.
","Can you check if this fixes it? https://github.com/afollestad/material-dialogs/commit/33a400604147a373fc6eccdd65f41fa9bd29a147

I have to go to class, but I'll get back to this later.
","Huh, it seems to fix it, but now the dialog width and some padding is messed up.
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/272,,"Do you have sample code to reproduce? (and the device/screen size/dpi you're testing against).

Just taking a quick look, 81197a67 seemed to add conditional titlebar padding, I'd guess that it needs similar constraints as the bottom margin in setDividerVisibility (""Only enable the bottom margin if our available window space can hold the margin"")

The conditional padding is a pain. A custom root view that does the measures and applies the padding might be easier to maintain than having callbacks and checks in the Dialog, this might also help with the slow remeasure/relayouts as we should be able to do it in one pass, whereas it seem something is taking multiple passes here.
","Well at the moment, it's noticeable with the library's sample project (the folder chooser).

It feels very laggy, and if the title divider appears for the first time it pushes the content down after 1-2 seconds.
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/251,"Hello,

I'm just trying out your new MaterialListPreference, as always it works as expected, but I miss something.  There is no support for default value to be marked on the list that shows up when using MaterialListPreference. If you need help I could have a further look at the code and do a PR.

Thanks in advanced.
","Maybe we can use itemsCallbackSingleChoice instead of itemsCallback?
Additional upside would be show radio buttons just like in Lollipop's ListPreference.
",
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/223,"When you select positive button its focusing on negative button, leading to some bad UX.
","How often would that be an issue though? Generally a dialog should be dismissed when the positive action button is pressed.
","Irrespective of dialog. As a button, it should not focus another when clicking on that right ?
"
afollestad/material-dialogs,https://github.com/afollestad/material-dialogs/issues/154,"Hi I noticed that using many items in  multi choice dialog, due to of recycle of views, items that aren't checked by the user seem checked, instead the callback works great.
","Can you clarify?
","Yes.. I have a list of 30 items .. I check only the first item, but scrolling the list, also elements 10 , 19 , 28 are apparently checked. But the callback get only the first item and this is correct. I believe is the recycle of view that cause this error.
"
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1541,"Hi.

Recently, I need to know is circuit breaker is half-opened? can I execute command? 
```
  @Test
  public void can_read_state_of_HALF_OPEN() {
    String commandKey = ""test444""; 
    executeBeforeCircuiteOpenLimit(commandKey); // 
    {
      waitHealthUpdate();
      CommandHelloWorld cmd = new CommandHelloWorld(commandKey, true); <- when second arg is true, throw execption
      assertFalse(cmd.isCircuitBreakerOpen());
      try {
        // over 50% error!!
        cmd.execute();
        fail(""Must throw exception"");
      } catch (HystrixRuntimeException ex) {
        // ok, circuit is opened! 
      }
      waitHealthUpdate();
      assertTrue(""Error ratio is over 50%, circuit must be opened"", cmd.isCircuitBreakerOpen());
      {
        CommandHelloWorld cmdAllowRequest = new CommandHelloWorld(commandKey, true);
        assertFalse(""When circuit is opened, not allow request"", cmdAllowRequest.allowRequest());
      }
    }

    {
      waitSleepTime();
      waitHealthUpdate();
      CommandHelloWorld cmd = new CommandHelloWorld(commandKey, false);

      assertTrue(""Over sleep time, but no request tried, no status change. So circuit status is opened, too"", cmd.isCircuitBreakerOpen());
      /* CHECK ALLOW */ assertTrue(""But over sleep time, circuit is half opened, must allow request "", cmd.allowRequest());

      
    }
    
    { 
      CommandHelloWorld cmd = new CommandHelloWorld(commandKey, false); <- when second arg is false, not throw execption, success
     /* HERE */  cmd.execute();

      assertFalse(""over sleep, first request is succcees, circut status must be  changed"", cmd.isCircuitBreakerOpen());
    }
    {
      CommandHelloWorld cmd = new CommandHelloWorld(commandKey, false);
      cmd.execute();
    }

  }

  class CommandHelloWorld extends HystrixCommand<String> {
    ...
    public boolean allowRequest() {
      return circuitBreaker.allowRequest();
    }
    ...
    @Override
    protected String run() {
      if (error) {
        throw new IllegalArgumentException(""No"");
      }
      return ""Hello "" + name + ""!"";
    }

  }
```
But this test is failed at /* HERE */  . 
Result: Circuit is shorted 

So I remove /* CHECK ALLOW */ line (remove call allowRequest ), 
Test is success. 

I trace into circuitBreaker.allowRequest(),
And found ​HystrixCircuitBreakerImpl allowSingleTest method
```
  public boolean allowSingleTest() {
    long timeCircuitOpenedOrWasLastTested = circuitOpenedOrLastTestedTime.get();
    // 1) if the circuit is open
    // 2) and it's been longer than 'sleepWindow' since we opened the circuit
    if (circuitOpen.get() && System.currentTimeMillis() > timeCircuitOpenedOrWasLastTested + properties.circuitBreakerSleepWindowInMilliseconds().get()) {
      // We push the 'circuitOpenedTime' ahead by 'sleepWindow' since we have allowed one request to try.
      // If it succeeds the circuit will be closed, otherwise another singleTest will be allowed at the end of the 'sleepWindow'.
      if (circuitOpenedOrLastTestedTime.compareAndSet(timeCircuitOpenedOrWasLastTested, System.currentTimeMillis())) {
        // if this returns true that means we set the time so we'll return true to allow the singleTest
        // if it returned false it means another thread raced us and allowed the singleTest before we did
        return true;
      }
    }
    return false;
  }
```

At  Seconds If statement, It change circuitOpenedOrLastTestedTime. 

I think this is bug. I just call query method, but it change status. 

",Can someone take a look to sanity-check?,
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1456,"![imagen](https://cloud.githubusercontent.com/assets/16137380/21840815/c859115a-d7df-11e6-96b4-4a4c51a141ea.png)

When you click in Add Stream button the injection will be executed:
![imagen](https://cloud.githubusercontent.com/assets/16137380/21840830/e63e773c-d7df-11e6-9dc8-e9bf5516a3c9.png)

You have to click in the injected title or url field to view the JavaSript alert.",Would you or anyone else be interested in submitting a PR to fix this?,
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1452,"Version Using 1.5.9

```
@HystrixCommand(fallbackMethod = ""fallback"")
	public <T> Observable<T> callAsync(final String url, final Class<T> responseType, final Map<String, ?> params){
		return Observable.create(new Observable.OnSubscribe<T>() {
			@Override
			public void call(Subscriber<? super T> observer) {
				try {
					if (!observer.isUnsubscribed()) {
						observer.onNext(restClient.callForAsync(url, responseType, params));
						observer.onCompleted();
					}
				} catch (Exception e) {
					observer.onError(e);
				}
			}
		}).subscribeOn(Schedulers.io());
	}
```

`public <T> T fallback(final String url, final Class<T> responseType, final Map<String, ?> params){
		return null;
	}`

",Can close ?,
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1416,"Hi,
i have the following code:

@HystrixCommand(fallbackMethod = ""failedToAdd"", threadPoolKey = ""addRemoveThreadPool"",
        ignoreExceptions = {HttpRequestMethodNotSupportedException.class, TypeMismatchException.class,
            MethodArgumentNotValidException.class}
    )

    @Override
    public JobDataDto addJobData(NewJobDataDto job) {
        return dataJobService.addJobData(job);
    }

    @HystrixCommand(fallbackMethod = ""failedToMarkJobAsFinished"", threadPoolKey = ""addRemoveThreadPool"",
        ignoreExceptions = {HttpRequestMethodNotSupportedException.class, TypeMismatchException.class,
            MethodArgumentNotValidException.class}
    )
    @Override
    public JobDataDto markJobAsFinished(String fullIdIteration, FinishedJobDataDto finishedJobDataDto) {
        return dataJobService.markJobAsFinished(fullIdIteration, finishedJobDataDto);
    }

    @HystrixCommand(fallbackMethod = ""failedToAddDataPoint"", threadPoolKey = ""addDataPointThreadPool"",
        ignoreExceptions = {HttpRequestMethodNotSupportedException.class, TypeMismatchException.class,
            MethodArgumentNotValidException.class}
    )
    @Override
    public DataPointDto addDataPoint(String fullIdIteration, DataPointDto dataPointDto) {
        return dataJobService.addDataPoint(fullIdIteration, dataPointDto);
    }
This is the only code i have that uses Hystrix.
When i check the hytrix stream, looks like i have 3 thread pools instead of 2:
NBODataService (the name of application)
addDataPointThreadPool
addRemoveThreadPool

Why do I have the thread pool with the service name created?

I am using v 1.5.2
Thanks","Can you check if a command exists that is running in `NBODataService`?

Feel free to paste the raw Hystrix stream here as well and I can try to determine what's going on.

It would also be a good idea to look at a thread dump on your system and see if threads with that name are being created.
","Hi,
i have defined 3 hystrix commands:

``` java
@HystrixCommand(fallbackMethod = ""failedToAdd"", threadPoolKey = ""addRemoveThreadPool"",
        ignoreExceptions = {HttpRequestMethodNotSupportedException.class, TypeMismatchException.class,
            MethodArgumentNotValidException.class}
    )
    @Override
    public JobDataDto addJobData(NewJobDataDto job) {
        return dataJobService.addJobData(job);
    }

    @HystrixCommand(fallbackMethod = ""failedToMarkJobAsFinished"", threadPoolKey = ""addRemoveThreadPool"",
        ignoreExceptions = {HttpRequestMethodNotSupportedException.class, TypeMismatchException.class,
            MethodArgumentNotValidException.class}
    )
    @Override
    public JobDataDto markJobAsFinished(String fullIdIteration, FinishedJobDataDto finishedJobDataDto) {
        return dataJobService.markJobAsFinished(fullIdIteration, finishedJobDataDto);
    }

    @HystrixCommand(fallbackMethod = ""failedToAddDataPoint"", threadPoolKey = ""addDataPointThreadPool"",
        ignoreExceptions = {HttpRequestMethodNotSupportedException.class, TypeMismatchException.class,
            MethodArgumentNotValidException.class}
    )
```

I have no other commands defined...
"
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1322,"When trying to upgrade from `1.4.23` to `1.5.4`, I started to get this error:

```
java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()Ljava/util/concurrent/ConcurrentHashMap$KeySetView;
```

The issue seems somewhat related to https://github.com/Netflix/Hystrix/pull/359 and the issue seems to be described [here](https://gist.github.com/AlainODea/1375759b8720a3f9f094).

FWIW version `1.5.3` works.
","Can you try that and verify you're fixed?
","@mattrjacobs yeah, just fired a build... I'l report in like half a hour...
"
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1289,"The following code at https://github.com/Netflix/Hystrix/blob/master/hystrix-core/src/main/java/com/netflix/hystrix/HystrixThreadPool.java#L146 ignores the return value from awaitTermination called on the ThreadPoolExecutor.

```
pool.getExecutor().awaitTermination(timeout, unit);
```

There's no guarantee that the executor has terminated. The message in the RuntimeException that is thrown if there's an InteruptedException indicates that the intention is to make sure the ThreadPool is properly shutdown, so I think this is an exceptional state.

Typically I would put this in a loop even though this somewhat changes the semantics of timeout / unit to be a frequency to check.

BTW this particularly causes problems in tests (where Hystrix.reset is called a lot) and there are Hystrix managed threads that get put to sleep a lot. My use-case is a Hystrix command that wraps the HTTP call to SQS, which lets you wait up to 20sec for a message.
","Would you like to submit a PR for this?  I'd be happy to review one.    
","Created #1294. Travis doesn't seem to like me, so any help appreciated.
"
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1196,"I am using hystrix to make a Network call . The execution isolation strategy is THREAD. 
The thread timeout is set as 20 ms.
For 95 percentile requests the timeout is getting honoured, but for 98 and 99 percentile requests the time taken for getting response from Network Call is around 50-100 ms.
","When you mention ""time taken for getting response from Network call"", what are you using to measure this?  Is it the Hystrix latency metrics?
","Yeah as seen from circuit breaker metrics the 99 percentile latency > 50 ms
"
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/1155,"I have implemented a fallback that accepts Throwable.

What I see is the following:

If I get into my @HystrixCommand annotated function and throw an exception, then I do in fact see the correct throwable in the fallback function.

If the exception is raised as part of the @HystrixCommand processing within javanica such as timeout or queue threshold is reached etc, then the throwable in the fallback is not populated.

Is there anyway for me to see these exceptions?  I am using 1.5.1.
","Can someone more familiar with `hystrix-javanica` look into this bug? 
/cc @dmgcodevil
",
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/969,"hystrix-core drags in servlet-api 2.5 as a runtime dependency - maybe this should be set as provided as it is usually provided by container - and many may run v3.1 or 3.0
","Which version are you pulling in?  When I look at 1.4.20, servlet-api is not directly referenced in the hystrix-core POM:

https://bintray.com/netflixoss/maven/Hystrix/1.4.20/#files/com/netflix/hystrix/hystrix-core/1.4.20
","Sorry - I squinted a bit on mvn dependency:tree.
It is through http://repo1.maven.org/maven2/com/netflix/hystrix/hystrix-metrics-event-stream/1.4.20/hystrix-metrics-event-stream-1.4.20.pom and http://repo1.maven.org/maven2/com/netflix/hystrix/hystrix-request-servlet/1.4.20/hystrix-request-servlet-1.4.20.pom
"
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/967,"There is a Groovy bug (https://issues.apache.org/jira/browse/GROOVY-6286) which is causing us problems. Basically if a top level class has a static method name that is exactly the same as an inner class, the code will fail. Would it be possible to add alternative method names to Hystrix setter calls as a workaround for this? Obviously Groovy should fix this issue but it seems like it's been a problem for a long time.

Code like this fails:
`HystrixThreadPoolProperties.Setter()`

Maybe something like this as an alternative method invocation:
`HystrixThreadPoolProperties.setterInstance()`

This is a problem for `HystrixThreadPoolProperties` and `HystrixCommandProperties`. Maybe other places as well.
","Can you take a look at #968 to make sure that's what you had in mind?
",
Netflix/Hystrix,https://github.com/Netflix/Hystrix/issues/352,"This issue happens in the Rx-based hystrix-core jar, which is version 1.4 series.

We are following exactly the same way as ""Fallback: Cache via Network"" pattern in https://github.com/Netflix/Hystrix/wiki/How-To-Use.

We are using different thread pools for primary and secondary commands.

We see our Tomcat threads completely blocked in some instances. Here is the stacktrace:

""http-0.0.0.0-7101-56"" daemon prio=10 tid=0x00007fc836453000 nid=0x1162 waiting on condition [0x00007fc0639b6000]
   java.lang.Thread.State: WAITING (parking)
  at sun.misc.Unsafe.park(Native Method)
- parking to wait for  <0x00007fc3ba56b0f8> (a java.util.concurrent.CountDownLatch$Sync)
  at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994)
  at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303)
  at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:236)
  at rx.internal.operators.BlockingOperatorToFuture$2.get(BlockingOperatorToFuture.java:105)
  at com.netflix.hystrix.HystrixExecutableBase$1.performBlockingGetWithTimeout(HystrixExecutableBase.java:506)
  at com.netflix.hystrix.HystrixExecutableBase$1.get(HystrixExecutableBase.java:387)
  at com.netflix.hystrix.HystrixExecutableBase.execute(HystrixExecutableBase.java:296)
  at com.netflix.hystrix.HystrixObservableCommand.execute(HystrixObservableCommand.java:50)
  at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:485)
  at com.netflix.gps.isolation.sims.impl.SimsClientQueryImpl.getVideoSims(SimsClientQueryImpl.java:26)
  ...
","Do you have any more details that might help me narrow it down?  Is request caching used on any of your commands?  I see in the stacktrace above that you're invoking that particular command via `execute()`.  Do you have other threads invoking this command concurrently?  Are they doing so via `execute()`, `queue()`, or `observe()`?
",
libgdx/libgdx,https://github.com/libgdx/libgdx/issues/5808,"Hello,
I am the developer of Happy Can:
https://play.google.com/store/apps/details?id=com.happycenter.happycan.android

After August 1 2019, I developed Happy Can version 15 with 64-bit ABI support.
To do this, I updated LibGDX, Gradle, Android Studio etc.
And for the first time, the game does not run on some devices such as Samsung SM-T113 Tablet and some of Android 4.x devices.
My game is running in debug mode on all devices
but it is not running in release mode on some devices:
[https://imgbbb.com/image/LRjHD2](https://imgbbb.com/image/LRjHD2)
[https://imgbbb.com/image/LRj62G](https://imgbbb.com/image/LRj62G)
","What does ""not running"" mean?
Are there any exceptions?
Can you supply a minimal example in which this occurs so we can reproduce it?","I download the game from PlayStore, tab on the icon and it throws that error message:
""Happy Can has stopped"":
https://imgbbb.com/image/LRj62G

Exception class: java.lang.verifyError
"
libgdx/libgdx,https://github.com/libgdx/libgdx/issues/4106,"#### Issue details

When rendering text on screen using Distance Field Fonts as described in the tutorial, some letters have the wrong padding. I tried this with multiple fonts and they all had this problem. The last one I tried was Arial Black with the same settings in Hiero as described in this tutorial: [https://github.com/libgdx/libgdx/wiki/Distance-field-fonts](https://github.com/libgdx/libgdx/wiki/Distance-field-fonts)

I noticed the problem always seemed to be with the same letters, like with the letter 'j' in this case 
![6e03375d772b45e243484ccb470a10e2](https://cloud.githubusercontent.com/assets/15983269/15627771/4e6147c8-24f7-11e6-9ce0-957ba645e51f.png)

As you can see, the first 'i' after the 'j' is too close. I tried this again with another font (""Roboto"") and it still had the same problem with the same settings. Note that this problem persisted regardless of my settings or my font.
![524f56d475893268c3385e2572cda93e](https://cloud.githubusercontent.com/assets/15983269/15627781/aa5fc77a-24f7-11e6-9c91-fba943575bd5.png)
#### Reproduction steps/code

Here is the code I used. This code was compiled using IntelliJ and Gradle, with LibGDX version 1.6.2 and 1.9.3, the result was the same regardless of the LibGDX version.

``` java
package com.mygdx.game;

import com.badlogic.gdx.ApplicationAdapter;
import com.badlogic.gdx.Gdx;
import com.badlogic.gdx.graphics.Color;
import com.badlogic.gdx.graphics.GL20;
import com.badlogic.gdx.graphics.Texture;
import com.badlogic.gdx.graphics.g2d.BitmapFont;
import com.badlogic.gdx.graphics.g2d.SpriteBatch;
import com.badlogic.gdx.graphics.g2d.TextureRegion;
import com.badlogic.gdx.graphics.glutils.ShaderProgram;

public class MyGdxGame extends ApplicationAdapter
{
    SpriteBatch batch;
    BitmapFont font;
    ShaderProgram fontShader;

    @Override public void create ()
    {
        Texture text = new Texture(Gdx.files.internal(""test.png""));
        text.setFilter(Texture.TextureFilter.Linear, Texture.TextureFilter.Linear);

        batch = new SpriteBatch();
        font = new BitmapFont(Gdx.files.internal(""test"" + "".fnt""), new TextureRegion(text), false);
        font.setColor(Color.BLACK);
        font.getData().setScale(3);
        fontShader = new ShaderProgram(Gdx.files.internal(""font.vert""), Gdx.files.internal(""font.frag""));
    }

    @Override
    public void render ()
    {
        Gdx.gl.glClearColor(1, 1, 1, 1);
        Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);
        batch.setShader(fontShader);
        batch.begin();

        font.draw(batch, ""jii"", 0, 100);
        batch.end();
    }
}
```
#### Please select the affected platforms
- [X] Android
- [X] iOS
- [X] HTML/GWT
- [X] Windows
- [X] Linux
- [X] MacOS
","Does this look ok with other shaders? I would assume the problem is in how
the fonts texture map has arranged the letters OR in how that texture is
used to create a bitmap for the shader.
I dont think it will be a issue in the distance field shader itself.
Have you tried looking at the test.png itself ? Its possible even with the
gradient style for the distance field you can still see if the spacing
looks off on some letters.

## 

http://lostagain.nl <-- our company site.
http://fanficmaker.com <-- our, really,really, bad story generator.

On 28 May 2016 at 16:19, SasLuca notifications@github.com wrote:

> Issue details
> 
> When rendering text on screen using Distance Field Fonts as described in
> the tutorial, some letters have the wrong padding. I tried this with
> multiple fonts and they all had this problem. The last one I tried was
> Arial Black with the same settings in Hiero as described in this tutorial:
> https://github.com/libgdx/libgdx/wiki/Distance-field-fonts
> 
> I noticed the problem always seemed to be with the same letters, like with
> the letter 'j' in this case
> [image: 6e03375d772b45e243484ccb470a10e2]
> https://cloud.githubusercontent.com/assets/15983269/15627771/4e6147c8-24f7-11e6-9ce0-957ba645e51f.png
> 
> As you can see, the first 'i' after the 'j' is too close. I tried this
> again with another font (""Roboto"") and it still had the same problem with
> the same settings. Note that this problem persisted regardless of my
> settings or my font.
> [image: 524f56d475893268c3385e2572cda93e]
> https://cloud.githubusercontent.com/assets/15983269/15627781/aa5fc77a-24f7-11e6-9c91-fba943575bd5.png
> Reproduction steps/code
> 
> Here is the code I used. This code was compiled using IntelliJ and Gradle,
> with LibGDX version 1.6.2 and 1.9.3, the result was the same regardless of
> the LibGDX version.
> 
> package com.mygdx.game;
> import com.badlogic.gdx.ApplicationAdapter;import com.badlogic.gdx.Gdx;import com.badlogic.gdx.graphics.Color;import com.badlogic.gdx.graphics.GL20;import com.badlogic.gdx.graphics.Texture;import com.badlogic.gdx.graphics.g2d.BitmapFont;import com.badlogic.gdx.graphics.g2d.SpriteBatch;import com.badlogic.gdx.graphics.g2d.TextureRegion;import com.badlogic.gdx.graphics.glutils.ShaderProgram;
> public class MyGdxGame extends ApplicationAdapter
> {
>     SpriteBatch batch;
>     BitmapFont font;
>     ShaderProgram fontShader;
> 
> ```
> @Override public void create ()
> {
>     Texture text = new Texture(Gdx.files.internal(""test.png""));
>     text.setFilter(Texture.TextureFilter.Linear, Texture.TextureFilter.Linear);
> 
>     batch = new SpriteBatch();
>     font = new BitmapFont(Gdx.files.internal(""test"" + "".fnt""), new TextureRegion(text), false);
>     font.setColor(Color.BLACK);
>     font.getData().setScale(3);
>     fontShader = new ShaderProgram(Gdx.files.internal(""font.vert""), Gdx.files.internal(""font.frag""));
> }
> 
> @Override
> public void render ()
> {
>     Gdx.gl.glClearColor(1, 1, 1, 1);
>     Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);
>     batch.setShader(fontShader);
>     batch.begin();
> 
>     font.draw(batch, ""jii"", 0, 100);
>     batch.end();
> }
> ```
> 
> }
> 
> Please select the affected platforms
> - Android
> - iOS
> - HTML/GWT
> - Windows
> - Linux
> - MacOS
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/libgdx/libgdx/issues/4106, or mute the thread
> https://github.com/notifications/unsubscribe/AFbm0RjA4V9GbU0Xhgv33tyZq6ZsFqejks5qGE77gaJpZM4IpFah
> .
","@ThomasWrobel I never tried using it with different shaders. I just used the shader mentioned in the tutorial. I also tried setting the smoothing using 2 uniform variables for scale and spread but it doesn't change anything. Also, there is no problem with the padding in the test.png. You can view it here: [https://gyazo.com/09c8b19db8d25a514bba1e134d67de4a](https://gyazo.com/09c8b19db8d25a514bba1e134d67de4a)
"
libgdx/libgdx,https://github.com/libgdx/libgdx/issues/3500,"I have found a bug in libgdx:
# Steps to reproduce
1. You have to have nexus device, that does have on screen buttons (tested on nexus 5 and nexus 9), device must be running Android 6.0 (app worked correctly in previous versions)
2. Create fresh new project (can be only andorid, no need for ios, desktop or html)
3. edit AndoridLauncher.java, add folowing comfig: `config.useImmersiveMode = true;` to enable ""full screen mode""
4. Set app to be portrait rather than landscape (In AndoridManifest.xml, set: `android:screenOrientation=""portrait""`)
5. Build & Deploy
6. Start app -> **App runs fine** -> _App runs fine only on first start_
7. Exit app by pressing back button twice
8. Start app again
9. There is **black belt at the bottom of the screen** as shown in screenshot)

![screenshot_20151022-083547](https://cloud.githubusercontent.com/assets/15046120/10658606/d101e7ac-7898-11e5-952c-5a368b9f9e10.png)

Aditional info:
- belt can be removed by going out of the app and back into (middle button)
- belt can be removed by going to app switcher and back into the app
- our app is still in the development, therefore I cannot give you link to the play store to test it, but we have observed same problem with https://play.google.com/store/apps/details?id=com.freaxator.game100balls which presumably uses libgdx framework. 
- I have used latest gdx-setup.jar and latest LibGDX 1.7.0
# Logs

This is log of first startup (no black belt)

> 10-22 09:04:45.451 17959-17959/? I/art: Late-enabling -Xcheck:jni
> 10-22 09:04:45.484 17959-17965/? I/art: Debugger is no longer active
> 10-22 09:04:45.533 17959-17959/? I/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: QUALCOMM Build: 09/02/15, 76f806e, Ibddc658e36
> 10-22 09:04:45.665 17959-17959/? I/AndroidInput: sensor listener setup
> 10-22 09:04:45.673 17959-17982/? D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true
> 10-22 09:04:45.715 17959-17982/? I/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: QUALCOMM Build: 09/02/15, 76f806e, Ibddc658e36
> 10-22 09:04:45.715 17959-17982/? I/OpenGLRenderer: Initialized EGL, version 1.4
> 10-22 09:04:45.746 17959-17978/? W/GL2JNIView: creating OpenGL ES 2.0 context
> 10-22 09:04:45.761 17959-17978/? I/GL2: all initialized 2
> 10-22 09:04:45.761 17959-17978/? I/AndroidGraphics: OGL renderer: Adreno (TM) 330
> 10-22 09:04:45.761 17959-17978/? I/AndroidGraphics: OGL vendor: Qualcomm
> 10-22 09:04:45.762 17959-17978/? I/AndroidGraphics: OGL version: OpenGL ES 3.0 V@127.0 AU@  (GIT@Ibddc658e36)
> 10-22 09:04:45.762 17959-17978/? I/AndroidGraphics: OGL extensions: GL_AMD_compressed_ATC_texture GL_AMD_performance_monitor GL_AMD_program_binary_Z400 GL_EXT_debug_label GL_EXT_debug_marker GL_EXT_discard_framebuffer GL_EXT_robustness GL_EXT_texture_format_BGRA8888 GL_EXT_texture_type_2_10_10_10_REV GL_NV_fence GL_OES_compressed_ETC1_RGB8_texture GL_OES_depth_texture GL_OES_depth24 GL_OES_EGL_image GL_OES_EGL_sync GL_OES_EGL_image_external GL_OES_element_index_uint GL_OES_fbo_render_mipmap GL_OES_fragment_precision_high GL_OES_get_program_binary GL_OES_packed_depth_stencil GL_OES_depth_texture_cube_map GL_OES_rgb8_rgba8 GL_OES_standard_derivatives GL_OES_texture_3D GL_OES_texture_float GL_OES_texture_half_float GL_OES_texture_half_float_linear GL_OES_texture_npot GL_OES_vertex_half_float GL_OES_vertex_type_10_10_10_2 GL_OES_vertex_array_object GL_QCOM_alpha_test GL_QCOM_binning_control GL_QCOM_driver_control GL_QCOM_perfmon_global_mode GL_QCOM_extended_get GL_QCOM_extended_get2 GL_QCOM_tiled_rendering GL_QCOM_writeonly_rendering GL_EXT_sRGB GL_EXT_sRGB_write_control GL_EXT_texture_sRGB_decode GL_EXT_texture_filter_anisotropic GL_EXT_multisampled_render_to_texture GL_EXT_color_buffer_float > GL_EXT_color_buffer_half_float GL_EXT_disjoint_timer_query 
> 10-22 09:04:45.763 17959-17978/? W/Adreno-EGL: <qeglDrvAPI_eglGetConfigAttrib:607>: EGL_BAD_ATTRIBUTE
> 10-22 09:04:45.763 17959-17978/? W/Adreno-EGL: <qeglDrvAPI_eglGetConfigAttrib:607>: EGL_BAD_ATTRIBUTE
> 10-22 09:04:45.763 17959-17978/? I/AndroidGraphics: framebuffer: (5, 6, 5, 0)
> 10-22 09:04:45.763 17959-17978/? I/AndroidGraphics: depthbuffer: (16)
> 10-22 09:04:45.763 17959-17978/? I/AndroidGraphics: stencilbuffer: (0)
> 10-22 09:04:45.763 17959-17978/? I/AndroidGraphics: samples: (0)
> 10-22 09:04:45.763 17959-17978/? I/AndroidGraphics: coverage sampling: (false)
> 10-22 09:04:45.767 17959-17978/? I/AndroidGraphics: Managed meshes/app: { }
> 10-22 09:04:45.767 17959-17978/? I/AndroidGraphics: Managed textures/app: { }
> 10-22 09:04:45.767 17959-17978/? I/AndroidGraphics: Managed cubemap/app: { }
> 10-22 09:04:45.767 17959-17978/? I/AndroidGraphics: Managed shaders/app: { }
> 10-22 09:04:45.767 17959-17978/? I/AndroidGraphics: Managed buffers/app: { }

This is log of second startup (bug, black belt)

> 10-22 09:02:41.778 15895-15895/? I/art: Late-enabling -Xcheck:jni
> 10-22 09:02:41.866 15895-15895/com.mygdx.game.android I/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: QUALCOMM Build: 09/02/15, 76f806e, Ibddc658e36
> 10-22 09:02:42.004 15895-15895/com.mygdx.game.android I/AndroidInput: sensor listener setup
> 10-22 09:02:42.010 15895-15936/com.mygdx.game.android D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true
> 10-22 09:02:42.052 15895-15936/com.mygdx.game.android I/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: QUALCOMM Build: 09/02/15, 76f806e, Ibddc658e36
> 10-22 09:02:42.052 15895-15936/com.mygdx.game.android I/OpenGLRenderer: Initialized EGL, version 1.4
> 10-22 09:02:42.072 15895-15930/com.mygdx.game.android W/GL2JNIView: creating OpenGL ES 2.0 context
> 10-22 09:02:42.085 15895-15930/com.mygdx.game.android I/GL2: all initialized 2
> 10-22 09:02:42.086 15895-15930/com.mygdx.game.android I/AndroidGraphics: OGL renderer: Adreno (TM) 330
> 10-22 09:02:42.086 15895-15930/com.mygdx.game.android I/AndroidGraphics: OGL vendor: Qualcomm
> 10-22 09:02:42.086 15895-15930/com.mygdx.game.android I/AndroidGraphics: OGL version: OpenGL ES 3.0 V@127.0 AU@  (GIT@Ibddc658e36)
> 10-22 09:02:42.086 15895-15930/com.mygdx.game.android I/AndroidGraphics: OGL extensions: GL_AMD_compressed_ATC_texture GL_AMD_performance_monitor GL_AMD_program_binary_Z400 GL_EXT_debug_label GL_EXT_debug_marker GL_EXT_discard_framebuffer GL_EXT_robustness GL_EXT_texture_format_BGRA8888 GL_EXT_texture_type_2_10_10_10_REV GL_NV_fence GL_OES_compressed_ETC1_RGB8_texture GL_OES_depth_texture GL_OES_depth24 GL_OES_EGL_image GL_OES_EGL_sync GL_OES_EGL_image_external GL_OES_element_index_uint GL_OES_fbo_render_mipmap GL_OES_fragment_precision_high GL_OES_get_program_binary GL_OES_packed_depth_stencil GL_OES_depth_texture_cube_map GL_OES_rgb8_rgba8 GL_OES_standard_derivatives GL_OES_texture_3D GL_OES_texture_float GL_OES_texture_half_float GL_OES_texture_half_float_linear GL_OES_texture_npot GL_OES_vertex_half_float GL_OES_vertex_type_10_10_10_2 GL_OES_vertex_array_object GL_QCOM_alpha_test GL_QCOM_binning_control GL_QCOM_driver_control GL_QCOM_perfmon_global_mode GL_QCOM_extended_get GL_QCOM_extended_get2 GL_QCOM_tiled_rendering GL_QCOM_writeonly_rendering GL_EXT_sRGB GL_EXT_sRGB_write_control GL_EXT_texture_sRGB_decode GL_EXT_texture_filter_anisotropic GL_EXT_multisampled_render_to_texture GL_EXT_color_buffer_float > GL_EXT_color_buffer_half_float GL_EXT_disjoint_timer_query 
> 10-22 09:02:42.086 15895-15930/com.mygdx.game.android W/Adreno-EGL: <qeglDrvAPI_eglGetConfigAttrib:607>: EGL_BAD_ATTRIBUTE
> 10-22 09:02:42.086 15895-15930/com.mygdx.game.android W/Adreno-EGL: <qeglDrvAPI_eglGetConfigAttrib:607>: EGL_BAD_ATTRIBUTE
> 10-22 09:02:42.086 15895-15930/com.mygdx.game.android I/AndroidGraphics: framebuffer: (5, 6, 5, 0)
> 10-22 09:02:42.087 15895-15930/com.mygdx.game.android I/AndroidGraphics: depthbuffer: (16)
> 10-22 09:02:42.087 15895-15930/com.mygdx.game.android I/AndroidGraphics: stencilbuffer: (0)
> 10-22 09:02:42.087 15895-15930/com.mygdx.game.android I/AndroidGraphics: samples: (0)
> 10-22 09:02:42.087 15895-15930/com.mygdx.game.android I/AndroidGraphics: coverage sampling: (false)
> 10-22 09:02:42.090 15895-15930/com.mygdx.game.android I/AndroidGraphics: Managed meshes/app: { }
> 10-22 09:02:42.090 15895-15930/com.mygdx.game.android I/AndroidGraphics: Managed textures/app: { }
> 10-22 09:02:42.090 15895-15930/com.mygdx.game.android I/AndroidGraphics: Managed cubemap/app: { }
> 10-22 09:02:42.091 15895-15930/com.mygdx.game.android I/AndroidGraphics: Managed shaders/app: { }
> 10-22 09:02:42.091 15895-15930/com.mygdx.game.android I/AndroidGraphics: Managed buffers/app: { }
","May it be related to https://github.com/libgdx/libgdx/issues/3335?
","Unfortunately I don't know how to modify AndroidApplication.java and then test if changing the order would help. (Everything I tried resulted in error)
"
libgdx/libgdx,https://github.com/libgdx/libgdx/issues/2989,"Hi,

I've found small problem in Actor's drawDebugBounds method. My app has viewport working in virtual world dimensions 16 units x 9 units. drawDebugBounds is using its coordinates instead of pixel screen resolution and because of this and ""width - 1, height - 1"", every rectangle is one unit short in width (1/16 of viewport) and height (1/9 of viewport). Fullscreen background with 16x9 unit size has 15x8 debug rectangle, sprites with 1x1 unit size has 0x0 debug rectangle, etc.

_my code_

``` java
        camera = new OrthographicCamera();
        viewport = new FitViewport(16f, 9f, camera);
        viewport.apply();
        stage = new Stage(viewport);
```

_libgdx/gdx/src/com/badlogic/gdx/scenes/scene2d/Actor.java_

``` java
    /** Draws a rectange for the bounds of this actor if {@link #getDebug()} is true. */
    protected void drawDebugBounds (ShapeRenderer shapes) {
        if (!debug) return;
        shapes.set(ShapeType.Line);
        shapes.setColor(stage.getDebugColor());
        shapes.rect(x, y, originX, originY, width - 1, height - 1, scaleX, scaleY, rotation);
    }
```
","Do you have an executable example?
",
netty/netty,https://github.com/netty/netty/issues/9315,"
![image](https://user-images.githubusercontent.com/8908278/60562297-948f2400-9d89-11e9-8f6f-433f089aaefc.png)

multi frames aggregate in one frame。 cannot get the correct data。","How does your client send messages? Could you please provide code that can be reproduced?

","sorry, I can't provide the code. The client was written by c/c++ and does not send the unreadable sigin，this can be added by netty-codec-http.this bug happens when the network is unstable. I guess the aggregator does not work correctly. hope this can help you.

> How does your client send messages? Could you please provide code that can be reproduced?
"
netty/netty,https://github.com/netty/netty/issues/8442,"### Expected behavior

TLS continues to work in 4.1.31.Final when providing an explicit list of ciphers via `SslContextBuilder.ciphers(...)`.

### Actual behavior

After upgrading, my `SslContextBuilder.build()` throws:

```
Caused by: java.lang.IllegalArgumentException: unsupported cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384(ECDHE-ECDSA-AES256-SHA384)
       at io.netty.handler.ssl.CipherSuiteConverter.convertToCipherStrings(CipherSuiteConverter.java:418)
       at io.netty.handler.ssl.ReferenceCountedOpenSslContext.<init>(ReferenceCountedOpenSslContext.java:252)
       ... 34 more
```

It looks like this is due to changes in #8293, in particular [this](https://github.com/netty/netty/blob/netty-4.1.31.Final/handler/src/main/java/io/netty/handler/ssl/CipherSuiteConverter.java#L418) check in `CipherSuiteConverter.convertToCipherStrings()` which throws if false. Should it just `continue` instead of throwing so that the current cipherSuite is excluded from the lists being built (since a later cipher in the list may be available)? I verified that it works as before with this modification.

### Minimal yet complete reproducer code (or URL to code)

```java
KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
kmf.init(null,null);
String[] ciphers = ((SSLSocketFactory)SSLSocketFactory.getDefault()).getDefaultCipherSuites();
SslContextBuilder.forServer(kmf).sslProvider(SslProvider.OPENSSL) 
    .ciphers(Arrays.asList(ciphers)).build();
```

### Netty version

4.1.31.Final

### JVM version (e.g. `java -version`)

```
java version ""1.8.0_181""
Java(TM) SE Runtime Environment (build 1.8.0_181-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)
```

### OS version (e.g. `uname -a`)

`Linux 3.10.0-862.14.4.el7.x86_64`
","Should it just continue instead of throwing so that the current cipherSuite is excluded from the lists being built (since a later cipher in the list may be available)? I verified that it works as before with this modification.
> 
> Minimal yet complete reproducer code (or URL to code)
> 
> KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
> kmf.init(null,null);
> String[] ciphers = ((SSLSocketFactory)SSLSocketFactory.getDefault()).getDefaultCipherSuites();
> SslContextBuilder.forServer(kmf).sslProvider(SslProvider.OPENSSL) 
>     .ciphers(Arrays.asList(ciphers)).build();
> Netty version
> 
> 4.1.31.Final
> 
> JVM version (e.g. java -version)
> 
> java version ""1.8.0_181""
> Java(TM) SE Runtime Environment (build 1.8.0_181-b13)
> Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)
> OS version (e.g. uname -a)
> 
> Linux 3.10.0-862.14.4.el7.x86_64
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",
netty/netty,https://github.com/netty/netty/issues/7394,"The following link show out of memory info from hprof:
[hprof summary](https://www.evernote.com/shard/s428/sh/184600fb-cb43-4ed8-97a5-49dfb860bef7/d5fa26e81c51123d5acaba6662f0e00a)
[hprof original file](https://s3.amazonaws.com/bidder-code-data/java.tar.gz)
### Steps to reproduce
10 client Pools, 350 connection per pool. 
### Minimal yet complete reproducer code (or URL to code)
      //client send code, need use any pool class to replace Unpooled.copiedBuffer ?
        ByteBuf byteBuf = Unpooled.copiedBuffer(content, StandardCharsets.UTF_8);
        FullHttpRequest msg = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.POST, uri.getRawPath() + ""?"" + uri.getRawQuery(), Unpooled.wrappedBuffer(byteBuf));
        msg.headers().set(HttpHeaderNames.HOST, uri.getHost());
        msg.headers().set(HttpHeaderNames.CACHE_CONTROL, false);
        msg.headers().set(HttpHeaderNames.ACCESS_CONTROL_ALLOW_HEADERS, false);
        msg.headers().set(HttpHeaderNames.CONTENT_TYPE, new AsciiString(""application/json""));
        msg.headers().set(HttpHeaderNames.CONTENT_LENGTH, byteBuf.readableBytes());
       ClientPool.sendMsg(msg);
   //ClientPool  sendMsg code
        final FixedChannelPool pool = getInstance().poolMap.get(address);

        Future<Channel> future = pool.acquire();

        future.addListener(new FutureListener<Channel>() {

            public void operationComplete(Future<Channel> f) {

                if (f.isSuccess()) {
                    Channel ch = null;
                    try {
                        ch = f.getNow();
                        ReferenceCountUtil.retain(msg); //need?
                        ch.writeAndFlush(msg);
                    } catch (Throwable a) {
                        a.printStackTrace();
                    } finally {
                        ReferenceCountUtil.release(msg);  //need?
                 }else{ 
                           //f.isSuccess()==false, no channel available
                         //some business operation
                        //   ReferenceCountUtil.release(msg);   //need?  no add this right now
                    }

              
when received response from server,
ClientPool.release(ctx.channel());
I active the release method when server response.  If server response slow, it will produce many f.isSuccess()=false.   Is this cause out of memory?

### Netty version
nettyall 4.1.16 Final
### JVM version (e.g. `java -version`)
java version ""1.8.0_131""
Java(TM) SE Runtime Environment (build 1.8.0_131-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)
### OS version (e.g. `uname -a`)
Linux ip-172-31-9-182.ec2.internal 3.10.0-514.21.2.el7.x86_64 #1 SMP Sun May 28 17:08:21 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
",can you share the hprof file ?,Is the above hrof html file enough? or do you need original hrof file?
netty/netty,https://github.com/netty/netty/issues/6508,"### Expected behavior
Connection and echoing

### Actual behavior
Throws exception

### Steps to reproduce
Use the following commands to get the code:
git clone git@github.com:ClarkHobbie/ssltest.git
Follow steps in the README.md

### Minimal yet complete reproducer code (or URL to code)
https://github.com/ClarkHobbie/ssltest

### Netty version
4.1.6.Final

### JVM version (e.g. `java -version`)
java version ""1.8.0_101""
Java(TM) SE Runtime Environment (build 1.8.0_101-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)

### OS version (e.g. `uname -a`)
""ver"" from the command promp give:

Microsoft Windows [Version 10.0.14393]

###Misc
Created the same program with core Java and apache mina version 2.0.16 at ssltest2 & ssltest3.
They are available on GitHub via git@github.com:ClarkHobbie/ssltest2.git and git@github.com:ClarkHobbie/ssltest3.git
or via https://github.com/ClarkHobbie/ssltest2 & https://github.com/ClarkHobbie/ssltest3","Can you list the explicit steps in sequence for how you generate the keystone and trust store? Running the `keytool –keystore serverkeystore –genkey –alias server -keyalg rsa -storepass whatever` command generates `Illegal option:  –keystore`.

Also you are blocking on the EventLoop thread when you read input from `stdin`, which will prevent the EventLoop from making progress. If you need to block you should offload this onto some custom `Executor`.

Here is my java version info:
> java -version
java version ""1.8.0_112""
Java(TM) SE Runtime Environment (build 1.8.0_112-b16)
Java HotSpot(TM) 64-Bit Server VM (build 25.112-b16, mixed mode)","I have updated the README file to use -importcert instead of -import.  I have also included the motivation behind each step.  

Please remember that the example comes with truststore and serverkeystore which have already undergone these steps: the instructions are there only if you want to recreate these files.

Regarding why I am trying to import ca-certificate.pem.txt: 

I am trying to create a distributed system that uses SSL/TLS encrytpion to communicate.  Each user of the system needs to get their own certificate.  Rather than requiring general certificates I am using locally signed certificates.  This requires that I create a certificate authority and import that certificate authority in various places, including keystores.  Hence my trying to import ca-certificate.pem.txt.

The steps to creating truststore and keystore:

1) Create the local CA self-signed certificate and private key

    openssl req -x509 -newkey rsa:2048 -keyout ca-key.pem.txt -out ca-certificate.pem.txt -days 365 -nodes

2) Create the truststore

    keytool -importcert -keystore truststore -file ca-certificate.pem.txt -alias ca  -storepass whatever

3) Create the server keystore

    keytool –keystore serverkeystore –genkey –alias server -keyalg rsa -storepass whatever

4) Create a certificate signing request for the server

    keytool –keystore serverkeystore -storepass whatever –certreq –alias server –file server.csr

5) Sign the server CSR with the local CA

    openssl x509 -req -CA ca-certificate.pem.txt -CAkey ca-key.pem.txt -in server.csr -out server.cer -days 365 –CAcreateserial

6) Import the local CA to the server keystore

    keytool -importcert -keystore serverkeystore -storepass whatever -file ca-certificate.pem.txt -alias ca

7) Import the singed certificate to the sever kestore

    keytool -importcert -keystore serverkeystore -storepass whatever -file server.cer -alias server

For whatever reason, my version of keytool interprets ""-import"" as ""-importcert"""
netty/netty,https://github.com/netty/netty/issues/6228,"### Expected behavior
No Error
### Actual behavior
I am getting error when i write data at client side using 

ChannelFuture future=channel.writeAndFlush(uMessage);
				future.addListener(new GenericFutureListener<Future<? super Void>>() {

					@Override
					public void operationComplete(Future<? super Void> future) throws Exception {
						// TODO Auto-generated method stub
						if(future.isSuccess()){
							System.out.println(""Success"");
						}
						else{
							System.out.println(""Failure"");
							future.cause().printStackTrace();
						}
					}
				});

I get below error from future.cause().printStackTrace();


javax.net.ssl.SSLException: SSLEngine closed already
	at io.netty.handler.ssl.SslHandler.wrap(...)(Unknown Source)

Here this is my client code,
public SSLEngine getSslEngine() throws Exception {

		TrustManagerFactory tmFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());
		String keystorePass = ""123456"";

		KeyStore ks = KeyStore.getInstance(""JKS"");
		tmFactory.init(ks);

		ks.load(new FileInputStream(""resources/newssl/keystore.jks""), keystorePass.toCharArray());

		// Set up key manager factory to use our key store
		KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
		kmf.init(ks, keystorePass.toCharArray());

		KeyManager[] km = kmf.getKeyManagers();
		TrustManager[] tm = tmFactory.getTrustManagers();

		SSLContext sslContext = SSLContext.getInstance(""TLS"");
		sslContext.init(km, tm, null);
		sslContext.getServerSessionContext().setSessionCacheSize(0);
		sslContext.getServerSessionContext().setSessionTimeout(0);
		SSLEngine sslEngine = sslContext.getDefault().createSSLEngine(serverIp, serverPort);

		sslEngine.setUseClientMode(true);
		sslEngine.setEnabledProtocols(sslEngine.getSupportedProtocols());
		sslEngine.setEnabledCipherSuites(sslEngine.getSupportedCipherSuites());
		return sslEngine;
	}

Here its my server code,

TrustManagerFactory tmFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());
		KeyStore ks = KeyStore.getInstance(""JKS"");
		tmFactory.init(ks);
		String keystorePass = ""123456"";

		ks.load(new FileInputStream(""src/main/resources/newssl/keystore.jks""), keystorePass.toCharArray());

		// Set up key manager factory to use our key store
		KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
		kmf.init(ks, keystorePass.toCharArray());

		KeyManager[] km = kmf.getKeyManagers();
		TrustManager[] tm = tmFactory.getTrustManagers();

		SSLContext sslContext = SSLContext.getInstance(""TLS"");
		sslContext.init(km, tm, null);
		sslContext.getServerSessionContext().setSessionCacheSize(0);
		sslContext.getServerSessionContext().setSessionTimeout(0);
		SSLEngine sslEngine = sslContext.getDefault().createSSLEngine(""127.0.0.1"", 11235);
		sslEngine.setUseClientMode(false);
		sslEngine.setEnabledProtocols(sslEngine.getSupportedProtocols());
		sslEngine.setEnabledCipherSuites(sslEngine.getSupportedCipherSuites());
		sslEngine.setEnableSessionCreation(true);
		return sslEngine;
 
### Steps to reproduce

### Minimal yet complete reproducer code (or URL to code)

### Netty version
4.1.6.Final
### JVM version (e.g. `java -version`)
JavaSE-1.7
### OS version (e.g. `uname -a`)
Windows Server 2012 R2 Standard",did you check `sslHandler.handshakeFuture()` ?,"@normanmaurer I checked with below code
                 SSLEngine sslEngine = client.getSslEngine();
		socketChannel.pipeline().addFirst(""handler"", new SslHandler(sslEngine, false));
               Future f1=sslHandler.handshakeFuture();
		f1.addListener(new GenericFutureListener<Future<?>>() {
			
			@Override
			public void operationComplete(Future<?> future) throws Exception {
			  if(future.isSuccess()){
				  System.out.println(""Success"");
			  }
			  else{
				  System.out.println(""Failure---"");
			  }
				
			}
		} );

and i am getting Failure , so what could be the reason, how to resolve it?"
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/997,"Error in using Natural Language understanding API.
```none
Caused by: android.os.NetworkOnMainThreadException
        at android.os.StrictMode$AndroidBlockGuardPolicy.onNetwork(StrictMode.java:1303)
        at java.net.Inet6AddressImpl.lookupHostByName(Inet6AddressImpl.java:86)
        at java.net.Inet6AddressImpl.lookupAllHostAddr(Inet6AddressImpl.java:74)
        at java.net.InetAddress.getAllByName(InetAddress.java:752)
        at okhttp3.Dns$1.lookup(Dns.java:40)
        at okhttp3.internal.connection.RouteSelector.resetNextInetSocketAddress(RouteSelector.java:185)
        at okhttp3.internal.connection.RouteSelector.nextProxy(RouteSelector.java:149)
        at okhttp3.internal.connection.RouteSelector.next(RouteSelector.java:84)
        at okhttp3.internal.connection.StreamAllocation.findConnection(StreamAllocation.java:214)
        at okhttp3.internal.connection.StreamAllocation.findHealthyConnection(StreamAllocation.java:135)
        at okhttp3.internal.connection.StreamAllocation.newStream(StreamAllocation.java:114)
        at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:42)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:126)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147)
        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121)
        at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:200)
        at okhttp3.RealCall.execute(RealCall.java:77)
        at com.ibm.watson.developer_cloud.service.WatsonService$WatsonServiceCall.execute(WatsonService.java:531)
        at com.example.krishna.ibm2.MainActivity.onCreate(MainActivity.java:142)
        at android.app.Activity.performCreate(Activity.java:6662)
        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1118)
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2599)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2707) 
        at android.app.ActivityThread.-wrap12(ActivityThread.java) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1460) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:154) 
        at android.app.ActivityThread.main(ActivityThread.java:6077) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:866) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:756)
```","Would you be able to provide a snippet of the code you're using to make the API call, as well as the Java and Android SDK versions you're using?","```
NaturalLanguageUnderstanding service = new NaturalLanguageUnderstanding(
                ""DATE"",
                ""USERNAME"",
                ""PASSWORD""
        );
        service.setEndPoint(""https://gateway.watsonplatform.net/natural-language-understanding/api"");
        String text = ""IBM is an American multinational technology "" +
                ""company headquartered in Armonk, New York, "" +
                ""United States, with operations in over 170 countries."";

        EntitiesOptions entitiesOptions = new EntitiesOptions.Builder()
                .emotion(true)
                .sentiment(true)
                .limit(2)
                .build();

        KeywordsOptions keywordsOptions = new KeywordsOptions.Builder()
                .emotion(true)
                .sentiment(true)
                .limit(2)
                .build();

        Features features = new Features.Builder()
                .entities(entitiesOptions)
                .keywords(keywordsOptions)
                .build();

        AnalyzeOptions parameters = new AnalyzeOptions.Builder()
                .text(text)
                .features(features)
                .build();

        AnalysisResults response = service
                .analyze(parameters)
                .execute();

        ServiceCall call = service.analyze(parameters);
        call.enqueue(new ServiceCallback<AnalysisResults>() {
            @Override public void onResponse(AnalysisResults response) {
                String s = String.valueOf((CharSequence) response);
                Log.d(""Cllg"", s);
            }
            @Override public void onFailure(Exception e) {

            }
        });
```
JAVA SDK = java-sdk-6.8.0-jar-with-dependencies.jar
minSdkVersion 21
targetSdkVersion 27"
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/870,"The Customization ID is not being used when it is passed into the RecognizeOptions object.  I was running the same file into the sessionless recognize audio code provided by the API and getting the exact same response in terms of confidence and transcription, regardless of whether I specified the  custom language model or not.  The model I was using was trained with a corpus of 1.7 million utterances and just over 100 custom words.  The code below is from the API with the added line to specify the customization ID.  You can easily reproduce this by training a model, specifying the id in the code below BUT also add the customizationWeight parameter.  With the weight specified the output of the API call is `Cannot specify customization weight when not using customization.` I am using Java 8 and the latest version of the SDK (2.4.1)

### When reporting a bug, please be sure to include the following:

- Steps to reproduce
1. Train a custom model with some corpus/custom words
2. Run the code below using that customization ID (from the API Explorer):
```
SpeechToText service = new SpeechToText();
service.setUsernameAndPassword(""{username""}, ""{password}"");

RecognizeOptions options = new RecognizeOptions.Builder()
  .contentType(""audio/flac"").timestamps(true)
  .wordAlternativesThreshold(0.9).customizationId(""{customizationID}"")
  .keywords(new String[]{""colorado"", ""tornado"", ""tornadoes""})
  .keywordsThreshold(0.5).build();

String[] files = {""audio-file1.flac"", ""audio-file2.flac""};
for (String file : files) {
  SpeechResults results = service.recognize(new File(file), options).execute();
  System.out.println(results);
}
```
3. Remove the customization ID parameter and you will see the output of the function is exactly the same

Alternatively, you can do this...
1. Train a custom model with some corpus/custom words
2. Run this code
```SpeechToText service = new SpeechToText();
service.setUsernameAndPassword(""{username""}, ""{password}"");

RecognizeOptions options = new RecognizeOptions.Builder()
  .contentType(""audio/flac"").timestamps(true)
  .wordAlternativesThreshold(0.9).customizationId(""{customizationID}"").customizationWeight(0.5)
  .keywords(new String[]{""colorado"", ""tornado"", ""tornadoes""})
  .keywordsThreshold(0.5).build();

String[] files = {""audio-file1.flac"", ""audio-file2.flac""};
for (String file : files) {
  SpeechResults results = service.recognize(new File(file), options).execute();
  System.out.println(results);
}
```
3. You will notice the error that you cannot specify weight without specifying a customization model ID first.
",Would you like to write a patch for this? We'd be more than happy to walk you through the steps involved.,@lpatino10 Sounds great! Let me know.  @germanattanasio I would love to create the patch if I am allowed to.  My manager was really excited about me getting the chance to contribute to the SDK.  Don't know if you saw but I work for IBM Watson on the public sector implementations team so it would be a great experience to get under the hood of something that we use so frequently.
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/754,"I've just created the custom model, added corpus and trained (400 words in the model). Model is available. Trying to recognize 2 minutes of audio from a FLAC file. Job worked with Watson default (not custom) model and also using the regular request (not using websockets).

Maybe Watson custom model is slower than the default one and the latency may be affecting the websockets timeouts? 

So

this works

```
		SpeechToText service = new SpeechToText();
		service.setUsernameAndPassword(""..."", ""..."");

		RecognizeOptions options = new RecognizeOptions.Builder().continuous(true).timestamps(true)
				.interimResults(true).contentType(HttpMediaType.AUDIO_FLAC).customizationId(""19b28680-7452-11e7-a2b2-17481cb0c9b8"")
				.build();

		SpeechResults rs = service.recognize(new File(""...""), options).execute();
		System.out.println(rs);

```
and this does not work

		SpeechToText service = new SpeechToText();
		service.setUsernameAndPassword(""..."", ""..."");

		InputStream audio = new FileInputStream(
				new File(""...""));

		RecognizeOptions options = new RecognizeOptions.Builder().continuous(true).timestamps(true)
				.interimResults(true).contentType(HttpMediaType.AUDIO_FLAC).customizationId(""19b28680-7452-11e7-a2b2-17481cb0c9b8"")
				.build();

		BaseRecognizeCallback call = new BaseRecognizeCallback() {

			@Override
			public void onTranscription(SpeechResults speechResults) {
				System.out.println(speechResults);
				try {
					System.out.print(speechResults.getResults().get(0).getAlternatives().get(0).getTimestamps().get(0)
							.getStartTime());
					System.out.print("" : "");
					System.out.println(speechResults.getResults().get(0).getAlternatives().get(0).getTranscript());
				} catch (NullPointerException npe) {
					// ignore
				}
			}

		};

		service.recognizeUsingWebSocket(audio, options, call);

		// wait 20 seconds for the asynchronous response
		Thread.sleep(20000);
","Do other custom models on your same service work correctly? I'd maybe try creating a new custom model, add a word or two, train it, and then test that one. It could be an issue with your specific Watson service as well maybe?","STT service was provisioned and model was created a couple of days ago, Watson SDK I am using the latest stable 3.8.0. Can I get SDK snapshot using Maven or do I have to download? Sounds like something worth trying."
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/721,"Well, regarding the steps to reproduce the error, I don't really have a step-by-step, but here's what happened:
We have an application running on Bluemix since july 2016 and we using Retrieve & Rank API service. 
Recently our API calls started returning error code 500 and we are unable to use our application right now. We openned a ticket to Bluemix support and they confirmed that this issue should have been resolved using jdk 3.8.0, but it still returns to us the error code 500. 
Therefore Bluemix Support team asked us to open an issue on this GitHub.   

Expected Behavior:
Return a list of the collections we have

Actual Behavior:
Error code 500
![rrerror500](https://cloud.githubusercontent.com/assets/29230864/26834417/aca26f94-4aab-11e7-84cd-289686ee9c6f.png)
![rrinternalerror](https://cloud.githubusercontent.com/assets/29230864/26834416/ac90fb7e-4aab-11e7-980f-9fc15724948e.png)

Java-jdk version 3.8.0 and 3.7.2 both with the same error

And here is the code of our Servlet:

```java
package br.ibm.pcm;

import java.io.IOException;
import java.io.PrintWriter;
import java.util.List;


import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;

import org.apache.solr.client.solrj.SolrServerException;
import org.json.simple.JSONArray;
import org.json.simple.JSONObject;

/**
 * Servlet implementation class GetColletions
 */
@WebServlet(""/GetCollections"")
public class GetCollections extends HttpServlet {
	private static final long serialVersionUID = 1L;
       
    /**
     * @see HttpServlet#HttpServlet()
     */
    public GetCollections() {
        super();
        // TODO Auto-generated constructor stub
    }

	/**
	 * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)
	 */
	protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
		response.getWriter();
        PrintWriter out;
        response.setContentType(""text/html"");
        out = response.getWriter ();
        
        JSONObject obj = new JSONObject();
    	JSONArray list = new JSONArray();
        WatsonProcessing wp = new WatsonProcessing();
        
        try {
			List<String> collections = wp.listCollections();
			for(int i=0; i<collections.size();i++){
	    	list.add(collections.get(i));
			}
		} catch (SolrServerException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
    	obj.put(""collections"", list);
    	out.print(obj);
	}



	/**
	 * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response)
	 */
	protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
		// TODO Auto-generated method stub
		doGet(request, response);
	}

}
```


And this is the code from our class to list the collections ( receiving error 500 ):

```java
public List<String> listCollections() throws SolrServerException, IOException {
		    HttpSolrClient solrClient=null;
		  	List<String> cluster_ids = GetClusterIds();
		  	List<String> collections= new ArrayList<String>();
		  	
		  	for(int i=0;i<cluster_ids.size();i++){
				  solrClient = getSolrClient(RR.getSolrUrl(cluster_ids.get(i)), USERNAME, PASSWORD,cluster_ids.get(i));
				    CollectionAdminRequest.List listCollectionRequest = new CollectionAdminRequest.List();
				    CollectionAdminResponse listResponse = listCollectionRequest.process(solrClient);
				    List<String> lista_collections = (List<String>) listResponse.getResponse().get(""collections"");	
				    for(int j=0;j<lista_collections.size();j++){
				    	collections.add(lista_collections.get(j));
				    }
		  	}

			return collections;
	  }
```",can you also check if calling `listClusters()` works? ,"Hello @germanattanasio ! Sorry for the delayed response, I have updated the SolrJ and SolrJ-core both to version 6.5.1 and java-jdk is already at 3.8.0 but I still get the error code 500 while trying to get the collections from the clusters or any other call to our Retrieve & Rank service ... 
listClusters() worked for almost a year, we haven't changed anything on the code, right now it is returning code 500 but it has worked for almost a year ... I will be glad to help in anything I can, just let me know what you need.
Thanks in advance!
Attached below are some screenshots of the proccess and also the error we receive:
`Error 500: java.lang.RuntimeException: java.net.UnknownServiceException: Unable to find acceptable protocols
. isFallback=false, modes=[ConnectionSpec&#40;cipherSuites=[TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,
 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_DHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
, TLS_DHE_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256
, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_3DES_EDE_CBC_SHA], tlsVersions
=[TLS_1_2, TLS_1_1, TLS_1_0], supportsTlsExtensions=true&#41;, ConnectionSpec&#40;cipherSuites=[TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_DHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
, TLS_DHE_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256
, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_3DES_EDE_CBC_SHA], tlsVersions
=[TLS_1_0], supportsTlsExtensions=true&#41;, ConnectionSpec&#40;&#41;], supported protocols=[TLSv1, TLSv1
.1, TLSv1.2] `
![error500](https://user-images.githubusercontent.com/29230864/26992798-a64c8d36-4d36-11e7-9c70-e7251ad59db6.png)
![updated_dependencies](https://user-images.githubusercontent.com/29230864/26992799-a66ae57e-4d36-11e7-9595-e3880f9550cb.png)
![updated_dependencies2](https://user-images.githubusercontent.com/29230864/26992800-a69a49ae-4d36-11e7-9563-9904c97d8a7e.png)


`"
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/614,"The JVM throws `java.lang.NoSuchMethodError` when I upgrade my sdk from 3.5.3 to 3.6. Seems to be a dependency issue with okhttp/okio. 

```
Caused by: java.lang.NoSuchMethodError: okio/BufferedSource.rangeEquals(JLokio/ByteString;)Z (loaded from file:/opt/ibm/wlp/output/defaultServer/workarea/org.eclipse.osgi/79/data/cache/com.ibm.ws.app.manager_40/.cache/WEB-INF/lib/okio-1.6.0.jar by com.ibm.ws.classloading.internal.AppClassLoader@e9914ce0) called from class okhttp3.internal.Util (loaded from file:/opt/ibm/wlp/output/defaultServer/workarea/org.eclipse.osgi/79/data/cache/com.ibm.ws.app.manager_40/.cache/WEB-INF/lib/okhttp-3.6.0.jar by com.ibm.ws.classloading.internal.AppClassLoader@e9914ce0).
        at okhttp3.internal.Util.bomAwareCharset(Util.java:412)
        at okhttp3.ResponseBody$BomAwareReader.read(ResponseBody.java:248)
        at com.google.gson.stream.JsonReader.fillBuffer(JsonReader.java:1300)
        at com.google.gson.stream.JsonReader.nextNonWhitespace(JsonReader.java:1346)
        at com.google.gson.stream.JsonReader.consumeNonExecutePrefix(JsonReader.java:1582)
        at com.google.gson.stream.JsonReader.doPeek(JsonReader.java:538)
        at com.google.gson.stream.JsonReader.peek(JsonReader.java:429)
        at com.google.gson.Gson.fromJson(Gson.java:806)
        at com.ibm.watson.developer_cloud.util.ResponseUtils.getObject(ResponseUtils.java:93)
        at com.ibm.watson.developer_cloud.util.ResponseConverterUtils$3.convert(ResponseConverterUtils.java:79)
        at com.ibm.watson.developer_cloud.util.ResponseConverterUtils$3.convert(ResponseConverterUtils.java:76)
        at com.ibm.watson.developer_cloud.service.WatsonService.processServiceCall(WatsonService.java:405)
        at com.ibm.watson.developer_cloud.service.WatsonService$1.execute(WatsonService.java:180)

```",Can you provide code to reproduce the error?,"I used IBM JDK (IBM Bluemix Liberty docker container)

```
java version ""1.8.0""
Java(TM) SE Runtime Environment (build pxa6480sr3fp22-20161213_02(SR3 FP22))
IBM J9 VM (build 2.8, JRE 1.8.0 Linux amd64-64 Compressed References 20161209_329148 (JIT enabled, AOT enabled)
J9VM - R28_20161209_1345_B329148
JIT  - tr.r14.java.green_20161207_128946
GC   - R28_20161209_1345_B329148_CMPRSS
J9CL - 20161209_329148)
JCL - 20161213_01 based on Oracle jdk8u111-b14
```
The code is similar to what is mentioned here in the sample below(Java example)
https://www.ibm.com/watson/developercloud/conversation/api/v1/#send_message
"
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/610,"IBM Java (any version) has incompatibilities with the OkHttpClient that are documented [here](https://github.com/square/okhttp/issues/3173). It is possible OkHttpClient may resolve this issue soon as there is current activity on it.

This [issue](https://github.com/cloudant/java-cloudant/issues/215) proposes a solution that involves configuring OkHttpClient with a custom SSLContext but I believe would require reflection to only do this when IBM Java is in use (you would not want to interfere with defaults on other platforms/JDKs).
",What's the output of that if running in Android?,
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/609,"The Alchemy date extraction is not working properly for the Java SDK. The date extraction is failing to find any dates with both the DateExtraction and CombinedCall API calls. The following are example strings that do not return any dates:

Show all results in 2016.
2016

I have narrowed down the problem to the jars contained in

```xml
<dependency>
    <groupId>com.ibm.watson.developer_cloud</groupId>
    <artifactId>java-sdk</artifactId>
</dependency>
```

I know this because I ran the same queries using the curl posts and the dates were extracted properly. In my environment, I use a custom model. I have confirmed that the custom model is not the issue though, as I have removed that factor, and the date extraction still fails.

Found some additional bugs with the date extraction. I am using the following as an anchorDate: Mon Feb 27 10:36:59 CST 2017.

1) What happened to shipment SHxMPOIPxAxGx170224x1 from last week.
This is the date extracted out by Watson Alchemy.
```json
""dates"": [
{
""date"": ""2017-03-06T10:36:59.000"",
""text"": ""from last week""
}
]
```
I expect the date to be 2017-02-20.

2) Show purchase orders from February.
This is the date extracted out by Watson Alchemy.
```json
""dates"": [
{
""date"": ""2017-03-01T00:00:00.000"",
""text"": ""from february""
}
]
```
I expect the date to be inclusive with the month that is specified in the text. So in this case, I expect a value of 2017-02-01.

Here is a list of some date extraction queries that are working correctly:
Show purchase order TPA0002 in 2016
show shipment number 169676326 and from 10/15/2016 to 09-21-2015
Display invoice 012615466 that happened last Saturday","Did you try using Natural Language Understanding?
https://natural-language-understanding-demo.mybluemix.net/","@germanattanasio  Please reopen this issue.  You did not solve the problem with extracting out the year from some queries.  

Show all results in 2016.
2016

I have tested this scenario in the Java SDK and in curl posts.  These queries do not work in the Java SDK, but they do work in the curls.  "
watson-developer-cloud/java-sdk,https://github.com/watson-developer-cloud/java-sdk/issues/456,"I use the following call (answersFile contains 1000 items):

``` java
RetrieveAndRank.rank(ranker_id, answersFile, topAnswers).execute();
```

It's response always contains 10 answers despite the topAnswers value.
I tried R&R service Rest API and this functionality works fine.
I'm not sure, but you use the `""form-data; name=\""answer_metadata\""""`, but the Rest API accept the  ""answers"" form-data.
","Can you please take a look?
",
line/armeria,https://github.com/line/armeria/issues/1781,"https://line.github.io/armeria/client-retry.html

In above link, I do not get any difference between two code chunks except import statements.

If you have any other intention, please tell me and let me fix.",Would you mind sending a PR for that?,"Ah, there is a difference. I totally did not notice that.

Firstly, I though that if there is a difference in that topic, then it should be related with `RetryClient`. What you said is difference between `ClientBuilder` and `HttpClientBuilder`. I am not sure still about on it.

Anyway, I will happily prepare for that PR."
line/armeria,https://github.com/line/armeria/issues/1693,"Armeria Client no respond encountered, would you please help look into this issue.
Armeria version is `0.81.0`

## Background:

### Service Provider: Thrift Based Service

service registration as below:

```java
public static ThriftServiceRegistrationBean serviceRegistrationBean(Object serviceIfaceBean) {
    String path = null;
    Class<?> parent = serviceIfaceBean.getClass();
    for (Class<?> iface : parent.getInterfaces()) {
        if (iface.getName().endsWith(""Iface"")) {
            path = iface.getName();
            break;
        }
    }

    requireNonNull(path, ""Thrift Service must implement Iface or AsyncIface"");

    return new ThriftServiceRegistrationBean()
            .setServiceName(serviceIfaceBean.getClass().getName())
            .setService(THttpService.of(serviceIfaceBean))
            .setPath(""/"" + path)
            .setDecorators(LoggingService.newDecorator(), ServerAuthCheckDecorator.newDecorator());
}
```

### Client:
client code as below:

```java
public static <T> T generateClient(String endpoint, Class<T> clazz) {
    endpoint = String.format(""tbinary+h2c://%s/%s"", endpoint, clazz.getName());
    return build(endpoint, clazz);
}

private static <T> T build(String endpoint, Class<T> clazz) {
    ClientBuilder builder = new ClientBuilder(endpoint);
    builder.decorator(ClientAuthCheckDecorator.newDecorator());
    return builder.build(clazz);
}
```

## The Problem

when `service A` call `service B`, by the help of the logging, we found that, the `request` didn't reach up to `service B`, and `the thread` was hung up, client is waiting forever.
here is the thread dump for the hung up thread.
```
""armeria-common-worker-epoll-2-2"" #79 daemon prio=5 os_prio=0 tid=0x00007fad0c006000 nid=0x5f waiting on condition [0x00007facfa6ea000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000f252edf0> (a java.util.concurrent.CompletableFuture$Signaller)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1693)
	at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323)
	at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1729)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
	at com.linecorp.armeria.client.thrift.THttpClientInvocationHandler.invokeClientMethod(THttpClientInvocationHandler.java:135)
	at com.linecorp.armeria.client.thrift.THttpClientInvocationHandler.invoke(THttpClientInvocationHandler.java:85)
	at com.sun.proxy.$Proxy68.getOrgThirdPartResConfig(Unknown Source)
	at com.hnair.phoenix.mgmt.services.project.domain.service.impl.ApplicationServiceImpl.sendCreatApplicationEvent(ApplicationServiceImpl.java:129)
	at com.hnair.phoenix.mgmt.services.project.domain.service.impl.ApplicationServiceImpl.createApplication(ApplicationServiceImpl.java:110)
	at com.hnair.phoenix.mgmt.services.project.domain.service.impl.ApplicationServiceImpl$$FastClassBySpringCGLIB$$94c5215e.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
	at com.hnair.phoenix.mgmt.services.project.domain.service.impl.ApplicationServiceImpl$$EnhancerBySpringCGLIB$$49a6a3f4.createApplication(<generated>)
	at com.hnair.phoenix.mgmt.services.project.interfaces.facade.impl.ApplicationServiceFacadeImpl.createApplication(ApplicationServiceFacadeImpl.java:54)
	at com.hnair.phoenix.mgmt.services.project.api.ApplicationServiceAsyncApi.createApplication(ApplicationServiceAsyncApi.java:68)
	at com.hnair.phoenix.services.project.v1.ApplicationService$AsyncProcessor$createApplication.start(ApplicationService.java:1342)
	at com.hnair.phoenix.services.project.v1.ApplicationService$AsyncProcessor$createApplication.start(ApplicationService.java:1280)
	at com.linecorp.armeria.server.thrift.ThriftCallService.invokeAsynchronously(ThriftCallService.java:162)
	at com.linecorp.armeria.server.thrift.ThriftCallService.invoke(ThriftCallService.java:145)
	at com.linecorp.armeria.server.thrift.ThriftCallService.serve(ThriftCallService.java:129)
	at com.linecorp.armeria.server.thrift.ThriftCallService.serve(ThriftCallService.java:52)
	at com.linecorp.armeria.server.thrift.THttpService.invoke(THttpService.java:605)
	at com.linecorp.armeria.server.thrift.THttpService.decodeAndInvoke(THttpService.java:580)
	at com.linecorp.armeria.server.thrift.THttpService.lambda$doPost$3(THttpService.java:434)
	at com.linecorp.armeria.server.thrift.THttpService$$Lambda$631/883285835.apply(Unknown Source)
	at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:822)
	at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:797)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)
	at com.linecorp.armeria.common.HttpMessageAggregator.apply(HttpMessageAggregator.java:151)
	at com.linecorp.armeria.common.HttpMessageAggregator.apply(HttpMessageAggregator.java:36)
	at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:822)
	at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:797)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:333)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:905)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
```

## The current workaround
At the moment, we setup the timeout for the client as following.
It's curious that why the request didn't send out, and no exception occured, but the thread is still waiting for the response.

```
private static <T> T build(String endpoint, Class<T> clazz) {
    ClientBuilder builder = new ClientBuilder(endpoint);
    builder.defaultWriteTimeoutMillis(1000L)
        .defaultResponseTimeoutMillis(5000)
        .decorator(ClientAuthCheckDecorator.newDecorator());
    return builder.build(clazz);
}       
```","Could you let me know what happens if you:

- make it fully asynchronous so that your event loop thread does not block,
- or run the synchronous call in a different thread pool

..?","@trustin thanks for your quick response.
First, the issue is happen intermittently, after I restart the client service, it will come into normally OR after while it also will work again.
in my case, the java process runs a few hours later, this problem will happen.

I'll try to change the code to asynchronous and see what will happend. once I have clue, I will post it here."
line/armeria,https://github.com/line/armeria/issues/1437,"In a service that is scraped by prometheus using `new LoggingServiceBuilder().build()`, which enables logging of error responses, a large number of scrapes get logged as errors - creates quite a lot of spam. Perhaps this is a problem with prometheus's golang HTTP client, but wonder if there could be something going wrong in Armeria. The metrics are all available in prometheus so the scrape seems to be succeeding fine.

Log errors are usually Connection reset by peer
```
[h1://scrubbed:8080//internal/metrics#GET] Response: {startTime=2018-11-14T04:16:01.624Z(1542168961624), length=58903B, duration=1039µs(1039150ns), cause=io.netty.channel.unix.Errors$NativeIoException: writevAddresses(..) failed: Connection reset by peer, headers=[:status=200, content-type=text/plain; version=0.0.4; charset=utf-8, content-length=58903]}
```

Using armeria's default `PrometheusExpositionService`.",Could you paste the full stack trace just in case it has useful info?,"Sure

```
""io.netty.channel.unix.Errors$NativeIoException: writevAddresses(..) failed: Connection reset by peer
	at io.netty.channel.unix.Errors.newIOException(Errors.java:122) ~[netty-transport-native-unix-common-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.unix.Errors.ioResult(Errors.java:146) ~[netty-transport-native-unix-common-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.unix.FileDescriptor.writevAddresses(FileDescriptor.java:155) ~[netty-transport-native-unix-common-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.epoll.AbstractEpollStreamChannel.writeBytesMultiple(AbstractEpollStreamChannel.java:316) ~[netty-transport-native-epoll-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.epoll.AbstractEpollStreamChannel.doWriteMultiple(AbstractEpollStreamChannel.java:522) ~[netty-transport-native-epoll-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.epoll.AbstractEpollStreamChannel.doWrite(AbstractEpollStreamChannel.java:434) ~[netty-transport-native-epoll-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:934) [netty-transport-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:525) [netty-transport-native-epoll-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:411) [netty-transport-native-epoll-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:321) [netty-transport-native-epoll-4.1.30.Final-linux-x86_64.jar:4.1.30.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-common-4.1.30.Final.jar:4.1.30.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.30.Final.jar:4.1.30.Final]
	at java.lang.Thread.run(Thread.java:834) [?:?]
```"
line/armeria,https://github.com/line/armeria/issues/1104,"We are using Armeria with Spring-boot 2 and Gradle.

Since spring-boot 2.0, spring-boot gradle plugin no longer add group name to the name of jar.
https://github.com/spring-projects/spring-boot/issues/10778

As a result, conflict zipkin artifacts used by Armeria in jar.
Jar file contains two `BOOT-INF/lib/zipkin-2.5.1.jar` in our project.
Also application booting up failed sometime.... (result depends on build env)

```
2018-03-27 15:45:37.940 ERROR 18459 --- [           main] o.s.boot.SpringApplication               : Application run failed
java.lang.IllegalStateException: Error processing condition on com.linecorp.armeria.spring.ArmeriaAutoConfiguration
    at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:64)
...
    at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51)
Caused by: java.lang.TypeNotPresentException: Type zipkin2.Span not present
```

Looks Armeria depends `io.zipkin.java:zipkin` which depends on `io.zipkin.zipkin2:zipkin`.
However, `io.zipkin.java:zipkin` seems just a alias artifact of zipkin2.
If armeria depends on `io.zipkin.zipkin2:zipkin`, this issue might be resolved.

```
|    +--- com.linecorp.armeria:armeria-zipkin-shaded:0.59.0
|    |    +--- com.linecorp.armeria:armeria-shaded:0.59.0 (*)
|    |    +--- com.google.code.findbugs:jsr305:3.0.2
|    |    +--- io.zipkin.brave:brave:4.17.2
|    |    |    +--- io.zipkin.zipkin2:zipkin:2.5.1
|    |    |    \--- io.zipkin.reporter2:zipkin-reporter:2.4.1
|    |    |         \--- io.zipkin.zipkin2:zipkin:2.5.1
|    |    +--- io.zipkin.java:zipkin:2.5.1
|    |    |    \--- io.zipkin.zipkin2:zipkin:2.5.1
|    |    \--- org.slf4j:slf4j-api:1.7.25
```",Did you try this workaround? https://github.com/spring-projects/spring-boot/issues/10778#issuecomment-372573514,"I tried the workaround, and it works well.

BTW, the brave library only depend on zipkin2, so I thought we can replace with zipkin2 completely.
But it seems difficult..."
line/armeria,https://github.com/line/armeria/issues/739,"I sent 10 requests simultaneously, nine of which were executed successfully, but one of them returned immediately before the logic code was executed.

I set the timeout timeout of 30 seconds, but within one second, one of the requests returned immediately. My logical code was not yet running

1. The first black font section is the response received from one of the requests

2.The second black font part is the log for immediate response


Could you please help me to see what might have caused this ???  @minwoox @anuraaga 



the  client  side    log:

2017-08-23 09:26:31.927  INFO 19313 --- [orker-epoll-3-3] c.l.a.client.logging.LoggingClient       : [id: 0x63f1ab03, L:/192.168.1.25:40158 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.922Z(1503451591922), length=67B, duration=3728µs(3728273ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/MarketChargeService/marketCharge], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
1 ------------------------
2017-08-23 09:26:31.929  INFO 19313 --- [orker-epoll-3-1] c.l.a.client.logging.LoggingClient       : [id: 0x27ae5be7, L:/192.168.1.25:40156 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.922Z(1503451591922), length=66B, duration=6532µs(6532253ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/BalanceFreezeService/BalanceFreeze], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}
2--------------------------------
2017-08-23 09:26:31.930  INFO 19313 --- [rker-epoll-3-10] c.l.a.client.logging.LoggingClient       : [id: 0xed3b6cff, L:/192.168.1.25:40165 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.925Z(1503451591925), length=68B, duration=4557µs(4557678ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/BalanceFreezeService/BalanceFreeze], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}

3--------------------------------
2017-08-23 09:26:31.930  INFO 19313 --- [orker-epoll-3-2] c.l.a.client.logging.LoggingClient       : [id: 0x162b58b9, L:/192.168.1.25:40157 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.925Z(1503451591925), length=67B, duration=4406µs(4406489ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/MarketChargeService/marketCharge], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
4--------------------------------
2017-08-23 09:26:31.930  INFO 19313 --- [orker-epoll-3-8] c.l.a.client.logging.LoggingClient       : [id: 0x0b10107e, L:/192.168.1.25:40163 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.925Z(1503451591925), length=67B, duration=4493µs(4493467ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/BalanceFreezeService/BalanceFreeze], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}
5--------------------------------
2017-08-23 09:26:31.932  INFO 19313 --- [orker-epoll-3-7] c.l.a.client.logging.LoggingClient       : [id: 0x0c41ec0e, L:/192.168.1.25:40162 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.925Z(1503451591925), length=67B, duration=6497µs(6497804ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/MarketChargeService/marketCharge], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}

6--------------------------------
2017-08-23 09:26:31.933  INFO 19313 --- [orker-epoll-3-4] c.l.a.client.logging.LoggingClient       : [id: 0x68548a21, L:/192.168.1.25:40159 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.925Z(1503451591925), length=67B, duration=7775µs(7775595ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/MarketChargeService/marketCharge], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}

7-----------------------------
2017-08-23 09:26:31.933  INFO 19313 --- [orker-epoll-3-5] c.l.a.client.logging.LoggingClient       : [id: 0xa9acd948, L:/192.168.1.25:40160 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.926Z(1503451591926), length=67B, duration=7479µs(7479765ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/MarketChargeService/marketCharge], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
8----------------------------------
2017-08-23 09:26:31.934  INFO 19313 --- [orker-epoll-3-6] c.l.a.client.logging.LoggingClient       : [id: 0x95f74610, L:/192.168.1.25:40161 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.926Z(1503451591926), length=68B, duration=7936µs(7936793ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/BalanceFreezeService/BalanceFreeze], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}
9---------------------------------------------
2017-08-23 09:26:31.936  INFO 19313 --- [orker-epoll-3-9] c.l.a.client.logging.LoggingClient       : [id: 0x2573ca57, L:/192.168.1.25:40164 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Request: {startTime=2017-08-23T01:26:31.928Z(1503451591928), length=67B, duration=7777µs(7777088ns), scheme=gproto+h2c, host=192.168.1.25, headers=[:method=POST, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, :authority=192.168.1.25:8181, :scheme=http, user-agent=armeria/0.52.0, :path=/rpc/MarketChargeService/marketCharge], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
10----------------------------------------



**2017-08-23 09:26:33.183  INFO 19313 --- [orker-epoll-3-1] c.l.a.client.logging.LoggingClient       : [id: 0x27ae5be7, L:/192.168.1.25:40156 - R:192.168.1.25/192.168.1.25:8181][http://192.168.1.25:8181/rpc/#POST] Response: {startTime=2017-08-23T01:26:33.181Z(1503451593181), length=0B, duration=110µs(110421ns), headers=[:status=200, content-type=application/grpc+proto, grpc-status=0], content=DefaultRpcResponse{success}}
java.util.concurrent.TimeoutException: io.grpc.StatusRuntimeException: INTERNAL: No value received for unary call
        at com.afis.jzcg.PingAnFunction.balanceFreeze(PingAnFunction.java:128)
        at com.afis.jx.htp.util.FundTransfer$27.get(FundTransfer.java:1750)
        at com.afis.jx.htp.util.FundTransfer$27.get(FundTransfer.java:1743)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)**



the  server side log:


2017-08-23 09:26:31.924 [DEBUG] [armeria-server-epoll-5-4] c.l.a.internal.Http2GoAwayListener - [id: 0xf4642e1f, L:/192.168.1.25:8181 - R:/192.168.1.25:40159] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.924 [DEBUG] [armeria-server-epoll-5-6] c.l.a.internal.Http2GoAwayListener - [id: 0xe765d8de, L:/192.168.1.25:8181 - R:/192.168.1.25:40161] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.925 [DEBUG] [armeria-server-epoll-5-1] c.l.a.internal.Http2GoAwayListener - [id: 0xb4672d97, L:/192.168.1.25:8181 - R:/192.168.1.25:40156] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.926 [DEBUG] [armeria-server-epoll-5-9] c.l.a.internal.Http2GoAwayListener - [id: 0x75360336, L:/192.168.1.25:8181 - R:/192.168.1.25:40164] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.926 [DEBUG] [armeria-server-epoll-5-8] c.l.a.internal.Http2GoAwayListener - [id: 0x128b3bf1, L:/192.168.1.25:8181 - R:/192.168.1.25:40163] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.926 [DEBUG] [armeria-server-epoll-5-5] c.l.a.internal.Http2GoAwayListener - [id: 0x58e3169b, L:/192.168.1.25:8181 - R:/192.168.1.25:40160] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.927 [DEBUG] [armeria-server-epoll-5-10] c.l.a.internal.Http2GoAwayListener - [id: 0xc6457a94, L:/192.168.1.25:8181 - R:/192.168.1.25:40165] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.926 [DEBUG] [armeria-server-epoll-5-3] c.l.a.internal.Http2GoAwayListener - [id: 0x4f5bac9c, L:/192.168.1.25:8181 - R:/192.168.1.25:40158] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.927 [DEBUG] [armeria-server-epoll-5-7] c.l.a.internal.Http2GoAwayListener - [id: 0xee49da00, L:/192.168.1.25:8181 - R:/192.168.1.25:40162] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:31.927 [DEBUG] [armeria-server-epoll-5-2] c.l.a.internal.Http2GoAwayListener - [id: 0x7652431f, L:/192.168.1.25:8181 - R:/192.168.1.25:40157] HTTP/2 upgrade stream removed: CLOSED
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-1] armeria.services.rpc - [id: 0xb4672d97, L:/192.168.1.25:8181 - R:/192.168.1.25:40156][h2c://afistest25:8181/rpc/BalanceFreezeService/BalanceFreeze#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=66B, duration=69053µs(69053619ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/BalanceFreezeService/BalanceFreeze, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-7] armeria.services.rpc - [id: 0xee49da00, L:/192.168.1.25:8181 - R:/192.168.1.25:40162][h2c://afistest25:8181/rpc/MarketChargeService/marketCharge#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=67B, duration=65892µs(65892274ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/MarketChargeService/marketCharge, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-2] armeria.services.rpc - [id: 0x7652431f, L:/192.168.1.25:8181 - R:/192.168.1.25:40157][h2c://afistest25:8181/rpc/MarketChargeService/marketCharge#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=67B, duration=71103µs(71103886ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/MarketChargeService/marketCharge, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-4] armeria.services.rpc - [id: 0xf4642e1f, L:/192.168.1.25:8181 - R:/192.168.1.25:40159][h2c://afistest25:8181/rpc/MarketChargeService/marketCharge#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=67B, duration=68835µs(68835603ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/MarketChargeService/marketCharge, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-8] armeria.services.rpc - [id: 0x128b3bf1, L:/192.168.1.25:8181 - R:/192.168.1.25:40163][h2c://afistest25:8181/rpc/BalanceFreezeService/BalanceFreeze#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=67B, duration=63811µs(63811621ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/BalanceFreezeService/BalanceFreeze, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-10] armeria.services.rpc - [id: 0xc6457a94, L:/192.168.1.25:8181 - R:/192.168.1.25:40165][h2c://afistest25:8181/rpc/BalanceFreezeService/BalanceFreeze#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=68B, duration=66461µs(66461073ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/BalanceFreezeService/BalanceFreeze, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-6] armeria.services.rpc - [id: 0xe765d8de, L:/192.168.1.25:8181 - R:/192.168.1.25:40161][h2c://afistest25:8181/rpc/BalanceFreezeService/BalanceFreeze#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=68B, duration=68037µs(68037037ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/BalanceFreezeService/BalanceFreeze, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=BalanceFreezeService/BalanceFreeze, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-3] armeria.services.rpc - [id: 0x4f5bac9c, L:/192.168.1.25:8181 - R:/192.168.1.25:40158][h2c://afistest25:8181/rpc/MarketChargeService/marketCharge#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=67B, duration=64857µs(64857458ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/MarketChargeService/marketCharge, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-9] armeria.services.rpc - [id: 0x75360336, L:/192.168.1.25:8181 - R:/192.168.1.25:40164][h2c://afistest25:8181/rpc/MarketChargeService/marketCharge#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=67B, duration=65194µs(65194608ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/MarketChargeService/marketCharge, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
2017-08-23 09:26:32.056 [INFO ] [armeria-server-epoll-5-5] armeria.services.rpc - [id: 0x58e3169b, L:/192.168.1.25:8181 - R:/192.168.1.25:40160][h2c://afistest25:8181/rpc/MarketChargeService/marketCharge#POST] Request: {startTime=2017-08-23T01:26:31.948Z(1503451591948), length=67B, duration=64189µs(64189296ns), scheme=gproto+h2c, host=afistest25, headers=[:method=POST, :authority=192.168.1.25:8181, :scheme=http, :path=/rpc/MarketChargeService/marketCharge, content-type=application/grpc+proto, grpc-accept-encoding=gzip, grpc-timeout=30000000u, user-agent=armeria/0.52.0], content=DefaultRpcRequest{serviceType=GrpcLogUtil, method=MarketChargeService/marketCharge, params=[]}}
2017-08-23 09:26:32.088 [DEBUG] [armeria-blocking-tasks-1-3] org.apache.ibatis.logging.LogFactory - Logging initialized using 'class org.apache.ibatis.logging.slf4j.Slf4jImpl' adapter.
2017-08-23 09:26:32.442 [DEBUG] [armeria-blocking-tasks-1-3] o.a.i.d.pooled.PooledDataSource - PooledDataSource forcefully closed/removed all connections.
2017-08-23 09:26:32.442 [DEBUG] [armeria-blocking-tasks-1-3] o.a.i.d.pooled.PooledDataSource - PooledDataSource forcefully closed/removed all connections.
2017-08-23 09:26:32.442 [DEBUG] [armeria-blocking-tasks-1-3] o.a.i.d.pooled.PooledDataSource - PooledDataSource forcefully closed/removed all connections.
2017-08-23 09:26:32.442 [DEBUG] [armeria-blocking-tasks-1-3] o.a.i.d.pooled.PooledDataSource - PooledDataSource forcefully closed/removed all connections.
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-8] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-9] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-5] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-2] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-7] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-1] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-6] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-3] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
2017-08-23 09:26:33.171 [DEBUG] [armeria-blocking-tasks-1-4] o.a.i.t.jdbc.JdbcTransaction - Opening JDBC Connection
**2017-08-23 09:26:33.180 [INFO ] [armeria-server-epoll-5-1] armeria.services.rpc - [id: 0xb4672d97, L:/192.168.1.25:8181 - R:/192.168.1.25:40156][h2c://afistest25:8181/rpc/BalanceFreezeService/BalanceFreeze#POST] Response: {startTime=2017-08-23T01:26:33.170Z(1503451593170), length=0B, duration=9471µs(9471389ns), headers=[:status=200, content-type=application/grpc+proto, grpc-status=0], content=DefaultRpcResponse{success}}**
",Do you think it's possible an exception was thrown and caught in a way that `onComplete()` was called without calling `onNext()` on the server?,"Thanks,@minwoox @anuraaga @trustin  

it is very strange.I've done a lot of data simulation on the original environment,But none of the above shows up.

@anuraaga  You may be right.  I agree with what you said .   I only  catch InterruptedException,ExecutionException,TimeoutException.
"
line/armeria,https://github.com/line/armeria/issues/361,"After following the maven  [here](http://line.github.io/armeria/setup-maven.html) and running the main class I get this error

> Error: Could not find or load main class hiwi.trail.App

Note: When I remove all the dependancies from the POM.xml the project works completely fine.
",Could you provide a simple project that reproduces the problem? (because I can't with mine.),"Hello @trustin here is  a screenshot of what the project looks like 

![Screenshot](https://raw.githubusercontent.com/xtarx/iNeed-smart-fridge/master/Screen%20Shot%202017-01-05%20at%2011.13.24.png)

notice also the red circle on the project


project is attached [here](https://github.com/xtarx/iNeed-smart-fridge/raw/master/hiwi.armeria.zip)


Thanks in advance :)"
line/armeria,https://github.com/line/armeria/issues/187,"```
Caused by: java.lang.ClassCastException: org.apache.thrift.meta_data.FieldValueMetaData cannot be cast to org.apache.thrift.meta_data.StructMetaData
    at com.linecorp.armeria.common.thrift.ThriftUtil.toJavaType(ThriftUtil.java:82)
    at com.linecorp.armeria.server.thrift.ThriftFunction.<init>(ThriftFunction.java:106)
    at com.linecorp.armeria.server.thrift.ThriftFunction.<init>(ThriftFunction.java:52)
    at com.linecorp.armeria.server.thrift.ThriftServiceCodec.registerFunction(ThriftServiceCodec.java:146)
```
","Could you elaborate on how this exception is triggered?
","@trustin This exception is gone by put the service after all messages in thrift file,  so I closed the issue. I don't know why.
"
paypal/PayPal-Java-SDK,https://github.com/paypal/PayPal-Java-SDK/issues/211,"Reference field is missing from Invoice. That's pretty much it.
","Do you mean the `reference_id` in the Authorization Object ?
","No. This one: https://developer.paypal.com/docs/api/invoicing/#invoices_create

> reference string
> Reference data, such as PO number, to add to the invoice. Maximum length is 60 characters.

`cc_info` field is missing too
"
paypal/PayPal-Java-SDK,https://github.com/paypal/PayPal-Java-SDK/issues/173,"### General Information
- Mode (Sandbox/Live): Live
- PayPal-Debug-ID(s) (from any logs): 3c65a55c453d4
- Version of Java used: 1.8.0_77
- SDK Version: 1.4.2
### Issue Description

I've got problem with method Tokeninfo.createFromAuthorizationCode.
In Sandbox mode everything is OK, but after switching to Live mode I receive

```
com.paypal.base.rest.PayPalRESTException: Error code : 400 with response : {""error_description"":""client id or secret is null"",""error"":""invalid_client"",""correlation_id"":""3c65a55c453d4"",""information_link"":""https://developer.paypal.com/docs/api/#errors""}
    at com.paypal.base.rest.PayPalRESTException.createFromHttpErrorException(PayPalRESTException.java:72)
    at com.paypal.base.rest.PayPalResource.execute(PayPalResource.java:439)
    at com.paypal.base.rest.PayPalResource.configureAndExecute(PayPalResource.java:267)
    at com.paypal.api.openidconnect.Tokeninfo.createFromAuthorizationCodeParameters(Tokeninfo.java:254)
    at com.paypal.api.openidconnect.Tokeninfo.createFromAuthorizationCode(Tokeninfo.java:194)
    at controllers.saas.PaymentController.returnUrl(PaymentController.java:189)
    at router.Routes$$anonfun$routes$1$$anonfun$applyOrElse$80$$anonfun$apply$80.apply(Routes.scala:2098)
    at router.Routes$$anonfun$routes$1$$anonfun$applyOrElse$80$$anonfun$apply$80.apply(Routes.scala:2098)
    at play.core.routing.HandlerInvokerFactory$$anon$4.resultCall(HandlerInvoker.scala:157)
    at play.core.routing.HandlerInvokerFactory$$anon$4.resultCall(HandlerInvoker.scala:156)
Caused by: com.paypal.base.exception.HttpErrorException: Error code : 400 with response : {""error_description"":""client id or secret is null"",""error"":""invalid_client"",""correlation_id"":""3c65a55c453d4"",""information_link"":""https://developer.paypal.com/docs/api/#errors""}
    at com.paypal.base.HttpConnection.executeWithStream(HttpConnection.java:174)
    at com.paypal.base.HttpConnection.execute(HttpConnection.java:67)
    at com.paypal.base.rest.PayPalResource.execute(PayPalResource.java:425)
    at com.paypal.base.rest.PayPalResource.configureAndExecute(PayPalResource.java:267)
    at com.paypal.api.openidconnect.Tokeninfo.createFromAuthorizationCodeParameters(Tokeninfo.java:254)
    at com.paypal.api.openidconnect.Tokeninfo.createFromAuthorizationCode(Tokeninfo.java:194)
    at controllers.saas.PaymentController.returnUrl(PaymentController.java:189)
    at router.Routes$$anonfun$routes$1$$anonfun$applyOrElse$80$$anonfun$apply$80.apply(Routes.scala:2098)
    at router.Routes$$anonfun$routes$1$$anonfun$applyOrElse$80$$anonfun$apply$80.apply(Routes.scala:2098)
    at play.core.routing.HandlerInvokerFactory$$anon$4.resultCall(HandlerInvoker.scala:157)
Caused by: java.io.IOException: Server returned HTTP response code: 400 for URL: https://api.paypal.com/v1/identity/openidconnect/tokenservice
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
    at sun.net.www.protocol.http.HttpURLConnection$10.run(HttpURLConnection.java:1890)
    at sun.net.www.protocol.http.HttpURLConnection$10.run(HttpURLConnection.java:1885)
    at java.security.AccessController.doPrivileged(Native Method)
    at sun.net.www.protocol.http.HttpURLConnection.getChainedException(HttpURLConnection.java:1884)
    at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1457)
    at sun.net.www.protocol.http.HttpURLConnection.access$200(HttpURLConnection.java:90)
Caused by: java.io.IOException: Server returned HTTP response code: 400 for URL: https://api.paypal.com/v1/identity/openidconnect/tokenservice
    at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1840)
    at sun.net.www.protocol.http.HttpURLConnection.access$200(HttpURLConnection.java:90)
    at sun.net.www.protocol.http.HttpURLConnection$9.run(HttpURLConnection.java:1433)
    at sun.net.www.protocol.http.HttpURLConnection$9.run(HttpURLConnection.java:1431)
    at java.security.AccessController.doPrivileged(Native Method)
    at java.security.AccessController.doPrivilegedWithCombiner(AccessController.java:782)
    at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1430)
    at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
    at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338)
    at com.paypal.base.HttpConnection.executeWithStream(HttpConnection.java:133)
```

I think problem is in class HttpConnection. Method setHttpHeaders is called only in sandbox mode.
","Can you try setting both your **mode** and **endpoint** configurations to live values? 

I found a similar issue here and changing both of those configuration values was the suggestion https://github.com/paypal/PayPal-Java-SDK/issues/138.
","It did not work. Still the same problem.

sdk_config.properties:

mode = live 
clientId=...
clientSecret=...
service.EndPoint=https://api.paypal.com

code:

```
        Map<String, String> configurationMap = new HashMap<String, String>();
        configurationMap.put(Constants.MODE, PayPalResource.getConfigurations().get(Constants.MODE));
        configurationMap.put(Constants.CLIENT_ID, PayPalResource.getClientID());
        configurationMap.put(Constants.CLIENT_SECRET, PayPalResource.getClientSecret());
        configurationMap.put(Constants.ENDPOINT, PayPalResource.getConfigurations().get(Constants.ENDPOINT));

        APIContext apiContext = new APIContext();
        apiContext.setConfigurationMap(configurationMap);

        CreateFromAuthorizationCodeParameters param = new CreateFromAuthorizationCodeParameters();
        param.setClientID(PayPalResource.getClientID());
        param.setClientSecret(PayPalResource.getClientSecret());
        param.setCode(code);

        Tokeninfo info = Tokeninfo.createFromAuthorizationCode(apiContext, param);
```
"
paypal/PayPal-Java-SDK,https://github.com/paypal/PayPal-Java-SDK/issues/158,"I have integrated paypal gateway with java rest api to my website 
successfully.It went fine for some time, But unfortunately i got issue 
while getting access code now.I already raised ticket 2 times but i can not find out the problem excatly what causes the problem in integration. 

Thanks in advance.

You can check my code here :

``` java
Map<String, String> sdkConfig = new HashMap<String, String>();
sdkConfig.put(""mode"", ""sandbox"");
System.out.println(""--------------- Paypal Test -------------------"");
String accessToken = new OAuthTokenCredential(""<ClientID>"", ""<SecretKey>"").getAccessToken();
APIContext apiContext = new APIContext(accessToken);
apiContext.setConfigurationMap(sdkConfig);

Amount amount = new Amount();
amount.setCurrency(""USD"");
amount.setTotal(""12"");

Transaction transaction = new Transaction();
transaction.setDescription(""creating a payment"");

List<Item> itemList=new ArrayList<Item>();
ItemList items=new ItemList();

Item item=new Item();
item.setName(""Cart"");
item.setQuantity(""1""); 
item.setPrice(""12"");
item.setCurrency(""USD"");
//item.setSku(shoppingProduct.getUnit());
itemList.add(item);
items.setItems(itemList);
transaction.setItemList(items);
transaction.setAmount(amount);

List<Transaction> transactions = new ArrayList<Transaction>();
transactions.add(transaction);
Payer payer = new Payer();
payer.setPaymentMethod(""paypal"");

Payment payment = new Payment();
payment.setIntent(""sale"");
payment.setPayer(payer);
payment.setTransactions(transactions);
RedirectUrls redirectUrls = new RedirectUrls();
redirectUrls.setCancelUrl(""cancel url"");
redirectUrls.setReturnUrl(""return url"");
payment.setRedirectUrls(redirectUrls);
Payment createdPayment = payment.create(apiContext); 

Iterator<Links> links1 = createdPayment.getLinks().iterator();
while (links1.hasNext()) {
  Links link = links1.next();
  if (link.getRel().equalsIgnoreCase(""approval_url"")) {
    request.setAttribute(""redirectURL"", link.getHref());
  }
}
request.setAttribute(""response"", com.paypal.api.payments.Payment.getLastResponse()); 

String output=com.paypal.api.payments.Payment.getLastResponse();
String redirectURL=null;
try {
  JSONObject json=new JSONObject(output);

  JSONArray links=json.getJSONArray(""links"");

  for(int i=0;i<links.length();i++ ){
    JSONObject hrefObj=links.getJSONObject(i);
    String str=hrefObj.getString(""method"");
    if(str.equalsIgnoreCase(""REDIRECT"")){
      redirectURL=hrefObj.getString(""href"");
    }
  }
} catch (JSONException e) {
  e.printStackTrace();
```
## Error Log Information:

```
com.paypal.exception.HttpErrorException: retry fails.. check log for more information
at com.paypal.core.HttpConnection.execute(HttpConnection.java:139)
at com.paypal.core.rest.OAuthTokenCredential.generateOAuthToken(OAuthTokenCredential.java:192)
at com.paypal.core.rest.OAuthTokenCredential.generateAccessToken(OAuthTokenCredential.java:148)
at com.paypal.core.rest.OAuthTokenCredential.getAccessToken(OAuthTokenCredential.java:126)
at com.thendral.controller.ThendralController.paypalRequest(ThendralController.java:9549)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:213)
at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:126)
at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:96)
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:617)
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:578)
at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80)
at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:923)
at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:852)
at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:882)
at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:778)
at javax.servlet.http.HttpServlet.service(HttpServlet.java:624)
at javax.servlet.http.HttpServlet.service(HttpServlet.java:731)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:505)
at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)
at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:956)
at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:423)
at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1079)
at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:625)
at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)
at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
at java.lang.Thread.run(Unknown Source)
```
","What error are you getting now?  Are you at least getting a connection to the PayPal servers?  

`
     public static void main(String[] args) throws PayPalRESTException {  
        Map<String, String> sdkConfig = new HashMap<String, String>();
        sdkConfig.put(Constants.MODE, Constants.SANDBOX);

```
    String clientId = """";
        String clientSecret = """";

    String accessToken = new OAuthTokenCredential(clientId, clientSecret, sdkConfig).getAccessToken();

    APIContext apiContext = new APIContext(accessToken);
    System.out.println(accessToken);
            // still need to toss in the sdkConfig here
    apiContext.setConfigurationMap(sdkConfig); 

    Amount amount = new Amount();
    amount.setCurrency(""USD"");
    amount.setTotal(""1"");

    Transaction transaction = new Transaction();
    transaction.setDescription(""creating a payment"");

    List itemList=new ArrayList();
    ItemList items=new ItemList();

    Item item=new Item();
    item.setName(""Cart"");
    item.setQuantity(""1""); 
    item.setPrice(""1"");
    item.setCurrency(""USD"");
    //item.setSku(shoppingProduct.getUnit());
    itemList.add(item);
    items.setItems(itemList);
    transaction.setItemList(items);
    transaction.setAmount(amount);

    List transactions = new ArrayList();
    transactions.add(transaction);
    Payer payer = new Payer();
    payer.setPaymentMethod(""paypal"");

    Payment payment = new Payment();
    payment.setIntent(""sale"");
    payment.setPayer(payer);
    payment.setTransactions(transactions);
    RedirectUrls redirectUrls = new RedirectUrls();
    redirectUrls.setCancelUrl(""https://return.com"");
    redirectUrls.setReturnUrl(""https://return.com"");
    payment.setRedirectUrls(redirectUrls);
    try {

        Payment createdPayment = payment.create(apiContext);
                    System.out.println(createdPayment.getId());
        String output=com.paypal.api.payments.Payment.getLastResponse();
        System.out.println(output);

    } catch (Exception e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
    }
}`
```
","@pp-randy  i already added rest-api-sdk 0.7.1 jar . i can't connect with paypal server. same error i am getting .

error code:

Exception in thread ""main"" com.paypal.core.rest.PayPalRESTException: retry fails..  check log for more information
    at com.paypal.core.rest.OAuthTokenCredential.generateOAuthToken(OAuthTokenCredential.java:201)
    at com.paypal.core.rest.OAuthTokenCredential.generateAccessToken(OAuthTokenCredential.java:148)
    at com.paypal.core.rest.OAuthTokenCredential.getAccessToken(OAuthTokenCredential.java:126)
    at SubScribe.main(SubScribe.java:31)
Caused by: com.paypal.exception.HttpErrorException: retry fails..  check log for more information
    at com.paypal.core.HttpConnection.execute(HttpConnection.java:139)
    at com.paypal.core.rest.OAuthTokenCredential.generateOAuthToken(OAuthTokenCredential.java:192)
    ... 3 more

![image](https://cloud.githubusercontent.com/assets/17721368/13672952/fce17cb6-e6fc-11e5-80cf-52581d1cc531.png)

![image](https://cloud.githubusercontent.com/assets/17721368/13672964/0e4ea56e-e6fd-11e5-89bf-9386ecbd1f6a.png)
"
skylot/jadx,https://github.com/skylot/jadx/issues/772,"window10
![res](https://user-images.githubusercontent.com/27600008/67998931-299d1d80-fc95-11e9-8036-db2675e347a8.gif)

","Which Jadx version do you use? Have you tried the latest unstable version? Does this bug occur always?
Which Java version is used (shown for example in Jadx about box)?",
skylot/jadx,https://github.com/skylot/jadx/issues/765,"I am deobfuscating an app containing android.support library, whose classes are obfuscated as a, b, etc. Automatic deobfuscator doesn't recognize android.support.vX as a valid name and renames vX to autogenerated unique name like C0001vX","What name would you have expected? 
Note that Jadx does not contain functionality for library identification. Therefore Jadx is is not able to regenerate the original class names. The deobfuscation feature is mainly for classes that has been obfuscated in a way that makes them hard to read by humans.","Well, this can be seen as a small subset of #66, but this one is easy to fix. Something like if(class_name.startsWith(""android.support.v"") ) deobfuscate=false;"
skylot/jadx,https://github.com/skylot/jadx/issues/747,"when running on MacBook Pro, Jadx recognises case sensitive file systems as insensitive file systems and case insensitive file systems as case sensitive.","What is Jade?
2. What is the effect of this case sensitive and insensitive errors?","Jade is a typo, supposed to be ""Jadx"".
I learned about this bug due to the following situation:
I had classes in the same package, one is called Z and one is called z (only difference is lower-upper case).
when running Jadx decompiler (not Jadx gui) on the apk file on a case insensitive file system, I found out that only the file z.java exists, and it holds the content that the file Z.java should have held.
I tried to do the same thing using a case sensitive file system, and found out that neither of the files exist in the package, instead appeared files calle C001.java and C002.java, when i opened the files there was a comment at the beggining: `/* renamed from (package name).z, reason: case insensitive file system */`

the only way i could make Jadx decompile the apk successfully is to run it on a case insensitive system, but have the output folder be mounted on a case sensitive volume"
skylot/jadx,https://github.com/skylot/jadx/issues/743,"Hi @skylot,

I've noticed that a lot of apps are not decompiled completely. I caught one of them with a deadlock 

jadx-cli args
```
--no-replace-consts --show-bad-code --threads-count 8 --no-inline-anonymous --no-imports --deobf --deobf-min 2 --deobf-rewrite-cfg
```

Output of ``` jstack ```
```
Full thread dump Java HotSpot(TM) 64-Bit Server VM (12.0.2+10 mixed mode, sharing):

Threads class SMR info:
_java_thread_list=0x00007ffec3f45cc0, length=21, elements={
0x00007ffec200b000, 0x00007ffec60b1800, 0x00007ffec2004000, 0x00007ffec5834000,
0x00007ffec5833000, 0x00007ffec5837000, 0x00007ffec5008800, 0x00007ffec5860000,
0x00007ffec508f800, 0x00007ffec2923000, 0x00007ffec662e000, 0x00007ffec7755000,
0x00007ffec30af000, 0x00007ffec30b2000, 0x00007ffec4115000, 0x00007ffec32f3800,
0x00007ffec4116000, 0x00007ffec32fe800, 0x00007ffec5a9a000, 0x00007ffec742f000,
0x00007ffec8341800
}

""main"" #1 prio=5 os_prio=31 cpu=6028.67ms elapsed=150.42s tid=0x00007ffec200b000 nid=0x2203 waiting on condition  [0x000070000eb68000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at jdk.internal.misc.Unsafe.park(java.base@12.0.2/Native Method)
	- parking to wait for  <0x000000046b2754d0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(java.base@12.0.2/LockSupport.java:235)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(java.base@12.0.2/AbstractQueuedSynchronizer.java:2123)
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(java.base@12.0.2/ThreadPoolExecutor.java:1454)
	at jadx.api.JadxDecompiler.save(JadxDecompiler.java:143)
	at jadx.api.JadxDecompiler.save(JadxDecompiler.java:128)
	at jadx.cli.JadxCLI.processAndSave(JadxCLI.java:39)
	at jadx.cli.JadxCLI.main(JadxCLI.java:19)

   Locked ownable synchronizers:
	- None

""Reference Handler"" #2 daemon prio=10 os_prio=31 cpu=1.32ms elapsed=150.40s tid=0x00007ffec60b1800 nid=0x4403 waiting on condition  [0x000070001007d000]
   java.lang.Thread.State: RUNNABLE
	at java.lang.ref.Reference.waitForReferencePendingList(java.base@12.0.2/Native Method)
	at java.lang.ref.Reference.processPendingReferences(java.base@12.0.2/Reference.java:241)
	at java.lang.ref.Reference$ReferenceHandler.run(java.base@12.0.2/Reference.java:213)

   Locked ownable synchronizers:
	- None

""Finalizer"" #3 daemon prio=8 os_prio=31 cpu=0.20ms elapsed=150.40s tid=0x00007ffec2004000 nid=0x3703 in Object.wait()  [0x0000700010f80000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(java.base@12.0.2/Native Method)
	- waiting on <0x000000044479a3d0> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(java.base@12.0.2/ReferenceQueue.java:155)
	- locked <0x000000044479a3d0> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(java.base@12.0.2/ReferenceQueue.java:176)
	at java.lang.ref.Finalizer$FinalizerThread.run(java.base@12.0.2/Finalizer.java:170)

   Locked ownable synchronizers:
	- None

""Signal Dispatcher"" #4 daemon prio=9 os_prio=31 cpu=0.26ms elapsed=150.40s tid=0x00007ffec5834000 nid=0x3d03 runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

""C2 CompilerThread0"" #5 daemon prio=9 os_prio=31 cpu=9832.54ms elapsed=150.40s tid=0x00007ffec5833000 nid=0xa903 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE
   No compile task

   Locked ownable synchronizers:
	- None

""C1 CompilerThread0"" #8 daemon prio=9 os_prio=31 cpu=3159.32ms elapsed=150.40s tid=0x00007ffec5837000 nid=0x5603 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE
   No compile task

   Locked ownable synchronizers:
	- None

""Sweeper thread"" #9 daemon prio=9 os_prio=31 cpu=82.48ms elapsed=150.40s tid=0x00007ffec5008800 nid=0xa603 runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

""Service Thread"" #10 daemon prio=9 os_prio=31 cpu=4.99ms elapsed=150.38s tid=0x00007ffec5860000 nid=0x5903 runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

""Common-Cleaner"" #11 daemon prio=8 os_prio=31 cpu=1.34ms elapsed=150.38s tid=0x00007ffec508f800 nid=0x5c03 in Object.wait()  [0x0000700014e95000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(java.base@12.0.2/Native Method)
	- waiting on <no object reference available>
	at java.lang.ref.ReferenceQueue.remove(java.base@12.0.2/ReferenceQueue.java:155)
	- locked <0x000000044479ad88> (a java.lang.ref.ReferenceQueue$Lock)
	at jdk.internal.ref.CleanerImpl.run(java.base@12.0.2/CleanerImpl.java:148)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)
	at jdk.internal.misc.InnocuousThread.run(java.base@12.0.2/InnocuousThread.java:134)

   Locked ownable synchronizers:
	- None

""pool-1-thread-1"" #12 prio=5 os_prio=31 cpu=2235.01ms elapsed=143.88s tid=0x00007ffec2923000 nid=0x8f03 waiting for monitor entry  [0x0000700016ecb000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004423df9f0> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b276298> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""pool-1-thread-2"" #13 prio=5 os_prio=31 cpu=4026.55ms elapsed=143.88s tid=0x00007ffec662e000 nid=0x8c03 waiting for monitor entry  [0x0000700017dce000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a53c20> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004423d76b8> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b2eadd8> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""pool-1-thread-3"" #14 prio=5 os_prio=31 cpu=2233.49ms elapsed=143.88s tid=0x00007ffec7755000 nid=0x7003 waiting for monitor entry  [0x0000700018cd0000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.dex.nodes.ClassNode.loadAndProcess(ClassNode.java:251)
	at jadx.core.dex.nodes.RootNode.getClassGenerics(RootNode.java:279)
	at jadx.core.utils.TypeUtils.replaceClassGenerics(TypeUtils.java:35)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.invokeListener(TypeUpdate.java:296)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$45/0x00000008011adc40.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:73)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:50)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.applyImmutableType(TypeInferenceVisitor.java:155)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.setImmutableType(TypeInferenceVisitor.java:136)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor$$Lambda$126/0x000000080126b840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.runTypePropagation(TypeInferenceVisitor.java:102)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.visit(TypeInferenceVisitor.java:71)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:30)
	at jadx.core.dex.visitors.DepthTraversal.lambda$visit$1(DepthTraversal.java:15)
	at jadx.core.dex.visitors.DepthTraversal$$Lambda$90/0x0000000801246840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:15)
	at jadx.core.dex.visitors.DepthTraversal.lambda$visit$0(DepthTraversal.java:14)
	at jadx.core.dex.visitors.DepthTraversal$$Lambda$89/0x0000000801247440.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:14)
	at jadx.core.ProcessClass.process(ProcessClass.java:43)
	- locked <0x0000000444a53c20> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004422eb2f0> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b3604f8> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""pool-1-thread-4"" #15 prio=5 os_prio=31 cpu=2264.72ms elapsed=143.88s tid=0x00007ffec30af000 nid=0x8703 waiting for monitor entry  [0x0000700019bd4000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004423f94e8> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b3d5550> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""pool-1-thread-5"" #16 prio=5 os_prio=31 cpu=2017.32ms elapsed=143.88s tid=0x00007ffec30b2000 nid=0x7203 waiting for monitor entry  [0x000070001aad7000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a53c20> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004423a1f28> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b000360> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""pool-1-thread-6"" #17 prio=5 os_prio=31 cpu=2136.99ms elapsed=143.88s tid=0x00007ffec4115000 nid=0x7303 waiting for monitor entry  [0x000070001b9da000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a53c20> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:60)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x000000044243a208> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b0eac38> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""pool-1-thread-7"" #18 prio=5 os_prio=31 cpu=2134.24ms elapsed=143.88s tid=0x00007ffec32f3800 nid=0x7403 waiting for monitor entry  [0x000070001c8db000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a53c20> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass.process(ProcessClass.java:27)
	at jadx.core.dex.nodes.ClassNode.loadAndProcess(ClassNode.java:251)
	at jadx.core.dex.nodes.RootNode.getClassGenerics(RootNode.java:279)
	at jadx.core.utils.TypeUtils.replaceClassGenerics(TypeUtils.java:35)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.invokeListener(TypeUpdate.java:296)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$45/0x00000008011adc40.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.moveListener(TypeUpdate.java:324)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$36/0x00000008011af840.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.moveListener(TypeUpdate.java:324)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$36/0x00000008011af840.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:142)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.moveListener(TypeUpdate.java:324)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$36/0x00000008011af840.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:73)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:50)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.applyImmutableType(TypeInferenceVisitor.java:155)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.setImmutableType(TypeInferenceVisitor.java:136)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor$$Lambda$126/0x000000080126b840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.runTypePropagation(TypeInferenceVisitor.java:102)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.visit(TypeInferenceVisitor.java:71)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:30)
	at jadx.core.dex.visitors.DepthTraversal.lambda$visit$1(DepthTraversal.java:15)
	at jadx.core.dex.visitors.DepthTraversal$$Lambda$90/0x0000000801246840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:15)
	at jadx.core.ProcessClass.process(ProcessClass.java:43)
	- locked <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:60)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004423a5b08> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b075828> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""pool-1-thread-8"" #19 prio=5 os_prio=31 cpu=2154.06ms elapsed=143.87s tid=0x00007ffec4116000 nid=0x8003 waiting for monitor entry  [0x000070001d7e0000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x0000000446a769b8> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- <0x000000046b2eb100> (a java.util.concurrent.ThreadPoolExecutor$Worker)

""Java2D Disposer"" #21 daemon prio=10 os_prio=31 cpu=1.86ms elapsed=141.24s tid=0x00007ffec32fe800 nid=0x7907 in Object.wait()  [0x000070001e6e3000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(java.base@12.0.2/Native Method)
	- waiting on <0x000000046b3d56f8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(java.base@12.0.2/ReferenceQueue.java:155)
	- locked <0x000000046b3d56f8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(java.base@12.0.2/ReferenceQueue.java:176)
	at sun.java2d.Disposer.run(java.desktop@12.0.2/Disposer.java:144)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- None

""AppKit Thread"" #22 daemon prio=5 os_prio=31 cpu=264.56ms elapsed=141.21s tid=0x00007ffec5a9a000 nid=0x307 runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

""Java2D Queue Flusher"" #24 daemon prio=10 os_prio=31 cpu=83.59ms elapsed=140.95s tid=0x00007ffec742f000 nid=0xf507 in Object.wait()  [0x00007000207fb000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(java.base@12.0.2/Native Method)
	- waiting on <no object reference available>
	at sun.java2d.opengl.OGLRenderQueue$QueueFlusher.run(java.desktop@12.0.2/OGLRenderQueue.java:205)
	- locked <0x000000046b075b48> (a sun.java2d.opengl.OGLRenderQueue$QueueFlusher)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

   Locked ownable synchronizers:
	- None

""Attach Listener"" #54 daemon prio=9 os_prio=31 cpu=0.61ms elapsed=0.57s tid=0x00007ffec8341800 nid=0xc063 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

""VM Thread"" os_prio=31 cpu=583.42ms elapsed=150.41s tid=0x00007ffec5832000 nid=0x4503 runnable  

""GC Thread#0"" os_prio=31 cpu=357.17ms elapsed=150.42s tid=0x00007ffec581e800 nid=0x4f03 runnable  

""GC Thread#1"" os_prio=31 cpu=372.99ms elapsed=149.43s tid=0x00007ffec60a1800 nid=0x5f07 runnable  

""GC Thread#2"" os_prio=31 cpu=364.40ms elapsed=149.43s tid=0x00007ffec6158000 nid=0x5e07 runnable  

""GC Thread#3"" os_prio=31 cpu=363.83ms elapsed=149.43s tid=0x00007ffec6159000 nid=0x6207 runnable  

""GC Thread#4"" os_prio=31 cpu=378.84ms elapsed=149.43s tid=0x00007ffec2018000 nid=0xa003 runnable  

""GC Thread#5"" os_prio=31 cpu=374.66ms elapsed=149.43s tid=0x00007ffec6152000 nid=0x6403 runnable  

""GC Thread#6"" os_prio=31 cpu=245.64ms elapsed=148.57s tid=0x00007ffec290d000 nid=0x6e03 runnable  

""GC Thread#7"" os_prio=31 cpu=247.52ms elapsed=148.57s tid=0x00007ffec304e000 nid=0x9103 runnable  

""G1 Main Marker"" os_prio=31 cpu=0.56ms elapsed=150.42s tid=0x00007ffec500a000 nid=0x4d03 runnable  

""G1 Conc#0"" os_prio=31 cpu=230.08ms elapsed=150.42s tid=0x00007ffec581f800 nid=0x4a03 runnable  

""G1 Conc#1"" os_prio=31 cpu=235.44ms elapsed=148.63s tid=0x00007ffec49d7800 nid=0x6d03 runnable  

""G1 Refine#0"" os_prio=31 cpu=285.65ms elapsed=150.41s tid=0x00007ffec60a0000 nid=0x3003 runnable  

""G1 Refine#1"" os_prio=31 cpu=116.28ms elapsed=148.85s tid=0x00007ffec3099000 nid=0x9b03 runnable  

""G1 Refine#2"" os_prio=31 cpu=81.27ms elapsed=148.85s tid=0x00007ffec5861800 nid=0x9a03 runnable  

""G1 Refine#3"" os_prio=31 cpu=56.36ms elapsed=148.85s tid=0x00007ffec309a000 nid=0x9803 runnable  

""G1 Refine#4"" os_prio=31 cpu=50.29ms elapsed=148.85s tid=0x00007ffec291f000 nid=0x9603 runnable  

""G1 Refine#5"" os_prio=31 cpu=27.60ms elapsed=148.85s tid=0x00007ffec40c3800 nid=0x6a03 runnable  

""G1 Refine#6"" os_prio=31 cpu=26.09ms elapsed=148.85s tid=0x00007ffec309a800 nid=0x9403 runnable  

""G1 Refine#7"" os_prio=31 cpu=27.13ms elapsed=148.84s tid=0x00007ffec309b800 nid=0x6b03 runnable  

""G1 Young RemSet Sampling"" os_prio=31 cpu=129.26ms elapsed=150.41s tid=0x00007ffec60a1000 nid=0x4803 runnable  
""VM Periodic Task Thread"" os_prio=31 cpu=118.62ms elapsed=150.38s tid=0x00007ffec508e800 nid=0xa303 waiting on condition  

JNI global refs: 77, weak refs: 2


Found one Java-level deadlock:
=============================
""pool-1-thread-1"":
  waiting to lock monitor 0x000000014600b200 (object 0x0000000444a58f28, a jadx.core.dex.info.ClassInfo),
  which is held by ""pool-1-thread-7""
""pool-1-thread-7"":
  waiting to lock monitor 0x0000000145e9ee00 (object 0x0000000444a53c20, a jadx.core.dex.info.ClassInfo),
  which is held by ""pool-1-thread-3""
""pool-1-thread-3"":
  waiting to lock monitor 0x000000014600b200 (object 0x0000000444a58f28, a jadx.core.dex.info.ClassInfo),
  which is held by ""pool-1-thread-7""

Java stack information for the threads listed above:
===================================================
""pool-1-thread-1"":
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004423df9f0> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)
""pool-1-thread-7"":
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a53c20> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass.process(ProcessClass.java:27)
	at jadx.core.dex.nodes.ClassNode.loadAndProcess(ClassNode.java:251)
	at jadx.core.dex.nodes.RootNode.getClassGenerics(RootNode.java:279)
	at jadx.core.utils.TypeUtils.replaceClassGenerics(TypeUtils.java:35)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.invokeListener(TypeUpdate.java:296)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$45/0x00000008011adc40.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.moveListener(TypeUpdate.java:324)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$36/0x00000008011af840.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.moveListener(TypeUpdate.java:324)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$36/0x00000008011af840.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:142)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.moveListener(TypeUpdate.java:324)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$36/0x00000008011af840.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:73)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:50)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.applyImmutableType(TypeInferenceVisitor.java:155)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.setImmutableType(TypeInferenceVisitor.java:136)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor$$Lambda$126/0x000000080126b840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.runTypePropagation(TypeInferenceVisitor.java:102)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.visit(TypeInferenceVisitor.java:71)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:30)
	at jadx.core.dex.visitors.DepthTraversal.lambda$visit$1(DepthTraversal.java:15)
	at jadx.core.dex.visitors.DepthTraversal$$Lambda$90/0x0000000801246840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:15)
	at jadx.core.ProcessClass.process(ProcessClass.java:43)
	- locked <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:60)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004423a5b08> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)
""pool-1-thread-3"":
	at jadx.core.ProcessClass.process(ProcessClass.java:35)
	- waiting to lock <0x0000000444a58f28> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.dex.nodes.ClassNode.loadAndProcess(ClassNode.java:251)
	at jadx.core.dex.nodes.RootNode.getClassGenerics(RootNode.java:279)
	at jadx.core.utils.TypeUtils.replaceClassGenerics(TypeUtils.java:35)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.invokeListener(TypeUpdate.java:296)
	at jadx.core.dex.visitors.typeinference.TypeUpdate$$Lambda$45/0x00000008011adc40.update(Unknown Source)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.runListeners(TypeUpdate.java:190)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdate(TypeUpdate.java:171)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.requestUpdateForSsaVar(TypeUpdate.java:148)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeForSsaVar(TypeUpdate.java:136)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.updateTypeChecked(TypeUpdate.java:116)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:73)
	at jadx.core.dex.visitors.typeinference.TypeUpdate.apply(TypeUpdate.java:50)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.applyImmutableType(TypeInferenceVisitor.java:155)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.setImmutableType(TypeInferenceVisitor.java:136)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor$$Lambda$126/0x000000080126b840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.runTypePropagation(TypeInferenceVisitor.java:102)
	at jadx.core.dex.visitors.typeinference.TypeInferenceVisitor.visit(TypeInferenceVisitor.java:71)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:30)
	at jadx.core.dex.visitors.DepthTraversal.lambda$visit$1(DepthTraversal.java:15)
	at jadx.core.dex.visitors.DepthTraversal$$Lambda$90/0x0000000801246840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:15)
	at jadx.core.dex.visitors.DepthTraversal.lambda$visit$0(DepthTraversal.java:14)
	at jadx.core.dex.visitors.DepthTraversal$$Lambda$89/0x0000000801247440.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.dex.visitors.DepthTraversal.visit(DepthTraversal.java:14)
	at jadx.core.ProcessClass.process(ProcessClass.java:43)
	- locked <0x0000000444a53c20> (a jadx.core.dex.info.ClassInfo)
	at jadx.core.ProcessClass$$Lambda$153/0x000000080127a840.accept(Unknown Source)
	at java.util.ArrayList.forEach(java.base@12.0.2/ArrayList.java:1540)
	at jadx.core.ProcessClass.generateCode(ProcessClass.java:61)
	at jadx.core.dex.nodes.ClassNode.decompile(ClassNode.java:262)
	- locked <0x00000004422eb2f0> (a jadx.core.dex.nodes.ClassNode)
	at jadx.api.JavaClass.getCodeInfo(JavaClass.java:53)
	at jadx.api.JadxDecompiler.lambda$appendSourcesSave$0(JadxDecompiler.java:201)
	at jadx.api.JadxDecompiler$$Lambda$74/0x00000008011f0040.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@12.0.2/ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@12.0.2/ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(java.base@12.0.2/Thread.java:835)

Found 1 deadlock.
```

APK: https://drive.google.com/file/d/18wPwqqSeeppz5LDybFX3CLvAZJ3sB7JJ/view?usp=sharing","Do you already have a working partitioning algorithm in mind for splitting up the graphs in regions that don't ""collide"", one for each thread?

Or do you have an alternative approach in mind how to make use of the dependency information?",
greenrobot/EventBus,https://github.com/greenrobot/EventBus/issues/490,"this version doesn`t regist onStart(), it should be onCreate() regist","Do you have a code example of what does not work?

Keep in mind that you can `register(Object)` wherever you want. Using `onStart()` is just a reasonable suggestion. -ut",
zxing/zxing,https://github.com/zxing/zxing/issues/842,"Steps to reproduce:

- have a contact with a phone number in the e164 format
- share the contact with the barcode scanner

![1845297871461598955_2](https://user-images.githubusercontent.com/10261186/28911439-cd6b6656-7830-11e7-88dd-ead3dab5c2e6.png)

As you can see, the barcode scanner is displaying the country prefix (+49 since it is a german phone number), but it somehow cut off the `+` character.

The data encoded in the qrcode is correct, though.",Do you see anything in the code that does otherwise?,"No, i didn't have a look yet.

The vcard (or whatever it is) ""inside"" the qrcode is correct though:
![432364321742048573](https://user-images.githubusercontent.com/10261186/28911875-4d9e57c4-7832-11e7-97ba-e21081de1cf2.png)

Are you also experiencing this issue? This could be os/rom related, for all we know. I am running Android 7.1.2, lineageos 14.1, a build from july."
zxing/zxing,https://github.com/zxing/zxing/issues/751,"Barcode scanner seems to be using different type defaults for `ADR` and `TEL` than suggested in the specification (at least for vCard 2.1). For me it defaults to 'private' but it should to 'work'. From looking at the code it seems that there is no default internally. This can also result in wrong order of types, e.g. this vCard data will swap the types of the second and third number.  

```
BEGIN:VCARD
N:;John;;;
TEL;WORK:10
TEL:2
TEL;CELL:30
END:VCARD  
```

IMHO a good solution for both issues would be to default to the type 'WORK' for phone numbers and addresses at parse time. This should be close enough to the specification. Maybe also for eMails.  

I guess this could be implemented by adding a `defaultType` Parameter to the function `matchVCardPrefixedField` in VCardResultParser.java?
","What's the scenario where the types are wrong though? That does sound like a problem. The 'types' and values arrays should be of equal length. Are you on the trail of a fix already? if you have a PR to look at, I'll review. Maybe this as a test case plus some extra arg checking would reveal the issue.","Yes, it seems ""private"" is the Android default. I think it would be best for ZXing to itself insert a default of ""work"" as that is the recommended default in the vCard spec.  
  
The vCard data above ( [QR Code from it in ZXing Generator](https://zxing.org/w/chart?cht=qr&chs=350x350&chld=L&choe=UTF-8&chl=BEGIN%3AVCARD%0AN%3A%3BJohn%3B%3B%3B%0ATEL%3BWORK%3A10%0ATEL%3A2%0ATEL%3BCELL%3A30%0AEND%3AVCARD++) ) results in a wrong type for ""2"" and ""30"". The reason for this seems to be that the 'types' and 'values' arrays are NOT of equal length as ""2"" in the example does not get a type. Would it get a default type (""work"") everything should work as expected.  
  
Unfortunately I am not fluent in Java but I *think* a fix for both issues could look like this:  
* add ´defaultType´ parameter to the function ´matchVCardPrefixedField´.
* in ´AddressBookParsedResult´ append default values ´work´ to the fields ´ADR´, ´TEL´ and ´EMAIL´

"
zxing/zxing,https://github.com/zxing/zxing/issues/557,"Hi ZXing Team,
I am trying to build ZXing android source code in Android Studio IDE, where i am using **compileSdkVersion 23** and **buildToolsVersion ""23.0.2""** in **build.gradle** file.

I want to compile source code with Android SDK API 23 to support runtime permission, but IDE shows compile time error for API Level 23 because Android OS remove the **Browser.BookmarkColumns** class from API Level 23.

Please suggest solution for this problem ?
","How about opening a pull request to just replace those references with the string value of those constants? that's OK by me.
","Actually i merge code manually in Android Studio, No direct pull request. Also i don't want to make any change on existing code for better code merging  in future. So can you provide any solution accordingly. 
"
zxing/zxing,https://github.com/zxing/zxing/issues/518,"When I run the CommandLineRunner in javase it works unless I try to pass it command line arguments (like --try_harder and --crop).

Here is the error message:

> Exception in thread ""main"" java.lang.NoClassDefFoundError: com/beust/jcommander/JCommander
>   at com.google.zxing.client.j2se.CommandLineRunner.main(CommandLineRunner.java:52)
> Caused by: java.lang.ClassNotFoundException: com.beust.jcommander.JCommander
>   at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
>   at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
>   at java.security.AccessController.doPrivileged(Native Method)
>   at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
>   at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
>   at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
>   at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
>   ... 1 more

I tried it both with the jar files I built, and with the ones hosted at the Maven Release Repository.  It works on 3.2.0, but is broken on 3.2.1.
","How are you running this? the command-line programs need jcommander, so it has to be included in some way on the classpath. It's correctly specified in the Maven build.
","I'm trying to follow the instructions on the [get started developing wiki page](https://github.com/zxing/zxing/wiki/Getting-Started-Developing#javase).  Basically I'm running the  command: 

```
java -cp javase/target/javase-x.y.z.jar:core/target/core-x.y.z.jar com.google.zxing.client.j2se.CommandLineRunner [URL | FILE]
```

Here are the steps I originally took (which failed):

```
git clone htp://github.com/zxing/zxing
mvn package
java -cp javase/target/javase-3.2.2-SNAPSHOT.jar:core/target/core-3.2.2-SNAPSHOT.jar com.google.zxing.client.j2se.CommandLineRunner BigTestFile.png --crop=811,543,223,263 --try_harder
```

I then tried this and it worked:

```
wget http://central.maven.org/maven2/com/google/zxing/core/3.2.0/core-3.2.0.jar
wget http://central.maven.org/maven2/com/google/zxing/javase/3.2.0/javase-3.2.0.jar
java -cp javase-3.2.0.jar:core-3.2.0.jar com.google.zxing.client.j2se.CommandLineRunner BigTestFile.png --crop=811,543,223,263 --try_harder
```

However, when I do the same for 3.2.1 it fails.
"
zxing/zxing,https://github.com/zxing/zxing/issues/361,"Given the following encode method:

```
public static BufferedImage encode(String contents, String format, int width, int height,    Map<EncodeHintType, ?> hints) {
    BufferedImage result = null;
    BarcodeFormat barcodeFormat = BarcodeFormat.valueOf(format);
    MultiFormatWriter barcodeWriter = new MultiFormatWriter();
    BitMatrix matrix = null;
    try {
        matrix = barcodeWriter.encode(contents, barcodeFormat, width, height, hints);
    } catch (WriterException ex) {
        return null;
    }
    result = MatrixToImageWriter.toBufferedImage(matrix);
    return result;
}
```

Calling encode(""1234"", ""DATA_MATRIX"", 300, 300, null) throws 

```
Exception in thread ""main"" java.lang.IllegalArgumentException: Can't find a symbol arrangement that matches the message. Data codewords: 2
at com.google.zxing.datamatrix.encoder.SymbolInfo.lookup(SymbolInfo.java:148)
at com.google.zxing.datamatrix.encoder.EncoderContext.updateSymbolInfo(EncoderContext.java:127)
at com.google.zxing.datamatrix.encoder.EncoderContext.updateSymbolInfo(EncoderContext.java:122)
at com.google.zxing.datamatrix.encoder.HighLevelEncoder.encodeHighLevel(HighLevelEncoder.java:189)
at com.google.zxing.datamatrix.DataMatrixWriter.encode(DataMatrixWriter.java:84)
at com.google.zxing.MultiFormatWriter.encode(MultiFormatWriter.java:94)
```
","Can you debug to see what's going on, and suggest a patch? this might be a straightforward one.
",
zxing/zxing,https://github.com/zxing/zxing/issues/302,"I have developed a simple web app we use for tracking boxes at work which updates a database.

The boxes all have barcodes attached.

This is somewhat simplified, but for the purposes of this bug report I have two pages in the web app:
- Look up a box
- Add a new box

On the ""add a new box"" page I have a button which links to Barcode Scanner with a URL like:
http://zxing.appspot.com/scan?ret=https%3A%2F%2Fmyserver.example.com%2Faddbox.php%3F%26xid%3D%7BCODE%7D

On the ""look up a box"" page I have a similar button but it links to a different URL:
http://zxing.appspot.com/scan?ret=https%3A%2F%2Fmyserver.example.com%2Flookupbox.php%3F%26xid%3D%7BCODE%7D

However, I find if I go to ""add a new box"", scan a barcode with a particular value (doesn't seem to matter what type of barcode, I've reproduced with code 128 and with QR code), I am redirected correctly. But if I later go to ""look up a box"" and scan the same barcode, it returns me to addbox.php not lookupbox.php even though the link on the ""look up a box"" page was definitely correct.

If I scan a different barcode on the ""look up a box"" page I'm correctly redirected to lookupbox.php. If I clear all zxing's app data, and go to the ""look up a box"" page, and scan the same barcode, I'm also correctly redirected to lookupbox.php.

It looks like zxing is somehow caching the ret= value along with a particular barcode and refusing to change it on a later scan of the same code.

This breaks my web app's functionality. I guess the only way I can really work around it is by redirecting all scans to the same scan.php page and then using PHP session variables or something to tell scan.php where I really want to be redirected to. This is, quite obviously, a pain.

I'm using Barcode Scanner version 4.7.0 on a Sony Xperia Z2 running Android 4.4.4.
","Can I send you a debug build to test, or are you in a position to build from a branch here?
","If you can tell me how to install the debug build, I'm happy to test it. I don't have a rooted phone.

I put together a trivial test example - and in creating it found the bug is slightly different to what I thought.

http://www.tx9.co.uk/zxingtest.php

I cleared app data, then used the ""go to a.php"" link and scan a barcode, it takes me to a.php
Then I use the ""go to b.php"" link and scan the same code, and go to b.php
Then I go back and use the ""go to a.php"" link and always end up at b.php, even if I scan a different code.
"
zxing/zxing,https://github.com/zxing/zxing/issues/214,"I am using 3.1.1-SNAPSHOT of ZXing.
Encoded some UTF-8 text to Aztec Code using the library.
However, the Aztec Decoder fails to read the generated code.

The stacktrace is following:
java.lang.ArrayIndexOutOfBoundsException: 650
        at com.google.zxing.common.BitMatrix.get(BitMatrix.java:74)
        at com.google.zxing.aztec.decoder.Decoder.extractBits(Decoder.java:306)
        at com.google.zxing.aztec.decoder.Decoder.decode(Decoder.java:76)
        at com.google.zxing.aztec.AztecReader.decode(AztecReader.java:67)
        at com.google.zxing.MultiFormatReader.decodeInternal(MultiFormatReader.java:171)
        at com.google.zxing.MultiFormatReader.decode(MultiFormatReader.java:55)
        at net.atos.titan.matrixcode.MatrixCode.readMatrixCodeFromBufferedImage(MatrixCode.java:58)
        at net.atos.titan.matrixcode.MatrixCode.readMatrixCodeFromFile(MatrixCode.java:51)
        at net.atos.titan.matrixcode.MatrixCodeTest.testLoop(MatrixCodeTest.java:65)
","Can you debug? it looks like `Decoder.extractBits` overruns the size of your image. I don't know the code, and at first glance it looks complex. If you know your image and Aztec you might be able to see why and propose a patch.
","I can see that BitMatrix is sized 645 whereas the offset calculated is 650.
![02-09-2014 11-30-37](https://cloud.githubusercontent.com/assets/8625707/4117041/716232be-328c-11e4-8e4d-0059cc0b784b.png)

Unfortunately, I do not have much background in Aztec code hence I am unable to understand the bit extraction logic.
Would it be worth sending you the project?
"
zxing/zxing,https://github.com/zxing/zxing/issues/194,"Sorry for my english, I'm a french user ;-)

All is in title. Try to scan a white code with a black background. That doesn't work for me. 
Tried with a Google Nexus 5.
Version 4.7.0 of Barcode Scanner

I hope it will be fixed soon.
","Did you turn on inverted scan?
","Yes of course ;-)
"
airbnb/lottie-android,https://github.com/airbnb/lottie-android/issues/1410,"lottie版本从2.7.0升级到了3.0.7后，产生了这个奔溃
You must set an images folder before loading an image. Set it with LottieComposition#setImagesFolder or LottieDrawable#setImagesFolder
在2.7.0上是运行正常的，升级后，有一定概率出现上面的bug","Can you post the crash callstack? 

Meanwhile, I would suggest you update the title/description to English so that it can benefit developers with different language background.",
airbnb/lottie-android,https://github.com/airbnb/lottie-android/issues/1391,"Lottie animation not working for Android 10 on Version 3.0.7 but works fine on version 3.0.0.
on Android 10, Version 3.0.7  only renders lottie json first screen  but doesn't animate. 

Testing on Essential Phone-1 with Android 10 
Lottie file used path = LottieSample/src/main/assets/lottiefiles/day_night_cycle.json
",Do you have animations disabled?,if animations were  disabled it also won't be working on  version 3.0.0 . I have checked animations were not disabled. 
airbnb/lottie-android,https://github.com/airbnb/lottie-android/issues/1342,"** If you don't use this template, your issue will be closed **

**Checklist**
1. My animation doesn't use any [unsupported features](http://airbnb.io/lottie/#/supported-features).
2. I know what part of my animation doesn't work.
3. I have created a simplified version of my animation 
4. I have attached the AEP file (as a zip file so it can be attached) that only has the part of the animation that doesn't work.

**Describe the bug**
We're using both dynamic text and coloring some elements in our animation at runtime using `ValueCallback`. Unfortunately, it looks like it's impossible to target the dynamic texts. We have tried: 

```
        animation.addValueCallback(
            KeyPath(""**""),
            LottieProperty.STROKE_COLOR
        ) {
            context!!.getThemeColor(android.R.attr.textColorPrimary)
        }
        animation.addValueCallback(
            KeyPath(""**""),
            LottieProperty.COLOR
        ) {
            context!!.getThemeColor(android.R.attr.textColorPrimary)
        }
```

and it colors everything else in the animation except for our texts.

**What version of Lottie did you test this on?**
3.0.7

**What version of Android did you test this on?**
api 23 - 28

**Steps To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Screenshots**

Let me know if you need anything else from me. Happy to provide any of the above if it's useful.","What property I have to change/animate?

In `after effect`?

In Effect panel?
![](https://i.imgur.com/OSjySj7.png)

or in the text editor?
![](https://i.imgur.com/gPRX9mA.png)

And what `LottieProperty` I have to change?
`LottieProperty.COLOR` , `LottieProperty.COLOR_FILTER` or `LottieProperty.STROKE_COLOR`",
airbnb/lottie-android,https://github.com/airbnb/lottie-android/issues/665,"Using this file: 
https://www.lottiefiles.com/29-motorcycle

with merge paths enabled on a KitKat+ phone in Lottie preview, the motorcycle doesn't render properly.  Something seems to go off with the PathOp.Intersect.  

I'm finding this while working on a Flutter port of Lottie that's largely based off of the Android code.  It renders fine if I force it to go to PathOp.Union.  It makes me suspect there may be an issue with the parsing of the MergeModes - is this documented somewhere?  In https://github.com/airbnb/lottie-web/blob/76032ed287004dbef90f08fa3b30d0c896f2da3c/docs/json/shapes/merge.json it's just listed as ""number"".
",How has it been?,"The thing is it breaks if you enable merge paths but doesn't if you turn them off.  I have the same behavior in my flutter port and I'm looking for clarification on these mappings.

Flutter's been great.  I nearly have parity with the Android version and I'm hoping to release an initial version soon (need a PR I have open in the engine to land that enables path measure and path operations)."
airbnb/lottie-android,https://github.com/airbnb/lottie-android/issues/526,"animationView.setImageAssetDelegate(new ImageAssetDelegate() {
  @Override public Bitmap fetchBitmap(LottieImageAsset asset) {
    // Your bitmap fetching code
  }
});
I am now using the 2.2.0 version of Json, if I have four pictures, when I first through the setImageAssetDelegate method for Lottie images, fetchBitmap method in asset asked me to provide img_0, img_1, img_2, img_3 these pictures, when I was second times for the same Lottie call setImageAssetDelegat, fetchBitmap method start from img_0, but the 2.2.5 version in second after a call to the setImageAssetDelegate method is img_4 from the beginning, which leads to the error",Can you explain it again and attach an animation that reproduces it?,"
       mLottieView.setImageAssetDelegate(new ImageAssetDelegate() {
            @Override
            public Bitmap fetchBitmap(LottieImageAsset asset) {
                Bitmap bitmap = BitmapFactory.decodeFile(GiftUtil.getJsonFileDir(mCurrentZipName , mGiftType) + ""/images/"" + asset.getFileName(), options);
                if (bitmap == null) {
                    LogUtils.e(TAG, ""GiftType: ""+mGiftType +""  FullScreenGiftView Lottie 加载json图片资源失败："" + asset.getFileName());
                }
                return bitmap;
            }
        });

I dynamically load the resource pictures in the way above.
I suppose there are two JSON files A and B, they all need 3 pictures, when I first went to use this way to load A, asset.getFileName were img_0, img_1, img_2, but when the second time I use the same LottieView and reset the setImageAssetDelegate to load B, asset.getFileName return img_3, img_4 so, img_5, error loading, I think when I use the same Lottie (different JSON files) again when loading the B should return img_0, img_1, img_2.

thank,"
airbnb/lottie-android,https://github.com/airbnb/lottie-android/issues/278,"I've done all the steps of implementing Lottie animation in my project
On API 23 and above things are going well, but when I'm triyng to test an animation on Lollipop or Kitkat device (device or emulator, doesn't matter, result is the same), I'm getting a strange look such as this

<= API22
![screenshot_1493805302](https://cloud.githubusercontent.com/assets/1627127/25656776/482c3602-3003-11e7-8e34-38a297c6ff91.png)

\> API22
![screenshot_1493805363](https://cloud.githubusercontent.com/assets/1627127/25656807/68304542-3003-11e7-8253-7a96d8dbdb41.png)

JSON+image:
[Animation.zip](https://github.com/airbnb/lottie-android/files/973026/Animation.zip)
","Can you try cloning the repo trying it in the sample app?
![image](https://cloud.githubusercontent.com/assets/1307745/25785926/a13a5a68-3359-11e7-837e-2a465dc35b9a.png)",
airbnb/lottie-android,https://github.com/airbnb/lottie-android/issues/171,"On my android device the typography animations behave very strange (letters ""L"" and ""F""). You can see it on the attached screenshot. My device is Samsung S5 mini, that have Android 6.0.1
![lottie_bug](https://cloud.githubusercontent.com/assets/16705217/23472470/1fe50f46-fed7-11e6-85d3-8d9e911101c1.png)
",Which version of the app is this in? And you don't have force gpu rendering on in developer settings do you?,
JakeWharton/butterknife,https://github.com/JakeWharton/butterknife/issues/1490,"After having added Butterknife, I get the following error when attempting to run my project:

```
FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':app:processDebugManifest'.
> Manifest merger failed : Attribute application@appComponentFactory value=(android.support.v4.app.CoreComponentFactory) from [com.android.support:support-compat:28.0.0] AndroidManifest.xml:22:18-91
  	is also present at [androidx.core:core:1.0.0] AndroidManifest.xml:22:18-86 value=(androidx.core.app.CoreComponentFactory).
  	Suggestion: add 'tools:replace=""android:appComponentFactory""' to <application> element at AndroidManifest.xml:5:5-18:19 to override.
```

Any ideas?

Project:

```
buildscript {
    repositories {
        google()
        jcenter()
    }
    dependencies {
        classpath 'com.android.tools.build:gradle:3.3.2'
    }
}
allprojects {
    repositories {
        google()
        jcenter()      
    }
}
task clean(type: Delete) {
    delete rootProject.buildDir
}
```

Module:

```
apply plugin: 'com.android.application'

android {
    compileSdkVersion 28
    defaultConfig {
        applicationId ""me.awebster.tipcalculator""
        minSdkVersion 15
        targetSdkVersion 28
        versionCode 1
        versionName ""1.0""
        testInstrumentationRunner ""android.support.test.runner.AndroidJUnitRunner""
    }
    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
        }
    }
}
dependencies {
    implementation fileTree(dir: 'libs', include: ['*.jar'])

    implementation 'com.android.support:appcompat-v7:28.0.0'
    implementation 'com.android.support.constraint:constraint-layout:1.1.3'
    testImplementation 'junit:junit:4.12'

    androidTestImplementation 'com.android.support.test:runner:1.0.2'
    androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.2'

    implementation 'com.jakewharton:butterknife:10.1.0'
    annotationProcessor 'com.jakewharton:butterknife-compiler:10.1.0'
}
```",Can you run Gradle with `--stacktrace` and paste the full exception stacktrace from that message?,
JakeWharton/butterknife,https://github.com/JakeWharton/butterknife/issues/1047,"build.gradle:
```
defaultConfig {
    // ...
    javaCompileOptions {
        annotationProcessorOptions {
            argument('butterknife.debuggable', 'false')
        }
    }
}
```
I get bunch of compile time errors similar to this:
```
Error:(25, 40) error: incompatible types: View cannot be converted to TextView
Error:(32, 48) error: incompatible types: View cannot be converted to Spinner
...
```
There seem to be missing casts in the generated sources:
```java
target.mTitle = source.findViewById(R.id.title);
target.mDescription = source.findViewById(R.id.description);
```",What does your `@BindView` look like so I can write a test?,"@JakeWharton Just a regular bindings:
```java
@BindView(R.id.text_view)
TextView mTextView;
```
Here is a simple application that you can inspect: [MyApplication2.zip](https://github.com/JakeWharton/butterknife/files/1212184/MyApplication2.zip)

> MyApplication2/app/build/generated/source/apt/debug/com/android/myapplication/MainActivity_ViewBinding.java
Error:(23, 43) error: incompatible types: View cannot be converted to TextView
Error:Execution failed for task ':app:compileDebugJavaWithJavac'.
> Compilation failed; see the compiler error output for details.
```java
  @UiThread
  public MainActivity_ViewBinding(MainActivity target, View source) {
    this.target = target;

    target.mTextView = source.findViewById(R.id.text_view);
  }
```"
JakeWharton/butterknife,https://github.com/JakeWharton/butterknife/issues/848,"Hi,

I worked and enjoyed butterknife very much, until now that I need to convert my app to library.
Following jake's instructions on github, I had to use butterknife plugin. However this plugin prevents my library to compile with the following error:

        Error:Execution failed for task ':mfcpdb:processDebugResources'.
        > Lexical error at line 4604, column 27.  Encountered: ""\u05f3"" (1523), after : """"

for 2 days I've googled to find a solution to this with no success. Sadly, i had to go over all my code and remove butterknife allover.

Can anyone help me with this?

Thanks, Yossi.


[A] system info:
===============
 - Windows 10 64 bit
 - Android studio 2.2.3
 - Java version 1.8.73

[B] my build .gradle (project):
=================

// Top-level build file where you can add configuration options common to all sub-projects/modules.

buildscript {
    repositories {
        jcenter()
        mavenCentral()
    }
    dependencies {
        classpath 'com.android.tools.build:gradle:2.2.3'
        classpath 'com.google.gms:google-services:3.0.0'
        classpath 'com.neenbedankt.gradle.plugins:android-apt:1.8'
        classpath 'com.jakewharton:butterknife-gradle-plugin:8.4.0'

        // NOTE: Do not place your application dependencies here; they belong
        // in the individual module build.gradle files
    }
}

allprojects {
    repositories {
        jcenter()
    }
}

subprojects {
    tasks.withType(JavaCompile) {
        options.compilerArgs << ""-Xlint:unchecked"" << ""-Xlint:deprecation""
    }
}

task clean(type: Delete) {
    delete rootProject.buildDir
}



[C] my build.gradle (library):
==================

apply plugin: 'com.android.library'
apply plugin: 'com.jakewharton.butterknife'
apply plugin: 'android-apt'

android {
    compileSdkVersion 25
    buildToolsVersion ""25.0.2""

    dexOptions {
        maxProcessCount 2
        javaMaxHeapSize ""2g""
    }
    defaultConfig {
        minSdkVersion 19
        targetSdkVersion 25
        versionCode 3
        versionName ""3.2""
        vectorDrawables.useSupportLibrary = true
        multiDexEnabled true
    }

    buildTypes {
        release {
            minifyEnabled false
//            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        }
    }
}



dependencies {
    compile fileTree(dir: 'libs', include: ['*.jar'])

    compile('com.h6ah4i.android.widget.advrecyclerview:advrecyclerview:0.9.3@aar') {
        transitive = true
    }
    compile 'com.android.support:multidex:1.0.1'
    compile 'com.android.support:appcompat-v7:25.1.0'
    compile 'com.android.support:design:25.1.0'
    compile 'com.android.support:recyclerview-v7:25.1.0'
    compile 'com.android.support:support-v4:25.1.0'
    compile 'com.android.support:cardview-v7:25.1.0'


    compile 'com.google.firebase:firebase-core:10.0.1'
    compile 'com.google.firebase:firebase-crash:10.0.1'
    compile 'com.google.firebase:firebase-messaging:10.0.1'
    compile 'com.google.android.gms:play-services-maps:10.0.1'
    compile 'com.google.android.gms:play-services-places:10.0.1'
    compile 'com.google.code.gson:gson:2.4'

    compile 'com.squareup.picasso:picasso:2.5.2'
    compile 'com.squareup.retrofit2:retrofit:2.1.0'
    compile 'com.squareup.retrofit2:converter-gson:2.1.0'
    compile 'com.squareup.okhttp3:okhttp:3.5.0'
    compile 'com.jakewharton.picasso:picasso2-okhttp3-downloader:1.0.2'

    compile 'com.jakewharton:butterknife:8.4.0'
    annotationProcessor 'com.jakewharton:butterknife-compiler:8.4.0'

    compile 'joda-time:joda-time:2.9.4'
    compile 'com.fatboyindustrial.gson-jodatime-serialisers:gson-jodatime-serialisers:1.3.0'

    compile 'com.makeramen:roundedimageview:2.2.1'

    compile 'com.github.hotchemi:permissionsdispatcher:2.3.1'
    apt 'com.github.hotchemi:permissionsdispatcher-processor:2.3.1'

    compile 'com.jaredrummler:android-device-names:1.1.2'
}

apply plugin: 'com.google.gms.google-services'



",Did you find a solution? Suddenly my app is unusable and I've narrowed it down to Butterknife. I'm getting logs related to GMS leaking SQL connections but I'm not sure they are related. I've removed Butterknife on a few activities and used it the old way and it's working. Maybe it's time to switch to view binding....,
bumptech/glide,https://github.com/bumptech/glide/issues/3673,"<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**: 4.5.0

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: 

I was trying to resize an image like the one below.
- 4032x3024
- ORIENTATION_ROTATE_90

Tried the following code.

```kotlin
GlideApp.with(context)
        .asBitmap()
        .override(1977, 2636) // consider the orientation
        .load(uri)
        .submit()
        .get()
```

I wanted an image `1977x2636`.
However, I got an image `2636x3515`.

Below is the Downsampler's log.

```
V/Downsampler: Calculate scaling, source: [4032x3024], target: [1977x2636], power of two scaled: [4032x3024], exact scale factor: 0.65376985, power of 2 sample size: 1, adjusted scale factor: 0.8716931343078613, target density: 1631763243, density: 1871946751
V/Downsampler: Calculated target [3515x2636] for source [4032x3024], sampleSize: 1, targetDensity: 1631763243, density: 1871946751, density multiplier: 0.8716932
V/Downsampler: Decoded [3515x2636] ARGB_8888 (37062160) from [4032x3024] image/jpeg with inBitmap [3515x2636] ARGB_8888 (37062160) for [1977x2636], sample size: 1, density: 1871946751, target density: 1631763243, thread: glide-source-thread-0, duration: 287.763101
```

Examined the calculation of `exact scale factor` and `adjusted scale factor` of `Calculate scaling`.

`exact scale factor` consider the orientation.
see: [Downsampler.java#L346-L356](https://github.com/bumptech/glide/blob/v4.5.0/library/src/main/java/com/bumptech/glide/load/resource/bitmap/Downsampler.java#L346-L356)

However, `adjusted scale factor` does not consider the orientation.
see: [Downsampler.java#L440-L441](https://github.com/bumptech/glide/blob/v4.5.0/library/src/main/java/com/bumptech/glide/load/resource/bitmap/Downsampler.java#L440-L441)

I think that this is why can not resize correctly.
Is the calculation of the `adjusted scale factor` correct, or a bug?",What version of Android were you using?,"@sjudd 
Thank you.

> What version of Android were you using?

The problem was confirmed in 5.1, 9.0.
But I think it is an issue independent of versions."
bumptech/glide,https://github.com/bumptech/glide/issues/3667,"<!--
Please fill in the below fields with some data to help us best diagnose the issue.
The more specific you are, the better! You can help a lot by not making us ask these questions.
Feel free to remove any irrelevant parts that you know are not related to the issue.
Any HTML comment like this will be stripped when rendering markdown, no need to delete them.
-->


<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**: 4.9.0

<!-- Do you use any integration library, like OkHttp3 or Volley? For example:
Fails to display with stock networking, but works with okhttp3-1.4.0 -->
**Integration libraries**: OkHttp3 [3.9.0]

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**: 35+ different device models, all on Android 9.0 Pie

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: Downloads an image via URL into a `Bitmap` object and assigns it to a notification's thumbnail. Source images range from 500KB to 3MB.

I've done extensive testing with LeakCanary/different network, image size, and memory scenarios and have been unable to reproduce the ANR as reported in Play Console, with ~60 affected users. The ANR trace appears to point out some kind of timeout with the download and the maximum Android service time limit, but unsure if this is a Glide issue or improper use of it on my part. OkHttp3 timeouts are set to 90 seconds R/W/Connect. All affected users are on Android 9.0, possibly related to the SSL/cleartext restrictions in Pie.

<!-- How do you use Glide?
Make sure you include everything as is in your app's code:
Changing a single method parameter can yield totally different results.
Please clarify any magic variables that appear in the code, for example: ""// `this` is a Fragment""
-->
**Glide load line / `GlideModule` (if any) / list Adapter code (if any)**:
Below code comes from: `BroadcastReciever` class -> `enqueueWork()` -> `JobIntentService` -> `AsyncTask` (below)
```java
   // This is inside doInBackground() of an AsyncTask, within the JobIntentService class.
                Bitmap notifThumb;
                try {
                    notifThumb = GlideApp.with(aContext.get()) //WeakReference.get to AppContext
                            .asBitmap()
                            .load(params[0]) //img direct url
                            .thumbnail(0.75f)
                            .override(1024, 512) //crop to thumbnail window size
                            .apply(new RequestOptions().skipMemoryCache(true).diskCacheStrategy(DiskCacheStrategy.NONE))
                            .into(1024,512) //possibly redundant
                            .get();
                } catch (ExecutionException | InterruptedException e) {
                    Crashlytics.setString(""ThumbUrl"", srcDirect);
                    Crashlytics.logException(e);
                    e.printStackTrace();
                }
```

No Layout XML involved. Downloads an image via URL into a `Bitmap` object and assigns it to a notification's thumbnail.

<!--
What is the error message that you got in the log?
You can find some help on diagnosing issues here: https://github.com/bumptech/glide/wiki/Debugging-and-Error-Handling
-->
**Stack trace / LogCat**:
```ruby
""main"" prio=5 tid=1 Blocked
  | group=""main"" sCount=1 dsCount=0 flags=1 obj=0x75352a18 self=0x76b5e14c00
  | sysTid=13298 nice=-4 cgrp=default sched=0/0 handle=0x773b8b1548
  | state=S schedstat=( 5520467430 3327803911 14046 ) utm=389 stm=162 core=3 HZ=100
  | stack=0x7fe9fc3000-0x7fe9fc5000 stackSize=8MB
  | held mutexes=
  at com.bumptech.glide.request.SingleRequest.isComplete (SingleRequest.java)
- waiting to lock <0x010c3574> (a com.bumptech.glide.request.SingleRequest) held by thread 62
  at com.bumptech.glide.request.ThumbnailRequestCoordinator.isComplete (ThumbnailRequestCoordinator.java:143)
  at com.bumptech.glide.manager.RequestTracker.restartRequests (RequestTracker.java:153)
  at com.bumptech.glide.RequestManager$RequestManagerConnectivityListener.onConnectivityChanged (RequestManager.java:675)
- locked <0x06344a9d> (a com.myappname.xxx.GlideRequests)
  at com.bumptech.glide.manager.DefaultConnectivityMonitor$1.onReceive (DefaultConnectivityMonitor.java:36)
  at android.app.LoadedApk$ReceiverDispatcher$Args.lambda$getRunnable$0 (LoadedApk.java:1391)
  at android.app.-$$Lambda$LoadedApk$ReceiverDispatcher$Args$_BumDX2UKsnxLVrE6UJsJZkotuA.run (lambda)
  at android.os.Handler.handleCallback (Handler.java:873)
  at android.os.Handler.dispatchMessage (Handler.java:99)
  at android.os.Looper.loop (Looper.java:193)
  at android.app.ActivityThread.main (ActivityThread.java:6718)
  at java.lang.reflect.Method.invoke (Method.java)
  at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run (RuntimeInit.java:493)
  at com.android.internal.os.ZygoteInit.main (ZygoteInit.java:858)
```

<!-- Bonus points if you attach a relevant screenshot, screen recording or a small demo project -->
",Do you have the stack trace for the other thread (tid=62)?,"> Do you have the stack trace for the other thread (tid=62)?

@sjudd 

For this specific ANR report, thread 62 is not listed unfortunately, most of the traces stop around threads 30-50. I checked another report and found an very similar stack that did log a Glide thread.

Main thread says ""held by thread 43"", and here is 43 which is also blocked:

```ruby
""glide-source-thread-1"" prio=5 tid=43 Blocked
  | group=""main"" sCount=1 dsCount=0 flags=1 obj=0x12d01f18 self=0x762cabf800
  | sysTid=32074 nice=9 cgrp=default sched=0/0 handle=0x7650cbd4f0
  | state=S schedstat=( 5979636 11002971 42 ) utm=0 stm=0 core=2 HZ=100
  | stack=0x7650bba000-0x7650bbc000 stackSize=1041KB
  | held mutexes=
  at com.bumptech.glide.request.SingleRequest.isResourceSet (SourceFile)
- waiting to lock <0x0b821f0b> (a com.bumptech.glide.request.SingleRequest) held by thread 14
  at com.bumptech.glide.request.ThumbnailRequestCoordinator.isResourceSet (SourceFile:1)
  at com.bumptech.glide.request.ThumbnailRequestCoordinator.isAnyResourceSet (SourceFile:1)
  at com.bumptech.glide.request.SingleRequest.i (SourceFile:1)
  at com.bumptech.glide.request.SingleRequest.a (SourceFile:62)
- locked <0x07f50dcc> (a com.bumptech.glide.request.SingleRequest)
  at com.bumptech.glide.request.SingleRequest.onLoadFailed (SourceFile:1)
- locked <0x07f50dcc> (a com.bumptech.glide.request.SingleRequest)
  at com.bumptech.glide.load.engine.h.a (SourceFile:17)
- locked <0x095ec1e8> (a com.bumptech.glide.load.engine.h)
  at com.bumptech.glide.load.engine.h$a.run (SourceFile:3)
- locked <0x095ec1e8> (a com.bumptech.glide.load.engine.h)
  at com.bumptech.glide.util.Executors$2.execute (SourceFile:1)
  at com.bumptech.glide.load.engine.h.c (SourceFile:23)
  at com.bumptech.glide.load.engine.h.onLoadFailed (SourceFile:4)
  at com.bumptech.glide.load.engine.g.e (SourceFile:3)
  at com.bumptech.glide.load.engine.g.i (SourceFile:10)
  at com.bumptech.glide.load.engine.g.j (SourceFile:4)
  at com.bumptech.glide.load.engine.g.run (SourceFile:7)
  at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1167)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:641)
  at java.lang.Thread.run (Thread.java:764)
  at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run (SourceFile:8)
```

Unfortunately thread 14 is not logged, list goes from 13 and jumps to 15."
bumptech/glide,https://github.com/bumptech/glide/issues/3353,"I have a question for method ""put"" in class DiskLruCacheWrapper.
Following is Source code: 
        DiskLruCache diskCache = getDiskCache();
        Value current = diskCache.get(safeKey);
        if (current != null) {
          return;
        }
 We will not get correct result next time when current  is non null. Because current cache may be wrong, and we can not replace it.
Glide version :4.7.1","How are you writing the incorrect result to begin with? Is this with Glide's default ModelLoaders/decoders? If so, what version of Glide are you using?","> Incorrect results shouldn't be written to the disk cache. How are you writing the incorrect result to begin with? Is this with Glide's default ModelLoaders/decoders? If so, what version of Glide are you using?
@sjudd 1. I do not know why incorrect results has been written to the disk cache, but they really existed in cache. And the scenario we came across was that the disk cache file can not been decoded successfully.
2. I do not know what is your meaning.
3. with default decoders and our custom remote modelLoaders
4. 4.7.1
"
bumptech/glide,https://github.com/bumptech/glide/issues/3157,"  @NonNull
  public final Registry setResourceDecoderBucketPriorityList(@NonNull List<String> buckets) {
    List<String> modifiedBuckets = new ArrayList<>(buckets);
    modifiedBuckets.add(0, BUCKET_PREPEND_ALL);
    modifiedBuckets.add(BUCKET_APPEND_ALL);
    decoderRegistry.setBucketPriorityList(modifiedBuckets);
    return this;
  }
It may appear here
java.lang.ClassCastException: int[] cannot be cast to java.lang.Object[]
        at java.util.Arrays$ArrayList.toArray(Arrays.java:120)
        at java.util.ArrayList.<init>(ArrayList.java:97)
        at com.bumptech.glide.Registry.setResourceDecoderBucketPriorityList(Registry.java:268)
Can you tell me what caused this?

Discovered by tracking， The last sentence here

  public Registry() {
    this.modelLoaderRegistry = new ModelLoaderRegistry(throwableListPool);
    this.encoderRegistry = new EncoderRegistry();
    this.decoderRegistry = new ResourceDecoderRegistry();
    this.resourceEncoderRegistry = new ResourceEncoderRegistry();
    this.dataRewinderRegistry = new DataRewinderRegistry();
    this.transcoderRegistry = new TranscoderRegistry();
    this.imageHeaderParserRegistry = new ImageHeaderParserRegistry();
    setResourceDecoderBucketPriorityList(
        Arrays.asList(BUCKET_GIF, BUCKET_BITMAP, BUCKET_BITMAP_DRAWABLE));
  }
 public static final String BUCKET_GIF = ""Gif"";
  public static final String BUCKET_BITMAP = ""Bitmap"";
  public static final String BUCKET_BITMAP_DRAWABLE = ""BitmapDrawable"";

Here is that this error should not occur",do you use yunos?,没有用那个..
bumptech/glide,https://github.com/bumptech/glide/issues/2977,"<!--
Please fill in the below fields with some data to help us best diagnose the issue.
The more specific you are, the better! You can help a lot by not making us ask these questions.
Feel free to remove any irrelevant parts that you know are not related to the issue.
Any HTML comment like this will be stripped when rendering markdown, no need to delete them.
-->


<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**: 4.6.1 

<!-- Do you use any integration library, like OkHttp3 or Volley? For example:
Fails to display with stock networking, but works with okhttp3-1.4.0 -->
**Integration libraries**: okHttp3

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**:one plus 5 / 8.1( api 27 )

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: 
view flickers and image shows wrong when scrolling

<!-- How do you use Glide?
Make sure you include everything as is in your app's code:
Changing a single method parameter can yield totally different results.
Please clarify any magic variables that appear in the code, for example: ""// `this` is a Fragment""
-->
![](https://i.niupic.com/images/2018/03/23/J8W1np.gif)
**Glide load line / `GlideModule` (if any) / list Adapter code (if any)**:
```java
        ScrollView scrollView = new ScrollView(this);
        main = new LinearLayout(this);
        main.setOrientation(LinearLayout.VERTICAL);
        scrollView.addView(main);
        setContentView(scrollView);

       String url = ""http://image.tuandai.com/bi/avator/201707/612c7ec6-6a9f-4a23-8e76-7dd90a7156c3组-1238.png"";
       String url1 = ""http://image.tuandai.com/bi/avator/201707/1c6d3172-b106-466b-9f2d-0fb8c3985bcfindex_icon_gift.png"";
       String url2 = ""http://image.tuandai.com/bi/avator/201707/f7ce8a49-7aae-4615-89d5-d8b1c6786899index_icon_data.png"";
       String url3 = ""http://image.tuandai.com/bi/avator/201707/7abe3ac4-ebc9-4279-b7a6-bcd05c57111dindex_icon_sign.png"";

        Glide.with(this).load(url).apply(new RequestOptions().fitCenter()).into(newImageView(""fitcenter()""));
        Glide.with(this).load(url1).apply(new RequestOptions().centerCrop()).into(newImageView(""centerCrop()""));
        Glide.with(this).load(url2).apply(new RequestOptions().centerInside()).into(newImageView(""centerInside()""));
        Glide.with(this).load(url3).apply(new RequestOptions().fitCenter()).into(newImageView(""fitcenter()""));
        Glide.with(this).load(url).apply(new RequestOptions().centerCrop()).into(newImageView(""centerCrop()""));
        Glide.with(this).load(url1).apply(new RequestOptions().centerInside()).into(newImageView(""centerInside()""));
        Glide.with(this).load(url2).apply(new RequestOptions().fitCenter()).into(newImageView(""fitcenter()""));
        Glide.with(this).load(url3).apply(new RequestOptions().centerCrop()).into(newImageView(""centerCrop()""));
        Glide.with(this).load(url).apply(new RequestOptions().centerInside()).into(newImageView(""centerInside()""));
        Glide.with(this).load(url2).apply(new RequestOptions().fitCenter()).into(newImageView(""fitcenter()""));
        Glide.with(this).load(url3).apply(new RequestOptions().centerCrop()).into(newImageView(""centerCrop()""));
        Glide.with(this).load(url).apply(new RequestOptions().centerInside()).into(newImageView(""centerInside()""));
        Glide.with(this).load(url1).apply(new RequestOptions().fitCenter()).into(newImageView(""fitcenter()""));
        Glide.with(this).load(url2).apply(new RequestOptions().centerCrop()).into(newImageView(""centerCrop()""));
        Glide.with(this).load(url3).apply(new RequestOptions().centerInside()).into(newImageView(""centerInside()""));

ImageView newImageView(String title) {
        addTextView(title);
        ImageView iv = new ImageView(this);
        iv.setLayoutParams(new LinearLayout.LayoutParams(UiUtil.dp2px(75), UiUtil.dp2px(75)));
        main.addView(iv);
        return iv;
    }
```

<!-- How does your app look like?
We're most interested in the layout attributes and the hierarchy around the ImageView -->
**Layout XML**:
```xml
no xml
```

<!--
What is the error message that you got in the log?
You can find some help on diagnosing issues here: https://github.com/bumptech/glide/wiki/Debugging-and-Error-Handling
-->
**Stack trace / LogCat**:
```ruby
no log
```

<!-- Bonus points if you attach a relevant screenshot, screen recording or a small demo project -->
","Maybe attach a sample app? Creating views like this is unusual, but probably fine. Usually the behavior you're describing comes from view re-use.",@sjudd This problem is caused by the mobile phone system. The mobile phone manufacturer has solved this problem.
bumptech/glide,https://github.com/bumptech/glide/issues/2824,"Original GlideVersion: 4.2.0
Device: Redmi Note 3 
Android Version: 7.1.2
Network: Wifi

When I update to 4.5.0, I can't load image from net url.
Here is the error message
```
E/GlideExecutor: Request threw uncaught throwable
                                                                         java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
                                                                             at java.util.ArrayList.get(ArrayList.java:411)
                                                                             at java.util.Collections$UnmodifiableList.get(Collections.java:1295)
                                                                             at com.bumptech.glide.load.engine.ResourceCacheGenerator.startNext(ResourceCacheGenerator.java:58)
                                                                             at com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:299)
                                                                             at com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:266)
                                                                             at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:230)
                                                                             at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
                                                                             at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
                                                                             at java.lang.Thread.run(Thread.java:761)
                                                                             at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:446)
```

Then I changed to 4.4.0, it worked. So is there something changed in 4.5.0?","What url are you using to reproduce this? Consider sending a pull request with [a failing test case][2].

[1]: https://github.com/bumptech/glide/blob/master/ISSUE_TEMPLATE.md
[2]: http://bumptech.github.io/glide/tut/failing-test-cases.html","I tried many urls, it worked in 4.4.0, but not in 4.5.0.
Just normal use,
```
Glide.with(activity).load(url).into(imageView);

```"
bumptech/glide,https://github.com/bumptech/glide/issues/2818,"<!--
Please fill in the below fields with some data to help us best diagnose the issue.
The more specific you are, the better! You can help a lot by not making us ask these questions.
Feel free to remove any irrelevant parts that you know are not related to the issue.
Any HTML comment like this will be stripped when rendering markdown, no need to delete them.
-->


<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**: 4.5.0

<!-- Do you use any integration library, like OkHttp3 or Volley? For example:
Fails to display with stock networking, but works with okhttp3-1.4.0 -->
**Integration libraries**: okhttp3-integration

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**: doesn't seem device related

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: 
Ok, i'm going to try to give as much details as possible and be concise.

I have a list of conversations (think facebook messenger). When it's a group conversation, I show the avatars of the users in a custom view (DuoAvatarLayout, a layout that wraps two `ImageView`) that shows the pictures side-by-side in a circle:
![](https://dha4w82d62smt.cloudfront.net/items/410O140a3l3w0g003Z1s/%5B194cf79c38be9f03b81ca42929362ff6%5D_Image+2018-01-16+at+4.14.00+PM.png)

Here's the class:
```java
public class DuoAvatarLayout extends LinearLayout {

    private Bitmap maskBitmap;
    private Paint paint, maskPaint;
    private float radius;

    public DuoAvatarLayout(Context context) {
        super(context);
        init(context, null, 0);
    }

    // Other constructors omitted for sake of brevity 
    
    private void init(Context context, AttributeSet attrs, int defStyle) {
        paint = new Paint(Paint.ANTI_ALIAS_FLAG);

        maskPaint = new Paint(Paint.ANTI_ALIAS_FLAG | Paint.FILTER_BITMAP_FLAG);
        maskPaint.setXfermode(new PorterDuffXfermode(PorterDuff.Mode.CLEAR));
        radius = getResources().getDimension(R.dimen.avatar_layout_radius);

        setWillNotDraw(false);
    }

    @Override
    public void draw(Canvas canvas) {
        Bitmap offscreenBitmap = Bitmap.createBitmap(canvas.getWidth(), canvas.getHeight(), Bitmap.Config.ARGB_8888);
        Canvas offscreenCanvas = new Canvas(offscreenBitmap);
        super.draw(offscreenCanvas);

        if (maskBitmap == null) {
            maskBitmap = createMask(canvas.getWidth(), canvas.getHeight());
        }

        offscreenCanvas.drawBitmap(maskBitmap, 0f, 0f, maskPaint);
        canvas.drawBitmap(offscreenBitmap, 0f, 0f, paint);
    }

    private Bitmap createMask(int width, int height) {
        Bitmap mask = Bitmap.createBitmap(width, height, Bitmap.Config.ALPHA_8);
        Canvas canvas = new Canvas(mask);

        Paint paint = new Paint(Paint.ANTI_ALIAS_FLAG);
        paint.setColor(Color.WHITE);

        canvas.drawRect(0, 0, width, height, paint);
        paint.setXfermode(new PorterDuffXfermode(PorterDuff.Mode.CLEAR));
        canvas.drawCircle(radius, radius, radius, paint);

        return mask;
    }
}
```
And the layout:
```xml
<com.myapp.views.widgets.DuoAvatarLayout
    xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    android:id=""@+id/duo_avatar_layout_container""
    android:layout_width=""50dp""
    android:layout_height=""50dp""
    android:orientation=""horizontal""
    >

    <ImageView
        android:id=""@+id/duo_avatar_image_left""
        android:layout_width=""25dp""
        android:layout_height=""50dp""
        android:scaleType=""centerCrop""
        />

    <View
        android:layout_width=""2dp""
        android:layout_height=""match_parent""
        android:paddingHorizontal=""2dp""
        android:background=""@color/white""
        />

    <ImageView
        android:id=""@+id/duo_avatar_image_right""
        android:layout_width=""25dp""
        android:layout_height=""50dp""
        android:scaleType=""centerCrop""
        />

</com.myapp.views.widgets.DuoAvatarLayout>
```
When the user has no picture, the API returns a 300x300 image with the initials of the user. For some reasons (and it's intermittent, it doesn't always happen and I can't seem to understand what's different when it does), sometimes one of these image won't load and I get the stacktrace below. It doesn't crash the app though.
```java
01-16 15:43:56.285 D/Glide: Finished loading BitmapDrawable from DATA_DISK_CACHE for http://192.168.1.171:5060/api/avatars/1-jb.png with size [66x61] in 212.897 ms
01-16 15:43:56.287 W/Glide: Load failed for http://192.168.1.171:5060/api/avatars/1-jb.png with size [66x131]
    class com.bumptech.glide.load.engine.GlideException: Failed to load resource
    There was 1 cause:
    java.lang.IllegalArgumentException(Bitmap not large enough to support new configuration)
     call GlideException#logRootCauses(String) for more detail
      Cause (1 of 1): class java.lang.IllegalArgumentException: Bitmap not large enough to support new configuration
01-16 15:43:56.288 I/Glide: Root cause (1 of 1)
    java.lang.IllegalArgumentException: Bitmap not large enough to support new configuration
        at android.graphics.Bitmap.nativeReconfigure(Native Method)
        at android.graphics.Bitmap.reconfigure(Bitmap.java:267)
        at com.bumptech.glide.load.engine.bitmap_recycle.SizeConfigStrategy.get(SizeConfigStrategy.java:70)
        at com.bumptech.glide.load.engine.bitmap_recycle.LruBitmapPool.getDirtyOrNull(LruBitmapPool.java:172)
        at com.bumptech.glide.load.engine.bitmap_recycle.LruBitmapPool.get(LruBitmapPool.java:124)
        at com.bumptech.glide.load.resource.bitmap.TransformationUtils.centerCrop(TransformationUtils.java:140)
        at com.bumptech.glide.load.resource.bitmap.CenterCrop.transform(CenterCrop.java:22)
        at com.bumptech.glide.load.resource.bitmap.BitmapTransformation.transform(BitmapTransformation.java:97)
        at com.bumptech.glide.load.engine.DecodeJob.onResourceDecoded(DecodeJob.java:527)
        at com.bumptech.glide.load.engine.DecodeJob$DecodeCallback.onResourceDecoded(DecodeJob.java:590)
        at com.bumptech.glide.load.engine.DecodePath.decode(DecodePath.java:45)
        at com.bumptech.glide.load.engine.LoadPath.loadWithExceptionList(LoadPath.java:56)
        at com.bumptech.glide.load.engine.LoadPath.load(LoadPath.java:42)
        at com.bumptech.glide.load.engine.DecodeJob.runLoadPath(DecodeJob.java:497)
        at com.bumptech.glide.load.engine.DecodeJob.decodeFromFetcher(DecodeJob.java:469)
        at com.bumptech.glide.load.engine.DecodeJob.decodeFromData(DecodeJob.java:455)
        at com.bumptech.glide.load.engine.DecodeJob.decodeFromRetrievedData(DecodeJob.java:407)
        at com.bumptech.glide.load.engine.DecodeJob.onDataFetcherReady(DecodeJob.java:376)
        at com.bumptech.glide.load.engine.DataCacheGenerator.onDataReady(DataCacheGenerator.java:95)
        at com.bumptech.glide.load.model.ByteBufferFileLoader$ByteBufferFetcher.loadData(ByteBufferFileLoader.java:74)
        at com.bumptech.glide.load.engine.DataCacheGenerator.startNext(DataCacheGenerator.java:75)
        at com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:299)
        at com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:266)
        at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:230)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)
        at java.lang.Thread.run(Thread.java:764)
        at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:446)
```

<!-- How do you use Glide?
Make sure you include everything as is in your app's code:
Changing a single method parameter can yield totally different results.
Please clarify any magic variables that appear in the code, for example: ""// `this` is a Fragment""
-->
**Glide load line / `GlideModule` (if any) / list Adapter code (if any)**:
Here's the code used to load the image into each `ImageView` of my DuoAvatarLayout. This code is inside my adapter:
```kotlin
members.forEachIndexed { index, member ->
    val requestCreator = 
        GlideApp
            .with(context)
            .load(member.profile.pictureThumbUrl)
            .placeholder(R.drawable.rectangle_placeholder)

    when (index) {
        0 -> requestCreator.into(duoAvatarLeftImage)
        1 -> requestCreator.into(duoAvatarRightImage)
    }
}
```

<!-- Bonus points if you attach a relevant screenshot, screen recording or a small demo project -->
Finally, here's the image it's supposed to load (1-jb.png)
![1-1ae317c33bd344440157e85303d49d82](https://user-images.githubusercontent.com/906656/35011734-38cbf010-fad5-11e7-8d38-9a99317c9c68.png)
Here's a row of my list with the DuoAvatarLayout. Sometimes, one of those images in the circle will not load and I will get the stacktrace.
![](https://dha4w82d62smt.cloudfront.net/items/410O140a3l3w0g003Z1s/%5B194cf79c38be9f03b81ca42929362ff6%5D_Image+2018-01-16+at+4.14.00+PM.png)
","Can you enable downsampler logging and copy/paste the output here?

```
adb shell setprop log.tag.Downsamapler VERBOSE
```

It will be quite verbose so you'll have to try to filter it down to your particular request.",
bumptech/glide,https://github.com/bumptech/glide/issues/2812,"<!--
Please fill in the below fields with some data to help us best diagnose the issue.
The more specific you are, the better! You can help a lot by not making us ask these questions.
Feel free to remove any irrelevant parts that you know are not related to the issue.
Any HTML comment like this will be stripped when rendering markdown, no need to delete them.
-->


<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**: 4.3.1

<!-- Do you use any integration library, like OkHttp3 or Volley? For example:
Fails to display with stock networking, but works with okhttp3-1.4.0 -->
**Integration libraries**:

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**: Pixel Android 8.1

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: 

I'm using gravatar to get the icon for an app, sometimes the user won't have a gravatar profile and that's ok, I just don't show it; however when that happens it seems that Glide doesn't closes the response body.

<!-- How do you use Glide?
Make sure you include everything as is in your app's code:
Changing a single method parameter can yield totally different results.
Please clarify any magic variables that appear in the code, for example: ""// `this` is a Fragment""
-->
**Glide load line / `GlideModule` (if any) / list Adapter code (if any)**:
```java
 Glide.with(context)
                .asBitmap()
                .load(gravatarURL)
                .into(object : SimpleTarget<Bitmap>() {
                    override fun onResourceReady(resource: Bitmap, glideAnimation: Transition<in Bitmap>) {
                        callback.onImageAvailable(resource)
                    }

                    override fun onLoadFailed(errorDrawable: Drawable?) {
                        // nothing expected
                    }
                })
```

<!-- How does your app look like?
We're most interested in the layout attributes and the hierarchy around the ImageView -->
**Layout XML**:
```xml
Irrelevant for this case
```

<!--
What is the error message that you got in the log?
You can find some help on diagnosing issues here: https://github.com/bumptech/glide/wiki/Debugging-and-Error-Handling
-->
**Stack trace / LogCat**:
```ruby
Root cause (1 of 1)
                                                           java.io.FileNotFoundException: https://www.gravatar.com/avatar/abc.jpg?s=96&d=404&r=g
                                                               at com.android.okhttp.internal.huc.HttpURLConnectionImpl.getInputStream(HttpURLConnectionImpl.java:251)
                                                               at com.android.okhttp.internal.huc.DelegatingHttpsURLConnection.getInputStream(DelegatingHttpsURLConnection.java:210)
                                                               at com.android.okhttp.internal.huc.HttpsURLConnectionImpl.getInputStream(Unknown Source:0)
                                                               at com.android.tools.profiler.support.network.httpurl.TrackedHttpURLConnection.getInputStream(TrackedHttpURLConnection.java:356)
                                                               at com.android.tools.profiler.support.network.httpurl.HttpsURLConnection$.getInputStream(HttpsURLConnection$.java:261)
                                                               at com.bumptech.glide.load.data.HttpUrlFetcher.loadDataWithRedirects(HttpUrlFetcher.java:104)
                                                               at com.bumptech.glide.load.data.HttpUrlFetcher.loadData(HttpUrlFetcher.java:54)
                                                               at com.bumptech.glide.load.model.MultiModelLoader$MultiFetcher.loadData(MultiModelLoader.java:96)
                                                               at com.bumptech.glide.load.model.MultiModelLoader$MultiFetcher.startNextOrFail(MultiModelLoader.java:147)
                                                               at com.bumptech.glide.load.model.MultiModelLoader$MultiFetcher.onLoadFailed(MultiModelLoader.java:141)
                                                               at com.bumptech.glide.load.data.HttpUrlFetcher.loadData(HttpUrlFetcher.java:60)
                                                               at com.bumptech.glide.load.model.MultiModelLoader$MultiFetcher.loadData(MultiModelLoader.java:96)
                                                               at com.bumptech.glide.load.engine.SourceGenerator.startNext(SourceGenerator.java:61)
                                                               at com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:298)
                                                               at com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:268)
                                                               at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:229)
                                                               at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)
                                                               at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)
                                                               at java.lang.Thread.run(Thread.java:764)
                                                               at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:413)
```

01-14 18:58:38.279 16938-17139/ W/OkHttpClient: A connection to https://www.gravatar.com/ was leaked. Did you forget to close a response body?

<!-- Bonus points if you attach a relevant screenshot, screen recording or a small demo project -->","Did you forget to close a response body?
01-17 11:02:38.214 19466-19577/com.package.xx W/OkHttpClient: A connection to  http://host.domain.de/ was leaked. Did you forget to close a response body?
```","I bumped up my glide version from `4.3.1` to `4.5.0` and the issue is now gone. If I go back I'm still getting the warning. It seems the OkHttp integration library doesn't actually make a difference for this issue. In my case updating wasn't a problem so I'll use the latest. 

Thanks."
bumptech/glide,https://github.com/bumptech/glide/issues/2708,"<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**: 4.4

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**: Nexus 5X / 7.1.2

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: 

I've found that with version 4.4 sometimes images don’t load. I must point out that this happens rarely, but as it happens I think was better to report it. The loading process is in a very simple RecyclerView with no complex code, which at the present time only displays a very small number of items, not even enough to scroll.

<!-- How do you use Glide?
Make sure you include everything as is in your app's code:
Changing a single method parameter can yield totally different results.
Please clarify any magic variables that appear in the code, for example: ""// `this` is a Fragment""
-->
**Glide load line / `GlideModule` (if any) / list Adapter code (if any)**:
    
    public class AdapterThumbnails extends RecyclerView.Adapter<ThumbnailViewHolder>
    {
        private static final String ASSETS_PATH = ""file:///android_asset/thumbnails/"";
    
        private final String[] mTestList = new String[]{""0.jpg"", ""1.jpg"", ""2.jpg""};
    
        private final Context mContext;
        private final int mMaxSize;
    
        public AdapterThumbnails(final Context context, final int maxSize)
        {
            this.mContext = context;
            this.mMaxSize = maxSize;
        }
    
        @Override
        public long getItemId(final int position)
        {
            return position;
        }
    
        @Override
        public int getItemCount()
        {
            return this.mTestList.length;
        }
    
        @Override
        public ThumbnailViewHolder onCreateViewHolder(final ViewGroup parent, final int viewType)
        {
            final ImageView newView = new ImageView(this.mContext);
            newView.setLayoutParams(new ViewGroup.LayoutParams(this.mMaxSize, this.mMaxSize));
            return new ThumbnailViewHolder(newView);
        }
    
        @Override
        public void onBindViewHolder(final ThumbnailViewHolder holder, final int position)
        {
            final ImageView thumbnail = (ImageView)holder.itemView;
    
            final Uri uri = Uri.parse(AdapterThumbnails.ASSETS_PATH + this.mTestList[position]);
    
            GlideApp.with(this.mContext)
                    .asBitmap()
                    .load(uri)
                    .diskCacheStrategy(DiskCacheStrategy.NONE)
                    .override(this.mMaxSize, this.mMaxSize)
                    .into(thumbnail);
        }
    
        @Override
        public void onViewRecycled(final ThumbnailViewHolder holder)
        {
            GlideApp.with(this.mContext).clear(holder.itemView);
        }
    }

<!--
What is the error message that you got in the log?
You can find some help on diagnosing issues here: https://github.com/bumptech/glide/wiki/Debugging-and-Error-Handling
-->
**Stack trace / LogCat**:
```ruby
E/GlideExecutor: Request threw uncaught throwable
   java.lang.NullPointerException: Attempt to invoke virtual method 'com.bumptech.glide.load.engine.Resource com.bumptech.glide.load.engine.LoadPath.load(com.bumptech.glide.load.data.DataRewinder, com.bumptech.glide.load.Options, int, int, com.bumptech.glide.load.engine.DecodePath$DecodeCallback)' on a null object reference
	   at com.bumptech.glide.load.engine.DecodeJob.runLoadPath(DecodeJob.java:499)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromFetcher(DecodeJob.java:471)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromData(DecodeJob.java:457)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromRetrievedData(DecodeJob.java:411)
	   at com.bumptech.glide.load.engine.DecodeJob.onDataFetcherReady(DecodeJob.java:380)
	   at com.bumptech.glide.load.engine.SourceGenerator.onDataReady(SourceGenerator.java:111)
	   at com.bumptech.glide.load.data.AssetPathFetcher.loadData(AssetPathFetcher.java:40)
	   at com.bumptech.glide.load.engine.SourceGenerator.startNext(SourceGenerator.java:61)
	   at com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:303)
	   at com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:270)
	   at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:234)
	   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
	   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
	   at java.lang.Thread.run(Thread.java:761)
	   at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:445)
12-11 12:10:59.049 30395-30395/com.perracolabs.test W/Glide: Load failed for file:///android_asset/thumbnails/0.jpg with size [189x189]
   class com.bumptech.glide.load.engine.GlideException: Failed to load resource
	 Cause (1 of 1): class java.lang.NullPointerException: Attempt to invoke virtual method 'com.bumptech.glide.load.engine.Resource com.bumptech.glide.load.engine.LoadPath.load(com.bumptech.glide.load.data.DataRewinder, com.bumptech.glide.load.Options, int, int, com.bumptech.glide.load.engine.DecodePath$DecodeCallback)' on a null object reference
12-11 12:10:59.050 30395-30395/com.perracolabs.test I/Glide: Root cause (1 of 1)
   java.lang.NullPointerException: Attempt to invoke virtual method 'com.bumptech.glide.load.engine.Resource com.bumptech.glide.load.engine.LoadPath.load(com.bumptech.glide.load.data.DataRewinder, com.bumptech.glide.load.Options, int, int, com.bumptech.glide.load.engine.DecodePath$DecodeCallback)' on a null object reference
	   at com.bumptech.glide.load.engine.DecodeJob.runLoadPath(DecodeJob.java:499)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromFetcher(DecodeJob.java:471)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromData(DecodeJob.java:457)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromRetrievedData(DecodeJob.java:411)
	   at com.bumptech.glide.load.engine.DecodeJob.onDataFetcherReady(DecodeJob.java:380)
	   at com.bumptech.glide.load.engine.SourceGenerator.onDataReady(SourceGenerator.java:111)
	   at com.bumptech.glide.load.data.AssetPathFetcher.loadData(AssetPathFetcher.java:40)
	   at com.bumptech.glide.load.engine.SourceGenerator.startNext(SourceGenerator.java:61)
	   at com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:303)
	   at com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:270)
	   at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:234)
	   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
	   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
	   at java.lang.Thread.run(Thread.java:761)
	   at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:445)
12-11 12:10:59.051 30395-30395/com.perracolabs.test W/Glide: Load failed for file:///android_asset/thumbnails/0.jpg with size [189x189]
   class com.bumptech.glide.load.engine.GlideException: Failed to load resource
	 Cause (1 of 1): class java.lang.NullPointerException: Attempt to invoke virtual method 'com.bumptech.glide.load.engine.Resource com.bumptech.glide.load.engine.LoadPath.load(com.bumptech.glide.load.data.DataRewinder, com.bumptech.glide.load.Options, int, int, com.bumptech.glide.load.engine.DecodePath$DecodeCallback)' on a null object reference
12-11 12:10:59.051 30395-30395/com.perracolabs.test I/Glide: Root cause (1 of 1)
   java.lang.NullPointerException: Attempt to invoke virtual method 'com.bumptech.glide.load.engine.Resource com.bumptech.glide.load.engine.LoadPath.load(com.bumptech.glide.load.data.DataRewinder, com.bumptech.glide.load.Options, int, int, com.bumptech.glide.load.engine.DecodePath$DecodeCallback)' on a null object reference
	   at com.bumptech.glide.load.engine.DecodeJob.runLoadPath(DecodeJob.java:499)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromFetcher(DecodeJob.java:471)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromData(DecodeJob.java:457)
	   at com.bumptech.glide.load.engine.DecodeJob.decodeFromRetrievedData(DecodeJob.java:411)
	   at com.bumptech.glide.load.engine.DecodeJob.onDataFetcherReady(DecodeJob.java:380)
	   at com.bumptech.glide.load.engine.SourceGenerator.onDataReady(SourceGenerator.java:111)
	   at com.bumptech.glide.load.data.AssetPathFetcher.loadData(AssetPathFetcher.java:40)
	   at com.bumptech.glide.load.engine.SourceGenerator.startNext(SourceGenerator.java:61)
	   at com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:303)
	   at com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:270)
	   at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:234)
	   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
	   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
	   at java.lang.Thread.run(Thread.java:761)
	   at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:445)
```

<!-- Bonus points if you attach a relevant screenshot, screen recording or a small demo project -->
","Do you use Glide elsewhere in your application, or only here?","For this project this is the only place where we use it, as this specific project is still at a very early stage.
In case it is of any use, next is the code of the Glide Module we are using:


	@GlideModule
	public final class GlideManager extends AppGlideModule
	{
		@Override
		public boolean isManifestParsingEnabled()
		{
			return false;
		}

		@Override
		public void applyOptions(final Context context, final GlideBuilder builder)
		{
			final int sizeMemory = 40 * 1024 * 1024; // 40 MB
			builder.setMemoryCache(new LruResourceCache(sizeMemory));

			final int sizeDisk = 75 * 1024 * 1024; // 75 MB
			builder.setDiskCache(new InternalCacheDiskCacheFactory(context, sizeDisk));
		}
	}"
bumptech/glide,https://github.com/bumptech/glide/issues/2689,"Stack:
```
Fatal Exception: java.lang.IllegalStateException: Already released
       at com.bumptech.glide.util.pool.StateVerifier$DefaultStateVerifier.throwIfRecycled(StateVerifier.java:44)
       at com.bumptech.glide.request.SingleRequest.onResourceReady(SingleRequest.java:518)
       at com.bumptech.glide.load.engine.EngineJob.handleResultOnMainThread(EngineJob.java:217)
       at com.bumptech.glide.load.engine.EngineJob$MainThreadCallback.handleMessage(EngineJob.java:322)
       at android.os.Handler.dispatchMessage(Handler.java:98)
       at android.os.Looper.loop(Looper.java:136)
       at android.app.ActivityThread.main(ActivityThread.java:5584)
       at java.lang.reflect.Method.invokeNative(Method.java)
       at java.lang.reflect.Method.invoke(Method.java:515)
       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1268)
       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1084)
       at dalvik.system.NativeStart.main(NativeStart.java)
```

[Fabric](http://crashes.to/s/77a94a0d3c4)",Can you provide the set of steps that you used to reproduce the error? What load line are you using? How often does it reproduce?,"Happened 255 times - [Fabric](http://crashes.to/s/77a94a0d3c4)

It happens various place in the code
A load example where we know it can crash: 
```
Glide.with(getContext())
                    .load(account.getProfilePictureThumbUrl())
                    .apply(new RequestOptions()
                            .fitCenter()
                            .centerCrop())
                    .apply(RequestOptions.bitmapTransform(new RoundedCorners(getContext().getResources().getDimensionPixelSize(R.dimen.corner_radius))))
                    .error(getOfflineRequest(R.drawable.as_shared_default_picture_offline, RequestOptions.bitmapTransform(new RoundedCorners(getContext().getResources().getDimensionPixelSize(R.dimen.corner_radius)))))
                    .listener(new RequestListener<Drawable>() {
                        @Override
                        public boolean onLoadFailed(@Nullable GlideException e, Object model, Target<Drawable> target, boolean isFirstResource) {
                            if (picture == null || progress == null) return false;
                            picture.setVisibility(View.VISIBLE);
                            progress.setVisibility(View.INVISIBLE);
                            if (runnableSuccess != null) { runnableSuccess.run(); }
                            return false;
                        }

                        @Override
                        public boolean onResourceReady(Drawable resource, Object model, Target<Drawable> target, DataSource dataSource, boolean isFirstResource) {
                            if (picture == null || progress == null) return false;
                            picture.setVisibility(View.VISIBLE);
                            progress.setVisibility(View.INVISIBLE);
                            if (runnableSuccess != null) { runnableSuccess.run(); }
                            return false;
                        }
                    })
                    .into(picture);
```

To reproduce:
Start many remote loads with Glide and go offline before Glide is done loading"
bumptech/glide,https://github.com/bumptech/glide/issues/2663,"<!--
Please fill in the below fields with some data to help us best diagnose the issue.
The more specific you are, the better! You can help a lot by not making us ask these questions.
Feel free to remove any irrelevant parts that you know are not related to the issue.
Any HTML comment like this will be stripped when rendering markdown, no need to delete them.
-->


<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**:
4.3.1
<!-- Do you use any integration library, like OkHttp3 or Volley? For example:
Fails to display with stock networking, but works with okhttp3-1.4.0 -->
**Integration libraries**:

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**:
All
<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: 
Glide loads cached image when it should skip cache and/or not cache in the firstplace. This case happens for vector drawables.

<!-- How do you use Glide?
Make sure you include everything as is in your app's code:
Changing a single method parameter can yield totally different results.
Please clarify any magic variables that appear in the code, for example: ""// `this` is a Fragment""
-->
**Glide load line / `GlideModule` (if any) / list Adapter code (if any)**:
```java
                if (backgroundIndex != -1 && background != null) {
                    int res = getBackgroundResource(backgroundIndex);
                    Glide.with(getContext())
                            .load(res)
                            .apply(new RequestOptions()
                                    .skipMemoryCache(true)
                                    .diskCacheStrategy(DiskCacheStrategy.NONE))
                            .listener(new RequestListener<Drawable>() {
                                @Override
                                public boolean onLoadFailed(@Nullable GlideException e, Object model, Target<Drawable> target, boolean isFirstResource) {
                                    SoudfaLog.d(TAG, ""Failed! : "" + e);
                                    return false;
                                }

                                @Override
                                public boolean onResourceReady(Drawable resource, Object model, Target<Drawable> target, DataSource dataSource, boolean isFirstResource) {
                                    SoudfaLog.d(TAG, ""Ready! : dataSource= "" + dataSource);
                                    return false;
                                }
                            })
                            .into(background);
                }
```

<!-- How does your app look like?
We're most interested in the layout attributes and the hierarchy around the ImageView -->
**Layout XML**:
```xml
<?xml version=""1.0"" encoding=""utf-8""?>
<RelativeLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    android:id=""@+id/frame""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:background=""@drawable/auth_background""
    android:alpha=""0""
    android:clickable=""true""
    android:clipChildren=""false""
    android:clipToPadding=""false"">

    <ImageView
        android:id=""@+id/background""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:layout_alignParentBottom=""true""
        android:layout_gravity=""bottom""
        android:adjustViewBounds=""true""
        app:srcCompat=""@drawable/pages_match_overlay_background_1"" />

    <com.soudfa.views.CustomFontTextView
        android:id=""@+id/title""
        style=""@style/XLargeBold""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:layout_alignParentTop=""true""
        android:layout_marginTop=""@dimen/overlay_card_margin_top""
        android:layout_marginStart=""@dimen/padding_48""
        android:layout_marginEnd=""@dimen/padding_48""
        android:lines=""1""
        android:text=""@string/overlay_mutual_interest_title""
        android:textAlignment=""center""
        android:textColor=""@color/brightest""
        android:textSize=""@dimen/overlay_title"" />

    <com.soudfa.views.CustomFontTextView
        android:id=""@+id/content""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:layout_below=""@+id/title""
        android:layout_marginBottom=""@dimen/padding_24""
        android:layout_marginTop=""@dimen/padding_8""
        android:layout_alignStart=""@+id/title""
        android:layout_alignEnd=""@+id/title""
        android:text=""@string/overlay_mutual_interest_content""
        android:textAlignment=""center""
        android:textColor=""@color/brightest""
        android:textSize=""@dimen/overlay_content"" />

    <android.support.constraint.ConstraintLayout xmlns:constraint=""http://schemas.android.com/apk/res-auto""
        android:id=""@+id/pictureContainer""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:layout_below=""@id/content""
        android:layout_above=""@+id/chat_now""
        android:layout_gravity=""bottom""
        android:layout_marginStart=""@dimen/overlay_picture_container_padding_sides""
        android:layout_marginEnd=""@dimen/overlay_picture_container_padding_sides""
        android:layout_marginBottom=""@dimen/overlay_picture_container_padding_bottom""
        android:clickable=""true"">

        <android.support.constraint.Guideline
            android:id=""@+id/center""
            android:layout_width=""0dp""
            android:layout_height=""match_parent""
            android:orientation=""vertical""
            android:visibility=""invisible""
            constraint:layout_constraintGuide_percent=""0.5"" />

        <com.soudfa.views.Notification.OverLay.OverlayPortrait_
            android:id=""@+id/user""
            android:layout_width=""0dp""
            android:layout_height=""0dp""
            android:background=""@drawable/shape_mutual_profile_image_stroke""
            app:layout_constraintDimensionRatio=""1:1""
            app:layout_constraintBottom_toBottomOf=""parent""
            app:layout_constraintTop_toTopOf=""parent""
            constraint:layout_constraintEnd_toEndOf=""parent""
            constraint:layout_constraintStart_toStartOf=""@id/center""
            constraint:layout_constraintHorizontal_bias=""0""
            constraint:layout_constraintVertical_bias=""0""
            android:padding=""9dp"" />

        <com.soudfa.views.Notification.OverLay.OverlayPortrait_
            android:id=""@+id/match""
            android:layout_width=""0dp""
            android:layout_height=""0dp""
            android:background=""@drawable/shape_mutual_profile_image_stroke""
            app:layout_constraintDimensionRatio=""1:1""
            app:layout_constraintBottom_toBottomOf=""parent""
            app:layout_constraintTop_toTopOf=""parent""
            constraint:layout_constraintEnd_toEndOf=""@id/center""
            constraint:layout_constraintStart_toStartOf=""parent""
            constraint:layout_constraintHorizontal_bias=""1""
            constraint:layout_constraintVertical_bias=""0""
            android:padding=""9dp""/>

    </android.support.constraint.ConstraintLayout>

    <Button
        android:id=""@+id/chat_now""
        style=""@style/SoudfaButton.OverLayButton""
        android:layout_width=""@dimen/overlay_button_chat_width""
        android:layout_height=""@dimen/overlay_button_chat_height""
        android:layout_above=""@+id/cancelButton""
        android:layout_centerHorizontal=""true""
        android:layout_marginBottom=""@dimen/padding_24""
        android:layout_marginEnd=""@dimen/padding_48""
        android:layout_marginStart=""@dimen/padding_48""
        android:background=""@drawable/action_overlay_positive""
        android:text=""@string/overlay_mutual_interest_action_positive"" />

    <com.soudfa.views.Buttons.RoundButtonWithIcon_
        android:id=""@+id/cancelButton""
        android:layout_width=""@dimen/overlay_button_cancel""
        android:layout_height=""@dimen/overlay_button_cancel""
        android:layout_alignParentBottom=""true""
        android:layout_centerHorizontal=""true""
        android:layout_marginBottom=""@dimen/padding_12""
        android:background=""@drawable/action_match_overlay_cancel""/>


```

<!--
What is the error message that you got in the log?
You can find some help on diagnosing issues here: https://github.com/bumptech/glide/wiki/Debugging-and-Error-Handling
-->
**Stack trace / LogCat**:
```ruby
11-30 16:19:04.544 13685-13685/com.soudfa D/DEBUG: match-mutual-overlay: Ready! : dataSource MEMORY_CACHE
```

<!-- Bonus points if you attach a relevant screenshot, screen recording or a small demo project -->
",Could you send a pull request with a failing test case? More detail on how to do this here: http://bumptech.github.io/glide/tut/failing-test-cases.html,"Project with cache issue:
[GlideCacheIssue.zip](https://github.com/bumptech/glide/files/1520981/GlideCacheIssue.zip)
"
bumptech/glide,https://github.com/bumptech/glide/issues/2548,"Android Studio 3.0
MacBook High Sierra 10.13.1 
Android emulator Nexus 5X API level 26
Run app using 
`implementation 'com.github.bumptech.glide:glide:4.2.0'`
Everything is fine but change to
`implementation 'com.github.bumptech.glide:glide:4.3.0'`
and it crashes for any image I attempt to display. Images are JPG files hosted by Amazon (cloudfront.net)
Placeholder image is 256x256 32-bit color PNG in the APK
Change back to 4.2.0, sync gradle, build app and it works perfectly again

```
11-01 13:56:52.545 16062-16199/{my app}.debug A/OpenGLRenderer: unknown bitmap configuration
11-01 13:56:52.545 16062-16199/{my app}..debug A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 16199 (glide-disk-cach)
11-01 13:56:52.565 16202-16202/? I/crash_dump32: obtaining output fd from tombstoned
11-01 13:56:52.565 1399-1399/? I//system/bin/tombstoned: received crash request for pid 16062
11-01 13:56:52.565 16202-16202/? I/crash_dump32: performing dump of process 16062 (target tid = 16199)
11-01 13:56:52.566 16202-16202/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
11-01 13:56:52.566 16202-16202/? A/DEBUG: Build fingerprint: 'google/sdk_gphone_x86/generic_x86:8.0.0/OSR1.170720.005/4205617:user/release-keys'
11-01 13:56:52.566 16202-16202/? A/DEBUG: Revision: '0'
11-01 13:56:52.566 16202-16202/? A/DEBUG: ABI: 'x86'
11-01 13:56:52.566 16202-16202/? A/DEBUG: pid: 16062, tid: 16199, name: glide-disk-cach  >>> {my app}.debug <<<
11-01 13:56:52.566 16202-16202/? A/DEBUG: signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------
11-01 13:56:52.567 16202-16202/? A/DEBUG: Abort message: 'unknown bitmap configuration'
11-01 13:56:52.567 16202-16202/? A/DEBUG:     eax 00000000  ebx 00003ebe  ecx 00003f47  edx 00000006
11-01 13:56:52.567 16202-16202/? A/DEBUG:     esi 00003f47  edi 928f95a8
11-01 13:56:52.568 16202-16202/? A/DEBUG:     xcs 00000073  xds 0000007b  xes 0000007b  xfs 0000003b  xss 0000007b
11-01 13:56:52.568 16202-16202/? A/DEBUG:     eip b5aebac4  ebp 928f95c8  esp 928f955c  flags 00000296
11-01 13:56:52.802 16202-16202/? A/DEBUG: backtrace:
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #00 pc 00000ac4  [vdso:b5aeb000] (__kernel_vsyscall+16)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #01 pc 00075b3c  /system/lib/libc.so (tgkill+28)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #02 pc 0001f04e  /system/lib/libc.so (abort+110)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #03 pc 00006a06  /system/lib/liblog.so (__android_log_assert+294)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #04 pc 0002784f  /system/lib/libhwui.so (_ZN7androidL14allocateBitmapEP8SkBitmapP12SkColorTablePF5sk_spINS_6BitmapEEjRK11SkImageInfojS3_E+191)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #05 pc 000280dd  /system/lib/libhwui.so (_ZN7android6Bitmap18allocateHeapBitmapEP8SkBitmapP12SkColorTable+45)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #06 pc 000fdb9d  /system/lib/libandroid_runtime.so (_ZL14Bitmap_creatorP7_JNIEnvP8_jobjectP10_jintArrayiiiiihP12_jfloatArrayS2_+365)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #07 pc 00aacd46  /system/framework/x86/boot-framework.oat (offset 0x5e6000) (android.graphics.Bitmap.nativeCreate+294)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #08 pc 00638ea2  /system/lib/libart.so (art_quick_invoke_static_stub+418)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #09 pc 00112b92  /system/lib/libart.so (_ZN3art9ArtMethod6InvokeEPNS_6ThreadEPjjPNS_6JValueEPKc+306)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #10 pc 003231ff  /system/lib/libart.so (_ZN3art11interpreter34ArtInterpreterToCompiledCodeBridgeEPNS_6ThreadEPNS_9ArtMethodEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+367)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #11 pc 0031cec3  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb1ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+803)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #12 pc 006217fd  /system/lib/libart.so (MterpInvokeStaticRange+397)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #13 pc 00629d21  /system/lib/libart.so (artMterpAsmInstructionStart+15265)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #14 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #15 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #16 pc 0031ce97  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb1ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+759)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #17 pc 006217fd  /system/lib/libart.so (MterpInvokeStaticRange+397)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #18 pc 00629d21  /system/lib/libart.so (artMterpAsmInstructionStart+15265)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #19 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #20 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #21 pc 0031bdb5  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+773)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #22 pc 0061fac4  /system/lib/libart.so (MterpInvokeStatic+484)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #23 pc 00629a21  /system/lib/libart.so (artMterpAsmInstructionStart+14497)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #24 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #25 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #26 pc 0031bdb5  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+773)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #27 pc 0061fac4  /system/lib/libart.so (MterpInvokeStatic+484)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #28 pc 00629a21  /system/lib/libart.so (artMterpAsmInstructionStart+14497)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #29 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #30 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #31 pc 0031bdb5  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+773)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #32 pc 0061fac4  /system/lib/libart.so (MterpInvokeStatic+484)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #33 pc 00629a21  /system/lib/libart.so (artMterpAsmInstructionStart+14497)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #34 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #35 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #36 pc 0031bdb5  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+773)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #37 pc 0061f3a3  /system/lib/libart.so (MterpInvokeInterface+1635)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #38 pc 00629aa1  /system/lib/libart.so (artMterpAsmInstructionStart+14625)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #39 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #40 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #41 pc 0031bdb5  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+773)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #42 pc 0061fac4  /system/lib/libart.so (MterpInvokeStatic+484)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #43 pc 00629a21  /system/lib/libart.so (artMterpAsmInstructionStart+14497)
11-01 13:56:52.802 16202-16202/? A/DEBUG:     #44 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #45 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #46 pc 0031ce97  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb1ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+759)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #47 pc 0062154e  /system/lib/libart.so (MterpInvokeDirectRange+462)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #48 pc 00629ca1  /system/lib/libart.so (artMterpAsmInstructionStart+15137)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #49 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #50 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #51 pc 0031ce97  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb1ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+759)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #52 pc 0061feb6  /system/lib/libart.so (MterpInvokeVirtualRange+838)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #53 pc 00629ba1  /system/lib/libart.so (artMterpAsmInstructionStart+14881)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #54 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #55 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #56 pc 0031bdb5  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+773)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #57 pc 0061e141  /system/lib/libart.so (MterpInvokeVirtual+881)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #58 pc 006298a1  /system/lib/libart.so (artMterpAsmInstructionStart+14113)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #59 pc 002f5f59  /system/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadEPKNS_7DexFile8CodeItemERNS_11ShadowFrameENS_6JValueEb+537)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #60 pc 002fdeda  /system/lib/libart.so (_ZN3art11interpreter33ArtInterpreterToInterpreterBridgeEPNS_6ThreadEPKNS_7DexFile8CodeItemEPNS_11ShadowFrameEPNS_6JValueE+234)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #61 pc 0031bdb5  /system/lib/libart.so (_ZN3art11interpreter6DoCallILb0ELb0EEEbPNS_9ArtMethodEPNS_6ThreadERNS_11ShadowFrameEPKNS_11InstructionEtPNS_6JValueE+773)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #62 pc 0061e141  /system/lib/libart.so (MterpInvokeVirtual+881)
11-01 13:56:52.803 16202-16202/? A/DEBUG:     #63 pc 006298a1  /system/lib/libart.so (artMterpAsmInstructionStart+14113)
11-01 13:56:53.663 1399-1399/? E//system/bin/tombstoned: Tombstone written to: /data/tombstones//tombstone_05
```",Do you have GlideModule? Can you please include a Glide load line you're using? (If you can narrow down which one is crashing),"```
                val requestOptions = RequestOptions().override(image.maxWidth, image.maxHeight).placeholder(R.drawable.dress_inventory)

                Glide.with(context)
                        .load(detail.Images[0].ThumbUrl)
                        .apply(requestOptions)
                        .into(object : ViewTarget<View, Drawable>(image) {
                            override fun onResourceReady(resource: Drawable, glideAnimation: Transition<in Drawable>?) =
                                    image.setImageDrawable(resource.current)

                            override fun onLoadFailed(errorDrawable: Drawable?) = Unit
                        })

```

Not using a GlideModule"
bumptech/glide,https://github.com/bumptech/glide/issues/2541,"Device: Nexus 5X. Android 7.1.2

After trying 4.3 I can confirm that Gifs do not always play. Sometimes the same Gif file will not start to play at all, other times will play without problems, and other times will play but at slow motion.

I’ve tried with several different Gif files just to discard if it was a specific file, but the issue happens with any Gif file and not specific to any.

I’ve tried to find a pattern to reproduce the issue, but it happens randomly with any Gif file. 

I can confirm that when reverting to 4.2 the issue disappears.
",Do you have another sample app you might be able to attach the reproduces the issue?,
bumptech/glide,https://github.com/bumptech/glide/issues/2472,"With this layout:

`````
<FrameLayout
        xmlns:android=""http://schemas.android.com/apk/res/android""
        xmlns:tools=""http://schemas.android.com/tools""
        android:layout_width=""@dimen/media_bubble_height""
        android:layout_height=""@dimen/media_bubble_height""
        android:layout_marginBottom=""5dp""
        android:layout_gravity=""center""
        android:scaleType=""centerCrop""
        android:adjustViewBounds=""true"">

    <ImageView android:id=""@+id/image""
               android:layout_width=""match_parent""
               android:layout_height=""match_parent""
               android:adjustViewBounds=""true""
               android:clickable=""false""
               android:longClickable=""false""
               android:scaleType=""fitCenter""/>

</FrameLayout>
`````

Loading a gif into the ImageView:

`````
    GlideApp.with(getContext())
            .load(model)
            .diskCacheStrategy(DiskCacheStrategy.NONE)
            .transform(new RoundedCorners(radius))
            .transition(withCrossFade())
            .into(image);
`````

Consistently produces these glitches in Glide 4.2.0:
![glitchy](https://user-images.githubusercontent.com/512439/31473424-40e8c868-aea9-11e7-994f-14a83fdee1ff.gif)

Happens for every gif I try, here's a sample:
https://media.giphy.com/media/xUNd9W5Wbh8cRmdFBe/giphy.gif

In Glide 3.7 I used a custom RoundedCorners transformation (I don't think one came with Glide?) and this wasn't an issue.

**Glide Version**: 4.2.0","Does the old custom one you used with 3.7 cause these glitches as well? Or just the built in one in Glide? 

Looks like #2345","The old custom one I used with 3.7 worked fine. I'm working on upgrading to 4.x to see if that resolves #2453, but I'm having problems with this and gif playback speed.

Here's a small standalone project that reproduces these glitches:
https://github.com/moxie0/GlitchyCorners"
bumptech/glide,https://github.com/bumptech/glide/issues/2462,"```
10-10 11:35:03.857 26060-27418/com.qunar.im E/GlideExecutor: Request threw uncaught throwable
                                                             java.lang.IllegalArgumentException: Fetchers don't match!, old: com.bumptech.glide.load.model.FileLoader$FileFetcher@5501613 new: com.bumptech.glide.load.model.FileLoader$FileFetcher@b90ae0a
                                                                 at com.bumptech.glide.util.Preconditions.checkArgument(Preconditions.java:17)
                                                                 at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:245)
                                                                 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
                                                                 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
                                                                 at java.lang.Thread.run(Thread.java:776)
                                                                 at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:386)
```

Load failed for https://qt.qunar.com/file/v2/download/perm/8d67e8b59808833e62cbcdd080b4fa36.gif?name=8d67e8b59808833e62cbcdd080b4fa36.gif with size [432x432]

```java
RequestOptions requestOptions = new RequestOptions()
                    .error(R.drawable.atom_ui_sharemore_picture)
                    .placeholder(R.drawable.atom_ui_sharemore_picture)
                    .diskCacheStrategy(DiskCacheStrategy.ALL)
                    .dontAnimate();
            Glide.with(context)
                    .asGif()
                    .load(url)
                    .apply(requestOptions) 
                    .into(mLoadingImgView);
```","What version of Glide are you using? Please always fill out the issue template.

Can you reproduce this in a sample app?","I use the latest version 4.2，I just delete requestOptions， only use
`Glide.with(context)
                    .asGif()
                    .load(url)
                    .into(mLoadingImgView);`
then it's ok， I don't know why"
bumptech/glide,https://github.com/bumptech/glide/issues/2452,"<!--
Please fill in the below fields with some data to help us best diagnose the issue.
The more specific you are, the better! You can help a lot by not making us ask these questions.
Feel free to remove any irrelevant parts that you know are not related to the issue.
Any HTML comment like this will be stripped when rendering markdown, no need to delete them.
-->


<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**:Glide 4.2.0 (https://github.com/bumptech/glide/releases)

<!-- Do you use any integration library, like OkHttp3 or Volley? For example:
Fails to display with stock networking, but works with okhttp3-1.4.0 -->
**Integration libraries**:No

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**:HUAWEI Mate9 7.0

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: compile Error: RequestOptionsGenerator$1 cannot be accessed
Error class file:... \libs\compiler-4.2.0.jar (com/bumptech/glide/annotation/compiler/RequestOptionsGenerator$1.class)
Class RequestOptionsGenerator$1 closed method property error
Please delete this file or make sure it is in the correct classpath.
Error: RequestOptionsGenerator$1 cannot be accessed
Error class file:... \libs\compiler-4.2.0.jar (com/bumptech/glide/annotation/compiler/RequestOptionsGenerator$1.class)
Class RequestOptionsGenerator$1 closed method property error
Please delete this file or make sure it is in the correct classpath.
1 mistakes
",Can you try running `gradlew` with `--stacktrace`?,"@TWiStErRob I see some duplicate classes in compiler-4.2.0.jar, you can open it by WinRAR"
bumptech/glide,https://github.com/bumptech/glide/issues/2413,"version
```   
 compile ('com.github.bumptech.glide:glide:4.2.0-SNAPSHOT'){
        exclude module: 'support-annotations'
    }
```
crash：

```
java.lang.NullPointerException: Attempt to invoke virtual method 'android.graphics.drawable.Drawable com.bumptech.glide.request.RequestOptions.getFallbackDrawable()' on a null object reference
 at com.bumptech.glide.request.SingleRequest.getFallbackDrawable(:361)
 at com.bumptech.glide.request.SingleRequest.setErrorPlaceholder(:402)
 at com.bumptech.glide.request.SingleRequest.onLoadFailed(:571)
 at com.bumptech.glide.request.SingleRequest.onLoadFailed(:553)
 at com.bumptech.glide.load.engine.EngineJob.handleExceptionOnMainThread(:259)
 at com.bumptech.glide.load.engine.EngineJob$iF.handleMessage(:291)
 at android.os.Handler.dispatchMessage(Handler.java:98)
 at android.os.Looper.loop(Looper.java:135)
 at android.app.ActivityThread.main(ActivityThread.java:5309)
 at java.lang.reflect.Method.invoke(Native Method)
 at java.lang.reflect.Method.invoke(Method.java:372)
 at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:908)
 at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:703)

```","What do you set as placeholder, error, and fallback drawables?
2. How do you load it (load line code)?
3. Is there any available sample on GitHub can directly reproduce this?","```
//load network gif image

   Glide.with(context)
                        .load(imageUri)
                        .apply(RequestOptions.diskCacheStrategyOf(DiskCacheStrategy.AUTOMATIC))
                        .apply(RequestOptions().placeholder(imageView.context.resources.getDrawable(holderConfig?.loading ?: R.drawable.emoticon_image_show_loading)))
                        .apply(RequestOptions().error(imageView.context.resources.getDrawable(holderConfig?.error ?: R.drawable.emoticon_image_show_retry)))
                        .listener(object : RequestListener<Drawable> {
                            override fun onLoadFailed(e: GlideException?, model: Any?, target: Target<Drawable>?, isFirstResource: Boolean): Boolean {
                                loadImageCompleteListener?.onLoadImageComplete(false)
                                return false
                            }

                            override fun onResourceReady(resource: Drawable?, model: Any?, target: Target<Drawable>?, dataSource: DataSource?, isFirstResource: Boolean): Boolean {
                                loadImageCompleteListener?.onLoadImageComplete(true)
                                return false
                            }
                        })
                        .into(imageView)

```"
bumptech/glide,https://github.com/bumptech/glide/issues/2370,"<!--
Please fill in the below fields with some data to help us best diagnose the issue.
The more specific you are, the better! You can help a lot by not making us ask these questions.
Feel free to remove any irrelevant parts that you know are not related to the issue.
Any HTML comment like this will be stripped when rendering markdown, no need to delete them.
-->


<!-- What version of Glide you're running, for example: 3.7.1 | 3.8.0-SNAPSHOT | 4.0.0-SNAPSHOT
It's essentially the version number from your build.gradle: `dependencies { compile '...:x.y.z' }` -->
**Glide Version**: 4.1.1

<!-- Share the details of your issue in prose, detailing actual and expected behavior. It also helps if you give some info **why** you are trying to do something as opposed to **what** is not working. -->
**Issue details / Repro steps / Use case background**: 

I found that glide 4.x have add a new api 
```
  public static RequestManager with(View view) {
    return getRetriever(view.getContext()).get(view);
  }
```

and I look into the source code 
```
  public RequestManager get(View view) {
    if (Util.isOnBackgroundThread()) {
      return get(view.getContext().getApplicationContext());
    }

    Preconditions.checkNotNull(view);
    Preconditions.checkNotNull(view.getContext(),
        ""Unable to obtain a request manager for a view without a Context"");
    Activity activity = findActivity(view.getContext());
    // The view might be somewhere else, like a service.
    if (activity == null) {
      return get(view.getContext().getApplicationContext());
    }

    // Support Fragments.
    if (activity instanceof FragmentActivity) {
      Fragment fragment = findSupportFragment(view, (FragmentActivity) activity);
      if (fragment == null) {
        return get(activity);
      }
      return get(fragment);
    }

    // Standard Fragments.
    android.app.Fragment fragment = findFragment(view, activity);
    if (fragment == null) {
      return get(activity);
    }
    return get(fragment);
  }
```

and I find a bug that if someone use AppCompatActivity  (which extends FragmentActivity).
And in that activity, use the android.app.Fragment, inside the fragment, use the code below to load image. 
```
    RequestManager manager = Glide.with(viewHolder.imageView);
    manager.load(current.uri).into(viewHolder.imageView);
```
The ```manager``` we get is from ```public RequestManager get(Activity activity)```, 
instead of  ```public RequestManager get(android.app.Fragment fragment)```
 ","Can you clarify:

> The manager we get is from public RequestManager get(Activity activity),
> instead of public RequestManager get(android.app.Fragment fragment)

How are you determining this? Can you attach a sample app that reproduces the issue, or a failing test case?","Here is the Sample https://github.com/liubaoyua/Example.

The debugger show that in MainActivity.java line 91,  
```
RequestManager manager = Glide.with(imageView);
manager.load(""https://assets-cdn.github.com/images/modules/site/universe-logo.png"")
                    .into(imageView);
```
The manager come from  RequestManagerRetriever.get(android.app.Activity), but the imageView is a fragment view."
bumptech/glide,https://github.com/bumptech/glide/issues/2345,"
![image](https://user-images.githubusercontent.com/21040178/30143749-047667b4-93ba-11e7-9a38-eb04272e314d.png)
![image](https://user-images.githubusercontent.com/21040178/30143758-172ab068-93ba-11e7-8d67-0001dc037ae4.png)

![image](https://user-images.githubusercontent.com/21040178/30143844-61dd13e4-93ba-11e7-98bd-9f714d0307fe.png)

Is there anything wrong with my code?
Why is the picture like this?
","What version of Glide are you using? Is this on a particular device or version of Android, or do you see this on multiple?

Have you tried it without the RoundedCorners transform? ","compile 'com.github.bumptech.glide:glide:4.0.0'
annotationProcessor 'com.github.bumptech.glide:compiler:4.0.0'"
bumptech/glide,https://github.com/bumptech/glide/issues/2271,"**Glide Version**: 4.0.0

**Integration libraries**: N/A

**Device/Android Version**: Nexus 7 2013 (7.1.2), OnePlus One (7.1.2)

**Issue details / Repro steps / Use case background**: 

Loading a local GIF (a copy of [this GIF](https://listen.moe/files/images/kanna.gif)) displays overdraw artifacts.

Within the activity ([link to code](https://github.com/arkon/listen-moe-android/blob/a389e9db8df3020f30f221b38cf166f6acfffa96/app/src/main/java/me/echeung/moemoekyun/ui/activities/SearchActivity.java#L51)):
```java
Glide.with(this)
        .load(R.drawable.kanna_dancing)
        .into(binding.searchPlaceholder);
```

**Layout XML** ([link to code](https://github.com/arkon/listen-moe-android/blob/1b8756aa00b5bbe2d9bbfcee5048afe10e267329/app/src/main/res/layout/activity_search.xml#L67)):
```xml
<ImageView
    android:id=""@+id/search_placeholder""
    android:layout_width=""156dp""
    android:layout_height=""200dp""
    android:layout_gravity=""center""
    android:layout_marginBottom=""16dp"" />
```

**Stack trace / LogCat**:
```ruby
E/GlideExecutor: Request threw uncaught throwable
    java.lang.NullPointerException: Attempt to invoke interface method 'void com.bumptech.glide.load.data.DataFetcher.cleanup()' on a null object reference
        at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:238)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
        at java.lang.Thread.run(Thread.java:761)
        at com.bumptech.glide.lo    GlideExecutor.java:347)
```

**GIF of what it looks like**:
<details>
<summary>Expand to see GIF</summary>

![baconnjh47deugene08192017111452](https://user-images.githubusercontent.com/4098258/29487952-a9e123aa-84cf-11e7-829f-85d57c89c7c9.gif)

</details>",Can we just have an option to force redrawing each frame?,"I ended up just opening up the GIF in Photoshop and exporting it again, which resulted in a (non-broken) GIF.

I assume that means the original GIF had incorrect disposal, but I don't know anything about that."
bumptech/glide,https://github.com/bumptech/glide/issues/2262,"I am trying to migrate from v3 to v4 and I'm running into an error I cannot seem to solve. Perhaps it is a bug in 4.0

I have seven fragments containing list views, each is using Glide to load images, and all are tied to the same activity. I'm using ""Glide.with(Fragment)"" for each fragment.

In the activity onDestroy, I'm seeing the following crash, which is weird, because I've done my best to not call ""Glide.with(Activity)"". Either way, I wouldn't expect this exception.

> Caused by: java.lang.IllegalStateException: Failed to remove target from managers
                                                                                      at com.bumptech.glide.Glide.removeFromManagers(Glide.java:639)
                                                                                      at com.bumptech.glide.RequestManager.untrackOrDelegate(RequestManager.java:426)
                                                                                      at com.bumptech.glide.RequestManager.clear(RequestManager.java:412)
                                                                                      at com.bumptech.glide.RequestManager.onDestroy(RequestManager.java:272)
                                                                                      at com.bumptech.glide.manager.ActivityFragmentLifecycle.onDestroy(ActivityFragmentLifecycle.java:64)
                                                                                      at com.bumptech.glide.manager.SupportRequestManagerFragment.onDestroy(SupportRequestManagerFragment.java:187)
                                                                                      at android.support.v4.app.Fragment.performDestroy(Fragment.java:2496)
                                                                                      at android.support.v4.app.FragmentManagerImpl.moveToState(FragmentManager.java:1483)
                                                                                      at android.support.v4.app.FragmentManagerImpl.moveFragmentToExpectedState(FragmentManager.java:1569)
                                                                                      at android.support.v4.app.FragmentManagerImpl.moveToState(FragmentManager.java:1636)
                                                                                      at android.support.v4.app.FragmentManagerImpl.dispatchDestroy(FragmentManager.java:3028)
                                                                                      at android.support.v4.app.Fragment.performDestroy(Fragment.java:2492)
                                                                                      at android.support.v4.app.FragmentManagerImpl.moveToState(FragmentManager.java:1483)
                                                                                      at android.support.v4.app.FragmentManagerImpl.moveFragmentToExpectedState(FragmentManager.java:1569)
                                                                                      at android.support.v4.app.FragmentManagerImpl.moveToState(FragmentManager.java:1636)
                                                                                      at android.support.v4.app.FragmentManagerImpl.dispatchDestroy(FragmentManager.java:3028)
                                                                                      at android.support.v4.app.FragmentController.dispatchDestroy(FragmentController.java:262)
                                                                                      at android.support.v4.app.FragmentActivity.onDestroy(FragmentActivity.java:390)
                                                                                      at android.support.v7.app.AppCompatActivity.onDestroy(AppCompatActivity.java:209)","Do you see this every time your Activity is destroyed? Or only sometimes? 

If you could reproduce this in a sample app it would be much easier for me to investigate. I agree this crash shouldn't happen.","I did not see this every time the activity was destroyed. I do believe it is a race condition.

Unfortunately, I am pressed for time and just reverted to the old version of Glide I was using."
bumptech/glide,https://github.com/bumptech/glide/issues/2240,"**Glide Version**: glide:4.0.0-RC0
**Integration libraries**: None
**Device/Android Version**: Android 7.1
**Issue details / Repro steps / Use case background**: 
There is big video (mp4) file, over 2.2G, I use glide to get thumbnail, it cause exception.

**Glide load line / `GlideModule` (if any) / list Adapter code (if any)**:
compile 'com.github.bumptech.glide:glide:4.0.0-RC0'
I do not use GlideModule
Bitmap thumbnail = null;
      thumbnail =
          Glide.with(context)
              .asBitmap()
              .apply(
                  new RequestOptions()
                      .override(request.getWidth(), request.getHeight())
                      .centerCrop())
              .load(filePath)
              .submit(request.getWidth(), request.getHeight())
              .get();

**Stack trace / LogCat**:


08-12 18:53:27.629  2438  4317 E GlideExecutor: java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:850)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at com.bumptech.glide.util.ByteBufferUtil.fromFile(ByteBufferUtil.java:31)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at com.bumptech.glide.load.model.ByteBufferFileLoader$ByteBufferFetcher.loadData(ByteBufferFileLoader.java:59)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at com.bumptech.glide.load.engine.SourceGenerator.startNext(SourceGenerator.java:61)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at com.bumptech.glide.load.engine.DecodeJob.runGenerators(DecodeJob.java:275)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at com.bumptech.glide.load.engine.DecodeJob.runWrapped(DecodeJob.java:245)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at com.bumptech.glide.load.engine.DecodeJob.run(DecodeJob.java:220)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at java.lang.Thread.run(Thread.java:761)
08-12 18:53:27.629  2438  4317 E GlideExecutor: 	at com.bumptech.glide.load.engine.executor.GlideExecutor$DefaultThreadFactory$1.run(GlideExecutor.java:347)
","Can you reproduce this on multiple devices or versions of Android? Or only one particular device/version of Android?

The code in our control uses longs for file size, it looks there's some internal cast from long to int in the framework code. ","> Hi， sjudd,
> In FileChannelImpl.map, it will check size.
> If size > Integer.MAX_VALUE, it will throw exception.
> It's android source code, so it can not change. 
> So if we want to get thumbnail for one file (ove 2GB file), how can I do?

moved to #2252 "
bumptech/glide,https://github.com/bumptech/glide/issues/2237,"**Glide Version**: 4.0.0

**Integration libraries**: okhttp3-integration

<!-- What devices you managed to get the issue to come up on? For example:
fails on Galaxy S4/GT-I9500 4.4.2, works fine on Nexus 6P 5.1 and Genymotion Nexus 5 5.0.1 -->
**Device/Android Version**: Galaxy Note 5 7.0/Nexus 6P 8.0

In my app there is a list (RecyclerView) of images, which load through Glide. Some images are GIF, so for them I use static thumbnails. When I quickly scroll down and up the app crashes with following exception:
```
E/AndroidRuntime: FATAL EXCEPTION: main
Process: com.blinkseven.jrviewer, PID: 18619
java.util.ConcurrentModificationException
    at java.util.ArrayList$Itr.next(ArrayList.java:831)
    at com.bumptech.glide.request.target.ViewTarget$SizeDeterminer.notifyCbs(ViewTarget.java:180)
    at com.bumptech.glide.request.target.ViewTarget$SizeDeterminer.checkCurrentDimens(ViewTarget.java:197)
    at com.bumptech.glide.request.target.ViewTarget$SizeDeterminer$SizeDeterminerLayoutListener.onPreDraw(ViewTarget.java:310)
    at android.view.ViewTreeObserver.dispatchOnPreDraw(ViewTreeObserver.java:1013)
    at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2513)
    at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1522)
    at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:7098)
    at android.view.Choreographer$CallbackRecord.run(Choreographer.java:927)
    at android.view.Choreographer.doCallbacks(Choreographer.java:702)
    at android.view.Choreographer.doFrame(Choreographer.java:638)
    at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:913)
    at android.os.Handler.handleCallback(Handler.java:751)
    at android.os.Handler.dispatchMessage(Handler.java:95)
    at android.os.Looper.loop(Looper.java:154)
    at android.app.ActivityThread.main(ActivityThread.java:6682)
    at java.lang.reflect.Method.invoke(Native Method)
    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1520)
    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1410)
```
I noticed that the app crashes only on items with GIFs and its thumbnails, namely when I include thumbnails loading.

<!-- How do you use Glide?
Make sure you include everything as is in your app's code:
Changing a single method parameter can yield totally different results.
Please clarify any magic variables that appear in the code, for example: ""// `this` is a Fragment""
-->
Here is an example of loading GIFs with Glide:
```
RequestBuilder<Drawable> thumbnailRequest = GlideApp
                .with(this)
                .load(imageModel.getUri())
                .thumbnail(0.5f)
                .fallback(android.R.color.holo_orange_light)
                .placeholder(android.R.color.holo_green_light)
                .error(android.R.color.holo_red_light)
                .dontAnimate();

        GlideApp
                .with(this)
                .load(imageModel.getFullUri())
                .listener(listener)
                // Load gif's thumbnail through RequestBuilder
                .thumbnail(thumbnailRequest)
                .fallback(android.R.color.holo_orange_light)
                .placeholder(android.R.color.holo_green_light)
                .error(android.R.color.holo_red_light)
                .into((ImageView) findViewById(R.id.image));
```

If exclude 'thumbnail' option there is no exception.",Can you share your Listener code? ,"Yes, here it is:
```
RequestListener<Drawable> listener = new RequestListener<Drawable>() {
            @Override
            public boolean onLoadFailed(@Nullable GlideException e, Object model,
                                        Target<Drawable> target, boolean isFirstResource) {
                return false;
            }

            @Override
            public boolean onResourceReady(Drawable resource, Object model, Target<Drawable> target,
                                           DataSource dataSource, boolean isFirstResource) {
                textView.setVisibility(View.GONE);
                return false;
            }
        };
```"
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/3924,"![image](https://user-images.githubusercontent.com/30915794/38464185-bab94996-3b3b-11e8-941d-d915fe797b80.png)
If I don't set the drawing icon to false, there will be problems.
",What problems?,If I do not turn off the method of drawing icon，dataset doesn't have any data. The program reads dataset's data and will reports the array subscript's transboundary.
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/3907,"I have 2 BarChart on the same page, both zoomed in, now I put one finger on one chart and second finger to the other chart and try to zoom out. It crashes with this stack trace:

```
    Process: com.path.sadow, PID: 28936
    java.lang.IllegalArgumentException: pointerIndex out of range
        at android.view.MotionEvent.nativeGetAxisValue(Native Method)
        at android.view.MotionEvent.getX(MotionEvent.java:2286)
        at android.support.v4.view.ViewPager.onInterceptTouchEvent(ViewPager.java:2066)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2368)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at android.view.ViewGroup.dispatchTransformedTouchEvent(ViewGroup.java:2841)
        at android.view.ViewGroup.dispatchTouchEvent(ViewGroup.java:2516)
        at com.android.internal.policy.PhoneWindow$DecorView.superDispatchTouchEvent(PhoneWindow.java:2823)
        at com.android.internal.policy.PhoneWindow.superDispatchTouchEvent(PhoneWindow.java:1848)
        at android.app.Activity.dispatchTouchEvent(Activity.java:3047)
        at android.support.v7.view.WindowCallbackWrapper.dispatchTouchEvent(WindowCallbackWrapper.java:68)
        at com.android.internal.policy.PhoneWindow$DecorView.dispatchTouchEvent(PhoneWindow.java:2784)
        at android.view.View.dispatchPointerEvent(View.java:10229)
        at android.view.ViewRootImpl$ViewPostImeInputStage.processPointerEvent(ViewRootImpl.java:5403)
        at android.view.ViewRootImpl$ViewPostImeInputStage.onProcess(ViewRootImpl.java:5239)
        at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4679)
        at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4732)
        at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4698)
        at android.view.ViewRootImpl$AsyncInputStage.forward(ViewRootImpl.java:4840)
        at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4706)
        at android.view.ViewRootImpl$AsyncInputStage.apply(ViewRootImpl.java:4897)
        at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4679)
        at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4732)
        at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4698)
        at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4706)
        at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4679)
        at android.view.ViewRootImpl.deliverInputEvent(ViewRootImpl.java:7376)
        at android.view.ViewRootImpl.doProcessInputEvents(ViewRootImpl.java:7254)
        at android.view.ViewRootImpl.enqueueInputEvent(ViewRootImpl.java:7215)
        at android.view.ViewRootImpl$WindowInputEventReceiver.onInputEvent(ViewRootImpl.java:7486)
        at android.view.InputEventReceiver.dispatchInputEvent(InputEventReceiver.java:185)
        at android.view.InputEventReceiver.nativeConsumeBatchedInputEvents(Native Method)
        at android.view.InputEventReceiver.consumeBatchedInputEvents(InputEventReceiver.java:176)
        at android.view.ViewRootImpl.doConsumeBatchedInput(ViewRootImpl.java:7450)
        at android.view.ViewRootImpl$ConsumeBatchedInputRunnable.run(ViewRootImpl.java:7513)
        at android.view.Choreographer$CallbackRecord.run(Choreographer.java:920)
    	at android.view.Choreographer.doCal
```",Can you close this issue to group all related information in one place?,"Here the problem is a bit different, multi touch zoom is working fine for 1 chart but if try to do it for 2 charts it crashes"
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/2385," i have found a bug, 
when ever we enter 1f or less then 1f in the entries....it doesnt add color in the piechart,this issue is not only for my app..but the sample app is also having same issue,

```
    entries.add(new PieEntry(1f, ""Monday""));
    entries.add(new PieEntry(1f,""Tuesday""));
    entries.add(new PieEntry(1f,""Wednesday""));
    setPieChart(entries);
```

I will get 3 entities but with no color,
Please fix this issue
","How to solve? I also encountered the same problem.
","@PhilJay  please solve this issue as soon as possible 
"
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/2106,"My Values:
![image](https://cloud.githubusercontent.com/assets/1205588/17442815/825c4c46-5aec-11e6-8b9b-df39263bd322.png)

The outputted graph:
![image](https://cloud.githubusercontent.com/assets/1205588/17442881/bad27500-5aec-11e6-87ac-0894b17ea8e8.png)

When the graph is largely positive:
![image](https://cloud.githubusercontent.com/assets/1205588/17442900/d00c652a-5aec-11e6-96cc-4e73e325d255.png)

Let me know if there is anything I can do to help debug. You can view it for yourself in my app https://play.google.com/store/apps/details?id=com.teamtol.livedota&hl=en by going to recent games and clicking on a few.
","What is the problem? Do you want the chart to start at zero?

`yAxis.setAxisMinValue(0f)` for positive chart

`yAxis.setAxisMaxValue(0f)` for negative chart
","@PhilJay sorry for not being more specific with the report. The issue is indeed that the first graph pictured does not start at 0. The reason I believe this is a bug is due to the fact that I am passing (0,0) as a value but it is not showing up in the graph that has large negative components. Even setting the last value to a positive number does not fix the issue. Is there perhaps some other value I need to set that I'm just not aware of?
"
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/2028,"Hi - I have set both 'LineDataSet.setDrawFilled(true)' and 'LineDataSet.setFillColor(...)' or 'LineDataSet.setFillDrawable(...API18...)' as per 'LineChartActivity1' example. For some weird reason, the area filled comes out as if it is w.r.t Y-axis. Can you help ?

<img width=""371"" alt=""screen shot 2016-07-16 at 4 17 02 am"" src=""https://cloud.githubusercontent.com/assets/13557123/16890513/04f42772-4b0d-11e6-859e-589c9971c4ce.png"">
<img width=""382"" alt=""screen shot 2016-07-16 at 4 23 45 am"" src=""https://cloud.githubusercontent.com/assets/13557123/16890535/285905d4-4b0d-11e6-83f9-e50ee40e8233.png"">
","Which device are you using?

What happens if you run the example app on your device? Does the issue then occur as well (e.g. in LineChartActivity1)?
","@PhilJay : I am using it on Genymotion (Google Nexus 5 - API 22).
 The example activity - graph  **1**  below - runs fine and shows the correct filled area. 

What do you suggest ?
 Does this have to do with baseline of the graph ? I mean, how does the graph know where the y-baseline of the shaded area should be ? 

**Maybe the graph is not w.r.t y-axis** but the baseline of the area is not at the min. of range of y values but somewhere in the middle. Attached are some more pics (graphs **2** through **4** below ).

**1**:
<img width=""562"" alt=""screen shot 2016-07-17 at 2 20 34 pm"" src=""https://cloud.githubusercontent.com/assets/13557123/16899665/ba0805d0-4c29-11e6-9fee-6c41ad2378d5.png"">

**2**: History for **_1 day_**:

<img width=""387"" alt=""screen shot 2016-07-17 at 4 53 35 pm"" src=""https://cloud.githubusercontent.com/assets/13557123/16900312/49945f90-4c3f-11e6-83a0-ff5b74f328b6.png"">
"
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/1895,"In Line chart when i increase first seekBar and when it reaches to approx value 350 app restarts it self.
I have attached zip file containing video of problem.
I tested this thing on Nexus 6. But not able to reproduc on nexus 4.
[MPAndroidChart Problem.zip](https://github.com/PhilJay/MPAndroidChart/files/324989/MPAndroidChart.Problem.zip)
","What kind of device are you using?

Could you tell me if the crash still occurs if you disable ""filled"" (the red gradient) option in the example you have shown me.
","No crash at all just simple restart of app as you can see in device. I'm using nexus 6(Lollipop) and Nexus 4(Lollipop). 
problem occur in only Nexus 6 but not reproducible on Nexus 4.
"
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/1779,"After updating library to 2.2.4 in my app some of my charts are messed.
I can't find differences in the usage between these version so I think this could be a bug.

![mpchartengine-difference-222vs224](https://cloud.githubusercontent.com/assets/963361/15333315/7245b516-1c69-11e6-9863-ebbbff3ad3c6.jpg)

Here's my styling for the chart

``````
   ```
            mChartView = (LineChart) findViewById(R.id.linechart);
            mChartView.setVisibility(View.VISIBLE);
            mChartView.setBorderWidth(0f);
            mChartView.setData(mDataChart);
            mChartView.setDrawBorders(false);
            mChartView.setDrawGridBackground(false);
            mChartView.setDescription(null);

            mChartView.setGridBackgroundColor(Color.parseColor(""#000000""));
            mChartView.getXAxis().setDrawAxisLine(false);
            mChartView.getXAxis().setPosition(XAxis.XAxisPosition.BOTTOM);
            mChartView.getAxis(YAxis.AxisDependency.LEFT).setDrawAxisLine(false);
            mChartView.getAxis(YAxis.AxisDependency.RIGHT).setEnabled(false);
            mChartView.getLegend().setForm(Legend.LegendForm.CIRCLE);
            mChartView.getAxis(YAxis.AxisDependency.LEFT).setStartAtZero(false);
            mChartView.getAxis(YAxis.AxisDependency.LEFT).setValueFormatter(new           YAxisValueFormatter() {
                @Override
                public String getFormattedValue(float value, YAxis yAxis) {
                    DecimalFormat mFormat = new DecimalFormat(""###,###,##0.00"");
                    return mFormat.format(value);
                }
            });

            MyMarkerView mv = new MyMarkerView(getBaseContext(), R.layout.marker_view);
            mChartView.setMarkerView(mv);
            mChartView.invalidate();
``````

```
```
","Could you post your whole setup (all the code from the activity or fragment)?
","So maybe this is related with data. I'm abroad right now but later I'll try to get more info for you.
This could be related also with the number format

#,## 

I've got a lots of values where the third place is important

0.051
0,053

I think this related with creating the axis.

Please try this on a list with numbers like:

0,21 - 0,29
0,031 - 0,050

The in 2.2.4 Axis is not showing (as you can see on the image). Everything works fine when you have bigger numbers.

I didn't change anything else to create the screenshots - just the 2.2.2 -> 2.2.4 update.
I'm back on 2.2.2
"
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/1604,"For example, method should include

```
copied.setDrawValues( isDrawValuesEnabled() );
```

Without it, the mDrawValues is lost during the copy.
","What do you think?
Should we keep it or just remove it from the library?
",
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/1484,"![device-2016-02-18-151807](https://cloud.githubusercontent.com/assets/4515769/13156949/256f9c0e-d653-11e5-9664-f544cca4bef8.png)

In the above chart, you can see that labels with the letter ""p"" or ""g"" (letters that go below the baseline) are not lined up with the rest of the labels. Maybe they have a different line height and it's throwing off the drawing calculations.
","Should a pull request be made to merge it into the source?
",
PhilJay/MPAndroidChart,https://github.com/PhilJay/MPAndroidChart/issues/1475,"Hi,

I'm using a **LineChart** and I'm having an option to toggle visiblity of lines in the chart by using the `lineDataSet.setVisible()` method. However when I set a line to not visible then the values for each entry is still shown (I'm using `lineData.setDrawValues(true)`. 

So there is no line visible but the values are still visible. Is there anyway to also toggle the visibilty of the values for each specific line? I don't want use `lineData.setDrawValues(false)` because that affects the whole chart. And I don't want to remove the dataset either, just make it not visible.

Thanks
","Which library version are you using?
","I'm using v2.2.0.
"
